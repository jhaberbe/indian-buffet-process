{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bcc2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\"/home/jhaberbe/Projects/indian-buffet-process/data/new_annotations.h5ad\")\n",
    "adata = adata[adata.obs[\"cell_type\"].eq(\"Macrophage\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7667098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == \"cuda\":\n",
    "    print(\"CUDA Enabled\")\n",
    "\n",
    "def setup_torch_data(adata, specimen_name: str = \"folder\"):\n",
    "    X = torch.tensor(adata[:, (adata.X > 0).mean(axis=0) > 0.05].X.todense())\n",
    "    size_factor = torch.tensor(np.log((adata.X.sum(axis=1) / adata.X.sum(axis=1).mean())))\n",
    "    folder = torch.tensor(pd.Categorical(adata.obs[specimen_name]).codes).float()\n",
    "    return X, size_factor, folder\n",
    "\n",
    "X, size_factor, folder = setup_torch_data(adata, specimen_name=\"orig.ident\")\n",
    "\n",
    "X = X.to(device)\n",
    "size_factor = size_factor.to(device)\n",
    "folder = folder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9c81ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, JitTraceMeanField_ELBO, JitTrace_ELBO\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float\n",
    "\n",
    "def model(X, K_tensor, size_factor, group_assignments, alpha=1.0):\n",
    "    K = int(K_tensor.item())\n",
    "    N, D = X.shape\n",
    "    G = int(torch.max(group_assignments).item() + 1)\n",
    "\n",
    "    # IBP stick-breaking beta parameters\n",
    "    alpha_param = pyro.param(\n",
    "        \"alpha\",\n",
    "        dist.Gamma(torch.full((), alpha, device=device, dtype=dtype),\n",
    "                   torch.full((), 1.0, device=device, dtype=dtype)),\n",
    "        constraint=dist.constraints.positive,\n",
    "    )\n",
    "    beta_param = pyro.param(\n",
    "        \"beta\",\n",
    "        dist.Gamma(alpha_param,\n",
    "                   torch.full((), 1.0, device=device, dtype=dtype)),\n",
    "        constraint=dist.constraints.positive,\n",
    "    )\n",
    "\n",
    "    with pyro.plate(\"ibp_features\", K):\n",
    "        v = pyro.sample(\"v\", dist.Beta(alpha_param, beta_param))  # [K]\n",
    "\n",
    "    pi = torch.cumprod(v, dim=0)\n",
    "\n",
    "    W = pyro.sample(\n",
    "        \"W\",\n",
    "        dist.Normal(torch.full((), 0.0, device=device, dtype=dtype),\n",
    "                    torch.full((), 1.0, device=device, dtype=dtype))\n",
    "        .expand([K, D]).to_event(2)\n",
    "    )\n",
    "\n",
    "    # Shared dispersion across all groups\n",
    "    r = pyro.sample(\n",
    "        \"r\",\n",
    "        dist.Gamma(torch.full((D,), 2.0, device=device, dtype=dtype),\n",
    "                   torch.full((D,), 1.0, device=device, dtype=dtype)).to_event(1)\n",
    "    )\n",
    "\n",
    "    # Per-group (folder) logits, shape [G, D]\n",
    "    folder_logit = pyro.param(\n",
    "        \"folder_logit\",\n",
    "        torch.zeros(G, D, device=device, dtype=dtype),\n",
    "    )\n",
    "\n",
    "    with pyro.plate(\"observations\", N):\n",
    "        z = pyro.sample(\"Z\", dist.Bernoulli(pi).to_event(1))  # [N, K]\n",
    "        logits = (z @ W) + size_factor.reshape(-1, 1)  # [N, D]\n",
    "\n",
    "        # Add per-group logit shift\n",
    "        group_logit_offset = folder_logit[group_assignments.int()]  # [N, D]\n",
    "        logits = logits + group_logit_offset\n",
    "\n",
    "        logits = torch.clamp(logits, -15, 15)\n",
    "        pyro.sample(\"X\", dist.NegativeBinomial(total_count=r, logits=logits).to_event(1), obs=X)\n",
    "\n",
    "\n",
    "def guide(X, K_tensor, size_factor, group_assignments, alpha=1.0):\n",
    "    K = int(K_tensor.item())\n",
    "    N, D = X.shape\n",
    "\n",
    "    with pyro.plate(\"ibp_features\", K):\n",
    "        qv_alpha = pyro.param(\"qv_alpha\", torch.ones(K, device=device, dtype=dtype),\n",
    "                              constraint=dist.constraints.greater_than(1e-2))\n",
    "        qv_beta = pyro.param(\"qv_beta\", torch.ones(K, device=device, dtype=dtype),\n",
    "                             constraint=dist.constraints.greater_than(1e-2))\n",
    "        pyro.sample(\"v\", dist.Beta(qv_alpha, qv_beta))\n",
    "\n",
    "    with pyro.plate(\"observations\", N):\n",
    "        qz_logits = pyro.param(\"qz_logits\", (torch.randn(N, K, device=device, dtype=dtype) * 0.01 - 2.0))\n",
    "        pyro.sample(\"Z\", dist.RelaxedBernoulliStraightThrough(\n",
    "            temperature=torch.full((), 0.5, device=device, dtype=dtype),\n",
    "            logits=qz_logits\n",
    "        ).to_event(1))\n",
    "\n",
    "    qW_loc = pyro.param(\"qW_loc\", torch.randn(K, D, device=device, dtype=dtype))\n",
    "    qW_scale = pyro.param(\"qW_scale\", torch.ones(K, D, device=device, dtype=dtype),\n",
    "                          constraint=dist.constraints.positive)\n",
    "    pyro.sample(\"W\", dist.Normal(qW_loc, qW_scale).to_event(2))\n",
    "\n",
    "    # Shared dispersion\n",
    "    qr_alpha = pyro.param(\"qr_alpha\", torch.ones(D, device=device, dtype=dtype),\n",
    "                          constraint=dist.constraints.positive)\n",
    "    qr_beta = pyro.param(\"qr_beta\", torch.ones(D, device=device, dtype=dtype),\n",
    "                         constraint=dist.constraints.positive)\n",
    "    pyro.sample(\"r\", dist.Gamma(qr_alpha, qr_beta).to_event(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b1a0764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">macrophage-2-individual-dispersions</strong> at: <a href='https://wandb.ai/kibr/ibp-nb-model-choroid-plexus/runs/3h5cbge1' target=\"_blank\">https://wandb.ai/kibr/ibp-nb-model-choroid-plexus/runs/3h5cbge1</a><br> View project at: <a href='https://wandb.ai/kibr/ibp-nb-model-choroid-plexus' target=\"_blank\">https://wandb.ai/kibr/ibp-nb-model-choroid-plexus</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250508_153410-3h5cbge1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jhaberbe/Projects/indian-buffet-process/notebook/wandb/run-20250508_153432-hucuzdsc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kibr/ibp-nb-model-choroid-plexus/runs/hucuzdsc' target=\"_blank\">macrophage-2-individual-dispersions</a></strong> to <a href='https://wandb.ai/kibr/ibp-nb-model-choroid-plexus' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kibr/ibp-nb-model-choroid-plexus' target=\"_blank\">https://wandb.ai/kibr/ibp-nb-model-choroid-plexus</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kibr/ibp-nb-model-choroid-plexus/runs/hucuzdsc' target=\"_blank\">https://wandb.ai/kibr/ibp-nb-model-choroid-plexus/runs/hucuzdsc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kibr/ibp-nb-model-choroid-plexus/runs/hucuzdsc?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x79ad81765d10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example training loop\n",
    "pyro.clear_param_store()\n",
    "\n",
    "X = X.to(device=device, dtype=dtype)\n",
    "size_factor = size_factor.to(device=device, dtype=dtype)\n",
    "K = torch.tensor(40, device=device)  # or whatever value, as a tensor\n",
    "folder = folder.to(device)\n",
    "\n",
    "optimizer = ClippedAdam({\"lr\": 0.01})\n",
    "elbo = JitTrace_ELBO() # Real Fn Fast\n",
    "svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "import wandb\n",
    "wandb.init(project=\"ibp-nb-model-choroid-plexus\", name=\"macrophage-2-individual-dispersions\", config={\n",
    "    \"latent_dim_K\": K,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"elbo\": \"JitTrace_ELBO\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "605b2e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182257/2470522040.py:67: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  K = int(K_tensor.item())\n",
      "/tmp/ipykernel_182257/2470522040.py:11: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  K = int(K_tensor.item())\n",
      "/tmp/ipykernel_182257/2470522040.py:13: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  G = int(torch.max(group_assignments).item() + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0] Loss: 2.84e+08 -1.9961990118026733 0.0\n",
      "[Step 1] Loss: 2.85e+08 -1.9938758611679077 0.0\n",
      "[Step 2] Loss: 2.74e+08 -1.9922291040420532 0.0\n",
      "[Step 3] Loss: 2.74e+08 -1.990607500076294 0.0\n",
      "[Step 4] Loss: 2.72e+08 -1.9889328479766846 0.0\n",
      "[Step 5] Loss: 2.60e+08 -1.9871249198913574 0.0\n",
      "[Step 6] Loss: 2.58e+08 -1.985206127166748 0.0\n",
      "[Step 7] Loss: 2.54e+08 -1.98308527469635 0.0\n",
      "[Step 8] Loss: 2.50e+08 -1.9808106422424316 0.0\n",
      "[Step 9] Loss: 2.47e+08 -1.978339672088623 0.0\n",
      "[Step 10] Loss: 2.38e+08 -1.9755586385726929 0.0\n",
      "[Step 11] Loss: 2.38e+08 -1.9725451469421387 0.0\n",
      "[Step 12] Loss: 2.33e+08 -1.9692996740341187 0.0\n",
      "[Step 13] Loss: 2.30e+08 -1.9658384323120117 0.0\n",
      "[Step 14] Loss: 2.31e+08 -1.962188482284546 0.0\n",
      "[Step 15] Loss: 2.26e+08 -1.9583611488342285 0.0\n",
      "[Step 16] Loss: 2.26e+08 -1.9544074535369873 0.0\n",
      "[Step 17] Loss: 2.21e+08 -1.9502997398376465 0.0\n",
      "[Step 18] Loss: 2.18e+08 -1.9460418224334717 0.0\n",
      "[Step 19] Loss: 2.18e+08 -1.9417006969451904 0.0\n",
      "[Step 20] Loss: 2.16e+08 -1.93726646900177 0.0\n",
      "[Step 21] Loss: 2.12e+08 -1.9327216148376465 0.0\n",
      "[Step 22] Loss: 2.09e+08 -1.9280736446380615 0.0\n",
      "[Step 23] Loss: 2.10e+08 -1.9233546257019043 0.0\n",
      "[Step 24] Loss: 2.06e+08 -1.9185715913772583 0.0\n",
      "[Step 25] Loss: 2.07e+08 -1.9137508869171143 0.0\n",
      "[Step 26] Loss: 2.01e+08 -1.9088689088821411 0.0\n",
      "[Step 27] Loss: 1.97e+08 -1.903908610343933 0.0\n",
      "[Step 28] Loss: 1.99e+08 -1.8989033699035645 0.0\n",
      "[Step 29] Loss: 1.94e+08 -1.8938411474227905 0.0\n",
      "[Step 30] Loss: 1.97e+08 -1.8887312412261963 0.0\n",
      "[Step 31] Loss: 1.94e+08 -1.8835841417312622 0.0\n",
      "[Step 32] Loss: 1.96e+08 -1.8784183263778687 0.0\n",
      "[Step 33] Loss: 1.92e+08 -1.873223900794983 0.0\n",
      "[Step 34] Loss: 1.90e+08 -1.8680108785629272 0.0\n",
      "[Step 35] Loss: 1.88e+08 -1.8628007173538208 0.0\n",
      "[Step 36] Loss: 1.87e+08 -1.8575751781463623 0.0\n",
      "[Step 37] Loss: 1.87e+08 -1.8523344993591309 0.0\n",
      "[Step 38] Loss: 1.86e+08 -1.8470906019210815 0.0\n",
      "[Step 39] Loss: 1.84e+08 -1.8418490886688232 0.0\n",
      "[Step 40] Loss: 1.83e+08 -1.8366100788116455 0.0\n",
      "[Step 41] Loss: 1.84e+08 -1.8313733339309692 0.0\n",
      "[Step 42] Loss: 1.84e+08 -1.826154351234436 0.0\n",
      "[Step 43] Loss: 1.83e+08 -1.820946455001831 0.0\n",
      "[Step 44] Loss: 1.84e+08 -1.8157494068145752 0.0\n",
      "[Step 45] Loss: 1.81e+08 -1.8105725049972534 0.0\n",
      "[Step 46] Loss: 1.81e+08 -1.805410623550415 0.0\n",
      "[Step 47] Loss: 1.80e+08 -1.8002784252166748 0.0\n",
      "[Step 48] Loss: 1.80e+08 -1.7951663732528687 0.0\n",
      "[Step 49] Loss: 1.78e+08 -1.7900691032409668 0.0\n",
      "[Step 50] Loss: 1.78e+08 -1.784986972808838 0.0\n",
      "[Step 51] Loss: 1.79e+08 -1.77994704246521 0.0\n",
      "[Step 52] Loss: 1.78e+08 -1.7749292850494385 0.0\n",
      "[Step 53] Loss: 1.79e+08 -1.7699490785598755 0.0\n",
      "[Step 54] Loss: 1.76e+08 -1.7649670839309692 0.0\n",
      "[Step 55] Loss: 1.75e+08 -1.7600189447402954 0.0\n",
      "[Step 56] Loss: 1.75e+08 -1.7550774812698364 0.0\n",
      "[Step 57] Loss: 1.76e+08 -1.7501596212387085 0.0\n",
      "[Step 58] Loss: 1.75e+08 -1.7452571392059326 0.0\n",
      "[Step 59] Loss: 1.75e+08 -1.7403700351715088 0.0\n",
      "[Step 60] Loss: 1.72e+08 -1.7355254888534546 0.0\n",
      "[Step 61] Loss: 1.74e+08 -1.7307072877883911 0.0\n",
      "[Step 62] Loss: 1.74e+08 -1.7259024381637573 0.0\n",
      "[Step 63] Loss: 1.72e+08 -1.721117615699768 0.0\n",
      "[Step 64] Loss: 1.72e+08 -1.716353178024292 0.0\n",
      "[Step 65] Loss: 1.71e+08 -1.711634635925293 0.0\n",
      "[Step 66] Loss: 1.71e+08 -1.706937551498413 0.0\n",
      "[Step 67] Loss: 1.71e+08 -1.702315092086792 0.0\n",
      "[Step 68] Loss: 1.72e+08 -1.6977378129959106 0.0\n",
      "[Step 69] Loss: 1.73e+08 -1.6932120323181152 0.0\n",
      "[Step 70] Loss: 1.70e+08 -1.6887286901474 0.0\n",
      "[Step 71] Loss: 1.69e+08 -1.68425714969635 0.0\n",
      "[Step 72] Loss: 1.70e+08 -1.6798006296157837 0.0\n",
      "[Step 73] Loss: 1.70e+08 -1.6753811836242676 0.0\n",
      "[Step 74] Loss: 1.69e+08 -1.670969843864441 0.0\n",
      "[Step 75] Loss: 1.71e+08 -1.6666029691696167 0.0\n",
      "[Step 76] Loss: 1.67e+08 -1.6622532606124878 0.0\n",
      "[Step 77] Loss: 1.69e+08 -1.6579525470733643 0.0\n",
      "[Step 78] Loss: 1.69e+08 -1.6536920070648193 0.0\n",
      "[Step 79] Loss: 1.71e+08 -1.6494604349136353 0.0\n",
      "[Step 80] Loss: 1.67e+08 -1.645246148109436 0.0\n",
      "[Step 81] Loss: 1.70e+08 -1.6410706043243408 0.0\n",
      "[Step 82] Loss: 1.68e+08 -1.6369267702102661 0.0\n",
      "[Step 83] Loss: 1.67e+08 -1.6327883005142212 0.0\n",
      "[Step 84] Loss: 1.69e+08 -1.628700613975525 0.0\n",
      "[Step 85] Loss: 1.68e+08 -1.6246274709701538 0.0\n",
      "[Step 86] Loss: 1.68e+08 -1.6205804347991943 0.0\n",
      "[Step 87] Loss: 1.67e+08 -1.6165465116500854 0.0\n",
      "[Step 88] Loss: 1.67e+08 -1.6125634908676147 0.0\n",
      "[Step 89] Loss: 1.67e+08 -1.6086206436157227 0.0\n",
      "[Step 90] Loss: 1.66e+08 -1.604673981666565 0.0\n",
      "[Step 91] Loss: 1.66e+08 -1.6007750034332275 0.0\n",
      "[Step 92] Loss: 1.67e+08 -1.5968945026397705 0.0\n",
      "[Step 93] Loss: 1.66e+08 -1.5930391550064087 0.0\n",
      "[Step 94] Loss: 1.68e+08 -1.5892057418823242 0.0\n",
      "[Step 95] Loss: 1.66e+08 -1.5853818655014038 0.0\n",
      "[Step 96] Loss: 1.67e+08 -1.5816566944122314 0.0\n",
      "[Step 97] Loss: 1.66e+08 -1.5779402256011963 0.0\n",
      "[Step 98] Loss: 1.66e+08 -1.574216365814209 0.0\n",
      "[Step 99] Loss: 1.65e+08 -1.5705013275146484 0.0\n",
      "[Step 100] Loss: 1.65e+08 -1.5667942762374878 0.0\n",
      "[Step 101] Loss: 1.64e+08 -1.563087821006775 0.0\n",
      "[Step 102] Loss: 1.66e+08 -1.5593929290771484 0.0\n",
      "[Step 103] Loss: 1.65e+08 -1.5556987524032593 0.0\n",
      "[Step 104] Loss: 1.65e+08 -1.5520145893096924 0.0\n",
      "[Step 105] Loss: 1.66e+08 -1.5483416318893433 0.0\n",
      "[Step 106] Loss: 1.64e+08 -1.5446833372116089 0.0\n",
      "[Step 107] Loss: 1.64e+08 -1.5410435199737549 0.0\n",
      "[Step 108] Loss: 1.64e+08 -1.5374544858932495 0.0\n",
      "[Step 109] Loss: 1.64e+08 -1.5339044332504272 0.0\n",
      "[Step 110] Loss: 1.65e+08 -1.5303839445114136 0.0\n",
      "[Step 111] Loss: 1.65e+08 -1.5268852710723877 0.0\n",
      "[Step 112] Loss: 1.64e+08 -1.5234167575836182 0.0\n",
      "[Step 113] Loss: 1.67e+08 -1.5199928283691406 0.0\n",
      "[Step 114] Loss: 1.65e+08 -1.5165880918502808 0.0\n",
      "[Step 115] Loss: 1.66e+08 -1.513249397277832 0.0\n",
      "[Step 116] Loss: 1.64e+08 -1.5098884105682373 0.0\n",
      "[Step 117] Loss: 1.64e+08 -1.5065432786941528 0.0\n",
      "[Step 118] Loss: 1.64e+08 -1.5032403469085693 0.0\n",
      "[Step 119] Loss: 1.64e+08 -1.4999943971633911 0.0\n",
      "[Step 120] Loss: 1.67e+08 -1.4967989921569824 0.0\n",
      "[Step 121] Loss: 1.64e+08 -1.493623971939087 0.0\n",
      "[Step 122] Loss: 1.63e+08 -1.4904731512069702 0.0\n",
      "[Step 123] Loss: 1.64e+08 -1.4873290061950684 0.0\n",
      "[Step 124] Loss: 1.64e+08 -1.484182596206665 0.0\n",
      "[Step 125] Loss: 1.62e+08 -1.4810538291931152 0.0\n",
      "[Step 126] Loss: 1.64e+08 -1.4779746532440186 0.0\n",
      "[Step 127] Loss: 1.63e+08 -1.4748952388763428 0.0\n",
      "[Step 128] Loss: 1.64e+08 -1.4718871116638184 0.0\n",
      "[Step 129] Loss: 1.64e+08 -1.4689135551452637 0.0\n",
      "[Step 130] Loss: 1.61e+08 -1.4659595489501953 0.0\n",
      "[Step 131] Loss: 1.61e+08 -1.4630402326583862 0.0\n",
      "[Step 132] Loss: 1.62e+08 -1.4601303339004517 0.0\n",
      "[Step 133] Loss: 1.62e+08 -1.4572503566741943 0.0\n",
      "[Step 134] Loss: 1.60e+08 -1.454380989074707 0.0\n",
      "[Step 135] Loss: 1.63e+08 -1.4515174627304077 0.0\n",
      "[Step 136] Loss: 1.62e+08 -1.4486995935440063 0.0\n",
      "[Step 137] Loss: 1.61e+08 -1.445872187614441 0.0\n",
      "[Step 138] Loss: 1.62e+08 -1.44305419921875 0.0\n",
      "[Step 139] Loss: 1.60e+08 -1.4402177333831787 0.0\n",
      "[Step 140] Loss: 1.62e+08 -1.4374102354049683 0.0\n",
      "[Step 141] Loss: 1.61e+08 -1.4346067905426025 0.0\n",
      "[Step 142] Loss: 1.62e+08 -1.4318106174468994 0.0\n",
      "[Step 143] Loss: 1.60e+08 -1.4290496110916138 0.0\n",
      "[Step 144] Loss: 1.63e+08 -1.426356315612793 0.0\n",
      "[Step 145] Loss: 1.62e+08 -1.423707365989685 0.0\n",
      "[Step 146] Loss: 1.60e+08 -1.4210717678070068 0.0\n",
      "[Step 147] Loss: 1.62e+08 -1.4184801578521729 0.0\n",
      "[Step 148] Loss: 1.61e+08 -1.4159536361694336 0.0\n",
      "[Step 149] Loss: 1.62e+08 -1.4134379625320435 0.0\n",
      "[Step 150] Loss: 1.59e+08 -1.410925030708313 0.0\n",
      "[Step 151] Loss: 1.59e+08 -1.4083788394927979 0.0\n",
      "[Step 152] Loss: 1.62e+08 -1.4058668613433838 0.0\n",
      "[Step 153] Loss: 1.62e+08 -1.403361439704895 0.0\n",
      "[Step 154] Loss: 1.61e+08 -1.4008854627609253 0.0\n",
      "[Step 155] Loss: 1.62e+08 -1.3983945846557617 0.0\n",
      "[Step 156] Loss: 1.63e+08 -1.3959864377975464 0.0\n",
      "[Step 157] Loss: 1.60e+08 -1.393620252609253 0.0\n",
      "[Step 158] Loss: 1.60e+08 -1.3912845849990845 0.0\n",
      "[Step 159] Loss: 1.59e+08 -1.38898503780365 0.0\n",
      "[Step 160] Loss: 1.62e+08 -1.3867599964141846 0.0\n",
      "[Step 161] Loss: 1.59e+08 -1.3845493793487549 0.0\n",
      "[Step 162] Loss: 1.64e+08 -1.3823680877685547 0.0\n",
      "[Step 163] Loss: 1.62e+08 -1.3802330493927002 0.0\n",
      "[Step 164] Loss: 1.62e+08 -1.3781788349151611 0.0\n",
      "[Step 165] Loss: 1.62e+08 -1.3761745691299438 0.0\n",
      "[Step 166] Loss: 1.61e+08 -1.374150037765503 0.0\n",
      "[Step 167] Loss: 1.60e+08 -1.3721668720245361 0.0\n",
      "[Step 168] Loss: 1.60e+08 -1.3701938390731812 0.0\n",
      "[Step 169] Loss: 1.60e+08 -1.368200659751892 0.0\n",
      "[Step 170] Loss: 1.62e+08 -1.3662656545639038 0.0\n",
      "[Step 171] Loss: 1.60e+08 -1.3643378019332886 0.0\n",
      "[Step 172] Loss: 1.61e+08 -1.3624753952026367 0.0\n",
      "[Step 173] Loss: 1.61e+08 -1.3606218099594116 0.0\n",
      "[Step 174] Loss: 1.60e+08 -1.3587573766708374 0.0\n",
      "[Step 175] Loss: 1.59e+08 -1.3568979501724243 0.0\n",
      "[Step 176] Loss: 1.60e+08 -1.3550652265548706 0.0\n",
      "[Step 177] Loss: 1.60e+08 -1.3532530069351196 0.0\n",
      "[Step 178] Loss: 1.59e+08 -1.351501703262329 0.0\n",
      "[Step 179] Loss: 1.60e+08 -1.3498308658599854 0.0\n",
      "[Step 180] Loss: 1.60e+08 -1.3482043743133545 0.0\n",
      "[Step 181] Loss: 1.59e+08 -1.3466047048568726 0.0\n",
      "[Step 182] Loss: 1.58e+08 -1.3450790643692017 0.0\n",
      "[Step 183] Loss: 1.58e+08 -1.3435717821121216 0.0\n",
      "[Step 184] Loss: 1.60e+08 -1.3420578241348267 0.0\n",
      "[Step 185] Loss: 1.58e+08 -1.3405824899673462 0.0\n",
      "[Step 186] Loss: 1.58e+08 -1.3391270637512207 0.0\n",
      "[Step 187] Loss: 1.59e+08 -1.3376730680465698 0.0\n",
      "[Step 188] Loss: 1.57e+08 -1.3361964225769043 0.0\n",
      "[Step 189] Loss: 1.58e+08 -1.3347264528274536 0.0\n",
      "[Step 190] Loss: 1.59e+08 -1.3332899808883667 0.0\n",
      "[Step 191] Loss: 1.58e+08 -1.3319140672683716 0.0\n",
      "[Step 192] Loss: 1.57e+08 -1.330557107925415 0.0\n",
      "[Step 193] Loss: 1.59e+08 -1.3293102979660034 0.0\n",
      "[Step 194] Loss: 1.57e+08 -1.3280904293060303 0.0\n",
      "[Step 195] Loss: 1.59e+08 -1.3268787860870361 0.0\n",
      "[Step 196] Loss: 1.59e+08 -1.3257166147232056 0.0\n",
      "[Step 197] Loss: 1.60e+08 -1.3246464729309082 0.0\n",
      "[Step 198] Loss: 1.59e+08 -1.323588490486145 0.0\n",
      "[Step 199] Loss: 1.58e+08 -1.3225404024124146 0.0\n",
      "[Step 200] Loss: 1.56e+08 -1.3214733600616455 0.0\n",
      "[Step 201] Loss: 1.58e+08 -1.3204718828201294 0.0\n",
      "[Step 202] Loss: 1.58e+08 -1.319465160369873 0.0\n",
      "[Step 203] Loss: 1.57e+08 -1.3184943199157715 0.0\n",
      "[Step 204] Loss: 1.59e+08 -1.3176130056381226 0.0\n",
      "[Step 205] Loss: 1.57e+08 -1.3167390823364258 0.0\n",
      "[Step 206] Loss: 1.55e+08 -1.3158808946609497 0.0\n",
      "[Step 207] Loss: 1.58e+08 -1.315100908279419 0.0\n",
      "[Step 208] Loss: 1.56e+08 -1.3143043518066406 0.0\n",
      "[Step 209] Loss: 1.57e+08 -1.313546061515808 0.0\n",
      "[Step 210] Loss: 1.58e+08 -1.3128128051757812 0.0\n",
      "[Step 211] Loss: 1.56e+08 -1.312091588973999 0.0\n",
      "[Step 212] Loss: 1.57e+08 -1.3114163875579834 0.0\n",
      "[Step 213] Loss: 1.59e+08 -1.3107848167419434 0.0\n",
      "[Step 214] Loss: 1.55e+08 -1.3101295232772827 0.0\n",
      "[Step 215] Loss: 1.55e+08 -1.309486985206604 0.0\n",
      "[Step 216] Loss: 1.56e+08 -1.3088769912719727 0.0\n",
      "[Step 217] Loss: 1.57e+08 -1.3083373308181763 0.0\n",
      "[Step 218] Loss: 1.56e+08 -1.3078575134277344 0.0\n",
      "[Step 219] Loss: 1.57e+08 -1.3074127435684204 0.0\n",
      "[Step 220] Loss: 1.55e+08 -1.3069168329238892 0.0\n",
      "[Step 221] Loss: 1.54e+08 -1.3064470291137695 0.0\n",
      "[Step 222] Loss: 1.57e+08 -1.3060379028320312 0.0\n",
      "[Step 223] Loss: 1.55e+08 -1.3055988550186157 0.0\n",
      "[Step 224] Loss: 1.55e+08 -1.3052276372909546 0.0\n",
      "[Step 225] Loss: 1.55e+08 -1.3048932552337646 0.0\n",
      "[Step 226] Loss: 1.55e+08 -1.3045947551727295 0.0\n",
      "[Step 227] Loss: 1.56e+08 -1.3043732643127441 0.0\n",
      "[Step 228] Loss: 1.55e+08 -1.3041293621063232 0.0\n",
      "[Step 229] Loss: 1.56e+08 -1.3039699792861938 0.0\n",
      "[Step 230] Loss: 1.56e+08 -1.3038829565048218 0.0\n",
      "[Step 231] Loss: 1.53e+08 -1.3038147687911987 0.0\n",
      "[Step 232] Loss: 1.53e+08 -1.3037093877792358 0.0\n",
      "[Step 233] Loss: 1.55e+08 -1.3036421537399292 0.0\n",
      "[Step 234] Loss: 1.54e+08 -1.303583025932312 0.0\n",
      "[Step 235] Loss: 1.54e+08 -1.303525447845459 0.0\n",
      "[Step 236] Loss: 1.53e+08 -1.3034751415252686 0.0\n",
      "[Step 237] Loss: 1.54e+08 -1.3034744262695312 0.0\n",
      "[Step 238] Loss: 1.55e+08 -1.3035639524459839 0.0\n",
      "[Step 239] Loss: 1.54e+08 -1.3036330938339233 0.0\n",
      "[Step 240] Loss: 1.54e+08 -1.3037358522415161 0.0\n",
      "[Step 241] Loss: 1.56e+08 -1.303887963294983 0.0\n",
      "[Step 242] Loss: 1.55e+08 -1.3041507005691528 0.0\n",
      "[Step 243] Loss: 1.52e+08 -1.304390549659729 0.0\n",
      "[Step 244] Loss: 1.55e+08 -1.3046190738677979 0.0\n",
      "[Step 245] Loss: 1.55e+08 -1.3049050569534302 0.0\n",
      "[Step 246] Loss: 1.53e+08 -1.3052494525909424 0.0\n",
      "[Step 247] Loss: 1.52e+08 -1.3055493831634521 0.0\n",
      "[Step 248] Loss: 1.53e+08 -1.3059041500091553 0.0\n",
      "[Step 249] Loss: 1.53e+08 -1.3063024282455444 0.0\n",
      "[Step 250] Loss: 1.53e+08 -1.3066959381103516 0.0\n",
      "[Step 251] Loss: 1.54e+08 -1.3071541786193848 0.0\n",
      "[Step 252] Loss: 1.54e+08 -1.30763578414917 0.0\n",
      "[Step 253] Loss: 1.54e+08 -1.3080743551254272 0.0\n",
      "[Step 254] Loss: 1.52e+08 -1.3085041046142578 0.0\n",
      "[Step 255] Loss: 1.53e+08 -1.3088746070861816 0.0\n",
      "[Step 256] Loss: 1.53e+08 -1.309303879737854 0.0\n",
      "[Step 257] Loss: 1.52e+08 -1.30976140499115 0.0\n",
      "[Step 258] Loss: 1.53e+08 -1.3102543354034424 0.0\n",
      "[Step 259] Loss: 1.53e+08 -1.3107718229293823 0.0\n",
      "[Step 260] Loss: 1.50e+08 -1.3112704753875732 0.0\n",
      "[Step 261] Loss: 1.52e+08 -1.311816692352295 0.0\n",
      "[Step 262] Loss: 1.50e+08 -1.3124030828475952 0.0\n",
      "[Step 263] Loss: 1.52e+08 -1.3130711317062378 0.0\n",
      "[Step 264] Loss: 1.53e+08 -1.3137855529785156 0.0\n",
      "[Step 265] Loss: 1.52e+08 -1.3145105838775635 0.0\n",
      "[Step 266] Loss: 1.52e+08 -1.315254807472229 0.0\n",
      "[Step 267] Loss: 1.50e+08 -1.3160462379455566 0.0\n",
      "[Step 268] Loss: 1.51e+08 -1.3168666362762451 0.0\n",
      "[Step 269] Loss: 1.53e+08 -1.3177839517593384 0.0\n",
      "[Step 270] Loss: 1.53e+08 -1.3187190294265747 0.0\n",
      "[Step 271] Loss: 1.52e+08 -1.3197438716888428 0.0\n",
      "[Step 272] Loss: 1.50e+08 -1.3207652568817139 0.0\n",
      "[Step 273] Loss: 1.51e+08 -1.3218271732330322 0.0\n",
      "[Step 274] Loss: 1.51e+08 -1.3229472637176514 0.0\n",
      "[Step 275] Loss: 1.50e+08 -1.3240666389465332 0.0\n",
      "[Step 276] Loss: 1.50e+08 -1.3251703977584839 0.0\n",
      "[Step 277] Loss: 1.48e+08 -1.3263047933578491 0.0\n",
      "[Step 278] Loss: 1.49e+08 -1.3274637460708618 0.0\n",
      "[Step 279] Loss: 1.49e+08 -1.3286139965057373 0.0\n",
      "[Step 280] Loss: 1.49e+08 -1.3297014236450195 0.0\n",
      "[Step 281] Loss: 1.50e+08 -1.3308693170547485 0.0\n",
      "[Step 282] Loss: 1.49e+08 -1.3320491313934326 0.0\n",
      "[Step 283] Loss: 1.50e+08 -1.333248496055603 0.0\n",
      "[Step 284] Loss: 1.51e+08 -1.3344807624816895 0.0\n",
      "[Step 285] Loss: 1.50e+08 -1.3357281684875488 0.0\n",
      "[Step 286] Loss: 1.50e+08 -1.336977481842041 0.0\n",
      "[Step 287] Loss: 1.51e+08 -1.338283896446228 0.0\n",
      "[Step 288] Loss: 1.50e+08 -1.3396117687225342 0.0\n",
      "[Step 289] Loss: 1.49e+08 -1.34099280834198 0.0\n",
      "[Step 290] Loss: 1.50e+08 -1.3424264192581177 0.0\n",
      "[Step 291] Loss: 1.50e+08 -1.3438762426376343 0.0\n",
      "[Step 292] Loss: 1.50e+08 -1.3453565835952759 0.0\n",
      "[Step 293] Loss: 1.48e+08 -1.3468198776245117 0.0\n",
      "[Step 294] Loss: 1.49e+08 -1.3482677936553955 0.0\n",
      "[Step 295] Loss: 1.50e+08 -1.3497146368026733 0.0\n",
      "[Step 296] Loss: 1.49e+08 -1.3511593341827393 0.0\n",
      "[Step 297] Loss: 1.48e+08 -1.3525642156600952 0.0\n",
      "[Step 298] Loss: 1.49e+08 -1.3540383577346802 0.0\n",
      "[Step 299] Loss: 1.48e+08 -1.3555421829223633 0.0\n",
      "[Step 300] Loss: 1.48e+08 -1.3571215867996216 0.0\n",
      "[Step 301] Loss: 1.46e+08 -1.3586328029632568 0.0\n",
      "[Step 302] Loss: 1.48e+08 -1.3601949214935303 0.0\n",
      "[Step 303] Loss: 1.47e+08 -1.3617265224456787 0.0\n",
      "[Step 304] Loss: 1.47e+08 -1.3632278442382812 0.0\n",
      "[Step 305] Loss: 1.48e+08 -1.364748477935791 0.0\n",
      "[Step 306] Loss: 1.47e+08 -1.3663153648376465 0.0\n",
      "[Step 307] Loss: 1.46e+08 -1.3678284883499146 0.0\n",
      "[Step 308] Loss: 1.47e+08 -1.3693960905075073 0.0\n",
      "[Step 309] Loss: 1.47e+08 -1.3709841966629028 0.0\n",
      "[Step 310] Loss: 1.48e+08 -1.372585654258728 0.0\n",
      "[Step 311] Loss: 1.47e+08 -1.3742388486862183 0.0\n",
      "[Step 312] Loss: 1.46e+08 -1.3758841753005981 0.0\n",
      "[Step 313] Loss: 1.49e+08 -1.3776044845581055 0.0\n",
      "[Step 314] Loss: 1.47e+08 -1.3793067932128906 0.0\n",
      "[Step 315] Loss: 1.46e+08 -1.3810131549835205 0.0\n",
      "[Step 316] Loss: 1.46e+08 -1.3827074766159058 0.0\n",
      "[Step 317] Loss: 1.47e+08 -1.3844503164291382 0.0\n",
      "[Step 318] Loss: 1.47e+08 -1.3862879276275635 0.0\n",
      "[Step 319] Loss: 1.46e+08 -1.3881558179855347 0.0\n",
      "[Step 320] Loss: 1.46e+08 -1.3901318311691284 0.0\n",
      "[Step 321] Loss: 1.48e+08 -1.3922144174575806 0.0\n",
      "[Step 322] Loss: 1.47e+08 -1.394322395324707 0.0\n",
      "[Step 323] Loss: 1.46e+08 -1.3964147567749023 0.0\n",
      "[Step 324] Loss: 1.47e+08 -1.3985402584075928 0.0\n",
      "[Step 325] Loss: 1.47e+08 -1.4006692171096802 0.0\n",
      "[Step 326] Loss: 1.46e+08 -1.4028229713439941 0.0\n",
      "[Step 327] Loss: 1.46e+08 -1.4050028324127197 0.0\n",
      "[Step 328] Loss: 1.44e+08 -1.4071415662765503 0.0\n",
      "[Step 329] Loss: 1.46e+08 -1.4093059301376343 0.0\n",
      "[Step 330] Loss: 1.44e+08 -1.4114272594451904 0.0\n",
      "[Step 331] Loss: 1.44e+08 -1.4135111570358276 0.0\n",
      "[Step 332] Loss: 1.45e+08 -1.4156368970870972 0.0\n",
      "[Step 333] Loss: 1.44e+08 -1.417780876159668 0.0\n",
      "[Step 334] Loss: 1.44e+08 -1.4199309349060059 0.0\n",
      "[Step 335] Loss: 1.44e+08 -1.422078251838684 0.0\n",
      "[Step 336] Loss: 1.42e+08 -1.4242445230484009 0.0\n",
      "[Step 337] Loss: 1.45e+08 -1.4264672994613647 0.0\n",
      "[Step 338] Loss: 1.44e+08 -1.428735613822937 0.0\n",
      "[Step 339] Loss: 1.44e+08 -1.430969476699829 0.0\n",
      "[Step 340] Loss: 1.44e+08 -1.4332776069641113 0.0\n",
      "[Step 341] Loss: 1.44e+08 -1.435617208480835 0.0\n",
      "[Step 342] Loss: 1.44e+08 -1.4379440546035767 0.0\n",
      "[Step 343] Loss: 1.44e+08 -1.4402835369110107 0.0\n",
      "[Step 344] Loss: 1.44e+08 -1.4426651000976562 0.0\n",
      "[Step 345] Loss: 1.45e+08 -1.445093035697937 0.0\n",
      "[Step 346] Loss: 1.45e+08 -1.4475682973861694 0.0\n",
      "[Step 347] Loss: 1.45e+08 -1.450039029121399 0.0\n",
      "[Step 348] Loss: 1.44e+08 -1.4525269269943237 0.0\n",
      "[Step 349] Loss: 1.42e+08 -1.455007791519165 0.0\n",
      "[Step 350] Loss: 1.43e+08 -1.457490086555481 0.0\n",
      "[Step 351] Loss: 1.42e+08 -1.4599980115890503 0.0\n",
      "[Step 352] Loss: 1.44e+08 -1.462466835975647 0.0\n",
      "[Step 353] Loss: 1.43e+08 -1.4649354219436646 0.0\n",
      "[Step 354] Loss: 1.41e+08 -1.467403531074524 0.0\n",
      "[Step 355] Loss: 1.41e+08 -1.4698855876922607 0.0\n",
      "[Step 356] Loss: 1.43e+08 -1.472390055656433 0.0\n",
      "[Step 357] Loss: 1.42e+08 -1.474888801574707 0.0\n",
      "[Step 358] Loss: 1.42e+08 -1.4774292707443237 0.0\n",
      "[Step 359] Loss: 1.42e+08 -1.4799368381500244 0.0\n",
      "[Step 360] Loss: 1.43e+08 -1.4824246168136597 0.0\n",
      "[Step 361] Loss: 1.42e+08 -1.4849236011505127 0.0\n",
      "[Step 362] Loss: 1.41e+08 -1.4874567985534668 0.0\n",
      "[Step 363] Loss: 1.43e+08 -1.49003005027771 0.0\n",
      "[Step 364] Loss: 1.42e+08 -1.4926331043243408 0.0\n",
      "[Step 365] Loss: 1.41e+08 -1.49526047706604 0.0\n",
      "[Step 366] Loss: 1.42e+08 -1.4979476928710938 0.0\n",
      "[Step 367] Loss: 1.40e+08 -1.5006120204925537 0.0\n",
      "[Step 368] Loss: 1.41e+08 -1.5032602548599243 0.0\n",
      "[Step 369] Loss: 1.41e+08 -1.5059725046157837 0.0\n",
      "[Step 370] Loss: 1.41e+08 -1.5086643695831299 0.0\n",
      "[Step 371] Loss: 1.42e+08 -1.5113449096679688 0.0\n",
      "[Step 372] Loss: 1.42e+08 -1.5140933990478516 0.0\n",
      "[Step 373] Loss: 1.41e+08 -1.5168695449829102 0.0\n",
      "[Step 374] Loss: 1.41e+08 -1.519671082496643 0.0\n",
      "[Step 375] Loss: 1.40e+08 -1.5224604606628418 0.0\n",
      "[Step 376] Loss: 1.40e+08 -1.525189995765686 0.0\n",
      "[Step 377] Loss: 1.40e+08 -1.5279159545898438 0.0\n",
      "[Step 378] Loss: 1.41e+08 -1.530665636062622 0.0\n",
      "[Step 379] Loss: 1.39e+08 -1.5333970785140991 0.0\n",
      "[Step 380] Loss: 1.39e+08 -1.5361217260360718 0.0\n",
      "[Step 381] Loss: 1.40e+08 -1.5388312339782715 0.0\n",
      "[Step 382] Loss: 1.40e+08 -1.5415887832641602 0.0\n",
      "[Step 383] Loss: 1.40e+08 -1.54434335231781 0.0\n",
      "[Step 384] Loss: 1.39e+08 -1.547128677368164 0.0\n",
      "[Step 385] Loss: 1.41e+08 -1.5499159097671509 0.0\n",
      "[Step 386] Loss: 1.38e+08 -1.552696943283081 0.0\n",
      "[Step 387] Loss: 1.39e+08 -1.5554461479187012 0.0\n",
      "[Step 388] Loss: 1.38e+08 -1.5582112073898315 0.0\n",
      "[Step 389] Loss: 1.39e+08 -1.5610052347183228 0.0\n",
      "[Step 390] Loss: 1.39e+08 -1.5638483762741089 0.0\n",
      "[Step 391] Loss: 1.39e+08 -1.5666708946228027 0.0\n",
      "[Step 392] Loss: 1.39e+08 -1.5695043802261353 0.0\n",
      "[Step 393] Loss: 1.38e+08 -1.5723257064819336 0.0\n",
      "[Step 394] Loss: 1.38e+08 -1.5751606225967407 0.0\n",
      "[Step 395] Loss: 1.40e+08 -1.5779894590377808 0.0\n",
      "[Step 396] Loss: 1.38e+08 -1.5808161497116089 0.0\n",
      "[Step 397] Loss: 1.38e+08 -1.5836660861968994 0.0\n",
      "[Step 398] Loss: 1.38e+08 -1.586559772491455 0.0\n",
      "[Step 399] Loss: 1.37e+08 -1.5894618034362793 0.0\n",
      "[Step 400] Loss: 1.37e+08 -1.5923172235488892 0.0\n",
      "[Step 401] Loss: 1.36e+08 -1.5951255559921265 0.0\n",
      "[Step 402] Loss: 1.36e+08 -1.5978773832321167 0.0\n",
      "[Step 403] Loss: 1.38e+08 -1.600643277168274 0.0\n",
      "[Step 404] Loss: 1.38e+08 -1.6034666299819946 0.0\n",
      "[Step 405] Loss: 1.37e+08 -1.6063042879104614 0.0\n",
      "[Step 406] Loss: 1.38e+08 -1.6091620922088623 0.0\n",
      "[Step 407] Loss: 1.35e+08 -1.6119725704193115 0.0\n",
      "[Step 408] Loss: 1.38e+08 -1.6148594617843628 0.0\n",
      "[Step 409] Loss: 1.35e+08 -1.6177263259887695 0.0\n",
      "[Step 410] Loss: 1.37e+08 -1.6206119060516357 0.0\n",
      "[Step 411] Loss: 1.37e+08 -1.6235874891281128 0.0\n",
      "[Step 412] Loss: 1.36e+08 -1.6265370845794678 0.0\n",
      "[Step 413] Loss: 1.36e+08 -1.6294854879379272 0.0\n",
      "[Step 414] Loss: 1.35e+08 -1.6323541402816772 0.0\n",
      "[Step 415] Loss: 1.37e+08 -1.6352304220199585 0.0\n",
      "[Step 416] Loss: 1.36e+08 -1.6380873918533325 0.0\n",
      "[Step 417] Loss: 1.35e+08 -1.6409469842910767 0.0\n",
      "[Step 418] Loss: 1.36e+08 -1.643816351890564 0.0\n",
      "[Step 419] Loss: 1.37e+08 -1.646719217300415 0.0\n",
      "[Step 420] Loss: 1.35e+08 -1.6496083736419678 0.0\n",
      "[Step 421] Loss: 1.36e+08 -1.6524866819381714 0.0\n",
      "[Step 422] Loss: 1.34e+08 -1.6553723812103271 0.0\n",
      "[Step 423] Loss: 1.35e+08 -1.658218502998352 0.0\n",
      "[Step 424] Loss: 1.34e+08 -1.6610753536224365 0.0\n",
      "[Step 425] Loss: 1.35e+08 -1.663854718208313 0.0\n",
      "[Step 426] Loss: 1.35e+08 -1.6666531562805176 0.0\n",
      "[Step 427] Loss: 1.35e+08 -1.669469952583313 0.0\n",
      "[Step 428] Loss: 1.35e+08 -1.672266960144043 0.0\n",
      "[Step 429] Loss: 1.35e+08 -1.6751036643981934 0.0\n",
      "[Step 430] Loss: 1.35e+08 -1.6779688596725464 0.0\n",
      "[Step 431] Loss: 1.35e+08 -1.6808326244354248 0.0\n",
      "[Step 432] Loss: 1.36e+08 -1.6837489604949951 0.0\n",
      "[Step 433] Loss: 1.34e+08 -1.686669111251831 0.0\n",
      "[Step 434] Loss: 1.34e+08 -1.6895623207092285 0.0\n",
      "[Step 435] Loss: 1.34e+08 -1.6924920082092285 0.0\n",
      "[Step 436] Loss: 1.34e+08 -1.6954491138458252 0.0\n",
      "[Step 437] Loss: 1.34e+08 -1.6983847618103027 0.0\n",
      "[Step 438] Loss: 1.35e+08 -1.701340913772583 0.0\n",
      "[Step 439] Loss: 1.34e+08 -1.7042903900146484 0.0\n",
      "[Step 440] Loss: 1.35e+08 -1.7072694301605225 0.0\n",
      "[Step 441] Loss: 1.34e+08 -1.7102258205413818 0.0\n",
      "[Step 442] Loss: 1.34e+08 -1.7131868600845337 0.0\n",
      "[Step 443] Loss: 1.34e+08 -1.716102957725525 0.0\n",
      "[Step 444] Loss: 1.33e+08 -1.7189589738845825 0.0\n",
      "[Step 445] Loss: 1.34e+08 -1.7218668460845947 0.0\n",
      "[Step 446] Loss: 1.34e+08 -1.7247964143753052 0.0\n",
      "[Step 447] Loss: 1.34e+08 -1.7277313470840454 0.0\n",
      "[Step 448] Loss: 1.32e+08 -1.7305907011032104 0.0\n",
      "[Step 449] Loss: 1.32e+08 -1.7334072589874268 0.0\n",
      "[Step 450] Loss: 1.31e+08 -1.736177682876587 0.0\n",
      "[Step 451] Loss: 1.32e+08 -1.7389546632766724 0.0\n",
      "[Step 452] Loss: 1.31e+08 -1.741732120513916 0.0\n",
      "[Step 453] Loss: 1.33e+08 -1.7445240020751953 0.0\n",
      "[Step 454] Loss: 1.33e+08 -1.7473348379135132 0.0\n",
      "[Step 455] Loss: 1.33e+08 -1.7501773834228516 0.0\n",
      "[Step 456] Loss: 1.32e+08 -1.7530115842819214 0.0\n",
      "[Step 457] Loss: 1.31e+08 -1.7558428049087524 0.0\n",
      "[Step 458] Loss: 1.33e+08 -1.7587226629257202 0.0\n",
      "[Step 459] Loss: 1.32e+08 -1.7616006135940552 0.0\n",
      "[Step 460] Loss: 1.32e+08 -1.7645041942596436 0.0\n",
      "[Step 461] Loss: 1.32e+08 -1.7674198150634766 0.0\n",
      "[Step 462] Loss: 1.33e+08 -1.7703602313995361 0.0\n",
      "[Step 463] Loss: 1.30e+08 -1.7732865810394287 0.0\n",
      "[Step 464] Loss: 1.31e+08 -1.776208758354187 0.0\n",
      "[Step 465] Loss: 1.31e+08 -1.779130458831787 0.0\n",
      "[Step 466] Loss: 1.32e+08 -1.7820162773132324 0.0\n",
      "[Step 467] Loss: 1.33e+08 -1.7849665880203247 0.0\n",
      "[Step 468] Loss: 1.32e+08 -1.787957787513733 0.0\n",
      "[Step 469] Loss: 1.32e+08 -1.7909414768218994 0.0\n",
      "[Step 470] Loss: 1.31e+08 -1.793932557106018 0.0\n",
      "[Step 471] Loss: 1.32e+08 -1.796939492225647 0.0\n",
      "[Step 472] Loss: 1.32e+08 -1.7999225854873657 0.0\n",
      "[Step 473] Loss: 1.32e+08 -1.8028873205184937 0.0\n",
      "[Step 474] Loss: 1.30e+08 -1.8058576583862305 0.0\n",
      "[Step 475] Loss: 1.31e+08 -1.808830976486206 0.0\n",
      "[Step 476] Loss: 1.31e+08 -1.811766266822815 0.0\n",
      "[Step 477] Loss: 1.30e+08 -1.8146861791610718 0.0\n",
      "[Step 478] Loss: 1.30e+08 -1.8176213502883911 0.0\n",
      "[Step 479] Loss: 1.30e+08 -1.8205368518829346 0.0\n",
      "[Step 480] Loss: 1.30e+08 -1.8234508037567139 0.0\n",
      "[Step 481] Loss: 1.29e+08 -1.8263133764266968 0.0\n",
      "[Step 482] Loss: 1.29e+08 -1.8291324377059937 0.0\n",
      "[Step 483] Loss: 1.31e+08 -1.8320074081420898 0.0\n",
      "[Step 484] Loss: 1.30e+08 -1.8348288536071777 0.0\n",
      "[Step 485] Loss: 1.29e+08 -1.8376575708389282 0.0\n",
      "[Step 486] Loss: 1.29e+08 -1.8404531478881836 0.0\n",
      "[Step 487] Loss: 1.29e+08 -1.8432214260101318 0.0\n",
      "[Step 488] Loss: 1.30e+08 -1.845979928970337 0.0\n",
      "[Step 489] Loss: 1.28e+08 -1.848745346069336 0.0\n",
      "[Step 490] Loss: 1.30e+08 -1.8515281677246094 0.0\n",
      "[Step 491] Loss: 1.29e+08 -1.8543224334716797 0.0\n",
      "[Step 492] Loss: 1.29e+08 -1.8570990562438965 0.0\n",
      "[Step 493] Loss: 1.28e+08 -1.859859585762024 0.0\n",
      "[Step 494] Loss: 1.29e+08 -1.8626092672348022 0.0\n",
      "[Step 495] Loss: 1.29e+08 -1.8654096126556396 0.0\n",
      "[Step 496] Loss: 1.28e+08 -1.8682091236114502 0.0\n",
      "[Step 497] Loss: 1.29e+08 -1.8710174560546875 0.0\n",
      "[Step 498] Loss: 1.29e+08 -1.8738328218460083 0.0\n",
      "[Step 499] Loss: 1.28e+08 -1.8766473531723022 0.0\n",
      "[Step 500] Loss: 1.28e+08 -1.87947678565979 0.0\n",
      "[Step 501] Loss: 1.29e+08 -1.8823074102401733 0.0\n",
      "[Step 502] Loss: 1.29e+08 -1.885144829750061 0.0\n",
      "[Step 503] Loss: 1.29e+08 -1.8879839181900024 0.0\n",
      "[Step 504] Loss: 1.28e+08 -1.8908264636993408 0.0\n",
      "[Step 505] Loss: 1.28e+08 -1.8936694860458374 0.0\n",
      "[Step 506] Loss: 1.27e+08 -1.89653480052948 0.0\n",
      "[Step 507] Loss: 1.29e+08 -1.8994004726409912 0.0\n",
      "[Step 508] Loss: 1.27e+08 -1.9022608995437622 0.0\n",
      "[Step 509] Loss: 1.28e+08 -1.9050434827804565 0.0\n",
      "[Step 510] Loss: 1.28e+08 -1.9078521728515625 0.0\n",
      "[Step 511] Loss: 1.28e+08 -1.9106167554855347 0.0\n",
      "[Step 512] Loss: 1.29e+08 -1.9133503437042236 0.0\n",
      "[Step 513] Loss: 1.28e+08 -1.9160637855529785 0.0\n",
      "[Step 514] Loss: 1.28e+08 -1.918818712234497 0.0\n",
      "[Step 515] Loss: 1.27e+08 -1.921519160270691 0.0\n",
      "[Step 516] Loss: 1.27e+08 -1.924228310585022 0.0\n",
      "[Step 517] Loss: 1.26e+08 -1.9269036054611206 0.0\n",
      "[Step 518] Loss: 1.26e+08 -1.929569125175476 0.0\n",
      "[Step 519] Loss: 1.26e+08 -1.9322158098220825 0.0\n",
      "[Step 520] Loss: 1.27e+08 -1.934866189956665 0.0\n",
      "[Step 521] Loss: 1.27e+08 -1.9374803304672241 0.0\n",
      "[Step 522] Loss: 1.27e+08 -1.9400242567062378 0.0\n",
      "[Step 523] Loss: 1.27e+08 -1.9425687789916992 0.0\n",
      "[Step 524] Loss: 1.27e+08 -1.9451279640197754 0.0\n",
      "[Step 525] Loss: 1.27e+08 -1.947653889656067 0.0\n",
      "[Step 526] Loss: 1.26e+08 -1.9501724243164062 0.0\n",
      "[Step 527] Loss: 1.25e+08 -1.952705979347229 0.0\n",
      "[Step 528] Loss: 1.26e+08 -1.955243706703186 0.0\n",
      "[Step 529] Loss: 1.26e+08 -1.9577831029891968 0.0\n",
      "[Step 530] Loss: 1.27e+08 -1.9603418111801147 0.0\n",
      "[Step 531] Loss: 1.25e+08 -1.962874174118042 0.0\n",
      "[Step 532] Loss: 1.26e+08 -1.9653817415237427 0.0\n",
      "[Step 533] Loss: 1.27e+08 -1.9679021835327148 0.0\n",
      "[Step 534] Loss: 1.25e+08 -1.9703909158706665 0.0\n",
      "[Step 535] Loss: 1.25e+08 -1.9729169607162476 0.0\n",
      "[Step 536] Loss: 1.25e+08 -1.9754406213760376 0.0\n",
      "[Step 537] Loss: 1.26e+08 -1.9779493808746338 0.0\n",
      "[Step 538] Loss: 1.25e+08 -1.9804372787475586 0.0\n",
      "[Step 539] Loss: 1.25e+08 -1.98294997215271 0.0\n",
      "[Step 540] Loss: 1.24e+08 -1.9854408502578735 0.0\n",
      "[Step 541] Loss: 1.26e+08 -1.9879224300384521 0.0\n",
      "[Step 542] Loss: 1.26e+08 -1.9903976917266846 0.0\n",
      "[Step 543] Loss: 1.27e+08 -1.9929131269454956 0.0\n",
      "[Step 544] Loss: 1.26e+08 -1.995400309562683 0.0\n",
      "[Step 545] Loss: 1.24e+08 -1.9978889226913452 0.0\n",
      "[Step 546] Loss: 1.26e+08 -2.0004050731658936 0.0\n",
      "[Step 547] Loss: 1.25e+08 -2.0029139518737793 0.0\n",
      "[Step 548] Loss: 1.24e+08 -2.0054075717926025 0.0\n",
      "[Step 549] Loss: 1.26e+08 -2.007939338684082 0.0\n",
      "[Step 550] Loss: 1.25e+08 -2.010493278503418 0.0\n",
      "[Step 551] Loss: 1.26e+08 -2.0130176544189453 0.0\n",
      "[Step 552] Loss: 1.24e+08 -2.0154898166656494 0.0\n",
      "[Step 553] Loss: 1.25e+08 -2.0179989337921143 0.0\n",
      "[Step 554] Loss: 1.24e+08 -2.020484447479248 0.0\n",
      "[Step 555] Loss: 1.24e+08 -2.022967576980591 0.0\n",
      "[Step 556] Loss: 1.24e+08 -2.0254387855529785 0.0\n",
      "[Step 557] Loss: 1.26e+08 -2.027937412261963 0.0\n",
      "[Step 558] Loss: 1.24e+08 -2.0303869247436523 0.0\n",
      "[Step 559] Loss: 1.24e+08 -2.0328094959259033 0.0\n",
      "[Step 560] Loss: 1.25e+08 -2.0352132320404053 0.0\n",
      "[Step 561] Loss: 1.25e+08 -2.0376334190368652 0.0\n",
      "[Step 562] Loss: 1.24e+08 -2.0400664806365967 0.0\n",
      "[Step 563] Loss: 1.24e+08 -2.0425381660461426 0.0\n",
      "[Step 564] Loss: 1.23e+08 -2.0449934005737305 0.0\n",
      "[Step 565] Loss: 1.25e+08 -2.0474655628204346 0.0\n",
      "[Step 566] Loss: 1.24e+08 -2.0498926639556885 0.0\n",
      "[Step 567] Loss: 1.23e+08 -2.0522875785827637 0.0\n",
      "[Step 568] Loss: 1.25e+08 -2.0547096729278564 0.0\n",
      "[Step 569] Loss: 1.24e+08 -2.0571329593658447 0.0\n",
      "[Step 570] Loss: 1.23e+08 -2.0595130920410156 0.0\n",
      "[Step 571] Loss: 1.24e+08 -2.061887264251709 0.0\n",
      "[Step 572] Loss: 1.23e+08 -2.064208507537842 0.0\n",
      "[Step 573] Loss: 1.24e+08 -2.066521167755127 0.0\n",
      "[Step 574] Loss: 1.23e+08 -2.0688440799713135 0.0\n",
      "[Step 575] Loss: 1.23e+08 -2.071134328842163 0.0\n",
      "[Step 576] Loss: 1.24e+08 -2.0734734535217285 0.0\n",
      "[Step 577] Loss: 1.23e+08 -2.0758285522460938 0.0\n",
      "[Step 578] Loss: 1.22e+08 -2.0781524181365967 0.0\n",
      "[Step 579] Loss: 1.23e+08 -2.08044695854187 0.0\n",
      "[Step 580] Loss: 1.21e+08 -2.0826468467712402 0.0\n",
      "[Step 581] Loss: 1.23e+08 -2.084843397140503 0.0\n",
      "[Step 582] Loss: 1.22e+08 -2.0869994163513184 0.0\n",
      "[Step 583] Loss: 1.24e+08 -2.0892066955566406 0.0\n",
      "[Step 584] Loss: 1.23e+08 -2.091426134109497 0.0\n",
      "[Step 585] Loss: 1.24e+08 -2.093641519546509 0.0\n",
      "[Step 586] Loss: 1.23e+08 -2.0958683490753174 0.0\n",
      "[Step 587] Loss: 1.20e+08 -2.098055839538574 0.0\n",
      "[Step 588] Loss: 1.22e+08 -2.1002328395843506 0.0\n",
      "[Step 589] Loss: 1.22e+08 -2.102415084838867 0.0\n",
      "[Step 590] Loss: 1.23e+08 -2.104569673538208 0.0\n",
      "[Step 591] Loss: 1.22e+08 -2.106698751449585 0.0\n",
      "[Step 592] Loss: 1.22e+08 -2.108820676803589 0.0\n",
      "[Step 593] Loss: 1.22e+08 -2.1109275817871094 0.0\n",
      "[Step 594] Loss: 1.22e+08 -2.113023042678833 0.0\n",
      "[Step 595] Loss: 1.22e+08 -2.1150498390197754 0.0\n",
      "[Step 596] Loss: 1.22e+08 -2.117039442062378 0.0\n",
      "[Step 597] Loss: 1.22e+08 -2.118980884552002 0.0\n",
      "[Step 598] Loss: 1.21e+08 -2.120889902114868 0.0\n",
      "[Step 599] Loss: 1.22e+08 -2.122803211212158 0.0\n",
      "[Step 600] Loss: 1.22e+08 -2.1247215270996094 0.0\n",
      "[Step 601] Loss: 1.22e+08 -2.126638174057007 0.0\n",
      "[Step 602] Loss: 1.22e+08 -2.12858247756958 0.0\n",
      "[Step 603] Loss: 1.22e+08 -2.130497455596924 0.0\n",
      "[Step 604] Loss: 1.22e+08 -2.132396936416626 0.0\n",
      "[Step 605] Loss: 1.22e+08 -2.1343398094177246 0.0\n",
      "[Step 606] Loss: 1.22e+08 -2.136298656463623 0.0\n",
      "[Step 607] Loss: 1.22e+08 -2.1382315158843994 0.0\n",
      "[Step 608] Loss: 1.20e+08 -2.1401593685150146 0.0\n",
      "[Step 609] Loss: 1.22e+08 -2.142073392868042 0.0\n",
      "[Step 610] Loss: 1.22e+08 -2.143983840942383 0.0\n",
      "[Step 611] Loss: 1.22e+08 -2.145878553390503 0.0\n",
      "[Step 612] Loss: 1.22e+08 -2.147796392440796 0.0\n",
      "[Step 613] Loss: 1.22e+08 -2.1497156620025635 0.0\n",
      "[Step 614] Loss: 1.22e+08 -2.151637077331543 0.0\n",
      "[Step 615] Loss: 1.20e+08 -2.153529644012451 0.0\n",
      "[Step 616] Loss: 1.21e+08 -2.155397891998291 0.0\n",
      "[Step 617] Loss: 1.20e+08 -2.1572763919830322 0.0\n",
      "[Step 618] Loss: 1.21e+08 -2.15917706489563 0.0\n",
      "[Step 619] Loss: 1.21e+08 -2.1610524654388428 0.0\n",
      "[Step 620] Loss: 1.22e+08 -2.162930727005005 0.0\n",
      "[Step 621] Loss: 1.21e+08 -2.1647908687591553 0.0\n",
      "[Step 622] Loss: 1.21e+08 -2.1666367053985596 0.0\n",
      "[Step 623] Loss: 1.21e+08 -2.168475866317749 0.0\n",
      "[Step 624] Loss: 1.21e+08 -2.1703221797943115 0.0\n",
      "[Step 625] Loss: 1.21e+08 -2.172165632247925 0.0\n",
      "[Step 626] Loss: 1.21e+08 -2.1739799976348877 0.0\n",
      "[Step 627] Loss: 1.20e+08 -2.175771474838257 0.0\n",
      "[Step 628] Loss: 1.19e+08 -2.177532911300659 0.0\n",
      "[Step 629] Loss: 1.21e+08 -2.179255247116089 0.0\n",
      "[Step 630] Loss: 1.20e+08 -2.180978536605835 0.0\n",
      "[Step 631] Loss: 1.19e+08 -2.1826794147491455 0.0\n",
      "[Step 632] Loss: 1.19e+08 -2.1843340396881104 0.0\n",
      "[Step 633] Loss: 1.20e+08 -2.185955286026001 0.0\n",
      "[Step 634] Loss: 1.21e+08 -2.187624216079712 0.0\n",
      "[Step 635] Loss: 1.20e+08 -2.189293146133423 0.0\n",
      "[Step 636] Loss: 1.19e+08 -2.1909639835357666 0.0\n",
      "[Step 637] Loss: 1.20e+08 -2.192622661590576 0.0\n",
      "[Step 638] Loss: 1.20e+08 -2.1942660808563232 0.0\n",
      "[Step 639] Loss: 1.19e+08 -2.1958978176116943 0.0\n",
      "[Step 640] Loss: 1.20e+08 -2.1974971294403076 0.0\n",
      "[Step 641] Loss: 1.20e+08 -2.1990976333618164 0.0\n",
      "[Step 642] Loss: 1.19e+08 -2.200659990310669 0.0\n",
      "[Step 643] Loss: 1.20e+08 -2.202252149581909 0.0\n",
      "[Step 644] Loss: 1.20e+08 -2.203827381134033 0.0\n",
      "[Step 645] Loss: 1.20e+08 -2.205368995666504 0.0\n",
      "[Step 646] Loss: 1.19e+08 -2.2069005966186523 0.0\n",
      "[Step 647] Loss: 1.19e+08 -2.208388328552246 0.0\n",
      "[Step 648] Loss: 1.19e+08 -2.209865093231201 0.0\n",
      "[Step 649] Loss: 1.20e+08 -2.211348056793213 0.0\n",
      "[Step 650] Loss: 1.20e+08 -2.2128617763519287 0.0\n",
      "[Step 651] Loss: 1.19e+08 -2.214393138885498 0.0\n",
      "[Step 652] Loss: 1.20e+08 -2.2159359455108643 0.0\n",
      "[Step 653] Loss: 1.19e+08 -2.2175073623657227 0.0\n",
      "[Step 654] Loss: 1.19e+08 -2.2190401554107666 0.0\n",
      "[Step 655] Loss: 1.19e+08 -2.220601797103882 0.0\n",
      "[Step 656] Loss: 1.18e+08 -2.22210955619812 0.0\n",
      "[Step 657] Loss: 1.19e+08 -2.2235991954803467 0.0\n",
      "[Step 658] Loss: 1.20e+08 -2.225079298019409 0.0\n",
      "[Step 659] Loss: 1.19e+08 -2.2265241146087646 0.0\n",
      "[Step 660] Loss: 1.19e+08 -2.227922201156616 0.0\n",
      "[Step 661] Loss: 1.20e+08 -2.229315757751465 0.0\n",
      "[Step 662] Loss: 1.19e+08 -2.230663776397705 0.0\n",
      "[Step 663] Loss: 1.19e+08 -2.2320094108581543 0.0\n",
      "[Step 664] Loss: 1.18e+08 -2.233384132385254 0.0\n",
      "[Step 665] Loss: 1.19e+08 -2.234743118286133 0.0\n",
      "[Step 666] Loss: 1.19e+08 -2.236048460006714 0.0\n",
      "[Step 667] Loss: 1.19e+08 -2.2373270988464355 0.0\n",
      "[Step 668] Loss: 1.20e+08 -2.2385876178741455 0.0\n",
      "[Step 669] Loss: 1.18e+08 -2.2398693561553955 0.0\n",
      "[Step 670] Loss: 1.19e+08 -2.2411327362060547 0.0\n",
      "[Step 671] Loss: 1.17e+08 -2.242379903793335 0.0\n",
      "[Step 672] Loss: 1.18e+08 -2.2436397075653076 0.0\n",
      "[Step 673] Loss: 1.17e+08 -2.244868040084839 0.0\n",
      "[Step 674] Loss: 1.20e+08 -2.2460732460021973 0.0\n",
      "[Step 675] Loss: 1.18e+08 -2.2472784519195557 0.0\n",
      "[Step 676] Loss: 1.18e+08 -2.2484397888183594 0.0\n",
      "[Step 677] Loss: 1.19e+08 -2.249605655670166 0.0\n",
      "[Step 678] Loss: 1.17e+08 -2.2507784366607666 0.0\n",
      "[Step 679] Loss: 1.18e+08 -2.251913547515869 0.0\n",
      "[Step 680] Loss: 1.18e+08 -2.252950668334961 0.0\n",
      "[Step 681] Loss: 1.18e+08 -2.2540063858032227 0.0\n",
      "[Step 682] Loss: 1.20e+08 -2.2551469802856445 0.0\n",
      "[Step 683] Loss: 1.17e+08 -2.256279230117798 0.0\n",
      "[Step 684] Loss: 1.17e+08 -2.2573721408843994 0.0\n",
      "[Step 685] Loss: 1.17e+08 -2.2583978176116943 0.0\n",
      "[Step 686] Loss: 1.18e+08 -2.2594382762908936 0.0\n",
      "[Step 687] Loss: 1.18e+08 -2.2604780197143555 0.0\n",
      "[Step 688] Loss: 1.17e+08 -2.2615270614624023 0.0\n",
      "[Step 689] Loss: 1.18e+08 -2.2625505924224854 0.0\n",
      "[Step 690] Loss: 1.18e+08 -2.2635786533355713 0.0\n",
      "[Step 691] Loss: 1.17e+08 -2.2646031379699707 0.0\n",
      "[Step 692] Loss: 1.17e+08 -2.2656233310699463 0.0\n",
      "[Step 693] Loss: 1.18e+08 -2.2666501998901367 0.0\n",
      "[Step 694] Loss: 1.17e+08 -2.2676563262939453 0.0\n",
      "[Step 695] Loss: 1.18e+08 -2.268655776977539 0.0\n",
      "[Step 696] Loss: 1.17e+08 -2.269585609436035 0.0\n",
      "[Step 697] Loss: 1.16e+08 -2.270491123199463 0.0\n",
      "[Step 698] Loss: 1.17e+08 -2.271371603012085 0.0\n",
      "[Step 699] Loss: 1.17e+08 -2.272235870361328 0.0\n",
      "[Step 700] Loss: 1.18e+08 -2.2730674743652344 0.0\n",
      "[Step 701] Loss: 1.18e+08 -2.2738664150238037 0.0\n",
      "[Step 702] Loss: 1.16e+08 -2.2746148109436035 0.0\n",
      "[Step 703] Loss: 1.17e+08 -2.27533221244812 0.0\n",
      "[Step 704] Loss: 1.17e+08 -2.2760698795318604 0.0\n",
      "[Step 705] Loss: 1.18e+08 -2.276759624481201 0.0\n",
      "[Step 706] Loss: 1.18e+08 -2.2774658203125 0.0\n",
      "[Step 707] Loss: 1.17e+08 -2.278085470199585 0.0\n",
      "[Step 708] Loss: 1.17e+08 -2.2786808013916016 0.0\n",
      "[Step 709] Loss: 1.17e+08 -2.279230833053589 0.0\n",
      "[Step 710] Loss: 1.18e+08 -2.279890537261963 0.0\n",
      "[Step 711] Loss: 1.17e+08 -2.2805371284484863 0.0\n",
      "[Step 712] Loss: 1.17e+08 -2.281165361404419 0.0\n",
      "[Step 713] Loss: 1.17e+08 -2.281801223754883 0.0\n",
      "[Step 714] Loss: 1.17e+08 -2.2824203968048096 0.0\n",
      "[Step 715] Loss: 1.17e+08 -2.2830183506011963 0.0\n",
      "[Step 716] Loss: 1.17e+08 -2.2836122512817383 0.0\n",
      "[Step 717] Loss: 1.17e+08 -2.2841849327087402 0.0\n",
      "[Step 718] Loss: 1.17e+08 -2.2847328186035156 0.0\n",
      "[Step 719] Loss: 1.17e+08 -2.285299062728882 0.0\n",
      "[Step 720] Loss: 1.16e+08 -2.285888433456421 0.0\n",
      "[Step 721] Loss: 1.16e+08 -2.2864742279052734 0.0\n",
      "[Step 722] Loss: 1.18e+08 -2.28702449798584 0.0\n",
      "[Step 723] Loss: 1.17e+08 -2.2876245975494385 0.0\n",
      "[Step 724] Loss: 1.16e+08 -2.2882401943206787 0.0\n",
      "[Step 725] Loss: 1.17e+08 -2.288884162902832 0.0\n",
      "[Step 726] Loss: 1.15e+08 -2.289517879486084 0.0\n",
      "[Step 727] Loss: 1.17e+08 -2.2901663780212402 0.0\n",
      "[Step 728] Loss: 1.16e+08 -2.290837287902832 0.0\n",
      "[Step 729] Loss: 1.17e+08 -2.291492462158203 0.0\n",
      "[Step 730] Loss: 1.16e+08 -2.292123794555664 0.0\n",
      "[Step 731] Loss: 1.16e+08 -2.2927627563476562 0.0\n",
      "[Step 732] Loss: 1.16e+08 -2.293362617492676 0.0\n",
      "[Step 733] Loss: 1.15e+08 -2.293956756591797 0.0\n",
      "[Step 734] Loss: 1.16e+08 -2.2945363521575928 0.0\n",
      "[Step 735] Loss: 1.17e+08 -2.295201063156128 0.0\n",
      "[Step 736] Loss: 1.15e+08 -2.295856237411499 0.0\n",
      "[Step 737] Loss: 1.16e+08 -2.2964930534362793 0.0\n",
      "[Step 738] Loss: 1.17e+08 -2.2970786094665527 0.0\n",
      "[Step 739] Loss: 1.15e+08 -2.2976572513580322 0.0\n",
      "[Step 740] Loss: 1.15e+08 -2.298225164413452 0.0\n",
      "[Step 741] Loss: 1.17e+08 -2.2987945079803467 0.0\n",
      "[Step 742] Loss: 1.15e+08 -2.2993688583374023 0.0\n",
      "[Step 743] Loss: 1.16e+08 -2.299851894378662 0.0\n",
      "[Step 744] Loss: 1.16e+08 -2.3003008365631104 0.0\n",
      "[Step 745] Loss: 1.14e+08 -2.300647258758545 0.0\n",
      "[Step 746] Loss: 1.16e+08 -2.3009347915649414 0.0\n",
      "[Step 747] Loss: 1.15e+08 -2.3012053966522217 0.0\n",
      "[Step 748] Loss: 1.16e+08 -2.3014838695526123 0.0\n",
      "[Step 749] Loss: 1.16e+08 -2.3017594814300537 0.0\n",
      "[Step 750] Loss: 1.17e+08 -2.3019707202911377 0.0\n",
      "[Step 751] Loss: 1.15e+08 -2.302135944366455 0.0\n",
      "[Step 752] Loss: 1.16e+08 -2.3022959232330322 0.0\n",
      "[Step 753] Loss: 1.15e+08 -2.30242657661438 0.0\n",
      "[Step 754] Loss: 1.15e+08 -2.302578926086426 0.0\n",
      "[Step 755] Loss: 1.15e+08 -2.3026909828186035 0.0\n",
      "[Step 756] Loss: 1.16e+08 -2.3027756214141846 0.0\n",
      "[Step 757] Loss: 1.15e+08 -2.3028581142425537 0.0\n",
      "[Step 758] Loss: 1.16e+08 -2.3029510974884033 0.0\n",
      "[Step 759] Loss: 1.15e+08 -2.303023338317871 0.0\n",
      "[Step 760] Loss: 1.16e+08 -2.3030850887298584 0.0\n",
      "[Step 761] Loss: 1.16e+08 -2.3031866550445557 0.0\n",
      "[Step 762] Loss: 1.15e+08 -2.303297519683838 0.0\n",
      "[Step 763] Loss: 1.15e+08 -2.3033573627471924 0.0\n",
      "[Step 764] Loss: 1.16e+08 -2.3034093379974365 0.0\n",
      "[Step 765] Loss: 1.15e+08 -2.3034110069274902 0.0\n",
      "[Step 766] Loss: 1.15e+08 -2.3033864498138428 0.0\n",
      "[Step 767] Loss: 1.16e+08 -2.3034143447875977 0.0\n",
      "[Step 768] Loss: 1.15e+08 -2.3034732341766357 0.0\n",
      "[Step 769] Loss: 1.16e+08 -2.303546905517578 0.0\n",
      "[Step 770] Loss: 1.15e+08 -2.3035731315612793 0.0\n",
      "[Step 771] Loss: 1.14e+08 -2.303551435470581 0.0\n",
      "[Step 772] Loss: 1.16e+08 -2.303555965423584 0.0\n",
      "[Step 773] Loss: 1.14e+08 -2.3035340309143066 0.0\n",
      "[Step 774] Loss: 1.15e+08 -2.303521156311035 0.0\n",
      "[Step 775] Loss: 1.16e+08 -2.303515672683716 0.0\n",
      "[Step 776] Loss: 1.15e+08 -2.3034746646881104 0.0\n",
      "[Step 777] Loss: 1.16e+08 -2.3034255504608154 0.0\n",
      "[Step 778] Loss: 1.15e+08 -2.303373098373413 0.0\n",
      "[Step 779] Loss: 1.15e+08 -2.3033392429351807 0.0\n",
      "[Step 780] Loss: 1.16e+08 -2.303325653076172 0.0\n",
      "[Step 781] Loss: 1.16e+08 -2.3033480644226074 0.0\n",
      "[Step 782] Loss: 1.14e+08 -2.3033511638641357 0.0\n",
      "[Step 783] Loss: 1.14e+08 -2.30330228805542 0.0\n",
      "[Step 784] Loss: 1.15e+08 -2.303210496902466 0.0\n",
      "[Step 785] Loss: 1.15e+08 -2.303126811981201 0.0\n",
      "[Step 786] Loss: 1.15e+08 -2.3029868602752686 0.0\n",
      "[Step 787] Loss: 1.14e+08 -2.3028392791748047 0.0\n",
      "[Step 788] Loss: 1.14e+08 -2.302687168121338 0.0\n",
      "[Step 789] Loss: 1.15e+08 -2.302537441253662 0.0\n",
      "[Step 790] Loss: 1.15e+08 -2.302398204803467 0.0\n",
      "[Step 791] Loss: 1.15e+08 -2.30222225189209 0.0\n",
      "[Step 792] Loss: 1.14e+08 -2.302016496658325 0.0\n",
      "[Step 793] Loss: 1.13e+08 -2.301767587661743 0.0\n",
      "[Step 794] Loss: 1.15e+08 -2.301513671875 0.0\n",
      "[Step 795] Loss: 1.14e+08 -2.3012425899505615 0.0\n",
      "[Step 796] Loss: 1.14e+08 -2.300919771194458 0.0\n",
      "[Step 797] Loss: 1.15e+08 -2.300551414489746 0.0\n",
      "[Step 798] Loss: 1.15e+08 -2.3002076148986816 0.0\n",
      "[Step 799] Loss: 1.14e+08 -2.2998762130737305 0.0\n",
      "[Step 800] Loss: 1.13e+08 -2.299490213394165 0.0\n",
      "[Step 801] Loss: 1.15e+08 -2.2990548610687256 0.0\n",
      "[Step 802] Loss: 1.14e+08 -2.298633575439453 0.0\n",
      "[Step 803] Loss: 1.14e+08 -2.2982213497161865 0.0\n",
      "[Step 804] Loss: 1.14e+08 -2.297797918319702 0.0\n",
      "[Step 805] Loss: 1.14e+08 -2.2973406314849854 0.0\n",
      "[Step 806] Loss: 1.15e+08 -2.296889305114746 0.0\n",
      "[Step 807] Loss: 1.13e+08 -2.2963926792144775 0.0\n",
      "[Step 808] Loss: 1.15e+08 -2.2958874702453613 0.0\n",
      "[Step 809] Loss: 1.13e+08 -2.2953569889068604 0.0\n",
      "[Step 810] Loss: 1.14e+08 -2.2948334217071533 0.0\n",
      "[Step 811] Loss: 1.14e+08 -2.294254779815674 0.0\n",
      "[Step 812] Loss: 1.14e+08 -2.2936630249023438 0.0\n",
      "[Step 813] Loss: 1.14e+08 -2.2930493354797363 0.0\n",
      "[Step 814] Loss: 1.14e+08 -2.2924859523773193 0.0\n",
      "[Step 815] Loss: 1.14e+08 -2.2919044494628906 0.0\n",
      "[Step 816] Loss: 1.14e+08 -2.2912776470184326 0.0\n",
      "[Step 817] Loss: 1.13e+08 -2.2906479835510254 0.0\n",
      "[Step 818] Loss: 1.14e+08 -2.290031909942627 0.0\n",
      "[Step 819] Loss: 1.13e+08 -2.289463758468628 0.0\n",
      "[Step 820] Loss: 1.13e+08 -2.2888309955596924 0.0\n",
      "[Step 821] Loss: 1.13e+08 -2.2881791591644287 0.0\n",
      "[Step 822] Loss: 1.15e+08 -2.287519693374634 0.0\n",
      "[Step 823] Loss: 1.14e+08 -2.2868599891662598 0.0\n",
      "[Step 824] Loss: 1.14e+08 -2.286173105239868 0.0\n",
      "[Step 825] Loss: 1.13e+08 -2.2854907512664795 0.0\n",
      "[Step 826] Loss: 1.14e+08 -2.2848029136657715 0.0\n",
      "[Step 827] Loss: 1.15e+08 -2.284093141555786 0.0\n",
      "[Step 828] Loss: 1.12e+08 -2.2833337783813477 0.0\n",
      "[Step 829] Loss: 1.14e+08 -2.2825512886047363 0.0\n",
      "[Step 830] Loss: 1.14e+08 -2.281766176223755 0.0\n",
      "[Step 831] Loss: 1.14e+08 -2.280984401702881 0.0\n",
      "[Step 832] Loss: 1.13e+08 -2.280184745788574 0.0\n",
      "[Step 833] Loss: 1.13e+08 -2.2793567180633545 0.0\n",
      "[Step 834] Loss: 1.13e+08 -2.278522491455078 0.0\n",
      "[Step 835] Loss: 1.13e+08 -2.2776906490325928 0.0\n",
      "[Step 836] Loss: 1.13e+08 -2.276878833770752 0.0\n",
      "[Step 837] Loss: 1.15e+08 -2.2759811878204346 0.0\n",
      "[Step 838] Loss: 1.13e+08 -2.2751195430755615 0.0\n",
      "[Step 839] Loss: 1.12e+08 -2.2741963863372803 0.0\n",
      "[Step 840] Loss: 1.13e+08 -2.2733092308044434 0.0\n",
      "[Step 841] Loss: 1.13e+08 -2.2724146842956543 0.0\n",
      "[Step 842] Loss: 1.13e+08 -2.2715067863464355 0.0\n",
      "[Step 843] Loss: 1.14e+08 -2.270604372024536 0.0\n",
      "[Step 844] Loss: 1.13e+08 -2.269686460494995 0.0\n",
      "[Step 845] Loss: 1.14e+08 -2.268763780593872 0.0\n",
      "[Step 846] Loss: 1.12e+08 -2.267836093902588 0.0\n",
      "[Step 847] Loss: 1.13e+08 -2.266963005065918 0.0\n",
      "[Step 848] Loss: 1.13e+08 -2.26608943939209 0.0\n",
      "[Step 849] Loss: 1.14e+08 -2.2651774883270264 0.0\n",
      "[Step 850] Loss: 1.12e+08 -2.2642526626586914 0.0\n",
      "[Step 851] Loss: 1.14e+08 -2.2633450031280518 0.0\n",
      "[Step 852] Loss: 1.13e+08 -2.262420177459717 0.0\n",
      "[Step 853] Loss: 1.12e+08 -2.261432409286499 0.0\n",
      "[Step 854] Loss: 1.13e+08 -2.2604284286499023 0.0\n",
      "[Step 855] Loss: 1.13e+08 -2.259498119354248 0.0\n",
      "[Step 856] Loss: 1.14e+08 -2.25854754447937 0.0\n",
      "[Step 857] Loss: 1.13e+08 -2.257615089416504 0.0\n",
      "[Step 858] Loss: 1.13e+08 -2.256667375564575 0.0\n",
      "[Step 859] Loss: 1.12e+08 -2.255635976791382 0.0\n",
      "[Step 860] Loss: 1.13e+08 -2.254559278488159 0.0\n",
      "[Step 861] Loss: 1.13e+08 -2.253537893295288 0.0\n",
      "[Step 862] Loss: 1.13e+08 -2.2524287700653076 0.0\n",
      "[Step 863] Loss: 1.14e+08 -2.251323938369751 0.0\n",
      "[Step 864] Loss: 1.13e+08 -2.2502083778381348 0.0\n",
      "[Step 865] Loss: 1.12e+08 -2.249114751815796 0.0\n",
      "[Step 866] Loss: 1.12e+08 -2.247962713241577 0.0\n",
      "[Step 867] Loss: 1.14e+08 -2.246778964996338 0.0\n",
      "[Step 868] Loss: 1.13e+08 -2.2455897331237793 0.0\n",
      "[Step 869] Loss: 1.12e+08 -2.2443881034851074 0.0\n",
      "[Step 870] Loss: 1.13e+08 -2.2433154582977295 0.0\n",
      "[Step 871] Loss: 1.12e+08 -2.242182731628418 0.0\n",
      "[Step 872] Loss: 1.13e+08 -2.2410202026367188 0.0\n",
      "[Step 873] Loss: 1.14e+08 -2.2398014068603516 0.0\n",
      "[Step 874] Loss: 1.13e+08 -2.2385594844818115 0.0\n",
      "[Step 875] Loss: 1.12e+08 -2.2372851371765137 0.0\n",
      "[Step 876] Loss: 1.12e+08 -2.2359628677368164 0.0\n",
      "[Step 877] Loss: 1.12e+08 -2.2345757484436035 0.0\n",
      "[Step 878] Loss: 1.13e+08 -2.233222007751465 0.0\n",
      "[Step 879] Loss: 1.12e+08 -2.2318155765533447 0.0\n",
      "[Step 880] Loss: 1.12e+08 -2.2304203510284424 0.0\n",
      "[Step 881] Loss: 1.12e+08 -2.229048252105713 0.0\n",
      "[Step 882] Loss: 1.12e+08 -2.2276766300201416 0.0\n",
      "[Step 883] Loss: 1.14e+08 -2.2263083457946777 0.0\n",
      "[Step 884] Loss: 1.12e+08 -2.224947690963745 0.0\n",
      "[Step 885] Loss: 1.12e+08 -2.2236380577087402 0.0\n",
      "[Step 886] Loss: 1.13e+08 -2.2223355770111084 0.0\n",
      "[Step 887] Loss: 1.12e+08 -2.221013307571411 0.0\n",
      "[Step 888] Loss: 1.13e+08 -2.219597816467285 0.0\n",
      "[Step 889] Loss: 1.12e+08 -2.218158721923828 0.0\n",
      "[Step 890] Loss: 1.13e+08 -2.2167303562164307 0.0\n",
      "[Step 891] Loss: 1.12e+08 -2.2153635025024414 0.0\n",
      "[Step 892] Loss: 1.13e+08 -2.2140371799468994 0.0\n",
      "[Step 893] Loss: 1.12e+08 -2.21268367767334 0.0\n",
      "[Step 894] Loss: 1.12e+08 -2.2113277912139893 0.0\n",
      "[Step 895] Loss: 1.13e+08 -2.209942102432251 0.0\n",
      "[Step 896] Loss: 1.13e+08 -2.2086472511291504 0.0\n",
      "[Step 897] Loss: 1.13e+08 -2.207322359085083 0.0\n",
      "[Step 898] Loss: 1.13e+08 -2.20599627494812 0.0\n",
      "[Step 899] Loss: 1.12e+08 -2.204641342163086 0.0\n",
      "[Step 900] Loss: 1.12e+08 -2.2032527923583984 0.0\n",
      "[Step 901] Loss: 1.13e+08 -2.201887369155884 0.0\n",
      "[Step 902] Loss: 1.14e+08 -2.2004740238189697 0.0\n",
      "[Step 903] Loss: 1.12e+08 -2.1990365982055664 0.0\n",
      "[Step 904] Loss: 1.14e+08 -2.197633743286133 0.0\n",
      "[Step 905] Loss: 1.12e+08 -2.196275472640991 0.0\n",
      "[Step 906] Loss: 1.11e+08 -2.1948838233947754 0.0\n",
      "[Step 907] Loss: 1.12e+08 -2.193476438522339 0.0\n",
      "[Step 908] Loss: 1.11e+08 -2.192061424255371 0.0\n",
      "[Step 909] Loss: 1.12e+08 -2.1906540393829346 0.0\n",
      "[Step 910] Loss: 1.12e+08 -2.1892404556274414 0.0\n",
      "[Step 911] Loss: 1.11e+08 -2.1877570152282715 0.0\n",
      "[Step 912] Loss: 1.12e+08 -2.186229705810547 0.0\n",
      "[Step 913] Loss: 1.11e+08 -2.1846516132354736 0.0\n",
      "[Step 914] Loss: 1.12e+08 -2.1830897331237793 0.0\n",
      "[Step 915] Loss: 1.11e+08 -2.1815102100372314 0.0\n",
      "[Step 916] Loss: 1.11e+08 -2.1799399852752686 0.0\n",
      "[Step 917] Loss: 1.11e+08 -2.1783454418182373 0.0\n",
      "[Step 918] Loss: 1.12e+08 -2.1767995357513428 0.0\n",
      "[Step 919] Loss: 1.12e+08 -2.1752028465270996 0.0\n",
      "[Step 920] Loss: 1.13e+08 -2.1736409664154053 0.0\n",
      "[Step 921] Loss: 1.13e+08 -2.1720855236053467 0.0\n",
      "[Step 922] Loss: 1.12e+08 -2.170499801635742 0.0\n",
      "[Step 923] Loss: 1.12e+08 -2.168898820877075 0.0\n",
      "[Step 924] Loss: 1.12e+08 -2.1673381328582764 0.0\n",
      "[Step 925] Loss: 1.13e+08 -2.165783166885376 0.0\n",
      "[Step 926] Loss: 1.12e+08 -2.164193630218506 0.0\n",
      "[Step 927] Loss: 1.11e+08 -2.1626007556915283 0.0\n",
      "[Step 928] Loss: 1.11e+08 -2.16096568107605 0.0\n",
      "[Step 929] Loss: 1.12e+08 -2.1594128608703613 0.0\n",
      "[Step 930] Loss: 1.11e+08 -2.1578547954559326 0.0\n",
      "[Step 931] Loss: 1.11e+08 -2.156301975250244 0.0\n",
      "[Step 932] Loss: 1.11e+08 -2.1547155380249023 0.0\n",
      "[Step 933] Loss: 1.12e+08 -2.153099298477173 0.0\n",
      "[Step 934] Loss: 1.11e+08 -2.1513760089874268 0.0\n",
      "[Step 935] Loss: 1.11e+08 -2.1496334075927734 0.0\n",
      "[Step 936] Loss: 1.12e+08 -2.147865056991577 0.0\n",
      "[Step 937] Loss: 1.10e+08 -2.146070957183838 0.0\n",
      "[Step 938] Loss: 1.11e+08 -2.144270658493042 0.0\n",
      "[Step 939] Loss: 1.11e+08 -2.1424648761749268 0.0\n",
      "[Step 940] Loss: 1.12e+08 -2.1406781673431396 0.0\n",
      "[Step 941] Loss: 1.11e+08 -2.1389360427856445 0.0\n",
      "[Step 942] Loss: 1.11e+08 -2.137146472930908 0.0\n",
      "[Step 943] Loss: 1.11e+08 -2.1353602409362793 0.0\n",
      "[Step 944] Loss: 1.12e+08 -2.133657932281494 0.0\n",
      "[Step 945] Loss: 1.11e+08 -2.131910800933838 0.0\n",
      "[Step 946] Loss: 1.12e+08 -2.130186080932617 0.0\n",
      "[Step 947] Loss: 1.11e+08 -2.1284329891204834 0.0\n",
      "[Step 948] Loss: 1.12e+08 -2.1266305446624756 0.0\n",
      "[Step 949] Loss: 1.12e+08 -2.1248419284820557 0.0\n",
      "[Step 950] Loss: 1.11e+08 -2.1230366230010986 0.0\n",
      "[Step 951] Loss: 1.11e+08 -2.1211962699890137 0.0\n",
      "[Step 952] Loss: 1.11e+08 -2.119333028793335 0.0\n",
      "[Step 953] Loss: 1.11e+08 -2.11749005317688 0.0\n",
      "[Step 954] Loss: 1.10e+08 -2.1155803203582764 0.0\n",
      "[Step 955] Loss: 1.12e+08 -2.1136093139648438 0.0\n",
      "[Step 956] Loss: 1.11e+08 -2.111706256866455 0.0\n",
      "[Step 957] Loss: 1.11e+08 -2.1098461151123047 0.0\n",
      "[Step 958] Loss: 1.12e+08 -2.1079232692718506 0.0\n",
      "[Step 959] Loss: 1.10e+08 -2.1059625148773193 0.0\n",
      "[Step 960] Loss: 1.13e+08 -2.10396146774292 0.0\n",
      "[Step 961] Loss: 1.12e+08 -2.1019704341888428 0.0\n",
      "[Step 962] Loss: 1.10e+08 -2.09997820854187 0.0\n",
      "[Step 963] Loss: 1.12e+08 -2.0980119705200195 0.0\n",
      "[Step 964] Loss: 1.11e+08 -2.096029758453369 0.0\n",
      "[Step 965] Loss: 1.13e+08 -2.0940704345703125 8.251369649769913e-07\n",
      "[Step 966] Loss: 1.11e+08 -2.0921149253845215 2.475410838087555e-06\n",
      "[Step 967] Loss: 1.12e+08 -2.09023118019104 2.475410838087555e-06\n",
      "[Step 968] Loss: 1.11e+08 -2.088346481323242 2.475410838087555e-06\n",
      "[Step 969] Loss: 1.12e+08 -2.086390256881714 2.475410838087555e-06\n",
      "[Step 970] Loss: 1.11e+08 -2.0844037532806396 2.475410838087555e-06\n",
      "[Step 971] Loss: 1.11e+08 -2.0824151039123535 2.475410838087555e-06\n",
      "[Step 972] Loss: 1.11e+08 -2.0803959369659424 3.300547859907965e-06\n",
      "[Step 973] Loss: 1.11e+08 -2.0783467292785645 4.95082167617511e-06\n",
      "[Step 974] Loss: 1.11e+08 -2.0762712955474854 4.95082167617511e-06\n",
      "[Step 975] Loss: 1.11e+08 -2.0741734504699707 4.95082167617511e-06\n",
      "[Step 976] Loss: 1.11e+08 -2.072124481201172 4.95082167617511e-06\n",
      "[Step 977] Loss: 1.11e+08 -2.0701470375061035 4.95082167617511e-06\n",
      "[Step 978] Loss: 1.11e+08 -2.0681231021881104 5.775958925369196e-06\n",
      "[Step 979] Loss: 1.10e+08 -2.0660619735717773 6.60109571981593e-06\n",
      "[Step 980] Loss: 1.10e+08 -2.0639965534210205 7.426232514262665e-06\n",
      "[Step 981] Loss: 1.12e+08 -2.0618808269500732 8.25136976345675e-06\n",
      "[Step 982] Loss: 1.10e+08 -2.059729814529419 9.076507012650836e-06\n",
      "[Step 983] Loss: 1.12e+08 -2.0575623512268066 9.076507012650836e-06\n",
      "[Step 984] Loss: 1.10e+08 -2.0553741455078125 9.90164335235022e-06\n",
      "[Step 985] Loss: 1.12e+08 -2.053241491317749 9.90164335235022e-06\n",
      "[Step 986] Loss: 1.11e+08 -2.051119804382324 9.90164335235022e-06\n",
      "[Step 987] Loss: 1.11e+08 -2.0489933490753174 1.1551917850738391e-05\n",
      "[Step 988] Loss: 1.11e+08 -2.0468385219573975 1.2377054190437775e-05\n",
      "[Step 989] Loss: 1.10e+08 -2.0446717739105225 1.320219143963186e-05\n",
      "[Step 990] Loss: 1.11e+08 -2.042494058609009 1.320219143963186e-05\n",
      "[Step 991] Loss: 1.10e+08 -2.04030442237854 1.320219143963186e-05\n",
      "[Step 992] Loss: 1.10e+08 -2.0381176471710205 1.320219143963186e-05\n",
      "[Step 993] Loss: 1.09e+08 -2.035935401916504 1.320219143963186e-05\n",
      "[Step 994] Loss: 1.12e+08 -2.0338332653045654 1.320219143963186e-05\n",
      "[Step 995] Loss: 1.11e+08 -2.0317771434783936 1.320219143963186e-05\n",
      "[Step 996] Loss: 1.11e+08 -2.029771327972412 1.4027328688825946e-05\n",
      "[Step 997] Loss: 1.11e+08 -2.027803421020508 1.485246502852533e-05\n",
      "[Step 998] Loss: 1.10e+08 -2.0258684158325195 1.7327876776107587e-05\n",
      "[Step 999] Loss: 1.11e+08 -2.0240166187286377 1.8153014025301673e-05\n",
      "[Step 1000] Loss: 1.10e+08 -2.0221214294433594 1.8978149455506355e-05\n",
      "[Step 1001] Loss: 1.11e+08 -2.020289897918701 1.8978149455506355e-05\n",
      "[Step 1002] Loss: 1.10e+08 -2.018489360809326 1.980328670470044e-05\n",
      "[Step 1003] Loss: 1.11e+08 -2.016655445098877 1.980328670470044e-05\n",
      "[Step 1004] Loss: 1.11e+08 -2.014850616455078 1.980328670470044e-05\n",
      "[Step 1005] Loss: 1.11e+08 -2.012967348098755 1.980328670470044e-05\n",
      "[Step 1006] Loss: 1.12e+08 -2.0110554695129395 2.0628423953894526e-05\n",
      "[Step 1007] Loss: 1.10e+08 -2.0091652870178223 2.2278698452282697e-05\n",
      "[Step 1008] Loss: 1.10e+08 -2.007298231124878 2.2278698452282697e-05\n",
      "[Step 1009] Loss: 1.10e+08 -2.0054116249084473 2.3103835701476783e-05\n",
      "[Step 1010] Loss: 1.11e+08 -2.0035641193389893 2.3103835701476783e-05\n",
      "[Step 1011] Loss: 1.11e+08 -2.0016887187957764 2.3103835701476783e-05\n",
      "[Step 1012] Loss: 1.10e+08 -1.9997559785842896 2.3103835701476783e-05\n",
      "[Step 1013] Loss: 1.11e+08 -1.9977848529815674 2.3928971131681465e-05\n",
      "[Step 1014] Loss: 1.10e+08 -1.9957635402679443 2.475410838087555e-05\n",
      "[Step 1015] Loss: 1.11e+08 -1.9937171936035156 2.640438287926372e-05\n",
      "[Step 1016] Loss: 1.10e+08 -1.9915984869003296 2.7229520128457807e-05\n",
      "[Step 1017] Loss: 1.10e+08 -1.9894264936447144 2.7229520128457807e-05\n",
      "[Step 1018] Loss: 1.10e+08 -1.9872442483901978 2.7229520128457807e-05\n",
      "[Step 1019] Loss: 1.10e+08 -1.9851861000061035 2.8054657377651893e-05\n",
      "[Step 1020] Loss: 1.11e+08 -1.9831546545028687 2.8879794626845978e-05\n",
      "[Step 1021] Loss: 1.11e+08 -1.9811567068099976 2.8879794626845978e-05\n",
      "[Step 1022] Loss: 1.10e+08 -1.979133129119873 3.135520455543883e-05\n",
      "[Step 1023] Loss: 1.11e+08 -1.9771158695220947 3.135520455543883e-05\n",
      "[Step 1024] Loss: 1.11e+08 -1.9750651121139526 3.3005479053827e-05\n",
      "[Step 1025] Loss: 1.11e+08 -1.9729821681976318 3.548089080140926e-05\n",
      "[Step 1026] Loss: 1.11e+08 -1.9708693027496338 3.6306028050603345e-05\n",
      "[Step 1027] Loss: 1.09e+08 -1.9687530994415283 3.960657340940088e-05\n",
      "[Step 1028] Loss: 1.11e+08 -1.9667448997497559 4.0431710658594966e-05\n",
      "[Step 1029] Loss: 1.10e+08 -1.964725375175476 4.125684790778905e-05\n",
      "[Step 1030] Loss: 1.10e+08 -1.9626662731170654 4.208198515698314e-05\n",
      "[Step 1031] Loss: 1.09e+08 -1.9605807065963745 4.373225965537131e-05\n",
      "[Step 1032] Loss: 1.10e+08 -1.958429217338562 4.538253415375948e-05\n",
      "[Step 1033] Loss: 1.10e+08 -1.956290364265442 4.4557396904565394e-05\n",
      "[Step 1034] Loss: 1.10e+08 -1.954193353652954 4.8683079512557015e-05\n",
      "[Step 1035] Loss: 1.09e+08 -1.9520883560180664 5.0333354010945186e-05\n",
      "[Step 1036] Loss: 1.11e+08 -1.950059413909912 5.115849126013927e-05\n",
      "[Step 1037] Loss: 1.11e+08 -1.9480743408203125 5.280876575852744e-05\n",
      "[Step 1038] Loss: 1.09e+08 -1.946082592010498 5.4459040256915614e-05\n",
      "[Step 1039] Loss: 1.09e+08 -1.944105863571167 5.4459040256915614e-05\n",
      "[Step 1040] Loss: 1.12e+08 -1.9421465396881104 5.6109314755303785e-05\n",
      "[Step 1041] Loss: 1.09e+08 -1.9401665925979614 5.6109314755303785e-05\n",
      "[Step 1042] Loss: 1.09e+08 -1.9381605386734009 5.7759589253691956e-05\n",
      "[Step 1043] Loss: 1.10e+08 -1.9361289739608765 5.8584722864907235e-05\n",
      "[Step 1044] Loss: 1.09e+08 -1.9340641498565674 5.940986011410132e-05\n",
      "[Step 1045] Loss: 1.09e+08 -1.9320107698440552 6.0234997363295406e-05\n",
      "[Step 1046] Loss: 1.10e+08 -1.9299427270889282 6.106013461248949e-05\n",
      "[Step 1047] Loss: 1.11e+08 -1.9278655052185059 6.188527186168358e-05\n",
      "[Step 1048] Loss: 1.10e+08 -1.925809383392334 6.271040911087766e-05\n",
      "[Step 1049] Loss: 1.11e+08 -1.923738718032837 6.353554636007175e-05\n",
      "[Step 1050] Loss: 1.09e+08 -1.9217075109481812 6.683609535684809e-05\n",
      "[Step 1051] Loss: 1.09e+08 -1.9196360111236572 6.931150710443035e-05\n",
      "[Step 1052] Loss: 1.11e+08 -1.9175989627838135 7.17869188520126e-05\n",
      "[Step 1053] Loss: 1.11e+08 -1.9155585765838623 7.426232332363725e-05\n",
      "[Step 1054] Loss: 1.09e+08 -1.9135041236877441 7.591259782202542e-05\n",
      "[Step 1055] Loss: 1.10e+08 -1.9115052223205566 7.838800956960768e-05\n",
      "[Step 1056] Loss: 1.10e+08 -1.9095005989074707 8.003828406799585e-05\n",
      "[Step 1057] Loss: 1.09e+08 -1.9074835777282715 8.25136958155781e-05\n",
      "[Step 1058] Loss: 1.09e+08 -1.9054521322250366 8.498910756316036e-05\n",
      "[Step 1059] Loss: 1.09e+08 -1.9033756256103516 8.581424481235445e-05\n",
      "[Step 1060] Loss: 1.10e+08 -1.9012855291366577 8.663938206154853e-05\n",
      "[Step 1061] Loss: 1.10e+08 -1.8992044925689697 8.911479380913079e-05\n",
      "[Step 1062] Loss: 1.09e+08 -1.8971190452575684 9.40656173042953e-05\n",
      "[Step 1063] Loss: 1.10e+08 -1.8949575424194336 9.489075455348939e-05\n",
      "[Step 1064] Loss: 1.10e+08 -1.8927600383758545 9.736615902511403e-05\n",
      "[Step 1065] Loss: 1.11e+08 -1.8906092643737793 9.819129627430812e-05\n",
      "[Step 1066] Loss: 1.09e+08 -1.8884806632995605 0.00010066670802189037\n",
      "[Step 1067] Loss: 1.10e+08 -1.886293649673462 0.00010149184527108446\n",
      "[Step 1068] Loss: 1.10e+08 -1.8840566873550415 0.00010396725701866671\n",
      "[Step 1069] Loss: 1.10e+08 -1.88182532787323 0.00010644266876624897\n",
      "[Step 1070] Loss: 1.09e+08 -1.8795567750930786 0.00010891808051383123\n",
      "[Step 1071] Loss: 1.09e+08 -1.8772844076156616 0.00011304376675980166\n",
      "[Step 1072] Loss: 1.10e+08 -1.874991774559021 0.00011716944572981447\n",
      "[Step 1073] Loss: 1.09e+08 -1.872708797454834 0.00012046999472659081\n",
      "[Step 1074] Loss: 1.10e+08 -1.8704559803009033 0.00012377054372336715\n",
      "[Step 1075] Loss: 1.10e+08 -1.8681071996688843 0.00012459568097256124\n",
      "[Step 1076] Loss: 1.10e+08 -1.8658193349838257 0.00012542081822175533\n",
      "[Step 1077] Loss: 1.09e+08 -1.8635154962539673 0.000132021916215308\n",
      "[Step 1078] Loss: 1.11e+08 -1.8612309694290161 0.00013697273971047252\n",
      "[Step 1079] Loss: 1.10e+08 -1.8589084148406982 0.0001386230142088607\n",
      "[Step 1080] Loss: 1.10e+08 -1.8566104173660278 0.00013944815145805478\n",
      "[Step 1081] Loss: 1.10e+08 -1.854256510734558 0.00014192356320563704\n",
      "[Step 1082] Loss: 1.09e+08 -1.8519588708877563 0.0001435738377040252\n",
      "[Step 1083] Loss: 1.10e+08 -1.849716305732727 0.00014934978389646858\n",
      "[Step 1084] Loss: 1.09e+08 -1.847420573234558 0.00015265033289324492\n",
      "[Step 1085] Loss: 1.11e+08 -1.8452174663543701 0.00015677601913921535\n",
      "[Step 1086] Loss: 1.10e+08 -1.8430547714233398 0.00015842629363760352\n",
      "[Step 1087] Loss: 1.11e+08 -1.8408929109573364 0.00016090170538518578\n",
      "[Step 1088] Loss: 1.09e+08 -1.8386902809143066 0.0001650273916311562\n",
      "[Step 1089] Loss: 1.10e+08 -1.8364880084991455 0.00016750280337873846\n",
      "[Step 1090] Loss: 1.10e+08 -1.83426833152771 0.0001716284896247089\n",
      "[Step 1091] Loss: 1.09e+08 -1.832012414932251 0.00017575417587067932\n",
      "[Step 1092] Loss: 1.09e+08 -1.8296966552734375 0.00018400554836262017\n",
      "[Step 1093] Loss: 1.10e+08 -1.827333688735962 0.0001889563718577847\n",
      "[Step 1094] Loss: 1.09e+08 -1.8249335289001465 0.00019473231805022806\n",
      "[Step 1095] Loss: 1.09e+08 -1.822571039199829 0.00020050827879458666\n",
      "[Step 1096] Loss: 1.10e+08 -1.8201824426651 0.00020628423953894526\n",
      "[Step 1097] Loss: 1.08e+08 -1.8178869485855103 0.00021040992578491569\n",
      "[Step 1098] Loss: 1.09e+08 -1.8155291080474854 0.00021783616102766246\n",
      "[Step 1099] Loss: 1.09e+08 -1.813194990158081 0.00022278698452282697\n",
      "[Step 1100] Loss: 1.09e+08 -1.8108216524124146 0.00023103835701476783\n",
      "[Step 1101] Loss: 1.10e+08 -1.808440089225769 0.00023433889145962894\n",
      "[Step 1102] Loss: 1.10e+08 -1.806069254875183 0.0002368143032072112\n",
      "[Step 1103] Loss: 1.08e+08 -1.803673267364502 0.00024589081294834614\n",
      "[Step 1104] Loss: 1.09e+08 -1.801236867904663 0.000254142185440287\n",
      "[Step 1105] Loss: 1.09e+08 -1.7987762689590454 0.0002582678571343422\n",
      "[Step 1106] Loss: 1.09e+08 -1.796356439590454 0.00025991813163273036\n",
      "[Step 1107] Loss: 1.09e+08 -1.793932318687439 0.0002681695041246712\n",
      "[Step 1108] Loss: 1.09e+08 -1.7915400266647339 0.0002722952049225569\n",
      "[Step 1109] Loss: 1.10e+08 -1.7891209125518799 0.0002772460284177214\n",
      "[Step 1110] Loss: 1.09e+08 -1.7867177724838257 0.00028467224910855293\n",
      "[Step 1111] Loss: 1.09e+08 -1.784377098083496 0.00029044822440482676\n",
      "[Step 1112] Loss: 1.08e+08 -1.7820218801498413 0.00029869956779293716\n",
      "[Step 1113] Loss: 1.09e+08 -1.7796566486358643 0.00030530066578648984\n",
      "[Step 1114] Loss: 1.09e+08 -1.7773367166519165 0.00030777609208598733\n",
      "[Step 1115] Loss: 1.09e+08 -1.775018334388733 0.00031437719007954\n",
      "[Step 1116] Loss: 1.10e+08 -1.772655725479126 0.0003185028617735952\n",
      "[Step 1117] Loss: 1.10e+08 -1.7703676223754883 0.00032427883706986904\n",
      "[Step 1118] Loss: 1.09e+08 -1.7681167125701904 0.0003300547832623124\n",
      "[Step 1119] Loss: 1.09e+08 -1.7658785581588745 0.00033583075855858624\n",
      "[Step 1120] Loss: 1.09e+08 -1.763604998588562 0.00034243182744830847\n",
      "[Step 1121] Loss: 1.09e+08 -1.7612857818603516 0.0003482078027445823\n",
      "[Step 1122] Loss: 1.09e+08 -1.7589409351348877 0.00035398374893702567\n",
      "[Step 1123] Loss: 1.08e+08 -1.7566016912460327 0.000364710547728464\n",
      "[Step 1124] Loss: 1.09e+08 -1.7543658018112183 0.0003713116457220167\n",
      "[Step 1125] Loss: 1.09e+08 -1.7521635293960571 0.0003762624692171812\n",
      "[Step 1126] Loss: 1.10e+08 -1.749959945678711 0.00038368868990801275\n",
      "[Step 1127] Loss: 1.08e+08 -1.7477624416351318 0.0003960657340940088\n",
      "[Step 1128] Loss: 1.09e+08 -1.7455226182937622 0.0004010165575891733\n",
      "[Step 1129] Loss: 1.09e+08 -1.7433325052261353 0.0004092679300811142\n",
      "[Step 1130] Loss: 1.09e+08 -1.741137146949768 0.00041751930257305503\n",
      "[Step 1131] Loss: 1.09e+08 -1.7389476299285889 0.00042494552326388657\n",
      "[Step 1132] Loss: 1.09e+08 -1.7368223667144775 0.0004331968957558274\n",
      "[Step 1133] Loss: 1.11e+08 -1.7346173524856567 0.0004397979937493801\n",
      "[Step 1134] Loss: 1.09e+08 -1.7324142456054688 0.0004488745180424303\n",
      "[Step 1135] Loss: 1.08e+08 -1.7301795482635498 0.0004530001897364855\n",
      "[Step 1136] Loss: 1.09e+08 -1.7279196977615356 0.0004645521112252027\n",
      "[Step 1137] Loss: 1.09e+08 -1.7256858348846436 0.00047527888091281056\n",
      "[Step 1138] Loss: 1.09e+08 -1.7234652042388916 0.0004810548562090844\n",
      "[Step 1139] Loss: 1.09e+08 -1.7212419509887695 0.000490956474095583\n",
      "[Step 1140] Loss: 1.08e+08 -1.7190263271331787 0.0004959073266945779\n",
      "[Step 1141] Loss: 1.09e+08 -1.7167787551879883 0.0005099346162751317\n",
      "[Step 1142] Loss: 1.09e+08 -1.7145440578460693 0.0005198362632654607\n",
      "[Step 1143] Loss: 1.09e+08 -1.7123003005981445 0.0005338636110536754\n",
      "[Step 1144] Loss: 1.09e+08 -1.7100309133529663 0.0005437652580440044\n",
      "[Step 1145] Loss: 1.08e+08 -1.707771897315979 0.0005495412042364478\n",
      "[Step 1146] Loss: 1.08e+08 -1.7055128812789917 0.0005610931548289955\n",
      "[Step 1147] Loss: 1.08e+08 -1.7033034563064575 0.0005668691010214388\n",
      "[Step 1148] Loss: 1.09e+08 -1.7010188102722168 0.0005726450472138822\n",
      "[Step 1149] Loss: 1.08e+08 -1.698713779449463 0.0005817215424031019\n",
      "[Step 1150] Loss: 1.09e+08 -1.6964517831802368 0.0005924483411945403\n",
      "[Step 1151] Loss: 1.09e+08 -1.6942411661148071 0.0006048253853805363\n",
      "[Step 1152] Loss: 1.09e+08 -1.6920267343521118 0.0006130767869763076\n",
      "[Step 1153] Loss: 1.09e+08 -1.6897822618484497 0.0006221532821655273\n",
      "[Step 1154] Loss: 1.09e+08 -1.6875591278076172 0.00062875438015908\n",
      "[Step 1155] Loss: 1.10e+08 -1.6853466033935547 0.0006386560271494091\n",
      "[Step 1156] Loss: 1.08e+08 -1.6831083297729492 0.0006485576741397381\n",
      "[Step 1157] Loss: 1.08e+08 -1.6808769702911377 0.0006592844147235155\n",
      "[Step 1158] Loss: 1.10e+08 -1.6786770820617676 0.0006700112135149539\n",
      "[Step 1159] Loss: 1.10e+08 -1.676600456237793 0.0006832134095020592\n",
      "[Step 1160] Loss: 1.09e+08 -1.6744847297668457 0.0006939402082934976\n",
      "[Step 1161] Loss: 1.09e+08 -1.6723418235778809 0.000704666948877275\n",
      "[Step 1162] Loss: 1.10e+08 -1.6702226400375366 0.0007178691448643804\n",
      "[Step 1163] Loss: 1.08e+08 -1.668107509613037 0.000729421095456928\n",
      "[Step 1164] Loss: 1.09e+08 -1.6660124063491821 0.0007351970416493714\n",
      "[Step 1165] Loss: 1.10e+08 -1.6639870405197144 0.0007500494830310345\n",
      "[Step 1166] Loss: 1.10e+08 -1.6619375944137573 0.0007632516790181398\n",
      "[Step 1167] Loss: 1.09e+08 -1.6598976850509644 0.0007739784778095782\n",
      "[Step 1168] Loss: 1.09e+08 -1.6578346490859985 0.0007913063745945692\n",
      "[Step 1169] Loss: 1.09e+08 -1.6557140350341797 0.0008012080215848982\n",
      "[Step 1170] Loss: 1.09e+08 -1.6535872220993042 0.000815235311165452\n",
      "[Step 1171] Loss: 1.08e+08 -1.6514620780944824 0.0008234867127612233\n",
      "[Step 1172] Loss: 1.09e+08 -1.6493916511535645 0.0008366889087483287\n",
      "[Step 1173] Loss: 1.09e+08 -1.647308588027954 0.0008465904975309968\n",
      "[Step 1174] Loss: 1.08e+08 -1.6451926231384277 0.0008564921445213258\n",
      "[Step 1175] Loss: 1.10e+08 -1.6431232690811157 0.0008688692469149828\n",
      "[Step 1176] Loss: 1.10e+08 -1.6411106586456299 0.0008779457421042025\n",
      "[Step 1177] Loss: 1.09e+08 -1.639136552810669 0.0008903227862901986\n",
      "[Step 1178] Loss: 1.09e+08 -1.6372259855270386 0.0009010495850816369\n",
      "[Step 1179] Loss: 1.08e+08 -1.635267734527588 0.0009192025754600763\n",
      "[Step 1180] Loss: 1.09e+08 -1.6333218812942505 0.0009291042224504054\n",
      "[Step 1181] Loss: 1.08e+08 -1.6313327550888062 0.00094313157023862\n",
      "[Step 1182] Loss: 1.10e+08 -1.629285454750061 0.0009489075164310634\n",
      "[Step 1183] Loss: 1.09e+08 -1.6271756887435913 0.0009604594088159502\n",
      "[Step 1184] Loss: 1.08e+08 -1.6251133680343628 0.0009711862076073885\n",
      "[Step 1185] Loss: 1.10e+08 -1.62312650680542 0.0009843884035944939\n",
      "[Step 1186] Loss: 1.09e+08 -1.6211881637573242 0.0009909895015880466\n",
      "[Step 1187] Loss: 1.09e+08 -1.6191668510437012 0.0010050168493762612\n",
      "[Step 1188] Loss: 1.08e+08 -1.6171236038208008 0.0010198692325502634\n",
      "[Step 1189] Loss: 1.08e+08 -1.615100383758545 0.0010330714285373688\n",
      "[Step 1190] Loss: 1.08e+08 -1.613093614578247 0.0010503993835300207\n",
      "[Step 1191] Loss: 1.09e+08 -1.611053705215454 0.0010603009723126888\n",
      "[Step 1192] Loss: 1.08e+08 -1.6090117692947388 0.0010776289273053408\n",
      "[Step 1193] Loss: 1.09e+08 -1.6069835424423218 0.0010949567658826709\n",
      "[Step 1194] Loss: 1.07e+08 -1.6049760580062866 0.0011081589618697762\n",
      "[Step 1195] Loss: 1.09e+08 -1.6029022932052612 0.0011230114614591002\n",
      "[Step 1196] Loss: 1.09e+08 -1.6008201837539673 0.001129612559452653\n",
      "[Step 1197] Loss: 1.09e+08 -1.598667025566101 0.0011461152462288737\n",
      "[Step 1198] Loss: 1.08e+08 -1.5965428352355957 0.0011560168350115418\n",
      "[Step 1199] Loss: 1.08e+08 -1.5944263935089111 0.0011716944864019752\n",
      "[Step 1200] Loss: 1.08e+08 -1.5922921895980835 0.0011857218341901898\n",
      "[Step 1201] Loss: 1.09e+08 -1.5901618003845215 0.001198098878376186\n",
      "[Step 1202] Loss: 1.08e+08 -1.588050365447998 0.0012063502799719572\n",
      "[Step 1203] Loss: 1.10e+08 -1.5859137773513794 0.0012212026631459594\n",
      "[Step 1204] Loss: 1.08e+08 -1.5837758779525757 0.0012360551627352834\n",
      "[Step 1205] Loss: 1.09e+08 -1.5816020965576172 0.0012484322069212794\n",
      "[Step 1206] Loss: 1.09e+08 -1.5795193910598755 0.0012632847065106034\n",
      "[Step 1207] Loss: 1.08e+08 -1.577402949333191 0.0012731862952932715\n",
      "[Step 1208] Loss: 1.08e+08 -1.5752918720245361 0.0012896890984848142\n",
      "[Step 1209] Loss: 1.08e+08 -1.573169231414795 0.0012995906872674823\n",
      "[Step 1210] Loss: 1.09e+08 -1.5709853172302246 0.0013152683386579156\n",
      "[Step 1211] Loss: 1.09e+08 -1.5688763856887817 0.0013292956864461303\n",
      "[Step 1212] Loss: 1.08e+08 -1.5668017864227295 0.0013449732214212418\n",
      "[Step 1213] Loss: 1.10e+08 -1.564712405204773 0.001360650872811675\n",
      "[Step 1214] Loss: 1.08e+08 -1.562631607055664 0.0013697273097932339\n",
      "[Step 1215] Loss: 1.08e+08 -1.5605143308639526 0.0013845798093825579\n",
      "[Step 1216] Loss: 1.09e+08 -1.5584022998809814 0.0013928312109783292\n",
      "[Step 1217] Loss: 1.08e+08 -1.5562491416931152 0.0014085087459534407\n",
      "[Step 1218] Loss: 1.08e+08 -1.5540693998336792 0.001426661852747202\n",
      "[Step 1219] Loss: 1.08e+08 -1.5518507957458496 0.0014398640487343073\n",
      "[Step 1220] Loss: 1.08e+08 -1.5496571063995361 0.0014547164319083095\n",
      "[Step 1221] Loss: 1.09e+08 -1.5474812984466553 0.0014654432889074087\n",
      "[Step 1222] Loss: 1.07e+08 -1.54532790184021 0.0014819459756836295\n",
      "[Step 1223] Loss: 1.09e+08 -1.5432308912277222 0.001492672716267407\n",
      "[Step 1224] Loss: 1.08e+08 -1.5411465167999268 0.0015083503676578403\n",
      "[Step 1225] Loss: 1.08e+08 -1.5390318632125854 0.001519902260042727\n",
      "[Step 1226] Loss: 1.09e+08 -1.5369235277175903 0.001532279304228723\n",
      "[Step 1227] Loss: 1.08e+08 -1.534779667854309 0.0015479569556191564\n",
      "[Step 1228] Loss: 1.08e+08 -1.5326639413833618 0.0015586836962029338\n",
      "[Step 1229] Loss: 1.08e+08 -1.5305615663528442 0.0015735361957922578\n",
      "[Step 1230] Loss: 1.09e+08 -1.5284510850906372 0.0015883886953815818\n",
      "[Step 1231] Loss: 1.10e+08 -1.526451826095581 0.0016015908913686872\n",
      "[Step 1232] Loss: 1.09e+08 -1.52444326877594 0.0016123176319524646\n",
      "[Step 1233] Loss: 1.09e+08 -1.5225977897644043 0.00162551982793957\n",
      "[Step 1234] Loss: 1.09e+08 -1.5207780599594116 0.0016362465685233474\n",
      "[Step 1235] Loss: 1.08e+08 -1.518937110900879 0.0016510990681126714\n",
      "[Step 1236] Loss: 1.08e+08 -1.5170961618423462 0.0016618258086964488\n",
      "[Step 1237] Loss: 1.09e+08 -1.5152411460876465 0.0016733778174966574\n",
      "[Step 1238] Loss: 1.09e+08 -1.5134268999099731 0.0016874050488695502\n",
      "[Step 1239] Loss: 1.09e+08 -1.5116794109344482 0.0016964816022664309\n",
      "[Step 1240] Loss: 1.09e+08 -1.5098779201507568 0.0017105089500546455\n",
      "[Step 1241] Loss: 1.08e+08 -1.5080316066741943 0.0017228859942406416\n",
      "[Step 1242] Loss: 1.09e+08 -1.5062634944915771 0.001738563529215753\n",
      "[Step 1243] Loss: 1.08e+08 -1.5044856071472168 0.0017443395918235183\n",
      "[Step 1244] Loss: 1.07e+08 -1.502651333808899 0.0017575417878106236\n",
      "[Step 1245] Loss: 1.08e+08 -1.5007727146148682 0.0017748696263879538\n",
      "[Step 1246] Loss: 1.09e+08 -1.4989044666290283 0.0017888969741761684\n",
      "[Step 1247] Loss: 1.08e+08 -1.497004508972168 0.0018062248127534986\n",
      "[Step 1248] Loss: 1.08e+08 -1.495086669921875 0.001824377803131938\n",
      "[Step 1249] Loss: 1.08e+08 -1.493155837059021 0.0018318040529266\n",
      "[Step 1250] Loss: 1.08e+08 -1.4911417961120605 0.001844181097112596\n",
      "[Step 1251] Loss: 1.08e+08 -1.4891611337661743 0.0018623340874910355\n",
      "[Step 1252] Loss: 1.08e+08 -1.487199068069458 0.0018780117388814688\n",
      "[Step 1253] Loss: 1.08e+08 -1.4851603507995605 0.0018969898810610175\n",
      "[Step 1254] Loss: 1.08e+08 -1.483046054840088 0.0019176183268427849\n",
      "[Step 1255] Loss: 1.08e+08 -1.4809807538986206 0.0019324708264321089\n",
      "[Step 1256] Loss: 1.09e+08 -1.4789764881134033 0.001944847870618105\n",
      "[Step 1257] Loss: 1.09e+08 -1.4769606590270996 0.0019613506738096476\n",
      "[Step 1258] Loss: 1.08e+08 -1.4749969244003296 0.001974552869796753\n",
      "[Step 1259] Loss: 1.09e+08 -1.4730262756347656 0.0019927057437598705\n",
      "[Step 1260] Loss: 1.08e+08 -1.4710177183151245 0.002003432484343648\n",
      "[Step 1261] Loss: 1.08e+08 -1.4690511226654053 0.0020125091541558504\n",
      "[Step 1262] Loss: 1.09e+08 -1.4670305252075195 0.00202818657271564\n",
      "[Step 1263] Loss: 1.07e+08 -1.4649872779846191 0.0020422139205038548\n",
      "[Step 1264] Loss: 1.07e+08 -1.4628942012786865 0.0020636676345020533\n",
      "[Step 1265] Loss: 1.08e+08 -1.4607905149459839 0.0020760446786880493\n",
      "[Step 1266] Loss: 1.08e+08 -1.458633303642273 0.0020908971782773733\n",
      "[Step 1267] Loss: 1.07e+08 -1.4564893245697021 0.0021107003558427095\n",
      "[Step 1268] Loss: 1.08e+08 -1.4544203281402588 0.0021305035334080458\n",
      "[Step 1269] Loss: 1.08e+08 -1.4523340463638306 0.0021494817920029163\n",
      "[Step 1270] Loss: 1.08e+08 -1.4501978158950806 0.0021676348987966776\n",
      "[Step 1271] Loss: 1.08e+08 -1.448042392730713 0.002185787772759795\n",
      "[Step 1272] Loss: 1.08e+08 -1.4458667039871216 0.002200640272349119\n",
      "[Step 1273] Loss: 1.07e+08 -1.4436777830123901 0.002217143075540662\n",
      "[Step 1274] Loss: 1.09e+08 -1.4415299892425537 0.0022336458787322044\n",
      "[Step 1275] Loss: 1.08e+08 -1.4394248723983765 0.0022559245117008686\n",
      "[Step 1276] Loss: 1.09e+08 -1.4374059438705444 0.0022683015558868647\n",
      "[Step 1277] Loss: 1.08e+08 -1.435402274131775 0.0022848043590784073\n",
      "[Step 1278] Loss: 1.08e+08 -1.4334206581115723 0.0023021320812404156\n",
      "[Step 1279] Loss: 1.08e+08 -1.4314061403274536 0.002317809732630849\n",
      "[Step 1280] Loss: 1.08e+08 -1.4293984174728394 0.0023417386692017317\n",
      "[Step 1281] Loss: 1.08e+08 -1.4273761510849 0.002354940865188837\n",
      "[Step 1282] Loss: 1.09e+08 -1.425452709197998 0.002374744275584817\n",
      "[Step 1283] Loss: 1.08e+08 -1.4236284494400024 0.002387121319770813\n",
      "[Step 1284] Loss: 1.07e+08 -1.421804666519165 0.002401973819360137\n",
      "[Step 1285] Loss: 1.08e+08 -1.4199899435043335 0.0024151757825165987\n",
      "[Step 1286] Loss: 1.08e+08 -1.4181486368179321 0.0024300282821059227\n",
      "[Step 1287] Loss: 1.08e+08 -1.4162954092025757 0.0024498316925019026\n",
      "[Step 1288] Loss: 1.07e+08 -1.4144196510314941 0.002465509343892336\n",
      "[Step 1289] Loss: 1.07e+08 -1.4124842882156372 0.002477886388078332\n",
      "[Step 1290] Loss: 1.09e+08 -1.4106673002243042 0.0024952141102403402\n",
      "[Step 1291] Loss: 1.07e+08 -1.4087982177734375 0.0025133672170341015\n",
      "[Step 1292] Loss: 1.09e+08 -1.406970739364624 0.002533995546400547\n",
      "[Step 1293] Loss: 1.07e+08 -1.4050755500793457 0.0025529738049954176\n",
      "[Step 1294] Loss: 1.09e+08 -1.4031449556350708 0.002561225090175867\n",
      "[Step 1295] Loss: 1.08e+08 -1.4012365341186523 0.0025793781969696283\n",
      "[Step 1296] Loss: 1.07e+08 -1.3993241786956787 0.0025892797857522964\n",
      "[Step 1297] Loss: 1.07e+08 -1.397451639175415 0.0026049574371427298\n",
      "[Step 1298] Loss: 1.07e+08 -1.3956066370010376 0.0026140338741242886\n",
      "[Step 1299] Loss: 1.07e+08 -1.393789529800415 0.0026288863737136126\n",
      "[Step 1300] Loss: 1.09e+08 -1.392031192779541 0.002649514703080058\n",
      "[Step 1301] Loss: 1.07e+08 -1.3902709484100342 0.0026726187206804752\n",
      "[Step 1302] Loss: 1.07e+08 -1.3885411024093628 0.0026849957648664713\n",
      "[Step 1303] Loss: 1.08e+08 -1.3868284225463867 0.002703973790630698\n",
      "[Step 1304] Loss: 1.08e+08 -1.3850274085998535 0.002715525683015585\n",
      "[Step 1305] Loss: 1.07e+08 -1.3832226991653442 0.002730378182604909\n",
      "[Step 1306] Loss: 1.08e+08 -1.3814231157302856 0.00274853128939867\n",
      "[Step 1307] Loss: 1.10e+08 -1.3798151016235352 0.0027609083335846663\n",
      "[Step 1308] Loss: 1.08e+08 -1.378187656402588 0.002781536662951112\n",
      "[Step 1309] Loss: 1.08e+08 -1.37656569480896 0.002799689769744873\n",
      "[Step 1310] Loss: 1.08e+08 -1.3749170303344727 0.0028227935545146465\n",
      "[Step 1311] Loss: 1.08e+08 -1.3732998371124268 0.0028425967320799828\n",
      "[Step 1312] Loss: 1.08e+08 -1.3715842962265015 0.0028599246870726347\n",
      "[Step 1313] Loss: 1.08e+08 -1.3697912693023682 0.00287312688305974\n",
      "[Step 1314] Loss: 1.07e+08 -1.3680065870285034 0.002897880971431732\n",
      "[Step 1315] Loss: 1.08e+08 -1.3662562370300293 0.002912733471021056\n",
      "[Step 1316] Loss: 1.08e+08 -1.3644776344299316 0.0029251105152070522\n",
      "[Step 1317] Loss: 1.07e+08 -1.362694263458252 0.002936662407591939\n",
      "[Step 1318] Loss: 1.07e+08 -1.3608864545822144 0.0029531652107834816\n",
      "[Step 1319] Loss: 1.09e+08 -1.3591328859329224 0.002973793540149927\n",
      "[Step 1320] Loss: 1.08e+08 -1.357362985610962 0.002991121495142579\n",
      "[Step 1321] Loss: 1.08e+08 -1.3556078672409058 0.0030043236911296844\n",
      "[Step 1322] Loss: 1.07e+08 -1.3538241386413574 0.0030290777795016766\n",
      "[Step 1323] Loss: 1.08e+08 -1.3519837856292725 0.0030505312606692314\n",
      "[Step 1324] Loss: 1.08e+08 -1.3502036333084106 0.003067034063860774\n",
      "[Step 1325] Loss: 1.08e+08 -1.3484346866607666 0.0030876626260578632\n",
      "[Step 1326] Loss: 1.07e+08 -1.3466010093688965 0.003109116107225418\n",
      "[Step 1327] Loss: 1.07e+08 -1.3447667360305786 0.0031272689811885357\n",
      "[Step 1328] Loss: 1.08e+08 -1.3428657054901123 0.0031437717843800783\n",
      "[Step 1329] Loss: 1.07e+08 -1.3409680128097534 0.003163575194776058\n",
      "[Step 1330] Loss: 1.08e+08 -1.3390271663665771 0.003189979586750269\n",
      "[Step 1331] Loss: 1.07e+08 -1.3371425867080688 0.003211433067917824\n",
      "[Step 1332] Loss: 1.07e+08 -1.3352349996566772 0.0032328865490853786\n",
      "[Step 1333] Loss: 1.08e+08 -1.3333247900009155 0.0032617663964629173\n",
      "[Step 1334] Loss: 1.07e+08 -1.3314058780670166 0.0032799195032566786\n",
      "[Step 1335] Loss: 1.08e+08 -1.3295848369598389 0.0032955969218164682\n",
      "[Step 1336] Loss: 1.08e+08 -1.3276938199996948 0.0033195260912179947\n",
      "[Step 1337] Loss: 1.07e+08 -1.3257430791854858 0.003341804724186659\n",
      "[Step 1338] Loss: 1.07e+08 -1.3238273859024048 0.00335995783098042\n",
      "[Step 1339] Loss: 1.08e+08 -1.3219863176345825 0.0033805861603468657\n",
      "[Step 1340] Loss: 1.07e+08 -1.3201450109481812 0.003408640855923295\n",
      "[Step 1341] Loss: 1.07e+08 -1.3183207511901855 0.003433394944295287\n",
      "[Step 1342] Loss: 1.07e+08 -1.3164558410644531 0.0034540232736617327\n",
      "[Step 1343] Loss: 1.08e+08 -1.314585566520691 0.003472176380455494\n",
      "[Step 1344] Loss: 1.08e+08 -1.312786340713501 0.003489504335448146\n",
      "[Step 1345] Loss: 1.08e+08 -1.3111079931259155 0.0035084823612123728\n",
      "[Step 1346] Loss: 1.08e+08 -1.3093527555465698 0.0035299358423799276\n",
      "[Step 1347] Loss: 1.08e+08 -1.3075683116912842 0.003548088949173689\n",
      "[Step 1348] Loss: 1.07e+08 -1.305686116218567 0.0035687172785401344\n",
      "[Step 1349] Loss: 1.07e+08 -1.3038277626037598 0.0036041983403265476\n",
      "[Step 1350] Loss: 1.08e+08 -1.3020159006118774 0.0036256518214941025\n",
      "[Step 1351] Loss: 1.07e+08 -1.3001831769943237 0.0036504059098660946\n",
      "[Step 1352] Loss: 1.08e+08 -1.2983404397964478 0.0036751599982380867\n",
      "[Step 1353] Loss: 1.08e+08 -1.296550989151001 0.003693313105031848\n",
      "[Step 1354] Loss: 1.08e+08 -1.2947535514831543 0.003712291130796075\n",
      "[Step 1355] Loss: 1.07e+08 -1.292927622795105 0.0037230178713798523\n",
      "[Step 1356] Loss: 1.08e+08 -1.2911072969436646 0.0037510725669562817\n",
      "[Step 1357] Loss: 1.07e+08 -1.2892985343933105 0.0037799524143338203\n",
      "[Step 1358] Loss: 1.09e+08 -1.2874212265014648 0.0038071819581091404\n",
      "[Step 1359] Loss: 1.07e+08 -1.2855485677719116 0.003830285742878914\n",
      "[Step 1360] Loss: 1.07e+08 -1.2836217880249023 0.0038558649830520153\n",
      "[Step 1361] Loss: 1.08e+08 -1.281792163848877 0.0038814442232251167\n",
      "[Step 1362] Loss: 1.07e+08 -1.279987096786499 0.003910324070602655\n",
      "[Step 1363] Loss: 1.07e+08 -1.2781585454940796 0.003928476944565773\n",
      "[Step 1364] Loss: 1.07e+08 -1.2763439416885376 0.003957356791943312\n",
      "[Step 1365] Loss: 1.09e+08 -1.274656891822815 0.003980460576713085\n",
      "[Step 1366] Loss: 1.07e+08 -1.2730227708816528 0.0040085152722895145\n",
      "[Step 1367] Loss: 1.08e+08 -1.271362543106079 0.004034094512462616\n",
      "[Step 1368] Loss: 1.07e+08 -1.2697491645812988 0.004062149208039045\n",
      "[Step 1369] Loss: 1.08e+08 -1.2680976390838623 0.004088553600013256\n",
      "[Step 1370] Loss: 1.07e+08 -1.2664304971694946 0.004107531625777483\n",
      "[Step 1371] Loss: 1.07e+08 -1.2647291421890259 0.004126510117202997\n",
      "[Step 1372] Loss: 1.06e+08 -1.2630457878112793 0.004154564812779427\n",
      "[Step 1373] Loss: 1.07e+08 -1.2612806558609009 0.004184269346296787\n",
      "[Step 1374] Loss: 1.07e+08 -1.259589672088623 0.004207373596727848\n",
      "[Step 1375] Loss: 1.07e+08 -1.2578775882720947 0.004234602674841881\n",
      "[Step 1376] Loss: 1.07e+08 -1.2561107873916626 0.0042610070668160915\n",
      "[Step 1377] Loss: 1.08e+08 -1.254365086555481 0.00428988691419363\n",
      "[Step 1378] Loss: 1.07e+08 -1.2526365518569946 0.004314641002565622\n",
      "[Step 1379] Loss: 1.06e+08 -1.250867486000061 0.004340220242738724\n",
      "[Step 1380] Loss: 1.07e+08 -1.2491083145141602 0.004373225849121809\n",
      "[Step 1381] Loss: 1.07e+08 -1.247327208518982 0.004405406303703785\n",
      "[Step 1382] Loss: 1.08e+08 -1.2455213069915771 0.004430985543876886\n",
      "[Step 1383] Loss: 1.07e+08 -1.243638038635254 0.004454914480447769\n",
      "[Step 1384] Loss: 1.07e+08 -1.241744041442871 0.004480493720620871\n",
      "[Step 1385] Loss: 1.07e+08 -1.239834189414978 0.004516799934208393\n",
      "[Step 1386] Loss: 1.09e+08 -1.2378958463668823 0.004541554022580385\n",
      "[Step 1387] Loss: 1.06e+08 -1.2359427213668823 0.004572083707898855\n",
      "[Step 1388] Loss: 1.07e+08 -1.234005331993103 0.004609215073287487\n",
      "[Step 1389] Loss: 1.09e+08 -1.2322194576263428 0.004642220679670572\n",
      "[Step 1390] Loss: 1.07e+08 -1.2304619550704956 0.004670275375247002\n",
      "[Step 1391] Loss: 1.07e+08 -1.2286996841430664 0.004701630212366581\n",
      "[Step 1392] Loss: 1.07e+08 -1.2268577814102173 0.004731335211545229\n",
      "[Step 1393] Loss: 1.06e+08 -1.2250499725341797 0.004766816273331642\n",
      "[Step 1394] Loss: 1.07e+08 -1.2232455015182495 0.004790745209902525\n",
      "[Step 1395] Loss: 1.07e+08 -1.221409797668457 0.004821275360882282\n",
      "[Step 1396] Loss: 1.07e+08 -1.21955406665802 0.004842728842049837\n",
      "[Step 1397] Loss: 1.08e+08 -1.2177501916885376 0.004871608689427376\n",
      "[Step 1398] Loss: 1.08e+08 -1.215899109840393 0.004911215044558048\n",
      "[Step 1399] Loss: 1.08e+08 -1.214066982269287 0.004945870954543352\n",
      "[Step 1400] Loss: 1.07e+08 -1.2121965885162354 0.004983002319931984\n",
      "[Step 1401] Loss: 1.07e+08 -1.210394263267517 0.005016007460653782\n",
      "[Step 1402] Loss: 1.07e+08 -1.2086514234542847 0.005059740040451288\n",
      "[Step 1403] Loss: 1.10e+08 -1.2070399522781372 0.005082843825221062\n",
      "[Step 1404] Loss: 1.07e+08 -1.2054860591888428 0.005107597913593054\n",
      "[Step 1405] Loss: 1.07e+08 -1.2039750814437866 0.005137302912771702\n",
      "[Step 1406] Loss: 1.07e+08 -1.2024320363998413 0.0051670074462890625\n",
      "[Step 1407] Loss: 1.07e+08 -1.2008397579193115 0.005193411838263273\n",
      "[Step 1408] Loss: 1.07e+08 -1.1992653608322144 0.005217341240495443\n",
      "[Step 1409] Loss: 1.07e+08 -1.1977524757385254 0.005244570318609476\n",
      "[Step 1410] Loss: 1.06e+08 -1.1961936950683594 0.005274275317788124\n",
      "[Step 1411] Loss: 1.07e+08 -1.1945871114730835 0.0053023300133645535\n",
      "[Step 1412] Loss: 1.07e+08 -1.192957878112793 0.005341936834156513\n",
      "[Step 1413] Loss: 1.07e+08 -1.1913169622421265 0.005366690922528505\n",
      "[Step 1414] Loss: 1.06e+08 -1.1896437406539917 0.005407947581261396\n",
      "[Step 1415] Loss: 1.07e+08 -1.1880015134811401 0.00544342864304781\n",
      "[Step 1416] Loss: 1.08e+08 -1.1864372491836548 0.005465707276016474\n",
      "[Step 1417] Loss: 1.09e+08 -1.1850202083587646 0.00549788773059845\n",
      "[Step 1418] Loss: 1.07e+08 -1.1835830211639404 0.005522641818970442\n",
      "[Step 1419] Loss: 1.06e+08 -1.1821107864379883 0.005549871362745762\n",
      "[Step 1420] Loss: 1.06e+08 -1.1806714534759521 0.005580401513725519\n",
      "[Step 1421] Loss: 1.06e+08 -1.179184913635254 0.0056092808954417706\n",
      "[Step 1422] Loss: 1.07e+08 -1.177661418914795 0.005642286501824856\n",
      "[Step 1423] Loss: 1.06e+08 -1.1760470867156982 0.0056711663492023945\n",
      "[Step 1424] Loss: 1.07e+08 -1.1744531393051147 0.00569179467856884\n",
      "[Step 1425] Loss: 1.07e+08 -1.1728280782699585 0.005726450588554144\n",
      "[Step 1426] Loss: 1.07e+08 -1.1712517738342285 0.005765231791883707\n",
      "[Step 1427] Loss: 1.06e+08 -1.1696491241455078 0.005799887701869011\n",
      "[Step 1428] Loss: 1.07e+08 -1.168141484260559 0.005842794664204121\n",
      "[Step 1429] Loss: 1.07e+08 -1.1665337085723877 0.00587084935978055\n",
      "[Step 1430] Loss: 1.06e+08 -1.164896011352539 0.005899729207158089\n",
      "[Step 1431] Loss: 1.07e+08 -1.1632704734802246 0.005931909661740065\n",
      "[Step 1432] Loss: 1.07e+08 -1.1616960763931274 0.00597976753488183\n",
      "[Step 1433] Loss: 1.07e+08 -1.160049557685852 0.006018549203872681\n",
      "[Step 1434] Loss: 1.07e+08 -1.1583869457244873 0.006052379496395588\n",
      "[Step 1435] Loss: 1.07e+08 -1.1567789316177368 0.006098587531596422\n",
      "[Step 1436] Loss: 1.08e+08 -1.1551454067230225 0.006138193886727095\n",
      "[Step 1437] Loss: 1.07e+08 -1.1535985469818115 0.006169549189507961\n",
      "[Step 1438] Loss: 1.07e+08 -1.152085781097412 0.006208330392837524\n",
      "[Step 1439] Loss: 1.07e+08 -1.15058434009552 0.0062462869100272655\n",
      "[Step 1440] Loss: 1.07e+08 -1.1490570306777954 0.00628341780975461\n",
      "[Step 1441] Loss: 1.06e+08 -1.1475460529327393 0.006323849782347679\n",
      "[Step 1442] Loss: 1.08e+08 -1.1460187435150146 0.006360980682075024\n",
      "[Step 1443] Loss: 1.06e+08 -1.1444263458251953 0.006417090073227882\n",
      "[Step 1444] Loss: 1.07e+08 -1.1428927183151245 0.006465773098170757\n",
      "[Step 1445] Loss: 1.07e+08 -1.141302466392517 0.006511981133371592\n",
      "[Step 1446] Loss: 1.07e+08 -1.1396294832229614 0.006546636577695608\n",
      "[Step 1447] Loss: 1.07e+08 -1.1379647254943848 0.006592018995434046\n",
      "[Step 1448] Loss: 1.07e+08 -1.1363149881362915 0.006641527637839317\n",
      "[Step 1449] Loss: 1.07e+08 -1.134655237197876 0.006686084903776646\n",
      "[Step 1450] Loss: 1.07e+08 -1.1330692768096924 0.006730642169713974\n",
      "[Step 1451] Loss: 1.06e+08 -1.1315200328826904 0.006770248990505934\n",
      "[Step 1452] Loss: 1.06e+08 -1.1299446821212769 0.006815631408244371\n",
      "[Step 1453] Loss: 1.08e+08 -1.1283866167068481 0.0068700904957950115\n",
      "[Step 1454] Loss: 1.08e+08 -1.1268693208694458 0.0069162980653345585\n",
      "[Step 1455] Loss: 1.06e+08 -1.1253730058670044 0.00695672957226634\n",
      "[Step 1456] Loss: 1.07e+08 -1.123878836631775 0.007002112455666065\n",
      "[Step 1457] Loss: 1.08e+08 -1.1224946975708008 0.007042543962597847\n",
      "[Step 1458] Loss: 1.06e+08 -1.121093988418579 0.007085450924932957\n",
      "[Step 1459] Loss: 1.08e+08 -1.1196444034576416 0.007134959567338228\n",
      "[Step 1460] Loss: 1.06e+08 -1.118194580078125 0.0071819922886788845\n",
      "[Step 1461] Loss: 1.07e+08 -1.1166942119598389 0.00722985016182065\n",
      "[Step 1462] Loss: 1.07e+08 -1.1151756048202515 0.007278533186763525\n",
      "[Step 1463] Loss: 1.08e+08 -1.1137572526931763 0.007314014248549938\n",
      "[Step 1464] Loss: 1.06e+08 -1.1123363971710205 0.007353620603680611\n",
      "[Step 1465] Loss: 1.07e+08 -1.110880970954895 0.007384975906461477\n",
      "[Step 1466] Loss: 1.07e+08 -1.1094242334365845 0.007414680905640125\n",
      "[Step 1467] Loss: 1.07e+08 -1.1079281568527222 0.007458413019776344\n",
      "[Step 1468] Loss: 1.08e+08 -1.106598973274231 0.007488118018954992\n",
      "[Step 1469] Loss: 1.06e+08 -1.1051775217056274 0.007525248918682337\n",
      "[Step 1470] Loss: 1.06e+08 -1.1037745475769043 0.007565680891275406\n",
      "[Step 1471] Loss: 1.05e+08 -1.102374792098999 0.007605287246406078\n",
      "[Step 1472] Loss: 1.07e+08 -1.101028323173523 0.007650670129805803\n",
      "[Step 1473] Loss: 1.07e+08 -1.0996018648147583 0.00769687769934535\n",
      "[Step 1474] Loss: 1.07e+08 -1.0982187986373901 0.007738959509879351\n",
      "[Step 1475] Loss: 1.07e+08 -1.0967944860458374 0.007793418597429991\n",
      "[Step 1476] Loss: 1.06e+08 -1.095386028289795 0.007837151177227497\n",
      "[Step 1477] Loss: 1.06e+08 -1.0939875841140747 0.007877582684159279\n",
      "[Step 1478] Loss: 1.08e+08 -1.0925469398498535 0.007922965101897717\n",
      "[Step 1479] Loss: 1.07e+08 -1.0909925699234009 0.007970822975039482\n",
      "[Step 1480] Loss: 1.06e+08 -1.089448094367981 0.008012904785573483\n",
      "[Step 1481] Loss: 1.06e+08 -1.0878682136535645 0.008060762658715248\n",
      "[Step 1482] Loss: 1.09e+08 -1.0864757299423218 0.008106970228254795\n",
      "[Step 1483] Loss: 1.06e+08 -1.0850409269332886 0.008165555074810982\n",
      "[Step 1484] Loss: 1.07e+08 -1.0836113691329956 0.008202686905860901\n",
      "[Step 1485] Loss: 1.07e+08 -1.0821768045425415 0.00824724417179823\n",
      "[Step 1486] Loss: 1.07e+08 -1.080660104751587 0.008299227803945541\n",
      "[Step 1487] Loss: 1.07e+08 -1.079119086265564 0.008346260525286198\n",
      "[Step 1488] Loss: 1.07e+08 -1.0775460004806519 0.008396593853831291\n",
      "[Step 1489] Loss: 1.07e+08 -1.0759772062301636 0.008454353548586369\n",
      "[Step 1490] Loss: 1.06e+08 -1.074387788772583 0.008505512028932571\n",
      "[Step 1491] Loss: 1.07e+08 -1.0728764533996582 0.008557495661079884\n",
      "[Step 1492] Loss: 1.06e+08 -1.0713351964950562 0.008623506873846054\n",
      "[Step 1493] Loss: 1.07e+08 -1.0698387622833252 0.008673015050590038\n",
      "[Step 1494] Loss: 1.07e+08 -1.0682833194732666 0.008716747164726257\n",
      "[Step 1495] Loss: 1.07e+08 -1.0667768716812134 0.008762954734265804\n",
      "[Step 1496] Loss: 1.07e+08 -1.0652047395706177 0.00881163775920868\n",
      "[Step 1497] Loss: 1.07e+08 -1.0635844469070435 0.008844642899930477\n",
      "[Step 1498] Loss: 1.06e+08 -1.061960220336914 0.00889497622847557\n",
      "[Step 1499] Loss: 1.07e+08 -1.060350775718689 0.00895026046782732\n",
      "[Step 1500] Loss: 1.08e+08 -1.0588712692260742 0.009012971073389053\n",
      "[Step 1501] Loss: 1.06e+08 -1.0574034452438354 0.009069905616343021\n",
      "[Step 1502] Loss: 1.08e+08 -1.0558722019195557 0.00912601500749588\n",
      "[Step 1503] Loss: 1.06e+08 -1.054334282875061 0.009188725613057613\n",
      "[Step 1504] Loss: 1.07e+08 -1.0527867078781128 0.009243184700608253\n",
      "[Step 1505] Loss: 1.07e+08 -1.05137300491333 0.009295168332755566\n",
      "[Step 1506] Loss: 1.06e+08 -1.0499825477600098 0.00935045164078474\n",
      "[Step 1507] Loss: 1.07e+08 -1.048553705215454 0.009392534382641315\n",
      "[Step 1508] Loss: 1.06e+08 -1.0471848249435425 0.009445343166589737\n",
      "[Step 1509] Loss: 1.06e+08 -1.0458718538284302 0.009506402537226677\n",
      "[Step 1510] Loss: 1.07e+08 -1.0446200370788574 0.009554261341691017\n",
      "[Step 1511] Loss: 1.07e+08 -1.0432586669921875 0.009618621319532394\n",
      "[Step 1512] Loss: 1.07e+08 -1.0419130325317383 0.009676381014287472\n",
      "[Step 1513] Loss: 1.06e+08 -1.0405710935592651 0.00973414070904255\n",
      "[Step 1514] Loss: 1.05e+08 -1.0391771793365479 0.009793550707399845\n",
      "[Step 1515] Loss: 1.06e+08 -1.0377726554870605 0.009858736768364906\n",
      "[Step 1516] Loss: 1.06e+08 -1.0362813472747803 0.009918146766722202\n",
      "[Step 1517] Loss: 1.07e+08 -1.034799575805664 0.00998250674456358\n",
      "[Step 1518] Loss: 1.07e+08 -1.0332319736480713 0.010038616135716438\n",
      "[Step 1519] Loss: 1.07e+08 -1.0316236019134521 0.010089774616062641\n",
      "[Step 1520] Loss: 1.07e+08 -1.0299698114395142 0.010150834918022156\n",
      "[Step 1521] Loss: 1.06e+08 -1.0283782482147217 0.010221797041594982\n",
      "[Step 1522] Loss: 1.06e+08 -1.02676260471344 0.01027873158454895\n",
      "[Step 1523] Loss: 1.07e+08 -1.0252050161361694 0.01032163854688406\n",
      "[Step 1524] Loss: 1.07e+08 -1.0236483812332153 0.010387648828327656\n",
      "[Step 1525] Loss: 1.06e+08 -1.02217435836792 0.010452009737491608\n",
      "[Step 1526] Loss: 1.06e+08 -1.020660638809204 0.010512244887650013\n",
      "[Step 1527] Loss: 1.06e+08 -1.0191303491592407 0.010577430948615074\n",
      "[Step 1528] Loss: 1.07e+08 -1.0176641941070557 0.010653343051671982\n",
      "[Step 1529] Loss: 1.07e+08 -1.016174077987671 0.010702026076614857\n",
      "[Step 1530] Loss: 1.06e+08 -1.0146628618240356 0.010780414566397667\n",
      "[Step 1531] Loss: 1.06e+08 -1.0132042169570923 0.0108431251719594\n",
      "[Step 1532] Loss: 1.07e+08 -1.0117243528366089 0.01091573666781187\n",
      "[Step 1533] Loss: 1.08e+08 -1.010391354560852 0.010966069996356964\n",
      "[Step 1534] Loss: 1.06e+08 -1.0090402364730835 0.011033731512725353\n",
      "[Step 1535] Loss: 1.06e+08 -1.0076971054077148 0.011086540296673775\n",
      "[Step 1536] Loss: 1.06e+08 -1.0063152313232422 0.011152551509439945\n",
      "[Step 1537] Loss: 1.08e+08 -1.0048792362213135 0.011218561790883541\n",
      "[Step 1538] Loss: 1.06e+08 -1.003373384475708 0.011278796941041946\n",
      "[Step 1539] Loss: 1.07e+08 -1.001842737197876 0.011346458457410336\n",
      "[Step 1540] Loss: 1.05e+08 -1.0003329515457153 0.011439698748290539\n",
      "[Step 1541] Loss: 1.06e+08 -0.9987818002700806 0.011515611782670021\n",
      "[Step 1542] Loss: 1.06e+08 -0.9972729086875916 0.011597299948334694\n",
      "[Step 1543] Loss: 1.05e+08 -0.9957817792892456 0.011677338741719723\n",
      "[Step 1544] Loss: 1.06e+08 -0.9942799210548401 0.011750775389373302\n",
      "[Step 1545] Loss: 1.06e+08 -0.9926769137382507 0.011821737512946129\n",
      "[Step 1546] Loss: 1.06e+08 -0.9910491108894348 0.011895999312400818\n",
      "[Step 1547] Loss: 1.06e+08 -0.98941969871521 0.011976038105785847\n",
      "[Step 1548] Loss: 1.07e+08 -0.9879333972930908 0.012058551423251629\n",
      "[Step 1549] Loss: 1.06e+08 -0.9864441156387329 0.012142715975642204\n",
      "[Step 1550] Loss: 1.07e+08 -0.9849594235420227 0.01220955140888691\n",
      "[Step 1551] Loss: 1.06e+08 -0.983456015586853 0.012295366264879704\n",
      "[Step 1552] Loss: 1.06e+08 -0.9818992614746094 0.01238530594855547\n",
      "[Step 1553] Loss: 1.07e+08 -0.9803394675254822 0.012471945025026798\n",
      "[Step 1554] Loss: 1.06e+08 -0.9787770509719849 0.012551983818411827\n",
      "[Step 1555] Loss: 1.05e+08 -0.9772043228149414 0.012637797743082047\n",
      "[Step 1556] Loss: 1.08e+08 -0.9755035042762756 0.0127112353220582\n",
      "[Step 1557] Loss: 1.05e+08 -0.9739165902137756 0.01278549712151289\n",
      "[Step 1558] Loss: 1.06e+08 -0.9723569750785828 0.012875436805188656\n",
      "[Step 1559] Loss: 1.06e+08 -0.9707878828048706 0.012967852875590324\n",
      "[Step 1560] Loss: 1.07e+08 -0.969195544719696 0.013066869229078293\n",
      "[Step 1561] Loss: 1.06e+08 -0.9677184820175171 0.013157634064555168\n",
      "[Step 1562] Loss: 1.06e+08 -0.9661818742752075 0.01325252465903759\n",
      "[Step 1563] Loss: 1.07e+08 -0.9645673632621765 0.013336689211428165\n",
      "[Step 1564] Loss: 1.06e+08 -0.9629769325256348 0.013439006172120571\n",
      "[Step 1565] Loss: 1.06e+08 -0.9614095687866211 0.013533896766602993\n",
      "[Step 1566] Loss: 1.06e+08 -0.9598900675773621 0.013612284325063229\n",
      "[Step 1567] Loss: 1.07e+08 -0.9584017395973206 0.013709650374948978\n",
      "[Step 1568] Loss: 1.06e+08 -0.9568729400634766 0.013802066445350647\n",
      "[Step 1569] Loss: 1.07e+08 -0.9554896354675293 0.013878803700208664\n",
      "[Step 1570] Loss: 1.07e+08 -0.9541659951210022 0.013944814912974834\n",
      "[Step 1571] Loss: 1.06e+08 -0.9528244137763977 0.014015776105225086\n",
      "[Step 1572] Loss: 1.06e+08 -0.9514909982681274 0.014100765809416771\n",
      "[Step 1573] Loss: 1.05e+08 -0.9501767754554749 0.014184929430484772\n",
      "[Step 1574] Loss: 1.07e+08 -0.948946475982666 0.014275694265961647\n",
      "[Step 1575] Loss: 1.05e+08 -0.9477741718292236 0.014364809729158878\n",
      "[Step 1576] Loss: 1.06e+08 -0.9465592503547668 0.01443577092140913\n",
      "[Step 1577] Loss: 1.05e+08 -0.945318877696991 0.014505082741379738\n",
      "[Step 1578] Loss: 1.06e+08 -0.9441003799438477 0.01458842121064663\n",
      "[Step 1579] Loss: 1.07e+08 -0.9428002834320068 0.014668460004031658\n",
      "[Step 1580] Loss: 1.06e+08 -0.9414966702461243 0.014754273928701878\n",
      "[Step 1581] Loss: 1.06e+08 -0.9402351975440979 0.01483101211488247\n",
      "[Step 1582] Loss: 1.06e+08 -0.9389492273330688 0.014919301494956017\n",
      "[Step 1583] Loss: 1.07e+08 -0.9376351237297058 0.015013366937637329\n",
      "[Step 1584] Loss: 1.06e+08 -0.9362564086914062 0.015093405731022358\n",
      "[Step 1585] Loss: 1.07e+08 -0.9349080324172974 0.01517509389668703\n",
      "[Step 1586] Loss: 1.06e+08 -0.9335716962814331 0.015269984491169453\n",
      "[Step 1587] Loss: 1.05e+08 -0.9321487545967102 0.01533929631114006\n",
      "[Step 1588] Loss: 1.06e+08 -0.9307931661605835 0.01540613267570734\n",
      "[Step 1589] Loss: 1.08e+08 -0.9295252561569214 0.015489471144974232\n",
      "[Step 1590] Loss: 1.06e+08 -0.9281850457191467 0.015594263561069965\n",
      "[Step 1591] Loss: 1.06e+08 -0.9268896579742432 0.01568998023867607\n",
      "[Step 1592] Loss: 1.07e+08 -0.9255239367485046 0.015770843252539635\n",
      "[Step 1593] Loss: 1.07e+08 -0.9240478873252869 0.01584758050739765\n",
      "[Step 1594] Loss: 1.07e+08 -0.9225104451179504 0.015963099896907806\n",
      "[Step 1595] Loss: 1.05e+08 -0.920995831489563 0.016062116250395775\n",
      "[Step 1596] Loss: 1.06e+08 -0.9194684624671936 0.01615453138947487\n",
      "[Step 1597] Loss: 1.05e+08 -0.9179019331932068 0.01625189743936062\n",
      "[Step 1598] Loss: 1.06e+08 -0.9163281917572021 0.016354214400053024\n",
      "[Step 1599] Loss: 1.07e+08 -0.9147886037826538 0.01644415408372879\n",
      "[Step 1600] Loss: 1.06e+08 -0.9131752848625183 0.016562974080443382\n",
      "[Step 1601] Loss: 1.06e+08 -0.9115539789199829 0.016680143773555756\n",
      "[Step 1602] Loss: 1.06e+08 -0.9100649952888489 0.01678493618965149\n",
      "[Step 1603] Loss: 1.06e+08 -0.9085554480552673 0.016871575266122818\n",
      "[Step 1604] Loss: 1.06e+08 -0.9070404767990112 0.01696811616420746\n",
      "[Step 1605] Loss: 1.06e+08 -0.905590832233429 0.017072083428502083\n",
      "[Step 1606] Loss: 1.04e+08 -0.9041122794151306 0.017167799174785614\n",
      "[Step 1607] Loss: 1.06e+08 -0.902716338634491 0.017253613099455833\n",
      "[Step 1608] Loss: 1.07e+08 -0.9013651013374329 0.01734107919037342\n",
      "[Step 1609] Loss: 1.06e+08 -0.8999791741371155 0.017446696758270264\n",
      "[Step 1610] Loss: 1.06e+08 -0.8985942602157593 0.017530860379338264\n",
      "[Step 1611] Loss: 1.05e+08 -0.8972830176353455 0.017641428858041763\n",
      "[Step 1612] Loss: 1.06e+08 -0.8960063457489014 0.017723942175507545\n",
      "[Step 1613] Loss: 1.06e+08 -0.8947270512580872 0.017824608832597733\n",
      "[Step 1614] Loss: 1.05e+08 -0.8935061693191528 0.01791289821267128\n",
      "[Step 1615] Loss: 1.06e+08 -0.8922189474105835 0.018024291843175888\n",
      "[Step 1616] Loss: 1.06e+08 -0.8909414410591125 0.018115056678652763\n",
      "[Step 1617] Loss: 1.07e+08 -0.889787495136261 0.018210772424936295\n",
      "[Step 1618] Loss: 1.06e+08 -0.8886193037033081 0.018304837867617607\n",
      "[Step 1619] Loss: 1.06e+08 -0.8874058127403259 0.018403854221105576\n",
      "[Step 1620] Loss: 1.06e+08 -0.8861774802207947 0.01850699633359909\n",
      "[Step 1621] Loss: 1.06e+08 -0.884911835193634 0.018586210906505585\n",
      "[Step 1622] Loss: 1.06e+08 -0.8835510015487671 0.018699252977967262\n",
      "[Step 1623] Loss: 1.05e+08 -0.8821964263916016 0.018794970586895943\n",
      "[Step 1624] Loss: 1.05e+08 -0.8808345198631287 0.018903888761997223\n",
      "[Step 1625] Loss: 1.06e+08 -0.8794441819190979 0.019007856026291847\n",
      "[Step 1626] Loss: 1.06e+08 -0.878125011920929 0.019142352044582367\n",
      "[Step 1627] Loss: 1.05e+08 -0.8767678737640381 0.01923559233546257\n",
      "[Step 1628] Loss: 1.06e+08 -0.8753951191902161 0.019348636269569397\n",
      "[Step 1629] Loss: 1.06e+08 -0.8740150928497314 0.019460855051875114\n",
      "[Step 1630] Loss: 1.05e+08 -0.8726908564567566 0.01956399716436863\n",
      "[Step 1631] Loss: 1.06e+08 -0.8713946342468262 0.019663838669657707\n",
      "[Step 1632] Loss: 1.06e+08 -0.8701254725456238 0.0197471771389246\n",
      "[Step 1633] Loss: 1.06e+08 -0.8687565922737122 0.019848668947815895\n",
      "[Step 1634] Loss: 1.06e+08 -0.8674541115760803 0.019960062578320503\n",
      "[Step 1635] Loss: 1.05e+08 -0.8661640286445618 0.020044228062033653\n",
      "[Step 1636] Loss: 1.05e+08 -0.8648056387901306 0.0201721228659153\n",
      "[Step 1637] Loss: 1.07e+08 -0.8637113571166992 0.020272789523005486\n",
      "[Step 1638] Loss: 1.05e+08 -0.8625535368919373 0.020368505269289017\n",
      "[Step 1639] Loss: 1.04e+08 -0.8613945245742798 0.020477423444390297\n",
      "[Step 1640] Loss: 1.07e+08 -0.8601128458976746 0.020586341619491577\n",
      "[Step 1641] Loss: 1.06e+08 -0.8588665127754211 0.02069278433918953\n",
      "[Step 1642] Loss: 1.06e+08 -0.8575369119644165 0.020809128880500793\n",
      "[Step 1643] Loss: 1.06e+08 -0.8562285304069519 0.020926298573613167\n",
      "[Step 1644] Loss: 1.06e+08 -0.8549990653991699 0.021040992811322212\n",
      "[Step 1645] Loss: 1.06e+08 -0.8536453247070312 0.02115403674542904\n",
      "[Step 1646] Loss: 1.06e+08 -0.8522381782531738 0.021269556134939194\n",
      "[Step 1647] Loss: 1.05e+08 -0.8508344888687134 0.021386725828051567\n",
      "[Step 1648] Loss: 1.06e+08 -0.8495188355445862 0.021495644003152847\n",
      "[Step 1649] Loss: 1.06e+08 -0.8483484387397766 0.021605385467410088\n",
      "[Step 1650] Loss: 1.05e+08 -0.8471049070358276 0.021716779097914696\n",
      "[Step 1651] Loss: 1.05e+08 -0.8459028601646423 0.021817445755004883\n",
      "[Step 1652] Loss: 1.06e+08 -0.8445777893066406 0.02193048968911171\n",
      "[Step 1653] Loss: 1.06e+08 -0.8432608842849731 0.022056736052036285\n",
      "[Step 1654] Loss: 1.06e+08 -0.841896653175354 0.022176381200551987\n",
      "[Step 1655] Loss: 1.05e+08 -0.8406329154968262 0.022300977259874344\n",
      "[Step 1656] Loss: 1.06e+08 -0.8393843173980713 0.022417321801185608\n",
      "[Step 1657] Loss: 1.07e+08 -0.8381385803222656 0.022558419033885002\n",
      "[Step 1658] Loss: 1.05e+08 -0.8368574976921082 0.02269456721842289\n",
      "[Step 1659] Loss: 1.06e+08 -0.8354997038841248 0.022847216576337814\n",
      "[Step 1660] Loss: 1.06e+08 -0.8341431617736816 0.022956134751439095\n",
      "[Step 1661] Loss: 1.06e+08 -0.8328108191490173 0.02307165414094925\n",
      "[Step 1662] Loss: 1.07e+08 -0.8316677808761597 0.02320367656648159\n",
      "[Step 1663] Loss: 1.06e+08 -0.8305976390838623 0.023310119286179543\n",
      "[Step 1664] Loss: 1.06e+08 -0.8294283151626587 0.023412436246871948\n",
      "[Step 1665] Loss: 1.06e+08 -0.8281802535057068 0.023522179573774338\n",
      "[Step 1666] Loss: 1.06e+08 -0.8268958330154419 0.023634398356080055\n",
      "[Step 1667] Loss: 1.07e+08 -0.8255579471588135 0.023752393200993538\n",
      "[Step 1668] Loss: 1.07e+08 -0.8243613839149475 0.023888539522886276\n",
      "[Step 1669] Loss: 1.05e+08 -0.8231516480445862 0.02400570921599865\n",
      "[Step 1670] Loss: 1.05e+08 -0.8219590783119202 0.024119578301906586\n",
      "[Step 1671] Loss: 1.05e+08 -0.8207217454910278 0.024216944351792336\n",
      "[Step 1672] Loss: 1.05e+08 -0.8194150328636169 0.024375371634960175\n",
      "[Step 1673] Loss: 1.05e+08 -0.8181132674217224 0.024498317390680313\n",
      "[Step 1674] Loss: 1.05e+08 -0.8168001174926758 0.0246121846139431\n",
      "[Step 1675] Loss: 1.05e+08 -0.8154904842376709 0.02474420703947544\n",
      "[Step 1676] Loss: 1.05e+08 -0.8142110109329224 0.02485642582178116\n",
      "[Step 1677] Loss: 1.05e+08 -0.8129106760025024 0.024982672184705734\n",
      "[Step 1678] Loss: 1.06e+08 -0.8115429282188416 0.02510974369943142\n",
      "[Step 1679] Loss: 1.06e+08 -0.8101369142532349 0.025262393057346344\n",
      "[Step 1680] Loss: 1.07e+08 -0.8086583614349365 0.025418344885110855\n",
      "[Step 1681] Loss: 1.05e+08 -0.8071241974830627 0.025588322430849075\n",
      "[Step 1682] Loss: 1.05e+08 -0.8056206703186035 0.02572612091898918\n",
      "[Step 1683] Loss: 1.06e+08 -0.8041141629219055 0.02584823966026306\n",
      "[Step 1684] Loss: 1.06e+08 -0.8026037812232971 0.026038022711873055\n",
      "[Step 1685] Loss: 1.06e+08 -0.8011364340782166 0.026156842708587646\n",
      "[Step 1686] Loss: 1.05e+08 -0.7996504306793213 0.02629711478948593\n",
      "[Step 1687] Loss: 1.07e+08 -0.7983700633049011 0.026448115706443787\n",
      "[Step 1688] Loss: 1.04e+08 -0.7970674633979797 0.02658921293914318\n",
      "[Step 1689] Loss: 1.08e+08 -0.7960076928138733 0.026705557480454445\n",
      "[Step 1690] Loss: 1.05e+08 -0.7949147820472717 0.026811175048351288\n",
      "[Step 1691] Loss: 1.05e+08 -0.7937166690826416 0.02695227414369583\n",
      "[Step 1692] Loss: 1.05e+08 -0.7924664616584778 0.027094196528196335\n",
      "[Step 1693] Loss: 1.05e+08 -0.7912178039550781 0.02722209319472313\n",
      "[Step 1694] Loss: 1.05e+08 -0.789915919303894 0.027384646236896515\n",
      "[Step 1695] Loss: 1.06e+08 -0.7886040210723877 0.027539771050214767\n",
      "[Step 1696] Loss: 1.05e+08 -0.7873504161834717 0.027686646208167076\n",
      "[Step 1697] Loss: 1.06e+08 -0.7860633134841919 0.027861574664711952\n",
      "[Step 1698] Loss: 1.06e+08 -0.7847700119018555 0.028013400733470917\n",
      "[Step 1699] Loss: 1.05e+08 -0.7834874391555786 0.02818090282380581\n",
      "[Step 1700] Loss: 1.05e+08 -0.7822083830833435 0.028333552181720734\n",
      "[Step 1701] Loss: 1.06e+08 -0.7808980941772461 0.028501056134700775\n",
      "[Step 1702] Loss: 1.05e+08 -0.7796083688735962 0.02866690792143345\n",
      "[Step 1703] Loss: 1.05e+08 -0.7783597707748413 0.0288352370262146\n",
      "[Step 1704] Loss: 1.06e+08 -0.7770278453826904 0.028977159410715103\n",
      "[Step 1705] Loss: 1.04e+08 -0.7756627798080444 0.02912485972046852\n",
      "[Step 1706] Loss: 1.06e+08 -0.7743405699729919 0.029305564239621162\n",
      "[Step 1707] Loss: 1.05e+08 -0.7731200456619263 0.02946564182639122\n",
      "[Step 1708] Loss: 1.06e+08 -0.7720141410827637 0.02960013784468174\n",
      "[Step 1709] Loss: 1.05e+08 -0.7708706855773926 0.02975773997604847\n",
      "[Step 1710] Loss: 1.05e+08 -0.769782543182373 0.02989141084253788\n",
      "[Step 1711] Loss: 1.05e+08 -0.7686547040939331 0.030040761455893517\n",
      "[Step 1712] Loss: 1.06e+08 -0.767486572265625 0.030198361724615097\n",
      "[Step 1713] Loss: 1.05e+08 -0.7663514018058777 0.030319657176733017\n",
      "[Step 1714] Loss: 1.05e+08 -0.7651625275611877 0.030468182638287544\n",
      "[Step 1715] Loss: 1.05e+08 -0.7640621662139893 0.03062000684440136\n",
      "[Step 1716] Loss: 1.05e+08 -0.7630144953727722 0.03076275624334812\n",
      "[Step 1717] Loss: 1.05e+08 -0.7619875073432922 0.030901379883289337\n",
      "[Step 1718] Loss: 1.06e+08 -0.7610718011856079 0.031049903482198715\n",
      "[Step 1719] Loss: 1.06e+08 -0.760096549987793 0.031156346201896667\n",
      "[Step 1720] Loss: 1.05e+08 -0.7590851783752441 0.03128671646118164\n",
      "[Step 1721] Loss: 1.06e+08 -0.7580633759498596 0.031427815556526184\n",
      "[Step 1722] Loss: 1.05e+08 -0.7570185661315918 0.031558189541101456\n",
      "[Step 1723] Loss: 1.06e+08 -0.755969762802124 0.0316951610147953\n",
      "[Step 1724] Loss: 1.06e+08 -0.7547985911369324 0.03184781223535538\n",
      "[Step 1725] Loss: 1.05e+08 -0.7536197900772095 0.0320400670170784\n",
      "[Step 1726] Loss: 1.06e+08 -0.7525011897087097 0.03219189494848251\n",
      "[Step 1727] Loss: 1.06e+08 -0.7515662312507629 0.032326389104127884\n",
      "[Step 1728] Loss: 1.04e+08 -0.7505855560302734 0.03246088698506355\n",
      "[Step 1729] Loss: 1.05e+08 -0.7495508193969727 0.032601162791252136\n",
      "[Step 1730] Loss: 1.05e+08 -0.7484744191169739 0.03278186544775963\n",
      "[Step 1731] Loss: 1.06e+08 -0.7474057674407959 0.0329650454223156\n",
      "[Step 1732] Loss: 1.05e+08 -0.7462905049324036 0.033135849982500076\n",
      "[Step 1733] Loss: 1.05e+08 -0.7452383041381836 0.03329675272107124\n",
      "[Step 1734] Loss: 1.05e+08 -0.7441738843917847 0.03344940394163132\n",
      "[Step 1735] Loss: 1.05e+08 -0.7430948615074158 0.033598750829696655\n",
      "[Step 1736] Loss: 1.05e+08 -0.7420141100883484 0.03377285599708557\n",
      "[Step 1737] Loss: 1.05e+08 -0.7408809065818787 0.033925507217645645\n",
      "[Step 1738] Loss: 1.05e+08 -0.7397388219833374 0.03411446139216423\n",
      "[Step 1739] Loss: 1.06e+08 -0.7385267019271851 0.034287743270397186\n",
      "[Step 1740] Loss: 1.04e+08 -0.7373526096343994 0.03445689380168915\n",
      "[Step 1741] Loss: 1.05e+08 -0.7361433506011963 0.03464915230870247\n",
      "[Step 1742] Loss: 1.06e+08 -0.7348189949989319 0.034849658608436584\n",
      "[Step 1743] Loss: 1.07e+08 -0.7336716651916504 0.0350237637758255\n",
      "[Step 1744] Loss: 1.05e+08 -0.7325323820114136 0.03519291803240776\n",
      "[Step 1745] Loss: 1.04e+08 -0.7313439249992371 0.03535051643848419\n",
      "[Step 1746] Loss: 1.05e+08 -0.7301737666130066 0.035529572516679764\n",
      "[Step 1747] Loss: 1.06e+08 -0.729141891002655 0.03565829247236252\n",
      "[Step 1748] Loss: 1.04e+08 -0.72808837890625 0.03583652526140213\n",
      "[Step 1749] Loss: 1.05e+08 -0.7270727157592773 0.0360197052359581\n",
      "[Step 1750] Loss: 1.05e+08 -0.7260348200798035 0.036170702427625656\n",
      "[Step 1751] Loss: 1.04e+08 -0.7249915599822998 0.03634480759501457\n",
      "[Step 1752] Loss: 1.05e+08 -0.7239194512367249 0.03651973605155945\n",
      "[Step 1753] Loss: 1.05e+08 -0.7228171825408936 0.03671364486217499\n",
      "[Step 1754] Loss: 1.05e+08 -0.7217057943344116 0.03689517453312874\n",
      "[Step 1755] Loss: 1.05e+08 -0.720504641532898 0.037070102989673615\n",
      "[Step 1756] Loss: 1.05e+08 -0.7192812561988831 0.037240080535411835\n",
      "[Step 1757] Loss: 1.05e+08 -0.7179530262947083 0.0374273881316185\n",
      "[Step 1758] Loss: 1.05e+08 -0.7166417837142944 0.03763119503855705\n",
      "[Step 1759] Loss: 1.05e+08 -0.715363085269928 0.03785233199596405\n",
      "[Step 1760] Loss: 1.05e+08 -0.7141454219818115 0.03804871439933777\n",
      "[Step 1761] Loss: 1.05e+08 -0.7129554748535156 0.0382285937666893\n",
      "[Step 1762] Loss: 1.05e+08 -0.7117075324058533 0.038439828902482986\n",
      "[Step 1763] Loss: 1.04e+08 -0.7104325294494629 0.03863703832030296\n",
      "[Step 1764] Loss: 1.05e+08 -0.7091121673583984 0.038840021938085556\n",
      "[Step 1765] Loss: 1.05e+08 -0.7077721357345581 0.039059508591890335\n",
      "[Step 1766] Loss: 1.05e+08 -0.7063485383987427 0.039315301924943924\n",
      "[Step 1767] Loss: 1.07e+08 -0.705078661441803 0.03953973948955536\n",
      "[Step 1768] Loss: 1.05e+08 -0.703787624835968 0.039764177054166794\n",
      "[Step 1769] Loss: 1.05e+08 -0.7024590969085693 0.039980363100767136\n",
      "[Step 1770] Loss: 1.06e+08 -0.7012017965316772 0.04019077122211456\n",
      "[Step 1771] Loss: 1.06e+08 -0.7000104784965515 0.040395405143499374\n",
      "[Step 1772] Loss: 1.04e+08 -0.6987758278846741 0.04062314331531525\n",
      "[Step 1773] Loss: 1.05e+08 -0.6975491046905518 0.0408492311835289\n",
      "[Step 1774] Loss: 1.05e+08 -0.696414589881897 0.04104066267609596\n",
      "[Step 1775] Loss: 1.04e+08 -0.6952627301216125 0.041246119886636734\n",
      "[Step 1776] Loss: 1.06e+08 -0.6939730644226074 0.0414779856801033\n",
      "[Step 1777] Loss: 1.05e+08 -0.6926557421684265 0.041718099266290665\n",
      "[Step 1778] Loss: 1.05e+08 -0.6913632750511169 0.04195243865251541\n",
      "[Step 1779] Loss: 1.05e+08 -0.6899979710578918 0.04218677803874016\n",
      "[Step 1780] Loss: 1.06e+08 -0.6886211633682251 0.0424029640853405\n",
      "[Step 1781] Loss: 1.04e+08 -0.6872407793998718 0.04261254891753197\n",
      "[Step 1782] Loss: 1.05e+08 -0.6858060956001282 0.042881544679403305\n",
      "[Step 1783] Loss: 1.04e+08 -0.684424638748169 0.04314393550157547\n",
      "[Step 1784] Loss: 1.05e+08 -0.6830615401268005 0.04342448338866234\n",
      "[Step 1785] Loss: 1.04e+08 -0.6816713213920593 0.04366954788565636\n",
      "[Step 1786] Loss: 1.04e+08 -0.680243968963623 0.04392121732234955\n",
      "[Step 1787] Loss: 1.05e+08 -0.6788451075553894 0.044192686676979065\n",
      "[Step 1788] Loss: 1.04e+08 -0.6774169206619263 0.04447653144598007\n",
      "[Step 1789] Loss: 1.05e+08 -0.6760246157646179 0.04474552720785141\n",
      "[Step 1790] Loss: 1.04e+08 -0.6745815277099609 0.04502524808049202\n",
      "[Step 1791] Loss: 1.05e+08 -0.6732339262962341 0.04531239718198776\n",
      "[Step 1792] Loss: 1.05e+08 -0.6718604564666748 0.04557809233665466\n",
      "[Step 1793] Loss: 1.05e+08 -0.6705599427223206 0.0458512119948864\n",
      "[Step 1794] Loss: 1.05e+08 -0.6693640947341919 0.04610535129904747\n",
      "[Step 1795] Loss: 1.05e+08 -0.6681487560272217 0.04632648825645447\n",
      "[Step 1796] Loss: 1.05e+08 -0.666882336139679 0.046595484018325806\n",
      "[Step 1797] Loss: 1.05e+08 -0.6655706167221069 0.04685540124773979\n",
      "[Step 1798] Loss: 1.05e+08 -0.6642431020736694 0.047140900045633316\n",
      "[Step 1799] Loss: 1.04e+08 -0.662909984588623 0.04742474853992462\n",
      "[Step 1800] Loss: 1.04e+08 -0.6616918444633484 0.04767806455492973\n",
      "[Step 1801] Loss: 1.09e+08 -0.6609418988227844 0.04785382002592087\n",
      "[Step 1802] Loss: 1.04e+08 -0.6601261496543884 0.04802049696445465\n",
      "[Step 1803] Loss: 1.06e+08 -0.6591847538948059 0.04825400933623314\n",
      "[Step 1804] Loss: 1.05e+08 -0.6582226157188416 0.0484677217900753\n",
      "[Step 1805] Loss: 1.05e+08 -0.6572033166885376 0.048682257533073425\n",
      "[Step 1806] Loss: 1.05e+08 -0.6561875939369202 0.04892484471201897\n",
      "[Step 1807] Loss: 1.04e+08 -0.6551130414009094 0.04916166141629219\n",
      "[Step 1808] Loss: 1.04e+08 -0.6541134119033813 0.049399301409721375\n",
      "[Step 1809] Loss: 1.05e+08 -0.652997612953186 0.049666643142700195\n",
      "[Step 1810] Loss: 1.05e+08 -0.6518938541412354 0.04991336166858673\n",
      "[Step 1811] Loss: 1.05e+08 -0.6508828997612 0.050145223736763\n",
      "[Step 1812] Loss: 1.04e+08 -0.6499180197715759 0.05034078285098076\n",
      "[Step 1813] Loss: 1.05e+08 -0.6489564180374146 0.05059574916958809\n",
      "[Step 1814] Loss: 1.04e+08 -0.6479265093803406 0.050819359719753265\n",
      "[Step 1815] Loss: 1.05e+08 -0.6469419598579407 0.05104544758796692\n",
      "[Step 1816] Loss: 1.04e+08 -0.6459315419197083 0.051281437277793884\n",
      "[Step 1817] Loss: 1.04e+08 -0.6449204683303833 0.051513299345970154\n",
      "[Step 1818] Loss: 1.05e+08 -0.6438944339752197 0.05173443630337715\n",
      "[Step 1819] Loss: 1.08e+08 -0.6432251334190369 0.051888737827539444\n",
      "[Step 1820] Loss: 1.05e+08 -0.6425885558128357 0.05205376446247101\n",
      "[Step 1821] Loss: 1.05e+08 -0.6419811248779297 0.052214667201042175\n",
      "[Step 1822] Loss: 1.05e+08 -0.641339123249054 0.052410226315259933\n",
      "[Step 1823] Loss: 1.04e+08 -0.6407303214073181 0.05256452411413193\n",
      "[Step 1824] Loss: 1.05e+08 -0.6401596069335938 0.05271965265274048\n",
      "[Step 1825] Loss: 1.04e+08 -0.6395562887191772 0.05293253809213638\n",
      "[Step 1826] Loss: 1.05e+08 -0.6388975381851196 0.0530802346765995\n",
      "[Step 1827] Loss: 1.04e+08 -0.6381618976593018 0.053248561918735504\n",
      "[Step 1828] Loss: 1.04e+08 -0.6373385190963745 0.05346804857254028\n",
      "[Step 1829] Loss: 1.05e+08 -0.6365545988082886 0.053660307079553604\n",
      "[Step 1830] Loss: 1.05e+08 -0.6357254385948181 0.05387071520090103\n",
      "[Step 1831] Loss: 1.05e+08 -0.6348671317100525 0.05406380072236061\n",
      "[Step 1832] Loss: 1.04e+08 -0.6339454054832458 0.05429483577609062\n",
      "[Step 1833] Loss: 1.05e+08 -0.6330812573432922 0.05449121817946434\n",
      "[Step 1834] Loss: 1.05e+08 -0.6321973204612732 0.054690077900886536\n",
      "[Step 1835] Loss: 1.05e+08 -0.6313179731369019 0.054909564554691315\n",
      "[Step 1836] Loss: 1.05e+08 -0.6304016709327698 0.05513647571206093\n",
      "[Step 1837] Loss: 1.06e+08 -0.6294312477111816 0.05537494271993637\n",
      "[Step 1838] Loss: 1.05e+08 -0.6286283135414124 0.055564723908901215\n",
      "[Step 1839] Loss: 1.05e+08 -0.627811074256897 0.05575697869062424\n",
      "[Step 1840] Loss: 1.05e+08 -0.6269950866699219 0.05595171079039574\n",
      "[Step 1841] Loss: 1.05e+08 -0.6261919140815735 0.056133244186639786\n",
      "[Step 1842] Loss: 1.05e+08 -0.6254457831382751 0.056353554129600525\n",
      "[Step 1843] Loss: 1.04e+08 -0.6245623826980591 0.0565812923014164\n",
      "[Step 1844] Loss: 1.06e+08 -0.6236885190010071 0.05679665133357048\n",
      "[Step 1845] Loss: 1.05e+08 -0.6227605938911438 0.057021088898181915\n",
      "[Step 1846] Loss: 1.04e+08 -0.6217998266220093 0.057263679802417755\n",
      "[Step 1847] Loss: 1.06e+08 -0.6206775903701782 0.05749966949224472\n",
      "[Step 1848] Loss: 1.04e+08 -0.6195133328437805 0.057736482471227646\n",
      "[Step 1849] Loss: 1.06e+08 -0.6185314059257507 0.05802445486187935\n",
      "[Step 1850] Loss: 1.05e+08 -0.6175810098648071 0.058259621262550354\n",
      "[Step 1851] Loss: 1.06e+08 -0.6167000532150269 0.05848570913076401\n",
      "[Step 1852] Loss: 1.04e+08 -0.6156757473945618 0.05873572453856468\n",
      "[Step 1853] Loss: 1.04e+08 -0.6147723197937012 0.05900884419679642\n",
      "[Step 1854] Loss: 1.04e+08 -0.6138713955879211 0.05924566090106964\n",
      "[Step 1855] Loss: 1.04e+08 -0.6129348874092102 0.059484124183654785\n",
      "[Step 1856] Loss: 1.03e+08 -0.6120105981826782 0.05973413959145546\n",
      "[Step 1857] Loss: 1.05e+08 -0.6111143231391907 0.05998580530285835\n",
      "[Step 1858] Loss: 1.06e+08 -0.6101316213607788 0.060247376561164856\n",
      "[Step 1859] Loss: 1.05e+08 -0.6090631484985352 0.06048583984375\n",
      "[Step 1860] Loss: 1.05e+08 -0.6078986525535583 0.060770511627197266\n",
      "[Step 1861] Loss: 1.04e+08 -0.6066634058952332 0.06111789494752884\n",
      "[Step 1862] Loss: 1.04e+08 -0.6054109334945679 0.06144217401742935\n",
      "[Step 1863] Loss: 1.06e+08 -0.6041308641433716 0.061743348836898804\n",
      "[Step 1864] Loss: 1.04e+08 -0.6029481291770935 0.0620395727455616\n",
      "[Step 1865] Loss: 1.05e+08 -0.6018490195274353 0.062314342707395554\n",
      "[Step 1866] Loss: 1.05e+08 -0.6008098721504211 0.06256931275129318\n",
      "[Step 1867] Loss: 1.04e+08 -0.5998281836509705 0.06284408271312714\n",
      "[Step 1868] Loss: 1.05e+08 -0.5987687706947327 0.06313948333263397\n",
      "[Step 1869] Loss: 1.04e+08 -0.5976911783218384 0.06343900412321091\n",
      "[Step 1870] Loss: 1.05e+08 -0.5965769290924072 0.06374760717153549\n",
      "[Step 1871] Loss: 1.05e+08 -0.595396876335144 0.06404300779104233\n",
      "[Step 1872] Loss: 1.05e+08 -0.5942105650901794 0.06435408443212509\n",
      "[Step 1873] Loss: 1.04e+08 -0.5930058360099792 0.06470311433076859\n",
      "[Step 1874] Loss: 1.05e+08 -0.5919146537780762 0.0650191456079483\n",
      "[Step 1875] Loss: 1.04e+08 -0.5907284617424011 0.06539952754974365\n",
      "[Step 1876] Loss: 1.05e+08 -0.5894945859909058 0.06573536247015\n",
      "[Step 1877] Loss: 1.04e+08 -0.5882259011268616 0.06607697159051895\n",
      "[Step 1878] Loss: 1.06e+08 -0.5871586203575134 0.06641114503145218\n",
      "[Step 1879] Loss: 1.05e+08 -0.5860719084739685 0.06673790514469147\n",
      "[Step 1880] Loss: 1.04e+08 -0.5849476456642151 0.06704402714967728\n",
      "[Step 1881] Loss: 1.04e+08 -0.5838073492050171 0.06737986207008362\n",
      "[Step 1882] Loss: 1.05e+08 -0.5826452970504761 0.06772146373987198\n",
      "[Step 1883] Loss: 1.05e+08 -0.5814189910888672 0.06806307286024094\n",
      "[Step 1884] Loss: 1.06e+08 -0.5803776383399963 0.0683559998869896\n",
      "[Step 1885] Loss: 1.05e+08 -0.5792409777641296 0.06868687272071838\n",
      "[Step 1886] Loss: 1.05e+08 -0.5781239867210388 0.06903673708438873\n",
      "[Step 1887] Loss: 1.04e+08 -0.5769500732421875 0.0693700909614563\n",
      "[Step 1888] Loss: 1.04e+08 -0.5757486820220947 0.06972324848175049\n",
      "[Step 1889] Loss: 1.03e+08 -0.5745728015899658 0.07004257291555405\n",
      "[Step 1890] Loss: 1.05e+08 -0.5733032822608948 0.0704328641295433\n",
      "[Step 1891] Loss: 1.04e+08 -0.5720551013946533 0.0708446130156517\n",
      "[Step 1892] Loss: 1.04e+08 -0.5707900524139404 0.07119528949260712\n",
      "[Step 1893] Loss: 1.03e+08 -0.5695079565048218 0.07157237827777863\n",
      "[Step 1894] Loss: 1.03e+08 -0.5682456493377686 0.07195936888456345\n",
      "[Step 1895] Loss: 1.04e+08 -0.5670051574707031 0.0723092257976532\n",
      "[Step 1896] Loss: 1.04e+08 -0.5657053589820862 0.0726681649684906\n",
      "[Step 1897] Loss: 1.05e+08 -0.5644662380218506 0.07301884889602661\n",
      "[Step 1898] Loss: 1.04e+08 -0.5632997751235962 0.07338768243789673\n",
      "[Step 1899] Loss: 1.05e+08 -0.5621412396430969 0.07371773570775986\n",
      "[Step 1900] Loss: 1.04e+08 -0.5609981417655945 0.07405934482812881\n",
      "[Step 1901] Loss: 1.04e+08 -0.5598730444908142 0.07437949627637863\n",
      "[Step 1902] Loss: 1.04e+08 -0.5587741136550903 0.07468067109584808\n",
      "[Step 1903] Loss: 1.05e+08 -0.5576193928718567 0.07506270706653595\n",
      "[Step 1904] Loss: 1.04e+08 -0.5564632415771484 0.07538451254367828\n",
      "[Step 1905] Loss: 1.05e+08 -0.5554133653640747 0.07570384442806244\n",
      "[Step 1906] Loss: 1.04e+08 -0.5543481707572937 0.07602894306182861\n",
      "[Step 1907] Loss: 1.04e+08 -0.5532757639884949 0.07637467980384827\n",
      "[Step 1908] Loss: 1.04e+08 -0.5522375106811523 0.07672206312417984\n",
      "[Step 1909] Loss: 1.04e+08 -0.551146924495697 0.0770554170012474\n",
      "[Step 1910] Loss: 1.04e+08 -0.5501353144645691 0.07739784568548203\n",
      "[Step 1911] Loss: 1.03e+08 -0.5490810871124268 0.07775595784187317\n",
      "[Step 1912] Loss: 1.04e+08 -0.5479361414909363 0.07814954966306686\n",
      "[Step 1913] Loss: 1.04e+08 -0.5468713641166687 0.0784754753112793\n",
      "[Step 1914] Loss: 1.04e+08 -0.5458351969718933 0.07880718261003494\n",
      "[Step 1915] Loss: 1.04e+08 -0.5448501110076904 0.0791751891374588\n",
      "[Step 1916] Loss: 1.04e+08 -0.5438835620880127 0.07951845228672028\n",
      "[Step 1917] Loss: 1.04e+08 -0.5428515076637268 0.07985097914934158\n",
      "[Step 1918] Loss: 1.04e+08 -0.5418489575386047 0.08021733909845352\n",
      "[Step 1919] Loss: 1.05e+08 -0.5408320426940918 0.08060680329799652\n",
      "[Step 1920] Loss: 1.04e+08 -0.5398175716400146 0.08097976446151733\n",
      "[Step 1921] Loss: 1.05e+08 -0.5387236475944519 0.08138985931873322\n",
      "[Step 1922] Loss: 1.04e+08 -0.5376771688461304 0.08172239363193512\n",
      "[Step 1923] Loss: 1.04e+08 -0.5365805625915527 0.08206729590892792\n",
      "[Step 1924] Loss: 1.05e+08 -0.5354408621788025 0.0824914202094078\n",
      "[Step 1925] Loss: 1.04e+08 -0.5343272686004639 0.08290976285934448\n",
      "[Step 1926] Loss: 1.04e+08 -0.5331751704216003 0.08333306014537811\n",
      "[Step 1927] Loss: 1.04e+08 -0.532006561756134 0.0837571769952774\n",
      "[Step 1928] Loss: 1.04e+08 -0.5308584570884705 0.0841326117515564\n",
      "[Step 1929] Loss: 1.05e+08 -0.5297055840492249 0.08453940600156784\n",
      "[Step 1930] Loss: 1.04e+08 -0.5285044312477112 0.0849783793091774\n",
      "[Step 1931] Loss: 1.04e+08 -0.5272989273071289 0.08538104593753815\n",
      "[Step 1932] Loss: 1.05e+08 -0.5260526537895203 0.0857977420091629\n",
      "[Step 1933] Loss: 1.04e+08 -0.5248703360557556 0.08622351288795471\n",
      "[Step 1934] Loss: 1.05e+08 -0.5236853957176208 0.08665505796670914\n",
      "[Step 1935] Loss: 1.04e+08 -0.5224818587303162 0.08710228651762009\n",
      "[Step 1936] Loss: 1.04e+08 -0.5213369131088257 0.08751650154590607\n",
      "[Step 1937] Loss: 1.05e+08 -0.5202738046646118 0.08790596574544907\n",
      "[Step 1938] Loss: 1.04e+08 -0.519170880317688 0.08832596242427826\n",
      "[Step 1939] Loss: 1.05e+08 -0.5179890990257263 0.08871790021657944\n",
      "[Step 1940] Loss: 1.04e+08 -0.5167691707611084 0.0891486257314682\n",
      "[Step 1941] Loss: 1.03e+08 -0.5154995918273926 0.08959007263183594\n",
      "[Step 1942] Loss: 1.04e+08 -0.5141478180885315 0.09009670466184616\n",
      "[Step 1943] Loss: 1.03e+08 -0.5128369927406311 0.09055795520544052\n",
      "[Step 1944] Loss: 1.04e+08 -0.5114839673042297 0.09105551242828369\n",
      "[Step 1945] Loss: 1.04e+08 -0.5101187229156494 0.09153574705123901\n",
      "[Step 1946] Loss: 1.05e+08 -0.508703351020813 0.09201762080192566\n",
      "[Step 1947] Loss: 1.04e+08 -0.5072908997535706 0.0924953818321228\n",
      "[Step 1948] Loss: 1.04e+08 -0.5058092474937439 0.09302841871976852\n",
      "[Step 1949] Loss: 1.04e+08 -0.5042924880981445 0.09356888383626938\n",
      "[Step 1950] Loss: 1.04e+08 -0.5028724074363708 0.09404003620147705\n",
      "[Step 1951] Loss: 1.03e+08 -0.5014969706535339 0.09454749524593353\n",
      "[Step 1952] Loss: 1.03e+08 -0.5001086592674255 0.09503515064716339\n",
      "[Step 1953] Loss: 1.05e+08 -0.4987114369869232 0.09562677145004272\n",
      "[Step 1954] Loss: 1.04e+08 -0.4973660409450531 0.09613011032342911\n",
      "[Step 1955] Loss: 1.03e+08 -0.4960213899612427 0.09665736556053162\n",
      "[Step 1956] Loss: 1.04e+08 -0.4946976602077484 0.0971689522266388\n",
      "[Step 1957] Loss: 1.05e+08 -0.493570476770401 0.09759637713432312\n",
      "[Step 1958] Loss: 1.04e+08 -0.4924277067184448 0.09805762767791748\n",
      "[Step 1959] Loss: 1.04e+08 -0.4913155734539032 0.09848009794950485\n",
      "[Step 1960] Loss: 1.04e+08 -0.49026408791542053 0.09888936579227448\n",
      "[Step 1961] Loss: 1.04e+08 -0.4892338216304779 0.0992681011557579\n",
      "[Step 1962] Loss: 1.05e+08 -0.4882236421108246 0.09968644380569458\n",
      "[Step 1963] Loss: 1.05e+08 -0.4871518313884735 0.10009819269180298\n",
      "[Step 1964] Loss: 1.03e+08 -0.48605650663375854 0.1005421131849289\n",
      "[Step 1965] Loss: 1.04e+08 -0.48497274518013 0.10096623748540878\n",
      "[Step 1966] Loss: 1.05e+08 -0.48380574584007263 0.10142583400011063\n",
      "[Step 1967] Loss: 1.04e+08 -0.48258084058761597 0.10188543796539307\n",
      "[Step 1968] Loss: 1.03e+08 -0.48138150572776794 0.10235493630170822\n",
      "[Step 1969] Loss: 1.04e+08 -0.48018887639045715 0.10282774269580841\n",
      "[Step 1970] Loss: 1.04e+08 -0.4790221154689789 0.10329229384660721\n",
      "[Step 1971] Loss: 1.04e+08 -0.4779384136199951 0.10375024378299713\n",
      "[Step 1972] Loss: 1.04e+08 -0.4769030213356018 0.10415126383304596\n",
      "[Step 1973] Loss: 1.03e+08 -0.47587206959724426 0.1045580580830574\n",
      "[Step 1974] Loss: 1.04e+08 -0.4747845232486725 0.10498794913291931\n",
      "[Step 1975] Loss: 1.05e+08 -0.4737098813056946 0.10546158254146576\n",
      "[Step 1976] Loss: 1.04e+08 -0.47259074449539185 0.10590963065624237\n",
      "[Step 1977] Loss: 1.04e+08 -0.47145676612854004 0.10634943097829819\n",
      "[Step 1978] Loss: 1.03e+08 -0.4703159034252167 0.1068016067147255\n",
      "[Step 1979] Loss: 1.03e+08 -0.46914178133010864 0.10724057257175446\n",
      "[Step 1980] Loss: 1.04e+08 -0.46806761622428894 0.1076737716794014\n",
      "[Step 1981] Loss: 1.04e+08 -0.46699297428131104 0.10812264680862427\n",
      "[Step 1982] Loss: 1.03e+08 -0.46591225266456604 0.10857895016670227\n",
      "[Step 1983] Loss: 1.05e+08 -0.46498361229896545 0.10897088795900345\n",
      "[Step 1984] Loss: 1.03e+08 -0.46412140130996704 0.10933724790811539\n",
      "[Step 1985] Loss: 1.04e+08 -0.46323612332344055 0.10972258448600769\n",
      "[Step 1986] Loss: 1.04e+08 -0.46228721737861633 0.11009802669286728\n",
      "[Step 1987] Loss: 1.04e+08 -0.4612482488155365 0.11053700000047684\n",
      "[Step 1988] Loss: 1.05e+08 -0.46032339334487915 0.11098174750804901\n",
      "[Step 1989] Loss: 1.04e+08 -0.45935311913490295 0.11139844357967377\n",
      "[Step 1990] Loss: 1.04e+08 -0.45845702290534973 0.11179285496473312\n",
      "[Step 1991] Loss: 1.05e+08 -0.4576370418071747 0.11217241734266281\n",
      "[Step 1992] Loss: 1.04e+08 -0.4568309485912323 0.11253465712070465\n",
      "[Step 1993] Loss: 1.04e+08 -0.45602360367774963 0.11288534104824066\n",
      "[Step 1994] Loss: 1.03e+08 -0.4551779329776764 0.11331028491258621\n",
      "[Step 1995] Loss: 1.05e+08 -0.45431840419769287 0.11370222270488739\n",
      "[Step 1996] Loss: 1.04e+08 -0.4534468948841095 0.11411561816930771\n",
      "[Step 1997] Loss: 1.04e+08 -0.4525211453437805 0.11460327357053757\n",
      "[Step 1998] Loss: 1.05e+08 -0.4515930116176605 0.11503729224205017\n",
      "[Step 1999] Loss: 1.05e+08 -0.45061367750167847 0.11546801775693893\n",
      "[Step 2000] Loss: 1.06e+08 -0.4497922658920288 0.11585582792758942\n",
      "[Step 2001] Loss: 1.03e+08 -0.4489259719848633 0.1162436455488205\n",
      "[Step 2002] Loss: 1.04e+08 -0.4480597972869873 0.11666611582040787\n",
      "[Step 2003] Loss: 1.03e+08 -0.4471636414527893 0.117063008248806\n",
      "[Step 2004] Loss: 1.04e+08 -0.44633612036705017 0.11749455332756042\n",
      "[Step 2005] Loss: 1.05e+08 -0.4455602467060089 0.11789804697036743\n",
      "[Step 2006] Loss: 1.03e+08 -0.4447929263114929 0.11833453923463821\n",
      "[Step 2007] Loss: 1.04e+08 -0.4440533220767975 0.11870420724153519\n",
      "[Step 2008] Loss: 1.03e+08 -0.4432655870914459 0.11912832409143448\n",
      "[Step 2009] Loss: 1.04e+08 -0.44251444935798645 0.11949468404054642\n",
      "[Step 2010] Loss: 1.03e+08 -0.44174954295158386 0.1198866218328476\n",
      "[Step 2011] Loss: 1.04e+08 -0.4410431385040283 0.12023070454597473\n",
      "[Step 2012] Loss: 1.05e+08 -0.44028106331825256 0.12062842398881912\n",
      "[Step 2013] Loss: 1.04e+08 -0.43948110938072205 0.12105336785316467\n",
      "[Step 2014] Loss: 1.04e+08 -0.43873780965805054 0.1214585080742836\n",
      "[Step 2015] Loss: 1.04e+08 -0.43804576992988586 0.12181909382343292\n",
      "[Step 2016] Loss: 1.03e+08 -0.4373164176940918 0.122140072286129\n",
      "[Step 2017] Loss: 1.04e+08 -0.43655017018318176 0.12257739901542664\n",
      "[Step 2018] Loss: 1.05e+08 -0.4357690215110779 0.12297676503658295\n",
      "[Step 2019] Loss: 1.05e+08 -0.4350299537181854 0.12339840829372406\n",
      "[Step 2020] Loss: 1.03e+08 -0.434264212846756 0.12379364669322968\n",
      "[Step 2021] Loss: 1.04e+08 -0.4335658550262451 0.12415505945682526\n",
      "[Step 2022] Loss: 1.04e+08 -0.4328230619430542 0.12454947084188461\n",
      "[Step 2023] Loss: 1.04e+08 -0.43198928236961365 0.12491418421268463\n",
      "[Step 2024] Loss: 1.03e+08 -0.43117815256118774 0.12530282139778137\n",
      "[Step 2025] Loss: 1.04e+08 -0.4303331971168518 0.1257343739271164\n",
      "[Step 2026] Loss: 1.04e+08 -0.42944541573524475 0.1261560171842575\n",
      "[Step 2027] Loss: 1.04e+08 -0.42847028374671936 0.12666016817092896\n",
      "[Step 2028] Loss: 1.04e+08 -0.4275698959827423 0.12713050842285156\n",
      "[Step 2029] Loss: 1.04e+08 -0.42662087082862854 0.12759999930858612\n",
      "[Step 2030] Loss: 1.04e+08 -0.42568305134773254 0.128062903881073\n",
      "[Step 2031] Loss: 1.04e+08 -0.42470675706863403 0.1285398304462433\n",
      "[Step 2032] Loss: 1.03e+08 -0.42377904057502747 0.12904152274131775\n",
      "[Step 2033] Loss: 1.04e+08 -0.422748863697052 0.12954814732074738\n",
      "[Step 2034] Loss: 1.04e+08 -0.42171934247016907 0.13006551563739777\n",
      "[Step 2035] Loss: 1.05e+08 -0.4207591712474823 0.1305292397737503\n",
      "[Step 2036] Loss: 1.04e+08 -0.41979002952575684 0.13100287318229675\n",
      "[Step 2037] Loss: 1.04e+08 -0.4188711941242218 0.13146989047527313\n",
      "[Step 2038] Loss: 1.04e+08 -0.4178548753261566 0.1319451779127121\n",
      "[Step 2039] Loss: 1.04e+08 -0.4168306589126587 0.13244932889938354\n",
      "[Step 2040] Loss: 1.04e+08 -0.415667861700058 0.13307231664657593\n",
      "[Step 2041] Loss: 1.03e+08 -0.41453418135643005 0.13366806507110596\n",
      "[Step 2042] Loss: 1.05e+08 -0.41349083185195923 0.13422173261642456\n",
      "[Step 2043] Loss: 1.03e+08 -0.41243863105773926 0.13478776812553406\n",
      "[Step 2044] Loss: 1.05e+08 -0.4115235507488251 0.13532575964927673\n",
      "[Step 2045] Loss: 1.03e+08 -0.41060110926628113 0.13584394752979279\n",
      "[Step 2046] Loss: 1.04e+08 -0.409608393907547 0.13636378943920135\n",
      "[Step 2047] Loss: 1.03e+08 -0.40855664014816284 0.13692322373390198\n",
      "[Step 2048] Loss: 1.03e+08 -0.4075346887111664 0.13747112452983856\n",
      "[Step 2049] Loss: 1.04e+08 -0.4064399003982544 0.13801653683185577\n",
      "[Step 2050] Loss: 1.05e+08 -0.405201256275177 0.13864529132843018\n",
      "[Step 2051] Loss: 1.05e+08 -0.4041123390197754 0.13921216130256653\n",
      "[Step 2052] Loss: 1.05e+08 -0.40314850211143494 0.13971631228923798\n",
      "[Step 2053] Loss: 1.04e+08 -0.4021279811859131 0.1402312070131302\n",
      "[Step 2054] Loss: 1.03e+08 -0.40117526054382324 0.14075681567192078\n",
      "[Step 2055] Loss: 1.03e+08 -0.40027573704719543 0.14120899140834808\n",
      "[Step 2056] Loss: 1.04e+08 -0.39931362867355347 0.14169912040233612\n",
      "[Step 2057] Loss: 1.05e+08 -0.39831629395484924 0.14218924939632416\n",
      "[Step 2058] Loss: 1.04e+08 -0.3973200023174286 0.14276190102100372\n",
      "[Step 2059] Loss: 1.03e+08 -0.3963005542755127 0.14328669011592865\n",
      "[Step 2060] Loss: 1.03e+08 -0.3953639268875122 0.14373555779457092\n",
      "[Step 2061] Loss: 1.04e+08 -0.3943344056606293 0.1442834436893463\n",
      "[Step 2062] Loss: 1.03e+08 -0.3932173252105713 0.14490064978599548\n",
      "[Step 2063] Loss: 1.03e+08 -0.3921380043029785 0.14549392461776733\n",
      "[Step 2064] Loss: 1.04e+08 -0.3911486566066742 0.14603851735591888\n",
      "[Step 2065] Loss: 1.03e+08 -0.3901653289794922 0.14668460190296173\n",
      "[Step 2066] Loss: 1.05e+08 -0.38932159543037415 0.14713430404663086\n",
      "[Step 2067] Loss: 1.03e+08 -0.3884548246860504 0.14768631756305695\n",
      "[Step 2068] Loss: 1.03e+08 -0.38760900497436523 0.1481723189353943\n",
      "[Step 2069] Loss: 1.04e+08 -0.386696457862854 0.1486971080303192\n",
      "[Step 2070] Loss: 1.04e+08 -0.3858602046966553 0.14916661381721497\n",
      "[Step 2071] Loss: 1.04e+08 -0.38494232296943665 0.1496707648038864\n",
      "[Step 2072] Loss: 1.03e+08 -0.38398465514183044 0.15023598074913025\n",
      "[Step 2073] Loss: 1.04e+08 -0.38308173418045044 0.15076573193073273\n",
      "[Step 2074] Loss: 1.04e+08 -0.3821618854999542 0.15128473937511444\n",
      "[Step 2075] Loss: 1.03e+08 -0.3811781704425812 0.15188130736351013\n",
      "[Step 2076] Loss: 1.04e+08 -0.3801274299621582 0.1524886190891266\n",
      "[Step 2077] Loss: 1.03e+08 -0.3790906071662903 0.1530563086271286\n",
      "[Step 2078] Loss: 1.04e+08 -0.3781568109989166 0.1535835713148117\n",
      "[Step 2079] Loss: 1.03e+08 -0.3773318827152252 0.15409763157367706\n",
      "[Step 2080] Loss: 1.05e+08 -0.3766736388206482 0.1545432060956955\n",
      "[Step 2081] Loss: 1.04e+08 -0.3760238289833069 0.1549673229455948\n",
      "[Step 2082] Loss: 1.03e+08 -0.37531229853630066 0.1554698348045349\n",
      "[Step 2083] Loss: 1.03e+08 -0.3745693862438202 0.15595418214797974\n",
      "[Step 2084] Loss: 1.04e+08 -0.3739384114742279 0.15640471875667572\n",
      "[Step 2085] Loss: 1.05e+08 -0.37329450249671936 0.1568313091993332\n",
      "[Step 2086] Loss: 1.04e+08 -0.3725813627243042 0.15728925168514252\n",
      "[Step 2087] Loss: 1.02e+08 -0.37187355756759644 0.1577439159154892\n",
      "[Step 2088] Loss: 1.04e+08 -0.3711797595024109 0.158147394657135\n",
      "[Step 2089] Loss: 1.06e+08 -0.37077704071998596 0.1584337204694748\n",
      "[Step 2090] Loss: 1.04e+08 -0.3702148199081421 0.1587943136692047\n",
      "[Step 2091] Loss: 1.03e+08 -0.36960458755493164 0.1591738760471344\n",
      "[Step 2092] Loss: 1.03e+08 -0.3689238727092743 0.1595814824104309\n",
      "[Step 2093] Loss: 1.04e+08 -0.36817923188209534 0.15999817848205566\n",
      "[Step 2094] Loss: 1.03e+08 -0.36730194091796875 0.16050563752651215\n",
      "[Step 2095] Loss: 1.03e+08 -0.36641427874565125 0.16099989414215088\n",
      "[Step 2096] Loss: 1.05e+08 -0.36567601561546326 0.1614372283220291\n",
      "[Step 2097] Loss: 1.03e+08 -0.3648945987224579 0.16196531057357788\n",
      "[Step 2098] Loss: 1.04e+08 -0.36426907777786255 0.1623663306236267\n",
      "[Step 2099] Loss: 1.02e+08 -0.36357831954956055 0.16279539465904236\n",
      "[Step 2100] Loss: 1.04e+08 -0.3629170060157776 0.16320136189460754\n",
      "[Step 2101] Loss: 1.02e+08 -0.3622685968875885 0.1636279672384262\n",
      "[Step 2102] Loss: 1.05e+08 -0.36173751950263977 0.16400669515132904\n",
      "[Step 2103] Loss: 1.04e+08 -0.361105352640152 0.16439782083034515\n",
      "[Step 2104] Loss: 1.03e+08 -0.36040592193603516 0.16483183205127716\n",
      "[Step 2105] Loss: 1.04e+08 -0.35961899161338806 0.16524358093738556\n",
      "[Step 2106] Loss: 1.04e+08 -0.35879048705101013 0.16571803390979767\n",
      "[Step 2107] Loss: 1.04e+08 -0.3579291105270386 0.16624858975410461\n",
      "[Step 2108] Loss: 1.03e+08 -0.3570155203342438 0.16683197021484375\n",
      "[Step 2109] Loss: 1.04e+08 -0.3560650050640106 0.16747640073299408\n",
      "[Step 2110] Loss: 1.03e+08 -0.35504668951034546 0.16807132959365845\n",
      "[Step 2111] Loss: 1.04e+08 -0.3540130853652954 0.16870668530464172\n",
      "[Step 2112] Loss: 1.03e+08 -0.35291722416877747 0.16936348378658295\n",
      "[Step 2113] Loss: 1.04e+08 -0.35188111662864685 0.16998563706874847\n",
      "[Step 2114] Loss: 1.04e+08 -0.3507337272167206 0.17067132890224457\n",
      "[Step 2115] Loss: 1.03e+08 -0.3496555984020233 0.1713438183069229\n",
      "[Step 2116] Loss: 1.04e+08 -0.3485691547393799 0.17203114926815033\n",
      "[Step 2117] Loss: 1.04e+08 -0.3474447429180145 0.17272427678108215\n",
      "[Step 2118] Loss: 1.04e+08 -0.3463100790977478 0.17342562973499298\n",
      "[Step 2119] Loss: 1.03e+08 -0.34516656398773193 0.1741633117198944\n",
      "[Step 2120] Loss: 1.04e+08 -0.3440163731575012 0.17483001947402954\n",
      "[Step 2121] Loss: 1.04e+08 -0.34294790029525757 0.17546702921390533\n",
      "[Step 2122] Loss: 1.04e+08 -0.3419366180896759 0.17616096138954163\n",
      "[Step 2123] Loss: 1.04e+08 -0.34084823727607727 0.17690524458885193\n",
      "[Step 2124] Loss: 1.02e+08 -0.3397775888442993 0.1775364726781845\n",
      "[Step 2125] Loss: 1.03e+08 -0.3387424051761627 0.1781635731458664\n",
      "[Step 2126] Loss: 1.03e+08 -0.3376748263835907 0.17885339260101318\n",
      "[Step 2127] Loss: 1.04e+08 -0.33662062883377075 0.17951597273349762\n",
      "[Step 2128] Loss: 1.03e+08 -0.3355754613876343 0.18015214800834656\n",
      "[Step 2129] Loss: 1.04e+08 -0.33448129892349243 0.18084362149238586\n",
      "[Step 2130] Loss: 1.04e+08 -0.33346641063690186 0.18148474395275116\n",
      "[Step 2131] Loss: 1.04e+08 -0.3325410485267639 0.182130828499794\n",
      "[Step 2132] Loss: 1.03e+08 -0.3315806984901428 0.1827554553747177\n",
      "[Step 2133] Loss: 1.04e+08 -0.33068132400512695 0.18333305418491364\n",
      "[Step 2134] Loss: 1.04e+08 -0.3296365439891815 0.18399812281131744\n",
      "[Step 2135] Loss: 1.03e+08 -0.32864660024642944 0.1845831423997879\n",
      "[Step 2136] Loss: 1.04e+08 -0.32765936851501465 0.18530018627643585\n",
      "[Step 2137] Loss: 1.04e+08 -0.3267906904220581 0.18588602542877197\n",
      "[Step 2138] Loss: 1.03e+08 -0.3259517550468445 0.1864735335111618\n",
      "[Step 2139] Loss: 1.02e+08 -0.3251200020313263 0.18700656294822693\n",
      "[Step 2140] Loss: 1.03e+08 -0.3242572247982025 0.18758828938007355\n",
      "[Step 2141] Loss: 1.04e+08 -0.3234403729438782 0.18818238377571106\n",
      "[Step 2142] Loss: 1.03e+08 -0.3226759433746338 0.18874017894268036\n",
      "[Step 2143] Loss: 1.03e+08 -0.32186993956565857 0.18930044770240784\n",
      "[Step 2144] Loss: 1.03e+08 -0.32103046774864197 0.18986153602600098\n",
      "[Step 2145] Loss: 1.03e+08 -0.32015106081962585 0.1904754489660263\n",
      "[Step 2146] Loss: 1.03e+08 -0.31923946738243103 0.19107696413993835\n",
      "[Step 2147] Loss: 1.04e+08 -0.3183952271938324 0.19172883033752441\n",
      "[Step 2148] Loss: 1.04e+08 -0.3175245523452759 0.19235427677631378\n",
      "[Step 2149] Loss: 1.03e+08 -0.3166525363922119 0.19294095039367676\n",
      "[Step 2150] Loss: 1.04e+08 -0.31575068831443787 0.19357465207576752\n",
      "[Step 2151] Loss: 1.03e+08 -0.31489503383636475 0.19416050612926483\n",
      "[Step 2152] Loss: 1.03e+08 -0.3141239583492279 0.19468942284584045\n",
      "[Step 2153] Loss: 1.04e+08 -0.3133442997932434 0.19532889127731323\n",
      "[Step 2154] Loss: 1.04e+08 -0.3126235604286194 0.19581325352191925\n",
      "[Step 2155] Loss: 1.03e+08 -0.3119274973869324 0.19636857509613037\n",
      "[Step 2156] Loss: 1.05e+08 -0.3113233149051666 0.19684219360351562\n",
      "[Step 2157] Loss: 1.03e+08 -0.3107524812221527 0.19721515476703644\n",
      "[Step 2158] Loss: 1.03e+08 -0.31006795167922974 0.19774654507637024\n",
      "[Step 2159] Loss: 1.04e+08 -0.30938252806663513 0.19822347164154053\n",
      "[Step 2160] Loss: 1.03e+08 -0.3085736930370331 0.19877466559410095\n",
      "[Step 2161] Loss: 1.03e+08 -0.30768269300460815 0.19937124848365784\n",
      "[Step 2162] Loss: 1.03e+08 -0.3067408800125122 0.20006023347377777\n",
      "[Step 2163] Loss: 1.03e+08 -0.3058584928512573 0.2006254494190216\n",
      "[Step 2164] Loss: 1.03e+08 -0.3048606216907501 0.20130041241645813\n",
      "[Step 2165] Loss: 1.02e+08 -0.3038999140262604 0.20195062458515167\n",
      "[Step 2166] Loss: 1.03e+08 -0.3029004633426666 0.2026115506887436\n",
      "[Step 2167] Loss: 1.02e+08 -0.30193349719047546 0.203240305185318\n",
      "[Step 2168] Loss: 1.05e+08 -0.30115896463394165 0.20378737151622772\n",
      "[Step 2169] Loss: 1.03e+08 -0.3004292845726013 0.2042824625968933\n",
      "[Step 2170] Loss: 1.03e+08 -0.2997046113014221 0.20477424561977386\n",
      "[Step 2171] Loss: 1.05e+08 -0.29896679520606995 0.20532047748565674\n",
      "[Step 2172] Loss: 1.03e+08 -0.2980828285217285 0.20590798556804657\n",
      "[Step 2173] Loss: 1.03e+08 -0.29710498452186584 0.20658789575099945\n",
      "[Step 2174] Loss: 1.04e+08 -0.2961004674434662 0.20724718272686005\n",
      "[Step 2175] Loss: 1.02e+08 -0.29505226016044617 0.20796504616737366\n",
      "[Step 2176] Loss: 1.03e+08 -0.2939567565917969 0.20867961645126343\n",
      "[Step 2177] Loss: 1.03e+08 -0.2928183078765869 0.2094915509223938\n",
      "[Step 2178] Loss: 1.03e+08 -0.2916991710662842 0.2102580964565277\n",
      "[Step 2179] Loss: 1.02e+08 -0.2905097007751465 0.211055189371109\n",
      "[Step 2180] Loss: 1.04e+08 -0.2893424332141876 0.21188361942768097\n",
      "[Step 2181] Loss: 1.03e+08 -0.28823208808898926 0.21261633932590485\n",
      "[Step 2182] Loss: 1.03e+08 -0.2872668504714966 0.21332430839538574\n",
      "[Step 2183] Loss: 1.03e+08 -0.28638145327568054 0.21396708488464355\n",
      "[Step 2184] Loss: 1.03e+08 -0.28539150953292847 0.21459420025348663\n",
      "[Step 2185] Loss: 1.02e+08 -0.2843484878540039 0.21533268690109253\n",
      "[Step 2186] Loss: 1.04e+08 -0.28333210945129395 0.21599692106246948\n",
      "[Step 2187] Loss: 1.03e+08 -0.282349556684494 0.21668344736099243\n",
      "[Step 2188] Loss: 1.02e+08 -0.2814420461654663 0.21730229258537292\n",
      "[Step 2189] Loss: 1.02e+08 -0.28048092126846313 0.21798385679721832\n",
      "[Step 2190] Loss: 1.03e+08 -0.27943360805511475 0.2187025547027588\n",
      "[Step 2191] Loss: 1.04e+08 -0.27843737602233887 0.21937504410743713\n",
      "[Step 2192] Loss: 1.03e+08 -0.2773885130882263 0.2200632095336914\n",
      "[Step 2193] Loss: 1.03e+08 -0.2763579189777374 0.22075548768043518\n",
      "[Step 2194] Loss: 1.03e+08 -0.27528834342956543 0.22143210470676422\n",
      "[Step 2195] Loss: 1.03e+08 -0.2743191421031952 0.22205425798892975\n",
      "[Step 2196] Loss: 1.03e+08 -0.273391455411911 0.22269952297210693\n",
      "[Step 2197] Loss: 1.02e+08 -0.27244701981544495 0.2233348786830902\n",
      "[Step 2198] Loss: 1.03e+08 -0.2715442478656769 0.22391577064990997\n",
      "[Step 2199] Loss: 1.03e+08 -0.27060484886169434 0.2246006280183792\n",
      "[Step 2200] Loss: 1.04e+08 -0.2695726454257965 0.22533582150936127\n",
      "[Step 2201] Loss: 1.03e+08 -0.2684567868709564 0.22608423233032227\n",
      "[Step 2202] Loss: 1.03e+08 -0.26739394664764404 0.22683675587177277\n",
      "[Step 2203] Loss: 1.02e+08 -0.2662791907787323 0.22754554450511932\n",
      "[Step 2204] Loss: 1.02e+08 -0.2651429772377014 0.2283087968826294\n",
      "[Step 2205] Loss: 1.03e+08 -0.2641039490699768 0.22907039523124695\n",
      "[Step 2206] Loss: 1.04e+08 -0.26289188861846924 0.22983942925930023\n",
      "[Step 2207] Loss: 1.03e+08 -0.26177889108657837 0.2306026816368103\n",
      "[Step 2208] Loss: 1.03e+08 -0.26075828075408936 0.23132385313510895\n",
      "[Step 2209] Loss: 1.03e+08 -0.259831041097641 0.23201613128185272\n",
      "[Step 2210] Loss: 1.03e+08 -0.25897079706192017 0.23262178897857666\n",
      "[Step 2211] Loss: 1.03e+08 -0.25812414288520813 0.23322495818138123\n",
      "[Step 2212] Loss: 1.03e+08 -0.2573789954185486 0.23381328582763672\n",
      "[Step 2213] Loss: 1.03e+08 -0.2565698027610779 0.2344667911529541\n",
      "[Step 2214] Loss: 1.02e+08 -0.2557660639286041 0.23514340817928314\n",
      "[Step 2215] Loss: 1.04e+08 -0.2549993097782135 0.23578453063964844\n",
      "[Step 2216] Loss: 1.03e+08 -0.2542651295661926 0.2363736927509308\n",
      "[Step 2217] Loss: 1.03e+08 -0.25345075130462646 0.2369941920042038\n",
      "[Step 2218] Loss: 1.03e+08 -0.25257185101509094 0.23769719898700714\n",
      "[Step 2219] Loss: 1.04e+08 -0.251811146736145 0.2383267879486084\n",
      "[Step 2220] Loss: 1.02e+08 -0.2511312961578369 0.23889778554439545\n",
      "[Step 2221] Loss: 1.04e+08 -0.2505280673503876 0.2394060641527176\n",
      "[Step 2222] Loss: 1.04e+08 -0.25012630224227905 0.23974189162254333\n",
      "[Step 2223] Loss: 1.03e+08 -0.24971158802509308 0.2401198148727417\n",
      "[Step 2224] Loss: 1.03e+08 -0.2492528110742569 0.24049606919288635\n",
      "[Step 2225] Loss: 1.03e+08 -0.24876755475997925 0.24091771245002747\n",
      "[Step 2226] Loss: 1.04e+08 -0.24828678369522095 0.241298109292984\n",
      "[Step 2227] Loss: 1.04e+08 -0.24770322442054749 0.2417973130941391\n",
      "[Step 2228] Loss: 1.04e+08 -0.24701738357543945 0.24237820506095886\n",
      "[Step 2229] Loss: 1.03e+08 -0.24640193581581116 0.24288319051265717\n",
      "[Step 2230] Loss: 1.02e+08 -0.24569948017597198 0.24344180524349213\n",
      "[Step 2231] Loss: 1.03e+08 -0.24493572115898132 0.24404746294021606\n",
      "[Step 2232] Loss: 1.03e+08 -0.2442835569381714 0.24455492198467255\n",
      "[Step 2233] Loss: 1.04e+08 -0.2437523752450943 0.2449839860200882\n",
      "[Step 2234] Loss: 1.03e+08 -0.24316665530204773 0.2454666942358017\n",
      "[Step 2235] Loss: 1.02e+08 -0.24261729419231415 0.2459007203578949\n",
      "[Step 2236] Loss: 1.03e+08 -0.2420598566532135 0.2463165819644928\n",
      "[Step 2237] Loss: 1.03e+08 -0.24143004417419434 0.24672751128673553\n",
      "[Step 2238] Loss: 1.03e+08 -0.2407960146665573 0.24720443785190582\n",
      "[Step 2239] Loss: 1.04e+08 -0.240152046084404 0.24772591888904572\n",
      "[Step 2240] Loss: 1.03e+08 -0.23950932919979095 0.24823419749736786\n",
      "[Step 2241] Loss: 1.04e+08 -0.23883940279483795 0.24883325397968292\n",
      "[Step 2242] Loss: 1.07e+08 -0.23850269615650177 0.2490832656621933\n",
      "[Step 2243] Loss: 1.03e+08 -0.23816871643066406 0.2493613362312317\n",
      "[Step 2244] Loss: 1.04e+08 -0.23771452903747559 0.24972769618034363\n",
      "[Step 2245] Loss: 1.03e+08 -0.23721210658550262 0.2501460611820221\n",
      "[Step 2246] Loss: 1.03e+08 -0.23669978976249695 0.2505511939525604\n",
      "[Step 2247] Loss: 1.03e+08 -0.23611052334308624 0.25097283720970154\n",
      "[Step 2248] Loss: 1.03e+08 -0.23543336987495422 0.2515231966972351\n",
      "[Step 2249] Loss: 1.03e+08 -0.2346959263086319 0.25205788016319275\n",
      "[Step 2250] Loss: 1.03e+08 -0.2338189333677292 0.2526759207248688\n",
      "[Step 2251] Loss: 1.03e+08 -0.23295705020427704 0.25330302119255066\n",
      "[Step 2252] Loss: 1.04e+08 -0.23229289054870605 0.2537989318370819\n",
      "[Step 2253] Loss: 1.03e+08 -0.23155370354652405 0.2543971538543701\n",
      "[Step 2254] Loss: 1.03e+08 -0.23081180453300476 0.2549549341201782\n",
      "[Step 2255] Loss: 1.04e+08 -0.23016494512557983 0.25545579195022583\n",
      "[Step 2256] Loss: 1.02e+08 -0.22948983311653137 0.25596490502357483\n",
      "[Step 2257] Loss: 1.03e+08 -0.22884297370910645 0.2564583420753479\n",
      "[Step 2258] Loss: 1.03e+08 -0.22821266949176788 0.25693032145500183\n",
      "[Step 2259] Loss: 1.05e+08 -0.22772151231765747 0.25739073753356934\n",
      "[Step 2260] Loss: 1.03e+08 -0.22722800076007843 0.2577868103981018\n",
      "[Step 2261] Loss: 1.03e+08 -0.22662724554538727 0.2582843601703644\n",
      "[Step 2262] Loss: 1.03e+08 -0.2260335087776184 0.2587439715862274\n",
      "[Step 2263] Loss: 1.02e+08 -0.2253163605928421 0.259328156709671\n",
      "[Step 2264] Loss: 1.03e+08 -0.22446227073669434 0.2600056231021881\n",
      "[Step 2265] Loss: 1.03e+08 -0.22342945635318756 0.2607771158218384\n",
      "[Step 2266] Loss: 1.03e+08 -0.2226155549287796 0.26134809851646423\n",
      "[Step 2267] Loss: 1.03e+08 -0.22173085808753967 0.2619941830635071\n",
      "[Step 2268] Loss: 1.03e+08 -0.22082392871379852 0.26271453499794006\n",
      "[Step 2269] Loss: 1.03e+08 -0.22000734508037567 0.2632896602153778\n",
      "[Step 2270] Loss: 1.02e+08 -0.2191871702671051 0.26388704776763916\n",
      "[Step 2271] Loss: 1.02e+08 -0.21834975481033325 0.26452571153640747\n",
      "[Step 2272] Loss: 1.03e+08 -0.2175799012184143 0.2651098966598511\n",
      "[Step 2273] Loss: 1.02e+08 -0.21684934198856354 0.26572132110595703\n",
      "[Step 2274] Loss: 1.04e+08 -0.2161199003458023 0.2663525640964508\n",
      "[Step 2275] Loss: 1.04e+08 -0.21543359756469727 0.2668921947479248\n",
      "[Step 2276] Loss: 1.03e+08 -0.21475820243358612 0.26746320724487305\n",
      "[Step 2277] Loss: 1.03e+08 -0.21417753398418427 0.26789721846580505\n",
      "[Step 2278] Loss: 1.03e+08 -0.21358591318130493 0.2683262825012207\n",
      "[Step 2279] Loss: 1.03e+08 -0.21284693479537964 0.26889893412590027\n",
      "[Step 2280] Loss: 1.03e+08 -0.21221396327018738 0.26940226554870605\n",
      "[Step 2281] Loss: 1.03e+08 -0.21161587536334991 0.26989734172821045\n",
      "[Step 2282] Loss: 1.04e+08 -0.21092677116394043 0.27040067315101624\n",
      "[Step 2283] Loss: 1.03e+08 -0.21027934551239014 0.2709007263183594\n",
      "[Step 2284] Loss: 1.03e+08 -0.20965859293937683 0.27145686745643616\n",
      "[Step 2285] Loss: 1.03e+08 -0.20889276266098022 0.27207159996032715\n",
      "[Step 2286] Loss: 1.04e+08 -0.2080651819705963 0.27268877625465393\n",
      "[Step 2287] Loss: 1.03e+08 -0.20717978477478027 0.2733893394470215\n",
      "[Step 2288] Loss: 1.03e+08 -0.20632363855838776 0.27406758069992065\n",
      "[Step 2289] Loss: 1.02e+08 -0.20537367463111877 0.27482423186302185\n",
      "[Step 2290] Loss: 1.03e+08 -0.20437711477279663 0.27560481429100037\n",
      "[Step 2291] Loss: 1.02e+08 -0.2033945918083191 0.27638375759124756\n",
      "[Step 2292] Loss: 1.03e+08 -0.20239266753196716 0.27716681361198425\n",
      "[Step 2293] Loss: 1.04e+08 -0.20151789486408234 0.2777807116508484\n",
      "[Step 2294] Loss: 1.03e+08 -0.2006499022245407 0.27845484018325806\n",
      "[Step 2295] Loss: 1.03e+08 -0.1998547911643982 0.27903491258621216\n",
      "[Step 2296] Loss: 1.02e+08 -0.1989891678094864 0.2796851396560669\n",
      "[Step 2297] Loss: 1.04e+08 -0.19819773733615875 0.28032296895980835\n",
      "[Step 2298] Loss: 1.03e+08 -0.19732536375522614 0.28102928400039673\n",
      "[Step 2299] Loss: 1.04e+08 -0.1965257078409195 0.28163740038871765\n",
      "[Step 2300] Loss: 1.03e+08 -0.1956348419189453 0.28233298659324646\n",
      "[Step 2301] Loss: 1.02e+08 -0.19469712674617767 0.28310367465019226\n",
      "[Step 2302] Loss: 1.01e+08 -0.19373741745948792 0.2838495969772339\n",
      "[Step 2303] Loss: 1.03e+08 -0.19269341230392456 0.2847333252429962\n",
      "[Step 2304] Loss: 1.03e+08 -0.19169963896274567 0.2855204939842224\n",
      "[Step 2305] Loss: 1.03e+08 -0.1908995360136032 0.2861880362033844\n",
      "[Step 2306] Loss: 1.02e+08 -0.19001878798007965 0.28693974018096924\n",
      "[Step 2307] Loss: 1.03e+08 -0.18912534415721893 0.2876377999782562\n",
      "[Step 2308] Loss: 1.03e+08 -0.18817202746868134 0.2883985638618469\n",
      "[Step 2309] Loss: 1.02e+08 -0.18718001246452332 0.2892063856124878\n",
      "[Step 2310] Loss: 1.02e+08 -0.1861937791109085 0.2900282144546509\n",
      "[Step 2311] Loss: 1.02e+08 -0.18522751331329346 0.29086655378341675\n",
      "[Step 2312] Loss: 1.01e+08 -0.1842934936285019 0.29169169068336487\n",
      "[Step 2313] Loss: 1.02e+08 -0.18334001302719116 0.2924796938896179\n",
      "[Step 2314] Loss: 1.02e+08 -0.18237978219985962 0.2932627499103546\n",
      "[Step 2315] Loss: 1.02e+08 -0.181514710187912 0.2939971387386322\n",
      "[Step 2316] Loss: 1.04e+08 -0.18075896799564362 0.2946299910545349\n",
      "[Step 2317] Loss: 1.03e+08 -0.17996712028980255 0.29533055424690247\n",
      "[Step 2318] Loss: 1.02e+08 -0.17905670404434204 0.29607316851615906\n",
      "[Step 2319] Loss: 1.03e+08 -0.177984356880188 0.29697173833847046\n",
      "[Step 2320] Loss: 1.02e+08 -0.17690129578113556 0.2978901267051697\n",
      "[Step 2321] Loss: 1.02e+08 -0.17573335766792297 0.29893308877944946\n",
      "[Step 2322] Loss: 1.03e+08 -0.17467261850833893 0.29981929063796997\n",
      "[Step 2323] Loss: 1.02e+08 -0.17358563840389252 0.3007335364818573\n",
      "[Step 2324] Loss: 1.02e+08 -0.17251494526863098 0.3016057014465332\n",
      "[Step 2325] Loss: 1.03e+08 -0.17150084674358368 0.302451491355896\n",
      "[Step 2326] Loss: 1.04e+08 -0.17060577869415283 0.3032097816467285\n",
      "[Step 2327] Loss: 1.03e+08 -0.16962161660194397 0.30406710505485535\n",
      "[Step 2328] Loss: 1.03e+08 -0.16867652535438538 0.3048270344734192\n",
      "[Step 2329] Loss: 1.03e+08 -0.16768227517604828 0.3056274354457855\n",
      "[Step 2330] Loss: 1.02e+08 -0.16666512191295624 0.30654004216194153\n",
      "[Step 2331] Loss: 1.03e+08 -0.16560351848602295 0.3074377775192261\n",
      "[Step 2332] Loss: 1.03e+08 -0.16447950899600983 0.3084337115287781\n",
      "[Step 2333] Loss: 1.03e+08 -0.16326245665550232 0.30953940749168396\n",
      "[Step 2334] Loss: 1.03e+08 -0.1619953066110611 0.3105510175228119\n",
      "[Step 2335] Loss: 1.02e+08 -0.1607058346271515 0.3117532432079315\n",
      "[Step 2336] Loss: 1.03e+08 -0.15950536727905273 0.3127095699310303\n",
      "[Step 2337] Loss: 1.01e+08 -0.15823766589164734 0.31380289793014526\n",
      "[Step 2338] Loss: 1.02e+08 -0.15696966648101807 0.314914345741272\n",
      "[Step 2339] Loss: 1.03e+08 -0.15557117760181427 0.3161008954048157\n",
      "[Step 2340] Loss: 1.02e+08 -0.154195174574852 0.3172651529312134\n",
      "[Step 2341] Loss: 1.03e+08 -0.15275943279266357 0.31857961416244507\n",
      "[Step 2342] Loss: 1.03e+08 -0.1513766348361969 0.31973397731781006\n",
      "[Step 2343] Loss: 1.03e+08 -0.1499686986207962 0.32097166776657104\n",
      "[Step 2344] Loss: 1.02e+08 -0.1486346274614334 0.32213181257247925\n",
      "[Step 2345] Loss: 1.03e+08 -0.14722412824630737 0.3233373463153839\n",
      "[Step 2346] Loss: 1.03e+08 -0.14595893025398254 0.3243778347969055\n",
      "[Step 2347] Loss: 1.02e+08 -0.1447368860244751 0.32545217871665955\n",
      "[Step 2348] Loss: 1.02e+08 -0.1435421258211136 0.3265100121498108\n",
      "[Step 2349] Loss: 1.03e+08 -0.14238029718399048 0.3275975286960602\n",
      "[Step 2350] Loss: 1.02e+08 -0.14123786985874176 0.32857367396354675\n",
      "[Step 2351] Loss: 1.03e+08 -0.14017975330352783 0.3295201063156128\n",
      "[Step 2352] Loss: 1.02e+08 -0.13913729786872864 0.3304145336151123\n",
      "[Step 2353] Loss: 1.02e+08 -0.1380978226661682 0.3313147723674774\n",
      "[Step 2354] Loss: 1.02e+08 -0.13706709444522858 0.33228182792663574\n",
      "[Step 2355] Loss: 1.02e+08 -0.13598157465457916 0.33329838514328003\n",
      "[Step 2356] Loss: 1.03e+08 -0.13497057557106018 0.33421266078948975\n",
      "[Step 2357] Loss: 1.03e+08 -0.13390958309173584 0.33519208431243896\n",
      "[Step 2358] Loss: 1.02e+08 -0.1328822523355484 0.3361327350139618\n",
      "[Step 2359] Loss: 1.03e+08 -0.13183748722076416 0.3370428681373596\n",
      "[Step 2360] Loss: 1.03e+08 -0.13081763684749603 0.3379744589328766\n",
      "[Step 2361] Loss: 1.02e+08 -0.12984584271907806 0.338925838470459\n",
      "[Step 2362] Loss: 1.03e+08 -0.12893672287464142 0.33972787857055664\n",
      "[Step 2363] Loss: 1.03e+08 -0.12795661389827728 0.3406132459640503\n",
      "[Step 2364] Loss: 1.02e+08 -0.12699377536773682 0.34153079986572266\n",
      "[Step 2365] Loss: 1.02e+08 -0.12602314352989197 0.34246236085891724\n",
      "[Step 2366] Loss: 1.04e+08 -0.1252198964357376 0.34316208958625793\n",
      "[Step 2367] Loss: 1.01e+08 -0.1244615986943245 0.3438386917114258\n",
      "[Step 2368] Loss: 1.02e+08 -0.12369347363710403 0.34456562995910645\n",
      "[Step 2369] Loss: 1.01e+08 -0.12292307615280151 0.34528103470802307\n",
      "[Step 2370] Loss: 1.03e+08 -0.12208851426839828 0.34606078267097473\n",
      "[Step 2371] Loss: 1.03e+08 -0.12123198807239532 0.3468421995639801\n",
      "[Step 2372] Loss: 1.02e+08 -0.12032797187566757 0.34771767258644104\n",
      "[Step 2373] Loss: 1.02e+08 -0.11954661458730698 0.3484388291835785\n",
      "[Step 2374] Loss: 1.03e+08 -0.11872216314077377 0.3491930067539215\n",
      "[Step 2375] Loss: 1.01e+08 -0.11790766566991806 0.34991830587387085\n",
      "[Step 2376] Loss: 1.02e+08 -0.1170666515827179 0.35068485140800476\n",
      "[Step 2377] Loss: 1.02e+08 -0.11629333347082138 0.35142749547958374\n",
      "[Step 2378] Loss: 1.03e+08 -0.11565320938825607 0.3520446717739105\n",
      "[Step 2379] Loss: 1.03e+08 -0.11512769758701324 0.3525282144546509\n",
      "[Step 2380] Loss: 1.02e+08 -0.11459259688854218 0.3529886305332184\n",
      "[Step 2381] Loss: 1.02e+08 -0.11396657675504684 0.35352909564971924\n",
      "[Step 2382] Loss: 1.02e+08 -0.1132984459400177 0.3541157841682434\n",
      "[Step 2383] Loss: 1.02e+08 -0.1126616969704628 0.35472142696380615\n",
      "[Step 2384] Loss: 1.03e+08 -0.11194451153278351 0.35541868209838867\n",
      "[Step 2385] Loss: 1.02e+08 -0.11120554059743881 0.3561266362667084\n",
      "[Step 2386] Loss: 1.03e+08 -0.11056461185216904 0.3567017614841461\n",
      "[Step 2387] Loss: 1.03e+08 -0.10993906110525131 0.3573024570941925\n",
      "[Step 2388] Loss: 1.02e+08 -0.10929557681083679 0.3578668534755707\n",
      "[Step 2389] Loss: 1.02e+08 -0.1086730882525444 0.3584609627723694\n",
      "[Step 2390] Loss: 1.03e+08 -0.1079559251666069 0.35905835032463074\n",
      "[Step 2391] Loss: 1.02e+08 -0.1072428971529007 0.3596590459346771\n",
      "[Step 2392] Loss: 1.03e+08 -0.10655070096254349 0.36022260785102844\n",
      "[Step 2393] Loss: 1.04e+08 -0.1057640090584755 0.3609776198863983\n",
      "[Step 2394] Loss: 1.03e+08 -0.10495181381702423 0.3617565333843231\n",
      "[Step 2395] Loss: 1.02e+08 -0.10406803339719772 0.36260396242141724\n",
      "[Step 2396] Loss: 1.01e+08 -0.10316120088100433 0.36342498660087585\n",
      "[Step 2397] Loss: 1.03e+08 -0.10230675339698792 0.3642105162143707\n",
      "[Step 2398] Loss: 1.03e+08 -0.10159483551979065 0.3648054301738739\n",
      "[Step 2399] Loss: 1.02e+08 -0.10082553327083588 0.3655381500720978\n",
      "[Step 2400] Loss: 1.03e+08 -0.10008853673934937 0.3662172257900238\n",
      "[Step 2401] Loss: 1.02e+08 -0.09932314604520798 0.3669029176235199\n",
      "[Step 2402] Loss: 1.03e+08 -0.09862887114286423 0.36752673983573914\n",
      "[Step 2403] Loss: 1.01e+08 -0.0979207307100296 0.3681703507900238\n",
      "[Step 2404] Loss: 1.02e+08 -0.09714958816766739 0.368874192237854\n",
      "[Step 2405] Loss: 1.02e+08 -0.09634803235530853 0.3695945143699646\n",
      "[Step 2406] Loss: 1.02e+08 -0.09559013694524765 0.370304137468338\n",
      "[Step 2407] Loss: 1.03e+08 -0.09489987790584564 0.37095022201538086\n",
      "[Step 2408] Loss: 1.03e+08 -0.09425657987594604 0.3716128170490265\n",
      "[Step 2409] Loss: 1.03e+08 -0.09360461682081223 0.37224486470222473\n",
      "[Step 2410] Loss: 1.02e+08 -0.09285897016525269 0.3729660212993622\n",
      "[Step 2411] Loss: 1.01e+08 -0.09206560254096985 0.3737103044986725\n",
      "[Step 2412] Loss: 1.02e+08 -0.09119386970996857 0.3745329678058624\n",
      "[Step 2413] Loss: 1.02e+08 -0.0903310626745224 0.3753086030483246\n",
      "[Step 2414] Loss: 1.04e+08 -0.08935102820396423 0.3762046992778778\n",
      "[Step 2415] Loss: 1.03e+08 -0.08850021660327911 0.37699928879737854\n",
      "[Step 2416] Loss: 1.04e+08 -0.08756168186664581 0.377901166677475\n",
      "[Step 2417] Loss: 1.02e+08 -0.08660130947828293 0.37878820300102234\n",
      "[Step 2418] Loss: 1.04e+08 -0.08560176938772202 0.3797503113746643\n",
      "[Step 2419] Loss: 1.02e+08 -0.0846773087978363 0.38065382838249207\n",
      "[Step 2420] Loss: 1.02e+08 -0.08378278464078903 0.3815086781978607\n",
      "[Step 2421] Loss: 1.01e+08 -0.0828743651509285 0.3823948800563812\n",
      "[Step 2422] Loss: 1.02e+08 -0.08197665214538574 0.38323816657066345\n",
      "[Step 2423] Loss: 1.02e+08 -0.0810391902923584 0.38414084911346436\n",
      "[Step 2424] Loss: 1.03e+08 -0.08005654811859131 0.3850501775741577\n",
      "[Step 2425] Loss: 1.02e+08 -0.07910537719726562 0.38597431778907776\n",
      "[Step 2426] Loss: 1.02e+08 -0.07816184312105179 0.3868192732334137\n",
      "[Step 2427] Loss: 1.02e+08 -0.07727225869894028 0.38770464062690735\n",
      "[Step 2428] Loss: 1.02e+08 -0.07637146860361099 0.3885916471481323\n",
      "[Step 2429] Loss: 1.03e+08 -0.07542972266674042 0.38952404260635376\n",
      "[Step 2430] Loss: 1.02e+08 -0.07447092235088348 0.39042922854423523\n",
      "[Step 2431] Loss: 1.03e+08 -0.07349556684494019 0.3913426697254181\n",
      "[Step 2432] Loss: 1.03e+08 -0.07255835086107254 0.3922800123691559\n",
      "[Step 2433] Loss: 1.02e+08 -0.07153161615133286 0.39327841997146606\n",
      "[Step 2434] Loss: 1.02e+08 -0.0705476775765419 0.39422568678855896\n",
      "[Step 2435] Loss: 1.03e+08 -0.06944524496793747 0.3953074514865875\n",
      "[Step 2436] Loss: 1.03e+08 -0.06830573081970215 0.39643293619155884\n",
      "[Step 2437] Loss: 1.02e+08 -0.06727351248264313 0.397409051656723\n",
      "[Step 2438] Loss: 1.02e+08 -0.06633530557155609 0.3983200192451477\n",
      "[Step 2439] Loss: 1.01e+08 -0.06543897092342377 0.39924830198287964\n",
      "[Step 2440] Loss: 1.03e+08 -0.06460034847259521 0.4000528156757355\n",
      "[Step 2441] Loss: 1.02e+08 -0.06371200829744339 0.400886207818985\n",
      "[Step 2442] Loss: 1.03e+08 -0.06280189007520676 0.4017302989959717\n",
      "[Step 2443] Loss: 1.03e+08 -0.061865851283073425 0.4026511609554291\n",
      "[Step 2444] Loss: 1.02e+08 -0.060917116701602936 0.40351590514183044\n",
      "[Step 2445] Loss: 1.02e+08 -0.05995701253414154 0.40445077419281006\n",
      "[Step 2446] Loss: 1.03e+08 -0.059025947004556656 0.4053650498390198\n",
      "[Step 2447] Loss: 1.02e+08 -0.0581807941198349 0.4062207043170929\n",
      "[Step 2448] Loss: 1.03e+08 -0.05725990980863571 0.40709370374679565\n",
      "[Step 2449] Loss: 1.03e+08 -0.05641590431332588 0.40795597434043884\n",
      "[Step 2450] Loss: 1.02e+08 -0.055691588670015335 0.4086548686027527\n",
      "[Step 2451] Loss: 1.03e+08 -0.0549309067428112 0.4093157947063446\n",
      "[Step 2452] Loss: 1.02e+08 -0.05417908728122711 0.4100542962551117\n",
      "[Step 2453] Loss: 1.04e+08 -0.05345537140965462 0.41079774498939514\n",
      "[Step 2454] Loss: 1.02e+08 -0.05270860344171524 0.4114867150783539\n",
      "[Step 2455] Loss: 1.03e+08 -0.05193838104605675 0.4122392535209656\n",
      "[Step 2456] Loss: 1.03e+08 -0.051072053611278534 0.4130297303199768\n",
      "[Step 2457] Loss: 1.03e+08 -0.05030055716633797 0.4137921631336212\n",
      "[Step 2458] Loss: 1.03e+08 -0.04952812194824219 0.41455787420272827\n",
      "[Step 2459] Loss: 1.01e+08 -0.04876856133341789 0.4152955710887909\n",
      "[Step 2460] Loss: 1.03e+08 -0.04798620194196701 0.4160414934158325\n",
      "[Step 2461] Loss: 1.03e+08 -0.0472872331738472 0.41668757796287537\n",
      "[Step 2462] Loss: 1.02e+08 -0.04662727192044258 0.4172709286212921\n",
      "[Step 2463] Loss: 1.02e+08 -0.045879166573286057 0.4179690182209015\n",
      "[Step 2464] Loss: 1.01e+08 -0.0450938455760479 0.41878753900527954\n",
      "[Step 2465] Loss: 1.02e+08 -0.04442101716995239 0.419447660446167\n",
      "[Step 2466] Loss: 1.02e+08 -0.04370468109846115 0.4201597571372986\n",
      "[Step 2467] Loss: 1.03e+08 -0.043012138456106186 0.4208041727542877\n",
      "[Step 2468] Loss: 1.02e+08 -0.04230279475450516 0.42148324847221375\n",
      "[Step 2469] Loss: 1.02e+08 -0.04154468700289726 0.42213594913482666\n",
      "[Step 2470] Loss: 1.02e+08 -0.040796272456645966 0.4228455722332001\n",
      "[Step 2471] Loss: 1.02e+08 -0.03998532518744469 0.4236178994178772\n",
      "[Step 2472] Loss: 1.03e+08 -0.03922395035624504 0.42436298727989197\n",
      "[Step 2473] Loss: 1.01e+08 -0.03852694109082222 0.42499175667762756\n",
      "[Step 2474] Loss: 1.02e+08 -0.03788117691874504 0.4255346953868866\n",
      "[Step 2475] Loss: 1.03e+08 -0.03711050748825073 0.4262929856777191\n",
      "[Step 2476] Loss: 1.02e+08 -0.03637377545237541 0.42697784304618835\n",
      "[Step 2477] Loss: 1.03e+08 -0.03564298897981644 0.4277056157588959\n",
      "[Step 2478] Loss: 1.01e+08 -0.03481395170092583 0.42843422293663025\n",
      "[Step 2479] Loss: 1.02e+08 -0.03393341973423958 0.429281622171402\n",
      "[Step 2480] Loss: 1.01e+08 -0.03311226889491081 0.43006303906440735\n",
      "[Step 2481] Loss: 1.02e+08 -0.032260991632938385 0.43087661266326904\n",
      "[Step 2482] Loss: 1.02e+08 -0.03149893507361412 0.4316357374191284\n",
      "[Step 2483] Loss: 1.03e+08 -0.03068898804485798 0.43240559101104736\n",
      "[Step 2484] Loss: 1.02e+08 -0.029886340722441673 0.433120995759964\n",
      "[Step 2485] Loss: 1.01e+08 -0.029139218851923943 0.43379512429237366\n",
      "[Step 2486] Loss: 1.03e+08 -0.028284654021263123 0.43459221720695496\n",
      "[Step 2487] Loss: 1.01e+08 -0.027383150532841682 0.43550893664360046\n",
      "[Step 2488] Loss: 1.02e+08 -0.026407944038510323 0.43653953075408936\n",
      "[Step 2489] Loss: 1.03e+08 -0.025396525859832764 0.43753135204315186\n",
      "[Step 2490] Loss: 1.01e+08 -0.024455398321151733 0.4384249746799469\n",
      "[Step 2491] Loss: 1.03e+08 -0.023535240441560745 0.43935737013816833\n",
      "[Step 2492] Loss: 1.03e+08 -0.022680487483739853 0.44016188383102417\n",
      "[Step 2493] Loss: 1.04e+08 -0.022051546722650528 0.4407188594341278\n",
      "[Step 2494] Loss: 1.02e+08 -0.021320484578609467 0.44143837690353394\n",
      "[Step 2495] Loss: 1.03e+08 -0.020699549466371536 0.44207125902175903\n",
      "[Step 2496] Loss: 1.02e+08 -0.020029671490192413 0.44278499484062195\n",
      "[Step 2497] Loss: 1.02e+08 -0.019333072006702423 0.44342944025993347\n",
      "[Step 2498] Loss: 1.02e+08 -0.01865401305258274 0.4440796375274658\n",
      "[Step 2499] Loss: 1.02e+08 -0.017900880426168442 0.44484370946884155\n",
      "[Step 2500] Loss: 1.02e+08 -0.017178257927298546 0.4455648958683014\n",
      "[Step 2501] Loss: 1.02e+08 -0.016536356881260872 0.4461655914783478\n",
      "[Step 2502] Loss: 1.02e+08 -0.015884749591350555 0.44684135913848877\n",
      "[Step 2503] Loss: 1.03e+08 -0.01536562293767929 0.4473356306552887\n",
      "[Step 2504] Loss: 1.02e+08 -0.014731724746525288 0.44795364141464233\n",
      "[Step 2505] Loss: 1.03e+08 -0.014249828644096851 0.4483843743801117\n",
      "[Step 2506] Loss: 1.02e+08 -0.013760451227426529 0.4488126337528229\n",
      "[Step 2507] Loss: 1.02e+08 -0.013261133804917336 0.44934070110321045\n",
      "[Step 2508] Loss: 1.02e+08 -0.012743690982460976 0.44986632466316223\n",
      "[Step 2509] Loss: 1.02e+08 -0.012173132970929146 0.4504653811454773\n",
      "[Step 2510] Loss: 1.03e+08 -0.011463318020105362 0.4511568248271942\n",
      "[Step 2511] Loss: 1.02e+08 -0.010651430115103722 0.45195555686950684\n",
      "[Step 2512] Loss: 1.02e+08 -0.009912675246596336 0.4525686502456665\n",
      "[Step 2513] Loss: 1.01e+08 -0.009193681180477142 0.4533046782016754\n",
      "[Step 2514] Loss: 1.02e+08 -0.008515862748026848 0.4539598226547241\n",
      "[Step 2515] Loss: 1.02e+08 -0.007831531576812267 0.45464304089546204\n",
      "[Step 2516] Loss: 1.02e+08 -0.007150306366384029 0.4553155303001404\n",
      "[Step 2517] Loss: 1.03e+08 -0.006607856135815382 0.4557899832725525\n",
      "[Step 2518] Loss: 1.01e+08 -0.006077618338167667 0.4563494324684143\n",
      "[Step 2519] Loss: 1.02e+08 -0.005551045760512352 0.4568420350551605\n",
      "[Step 2520] Loss: 1.02e+08 -0.004855170380324125 0.45753350853919983\n",
      "[Step 2521] Loss: 1.02e+08 -0.004150856286287308 0.4582216739654541\n",
      "[Step 2522] Loss: 1.02e+08 -0.0034501058980822563 0.4588867127895355\n",
      "[Step 2523] Loss: 1.03e+08 -0.0026637970004230738 0.4596838057041168\n",
      "[Step 2524] Loss: 1.02e+08 -0.0018435594392940402 0.46046024560928345\n",
      "[Step 2525] Loss: 1.02e+08 -0.001096684718504548 0.4611673951148987\n",
      "[Step 2526] Loss: 1.01e+08 -0.00039006094448268414 0.46177881956100464\n",
      "[Step 2527] Loss: 1.02e+08 0.0003713835612870753 0.4625156819820404\n",
      "[Step 2528] Loss: 1.02e+08 0.0011543184518814087 0.4632764458656311\n",
      "[Step 2529] Loss: 1.03e+08 0.0019274861551821232 0.4639926552772522\n",
      "[Step 2530] Loss: 1.02e+08 0.0026625683531165123 0.46471714973449707\n",
      "[Step 2531] Loss: 1.02e+08 0.0034016044810414314 0.46540695428848267\n",
      "[Step 2532] Loss: 1.02e+08 0.004144185688346624 0.4660835564136505\n",
      "[Step 2533] Loss: 1.01e+08 0.004887793213129044 0.4667709171772003\n",
      "[Step 2534] Loss: 1.02e+08 0.005671491846442223 0.46744504570961\n",
      "[Step 2535] Loss: 1.02e+08 0.0064671458676457405 0.4681752920150757\n",
      "[Step 2536] Loss: 1.02e+08 0.007264282554388046 0.46895667910575867\n",
      "[Step 2537] Loss: 1.02e+08 0.008093051612377167 0.46978679299354553\n",
      "[Step 2538] Loss: 1.03e+08 0.008876632899045944 0.47053271532058716\n",
      "[Step 2539] Loss: 1.01e+08 0.009641582146286964 0.47129347920417786\n",
      "[Step 2540] Loss: 1.02e+08 0.010342278517782688 0.47199568152427673\n",
      "[Step 2541] Loss: 1.02e+08 0.011084765195846558 0.4727292060852051\n",
      "[Step 2542] Loss: 1.01e+08 0.011764033697545528 0.4733761250972748\n",
      "[Step 2543] Loss: 1.02e+08 0.012398761697113514 0.47396278381347656\n",
      "[Step 2544] Loss: 1.04e+08 0.012856239452958107 0.4744653105735779\n",
      "[Step 2545] Loss: 1.03e+08 0.013393432833254337 0.47495874762535095\n",
      "[Step 2546] Loss: 1.01e+08 0.013954655267298222 0.4754686653614044\n",
      "[Step 2547] Loss: 1.03e+08 0.014432033523917198 0.47599512338638306\n",
      "[Step 2548] Loss: 1.03e+08 0.014860517345368862 0.47643572092056274\n",
      "[Step 2549] Loss: 1.02e+08 0.015478531830012798 0.4770207703113556\n",
      "[Step 2550] Loss: 1.03e+08 0.01620328798890114 0.4777452349662781\n",
      "[Step 2551] Loss: 1.02e+08 0.01679319143295288 0.47830548882484436\n",
      "[Step 2552] Loss: 1.01e+08 0.017463386058807373 0.4789293110370636\n",
      "[Step 2553] Loss: 1.01e+08 0.018160603940486908 0.4795762002468109\n",
      "[Step 2554] Loss: 1.01e+08 0.01887398585677147 0.48031386733055115\n",
      "[Step 2555] Loss: 1.02e+08 0.019596343860030174 0.480959951877594\n",
      "[Step 2556] Loss: 1.01e+08 0.02028736285865307 0.48162996768951416\n",
      "[Step 2557] Loss: 1.02e+08 0.020990952849388123 0.48230740427970886\n",
      "[Step 2558] Loss: 1.02e+08 0.02175256237387657 0.48304590582847595\n",
      "[Step 2559] Loss: 1.03e+08 0.022436566650867462 0.48366889357566833\n",
      "[Step 2560] Loss: 1.02e+08 0.023204008117318153 0.48443707823753357\n",
      "[Step 2561] Loss: 1.02e+08 0.02388342097401619 0.4850592315196991\n",
      "[Step 2562] Loss: 1.01e+08 0.024627750739455223 0.485761433839798\n",
      "[Step 2563] Loss: 1.02e+08 0.02529287151992321 0.48642319440841675\n",
      "[Step 2564] Loss: 1.01e+08 0.0259491428732872 0.4869884252548218\n",
      "[Step 2565] Loss: 1.02e+08 0.02657867968082428 0.48759159445762634\n",
      "[Step 2566] Loss: 1.02e+08 0.027243373915553093 0.4882269501686096\n",
      "[Step 2567] Loss: 1.03e+08 0.027909863740205765 0.4888565242290497\n",
      "[Step 2568] Loss: 1.02e+08 0.028639107942581177 0.4895801544189453\n",
      "[Step 2569] Loss: 1.02e+08 0.029286108911037445 0.4901321828365326\n",
      "[Step 2570] Loss: 1.03e+08 0.029876533895730972 0.49069494009017944\n",
      "[Step 2571] Loss: 1.02e+08 0.03048979677259922 0.4912494122982025\n",
      "[Step 2572] Loss: 1.02e+08 0.031192975118756294 0.4919417202472687\n",
      "[Step 2573] Loss: 1.02e+08 0.03177185729146004 0.4924681484699249\n",
      "[Step 2574] Loss: 1.02e+08 0.032383088022470474 0.49298304319381714\n",
      "[Step 2575] Loss: 1.02e+08 0.0329783633351326 0.4935127794742584\n",
      "[Step 2576] Loss: 1.01e+08 0.03363099321722984 0.4940771758556366\n",
      "[Step 2577] Loss: 1.01e+08 0.03424042835831642 0.4946044385433197\n",
      "[Step 2578] Loss: 1.02e+08 0.034790944308042526 0.4950978457927704\n",
      "[Step 2579] Loss: 1.01e+08 0.03542561084032059 0.4956416189670563\n",
      "[Step 2580] Loss: 1.02e+08 0.03598012402653694 0.4961598217487335\n",
      "[Step 2581] Loss: 1.02e+08 0.03650747984647751 0.4965905249118805\n",
      "[Step 2582] Loss: 1.03e+08 0.03709243983030319 0.4972234070301056\n",
      "[Step 2583] Loss: 1.02e+08 0.03769221156835556 0.49771520495414734\n",
      "[Step 2584] Loss: 1.02e+08 0.03835798427462578 0.4983546733856201\n",
      "[Step 2585] Loss: 1.03e+08 0.039130233228206635 0.4990915060043335\n",
      "[Step 2586] Loss: 1.03e+08 0.03979512304067612 0.49968066811561584\n",
      "[Step 2587] Loss: 1.02e+08 0.04043251648545265 0.500309407711029\n",
      "[Step 2588] Loss: 1.01e+08 0.0411643423140049 0.5009720325469971\n",
      "[Step 2589] Loss: 1.02e+08 0.041958607733249664 0.5016799569129944\n",
      "[Step 2590] Loss: 1.01e+08 0.04265426844358444 0.502383828163147\n",
      "[Step 2591] Loss: 1.02e+08 0.04323567450046539 0.5028913021087646\n",
      "[Step 2592] Loss: 1.02e+08 0.04377896338701248 0.5034375190734863\n",
      "[Step 2593] Loss: 1.01e+08 0.0443108044564724 0.5039433240890503\n",
      "[Step 2594] Loss: 1.02e+08 0.04491446912288666 0.5044829845428467\n",
      "[Step 2595] Loss: 1.02e+08 0.0455382764339447 0.5050424337387085\n",
      "[Step 2596] Loss: 1.02e+08 0.04621836543083191 0.5056365132331848\n",
      "[Step 2597] Loss: 1.02e+08 0.04695848748087883 0.5063799619674683\n",
      "[Step 2598] Loss: 1.02e+08 0.047704800963401794 0.5071077346801758\n",
      "[Step 2599] Loss: 1.01e+08 0.04851699620485306 0.5078627467155457\n",
      "[Step 2600] Loss: 1.03e+08 0.049383923411369324 0.5086176991462708\n",
      "[Step 2601] Loss: 1.02e+08 0.050244107842445374 0.5094618201255798\n",
      "[Step 2602] Loss: 1.01e+08 0.051097285002470016 0.510206937789917\n",
      "[Step 2603] Loss: 1.03e+08 0.05185854807496071 0.5108761191368103\n",
      "[Step 2604] Loss: 1.02e+08 0.052634816616773605 0.5116270184516907\n",
      "[Step 2605] Loss: 1.02e+08 0.05344562605023384 0.5123762488365173\n",
      "[Step 2606] Loss: 1.03e+08 0.05426567420363426 0.5131064653396606\n",
      "[Step 2607] Loss: 1.03e+08 0.05513129383325577 0.5139546990394592\n",
      "[Step 2608] Loss: 1.02e+08 0.05593749135732651 0.51469486951828\n",
      "[Step 2609] Loss: 1.03e+08 0.05673608183860779 0.5154325366020203\n",
      "[Step 2610] Loss: 1.02e+08 0.05745807662606239 0.5161074995994568\n",
      "[Step 2611] Loss: 1.02e+08 0.058206707239151 0.5167148113250732\n",
      "[Step 2612] Loss: 1.02e+08 0.05903785303235054 0.5174772143363953\n",
      "[Step 2613] Loss: 1.02e+08 0.05990336462855339 0.5183106064796448\n",
      "[Step 2614] Loss: 1.02e+08 0.060685716569423676 0.5190615057945251\n",
      "[Step 2615] Loss: 1.02e+08 0.06149084493517876 0.5197785496711731\n",
      "[Step 2616] Loss: 1.01e+08 0.06233925372362137 0.520578920841217\n",
      "[Step 2617] Loss: 1.02e+08 0.06311223655939102 0.5212497711181641\n",
      "[Step 2618] Loss: 1.02e+08 0.06377129256725311 0.5218331217765808\n",
      "[Step 2619] Loss: 1.02e+08 0.06457248330116272 0.5226145386695862\n",
      "[Step 2620] Loss: 1.02e+08 0.06543402373790741 0.5234413146972656\n",
      "[Step 2621] Loss: 1.02e+08 0.06634649634361267 0.5243481397628784\n",
      "[Step 2622] Loss: 1.01e+08 0.06734965741634369 0.5253316760063171\n",
      "[Step 2623] Loss: 1.03e+08 0.0682917982339859 0.5262434482574463\n",
      "[Step 2624] Loss: 1.01e+08 0.06921520084142685 0.5270645022392273\n",
      "[Step 2625] Loss: 1.02e+08 0.07017574459314346 0.5279960632324219\n",
      "[Step 2626] Loss: 1.02e+08 0.07111690193414688 0.5288764834403992\n",
      "[Step 2627] Loss: 1.02e+08 0.07209568470716476 0.529783308506012\n",
      "[Step 2628] Loss: 1.02e+08 0.07306002825498581 0.5306744575500488\n",
      "[Step 2629] Loss: 1.02e+08 0.0738939717411995 0.5314401984214783\n",
      "[Step 2630] Loss: 1.02e+08 0.07480503618717194 0.5322603583335876\n",
      "[Step 2631] Loss: 1.03e+08 0.07579299807548523 0.5331647396087646\n",
      "[Step 2632] Loss: 1.01e+08 0.07682915776968002 0.5340963006019592\n",
      "[Step 2633] Loss: 1.02e+08 0.07771715521812439 0.5349668264389038\n",
      "[Step 2634] Loss: 1.02e+08 0.07868613302707672 0.5358497500419617\n",
      "[Step 2635] Loss: 1.02e+08 0.07961946725845337 0.5367334485054016\n",
      "[Step 2636] Loss: 1.02e+08 0.08046971261501312 0.5374917387962341\n",
      "[Step 2637] Loss: 1.01e+08 0.08134522289037704 0.5383309125900269\n",
      "[Step 2638] Loss: 1.02e+08 0.08220528066158295 0.5390801429748535\n",
      "[Step 2639] Loss: 1.02e+08 0.08314008265733719 0.5399028062820435\n",
      "[Step 2640] Loss: 1.03e+08 0.08391748368740082 0.5406033396720886\n",
      "[Step 2641] Loss: 1.03e+08 0.0845789983868599 0.5412155985832214\n",
      "[Step 2642] Loss: 1.01e+08 0.08529293537139893 0.5418740510940552\n",
      "[Step 2643] Loss: 1.02e+08 0.08594103157520294 0.5424549579620361\n",
      "[Step 2644] Loss: 1.01e+08 0.08648679405450821 0.5429500341415405\n",
      "[Step 2645] Loss: 1.02e+08 0.08709502220153809 0.543504536151886\n",
      "[Step 2646] Loss: 1.02e+08 0.08764044940471649 0.544040858745575\n",
      "[Step 2647] Loss: 1.01e+08 0.08817409723997116 0.5445194244384766\n",
      "[Step 2648] Loss: 1.02e+08 0.08876680582761765 0.545067310333252\n",
      "[Step 2649] Loss: 1.01e+08 0.08936338126659393 0.5456317067146301\n",
      "[Step 2650] Loss: 1.03e+08 0.0899573490023613 0.5461408495903015\n",
      "[Step 2651] Loss: 1.02e+08 0.0905761644244194 0.5466433167457581\n",
      "[Step 2652] Loss: 1.02e+08 0.09115370362997055 0.5471078753471375\n",
      "[Step 2653] Loss: 1.03e+08 0.09151729196310043 0.5474165081977844\n",
      "[Step 2654] Loss: 1.02e+08 0.09195293486118317 0.5477110743522644\n",
      "[Step 2655] Loss: 1.02e+08 0.09247055649757385 0.5481731295585632\n",
      "[Step 2656] Loss: 1.01e+08 0.09301629662513733 0.5486376881599426\n",
      "[Step 2657] Loss: 1.01e+08 0.09360655397176743 0.5491600036621094\n",
      "[Step 2658] Loss: 1.03e+08 0.09411242604255676 0.5496344566345215\n",
      "[Step 2659] Loss: 1.02e+08 0.09456639736890793 0.5500140190124512\n",
      "[Step 2660] Loss: 1.02e+08 0.09510783851146698 0.5504925847053528\n",
      "[Step 2661] Loss: 1.02e+08 0.09565626829862595 0.5510008931159973\n",
      "[Step 2662] Loss: 1.01e+08 0.09622246026992798 0.551591694355011\n",
      "[Step 2663] Loss: 1.02e+08 0.09685925394296646 0.5521470308303833\n",
      "[Step 2664] Loss: 1.02e+08 0.09737642109394073 0.5525801777839661\n",
      "[Step 2665] Loss: 1.01e+08 0.09797435998916626 0.5531181693077087\n",
      "[Step 2666] Loss: 1.02e+08 0.09855286031961441 0.5536553263664246\n",
      "[Step 2667] Loss: 1.02e+08 0.09913311153650284 0.5541842579841614\n",
      "[Step 2668] Loss: 1.01e+08 0.09971930831670761 0.554632306098938\n",
      "[Step 2669] Loss: 1.01e+08 0.10032765567302704 0.5551480054855347\n",
      "[Step 2670] Loss: 1.01e+08 0.10100991278886795 0.5557553172111511\n",
      "[Step 2671] Loss: 1.02e+08 0.10172685235738754 0.5563551783561707\n",
      "[Step 2672] Loss: 1.02e+08 0.10256626456975937 0.5570887327194214\n",
      "[Step 2673] Loss: 1.01e+08 0.10333943367004395 0.5577348470687866\n",
      "[Step 2674] Loss: 1.01e+08 0.1041111946105957 0.5584609508514404\n",
      "[Step 2675] Loss: 1.02e+08 0.10496644675731659 0.5592439770698547\n",
      "[Step 2676] Loss: 1.03e+08 0.10568241029977798 0.5598207712173462\n",
      "[Step 2677] Loss: 1.02e+08 0.10638955980539322 0.5604396462440491\n",
      "[Step 2678] Loss: 1.02e+08 0.10716213285923004 0.561052680015564\n",
      "[Step 2679] Loss: 1.01e+08 0.1079501286149025 0.5616682767868042\n",
      "[Step 2680] Loss: 1.02e+08 0.1088179275393486 0.5624587535858154\n",
      "[Step 2681] Loss: 1.02e+08 0.10966997593641281 0.5631766319274902\n",
      "[Step 2682] Loss: 1.01e+08 0.11054053157567978 0.5639976263046265\n",
      "[Step 2683] Loss: 1.02e+08 0.11151566356420517 0.564906895160675\n",
      "[Step 2684] Loss: 1.02e+08 0.11250242590904236 0.5657543540000916\n",
      "[Step 2685] Loss: 1.01e+08 0.11352303624153137 0.5666463375091553\n",
      "[Step 2686] Loss: 1.01e+08 0.11450820416212082 0.5675143599510193\n",
      "[Step 2687] Loss: 1.03e+08 0.11553645133972168 0.5683766007423401\n",
      "[Step 2688] Loss: 1.02e+08 0.11659304052591324 0.569290041923523\n",
      "[Step 2689] Loss: 1.02e+08 0.11753130704164505 0.570088803768158\n",
      "[Step 2690] Loss: 1.02e+08 0.11819498986005783 0.5706382989883423\n",
      "[Step 2691] Loss: 1.01e+08 0.11882057040929794 0.5712258219718933\n",
      "[Step 2692] Loss: 1.01e+08 0.11950195580720901 0.57174152135849\n",
      "[Step 2693] Loss: 1.02e+08 0.12010247260332108 0.5722349882125854\n",
      "[Step 2694] Loss: 1.01e+08 0.12069152295589447 0.5727127194404602\n",
      "[Step 2695] Loss: 1.01e+08 0.12124491482973099 0.573190450668335\n",
      "[Step 2696] Loss: 1.01e+08 0.12191516906023026 0.573747456073761\n",
      "[Step 2697] Loss: 1.02e+08 0.12258268147706985 0.5743415355682373\n",
      "[Step 2698] Loss: 1.02e+08 0.1232428178191185 0.574863851070404\n",
      "[Step 2699] Loss: 1.02e+08 0.1238865926861763 0.5754150152206421\n",
      "[Step 2700] Loss: 1.02e+08 0.12449236959218979 0.5759538412094116\n",
      "[Step 2701] Loss: 1.02e+08 0.1250348836183548 0.5763672590255737\n",
      "[Step 2702] Loss: 1.02e+08 0.12551678717136383 0.5768086910247803\n",
      "[Step 2703] Loss: 1.01e+08 0.12594209611415863 0.577164351940155\n",
      "[Step 2704] Loss: 1.02e+08 0.1263892650604248 0.5775216221809387\n",
      "[Step 2705] Loss: 1.03e+08 0.12693946063518524 0.5780340433120728\n",
      "[Step 2706] Loss: 1.01e+08 0.12753590941429138 0.578485369682312\n",
      "[Step 2707] Loss: 1.01e+08 0.1281765252351761 0.5789928436279297\n",
      "[Step 2708] Loss: 1.02e+08 0.12879303097724915 0.5794639587402344\n",
      "[Step 2709] Loss: 1.02e+08 0.12931695580482483 0.5798369646072388\n",
      "[Step 2710] Loss: 1.02e+08 0.12988361716270447 0.580303966999054\n",
      "[Step 2711] Loss: 1.01e+08 0.13050241768360138 0.5808106064796448\n",
      "[Step 2712] Loss: 1.04e+08 0.13085024058818817 0.581088662147522\n",
      "[Step 2713] Loss: 1.02e+08 0.13117460906505585 0.581306517124176\n",
      "[Step 2714] Loss: 1.02e+08 0.1314917653799057 0.5815342664718628\n",
      "[Step 2715] Loss: 1.02e+08 0.13182975351810455 0.5817999243736267\n",
      "[Step 2716] Loss: 1.01e+08 0.13218140602111816 0.5820342898368835\n",
      "[Step 2717] Loss: 1.01e+08 0.1325301229953766 0.582302451133728\n",
      "[Step 2718] Loss: 1.03e+08 0.13276921212673187 0.5824584364891052\n",
      "[Step 2719] Loss: 1.01e+08 0.13310812413692474 0.5827174782752991\n",
      "[Step 2720] Loss: 1.01e+08 0.13349305093288422 0.5830162167549133\n",
      "[Step 2721] Loss: 1.02e+08 0.13393844664096832 0.5833866596221924\n",
      "[Step 2722] Loss: 1.01e+08 0.13439728319644928 0.5837455987930298\n",
      "[Step 2723] Loss: 1.02e+08 0.13489334285259247 0.5841540694236755\n",
      "[Step 2724] Loss: 1.03e+08 0.1352291852235794 0.5844024419784546\n",
      "[Step 2725] Loss: 1.02e+08 0.13540907204151154 0.5844981670379639\n",
      "[Step 2726] Loss: 1.02e+08 0.13560324907302856 0.5845864415168762\n",
      "[Step 2727] Loss: 1.01e+08 0.13584011793136597 0.5847019553184509\n",
      "[Step 2728] Loss: 1.01e+08 0.13615308701992035 0.5849090814590454\n",
      "[Step 2729] Loss: 1.00e+08 0.13647659122943878 0.5850567817687988\n",
      "[Step 2730] Loss: 1.02e+08 0.1369120478630066 0.5854330062866211\n",
      "[Step 2731] Loss: 1.01e+08 0.13747446238994598 0.5858818888664246\n",
      "[Step 2732] Loss: 1.02e+08 0.1380506306886673 0.5863266587257385\n",
      "[Step 2733] Loss: 1.01e+08 0.13872715830802917 0.5868555903434753\n",
      "[Step 2734] Loss: 1.02e+08 0.13933704793453217 0.5873547792434692\n",
      "[Step 2735] Loss: 1.01e+08 0.1398698389530182 0.5877912640571594\n",
      "[Step 2736] Loss: 1.02e+08 0.14047400653362274 0.5883160829544067\n",
      "[Step 2737] Loss: 1.02e+08 0.1411229521036148 0.5887855291366577\n",
      "[Step 2738] Loss: 1.02e+08 0.14168182015419006 0.5892278552055359\n",
      "[Step 2739] Loss: 1.01e+08 0.14229631423950195 0.5896816849708557\n",
      "[Step 2740] Loss: 1.01e+08 0.14283931255340576 0.5900826454162598\n",
      "[Step 2741] Loss: 1.02e+08 0.1433306187391281 0.5904185175895691\n",
      "[Step 2742] Loss: 1.02e+08 0.1437961757183075 0.5908030271530151\n",
      "[Step 2743] Loss: 1.02e+08 0.1443709433078766 0.5912882089614868\n",
      "[Step 2744] Loss: 1.00e+08 0.1449238359928131 0.5916570425033569\n",
      "[Step 2745] Loss: 1.01e+08 0.1455102562904358 0.5920976400375366\n",
      "[Step 2746] Loss: 1.02e+08 0.14617985486984253 0.5926397442817688\n",
      "[Step 2747] Loss: 1.01e+08 0.14684191346168518 0.5931843519210815\n",
      "[Step 2748] Loss: 1.01e+08 0.1475437432527542 0.5937627553939819\n",
      "[Step 2749] Loss: 1.01e+08 0.14818324148654938 0.5942727327346802\n",
      "[Step 2750] Loss: 1.01e+08 0.1488797515630722 0.5948478579521179\n",
      "[Step 2751] Loss: 1.02e+08 0.14961859583854675 0.5954724550247192\n",
      "[Step 2752] Loss: 1.03e+08 0.150509774684906 0.5962472558021545\n",
      "[Step 2753] Loss: 1.02e+08 0.1514064222574234 0.5969734191894531\n",
      "[Step 2754] Loss: 1.03e+08 0.1524752676486969 0.5978752374649048\n",
      "[Step 2755] Loss: 1.02e+08 0.15342028439044952 0.5986781120300293\n",
      "[Step 2756] Loss: 1.01e+08 0.15445874631404877 0.5995048880577087\n",
      "[Step 2757] Loss: 1.01e+08 0.15545780956745148 0.6003267765045166\n",
      "[Step 2758] Loss: 1.02e+08 0.1563965380191803 0.6010817289352417\n",
      "[Step 2759] Loss: 1.03e+08 0.1573132574558258 0.6017748713493347\n",
      "[Step 2760] Loss: 1.02e+08 0.15824410319328308 0.6025183200836182\n",
      "[Step 2761] Loss: 1.02e+08 0.15921951830387115 0.6033030152320862\n",
      "[Step 2762] Loss: 1.02e+08 0.16021482646465302 0.6041149497032166\n",
      "[Step 2763] Loss: 1.01e+08 0.1611146777868271 0.6048493385314941\n",
      "[Step 2764] Loss: 1.02e+08 0.1618722826242447 0.6055077910423279\n",
      "[Step 2765] Loss: 1.01e+08 0.16256216168403625 0.6060713529586792\n",
      "[Step 2766] Loss: 1.01e+08 0.16329677402973175 0.6066935062408447\n",
      "[Step 2767] Loss: 1.01e+08 0.16401556134223938 0.6072917580604553\n",
      "[Step 2768] Loss: 1.02e+08 0.16469807922840118 0.6078190207481384\n",
      "[Step 2769] Loss: 1.02e+08 0.16536356508731842 0.6083545088768005\n",
      "[Step 2770] Loss: 1.01e+08 0.1660730540752411 0.6089403629302979\n",
      "[Step 2771] Loss: 1.01e+08 0.16675549745559692 0.6095121502876282\n",
      "[Step 2772] Loss: 1.01e+08 0.1673930138349533 0.6100279092788696\n",
      "[Step 2773] Loss: 1.02e+08 0.16797257959842682 0.6105180382728577\n",
      "[Step 2774] Loss: 1.03e+08 0.16842056810855865 0.6108472347259521\n",
      "[Step 2775] Loss: 1.01e+08 0.16889283061027527 0.6112020611763\n",
      "[Step 2776] Loss: 1.02e+08 0.16934780776500702 0.611556887626648\n",
      "[Step 2777] Loss: 1.01e+08 0.169892817735672 0.6120189428329468\n",
      "[Step 2778] Loss: 1.01e+08 0.17056073248386383 0.612538754940033\n",
      "[Step 2779] Loss: 1.00e+08 0.17130611836910248 0.6131007075309753\n",
      "[Step 2780] Loss: 1.01e+08 0.1720704585313797 0.6137014031410217\n",
      "[Step 2781] Loss: 1.01e+08 0.17280668020248413 0.6142831444740295\n",
      "[Step 2782] Loss: 1.01e+08 0.1736302226781845 0.6149696111679077\n",
      "[Step 2783] Loss: 1.01e+08 0.17443957924842834 0.6155983805656433\n",
      "[Step 2784] Loss: 1.01e+08 0.17525532841682434 0.6162329316139221\n",
      "[Step 2785] Loss: 1.01e+08 0.17600148916244507 0.6167973279953003\n",
      "[Step 2786] Loss: 1.01e+08 0.17665241658687592 0.6173237562179565\n",
      "[Step 2787] Loss: 1.01e+08 0.17737123370170593 0.6178246140480042\n",
      "[Step 2788] Loss: 1.02e+08 0.1782235950231552 0.6185399889945984\n",
      "[Step 2789] Loss: 1.01e+08 0.17911337316036224 0.6192685961723328\n",
      "[Step 2790] Loss: 1.02e+08 0.17982187867164612 0.6198461651802063\n",
      "[Step 2791] Loss: 1.01e+08 0.1805722713470459 0.6204419136047363\n",
      "[Step 2792] Loss: 1.00e+08 0.181272953748703 0.6209923028945923\n",
      "[Step 2793] Loss: 1.02e+08 0.18195214867591858 0.6215377449989319\n",
      "[Step 2794] Loss: 1.02e+08 0.18261758983135223 0.6220047473907471\n",
      "[Step 2795] Loss: 1.00e+08 0.18319198489189148 0.6224403977394104\n",
      "[Step 2796] Loss: 1.01e+08 0.1839037537574768 0.6230229735374451\n",
      "[Step 2797] Loss: 1.02e+08 0.1845533698797226 0.6236137747764587\n",
      "[Step 2798] Loss: 1.01e+08 0.1852910816669464 0.6242210865020752\n",
      "[Step 2799] Loss: 1.01e+08 0.18598362803459167 0.6247698068618774\n",
      "[Step 2800] Loss: 1.02e+08 0.1866442710161209 0.6252904534339905\n",
      "[Step 2801] Loss: 1.01e+08 0.18720901012420654 0.6257162094116211\n",
      "[Step 2802] Loss: 1.01e+08 0.18786774575710297 0.6261659264564514\n",
      "[Step 2803] Loss: 1.02e+08 0.1885550320148468 0.6267071962356567\n",
      "[Step 2804] Loss: 1.02e+08 0.1893482506275177 0.6273359656333923\n",
      "[Step 2805] Loss: 1.01e+08 0.19011171162128448 0.6279540061950684\n",
      "[Step 2806] Loss: 1.02e+08 0.19092275202274323 0.628599226474762\n",
      "[Step 2807] Loss: 1.00e+08 0.19168983399868011 0.6291801333427429\n",
      "[Step 2808] Loss: 1.01e+08 0.19240432977676392 0.6297156810760498\n",
      "[Step 2809] Loss: 1.02e+08 0.1931305080652237 0.6303155422210693\n",
      "[Step 2810] Loss: 1.01e+08 0.19392912089824677 0.6308807730674744\n",
      "[Step 2811] Loss: 1.02e+08 0.1947249174118042 0.6315251588821411\n",
      "[Step 2812] Loss: 1.01e+08 0.1954566240310669 0.6320202350616455\n",
      "[Step 2813] Loss: 1.02e+08 0.19624263048171997 0.6325945258140564\n",
      "[Step 2814] Loss: 1.01e+08 0.1969832479953766 0.6331375241279602\n",
      "[Step 2815] Loss: 1.01e+08 0.19770915806293488 0.6336977481842041\n",
      "[Step 2816] Loss: 1.01e+08 0.19844959676265717 0.6342522501945496\n",
      "[Step 2817] Loss: 1.01e+08 0.19913211464881897 0.6347176432609558\n",
      "[Step 2818] Loss: 1.01e+08 0.1998734176158905 0.6352159976959229\n",
      "[Step 2819] Loss: 1.01e+08 0.20062167942523956 0.6357168555259705\n",
      "[Step 2820] Loss: 1.00e+08 0.20131757855415344 0.6362391710281372\n",
      "[Step 2821] Loss: 1.02e+08 0.20189930498600006 0.6366113424301147\n",
      "[Step 2822] Loss: 1.01e+08 0.20252002775669098 0.6370701193809509\n",
      "[Step 2823] Loss: 1.02e+08 0.20329776406288147 0.6375849843025208\n",
      "[Step 2824] Loss: 1.01e+08 0.20405277609825134 0.6380462050437927\n",
      "[Step 2825] Loss: 1.01e+08 0.2048882097005844 0.6386180520057678\n",
      "[Step 2826] Loss: 1.01e+08 0.2056075781583786 0.6391444802284241\n",
      "[Step 2827] Loss: 1.02e+08 0.20631000399589539 0.639627993106842\n",
      "[Step 2828] Loss: 1.01e+08 0.20701834559440613 0.6401272416114807\n",
      "[Step 2829] Loss: 1.02e+08 0.20776820182800293 0.6406124234199524\n",
      "[Step 2830] Loss: 1.01e+08 0.2084662765264511 0.6410926580429077\n",
      "[Step 2831] Loss: 1.02e+08 0.20921087265014648 0.6416553854942322\n",
      "[Step 2832] Loss: 1.01e+08 0.20988014340400696 0.6421290040016174\n",
      "[Step 2833] Loss: 1.01e+08 0.21053414046764374 0.6425482034683228\n",
      "[Step 2834] Loss: 1.01e+08 0.21114808320999146 0.6429722905158997\n",
      "[Step 2835] Loss: 1.01e+08 0.21168257296085358 0.6432784199714661\n",
      "[Step 2836] Loss: 1.01e+08 0.212211012840271 0.6436620950698853\n",
      "[Step 2837] Loss: 1.01e+08 0.2127826064825058 0.6440309286117554\n",
      "[Step 2838] Loss: 1.02e+08 0.21326717734336853 0.6443378925323486\n",
      "[Step 2839] Loss: 1.02e+08 0.2137307971715927 0.6446654796600342\n",
      "[Step 2840] Loss: 1.01e+08 0.21422134339809418 0.6449716091156006\n",
      "[Step 2841] Loss: 1.01e+08 0.2147936075925827 0.6453495025634766\n",
      "[Step 2842] Loss: 1.01e+08 0.21538707613945007 0.6457464098930359\n",
      "[Step 2843] Loss: 1.02e+08 0.21582071483135223 0.6460179090499878\n",
      "[Step 2844] Loss: 1.01e+08 0.21622350811958313 0.6462530493736267\n",
      "[Step 2845] Loss: 1.02e+08 0.21655011177062988 0.6464106440544128\n",
      "[Step 2846] Loss: 1.02e+08 0.21685674786567688 0.6465723514556885\n",
      "[Step 2847] Loss: 1.01e+08 0.2172302007675171 0.646779477596283\n",
      "[Step 2848] Loss: 1.01e+08 0.21771065890789032 0.6471087336540222\n",
      "[Step 2849] Loss: 1.01e+08 0.21823300421237946 0.6474791765213013\n",
      "[Step 2850] Loss: 1.01e+08 0.21874365210533142 0.6477944254875183\n",
      "[Step 2851] Loss: 1.02e+08 0.21918654441833496 0.6481104493141174\n",
      "[Step 2852] Loss: 1.01e+08 0.21965362131595612 0.6484445929527283\n",
      "[Step 2853] Loss: 1.01e+08 0.22006992995738983 0.6486847400665283\n",
      "[Step 2854] Loss: 1.01e+08 0.22055493295192719 0.6489817500114441\n",
      "[Step 2855] Loss: 1.01e+08 0.22109194099903107 0.6493225693702698\n",
      "[Step 2856] Loss: 1.02e+08 0.22162291407585144 0.649675726890564\n",
      "[Step 2857] Loss: 1.01e+08 0.2222277969121933 0.6501427292823792\n",
      "[Step 2858] Loss: 1.03e+08 0.22295798361301422 0.6506914496421814\n",
      "[Step 2859] Loss: 1.02e+08 0.22369813919067383 0.6511436104774475\n",
      "[Step 2860] Loss: 1.01e+08 0.22443273663520813 0.6516098380088806\n",
      "[Step 2861] Loss: 1.01e+08 0.2251470535993576 0.6520628333091736\n",
      "[Step 2862] Loss: 1.07e+08 0.2254609912633896 0.6522253751754761\n",
      "[Step 2863] Loss: 1.02e+08 0.22584287822246552 0.6524143218994141\n",
      "[Step 2864] Loss: 1.01e+08 0.2262079268693924 0.6526668071746826\n",
      "[Step 2865] Loss: 1.01e+08 0.22660623490810394 0.6529086232185364\n",
      "[Step 2866] Loss: 1.02e+08 0.22697733342647552 0.6531016826629639\n",
      "[Step 2867] Loss: 1.01e+08 0.22728098928928375 0.6532254815101624\n",
      "[Step 2868] Loss: 1.02e+08 0.22754941880702972 0.6533863544464111\n",
      "[Step 2869] Loss: 1.03e+08 0.22780504822731018 0.6534746289253235\n",
      "[Step 2870] Loss: 1.00e+08 0.22809642553329468 0.6536528468132019\n",
      "[Step 2871] Loss: 1.02e+08 0.2285105437040329 0.6539168953895569\n",
      "[Step 2872] Loss: 1.02e+08 0.2289372980594635 0.6541793346405029\n",
      "[Step 2873] Loss: 1.01e+08 0.22940479218959808 0.6544945240020752\n",
      "[Step 2874] Loss: 1.01e+08 0.22989262640476227 0.6548129916191101\n",
      "[Step 2875] Loss: 1.01e+08 0.23032517731189728 0.6550589203834534\n",
      "[Step 2876] Loss: 1.01e+08 0.23083087801933289 0.6553155183792114\n",
      "[Step 2877] Loss: 1.02e+08 0.23136278986930847 0.6555919647216797\n",
      "[Step 2878] Loss: 1.02e+08 0.23191717267036438 0.6559203267097473\n",
      "[Step 2879] Loss: 1.01e+08 0.23239539563655853 0.6561852097511292\n",
      "[Step 2880] Loss: 1.01e+08 0.23290574550628662 0.6564773321151733\n",
      "[Step 2881] Loss: 1.01e+08 0.23349058628082275 0.6568816304206848\n",
      "[Step 2882] Loss: 1.01e+08 0.23405012488365173 0.6572380661964417\n",
      "[Step 2883] Loss: 9.98e+07 0.2345990240573883 0.6575574278831482\n",
      "[Step 2884] Loss: 1.00e+08 0.23512326180934906 0.6578759551048279\n",
      "[Step 2885] Loss: 1.01e+08 0.23574428260326385 0.6582950949668884\n",
      "[Step 2886] Loss: 1.02e+08 0.23631365597248077 0.6586862206459045\n",
      "[Step 2887] Loss: 1.01e+08 0.236776202917099 0.6589535474777222\n",
      "[Step 2888] Loss: 1.01e+08 0.23718108236789703 0.6592126488685608\n",
      "[Step 2889] Loss: 1.00e+08 0.23761005699634552 0.6594799757003784\n",
      "[Step 2890] Loss: 1.02e+08 0.2380669116973877 0.6597234010696411\n",
      "[Step 2891] Loss: 1.00e+08 0.23852863907814026 0.6599998474121094\n",
      "[Step 2892] Loss: 1.03e+08 0.23883844912052155 0.6601276993751526\n",
      "[Step 2893] Loss: 1.02e+08 0.23917481303215027 0.6603026390075684\n",
      "[Step 2894] Loss: 1.01e+08 0.2395997941493988 0.6605271100997925\n",
      "[Step 2895] Loss: 1.01e+08 0.240029975771904 0.6607416272163391\n",
      "[Step 2896] Loss: 1.03e+08 0.24036698043346405 0.6609099507331848\n",
      "[Step 2897] Loss: 1.00e+08 0.24071764945983887 0.6610997319221497\n",
      "[Step 2898] Loss: 1.01e+08 0.2411395162343979 0.6613126397132874\n",
      "[Step 2899] Loss: 1.01e+08 0.24164950847625732 0.66161048412323\n",
      "[Step 2900] Loss: 1.01e+08 0.24205438792705536 0.6618208885192871\n",
      "[Step 2901] Loss: 1.01e+08 0.24248315393924713 0.6620239019393921\n",
      "[Step 2902] Loss: 1.01e+08 0.24288298189640045 0.6622450351715088\n",
      "[Step 2903] Loss: 1.02e+08 0.24336671829223633 0.6625363230705261\n",
      "[Step 2904] Loss: 1.02e+08 0.24386043846607208 0.6628275513648987\n",
      "[Step 2905] Loss: 1.01e+08 0.24428623914718628 0.6630429625511169\n",
      "[Step 2906] Loss: 1.01e+08 0.24470552802085876 0.6632591485977173\n",
      "[Step 2907] Loss: 1.02e+08 0.245111882686615 0.6635140776634216\n",
      "[Step 2908] Loss: 1.01e+08 0.24548786878585815 0.6636906862258911\n",
      "[Step 2909] Loss: 1.00e+08 0.24589207768440247 0.6639134287834167\n",
      "[Step 2910] Loss: 9.98e+07 0.24632751941680908 0.6642096638679504\n",
      "[Step 2911] Loss: 1.01e+08 0.24681605398654938 0.6645116806030273\n",
      "[Step 2912] Loss: 1.02e+08 0.24725329875946045 0.6648194789886475\n",
      "[Step 2913] Loss: 1.01e+08 0.24768351018428802 0.6649927496910095\n",
      "[Step 2914] Loss: 1.01e+08 0.24812853336334229 0.6652196645736694\n",
      "[Step 2915] Loss: 1.01e+08 0.24858994781970978 0.6654680371284485\n",
      "[Step 2916] Loss: 1.02e+08 0.24902501702308655 0.6656998991966248\n",
      "[Step 2917] Loss: 1.01e+08 0.24961161613464355 0.6660340428352356\n",
      "[Step 2918] Loss: 1.01e+08 0.25017377734184265 0.6663649082183838\n",
      "[Step 2919] Loss: 1.01e+08 0.25084567070007324 0.6668286919593811\n",
      "[Step 2920] Loss: 1.01e+08 0.2514767646789551 0.6672098636627197\n",
      "[Step 2921] Loss: 1.01e+08 0.2522316873073578 0.667681872844696\n",
      "[Step 2922] Loss: 1.02e+08 0.2529737651348114 0.6681761145591736\n",
      "[Step 2923] Loss: 1.00e+08 0.2537001669406891 0.6685565114021301\n",
      "[Step 2924] Loss: 1.01e+08 0.25431978702545166 0.6689013838768005\n",
      "[Step 2925] Loss: 1.00e+08 0.25499773025512695 0.6693007946014404\n",
      "[Step 2926] Loss: 1.00e+08 0.2556578516960144 0.6697389483451843\n",
      "[Step 2927] Loss: 1.01e+08 0.2563042640686035 0.670126736164093\n",
      "[Step 2928] Loss: 1.01e+08 0.2569265067577362 0.6704262495040894\n",
      "[Step 2929] Loss: 1.01e+08 0.2575162649154663 0.6707695126533508\n",
      "[Step 2930] Loss: 1.01e+08 0.2580287754535675 0.6710582971572876\n",
      "[Step 2931] Loss: 1.01e+08 0.25856339931488037 0.6713107824325562\n",
      "[Step 2932] Loss: 1.01e+08 0.2590782046318054 0.6716441512107849\n",
      "[Step 2933] Loss: 1.00e+08 0.25967738032341003 0.672027051448822\n",
      "[Step 2934] Loss: 1.01e+08 0.2603522539138794 0.6724676489830017\n",
      "[Step 2935] Loss: 1.01e+08 0.2610948979854584 0.6729231476783752\n",
      "[Step 2936] Loss: 1.01e+08 0.2618728280067444 0.6733761429786682\n",
      "[Step 2937] Loss: 1.01e+08 0.2626475393772125 0.6738258004188538\n",
      "[Step 2938] Loss: 1.01e+08 0.2633616328239441 0.6743366122245789\n",
      "[Step 2939] Loss: 1.01e+08 0.26411324739456177 0.6747995018959045\n",
      "[Step 2940] Loss: 1.00e+08 0.2648550271987915 0.675287127494812\n",
      "[Step 2941] Loss: 1.01e+08 0.265632301568985 0.6757591366767883\n",
      "[Step 2942] Loss: 1.02e+08 0.26626500487327576 0.6760767698287964\n",
      "[Step 2943] Loss: 1.01e+08 0.266911119222641 0.6764315962791443\n",
      "[Step 2944] Loss: 1.01e+08 0.267538845539093 0.6768409013748169\n",
      "[Step 2945] Loss: 1.01e+08 0.2681009769439697 0.6771445274353027\n",
      "[Step 2946] Loss: 1.02e+08 0.2685464322566986 0.6773244142532349\n",
      "[Step 2947] Loss: 1.01e+08 0.26894500851631165 0.6775504946708679\n",
      "[Step 2948] Loss: 1.01e+08 0.2694579064846039 0.6777947545051575\n",
      "[Step 2949] Loss: 1.01e+08 0.269995778799057 0.6780505180358887\n",
      "[Step 2950] Loss: 1.01e+08 0.2705134153366089 0.6783302426338196\n",
      "[Step 2951] Loss: 1.00e+08 0.2709835469722748 0.6784994006156921\n",
      "[Step 2952] Loss: 1.02e+08 0.2715873122215271 0.6788286566734314\n",
      "[Step 2953] Loss: 1.01e+08 0.27210256457328796 0.6790968179702759\n",
      "[Step 2954] Loss: 1.01e+08 0.27266037464141846 0.6793913841247559\n",
      "[Step 2955] Loss: 1.00e+08 0.27327510714530945 0.6796975135803223\n",
      "[Step 2956] Loss: 1.01e+08 0.2740596532821655 0.6802033185958862\n",
      "[Step 2957] Loss: 1.02e+08 0.2749501168727875 0.6807289123535156\n",
      "[Step 2958] Loss: 1.01e+08 0.27589258551597595 0.6813576817512512\n",
      "[Step 2959] Loss: 1.02e+08 0.27677667140960693 0.681849479675293\n",
      "[Step 2960] Loss: 1.01e+08 0.2775628864765167 0.6822991371154785\n",
      "[Step 2961] Loss: 1.01e+08 0.27830401062965393 0.6827496886253357\n",
      "[Step 2962] Loss: 1.01e+08 0.27901944518089294 0.6831680536270142\n",
      "[Step 2963] Loss: 1.01e+08 0.2797698676586151 0.683577299118042\n",
      "[Step 2964] Loss: 1.01e+08 0.28050535917282104 0.6840212345123291\n",
      "[Step 2965] Loss: 1.02e+08 0.28130513429641724 0.684520423412323\n",
      "[Step 2966] Loss: 1.02e+08 0.2820499539375305 0.6850064396858215\n",
      "[Step 2967] Loss: 1.01e+08 0.28281864523887634 0.6854891180992126\n",
      "[Step 2968] Loss: 1.02e+08 0.28366366028785706 0.6860519051551819\n",
      "[Step 2969] Loss: 1.00e+08 0.284487247467041 0.6865733861923218\n",
      "[Step 2970] Loss: 9.97e+07 0.2852535545825958 0.6870371103286743\n",
      "[Step 2971] Loss: 1.01e+08 0.28609371185302734 0.687552809715271\n",
      "[Step 2972] Loss: 1.01e+08 0.28686609864234924 0.6879736185073853\n",
      "[Step 2973] Loss: 1.02e+08 0.28752070665359497 0.6883647441864014\n",
      "[Step 2974] Loss: 9.98e+07 0.28813183307647705 0.6887203454971313\n",
      "[Step 2975] Loss: 1.01e+08 0.2887764871120453 0.6890785098075867\n",
      "[Step 2976] Loss: 1.00e+08 0.28939610719680786 0.6894927024841309\n",
      "[Step 2977] Loss: 1.01e+08 0.29001718759536743 0.6898276805877686\n",
      "[Step 2978] Loss: 1.00e+08 0.2906821370124817 0.6902039647102356\n",
      "[Step 2979] Loss: 1.01e+08 0.2913224399089813 0.6905488967895508\n",
      "[Step 2980] Loss: 9.99e+07 0.29201745986938477 0.6909705400466919\n",
      "[Step 2981] Loss: 1.01e+08 0.29266494512557983 0.6913797855377197\n",
      "[Step 2982] Loss: 1.01e+08 0.2933742105960846 0.6917791366577148\n",
      "[Step 2983] Loss: 1.02e+08 0.2939394414424896 0.69212406873703\n",
      "[Step 2984] Loss: 1.01e+08 0.29453280568122864 0.6924087405204773\n",
      "[Step 2985] Loss: 1.00e+08 0.2950758635997772 0.6926752328872681\n",
      "[Step 2986] Loss: 1.01e+08 0.29563096165657043 0.6929582953453064\n",
      "[Step 2987] Loss: 1.01e+08 0.2961687743663788 0.6932198405265808\n",
      "[Step 2988] Loss: 1.01e+08 0.2965962588787079 0.6933658719062805\n",
      "[Step 2989] Loss: 1.00e+08 0.2970837354660034 0.6936216950416565\n",
      "[Step 2990] Loss: 1.01e+08 0.2976365387439728 0.693949282169342\n",
      "[Step 2991] Loss: 1.00e+08 0.2981255054473877 0.6941770315170288\n",
      "[Step 2992] Loss: 1.01e+08 0.2986468970775604 0.6944699287414551\n",
      "[Step 2993] Loss: 1.01e+08 0.29905784130096436 0.6946770548820496\n",
      "[Step 2994] Loss: 1.00e+08 0.2994198799133301 0.6948131918907166\n",
      "[Step 2995] Loss: 1.02e+08 0.2997046113014221 0.6948602199554443\n",
      "[Step 2996] Loss: 1.00e+08 0.30005306005477905 0.6949732303619385\n",
      "[Step 2997] Loss: 1.01e+08 0.3003973960876465 0.6950549483299255\n",
      "[Step 2998] Loss: 1.01e+08 0.3008464276790619 0.695247232913971\n",
      "[Step 2999] Loss: 1.01e+08 0.3013514578342438 0.6954526901245117\n",
      "[Step 3000] Loss: 1.02e+08 0.30191749334335327 0.6957290768623352\n",
      "[Step 3001] Loss: 1.00e+08 0.30240732431411743 0.6959708333015442\n",
      "[Step 3002] Loss: 1.01e+08 0.30298498272895813 0.6962546706199646\n",
      "[Step 3003] Loss: 1.01e+08 0.3035585582256317 0.6965847611427307\n",
      "[Step 3004] Loss: 1.00e+08 0.30412760376930237 0.6968628168106079\n",
      "[Step 3005] Loss: 1.01e+08 0.3047126531600952 0.6971375942230225\n",
      "[Step 3006] Loss: 1.00e+08 0.3052571415901184 0.6974338293075562\n",
      "[Step 3007] Loss: 1.02e+08 0.30575260519981384 0.6976425647735596\n",
      "[Step 3008] Loss: 1.00e+08 0.3062540590763092 0.6978835463523865\n",
      "[Step 3009] Loss: 1.01e+08 0.30672943592071533 0.6980897784233093\n",
      "[Step 3010] Loss: 1.00e+08 0.30720528960227966 0.6983051896095276\n",
      "[Step 3011] Loss: 1.01e+08 0.30755335092544556 0.6984330415725708\n",
      "[Step 3012] Loss: 1.01e+08 0.30790960788726807 0.6985485553741455\n",
      "[Step 3013] Loss: 1.02e+08 0.3083571791648865 0.6987631320953369\n",
      "[Step 3014] Loss: 1.01e+08 0.308742493391037 0.6989273428916931\n",
      "[Step 3015] Loss: 1.01e+08 0.30923697352409363 0.6991789937019348\n",
      "[Step 3016] Loss: 1.01e+08 0.3095914125442505 0.6992994546890259\n",
      "[Step 3017] Loss: 1.01e+08 0.30986353754997253 0.6993597149848938\n",
      "[Step 3018] Loss: 1.01e+08 0.3101363480091095 0.6994430422782898\n",
      "[Step 3019] Loss: 1.02e+08 0.3104638159275055 0.6995453238487244\n",
      "[Step 3020] Loss: 1.01e+08 0.31079116463661194 0.699698805809021\n",
      "[Step 3021] Loss: 1.02e+08 0.3111884295940399 0.69988614320755\n",
      "[Step 3022] Loss: 1.02e+08 0.31161007285118103 0.7000940442085266\n",
      "[Step 3023] Loss: 1.00e+08 0.3120673596858978 0.7002978920936584\n",
      "[Step 3024] Loss: 1.01e+08 0.3125142753124237 0.7005214691162109\n",
      "[Step 3025] Loss: 1.01e+08 0.31300461292266846 0.7007129192352295\n",
      "[Step 3026] Loss: 9.98e+07 0.3134599030017853 0.7009785771369934\n",
      "[Step 3027] Loss: 1.02e+08 0.3139176070690155 0.7012096643447876\n",
      "[Step 3028] Loss: 1.00e+08 0.31435972452163696 0.701418399810791\n",
      "[Step 3029] Loss: 1.01e+08 0.3148699998855591 0.7017039060592651\n",
      "[Step 3030] Loss: 1.00e+08 0.3154057562351227 0.701977014541626\n",
      "[Step 3031] Loss: 1.00e+08 0.31591886281967163 0.7021973133087158\n",
      "[Step 3032] Loss: 1.02e+08 0.3162217140197754 0.702233612537384\n",
      "[Step 3033] Loss: 1.02e+08 0.3165297210216522 0.702302098274231\n",
      "[Step 3034] Loss: 1.00e+08 0.3168739378452301 0.7024325132369995\n",
      "[Step 3035] Loss: 1.01e+08 0.31731563806533813 0.7025901079177856\n",
      "[Step 3036] Loss: 1.01e+08 0.31772279739379883 0.7027485370635986\n",
      "[Step 3037] Loss: 1.02e+08 0.31802332401275635 0.7028689980506897\n",
      "[Step 3038] Loss: 1.01e+08 0.3182671368122101 0.7029226422309875\n",
      "[Step 3039] Loss: 1.01e+08 0.3185672163963318 0.703039824962616\n",
      "[Step 3040] Loss: 1.00e+08 0.3188963830471039 0.703160285949707\n",
      "[Step 3041] Loss: 1.01e+08 0.3194270730018616 0.7033467292785645\n",
      "[Step 3042] Loss: 1.00e+08 0.31998422741889954 0.7036528587341309\n",
      "[Step 3043] Loss: 1.01e+08 0.3206093907356262 0.7039185762405396\n",
      "[Step 3044] Loss: 9.99e+07 0.32125580310821533 0.7042428255081177\n",
      "[Step 3045] Loss: 1.01e+08 0.32201310992240906 0.7046075463294983\n",
      "[Step 3046] Loss: 1.01e+08 0.32276007533073425 0.7050126791000366\n",
      "[Step 3047] Loss: 1.00e+08 0.32347750663757324 0.7053765654563904\n",
      "[Step 3048] Loss: 1.01e+08 0.3240773677825928 0.7056439518928528\n",
      "[Step 3049] Loss: 1.01e+08 0.3247218430042267 0.7059855461120605\n",
      "[Step 3050] Loss: 1.00e+08 0.32540014386177063 0.7063724994659424\n",
      "[Step 3051] Loss: 1.01e+08 0.3259933590888977 0.7066712379455566\n",
      "[Step 3052] Loss: 1.01e+08 0.32668378949165344 0.7070095539093018\n",
      "[Step 3053] Loss: 1.00e+08 0.3273848593235016 0.7073445320129395\n",
      "[Step 3054] Loss: 1.00e+08 0.32804620265960693 0.7076828479766846\n",
      "[Step 3055] Loss: 1.00e+08 0.3286137282848358 0.7080005407333374\n",
      "[Step 3056] Loss: 1.01e+08 0.3291866183280945 0.7082447409629822\n",
      "[Step 3057] Loss: 1.01e+08 0.32974866032600403 0.7084518671035767\n",
      "[Step 3058] Loss: 1.01e+08 0.33019107580184937 0.7086053490638733\n",
      "[Step 3059] Loss: 1.00e+08 0.330700546503067 0.708855390548706\n",
      "[Step 3060] Loss: 1.00e+08 0.3312194049358368 0.7091004252433777\n",
      "[Step 3061] Loss: 1.00e+08 0.3317740559577942 0.7093726992607117\n",
      "[Step 3062] Loss: 1.01e+08 0.33231210708618164 0.7095682621002197\n",
      "[Step 3063] Loss: 1.02e+08 0.33283504843711853 0.7097861170768738\n",
      "[Step 3064] Loss: 1.02e+08 0.33322396874427795 0.7099478244781494\n",
      "[Step 3065] Loss: 1.00e+08 0.3336743116378784 0.7101137042045593\n",
      "[Step 3066] Loss: 9.97e+07 0.3342061936855316 0.7103018164634705\n",
      "[Step 3067] Loss: 9.99e+07 0.33468523621559143 0.7104874849319458\n",
      "[Step 3068] Loss: 1.01e+08 0.3350519835948944 0.7106360197067261\n",
      "[Step 3069] Loss: 1.01e+08 0.33543860912323 0.7107861638069153\n",
      "[Step 3070] Loss: 1.01e+08 0.3359166979789734 0.7110147476196289\n",
      "[Step 3071] Loss: 1.03e+08 0.3362080454826355 0.7111104726791382\n",
      "[Step 3072] Loss: 1.02e+08 0.3365945518016815 0.7112317681312561\n",
      "[Step 3073] Loss: 1.02e+08 0.33709052205085754 0.7114405035972595\n",
      "[Step 3074] Loss: 1.01e+08 0.3376252055168152 0.7117169499397278\n",
      "[Step 3075] Loss: 1.00e+08 0.33814752101898193 0.7119323015213013\n",
      "[Step 3076] Loss: 1.00e+08 0.33869025111198425 0.7122120261192322\n",
      "[Step 3077] Loss: 1.01e+08 0.33927369117736816 0.7125049233436584\n",
      "[Step 3078] Loss: 1.01e+08 0.33985626697540283 0.7127343416213989\n",
      "[Step 3079] Loss: 1.01e+08 0.34037014842033386 0.7129101157188416\n",
      "[Step 3080] Loss: 1.00e+08 0.3409242033958435 0.7131386399269104\n",
      "[Step 3081] Loss: 1.01e+08 0.34153321385383606 0.713368833065033\n",
      "[Step 3082] Loss: 1.01e+08 0.3421594798564911 0.713631272315979\n",
      "[Step 3083] Loss: 1.01e+08 0.3427779972553253 0.7139621376991272\n",
      "[Step 3084] Loss: 9.98e+07 0.34334826469421387 0.7142360806465149\n",
      "[Step 3085] Loss: 1.01e+08 0.3438597023487091 0.7144481539726257\n",
      "[Step 3086] Loss: 1.00e+08 0.34441041946411133 0.7146791815757751\n",
      "[Step 3087] Loss: 9.97e+07 0.3449830710887909 0.7149605751037598\n",
      "[Step 3088] Loss: 1.00e+08 0.34563878178596497 0.7153095602989197\n",
      "[Step 3089] Loss: 1.01e+08 0.34610551595687866 0.7154721617698669\n",
      "[Step 3090] Loss: 1.00e+08 0.3465602695941925 0.7156776189804077\n",
      "[Step 3091] Loss: 1.01e+08 0.34715038537979126 0.715939998626709\n",
      "[Step 3092] Loss: 1.01e+08 0.34779393672943115 0.716212272644043\n",
      "[Step 3093] Loss: 1.01e+08 0.3483102023601532 0.7164284586906433\n",
      "[Step 3094] Loss: 1.01e+08 0.34886208176612854 0.7166471481323242\n",
      "[Step 3095] Loss: 1.01e+08 0.34949949383735657 0.7169771790504456\n",
      "[Step 3096] Loss: 1.00e+08 0.3500860631465912 0.7172247171401978\n",
      "[Step 3097] Loss: 1.01e+08 0.3506876826286316 0.7175284028053284\n",
      "[Step 3098] Loss: 1.00e+08 0.35129010677337646 0.7177891135215759\n",
      "[Step 3099] Loss: 1.01e+08 0.35194504261016846 0.7181076407432556\n",
      "[Step 3100] Loss: 1.00e+08 0.3525921404361725 0.7184095978736877\n",
      "[Step 3101] Loss: 1.01e+08 0.3533385097980499 0.7187644243240356\n",
      "[Step 3102] Loss: 1.01e+08 0.3539104759693146 0.7190433144569397\n",
      "[Step 3103] Loss: 1.00e+08 0.3545123338699341 0.7193205952644348\n",
      "[Step 3104] Loss: 9.95e+07 0.35504692792892456 0.7195730805397034\n",
      "[Step 3105] Loss: 9.97e+07 0.35553258657455444 0.7197801470756531\n",
      "[Step 3106] Loss: 1.01e+08 0.35593846440315247 0.7199138402938843\n",
      "[Step 3107] Loss: 1.01e+08 0.3561854660511017 0.7199295163154602\n",
      "[Step 3108] Loss: 1.01e+08 0.35634347796440125 0.7199105620384216\n",
      "[Step 3109] Loss: 1.00e+08 0.3565453886985779 0.7198899388313293\n",
      "[Step 3110] Loss: 1.02e+08 0.3567447066307068 0.7199006676673889\n",
      "[Step 3111] Loss: 1.00e+08 0.35691574215888977 0.7198857665061951\n",
      "[Step 3112] Loss: 1.00e+08 0.357205867767334 0.719937801361084\n",
      "[Step 3113] Loss: 1.01e+08 0.35742685198783875 0.719915509223938\n",
      "[Step 3114] Loss: 1.01e+08 0.35775235295295715 0.7199881076812744\n",
      "[Step 3115] Loss: 1.01e+08 0.3579906225204468 0.7200747728347778\n",
      "[Step 3116] Loss: 9.97e+07 0.35820630192756653 0.7200829982757568\n",
      "[Step 3117] Loss: 1.00e+08 0.35836827754974365 0.7200343012809753\n",
      "[Step 3118] Loss: 1.01e+08 0.35852256417274475 0.7200078964233398\n",
      "[Step 3119] Loss: 1.01e+08 0.3586476445198059 0.7200005054473877\n",
      "[Step 3120] Loss: 1.01e+08 0.35882896184921265 0.7200078964233398\n",
      "[Step 3121] Loss: 1.01e+08 0.3591515123844147 0.720141589641571\n",
      "[Step 3122] Loss: 1.00e+08 0.35946905612945557 0.7202513217926025\n",
      "[Step 3123] Loss: 1.02e+08 0.35980209708213806 0.7203932404518127\n",
      "[Step 3124] Loss: 1.01e+08 0.3600858151912689 0.7204312086105347\n",
      "[Step 3125] Loss: 1.01e+08 0.36038103699684143 0.7204897999763489\n",
      "[Step 3126] Loss: 1.01e+08 0.3607584536075592 0.7206366658210754\n",
      "[Step 3127] Loss: 1.01e+08 0.36110809445381165 0.7207381725311279\n",
      "[Step 3128] Loss: 1.00e+08 0.36143216490745544 0.7208240032196045\n",
      "[Step 3129] Loss: 1.02e+08 0.3616701662540436 0.7208726406097412\n",
      "[Step 3130] Loss: 9.98e+07 0.3620366156101227 0.7209939360618591\n",
      "[Step 3131] Loss: 1.00e+08 0.3623899817466736 0.7211589813232422\n",
      "[Step 3132] Loss: 1.01e+08 0.3627249002456665 0.7212538719177246\n",
      "[Step 3133] Loss: 1.01e+08 0.36311620473861694 0.7213900089263916\n",
      "[Step 3134] Loss: 1.01e+08 0.36341506242752075 0.721462607383728\n",
      "[Step 3135] Loss: 1.02e+08 0.3639155626296997 0.7216936945915222\n",
      "[Step 3136] Loss: 1.01e+08 0.36438465118408203 0.7218942046165466\n",
      "[Step 3137] Loss: 1.00e+08 0.3648342490196228 0.7221119999885559\n",
      "[Step 3138] Loss: 1.01e+08 0.3652883470058441 0.722314178943634\n",
      "[Step 3139] Loss: 1.01e+08 0.3656657934188843 0.7224288582801819\n",
      "[Step 3140] Loss: 1.02e+08 0.3658052682876587 0.7223942279815674\n",
      "[Step 3141] Loss: 1.01e+08 0.36600494384765625 0.72239750623703\n",
      "[Step 3142] Loss: 1.01e+08 0.3662411868572235 0.7223702669143677\n",
      "[Step 3143] Loss: 1.01e+08 0.36644574999809265 0.7223942279815674\n",
      "[Step 3144] Loss: 1.00e+08 0.3667011260986328 0.7224445343017578\n",
      "[Step 3145] Loss: 1.00e+08 0.36695072054862976 0.7224676609039307\n",
      "[Step 3146] Loss: 9.98e+07 0.36723360419273376 0.7225881218910217\n",
      "[Step 3147] Loss: 1.00e+08 0.36758872866630554 0.7226623892784119\n",
      "[Step 3148] Loss: 9.99e+07 0.3679840862751007 0.7227762341499329\n",
      "[Step 3149] Loss: 1.01e+08 0.36836203932762146 0.7228769063949585\n",
      "[Step 3150] Loss: 1.01e+08 0.36879244446754456 0.7229908108711243\n",
      "[Step 3151] Loss: 1.00e+08 0.3691253960132599 0.7230848670005798\n",
      "[Step 3152] Loss: 1.01e+08 0.3695663809776306 0.7231913208961487\n",
      "[Step 3153] Loss: 1.00e+08 0.36997827887535095 0.723301887512207\n",
      "[Step 3154] Loss: 1.00e+08 0.3704102337360382 0.7234264612197876\n",
      "[Step 3155] Loss: 1.01e+08 0.3708009421825409 0.7235469222068787\n",
      "[Step 3156] Loss: 1.01e+08 0.3710913360118866 0.7235922813415527\n",
      "[Step 3157] Loss: 1.00e+08 0.3713046610355377 0.7235906720161438\n",
      "[Step 3158] Loss: 1.00e+08 0.37147727608680725 0.7235634326934814\n",
      "[Step 3159] Loss: 9.98e+07 0.37174198031425476 0.7236121296882629\n",
      "[Step 3160] Loss: 1.01e+08 0.37202581763267517 0.7236517071723938\n",
      "[Step 3161] Loss: 1.00e+08 0.3723524808883667 0.7237334251403809\n",
      "[Step 3162] Loss: 9.95e+07 0.3727036714553833 0.7238736748695374\n",
      "[Step 3163] Loss: 1.01e+08 0.37302136421203613 0.7239603400230408\n",
      "[Step 3164] Loss: 1.01e+08 0.3733743131160736 0.7240973114967346\n",
      "[Step 3165] Loss: 1.01e+08 0.3736680746078491 0.7241649627685547\n",
      "[Step 3166] Loss: 9.95e+07 0.37404143810272217 0.7243250608444214\n",
      "[Step 3167] Loss: 1.01e+08 0.3743506669998169 0.7243852615356445\n",
      "[Step 3168] Loss: 1.01e+08 0.3748319745063782 0.7245610356330872\n",
      "[Step 3169] Loss: 1.00e+08 0.37540796399116516 0.7247903943061829\n",
      "[Step 3170] Loss: 1.00e+08 0.37596946954727173 0.7250577807426453\n",
      "[Step 3171] Loss: 1.00e+08 0.3766472339630127 0.725429892539978\n",
      "[Step 3172] Loss: 1.00e+08 0.3773292601108551 0.7257475852966309\n",
      "[Step 3173] Loss: 1.01e+08 0.37800487875938416 0.7260949611663818\n",
      "[Step 3174] Loss: 9.93e+07 0.37863364815711975 0.7264043688774109\n",
      "[Step 3175] Loss: 1.01e+08 0.3792251646518707 0.7266494631767273\n",
      "[Step 3176] Loss: 1.00e+08 0.37987130880355835 0.7269431948661804\n",
      "[Step 3177] Loss: 1.00e+08 0.380541056394577 0.7272624969482422\n",
      "[Step 3178] Loss: 1.00e+08 0.38108208775520325 0.7275307178497314\n",
      "[Step 3179] Loss: 1.00e+08 0.3817335069179535 0.7278112173080444\n",
      "[Step 3180] Loss: 1.00e+08 0.38230621814727783 0.7280430793762207\n",
      "[Step 3181] Loss: 1.01e+08 0.38286322355270386 0.7282658815383911\n",
      "[Step 3182] Loss: 1.01e+08 0.38350892066955566 0.7285414934158325\n",
      "[Step 3183] Loss: 1.00e+08 0.3841441869735718 0.7287560105323792\n",
      "[Step 3184] Loss: 9.97e+07 0.3848656415939331 0.7290679216384888\n",
      "[Step 3185] Loss: 1.01e+08 0.3856455981731415 0.7294028997421265\n",
      "[Step 3186] Loss: 9.99e+07 0.3863814175128937 0.7297272086143494\n",
      "[Step 3187] Loss: 9.90e+07 0.38707971572875977 0.7300060987472534\n",
      "[Step 3188] Loss: 9.94e+07 0.3877333700656891 0.7302750945091248\n",
      "[Step 3189] Loss: 9.93e+07 0.3882613778114319 0.7304665446281433\n",
      "[Step 3190] Loss: 1.00e+08 0.3888426125049591 0.7307033538818359\n",
      "[Step 3191] Loss: 1.01e+08 0.38949382305145264 0.7309467792510986\n",
      "[Step 3192] Loss: 1.01e+08 0.3901379704475403 0.7311918139457703\n",
      "[Step 3193] Loss: 9.95e+07 0.3907667100429535 0.7313865423202515\n",
      "[Step 3194] Loss: 1.01e+08 0.3912755846977234 0.7315202355384827\n",
      "[Step 3195] Loss: 1.01e+08 0.3917655050754547 0.7316703796386719\n",
      "[Step 3196] Loss: 1.01e+08 0.39224401116371155 0.7318519353866577\n",
      "[Step 3197] Loss: 1.00e+08 0.39276832342147827 0.7319831252098083\n",
      "[Step 3198] Loss: 1.00e+08 0.3933311104774475 0.7321374416351318\n",
      "[Step 3199] Loss: 1.00e+08 0.3938089609146118 0.7323379516601562\n",
      "[Step 3200] Loss: 1.01e+08 0.3943208158016205 0.7325533032417297\n",
      "[Step 3201] Loss: 1.00e+08 0.39482349157333374 0.7327274084091187\n",
      "[Step 3202] Loss: 1.01e+08 0.3952963054180145 0.7328833341598511\n",
      "[Step 3203] Loss: 1.01e+08 0.39590492844581604 0.7331250905990601\n",
      "[Step 3204] Loss: 9.98e+07 0.3965139389038086 0.7334461212158203\n",
      "[Step 3205] Loss: 1.01e+08 0.39699262380599976 0.7336069941520691\n",
      "[Step 3206] Loss: 1.00e+08 0.3974741995334625 0.7337604761123657\n",
      "[Step 3207] Loss: 1.00e+08 0.39796847105026245 0.7339065074920654\n",
      "[Step 3208] Loss: 1.01e+08 0.3983539640903473 0.7340187430381775\n",
      "[Step 3209] Loss: 1.01e+08 0.3986037075519562 0.7340376973152161\n",
      "[Step 3210] Loss: 1.02e+08 0.3988317847251892 0.7340608239173889\n",
      "[Step 3211] Loss: 1.01e+08 0.39909595251083374 0.7340847253799438\n",
      "[Step 3212] Loss: 1.01e+08 0.3993752598762512 0.7341746687889099\n",
      "[Step 3213] Loss: 1.01e+08 0.3995564877986908 0.7341441512107849\n",
      "[Step 3214] Loss: 1.00e+08 0.39971715211868286 0.7341400384902954\n",
      "[Step 3215] Loss: 9.98e+07 0.39996153116226196 0.7341153025627136\n",
      "[Step 3216] Loss: 9.94e+07 0.40013203024864197 0.7340996265411377\n",
      "[Step 3217] Loss: 1.01e+08 0.40032628178596497 0.7341054081916809\n",
      "[Step 3218] Loss: 1.00e+08 0.4005519151687622 0.7341697216033936\n",
      "[Step 3219] Loss: 1.01e+08 0.4006606638431549 0.7341251969337463\n",
      "[Step 3220] Loss: 9.98e+07 0.40075844526290894 0.7340971231460571\n",
      "[Step 3221] Loss: 1.00e+08 0.400834858417511 0.7340211868286133\n",
      "[Step 3222] Loss: 1.01e+08 0.4007720351219177 0.7338768243789673\n",
      "[Step 3223] Loss: 9.97e+07 0.4007614254951477 0.7337480783462524\n",
      "[Step 3224] Loss: 1.00e+08 0.4008563458919525 0.7336722016334534\n",
      "[Step 3225] Loss: 9.96e+07 0.40102553367614746 0.7336424589157104\n",
      "[Step 3226] Loss: 1.00e+08 0.4011526107788086 0.733616054058075\n",
      "[Step 3227] Loss: 1.01e+08 0.40136027336120605 0.7336548566818237\n",
      "[Step 3228] Loss: 1.00e+08 0.40162450075149536 0.7336713671684265\n",
      "[Step 3229] Loss: 1.00e+08 0.40189552307128906 0.7336887121200562\n",
      "[Step 3230] Loss: 1.00e+08 0.40204691886901855 0.7336639165878296\n",
      "[Step 3231] Loss: 1.01e+08 0.4021446108818054 0.733614444732666\n",
      "[Step 3232] Loss: 9.98e+07 0.4022328853607178 0.73359215259552\n",
      "[Step 3233] Loss: 1.01e+08 0.40247902274131775 0.7336771488189697\n",
      "[Step 3234] Loss: 9.96e+07 0.40272748470306396 0.733758807182312\n",
      "[Step 3235] Loss: 1.01e+08 0.40309038758277893 0.7338702082633972\n",
      "[Step 3236] Loss: 1.01e+08 0.4034898579120636 0.7340063452720642\n",
      "[Step 3237] Loss: 1.00e+08 0.4038134813308716 0.734097957611084\n",
      "[Step 3238] Loss: 1.01e+08 0.40421262383461 0.7342192530632019\n",
      "[Step 3239] Loss: 1.00e+08 0.40475425124168396 0.7344478368759155\n",
      "[Step 3240] Loss: 1.01e+08 0.4053678810596466 0.7346804738044739\n",
      "[Step 3241] Loss: 1.00e+08 0.4059242606163025 0.7348727583885193\n",
      "[Step 3242] Loss: 1.01e+08 0.40648186206817627 0.7350683212280273\n",
      "[Step 3243] Loss: 1.00e+08 0.40699830651283264 0.7352490425109863\n",
      "[Step 3244] Loss: 1.01e+08 0.40772756934165955 0.7355518341064453\n",
      "[Step 3245] Loss: 1.00e+08 0.40830522775650024 0.7357333898544312\n",
      "[Step 3246] Loss: 1.01e+08 0.40893158316612244 0.7359297871589661\n",
      "[Step 3247] Loss: 1.00e+08 0.40958064794540405 0.7361566424369812\n",
      "[Step 3248] Loss: 1.02e+08 0.4101056456565857 0.7363448143005371\n",
      "[Step 3249] Loss: 1.01e+08 0.4106837809085846 0.73655766248703\n",
      "[Step 3250] Loss: 9.97e+07 0.4111708104610443 0.7367119789123535\n",
      "[Step 3251] Loss: 1.00e+08 0.4117128252983093 0.7369331121444702\n",
      "[Step 3252] Loss: 1.00e+08 0.41233453154563904 0.7371518015861511\n",
      "[Step 3253] Loss: 1.01e+08 0.41290074586868286 0.7373374700546265\n",
      "[Step 3254] Loss: 1.00e+08 0.4134864807128906 0.7375429272651672\n",
      "[Step 3255] Loss: 1.01e+08 0.4140641391277313 0.7377318739891052\n",
      "[Step 3256] Loss: 9.98e+07 0.41455382108688354 0.7379117608070374\n",
      "[Step 3257] Loss: 1.01e+08 0.41502606868743896 0.7380940914154053\n",
      "[Step 3258] Loss: 1.00e+08 0.41540178656578064 0.7381864786148071\n",
      "[Step 3259] Loss: 1.00e+08 0.4158129096031189 0.7382863759994507\n",
      "[Step 3260] Loss: 1.01e+08 0.4163656532764435 0.7384637594223022\n",
      "[Step 3261] Loss: 1.01e+08 0.41682568192481995 0.7386065125465393\n",
      "[Step 3262] Loss: 1.00e+08 0.41729822754859924 0.7387409806251526\n",
      "[Step 3263] Loss: 1.01e+08 0.41773056983947754 0.7388045191764832\n",
      "[Step 3264] Loss: 1.00e+08 0.4181459844112396 0.7389076948165894\n",
      "[Step 3265] Loss: 1.02e+08 0.41844263672828674 0.7389770150184631\n",
      "[Step 3266] Loss: 9.99e+07 0.41879454255104065 0.7390223741531372\n",
      "[Step 3267] Loss: 1.01e+08 0.4192250072956085 0.7391782999038696\n",
      "[Step 3268] Loss: 1.00e+08 0.4196205735206604 0.739295482635498\n",
      "[Step 3269] Loss: 9.95e+07 0.42002543807029724 0.7394407391548157\n",
      "[Step 3270] Loss: 1.00e+08 0.42044171690940857 0.7395743727684021\n",
      "[Step 3271] Loss: 1.00e+08 0.42073196172714233 0.7396412491798401\n",
      "[Step 3272] Loss: 1.01e+08 0.4211101830005646 0.7397443652153015\n",
      "[Step 3273] Loss: 1.00e+08 0.42145398259162903 0.7398417592048645\n",
      "[Step 3274] Loss: 1.01e+08 0.4217208921909332 0.7398903965950012\n",
      "[Step 3275] Loss: 1.01e+08 0.4220640957355499 0.7399828433990479\n",
      "[Step 3276] Loss: 9.96e+07 0.4224579930305481 0.7401346564292908\n",
      "[Step 3277] Loss: 1.03e+08 0.42263931035995483 0.7401643395423889\n",
      "[Step 3278] Loss: 1.00e+08 0.4227936863899231 0.740140438079834\n",
      "[Step 3279] Loss: 1.02e+08 0.42290860414505005 0.7400991916656494\n",
      "[Step 3280] Loss: 1.00e+08 0.4230044484138489 0.7400488257408142\n",
      "[Step 3281] Loss: 1.00e+08 0.42301496863365173 0.7399638295173645\n",
      "[Step 3282] Loss: 1.01e+08 0.42307010293006897 0.7399473786354065\n",
      "[Step 3283] Loss: 1.01e+08 0.4230455458164215 0.7398375868797302\n",
      "[Step 3284] Loss: 1.00e+08 0.42298176884651184 0.7397319674491882\n",
      "[Step 3285] Loss: 1.01e+08 0.4227985143661499 0.7395207285881042\n",
      "[Step 3286] Loss: 1.01e+08 0.4226298928260803 0.7392979860305786\n",
      "[Step 3287] Loss: 9.96e+07 0.4225182831287384 0.7391453385353088\n",
      "[Step 3288] Loss: 9.99e+07 0.42247235774993896 0.7389745116233826\n",
      "[Step 3289] Loss: 1.00e+08 0.4225273132324219 0.7389291524887085\n",
      "[Step 3290] Loss: 9.99e+07 0.42257511615753174 0.7388284802436829\n",
      "[Step 3291] Loss: 1.01e+08 0.4226633906364441 0.7387566566467285\n",
      "[Step 3292] Loss: 1.00e+08 0.42283692955970764 0.7386906743049622\n",
      "[Step 3293] Loss: 1.01e+08 0.4232064187526703 0.7387698888778687\n",
      "[Step 3294] Loss: 1.01e+08 0.423477441072464 0.73880535364151\n",
      "[Step 3295] Loss: 9.98e+07 0.4237907826900482 0.7388672232627869\n",
      "[Step 3296] Loss: 1.00e+08 0.424114465713501 0.7388705611228943\n",
      "[Step 3297] Loss: 1.00e+08 0.42446568608283997 0.7389646172523499\n",
      "[Step 3298] Loss: 1.00e+08 0.4248133897781372 0.7389968037605286\n",
      "[Step 3299] Loss: 9.89e+07 0.4252232313156128 0.7390809655189514\n",
      "[Step 3300] Loss: 1.00e+08 0.4256029725074768 0.7391329407691956\n",
      "[Step 3301] Loss: 1.00e+08 0.4259347915649414 0.7391634583473206\n",
      "[Step 3302] Loss: 1.01e+08 0.4263175427913666 0.7392138242721558\n",
      "[Step 3303] Loss: 9.94e+07 0.4267149865627289 0.7392682433128357\n",
      "[Step 3304] Loss: 9.98e+07 0.4271570146083832 0.7393656373023987\n",
      "[Step 3305] Loss: 9.99e+07 0.4276638627052307 0.7394886016845703\n",
      "[Step 3306] Loss: 1.00e+08 0.42815279960632324 0.7396271824836731\n",
      "[Step 3307] Loss: 1.00e+08 0.4286889433860779 0.7397394180297852\n",
      "[Step 3308] Loss: 1.01e+08 0.42927610874176025 0.7399432063102722\n",
      "[Step 3309] Loss: 1.00e+08 0.4299046993255615 0.7401528358459473\n",
      "[Step 3310] Loss: 1.00e+08 0.43049147725105286 0.7403252720832825\n",
      "[Step 3311] Loss: 1.01e+08 0.43092772364616394 0.7404770851135254\n",
      "[Step 3312] Loss: 1.00e+08 0.43138793110847473 0.740555465221405\n",
      "[Step 3313] Loss: 9.93e+07 0.4318951964378357 0.7407535314559937\n",
      "[Step 3314] Loss: 1.01e+08 0.4323381781578064 0.7409268021583557\n",
      "[Step 3315] Loss: 1.00e+08 0.43281131982803345 0.7410571575164795\n",
      "[Step 3316] Loss: 1.02e+08 0.433223158121109 0.7411239743232727\n",
      "[Step 3317] Loss: 1.01e+08 0.43367791175842285 0.7412271499633789\n",
      "[Step 3318] Loss: 1.01e+08 0.4340569078922272 0.7413063645362854\n",
      "[Step 3319] Loss: 1.01e+08 0.4344915449619293 0.7414721846580505\n",
      "[Step 3320] Loss: 1.00e+08 0.43498754501342773 0.7416669130325317\n",
      "[Step 3321] Loss: 1.00e+08 0.43549853563308716 0.7418105006217957\n",
      "[Step 3322] Loss: 1.00e+08 0.4358886480331421 0.741898775100708\n",
      "[Step 3323] Loss: 9.98e+07 0.4363226294517517 0.7420159578323364\n",
      "[Step 3324] Loss: 9.99e+07 0.43677574396133423 0.742162823677063\n",
      "[Step 3325] Loss: 9.95e+07 0.43711113929748535 0.7422453761100769\n",
      "[Step 3326] Loss: 1.01e+08 0.4373663365840912 0.7422593832015991\n",
      "[Step 3327] Loss: 9.98e+07 0.43763428926467896 0.7422816753387451\n",
      "[Step 3328] Loss: 1.00e+08 0.4377767741680145 0.7422519326210022\n",
      "[Step 3329] Loss: 9.99e+07 0.4379154145717621 0.7422040700912476\n",
      "[Step 3330] Loss: 1.00e+08 0.43815845251083374 0.7421801686286926\n",
      "[Step 3331] Loss: 1.00e+08 0.438402384519577 0.7421554327011108\n",
      "[Step 3332] Loss: 9.94e+07 0.43868014216423035 0.7421793341636658\n",
      "[Step 3333] Loss: 9.93e+07 0.43888890743255615 0.7421677708625793\n",
      "[Step 3334] Loss: 1.00e+08 0.4391629099845886 0.7422049045562744\n",
      "[Step 3335] Loss: 1.00e+08 0.439358115196228 0.742191731929779\n",
      "[Step 3336] Loss: 1.00e+08 0.43957602977752686 0.7421975135803223\n",
      "[Step 3337] Loss: 1.01e+08 0.4397442638874054 0.7421413660049438\n",
      "[Step 3338] Loss: 1.00e+08 0.4400061368942261 0.7421422004699707\n",
      "[Step 3339] Loss: 1.01e+08 0.44040629267692566 0.742222249507904\n",
      "[Step 3340] Loss: 1.00e+08 0.4407607316970825 0.7422395944595337\n",
      "[Step 3341] Loss: 1.01e+08 0.4409981667995453 0.7422090768814087\n",
      "[Step 3342] Loss: 9.93e+07 0.4412491023540497 0.7421966791152954\n",
      "[Step 3343] Loss: 1.00e+08 0.4415547251701355 0.7421966791152954\n",
      "[Step 3344] Loss: 1.01e+08 0.4418497085571289 0.7421842813491821\n",
      "[Step 3345] Loss: 1.01e+08 0.44197720289230347 0.7421256899833679\n",
      "[Step 3346] Loss: 1.01e+08 0.4421250522136688 0.7420258522033691\n",
      "[Step 3347] Loss: 1.01e+08 0.44221678376197815 0.7418938279151917\n",
      "[Step 3348] Loss: 1.00e+08 0.4423876404762268 0.7417758703231812\n",
      "[Step 3349] Loss: 9.99e+07 0.4425434470176697 0.7417263388633728\n",
      "[Step 3350] Loss: 9.95e+07 0.44275885820388794 0.741650402545929\n",
      "[Step 3351] Loss: 1.01e+08 0.4428862929344177 0.7415612936019897\n",
      "[Step 3352] Loss: 9.87e+07 0.44302594661712646 0.741468071937561\n",
      "[Step 3353] Loss: 9.90e+07 0.4432220757007599 0.7414169311523438\n",
      "[Step 3354] Loss: 1.00e+08 0.44342049956321716 0.741384744644165\n",
      "[Step 3355] Loss: 9.90e+07 0.4435974359512329 0.741317093372345\n",
      "[Step 3356] Loss: 9.99e+07 0.4437887668609619 0.7413046956062317\n",
      "[Step 3357] Loss: 9.99e+07 0.444027304649353 0.7412716746330261\n",
      "[Step 3358] Loss: 1.00e+08 0.44436153769493103 0.7413154244422913\n",
      "[Step 3359] Loss: 9.96e+07 0.44472870230674744 0.74140864610672\n",
      "[Step 3360] Loss: 1.01e+08 0.4451432526111603 0.7414523959159851\n",
      "[Step 3361] Loss: 9.96e+07 0.44564956426620483 0.741626501083374\n",
      "[Step 3362] Loss: 9.98e+07 0.4461807608604431 0.7417288422584534\n",
      "[Step 3363] Loss: 1.01e+08 0.44678443670272827 0.7419251799583435\n",
      "[Step 3364] Loss: 9.93e+07 0.44737523794174194 0.7420827746391296\n",
      "[Step 3365] Loss: 1.00e+08 0.4479592740535736 0.7422618865966797\n",
      "[Step 3366] Loss: 9.99e+07 0.44853878021240234 0.7424722909927368\n",
      "[Step 3367] Loss: 9.93e+07 0.44914618134498596 0.7426546216011047\n",
      "[Step 3368] Loss: 9.95e+07 0.44968903064727783 0.7428278923034668\n",
      "[Step 3369] Loss: 9.99e+07 0.4502570331096649 0.7430251240730286\n",
      "[Step 3370] Loss: 1.00e+08 0.4508597254753113 0.7431893348693848\n",
      "[Step 3371] Loss: 1.01e+08 0.4513346552848816 0.7433246374130249\n",
      "[Step 3372] Loss: 1.01e+08 0.45166686177253723 0.7433576583862305\n",
      "[Step 3373] Loss: 1.00e+08 0.45193958282470703 0.7433510422706604\n",
      "[Step 3374] Loss: 1.01e+08 0.4520952105522156 0.7432850003242493\n",
      "[Step 3375] Loss: 9.98e+07 0.45226359367370605 0.7432528734207153\n",
      "[Step 3376] Loss: 1.00e+08 0.4524258077144623 0.7432190179824829\n",
      "[Step 3377] Loss: 9.88e+07 0.4526299238204956 0.7432330250740051\n",
      "[Step 3378] Loss: 9.97e+07 0.4527831971645355 0.7431389689445496\n",
      "[Step 3379] Loss: 9.93e+07 0.4529331922531128 0.7430828809738159\n",
      "[Step 3380] Loss: 9.98e+07 0.4530738890171051 0.7430663704872131\n",
      "[Step 3381] Loss: 9.95e+07 0.45320719480514526 0.7429789304733276\n",
      "[Step 3382] Loss: 1.01e+08 0.4533751606941223 0.7429607510566711\n",
      "[Step 3383] Loss: 9.97e+07 0.45348381996154785 0.7428724765777588\n",
      "[Step 3384] Loss: 1.00e+08 0.45373111963272095 0.7428740859031677\n",
      "[Step 3385] Loss: 9.98e+07 0.45394179224967957 0.7428905963897705\n",
      "[Step 3386] Loss: 1.00e+08 0.4541672468185425 0.7428807020187378\n",
      "[Step 3387] Loss: 1.01e+08 0.4542757570743561 0.7428006529808044\n",
      "[Step 3388] Loss: 1.00e+08 0.45435744524002075 0.7427495121955872\n",
      "[Step 3389] Loss: 1.00e+08 0.45462003350257874 0.7427668571472168\n",
      "[Step 3390] Loss: 9.96e+07 0.45491310954093933 0.742825448513031\n",
      "[Step 3391] Loss: 1.00e+08 0.45513027906417847 0.7427899241447449\n",
      "[Step 3392] Loss: 9.96e+07 0.4553915560245514 0.7427907586097717\n",
      "[Step 3393] Loss: 1.00e+08 0.4555463492870331 0.7427156567573547\n",
      "[Step 3394] Loss: 9.97e+07 0.45566990971565247 0.7426925897598267\n",
      "[Step 3395] Loss: 9.96e+07 0.4558982849121094 0.742682695388794\n",
      "[Step 3396] Loss: 9.91e+07 0.4561394155025482 0.7426777482032776\n",
      "[Step 3397] Loss: 9.94e+07 0.45639336109161377 0.7426925897598267\n",
      "[Step 3398] Loss: 1.00e+08 0.45665210485458374 0.7427065968513489\n",
      "[Step 3399] Loss: 9.99e+07 0.4570198953151703 0.7428097724914551\n",
      "[Step 3400] Loss: 1.00e+08 0.4573374092578888 0.7428419589996338\n",
      "[Step 3401] Loss: 9.95e+07 0.4577046036720276 0.7428955435752869\n",
      "[Step 3402] Loss: 1.01e+08 0.45810455083847046 0.7430019974708557\n",
      "[Step 3403] Loss: 1.01e+08 0.4584072232246399 0.7430152297019958\n",
      "[Step 3404] Loss: 9.95e+07 0.45879462361335754 0.7431117296218872\n",
      "[Step 3405] Loss: 9.91e+07 0.45923563838005066 0.7432132363319397\n",
      "[Step 3406] Loss: 1.00e+08 0.45978179574012756 0.7433774471282959\n",
      "[Step 3407] Loss: 1.01e+08 0.4602021872997284 0.7434921264648438\n",
      "[Step 3408] Loss: 1.00e+08 0.4604843258857727 0.7435457706451416\n",
      "[Step 3409] Loss: 1.00e+08 0.46077850461006165 0.743579626083374\n",
      "[Step 3410] Loss: 9.96e+07 0.46114322543144226 0.7436588406562805\n",
      "[Step 3411] Loss: 1.00e+08 0.46155089139938354 0.7437223792076111\n",
      "[Step 3412] Loss: 9.97e+07 0.4619605541229248 0.7438023686408997\n",
      "[Step 3413] Loss: 9.97e+07 0.4624711275100708 0.7439839243888855\n",
      "[Step 3414] Loss: 1.01e+08 0.46299877762794495 0.7441670894622803\n",
      "[Step 3415] Loss: 1.02e+08 0.46367761492729187 0.7444088459014893\n",
      "[Step 3416] Loss: 9.97e+07 0.46435654163360596 0.7446316480636597\n",
      "[Step 3417] Loss: 1.01e+08 0.4650578200817108 0.7448503375053406\n",
      "[Step 3418] Loss: 1.01e+08 0.46578776836395264 0.7450863122940063\n",
      "[Step 3419] Loss: 1.00e+08 0.466532438993454 0.7453635334968567\n",
      "[Step 3420] Loss: 1.00e+08 0.46719470620155334 0.7456045150756836\n",
      "[Step 3421] Loss: 9.93e+07 0.46786069869995117 0.7457868456840515\n",
      "[Step 3422] Loss: 9.98e+07 0.46855682134628296 0.7460145950317383\n",
      "[Step 3423] Loss: 9.94e+07 0.4692378640174866 0.7462241649627686\n",
      "[Step 3424] Loss: 9.96e+07 0.4698231816291809 0.7463982701301575\n",
      "[Step 3425] Loss: 9.99e+07 0.47046637535095215 0.7465971112251282\n",
      "[Step 3426] Loss: 9.88e+07 0.4711166024208069 0.7468190789222717\n",
      "[Step 3427] Loss: 9.98e+07 0.4716693162918091 0.7470229268074036\n",
      "[Step 3428] Loss: 1.01e+08 0.4721902906894684 0.7471656203269958\n",
      "[Step 3429] Loss: 9.99e+07 0.472659170627594 0.7473158240318298\n",
      "[Step 3430] Loss: 1.00e+08 0.4729667603969574 0.7473587393760681\n",
      "[Step 3431] Loss: 1.00e+08 0.4732176959514618 0.7473529577255249\n",
      "[Step 3432] Loss: 1.00e+08 0.4734503924846649 0.7473108768463135\n",
      "[Step 3433] Loss: 9.99e+07 0.47374776005744934 0.7472984790802002\n",
      "[Step 3434] Loss: 9.93e+07 0.4740297496318817 0.7472836375236511\n",
      "[Step 3435] Loss: 9.99e+07 0.47426819801330566 0.7472712397575378\n",
      "[Step 3436] Loss: 1.00e+08 0.4744258522987366 0.7471755743026733\n",
      "[Step 3437] Loss: 9.87e+07 0.47463756799697876 0.7470930218696594\n",
      "[Step 3438] Loss: 1.00e+08 0.47488051652908325 0.747073233127594\n",
      "[Step 3439] Loss: 9.91e+07 0.4751054048538208 0.747020423412323\n",
      "[Step 3440] Loss: 1.00e+08 0.4752252697944641 0.7469040751457214\n",
      "[Step 3441] Loss: 1.00e+08 0.4752289056777954 0.7467349171638489\n",
      "[Step 3442] Loss: 9.89e+07 0.47524094581604004 0.7465377449989319\n",
      "[Step 3443] Loss: 1.00e+08 0.47524935007095337 0.746325671672821\n",
      "[Step 3444] Loss: 9.98e+07 0.4752426743507385 0.7461284399032593\n",
      "[Step 3445] Loss: 1.00e+08 0.47525012493133545 0.7459633946418762\n",
      "[Step 3446] Loss: 1.00e+08 0.4753580093383789 0.7458008527755737\n",
      "[Step 3447] Loss: 9.95e+07 0.47561967372894287 0.7457166910171509\n",
      "[Step 3448] Loss: 1.01e+08 0.4759719669818878 0.7457191944122314\n",
      "[Step 3449] Loss: 9.97e+07 0.47634589672088623 0.7456960678100586\n",
      "[Step 3450] Loss: 9.99e+07 0.47669297456741333 0.7456977367401123\n",
      "[Step 3451] Loss: 9.97e+07 0.4770118296146393 0.7457109093666077\n",
      "[Step 3452] Loss: 1.00e+08 0.47736236453056335 0.7457142472267151\n",
      "[Step 3453] Loss: 1.00e+08 0.47769173979759216 0.7457414865493774\n",
      "[Step 3454] Loss: 1.00e+08 0.47806859016418457 0.7457472085952759\n",
      "[Step 3455] Loss: 1.00e+08 0.47848665714263916 0.7458074688911438\n",
      "[Step 3456] Loss: 9.98e+07 0.47889530658721924 0.7458710074424744\n",
      "[Step 3457] Loss: 1.00e+08 0.4794222116470337 0.7459931373596191\n",
      "[Step 3458] Loss: 1.00e+08 0.4799284338951111 0.7461110949516296\n",
      "[Step 3459] Loss: 1.00e+08 0.4803963005542755 0.7462348937988281\n",
      "[Step 3460] Loss: 1.01e+08 0.48095861077308655 0.7463916540145874\n",
      "[Step 3461] Loss: 1.00e+08 0.4814877510070801 0.7465344071388245\n",
      "[Step 3462] Loss: 9.99e+07 0.4820419251918793 0.7466722130775452\n",
      "[Step 3463] Loss: 9.98e+07 0.4825916290283203 0.7467712163925171\n",
      "[Step 3464] Loss: 9.99e+07 0.48316508531570435 0.7469494342803955\n",
      "[Step 3465] Loss: 1.00e+08 0.48360714316368103 0.7469940185546875\n",
      "[Step 3466] Loss: 9.92e+07 0.4840037226676941 0.7470493316650391\n",
      "[Step 3467] Loss: 9.94e+07 0.4844820201396942 0.7471351027488708\n",
      "[Step 3468] Loss: 1.00e+08 0.4849591851234436 0.7472299933433533\n",
      "[Step 3469] Loss: 1.00e+08 0.4854837656021118 0.7473463416099548\n",
      "[Step 3470] Loss: 9.91e+07 0.48602569103240967 0.7474445700645447\n",
      "[Step 3471] Loss: 9.98e+07 0.48654645681381226 0.7475559115409851\n",
      "[Step 3472] Loss: 9.97e+07 0.4870285391807556 0.7476475238800049\n",
      "[Step 3473] Loss: 9.94e+07 0.4875325858592987 0.7477011680603027\n",
      "[Step 3474] Loss: 9.99e+07 0.4879574179649353 0.7477613687515259\n",
      "[Step 3475] Loss: 1.01e+08 0.4882965683937073 0.7477836608886719\n",
      "[Step 3476] Loss: 1.00e+08 0.4887576103210449 0.7479099035263062\n",
      "[Step 3477] Loss: 9.99e+07 0.4891532063484192 0.7479396462440491\n",
      "[Step 3478] Loss: 1.00e+08 0.4896552562713623 0.7480006814002991\n",
      "[Step 3479] Loss: 1.00e+08 0.4901568293571472 0.7481343746185303\n",
      "[Step 3480] Loss: 1.00e+08 0.4906159043312073 0.748205304145813\n",
      "[Step 3481] Loss: 9.98e+07 0.4910120964050293 0.7482243180274963\n",
      "[Step 3482] Loss: 9.97e+07 0.49127623438835144 0.748174786567688\n",
      "[Step 3483] Loss: 1.01e+08 0.49139702320098877 0.7480716705322266\n",
      "[Step 3484] Loss: 1.00e+08 0.4914834499359131 0.7479544878005981\n",
      "[Step 3485] Loss: 1.00e+08 0.491578608751297 0.7478587627410889\n",
      "[Step 3486] Loss: 9.90e+07 0.49173375964164734 0.747805118560791\n",
      "[Step 3487] Loss: 1.00e+08 0.49195417761802673 0.74774569272995\n",
      "[Step 3488] Loss: 1.00e+08 0.492099404335022 0.7476780414581299\n",
      "[Step 3489] Loss: 9.93e+07 0.49224433302879333 0.7476516366004944\n",
      "[Step 3490] Loss: 1.00e+08 0.4924306571483612 0.7475699782371521\n",
      "[Step 3491] Loss: 9.98e+07 0.49263978004455566 0.7475088834762573\n",
      "[Step 3492] Loss: 9.98e+07 0.49299535155296326 0.74751877784729\n",
      "[Step 3493] Loss: 1.00e+08 0.4934142231941223 0.7475740909576416\n",
      "[Step 3494] Loss: 1.00e+08 0.4937385320663452 0.7475699782371521\n",
      "[Step 3495] Loss: 9.99e+07 0.49400249123573303 0.7475807070732117\n",
      "[Step 3496] Loss: 9.97e+07 0.4942610561847687 0.747556746006012\n",
      "[Step 3497] Loss: 9.96e+07 0.4944770932197571 0.7475419044494629\n",
      "[Step 3498] Loss: 1.00e+08 0.4947916269302368 0.7475278973579407\n",
      "[Step 3499] Loss: 9.98e+07 0.49520209431648254 0.7475757598876953\n",
      "[Step 3500] Loss: 9.97e+07 0.49567508697509766 0.7477192878723145\n",
      "[Step 3501] Loss: 9.97e+07 0.4961795210838318 0.7478405833244324\n",
      "[Step 3502] Loss: 1.00e+08 0.496597021818161 0.7479404807090759\n",
      "[Step 3503] Loss: 1.00e+08 0.49684038758277893 0.7479536533355713\n",
      "[Step 3504] Loss: 1.01e+08 0.4969448149204254 0.7479197978973389\n",
      "[Step 3505] Loss: 9.98e+07 0.4970516860485077 0.7478719353675842\n",
      "[Step 3506] Loss: 9.91e+07 0.49722835421562195 0.7478158473968506\n",
      "[Step 3507] Loss: 1.00e+08 0.4973793625831604 0.7477655410766602\n",
      "[Step 3508] Loss: 1.00e+08 0.49758121371269226 0.747737467288971\n",
      "[Step 3509] Loss: 9.99e+07 0.497794508934021 0.7477168440818787\n",
      "[Step 3510] Loss: 1.00e+08 0.4979379177093506 0.7476574182510376\n",
      "[Step 3511] Loss: 1.00e+08 0.4981045424938202 0.7476252317428589\n",
      "[Step 3512] Loss: 9.87e+07 0.4983639419078827 0.7476021647453308\n",
      "[Step 3513] Loss: 1.01e+08 0.4985028803348541 0.747556746006012\n",
      "[Step 3514] Loss: 1.01e+08 0.49858930706977844 0.7474775314331055\n",
      "[Step 3515] Loss: 1.00e+08 0.4986940026283264 0.7473620176315308\n",
      "[Step 3516] Loss: 1.00e+08 0.4987422227859497 0.7472299933433533\n",
      "[Step 3517] Loss: 1.00e+08 0.49871155619621277 0.7470657825469971\n",
      "[Step 3518] Loss: 9.99e+07 0.4987635314464569 0.7469849586486816\n",
      "[Step 3519] Loss: 9.90e+07 0.49887946248054504 0.7469106912612915\n",
      "[Step 3520] Loss: 1.01e+08 0.49909698963165283 0.7468686103820801\n",
      "[Step 3521] Loss: 9.97e+07 0.4993426203727722 0.7468306422233582\n",
      "[Step 3522] Loss: 1.00e+08 0.4994658827781677 0.746756374835968\n",
      "[Step 3523] Loss: 1.00e+08 0.49965700507164 0.746696949005127\n",
      "[Step 3524] Loss: 1.01e+08 0.4998927414417267 0.7466738820075989\n",
      "[Step 3525] Loss: 9.88e+07 0.500108003616333 0.7466391921043396\n",
      "[Step 3526] Loss: 9.96e+07 0.5003558993339539 0.7465847730636597\n",
      "[Step 3527] Loss: 1.01e+08 0.5006701946258545 0.746597945690155\n",
      "[Step 3528] Loss: 1.00e+08 0.5009652376174927 0.7466515898704529\n",
      "[Step 3529] Loss: 9.97e+07 0.5012304782867432 0.7466375827789307\n",
      "[Step 3530] Loss: 9.87e+07 0.5015807747840881 0.7467225193977356\n",
      "[Step 3531] Loss: 9.92e+07 0.5019335746765137 0.7467795014381409\n",
      "[Step 3532] Loss: 1.01e+08 0.5022565126419067 0.7468050718307495\n",
      "[Step 3533] Loss: 1.00e+08 0.5025674700737 0.7468776702880859\n",
      "[Step 3534] Loss: 9.98e+07 0.5028923153877258 0.7469362616539001\n",
      "[Step 3535] Loss: 9.94e+07 0.5031108260154724 0.7469577193260193\n",
      "[Step 3536] Loss: 9.94e+07 0.5033286213874817 0.7469180822372437\n",
      "[Step 3537] Loss: 9.95e+07 0.5035057663917542 0.7468785047531128\n",
      "[Step 3538] Loss: 1.01e+08 0.5035603642463684 0.7467860579490662\n",
      "[Step 3539] Loss: 1.00e+08 0.503679096698761 0.7467217445373535\n",
      "[Step 3540] Loss: 9.97e+07 0.503748893737793 0.746613621711731\n",
      "[Step 3541] Loss: 1.01e+08 0.5037106275558472 0.7464337348937988\n",
      "[Step 3542] Loss: 9.94e+07 0.5037389993667603 0.7463173866271973\n",
      "[Step 3543] Loss: 9.97e+07 0.5037774443626404 0.7462340593338013\n",
      "[Step 3544] Loss: 1.01e+08 0.5038061141967773 0.7461490631103516\n",
      "[Step 3545] Loss: 9.98e+07 0.5039281845092773 0.7460888624191284\n",
      "[Step 3546] Loss: 1.00e+08 0.5041947960853577 0.7460747957229614\n",
      "[Step 3547] Loss: 1.01e+08 0.5043609738349915 0.7460079789161682\n",
      "[Step 3548] Loss: 1.00e+08 0.5045813322067261 0.7460054755210876\n",
      "[Step 3549] Loss: 9.98e+07 0.5046889185905457 0.7459394931793213\n",
      "[Step 3550] Loss: 9.98e+07 0.5048230886459351 0.7458718419075012\n",
      "[Step 3551] Loss: 9.94e+07 0.505003809928894 0.7458462715148926\n",
      "[Step 3552] Loss: 9.95e+07 0.5051336288452148 0.745753824710846\n",
      "[Step 3553] Loss: 9.92e+07 0.5053561329841614 0.7457117438316345\n",
      "[Step 3554] Loss: 1.01e+08 0.5054857134819031 0.7456383109092712\n",
      "[Step 3555] Loss: 1.00e+08 0.5055948495864868 0.7455830574035645\n",
      "[Step 3556] Loss: 1.00e+08 0.5058295130729675 0.7455459237098694\n",
      "[Step 3557] Loss: 1.00e+08 0.5061782598495483 0.745610237121582\n",
      "[Step 3558] Loss: 9.94e+07 0.5064932703971863 0.7456292510032654\n",
      "[Step 3559] Loss: 9.96e+07 0.5068717002868652 0.7457051277160645\n",
      "[Step 3560] Loss: 9.95e+07 0.5072238445281982 0.7457670569419861\n",
      "[Step 3561] Loss: 9.96e+07 0.5075018405914307 0.7458404898643494\n",
      "[Step 3562] Loss: 9.99e+07 0.5077292919158936 0.7458809018135071\n",
      "[Step 3563] Loss: 9.95e+07 0.508072018623352 0.7459073066711426\n",
      "[Step 3564] Loss: 1.00e+08 0.5084569454193115 0.7459848523139954\n",
      "[Step 3565] Loss: 9.92e+07 0.5087788105010986 0.7459774613380432\n",
      "[Step 3566] Loss: 9.91e+07 0.5091497302055359 0.7460682392120361\n",
      "[Step 3567] Loss: 1.00e+08 0.509580135345459 0.7461342215538025\n",
      "[Step 3568] Loss: 1.00e+08 0.5100200176239014 0.7461754679679871\n",
      "[Step 3569] Loss: 9.95e+07 0.5104258060455322 0.746242344379425\n",
      "[Step 3570] Loss: 1.01e+08 0.5107277035713196 0.7462761402130127\n",
      "[Step 3571] Loss: 9.95e+07 0.511081337928772 0.746296763420105\n",
      "[Step 3572] Loss: 1.00e+08 0.5114988684654236 0.7463091611862183\n",
      "[Step 3573] Loss: 9.98e+07 0.5119351148605347 0.7463603019714355\n",
      "[Step 3574] Loss: 1.00e+08 0.5123696327209473 0.746461808681488\n",
      "[Step 3575] Loss: 1.00e+08 0.512782633304596 0.7465071678161621\n",
      "[Step 3576] Loss: 1.00e+08 0.5131564736366272 0.7465583682060242\n",
      "[Step 3577] Loss: 9.95e+07 0.5134397745132446 0.7465162873268127\n",
      "[Step 3578] Loss: 9.89e+07 0.5137667655944824 0.7465352416038513\n",
      "[Step 3579] Loss: 9.99e+07 0.5140331983566284 0.7465096712112427\n",
      "[Step 3580] Loss: 9.98e+07 0.5143470764160156 0.746522068977356\n",
      "[Step 3581] Loss: 1.00e+08 0.514623761177063 0.7465113401412964\n",
      "[Step 3582] Loss: 9.91e+07 0.514872133731842 0.7465088367462158\n",
      "[Step 3583] Loss: 9.89e+07 0.515165388584137 0.7465236783027649\n",
      "[Step 3584] Loss: 9.90e+07 0.515350341796875 0.7465311288833618\n",
      "[Step 3585] Loss: 1.00e+08 0.5154879093170166 0.7464122772216797\n",
      "[Step 3586] Loss: 9.95e+07 0.5155372619628906 0.7462926506996155\n",
      "[Step 3587] Loss: 1.00e+08 0.5155692100524902 0.7461466193199158\n",
      "[Step 3588] Loss: 9.95e+07 0.515668511390686 0.7460575103759766\n",
      "[Step 3589] Loss: 1.01e+08 0.5158502459526062 0.7460038661956787\n",
      "[Step 3590] Loss: 1.00e+08 0.5159922242164612 0.7459848523139954\n",
      "[Step 3591] Loss: 9.94e+07 0.5160990357398987 0.7458916306495667\n",
      "[Step 3592] Loss: 9.86e+07 0.5162397623062134 0.7458858489990234\n",
      "[Step 3593] Loss: 9.91e+07 0.5164086818695068 0.7458495497703552\n",
      "[Step 3594] Loss: 9.98e+07 0.5166661143302917 0.7459229826927185\n",
      "[Step 3595] Loss: 9.96e+07 0.5169628262519836 0.745927095413208\n",
      "[Step 3596] Loss: 1.00e+08 0.517332911491394 0.7459782958030701\n",
      "[Step 3597] Loss: 9.88e+07 0.5176653265953064 0.7459948062896729\n",
      "[Step 3598] Loss: 1.03e+08 0.5177339315414429 0.7459469437599182\n",
      "[Step 3599] Loss: 1.00e+08 0.5177947878837585 0.7458248138427734\n",
      "[Step 3600] Loss: 9.84e+07 0.5179354548454285 0.7457818984985352\n",
      "[Step 3601] Loss: 9.96e+07 0.5181669592857361 0.745805025100708\n",
      "[Step 3602] Loss: 9.95e+07 0.5184370279312134 0.7458305954933167\n",
      "[Step 3603] Loss: 9.99e+07 0.518734335899353 0.7458471059799194\n",
      "[Step 3604] Loss: 9.95e+07 0.5191004872322083 0.7459155917167664\n",
      "[Step 3605] Loss: 9.98e+07 0.519524097442627 0.7459725141525269\n",
      "[Step 3606] Loss: 9.93e+07 0.5199243426322937 0.7460352182388306\n",
      "[Step 3607] Loss: 1.01e+08 0.52024906873703 0.7460740208625793\n",
      "[Step 3608] Loss: 9.95e+07 0.5205265283584595 0.7460723519325256\n",
      "[Step 3609] Loss: 1.00e+08 0.5208513140678406 0.7460723519325256\n",
      "[Step 3610] Loss: 1.00e+08 0.521137535572052 0.7460789680480957\n",
      "[Step 3611] Loss: 1.00e+08 0.5215021371841431 0.746130108833313\n",
      "[Step 3612] Loss: 1.01e+08 0.5219238996505737 0.7461622953414917\n",
      "[Step 3613] Loss: 9.99e+07 0.5223354697227478 0.7462266683578491\n",
      "[Step 3614] Loss: 1.00e+08 0.5226211547851562 0.7462076544761658\n",
      "[Step 3615] Loss: 9.99e+07 0.5229822993278503 0.7461812496185303\n",
      "[Step 3616] Loss: 1.00e+08 0.5233263969421387 0.7462010383605957\n",
      "[Step 3617] Loss: 9.97e+07 0.5236672759056091 0.7461969256401062\n",
      "[Step 3618] Loss: 9.98e+07 0.5239638090133667 0.7461944818496704\n",
      "[Step 3619] Loss: 9.81e+07 0.5242841243743896 0.7462415099143982\n",
      "[Step 3620] Loss: 9.92e+07 0.5245897769927979 0.746250569820404\n",
      "[Step 3621] Loss: 9.98e+07 0.5248360633850098 0.7462497353553772\n",
      "[Step 3622] Loss: 1.01e+08 0.5248265862464905 0.7461168766021729\n",
      "[Step 3623] Loss: 9.99e+07 0.5248157978057861 0.7460409998893738\n",
      "[Step 3624] Loss: 9.87e+07 0.5247825980186462 0.7459295988082886\n",
      "[Step 3625] Loss: 9.97e+07 0.5246831178665161 0.7457835674285889\n",
      "[Step 3626] Loss: 9.88e+07 0.5246227979660034 0.7456597685813904\n",
      "[Step 3627] Loss: 9.89e+07 0.5245670676231384 0.7455129027366638\n",
      "[Step 3628] Loss: 9.93e+07 0.5244380235671997 0.7453577518463135\n",
      "[Step 3629] Loss: 9.93e+07 0.5243366956710815 0.7451803684234619\n",
      "[Step 3630] Loss: 9.98e+07 0.5243211984634399 0.7450466752052307\n",
      "[Step 3631] Loss: 9.90e+07 0.5243099927902222 0.7449369430541992\n",
      "[Step 3632] Loss: 1.00e+08 0.5243135094642639 0.7448214292526245\n",
      "[Step 3633] Loss: 1.00e+08 0.5242735743522644 0.7446861267089844\n",
      "[Step 3634] Loss: 1.00e+08 0.524097740650177 0.7445103526115417\n",
      "[Step 3635] Loss: 9.96e+07 0.5240427255630493 0.7443907260894775\n",
      "[Step 3636] Loss: 1.00e+08 0.5240277647972107 0.7442446351051331\n",
      "[Step 3637] Loss: 9.96e+07 0.5239638090133667 0.7440953254699707\n",
      "[Step 3638] Loss: 9.98e+07 0.5238776206970215 0.7439137697219849\n",
      "[Step 3639] Loss: 9.91e+07 0.5238491892814636 0.7437537312507629\n",
      "[Step 3640] Loss: 9.92e+07 0.52388596534729 0.7436794638633728\n",
      "[Step 3641] Loss: 9.99e+07 0.524002730846405 0.7436051964759827\n",
      "[Step 3642] Loss: 1.00e+08 0.5242376923561096 0.7435696721076965\n",
      "[Step 3643] Loss: 9.98e+07 0.5244439244270325 0.7435342073440552\n",
      "[Step 3644] Loss: 9.97e+07 0.5246149897575378 0.7435275912284851\n",
      "[Step 3645] Loss: 9.99e+07 0.5248820781707764 0.7435762882232666\n",
      "[Step 3646] Loss: 1.00e+08 0.525078296661377 0.7434970736503601\n",
      "[Step 3647] Loss: 9.96e+07 0.5252635478973389 0.7434690594673157\n",
      "[Step 3648] Loss: 9.99e+07 0.5254214406013489 0.7434442639350891\n",
      "[Step 3649] Loss: 9.99e+07 0.5255671143531799 0.7434129118919373\n",
      "[Step 3650] Loss: 9.92e+07 0.5256315469741821 0.7433345317840576\n",
      "[Step 3651] Loss: 9.99e+07 0.5257353186607361 0.743256151676178\n",
      "[Step 3652] Loss: 9.93e+07 0.525818943977356 0.7431620955467224\n",
      "[Step 3653] Loss: 9.95e+07 0.5258904099464417 0.7430655360221863\n",
      "[Step 3654] Loss: 1.00e+08 0.5259321928024292 0.7429195046424866\n",
      "[Step 3655] Loss: 1.01e+08 0.5261361002922058 0.7428807020187378\n",
      "[Step 3656] Loss: 9.94e+07 0.5263448357582092 0.7428205013275146\n",
      "[Step 3657] Loss: 1.01e+08 0.5266963839530945 0.7428361773490906\n",
      "[Step 3658] Loss: 9.93e+07 0.5270820260047913 0.7428988814353943\n",
      "[Step 3659] Loss: 9.93e+07 0.5274273157119751 0.7429178357124329\n",
      "[Step 3660] Loss: 1.01e+08 0.5277554988861084 0.7429161667823792\n",
      "[Step 3661] Loss: 9.95e+07 0.5281062722206116 0.7428980469703674\n",
      "[Step 3662] Loss: 9.83e+07 0.5284574031829834 0.7429277300834656\n",
      "[Step 3663] Loss: 9.99e+07 0.5287665128707886 0.7429417967796326\n",
      "[Step 3664] Loss: 9.89e+07 0.5291030406951904 0.7429219484329224\n",
      "[Step 3665] Loss: 9.98e+07 0.529416561126709 0.7429236173629761\n",
      "[Step 3666] Loss: 9.98e+07 0.5297027826309204 0.7429195046424866\n",
      "[Step 3667] Loss: 9.92e+07 0.5299715995788574 0.7429244518280029\n",
      "[Step 3668] Loss: 1.01e+08 0.5302181243896484 0.7429186701774597\n",
      "[Step 3669] Loss: 9.92e+07 0.5304838418960571 0.7429590821266174\n",
      "[Step 3670] Loss: 9.96e+07 0.5308102369308472 0.7430176734924316\n",
      "[Step 3671] Loss: 1.00e+08 0.5310678482055664 0.7430077791213989\n",
      "[Step 3672] Loss: 1.00e+08 0.53126460313797 0.7429830431938171\n",
      "[Step 3673] Loss: 9.86e+07 0.531456708908081 0.7429607510566711\n",
      "[Step 3674] Loss: 1.00e+08 0.5317395329475403 0.7429747581481934\n",
      "[Step 3675] Loss: 1.00e+08 0.5320173501968384 0.7430135607719421\n",
      "[Step 3676] Loss: 9.98e+07 0.5322100520133972 0.7429854869842529\n",
      "[Step 3677] Loss: 1.01e+08 0.5321941375732422 0.7428303956985474\n",
      "[Step 3678] Loss: 1.00e+08 0.5321484804153442 0.742690920829773\n",
      "[Step 3679] Loss: 9.99e+07 0.5321208238601685 0.742569625377655\n",
      "[Step 3680] Loss: 9.96e+07 0.5321316719055176 0.7424425482749939\n",
      "[Step 3681] Loss: 9.93e+07 0.5321733951568604 0.7423666715621948\n",
      "[Step 3682] Loss: 1.00e+08 0.5321057438850403 0.7422354817390442\n",
      "[Step 3683] Loss: 1.00e+08 0.5319960117340088 0.7421166300773621\n",
      "[Step 3684] Loss: 1.01e+08 0.5318440794944763 0.7419021129608154\n",
      "[Step 3685] Loss: 9.98e+07 0.531595766544342 0.7416743636131287\n",
      "[Step 3686] Loss: 1.01e+08 0.5312390327453613 0.7413228750228882\n",
      "[Step 3687] Loss: 9.97e+07 0.5309067368507385 0.7410348653793335\n",
      "[Step 3688] Loss: 1.00e+08 0.5306710004806519 0.7407881617546082\n",
      "[Step 3689] Loss: 1.00e+08 0.5303893685340881 0.7405315637588501\n",
      "[Step 3690] Loss: 9.87e+07 0.5300630331039429 0.7403128743171692\n",
      "[Step 3691] Loss: 9.93e+07 0.5298017859458923 0.7400455474853516\n",
      "[Step 3692] Loss: 1.00e+08 0.5295144319534302 0.7397839426994324\n",
      "[Step 3693] Loss: 9.89e+07 0.5293562412261963 0.7396222352981567\n",
      "[Step 3694] Loss: 1.01e+08 0.5291403532028198 0.7394300103187561\n",
      "[Step 3695] Loss: 1.00e+08 0.5289453864097595 0.7392154335975647\n",
      "[Step 3696] Loss: 1.00e+08 0.5288031697273254 0.7390157580375671\n",
      "[Step 3697] Loss: 1.00e+08 0.5288304090499878 0.7388523817062378\n",
      "[Step 3698] Loss: 9.99e+07 0.5288373231887817 0.7386939525604248\n",
      "[Step 3699] Loss: 9.89e+07 0.5288373231887817 0.7385231852531433\n",
      "[Step 3700] Loss: 9.96e+07 0.5289291143417358 0.7384538650512695\n",
      "[Step 3701] Loss: 9.97e+07 0.5290806293487549 0.7383754849433899\n",
      "[Step 3702] Loss: 1.00e+08 0.5292108654975891 0.738307774066925\n",
      "[Step 3703] Loss: 1.01e+08 0.529412567615509 0.738321840763092\n",
      "[Step 3704] Loss: 9.98e+07 0.5295876860618591 0.7382706999778748\n",
      "[Step 3705] Loss: 9.99e+07 0.5296504497528076 0.7381988763809204\n",
      "[Step 3706] Loss: 9.98e+07 0.529735267162323 0.7381477355957031\n",
      "[Step 3707] Loss: 9.98e+07 0.5297831296920776 0.7380833625793457\n",
      "[Step 3708] Loss: 1.00e+08 0.5297256112098694 0.7379925847053528\n",
      "[Step 3709] Loss: 1.00e+08 0.5297491550445557 0.737906813621521\n",
      "[Step 3710] Loss: 9.94e+07 0.5298014879226685 0.737778902053833\n",
      "[Step 3711] Loss: 9.93e+07 0.5298970937728882 0.73768150806427\n",
      "[Step 3712] Loss: 9.98e+07 0.5299462676048279 0.7376105785369873\n",
      "[Step 3713] Loss: 1.00e+08 0.5299475789070129 0.7374653220176697\n",
      "[Step 3714] Loss: 9.91e+07 0.5299962759017944 0.737363874912262\n",
      "[Step 3715] Loss: 9.96e+07 0.5300402641296387 0.7372714281082153\n",
      "[Step 3716] Loss: 1.00e+08 0.5299917459487915 0.7371327877044678\n",
      "[Step 3717] Loss: 9.99e+07 0.5299146175384521 0.7369372248649597\n",
      "[Step 3718] Loss: 1.01e+08 0.5299397110939026 0.7368242144584656\n",
      "[Step 3719] Loss: 9.91e+07 0.5299422740936279 0.7366896867752075\n",
      "[Step 3720] Loss: 9.94e+07 0.5300061106681824 0.7366046905517578\n",
      "[Step 3721] Loss: 9.95e+07 0.5301087498664856 0.736520528793335\n",
      "[Step 3722] Loss: 9.95e+07 0.530249297618866 0.7364710569381714\n",
      "[Step 3723] Loss: 9.99e+07 0.5304164290428162 0.7364363670349121\n",
      "[Step 3724] Loss: 9.96e+07 0.530616819858551 0.736399233341217\n",
      "[Step 3725] Loss: 9.94e+07 0.5308101177215576 0.7363472580909729\n",
      "[Step 3726] Loss: 9.96e+07 0.5310001969337463 0.736315906047821\n",
      "[Step 3727] Loss: 1.00e+08 0.5311853289604187 0.7362779378890991\n",
      "[Step 3728] Loss: 1.00e+08 0.5314862132072449 0.7362886667251587\n",
      "[Step 3729] Loss: 1.00e+08 0.531791090965271 0.7363192439079285\n",
      "[Step 3730] Loss: 1.00e+08 0.532261848449707 0.7364298105239868\n",
      "[Step 3731] Loss: 9.90e+07 0.5327271819114685 0.7365213632583618\n",
      "[Step 3732] Loss: 9.93e+07 0.5332673192024231 0.7366600036621094\n",
      "[Step 3733] Loss: 9.92e+07 0.5338444113731384 0.7368060350418091\n",
      "[Step 3734] Loss: 9.86e+07 0.5343990325927734 0.7369042634963989\n",
      "[Step 3735] Loss: 9.97e+07 0.5348886251449585 0.7369925379753113\n",
      "[Step 3736] Loss: 9.96e+07 0.535250723361969 0.7370189428329468\n",
      "[Step 3737] Loss: 9.92e+07 0.5356137752532959 0.7370230555534363\n",
      "[Step 3738] Loss: 9.91e+07 0.5358946919441223 0.7369966506958008\n",
      "[Step 3739] Loss: 9.92e+07 0.5362106561660767 0.7370007634162903\n",
      "[Step 3740] Loss: 9.91e+07 0.5365129113197327 0.7369958162307739\n",
      "[Step 3741] Loss: 9.91e+07 0.5367282629013062 0.7369595170021057\n",
      "[Step 3742] Loss: 1.00e+08 0.5369541049003601 0.7369685769081116\n",
      "[Step 3743] Loss: 1.00e+08 0.5370901823043823 0.7369116544723511\n",
      "[Step 3744] Loss: 1.00e+08 0.537386417388916 0.7369356155395508\n",
      "[Step 3745] Loss: 9.94e+07 0.5377556681632996 0.7369455099105835\n",
      "[Step 3746] Loss: 9.94e+07 0.538109302520752 0.7369678020477295\n",
      "[Step 3747] Loss: 9.94e+07 0.5383797883987427 0.7369900345802307\n",
      "[Step 3748] Loss: 9.86e+07 0.5386295914649963 0.7369925379753113\n",
      "[Step 3749] Loss: 1.00e+08 0.5388533473014832 0.7369735836982727\n",
      "[Step 3750] Loss: 9.92e+07 0.5391573309898376 0.7369430065155029\n",
      "[Step 3751] Loss: 9.97e+07 0.5394374132156372 0.7369455099105835\n",
      "[Step 3752] Loss: 9.98e+07 0.5397878885269165 0.7369793057441711\n",
      "[Step 3753] Loss: 1.00e+08 0.5400179028511047 0.7369397282600403\n",
      "[Step 3754] Loss: 1.00e+08 0.5401923060417175 0.7369083762168884\n",
      "[Step 3755] Loss: 9.96e+07 0.5403987169265747 0.7369100451469421\n",
      "[Step 3756] Loss: 9.88e+07 0.5406098365783691 0.7368959784507751\n",
      "[Step 3757] Loss: 1.01e+08 0.5407463908195496 0.7368126511573792\n",
      "[Step 3758] Loss: 1.00e+08 0.5409287214279175 0.7368250489234924\n",
      "[Step 3759] Loss: 9.97e+07 0.5412124395370483 0.7368192672729492\n",
      "[Step 3760] Loss: 1.00e+08 0.5414746403694153 0.7368646264076233\n",
      "[Step 3761] Loss: 9.97e+07 0.5417808890342712 0.7368679642677307\n",
      "[Step 3762] Loss: 9.90e+07 0.5421368479728699 0.7369108200073242\n",
      "[Step 3763] Loss: 9.91e+07 0.5425169467926025 0.7370082139968872\n",
      "[Step 3764] Loss: 9.93e+07 0.5427889227867126 0.7370098829269409\n",
      "[Step 3765] Loss: 9.96e+07 0.5430914163589478 0.7370404005050659\n",
      "[Step 3766] Loss: 9.91e+07 0.5434401035308838 0.7371121644973755\n",
      "[Step 3767] Loss: 9.83e+07 0.5437755584716797 0.7371790409088135\n",
      "[Step 3768] Loss: 1.00e+08 0.5439667701721191 0.737183153629303\n",
      "[Step 3769] Loss: 1.00e+08 0.5442212224006653 0.737213671207428\n",
      "[Step 3770] Loss: 1.00e+08 0.5444750785827637 0.7372450232505798\n",
      "[Step 3771] Loss: 9.99e+07 0.544724702835083 0.7372194528579712\n",
      "[Step 3772] Loss: 1.00e+08 0.5450331568717957 0.7372095584869385\n",
      "[Step 3773] Loss: 9.94e+07 0.5452508926391602 0.7371616959571838\n",
      "[Step 3774] Loss: 1.00e+08 0.5452926158905029 0.737063467502594\n",
      "[Step 3775] Loss: 9.87e+07 0.5453184247016907 0.7369545698165894\n",
      "[Step 3776] Loss: 1.00e+08 0.5452651977539062 0.7368225455284119\n",
      "[Step 3777] Loss: 9.96e+07 0.5451793670654297 0.7366872429847717\n",
      "[Step 3778] Loss: 1.01e+08 0.5449455380439758 0.7364941239356995\n",
      "[Step 3779] Loss: 1.00e+08 0.5447455048561096 0.7362920045852661\n",
      "[Step 3780] Loss: 1.00e+08 0.5446374416351318 0.7361080050468445\n",
      "[Step 3781] Loss: 9.96e+07 0.5445796251296997 0.7359412908554077\n",
      "[Step 3782] Loss: 1.01e+08 0.5443095564842224 0.7357028722763062\n",
      "[Step 3783] Loss: 9.97e+07 0.5441160202026367 0.7354841828346252\n",
      "[Step 3784] Loss: 9.98e+07 0.5439428687095642 0.7353092432022095\n",
      "[Step 3785] Loss: 1.00e+08 0.543776273727417 0.7350988388061523\n",
      "[Step 3786] Loss: 9.86e+07 0.5436770915985107 0.7349511384963989\n",
      "[Step 3787] Loss: 9.95e+07 0.5435687899589539 0.7347853183746338\n",
      "[Step 3788] Loss: 1.00e+08 0.5435391664505005 0.7346549034118652\n",
      "[Step 3789] Loss: 1.00e+08 0.543402910232544 0.7344940304756165\n",
      "[Step 3790] Loss: 1.01e+08 0.5432261228561401 0.7343339323997498\n",
      "[Step 3791] Loss: 1.01e+08 0.5430040955543518 0.7341054081916809\n",
      "[Step 3792] Loss: 1.00e+08 0.542934238910675 0.7339659333229065\n",
      "[Step 3793] Loss: 1.00e+08 0.5430431365966797 0.7338826060295105\n",
      "[Step 3794] Loss: 9.88e+07 0.5431474447250366 0.7337992787361145\n",
      "[Step 3795] Loss: 9.81e+07 0.5433036088943481 0.7338272929191589\n",
      "[Step 3796] Loss: 9.98e+07 0.543402910232544 0.7337514162063599\n",
      "[Step 3797] Loss: 9.94e+07 0.5434705018997192 0.7336548566818237\n",
      "[Step 3798] Loss: 9.94e+07 0.5435325503349304 0.7335888147354126\n",
      "[Step 3799] Loss: 9.95e+07 0.5436323881149292 0.7335277795791626\n",
      "[Step 3800] Loss: 1.00e+08 0.5437330007553101 0.7334972620010376\n",
      "[Step 3801] Loss: 9.92e+07 0.543825626373291 0.7334056496620178\n",
      "[Step 3802] Loss: 9.96e+07 0.5439587235450745 0.7333478927612305\n",
      "[Step 3803] Loss: 9.90e+07 0.544169545173645 0.7333635687828064\n",
      "[Step 3804] Loss: 1.00e+08 0.5443968772888184 0.7333676815032959\n",
      "[Step 3805] Loss: 1.00e+08 0.5447121858596802 0.7334163784980774\n",
      "[Step 3806] Loss: 9.95e+07 0.544977068901062 0.7334197163581848\n",
      "[Step 3807] Loss: 9.93e+07 0.5451909899711609 0.7334056496620178\n",
      "[Step 3808] Loss: 9.93e+07 0.5453985333442688 0.7333817481994629\n",
      "[Step 3809] Loss: 9.92e+07 0.5455807447433472 0.7333124279975891\n",
      "[Step 3810] Loss: 9.99e+07 0.545677900314331 0.7332505583763123\n",
      "[Step 3811] Loss: 9.98e+07 0.5457404255867004 0.7331556677818298\n",
      "[Step 3812] Loss: 9.94e+07 0.5458074808120728 0.7330516576766968\n",
      "[Step 3813] Loss: 1.00e+08 0.5459911823272705 0.7329972386360168\n",
      "[Step 3814] Loss: 9.88e+07 0.5462135076522827 0.7329337000846863\n",
      "[Step 3815] Loss: 1.00e+08 0.5464183688163757 0.7329196333885193\n",
      "[Step 3816] Loss: 9.99e+07 0.5464807748794556 0.7328585982322693\n",
      "[Step 3817] Loss: 9.91e+07 0.5464971661567688 0.7327083945274353\n",
      "[Step 3818] Loss: 9.95e+07 0.5464614033699036 0.732567310333252\n",
      "[Step 3819] Loss: 9.91e+07 0.5464358329772949 0.7324163317680359\n",
      "[Step 3820] Loss: 9.99e+07 0.5464463829994202 0.732279360294342\n",
      "[Step 3821] Loss: 9.88e+07 0.5464438796043396 0.7321316599845886\n",
      "[Step 3822] Loss: 1.00e+08 0.5463168025016785 0.7319344282150269\n",
      "[Step 3823] Loss: 9.95e+07 0.5461233854293823 0.731714129447937\n",
      "[Step 3824] Loss: 1.00e+08 0.5460532307624817 0.731518566608429\n",
      "[Step 3825] Loss: 9.87e+07 0.5459312200546265 0.7313691973686218\n",
      "[Step 3826] Loss: 1.00e+08 0.5457956790924072 0.731148898601532\n",
      "[Step 3827] Loss: 9.90e+07 0.5457648038864136 0.7309855222702026\n",
      "[Step 3828] Loss: 9.96e+07 0.545742392539978 0.7308493852615356\n",
      "[Step 3829] Loss: 9.91e+07 0.545710027217865 0.7307371497154236\n",
      "[Step 3830] Loss: 1.00e+08 0.5456243753433228 0.730590283870697\n",
      "[Step 3831] Loss: 9.91e+07 0.5455129146575928 0.7304359674453735\n",
      "[Step 3832] Loss: 9.95e+07 0.5454064607620239 0.730303168296814\n",
      "[Step 3833] Loss: 1.00e+08 0.5452464818954468 0.7301092147827148\n",
      "[Step 3834] Loss: 9.96e+07 0.5451832413673401 0.7299384474754333\n",
      "[Step 3835] Loss: 9.93e+07 0.5451166033744812 0.7297329902648926\n",
      "[Step 3836] Loss: 9.96e+07 0.5450555682182312 0.7296207547187805\n",
      "[Step 3837] Loss: 9.93e+07 0.5450051426887512 0.7294977903366089\n",
      "[Step 3838] Loss: 9.95e+07 0.5450016260147095 0.729337751865387\n",
      "[Step 3839] Loss: 9.78e+07 0.545046865940094 0.7292510867118835\n",
      "[Step 3840] Loss: 9.99e+07 0.5450043678283691 0.7291248440742493\n",
      "[Step 3841] Loss: 9.85e+07 0.5449360013008118 0.7289994359016418\n",
      "[Step 3842] Loss: 9.89e+07 0.545015275478363 0.7289020419120789\n",
      "[Step 3843] Loss: 9.92e+07 0.5451973676681519 0.7288814187049866\n",
      "[Step 3844] Loss: 9.95e+07 0.5454500317573547 0.7289202213287354\n",
      "[Step 3845] Loss: 9.88e+07 0.5456629991531372 0.7288880348205566\n",
      "[Step 3846] Loss: 1.00e+08 0.5459829568862915 0.7288921475410461\n",
      "[Step 3847] Loss: 9.78e+07 0.5463066697120667 0.7289581894874573\n",
      "[Step 3848] Loss: 9.98e+07 0.5464902520179749 0.7289449572563171\n",
      "[Step 3849] Loss: 9.81e+07 0.5466627478599548 0.7289260029792786\n",
      "[Step 3850] Loss: 9.95e+07 0.5468929409980774 0.7289127707481384\n",
      "[Step 3851] Loss: 9.96e+07 0.5470297932624817 0.7288798093795776\n",
      "[Step 3852] Loss: 9.87e+07 0.5472034215927124 0.7288063764572144\n",
      "[Step 3853] Loss: 1.00e+08 0.5472001433372498 0.7287246584892273\n",
      "[Step 3854] Loss: 9.85e+07 0.5471637845039368 0.7286108136177063\n",
      "[Step 3855] Loss: 1.00e+08 0.54716557264328 0.7285134196281433\n",
      "[Step 3856] Loss: 9.95e+07 0.5470625162124634 0.7283475995063782\n",
      "[Step 3857] Loss: 1.00e+08 0.5470202565193176 0.7282081246376038\n",
      "[Step 3858] Loss: 9.96e+07 0.5469590425491333 0.7280703186988831\n",
      "[Step 3859] Loss: 9.86e+07 0.5469304323196411 0.7279490232467651\n",
      "[Step 3860] Loss: 9.89e+07 0.5468596816062927 0.72784423828125\n",
      "[Step 3861] Loss: 9.92e+07 0.5467718839645386 0.7276883125305176\n",
      "[Step 3862] Loss: 9.97e+07 0.5466722249984741 0.7275183200836182\n",
      "[Step 3863] Loss: 9.96e+07 0.5465474724769592 0.7273615598678589\n",
      "[Step 3864] Loss: 1.00e+08 0.5462755560874939 0.7271057367324829\n",
      "[Step 3865] Loss: 9.97e+07 0.5460695624351501 0.7269035577774048\n",
      "[Step 3866] Loss: 9.96e+07 0.5460272431373596 0.7267517447471619\n",
      "[Step 3867] Loss: 9.91e+07 0.5460865497589111 0.7266403436660767\n",
      "[Step 3868] Loss: 9.94e+07 0.5460665822029114 0.7264794707298279\n",
      "[Step 3869] Loss: 1.00e+08 0.546014666557312 0.7263036966323853\n",
      "[Step 3870] Loss: 9.87e+07 0.545921266078949 0.7261922955513\n",
      "[Step 3871] Loss: 9.90e+07 0.5458380579948425 0.7260215282440186\n",
      "[Step 3872] Loss: 9.98e+07 0.5458661913871765 0.7258738279342651\n",
      "[Step 3873] Loss: 9.91e+07 0.5458529591560364 0.7257351875305176\n",
      "[Step 3874] Loss: 9.95e+07 0.5459189414978027 0.725612223148346\n",
      "[Step 3875] Loss: 9.93e+07 0.5460737347602844 0.7255387902259827\n",
      "[Step 3876] Loss: 9.87e+07 0.5462974905967712 0.7255140542984009\n",
      "[Step 3877] Loss: 9.94e+07 0.5465397834777832 0.7254785895347595\n",
      "[Step 3878] Loss: 9.98e+07 0.5467628240585327 0.7254183292388916\n",
      "[Step 3879] Loss: 9.94e+07 0.5469989776611328 0.7253498435020447\n",
      "[Step 3880] Loss: 9.91e+07 0.5472484827041626 0.7253036499023438\n",
      "[Step 3881] Loss: 9.99e+07 0.5474798083305359 0.7252929210662842\n",
      "[Step 3882] Loss: 9.92e+07 0.5477427244186401 0.7252458930015564\n",
      "[Step 3883] Loss: 9.88e+07 0.5480104684829712 0.7252359986305237\n",
      "[Step 3884] Loss: 9.93e+07 0.5482770204544067 0.7252070903778076\n",
      "[Step 3885] Loss: 9.97e+07 0.548671305179596 0.7252450585365295\n",
      "[Step 3886] Loss: 9.85e+07 0.5490849614143372 0.7252838611602783\n",
      "[Step 3887] Loss: 9.91e+07 0.549494743347168 0.7253432273864746\n",
      "[Step 3888] Loss: 9.89e+07 0.5498022437095642 0.7253605723381042\n",
      "[Step 3889] Loss: 9.90e+07 0.5500807762145996 0.7253721356391907\n",
      "[Step 3890] Loss: 9.90e+07 0.5504289865493774 0.725438117980957\n",
      "[Step 3891] Loss: 9.94e+07 0.550769031047821 0.7254925966262817\n",
      "[Step 3892] Loss: 9.92e+07 0.5511377453804016 0.7255313992500305\n",
      "[Step 3893] Loss: 9.95e+07 0.5515360832214355 0.7255734801292419\n",
      "[Step 3894] Loss: 9.91e+07 0.5518617033958435 0.7255767583847046\n",
      "[Step 3895] Loss: 9.84e+07 0.5521989464759827 0.7255907654762268\n",
      "[Step 3896] Loss: 9.96e+07 0.5524248480796814 0.7255743145942688\n",
      "[Step 3897] Loss: 9.89e+07 0.5526415705680847 0.7255215048789978\n",
      "[Step 3898] Loss: 9.89e+07 0.5529109835624695 0.7255074381828308\n",
      "[Step 3899] Loss: 9.91e+07 0.5531705617904663 0.7255297303199768\n",
      "[Step 3900] Loss: 9.92e+07 0.5534493923187256 0.7255503535270691\n",
      "[Step 3901] Loss: 9.92e+07 0.5537359714508057 0.7255825400352478\n",
      "[Step 3902] Loss: 9.89e+07 0.5539938807487488 0.7255643606185913\n",
      "[Step 3903] Loss: 9.92e+07 0.55428147315979 0.7255528569221497\n",
      "[Step 3904] Loss: 9.97e+07 0.5545753836631775 0.7255215048789978\n",
      "[Step 3905] Loss: 9.96e+07 0.5547960996627808 0.7255140542984009\n",
      "[Step 3906] Loss: 9.90e+07 0.5549378991127014 0.7254620790481567\n",
      "[Step 3907] Loss: 9.95e+07 0.5550554990768433 0.725385308265686\n",
      "[Step 3908] Loss: 1.00e+08 0.5552129149436951 0.7253209948539734\n",
      "[Step 3909] Loss: 9.88e+07 0.5554038882255554 0.7252689599990845\n",
      "[Step 3910] Loss: 9.93e+07 0.5555599927902222 0.7252029776573181\n",
      "[Step 3911] Loss: 9.89e+07 0.5557340979576111 0.725128710269928\n",
      "[Step 3912] Loss: 9.90e+07 0.5559654235839844 0.7250569462776184\n",
      "[Step 3913] Loss: 9.94e+07 0.5561796426773071 0.7249892950057983\n",
      "[Step 3914] Loss: 9.88e+07 0.5564123392105103 0.7249513268470764\n",
      "[Step 3915] Loss: 9.94e+07 0.5566026568412781 0.7248795032501221\n",
      "[Step 3916] Loss: 1.00e+08 0.5566176772117615 0.7247095704078674\n",
      "[Step 3917] Loss: 1.01e+08 0.5564654469490051 0.7244826555252075\n",
      "[Step 3918] Loss: 9.98e+07 0.5563293099403381 0.7242895364761353\n",
      "[Step 3919] Loss: 9.92e+07 0.556145429611206 0.7240956425666809\n",
      "[Step 3920] Loss: 9.91e+07 0.5559992790222168 0.7238745093345642\n",
      "[Step 3921] Loss: 9.91e+07 0.5558618307113647 0.7237309217453003\n",
      "[Step 3922] Loss: 9.92e+07 0.5556507110595703 0.7235271334648132\n",
      "[Step 3923] Loss: 9.98e+07 0.5555992722511292 0.7234000563621521\n",
      "[Step 3924] Loss: 9.96e+07 0.5555591583251953 0.7232581377029419\n",
      "[Step 3925] Loss: 9.88e+07 0.5554998517036438 0.7231194972991943\n",
      "[Step 3926] Loss: 9.81e+07 0.555467426776886 0.7230163812637329\n",
      "[Step 3927] Loss: 9.84e+07 0.5554221868515015 0.7229313850402832\n",
      "[Step 3928] Loss: 9.89e+07 0.5554785132408142 0.7228983640670776\n",
      "[Step 3929] Loss: 9.91e+07 0.5555617213249207 0.7228397727012634\n",
      "[Step 3930] Loss: 9.94e+07 0.5557462573051453 0.7228447198867798\n",
      "[Step 3931] Loss: 9.94e+07 0.5559824705123901 0.7228876352310181\n",
      "[Step 3932] Loss: 1.00e+08 0.5562281012535095 0.7229297161102295\n",
      "[Step 3933] Loss: 9.94e+07 0.5565076470375061 0.7229520082473755\n",
      "[Step 3934] Loss: 9.93e+07 0.5568375587463379 0.7229891419410706\n",
      "[Step 3935] Loss: 9.96e+07 0.557176947593689 0.7230386137962341\n",
      "[Step 3936] Loss: 9.89e+07 0.5574473738670349 0.7231005430221558\n",
      "[Step 3937] Loss: 1.00e+08 0.5577383041381836 0.7231104373931885\n",
      "[Step 3938] Loss: 9.99e+07 0.5578387975692749 0.7230857014656067\n",
      "[Step 3939] Loss: 9.89e+07 0.557958722114563 0.7230724692344666\n",
      "[Step 3940] Loss: 1.00e+08 0.558128297328949 0.7230485677719116\n",
      "[Step 3941] Loss: 9.88e+07 0.558257520198822 0.7230163812637329\n",
      "[Step 3942] Loss: 1.00e+08 0.558306872844696 0.7229511737823486\n",
      "[Step 3943] Loss: 1.01e+08 0.5582131147384644 0.7228232622146606\n",
      "[Step 3944] Loss: 9.96e+07 0.5581990480422974 0.7226722836494446\n",
      "[Step 3945] Loss: 1.00e+08 0.5581024885177612 0.7225262522697449\n",
      "[Step 3946] Loss: 9.89e+07 0.558072566986084 0.7224041223526001\n",
      "[Step 3947] Loss: 9.93e+07 0.5580168962478638 0.7223092317581177\n",
      "[Step 3948] Loss: 9.95e+07 0.5579071640968323 0.7221285104751587\n",
      "[Step 3949] Loss: 9.98e+07 0.5577473044395447 0.7219874262809753\n",
      "[Step 3950] Loss: 9.96e+07 0.5576595067977905 0.7218413949012756\n",
      "[Step 3951] Loss: 9.96e+07 0.5574963092803955 0.7216994166374207\n",
      "[Step 3952] Loss: 9.86e+07 0.5573008060455322 0.7215245366096497\n",
      "[Step 3953] Loss: 9.93e+07 0.5571179986000061 0.7213479280471802\n",
      "[Step 3954] Loss: 9.92e+07 0.5570392608642578 0.72121262550354\n",
      "[Step 3955] Loss: 9.98e+07 0.556919515132904 0.7210360169410706\n",
      "[Step 3956] Loss: 9.88e+07 0.5568686127662659 0.7209039926528931\n",
      "[Step 3957] Loss: 9.89e+07 0.5567994713783264 0.7207670211791992\n",
      "[Step 3958] Loss: 9.94e+07 0.5567289590835571 0.7206763029098511\n",
      "[Step 3959] Loss: 9.99e+07 0.5568060874938965 0.7206003665924072\n",
      "[Step 3960] Loss: 9.85e+07 0.5569450259208679 0.7205541729927063\n",
      "[Step 3961] Loss: 9.89e+07 0.5570910573005676 0.7205343246459961\n",
      "[Step 3962] Loss: 9.85e+07 0.5572122931480408 0.7204865217208862\n",
      "[Step 3963] Loss: 9.84e+07 0.557375431060791 0.720474123954773\n",
      "[Step 3964] Loss: 9.94e+07 0.5576217174530029 0.7204749584197998\n",
      "[Step 3965] Loss: 9.95e+07 0.5577834844589233 0.7204691767692566\n",
      "[Step 3966] Loss: 9.96e+07 0.5578790307044983 0.7204419374465942\n",
      "[Step 3967] Loss: 9.96e+07 0.5581013560295105 0.7204922437667847\n",
      "[Step 3968] Loss: 9.95e+07 0.5583325624465942 0.7204559445381165\n",
      "[Step 3969] Loss: 9.91e+07 0.5585607886314392 0.7204906344413757\n",
      "[Step 3970] Loss: 9.95e+07 0.5587916374206543 0.7204617261886597\n",
      "[Step 3971] Loss: 9.94e+07 0.5589627623558044 0.7203586101531982\n",
      "[Step 3972] Loss: 9.84e+07 0.5591728091239929 0.7203577756881714\n",
      "[Step 3973] Loss: 9.92e+07 0.5593425035476685 0.7203206419944763\n",
      "[Step 3974] Loss: 9.96e+07 0.559448778629303 0.7202430963516235\n",
      "[Step 3975] Loss: 9.85e+07 0.5595420598983765 0.7201506495475769\n",
      "[Step 3976] Loss: 1.00e+08 0.5596935153007507 0.7201184630393982\n",
      "[Step 3977] Loss: 9.85e+07 0.5598558187484741 0.7200871109962463\n",
      "[Step 3978] Loss: 9.90e+07 0.5600606203079224 0.7200928926467896\n",
      "[Step 3979] Loss: 1.00e+08 0.560425341129303 0.7201581001281738\n",
      "[Step 3980] Loss: 9.97e+07 0.560725212097168 0.7201902866363525\n",
      "[Step 3981] Loss: 9.84e+07 0.560984194278717 0.7201952338218689\n",
      "[Step 3982] Loss: 9.87e+07 0.5612344145774841 0.7202067971229553\n",
      "[Step 3983] Loss: 9.91e+07 0.5615438222885132 0.7202364802360535\n",
      "[Step 3984] Loss: 9.93e+07 0.5617499351501465 0.7202884554862976\n",
      "[Step 3985] Loss: 9.94e+07 0.5618581175804138 0.7202620506286621\n",
      "[Step 3986] Loss: 1.00e+08 0.5618777275085449 0.7201935648918152\n",
      "[Step 3987] Loss: 9.96e+07 0.5618624091148376 0.7201003432273865\n",
      "[Step 3988] Loss: 9.95e+07 0.5618556141853333 0.7200029492378235\n",
      "[Step 3989] Loss: 9.92e+07 0.5618407130241394 0.7199179530143738\n",
      "[Step 3990] Loss: 9.88e+07 0.561880350112915 0.7198305130004883\n",
      "[Step 3991] Loss: 9.97e+07 0.561840832233429 0.7196844816207886\n",
      "[Step 3992] Loss: 9.88e+07 0.5619110465049744 0.7195953726768494\n",
      "[Step 3993] Loss: 9.97e+07 0.5620700120925903 0.7195128202438354\n",
      "[Step 3994] Loss: 9.88e+07 0.562183141708374 0.719409704208374\n",
      "[Step 3995] Loss: 9.91e+07 0.5622789859771729 0.719342827796936\n",
      "[Step 3996] Loss: 1.00e+08 0.5623987913131714 0.719334602355957\n",
      "[Step 3997] Loss: 9.90e+07 0.5624516010284424 0.7192768454551697\n",
      "[Step 3998] Loss: 9.90e+07 0.5626023411750793 0.7192174196243286\n",
      "[Step 3999] Loss: 9.92e+07 0.5628550052642822 0.7191827893257141\n",
      "[Step 4000] Loss: 9.93e+07 0.5630120038986206 0.7191192507743835\n",
      "[Step 4001] Loss: 9.85e+07 0.5631471276283264 0.719092845916748\n",
      "[Step 4002] Loss: 9.95e+07 0.5633389353752136 0.719033420085907\n",
      "[Step 4003] Loss: 9.77e+07 0.5634903311729431 0.7190078496932983\n",
      "[Step 4004] Loss: 1.00e+08 0.5635137557983398 0.7189154624938965\n",
      "[Step 4005] Loss: 9.93e+07 0.5635328888893127 0.7188230156898499\n",
      "[Step 4006] Loss: 9.94e+07 0.5635195374488831 0.718730628490448\n",
      "[Step 4007] Loss: 1.01e+08 0.5635266900062561 0.7185589671134949\n",
      "[Step 4008] Loss: 9.82e+07 0.5635080337524414 0.718399703502655\n",
      "[Step 4009] Loss: 9.91e+07 0.5635030269622803 0.718285858631134\n",
      "[Step 4010] Loss: 9.97e+07 0.563405454158783 0.7181381583213806\n",
      "[Step 4011] Loss: 9.97e+07 0.5632794499397278 0.7180044651031494\n",
      "[Step 4012] Loss: 9.91e+07 0.5631923675537109 0.7178617119789124\n",
      "[Step 4013] Loss: 9.92e+07 0.563112199306488 0.7177082300186157\n",
      "[Step 4014] Loss: 1.01e+08 0.5628835558891296 0.7175201177597046\n",
      "[Step 4015] Loss: 9.88e+07 0.562674880027771 0.717313826084137\n",
      "[Step 4016] Loss: 9.91e+07 0.5625077486038208 0.717139720916748\n",
      "[Step 4017] Loss: 9.87e+07 0.5623640418052673 0.7169631719589233\n",
      "[Step 4018] Loss: 9.98e+07 0.5621797442436218 0.7167676091194153\n",
      "[Step 4019] Loss: 9.81e+07 0.5619776844978333 0.7166339159011841\n",
      "[Step 4020] Loss: 9.91e+07 0.5617824196815491 0.7164795994758606\n",
      "[Step 4021] Loss: 9.92e+07 0.5616658926010132 0.7163583040237427\n",
      "[Step 4022] Loss: 9.89e+07 0.5615935325622559 0.7162642478942871\n",
      "[Step 4023] Loss: 9.86e+07 0.5614835023880005 0.7161396741867065\n",
      "[Step 4024] Loss: 9.92e+07 0.5614510774612427 0.7160505652427673\n",
      "[Step 4025] Loss: 9.83e+07 0.561427116394043 0.7159597873687744\n",
      "[Step 4026] Loss: 9.87e+07 0.5614460110664368 0.7158681750297546\n",
      "[Step 4027] Loss: 9.90e+07 0.5614257454872131 0.7157889604568481\n",
      "[Step 4028] Loss: 9.85e+07 0.5614417791366577 0.7157584428787231\n",
      "[Step 4029] Loss: 9.91e+07 0.5614824891090393 0.7156776189804077\n",
      "[Step 4030] Loss: 9.93e+07 0.5615715384483337 0.7156602740287781\n",
      "[Step 4031] Loss: 9.91e+07 0.5616728067398071 0.7156347036361694\n",
      "[Step 4032] Loss: 9.95e+07 0.5617513656616211 0.7155637145042419\n",
      "[Step 4033] Loss: 9.91e+07 0.5618695616722107 0.71552574634552\n",
      "[Step 4034] Loss: 9.97e+07 0.5621668100357056 0.7155117392539978\n",
      "[Step 4035] Loss: 9.94e+07 0.5623612403869629 0.7154828906059265\n",
      "[Step 4036] Loss: 9.89e+07 0.562500536441803 0.7154844999313354\n",
      "[Step 4037] Loss: 1.00e+08 0.5627400279045105 0.7154713273048401\n",
      "[Step 4038] Loss: 1.00e+08 0.563038170337677 0.715472936630249\n",
      "[Step 4039] Loss: 9.94e+07 0.5633054375648499 0.7154704928398132\n",
      "[Step 4040] Loss: 1.00e+08 0.563480794429779 0.7154151797294617\n",
      "[Step 4041] Loss: 1.00e+08 0.5635161995887756 0.7153252363204956\n",
      "[Step 4042] Loss: 9.88e+07 0.5635817646980286 0.7152427434921265\n",
      "[Step 4043] Loss: 9.92e+07 0.5636231899261475 0.7151338458061218\n",
      "[Step 4044] Loss: 9.88e+07 0.5636544227600098 0.7150834798812866\n",
      "[Step 4045] Loss: 9.90e+07 0.5637603998184204 0.7150537967681885\n",
      "[Step 4046] Loss: 9.88e+07 0.563896119594574 0.7149993181228638\n",
      "[Step 4047] Loss: 9.85e+07 0.5640254020690918 0.7150067687034607\n",
      "[Step 4048] Loss: 9.94e+07 0.5641582608222961 0.7149638533592224\n",
      "[Step 4049] Loss: 9.87e+07 0.564254641532898 0.7148970365524292\n",
      "[Step 4050] Loss: 9.85e+07 0.5642721056938171 0.714824378490448\n",
      "[Step 4051] Loss: 9.93e+07 0.5642445683479309 0.7147171497344971\n",
      "[Step 4052] Loss: 9.90e+07 0.5643079876899719 0.7146956920623779\n",
      "[Step 4053] Loss: 9.83e+07 0.5643682479858398 0.714649498462677\n",
      "[Step 4054] Loss: 9.81e+07 0.5643976330757141 0.7145677804946899\n",
      "[Step 4055] Loss: 9.84e+07 0.5643227100372314 0.7144514322280884\n",
      "[Step 4056] Loss: 9.96e+07 0.564168393611908 0.7143730521202087\n",
      "[Step 4057] Loss: 9.84e+07 0.5639849305152893 0.7142459750175476\n",
      "[Step 4058] Loss: 1.01e+08 0.563555121421814 0.7139810919761658\n",
      "[Step 4059] Loss: 9.90e+07 0.5631261467933655 0.7137022018432617\n",
      "[Step 4060] Loss: 9.94e+07 0.5627008080482483 0.7134695053100586\n",
      "[Step 4061] Loss: 9.95e+07 0.562335193157196 0.7132104635238647\n",
      "[Step 4062] Loss: 9.91e+07 0.5619625449180603 0.7129859924316406\n",
      "[Step 4063] Loss: 9.94e+07 0.5615544319152832 0.7127120494842529\n",
      "[Step 4064] Loss: 9.93e+07 0.5611428618431091 0.7124711275100708\n",
      "[Step 4065] Loss: 9.94e+07 0.5608167052268982 0.7122499942779541\n",
      "[Step 4066] Loss: 9.98e+07 0.5604113936424255 0.7119892239570618\n",
      "[Step 4067] Loss: 9.90e+07 0.5600448250770569 0.7117507457733154\n",
      "[Step 4068] Loss: 9.88e+07 0.5597501993179321 0.7115452885627747\n",
      "[Step 4069] Loss: 9.88e+07 0.5594571232795715 0.7113415002822876\n",
      "[Step 4070] Loss: 9.95e+07 0.5592682361602783 0.7111789584159851\n",
      "[Step 4071] Loss: 1.00e+08 0.5589937567710876 0.7109850645065308\n",
      "[Step 4072] Loss: 9.90e+07 0.5587193369865417 0.7107787728309631\n",
      "[Step 4073] Loss: 9.90e+07 0.5585500597953796 0.7106120586395264\n",
      "[Step 4074] Loss: 9.84e+07 0.5583832859992981 0.7104552984237671\n",
      "[Step 4075] Loss: 9.88e+07 0.5582923293113708 0.7103150486946106\n",
      "[Step 4076] Loss: 9.93e+07 0.5581680536270142 0.7102044820785522\n",
      "[Step 4077] Loss: 9.91e+07 0.5579661130905151 0.710094690322876\n",
      "[Step 4078] Loss: 9.90e+07 0.5577899217605591 0.7099552750587463\n",
      "[Step 4079] Loss: 9.96e+07 0.5577574968338013 0.7099156379699707\n",
      "[Step 4080] Loss: 9.84e+07 0.5577532649040222 0.7098207473754883\n",
      "[Step 4081] Loss: 9.81e+07 0.5577359199523926 0.7097242474555969\n",
      "[Step 4082] Loss: 9.88e+07 0.5577288269996643 0.7096384167671204\n",
      "[Step 4083] Loss: 9.91e+07 0.5576503276824951 0.7095154523849487\n",
      "[Step 4084] Loss: 9.90e+07 0.5576032400131226 0.7094181180000305\n",
      "[Step 4085] Loss: 9.82e+07 0.5576146841049194 0.7093141674995422\n",
      "[Step 4086] Loss: 9.96e+07 0.5576909780502319 0.7092299461364746\n",
      "[Step 4087] Loss: 9.86e+07 0.5578406453132629 0.709180474281311\n",
      "[Step 4088] Loss: 9.86e+07 0.5580648183822632 0.7091326117515564\n",
      "[Step 4089] Loss: 9.99e+07 0.55818772315979 0.7090393900871277\n",
      "[Step 4090] Loss: 9.85e+07 0.5583217144012451 0.7089890241622925\n",
      "[Step 4091] Loss: 9.87e+07 0.5584307312965393 0.7089452743530273\n",
      "[Step 4092] Loss: 9.95e+07 0.5586102604866028 0.70888751745224\n",
      "[Step 4093] Loss: 9.85e+07 0.5588202476501465 0.7088834047317505\n",
      "[Step 4094] Loss: 9.89e+07 0.5591199398040771 0.7088867425918579\n",
      "[Step 4095] Loss: 9.82e+07 0.5594135522842407 0.7088545560836792\n",
      "[Step 4096] Loss: 9.88e+07 0.5597219467163086 0.708856999874115\n",
      "[Step 4097] Loss: 9.92e+07 0.5600478053092957 0.7088471055030823\n",
      "[Step 4098] Loss: 9.90e+07 0.5602542757987976 0.7088050246238708\n",
      "[Step 4099] Loss: 9.91e+07 0.5604810118675232 0.7087588310241699\n",
      "[Step 4100] Loss: 9.94e+07 0.5608912706375122 0.7088314294815063\n",
      "[Step 4101] Loss: 9.83e+07 0.5613411068916321 0.7089486122131348\n",
      "[Step 4102] Loss: 9.85e+07 0.5617357492446899 0.7090113162994385\n",
      "[Step 4103] Loss: 9.90e+07 0.5621287822723389 0.7090740203857422\n",
      "[Step 4104] Loss: 9.74e+07 0.5624940991401672 0.7091259956359863\n",
      "[Step 4105] Loss: 9.86e+07 0.562826931476593 0.7091746926307678\n",
      "[Step 4106] Loss: 9.86e+07 0.5630854964256287 0.7091639637947083\n",
      "[Step 4107] Loss: 9.88e+07 0.5632479786872864 0.7091664671897888\n",
      "[Step 4108] Loss: 9.90e+07 0.5633686184883118 0.7091524004936218\n",
      "[Step 4109] Loss: 9.83e+07 0.5634739398956299 0.7091119885444641\n",
      "[Step 4110] Loss: 9.92e+07 0.5635850429534912 0.7090657949447632\n",
      "[Step 4111] Loss: 9.87e+07 0.5636591911315918 0.7090179324150085\n",
      "[Step 4112] Loss: 9.86e+07 0.563729465007782 0.7090088129043579\n",
      "[Step 4113] Loss: 9.86e+07 0.5638202428817749 0.708969235420227\n",
      "[Step 4114] Loss: 9.96e+07 0.5639093518257141 0.708954393863678\n",
      "[Step 4115] Loss: 9.84e+07 0.5639833807945251 0.7089444994926453\n",
      "[Step 4116] Loss: 9.87e+07 0.5640689134597778 0.7089667320251465\n",
      "[Step 4117] Loss: 9.92e+07 0.5642460584640503 0.7090145945549011\n",
      "[Step 4118] Loss: 9.85e+07 0.5644527673721313 0.7090418338775635\n",
      "[Step 4119] Loss: 9.92e+07 0.5646425485610962 0.7090352177619934\n",
      "[Step 4120] Loss: 9.89e+07 0.5648485422134399 0.7090608477592468\n",
      "[Step 4121] Loss: 9.87e+07 0.5650940537452698 0.7091086506843567\n",
      "[Step 4122] Loss: 9.80e+07 0.5653327703475952 0.7091450095176697\n",
      "[Step 4123] Loss: 9.90e+07 0.5655153393745422 0.7091342806816101\n",
      "[Step 4124] Loss: 9.86e+07 0.5656788349151611 0.7091218829154968\n",
      "[Step 4125] Loss: 9.79e+07 0.5658707022666931 0.7091400623321533\n",
      "[Step 4126] Loss: 9.84e+07 0.5659407377243042 0.7091268301010132\n",
      "[Step 4127] Loss: 9.91e+07 0.5660507678985596 0.7090872526168823\n",
      "[Step 4128] Loss: 9.88e+07 0.5661110877990723 0.7090674042701721\n",
      "[Step 4129] Loss: 9.82e+07 0.5662073493003845 0.7090336084365845\n",
      "[Step 4130] Loss: 9.95e+07 0.5663633346557617 0.7089973092079163\n",
      "[Step 4131] Loss: 9.89e+07 0.5664534568786621 0.708961009979248\n",
      "[Step 4132] Loss: 9.85e+07 0.5665677189826965 0.7089502811431885\n",
      "[Step 4133] Loss: 9.82e+07 0.5666561722755432 0.7089213728904724\n",
      "[Step 4134] Loss: 9.87e+07 0.5667368173599243 0.7089205384254456\n",
      "[Step 4135] Loss: 9.80e+07 0.5668145418167114 0.7088817954063416\n",
      "[Step 4136] Loss: 9.93e+07 0.5667367577552795 0.7087472677230835\n",
      "[Step 4137] Loss: 9.91e+07 0.5666340589523315 0.7086268067359924\n",
      "[Step 4138] Loss: 9.89e+07 0.5665600895881653 0.7085475921630859\n",
      "[Step 4139] Loss: 9.83e+07 0.5665937066078186 0.7085112929344177\n",
      "[Step 4140] Loss: 9.84e+07 0.5666718482971191 0.7084840536117554\n",
      "[Step 4141] Loss: 9.88e+07 0.5667159557342529 0.708456814289093\n",
      "[Step 4142] Loss: 9.87e+07 0.5667776465415955 0.7084221839904785\n",
      "[Step 4143] Loss: 9.90e+07 0.5668043494224548 0.7083578109741211\n",
      "[Step 4144] Loss: 9.89e+07 0.5667964816093445 0.7082711458206177\n",
      "[Step 4145] Loss: 9.98e+07 0.5669018626213074 0.7082298994064331\n",
      "[Step 4146] Loss: 9.92e+07 0.5670368075370789 0.7081787586212158\n",
      "[Step 4147] Loss: 9.88e+07 0.5671072602272034 0.7081325650215149\n",
      "[Step 4148] Loss: 9.92e+07 0.5671871900558472 0.7080995440483093\n",
      "[Step 4149] Loss: 9.90e+07 0.5671980977058411 0.7080656886100769\n",
      "[Step 4150] Loss: 9.85e+07 0.5672405958175659 0.7080434560775757\n",
      "[Step 4151] Loss: 9.99e+07 0.5671934485435486 0.7079353332519531\n",
      "[Step 4152] Loss: 9.90e+07 0.5671095252037048 0.7077843546867371\n",
      "[Step 4153] Loss: 9.87e+07 0.5670706033706665 0.7076572775840759\n",
      "[Step 4154] Loss: 9.84e+07 0.5671205520629883 0.7076349854469299\n",
      "[Step 4155] Loss: 9.84e+07 0.567230224609375 0.7076069116592407\n",
      "[Step 4156] Loss: 1.00e+08 0.5672114491462708 0.7075104117393494\n",
      "[Step 4157] Loss: 9.89e+07 0.5672938227653503 0.7074460387229919\n",
      "[Step 4158] Loss: 9.91e+07 0.5673614740371704 0.7074138522148132\n",
      "[Step 4159] Loss: 9.92e+07 0.5675103664398193 0.7073610424995422\n",
      "[Step 4160] Loss: 9.84e+07 0.5676746964454651 0.7073321342468262\n",
      "[Step 4161] Loss: 9.92e+07 0.5678353309631348 0.7073189616203308\n",
      "[Step 4162] Loss: 9.78e+07 0.5679798126220703 0.7073082327842712\n",
      "[Step 4163] Loss: 9.90e+07 0.5680596232414246 0.7072215676307678\n",
      "[Step 4164] Loss: 9.87e+07 0.5680742859840393 0.7071225643157959\n",
      "[Step 4165] Loss: 9.93e+07 0.5681154131889343 0.7070310115814209\n",
      "[Step 4166] Loss: 9.97e+07 0.5681976079940796 0.706970751285553\n",
      "[Step 4167] Loss: 9.99e+07 0.5683415532112122 0.7069204449653625\n",
      "[Step 4168] Loss: 9.84e+07 0.5685229301452637 0.7068997621536255\n",
      "[Step 4169] Loss: 9.79e+07 0.5686577558517456 0.7068337798118591\n",
      "[Step 4170] Loss: 9.89e+07 0.5688172578811646 0.7067859172821045\n",
      "[Step 4171] Loss: 9.84e+07 0.5689778327941895 0.7067644596099854\n",
      "[Step 4172] Loss: 9.90e+07 0.5690500140190125 0.7066786289215088\n",
      "[Step 4173] Loss: 1.00e+08 0.5690611004829407 0.7066060304641724\n",
      "[Step 4174] Loss: 9.88e+07 0.5689676403999329 0.7064773440361023\n",
      "[Step 4175] Loss: 9.97e+07 0.5688901543617249 0.7063535451889038\n",
      "[Step 4176] Loss: 9.92e+07 0.5688795447349548 0.706231415271759\n",
      "[Step 4177] Loss: 9.90e+07 0.5688791275024414 0.7061505913734436\n",
      "[Step 4178] Loss: 1.03e+08 0.5686379671096802 0.7059401273727417\n",
      "[Step 4179] Loss: 9.94e+07 0.5685093402862549 0.7057784199714661\n",
      "[Step 4180] Loss: 9.82e+07 0.5684751868247986 0.7056876420974731\n",
      "[Step 4181] Loss: 9.91e+07 0.5684835910797119 0.7056076526641846\n",
      "[Step 4182] Loss: 9.90e+07 0.5685099959373474 0.7055044770240784\n",
      "[Step 4183] Loss: 9.95e+07 0.5686352252960205 0.7054293751716614\n",
      "[Step 4184] Loss: 9.93e+07 0.5687588453292847 0.7053700089454651\n",
      "[Step 4185] Loss: 9.91e+07 0.568786084651947 0.7053048014640808\n",
      "[Step 4186] Loss: 9.87e+07 0.568784236907959 0.7051818370819092\n",
      "[Step 4187] Loss: 9.91e+07 0.5687178373336792 0.7050366401672363\n",
      "[Step 4188] Loss: 9.89e+07 0.5685963034629822 0.7049046158790588\n",
      "[Step 4189] Loss: 1.01e+08 0.5682306289672852 0.7047016024589539\n",
      "[Step 4190] Loss: 9.92e+07 0.5679258108139038 0.7044953107833862\n",
      "[Step 4191] Loss: 9.87e+07 0.5675832629203796 0.7042428255081177\n",
      "[Step 4192] Loss: 9.84e+07 0.5671850442886353 0.7040324211120605\n",
      "[Step 4193] Loss: 9.91e+07 0.5669264197349548 0.7038806080818176\n",
      "[Step 4194] Loss: 9.83e+07 0.5667219161987305 0.7037345767021179\n",
      "[Step 4195] Loss: 9.84e+07 0.566574215888977 0.7036545276641846\n",
      "[Step 4196] Loss: 9.82e+07 0.5664231181144714 0.7035546898841858\n",
      "[Step 4197] Loss: 1.01e+08 0.5661003589630127 0.7033880352973938\n",
      "[Step 4198] Loss: 9.86e+07 0.5658224821090698 0.7032139301300049\n",
      "[Step 4199] Loss: 9.85e+07 0.5656047463417053 0.7031206488609314\n",
      "[Step 4200] Loss: 9.86e+07 0.5653572678565979 0.702942430973053\n",
      "[Step 4201] Loss: 9.76e+07 0.5651638507843018 0.7028351426124573\n",
      "[Step 4202] Loss: 9.83e+07 0.5650668740272522 0.7027831673622131\n",
      "[Step 4203] Loss: 9.90e+07 0.5649478435516357 0.7027336955070496\n",
      "[Step 4204] Loss: 9.94e+07 0.564812183380127 0.7026528120040894\n",
      "[Step 4205] Loss: 9.86e+07 0.5646631717681885 0.7025339603424072\n",
      "[Step 4206] Loss: 9.89e+07 0.5644819736480713 0.7024019956588745\n",
      "[Step 4207] Loss: 1.00e+08 0.5641894340515137 0.7022361159324646\n",
      "[Step 4208] Loss: 9.84e+07 0.5639068484306335 0.7020455002784729\n",
      "[Step 4209] Loss: 9.89e+07 0.5637695789337158 0.7019489407539368\n",
      "[Step 4210] Loss: 9.86e+07 0.5636357665061951 0.7018589973449707\n",
      "[Step 4211] Loss: 9.87e+07 0.5635102391242981 0.7017468214035034\n",
      "[Step 4212] Loss: 9.87e+07 0.5635337829589844 0.7016717195510864\n",
      "[Step 4213] Loss: 9.95e+07 0.5634874701499939 0.7015809416770935\n",
      "[Step 4214] Loss: 9.80e+07 0.5634698271751404 0.7015058398246765\n",
      "[Step 4215] Loss: 9.84e+07 0.5634944438934326 0.7014538645744324\n",
      "[Step 4216] Loss: 1.00e+08 0.5633336901664734 0.7013226747512817\n",
      "[Step 4217] Loss: 9.96e+07 0.5630875825881958 0.701117217540741\n",
      "[Step 4218] Loss: 9.93e+07 0.5627387762069702 0.7009373307228088\n",
      "[Step 4219] Loss: 9.95e+07 0.5624968409538269 0.7007855176925659\n",
      "[Step 4220] Loss: 9.87e+07 0.5622132420539856 0.700580894947052\n",
      "[Step 4221] Loss: 9.89e+07 0.5618762969970703 0.700369656085968\n",
      "[Step 4222] Loss: 9.90e+07 0.5615735650062561 0.7001782059669495\n",
      "[Step 4223] Loss: 9.97e+07 0.5612233877182007 0.6999669671058655\n",
      "[Step 4224] Loss: 9.92e+07 0.5608623027801514 0.6997227668762207\n",
      "[Step 4225] Loss: 9.87e+07 0.5604910850524902 0.6995222568511963\n",
      "[Step 4226] Loss: 9.88e+07 0.5601691603660583 0.6992846131324768\n",
      "[Step 4227] Loss: 9.89e+07 0.5598321557044983 0.6990213990211487\n",
      "[Step 4228] Loss: 9.87e+07 0.5594661831855774 0.6987573504447937\n",
      "[Step 4229] Loss: 9.93e+07 0.5590527653694153 0.6985081434249878\n",
      "[Step 4230] Loss: 9.89e+07 0.5586776733398438 0.698273777961731\n",
      "[Step 4231] Loss: 9.94e+07 0.5582836270332336 0.6980526447296143\n",
      "[Step 4232] Loss: 9.98e+07 0.5578415989875793 0.6977572441101074\n",
      "[Step 4233] Loss: 9.89e+07 0.5574122667312622 0.6975237727165222\n",
      "[Step 4234] Loss: 9.90e+07 0.5569976568222046 0.6972605586051941\n",
      "[Step 4235] Loss: 9.90e+07 0.5566678643226624 0.6970402002334595\n",
      "[Step 4236] Loss: 9.94e+07 0.5563474893569946 0.696838915348053\n",
      "[Step 4237] Loss: 9.90e+07 0.5560005903244019 0.6965913772583008\n",
      "[Step 4238] Loss: 9.88e+07 0.5557432770729065 0.6963990926742554\n",
      "[Step 4239] Loss: 9.92e+07 0.5555305480957031 0.6962002515792847\n",
      "[Step 4240] Loss: 9.87e+07 0.5552617311477661 0.6959757804870605\n",
      "[Step 4241] Loss: 9.84e+07 0.5550406575202942 0.6957835555076599\n",
      "[Step 4242] Loss: 9.85e+07 0.5549049973487854 0.6956242918968201\n",
      "[Step 4243] Loss: 9.92e+07 0.554847240447998 0.6955029964447021\n",
      "[Step 4244] Loss: 9.90e+07 0.5548598170280457 0.6953883171081543\n",
      "[Step 4245] Loss: 9.97e+07 0.5547940135002136 0.6952694654464722\n",
      "[Step 4246] Loss: 9.85e+07 0.5547212958335876 0.6951168179512024\n",
      "[Step 4247] Loss: 9.90e+07 0.55466228723526 0.6950293779373169\n",
      "[Step 4248] Loss: 9.82e+07 0.5546604990959167 0.6949592232704163\n",
      "[Step 4249] Loss: 9.77e+07 0.5547104477882385 0.6948610544204712\n",
      "[Step 4250] Loss: 9.82e+07 0.5547143220901489 0.6948255300521851\n",
      "[Step 4251] Loss: 9.90e+07 0.5547952651977539 0.6947430372238159\n",
      "[Step 4252] Loss: 9.94e+07 0.554904580116272 0.6947249174118042\n",
      "[Step 4253] Loss: 9.87e+07 0.5549860596656799 0.6946638226509094\n",
      "[Step 4254] Loss: 1.00e+08 0.5550026893615723 0.694591224193573\n",
      "[Step 4255] Loss: 9.85e+07 0.5549870133399963 0.6944897174835205\n",
      "[Step 4256] Loss: 9.78e+07 0.5549741387367249 0.6944047212600708\n",
      "[Step 4257] Loss: 9.87e+07 0.5549845695495605 0.6943098306655884\n",
      "[Step 4258] Loss: 9.88e+07 0.5549923777580261 0.6942430138587952\n",
      "[Step 4259] Loss: 9.90e+07 0.5549734830856323 0.6941712498664856\n",
      "[Step 4260] Loss: 9.85e+07 0.5549399852752686 0.6940375566482544\n",
      "[Step 4261] Loss: 9.83e+07 0.5548374652862549 0.6939145922660828\n",
      "[Step 4262] Loss: 9.84e+07 0.554793655872345 0.69383704662323\n",
      "[Step 4263] Loss: 9.80e+07 0.5547764897346497 0.6937041878700256\n",
      "[Step 4264] Loss: 9.96e+07 0.5546904802322388 0.6936092972755432\n",
      "[Step 4265] Loss: 9.81e+07 0.5545949935913086 0.6935028433799744\n",
      "[Step 4266] Loss: 9.84e+07 0.554448664188385 0.6934137344360352\n",
      "[Step 4267] Loss: 9.91e+07 0.5543681979179382 0.6933378577232361\n",
      "[Step 4268] Loss: 9.87e+07 0.5544065237045288 0.693294107913971\n",
      "[Step 4269] Loss: 9.78e+07 0.5545095801353455 0.6932619214057922\n",
      "[Step 4270] Loss: 9.81e+07 0.5546578764915466 0.6932454109191895\n",
      "[Step 4271] Loss: 9.95e+07 0.5548130869865417 0.6932272911071777\n",
      "[Step 4272] Loss: 9.78e+07 0.5550606846809387 0.6932387948036194\n",
      "[Step 4273] Loss: 9.78e+07 0.5553184747695923 0.6932438015937805\n",
      "[Step 4274] Loss: 9.93e+07 0.5555568337440491 0.6932462453842163\n",
      "[Step 4275] Loss: 9.79e+07 0.5557733774185181 0.6932998895645142\n",
      "[Step 4276] Loss: 9.91e+07 0.555941104888916 0.6933130621910095\n",
      "[Step 4277] Loss: 9.87e+07 0.5561699271202087 0.6933320760726929\n",
      "[Step 4278] Loss: 9.89e+07 0.5564899444580078 0.6933964490890503\n",
      "[Step 4279] Loss: 9.86e+07 0.556768536567688 0.6934021711349487\n",
      "[Step 4280] Loss: 9.89e+07 0.5570486187934875 0.6934327483177185\n",
      "[Step 4281] Loss: 9.89e+07 0.5572811961174011 0.6934418082237244\n",
      "[Step 4282] Loss: 9.93e+07 0.557549774646759 0.6934484243392944\n",
      "[Step 4283] Loss: 9.88e+07 0.5576673746109009 0.6934137344360352\n",
      "[Step 4284] Loss: 9.93e+07 0.5578569769859314 0.6934104561805725\n",
      "[Step 4285] Loss: 9.96e+07 0.5579628944396973 0.6933791041374207\n",
      "[Step 4286] Loss: 9.86e+07 0.5581785440444946 0.6933931112289429\n",
      "[Step 4287] Loss: 9.84e+07 0.5583651065826416 0.6933823823928833\n",
      "[Step 4288] Loss: 9.96e+07 0.558420717716217 0.6933262944221497\n",
      "[Step 4289] Loss: 9.94e+07 0.5585516095161438 0.6932949423789978\n",
      "[Step 4290] Loss: 9.98e+07 0.5585498809814453 0.6932264566421509\n",
      "[Step 4291] Loss: 9.89e+07 0.5584588646888733 0.6931183338165283\n",
      "[Step 4292] Loss: 9.84e+07 0.5583938360214233 0.6930317282676697\n",
      "[Step 4293] Loss: 9.89e+07 0.5583410859107971 0.6929491758346558\n",
      "[Step 4294] Loss: 9.94e+07 0.5582274794578552 0.6928237676620483\n",
      "[Step 4295] Loss: 9.81e+07 0.5580891966819763 0.6927189826965332\n",
      "[Step 4296] Loss: 9.90e+07 0.5578698515892029 0.692577064037323\n",
      "[Step 4297] Loss: 9.97e+07 0.5577300190925598 0.6924788951873779\n",
      "[Step 4298] Loss: 9.88e+07 0.5575844645500183 0.6923452019691467\n",
      "[Step 4299] Loss: 9.81e+07 0.5574620366096497 0.6922387480735779\n",
      "[Step 4300] Loss: 9.95e+07 0.557380199432373 0.6921058893203735\n",
      "[Step 4301] Loss: 9.80e+07 0.5573350787162781 0.6919920444488525\n",
      "[Step 4302] Loss: 9.89e+07 0.557332456111908 0.691904604434967\n",
      "[Step 4303] Loss: 9.77e+07 0.5573420524597168 0.6917840838432312\n",
      "[Step 4304] Loss: 9.84e+07 0.5573435425758362 0.6916462779045105\n",
      "[Step 4305] Loss: 9.90e+07 0.5573578476905823 0.6915695667266846\n",
      "[Step 4306] Loss: 9.93e+07 0.557350754737854 0.6915068626403809\n",
      "[Step 4307] Loss: 9.98e+07 0.5572634935379028 0.6913872361183167\n",
      "[Step 4308] Loss: 9.93e+07 0.5570993423461914 0.6912609934806824\n",
      "[Step 4309] Loss: 9.81e+07 0.5569384694099426 0.6911545395851135\n",
      "[Step 4310] Loss: 9.89e+07 0.5568127036094666 0.6910356879234314\n",
      "[Step 4311] Loss: 9.82e+07 0.5567623972892761 0.6909795999526978\n",
      "[Step 4312] Loss: 9.85e+07 0.5567131638526917 0.6908731460571289\n",
      "[Step 4313] Loss: 9.79e+07 0.5566319823265076 0.6907898187637329\n",
      "[Step 4314] Loss: 9.83e+07 0.5565648078918457 0.6906552910804749\n",
      "[Step 4315] Loss: 9.87e+07 0.5565320253372192 0.6905637383460999\n",
      "[Step 4316] Loss: 9.85e+07 0.5564036965370178 0.6904242634773254\n",
      "[Step 4317] Loss: 9.90e+07 0.5562951564788818 0.6903467178344727\n",
      "[Step 4318] Loss: 9.85e+07 0.5561975240707397 0.6902592778205872\n",
      "[Step 4319] Loss: 9.87e+07 0.5560265183448792 0.6901808381080627\n",
      "[Step 4320] Loss: 9.86e+07 0.555853009223938 0.6900373101234436\n",
      "[Step 4321] Loss: 9.87e+07 0.5557786226272583 0.689922571182251\n",
      "[Step 4322] Loss: 9.86e+07 0.555713951587677 0.6898739337921143\n",
      "[Step 4323] Loss: 9.98e+07 0.5554636120796204 0.689732015132904\n",
      "[Step 4324] Loss: 9.81e+07 0.555237889289856 0.6895859241485596\n",
      "[Step 4325] Loss: 9.86e+07 0.5551194548606873 0.6894901990890503\n",
      "[Step 4326] Loss: 9.92e+07 0.554964542388916 0.6893813014030457\n",
      "[Step 4327] Loss: 9.87e+07 0.5548079609870911 0.6892748475074768\n",
      "[Step 4328] Loss: 9.94e+07 0.5545294880867004 0.6891189217567444\n",
      "[Step 4329] Loss: 9.86e+07 0.5542912483215332 0.6889836192131042\n",
      "[Step 4330] Loss: 1.00e+08 0.5539742708206177 0.6888037323951721\n",
      "[Step 4331] Loss: 9.88e+07 0.5536595582962036 0.6886163949966431\n",
      "[Step 4332] Loss: 9.80e+07 0.5533036589622498 0.6884373426437378\n",
      "[Step 4333] Loss: 9.91e+07 0.5530712604522705 0.6883028745651245\n",
      "[Step 4334] Loss: 9.84e+07 0.5530489087104797 0.6882054805755615\n",
      "[Step 4335] Loss: 9.83e+07 0.55302894115448 0.6881815791130066\n",
      "[Step 4336] Loss: 9.82e+07 0.553086519241333 0.6881840229034424\n",
      "[Step 4337] Loss: 9.87e+07 0.5532113313674927 0.6881923079490662\n",
      "[Step 4338] Loss: 9.89e+07 0.5534302592277527 0.6881972551345825\n",
      "[Step 4339] Loss: 9.81e+07 0.5537029504776001 0.6882261037826538\n",
      "[Step 4340] Loss: 9.80e+07 0.5539599061012268 0.688247561454773\n",
      "[Step 4341] Loss: 9.88e+07 0.5541064143180847 0.6882302165031433\n",
      "[Step 4342] Loss: 9.86e+07 0.5543140172958374 0.688225269317627\n",
      "[Step 4343] Loss: 9.93e+07 0.5544884204864502 0.6882022023200989\n",
      "[Step 4344] Loss: 9.90e+07 0.5546375513076782 0.6881749629974365\n",
      "[Step 4345] Loss: 9.86e+07 0.5546691417694092 0.688111424446106\n",
      "[Step 4346] Loss: 9.88e+07 0.5547020435333252 0.6880132555961609\n",
      "[Step 4347] Loss: 9.88e+07 0.554740309715271 0.6879538297653198\n",
      "[Step 4348] Loss: 9.91e+07 0.5548294186592102 0.6879381537437439\n",
      "[Step 4349] Loss: 9.83e+07 0.5549997091293335 0.6878902912139893\n",
      "[Step 4350] Loss: 9.82e+07 0.5550763607025146 0.6878325343132019\n",
      "[Step 4351] Loss: 9.84e+07 0.5550757646560669 0.6877821683883667\n",
      "[Step 4352] Loss: 9.92e+07 0.5551717281341553 0.6877467036247253\n",
      "[Step 4353] Loss: 9.92e+07 0.5551431775093079 0.6876782178878784\n",
      "[Step 4354] Loss: 9.88e+07 0.5550732612609863 0.6875643730163574\n",
      "[Step 4355] Loss: 9.85e+07 0.5550622344017029 0.6875131726264954\n",
      "[Step 4356] Loss: 9.92e+07 0.5550571084022522 0.6874422430992126\n",
      "[Step 4357] Loss: 9.89e+07 0.5550342798233032 0.6873836517333984\n",
      "[Step 4358] Loss: 9.96e+07 0.5551209449768066 0.687333345413208\n",
      "[Step 4359] Loss: 9.86e+07 0.5553174614906311 0.6873258948326111\n",
      "[Step 4360] Loss: 9.86e+07 0.5555328726768494 0.6873093843460083\n",
      "[Step 4361] Loss: 9.80e+07 0.5556555986404419 0.6872945427894592\n",
      "[Step 4362] Loss: 9.91e+07 0.5557937026023865 0.6872870922088623\n",
      "[Step 4363] Loss: 9.85e+07 0.5559536814689636 0.6872722506523132\n",
      "[Step 4364] Loss: 9.88e+07 0.5560483336448669 0.6872268915176392\n",
      "[Step 4365] Loss: 9.79e+07 0.5561026334762573 0.6871550679206848\n",
      "[Step 4366] Loss: 9.84e+07 0.5561505556106567 0.6871163249015808\n",
      "[Step 4367] Loss: 9.83e+07 0.5562376379966736 0.6870453357696533\n",
      "[Step 4368] Loss: 9.84e+07 0.5563442707061768 0.6869826316833496\n",
      "[Step 4369] Loss: 9.89e+07 0.5563709735870361 0.6868712306022644\n",
      "[Step 4370] Loss: 9.85e+07 0.5563674569129944 0.686791181564331\n",
      "[Step 4371] Loss: 9.81e+07 0.5563567876815796 0.6867177486419678\n",
      "[Step 4372] Loss: 9.88e+07 0.5562310218811035 0.686640202999115\n",
      "[Step 4373] Loss: 9.88e+07 0.5561831593513489 0.6865634918212891\n",
      "[Step 4374] Loss: 1.00e+08 0.5561102032661438 0.6864850521087646\n",
      "[Step 4375] Loss: 9.83e+07 0.5560888648033142 0.6864141225814819\n",
      "[Step 4376] Loss: 9.93e+07 0.5561445355415344 0.6863893866539001\n",
      "[Step 4377] Loss: 9.83e+07 0.5562180876731873 0.6863085031509399\n",
      "[Step 4378] Loss: 9.81e+07 0.5562939047813416 0.6862449645996094\n",
      "[Step 4379] Loss: 9.81e+07 0.5563035011291504 0.6861732006072998\n",
      "[Step 4380] Loss: 9.86e+07 0.5562734603881836 0.6860865354537964\n",
      "[Step 4381] Loss: 9.86e+07 0.5563510060310364 0.6860163807868958\n",
      "[Step 4382] Loss: 1.01e+08 0.5562047362327576 0.6859248280525208\n",
      "[Step 4383] Loss: 9.83e+07 0.5560312271118164 0.6857572793960571\n",
      "[Step 4384] Loss: 9.89e+07 0.5559916496276855 0.6856863498687744\n",
      "[Step 4385] Loss: 9.89e+07 0.5559836626052856 0.6856228113174438\n",
      "[Step 4386] Loss: 9.85e+07 0.5560300946235657 0.6855477094650269\n",
      "[Step 4387] Loss: 9.78e+07 0.5561645030975342 0.685508131980896\n",
      "[Step 4388] Loss: 9.83e+07 0.5561978816986084 0.6854751110076904\n",
      "[Step 4389] Loss: 9.87e+07 0.5562877655029297 0.6854231357574463\n",
      "[Step 4390] Loss: 9.90e+07 0.5562647581100464 0.6853892803192139\n",
      "[Step 4391] Loss: 9.88e+07 0.5562578439712524 0.6853323578834534\n",
      "[Step 4392] Loss: 9.76e+07 0.5562741160392761 0.6852927803993225\n",
      "[Step 4393] Loss: 9.84e+07 0.5562386512756348 0.6852490305900574\n",
      "[Step 4394] Loss: 9.88e+07 0.5561504364013672 0.685160756111145\n",
      "[Step 4395] Loss: 9.82e+07 0.5560394525527954 0.6850773692131042\n",
      "[Step 4396] Loss: 9.84e+07 0.5558885931968689 0.6849766969680786\n",
      "[Step 4397] Loss: 9.79e+07 0.5557669997215271 0.6848710775375366\n",
      "[Step 4398] Loss: 9.89e+07 0.5557131171226501 0.6848356127738953\n",
      "[Step 4399] Loss: 9.92e+07 0.5555031299591064 0.6847283840179443\n",
      "[Step 4400] Loss: 9.85e+07 0.5552300214767456 0.6846153140068054\n",
      "[Step 4401] Loss: 9.85e+07 0.5549914836883545 0.6845163106918335\n",
      "[Step 4402] Loss: 9.89e+07 0.5546372532844543 0.6843760013580322\n",
      "[Step 4403] Loss: 9.84e+07 0.554295539855957 0.6842018961906433\n",
      "[Step 4404] Loss: 9.87e+07 0.5541011095046997 0.6840996146202087\n",
      "[Step 4405] Loss: 9.91e+07 0.5539712309837341 0.6840170621871948\n",
      "[Step 4406] Loss: 9.87e+07 0.5538581013679504 0.6839131116867065\n",
      "[Step 4407] Loss: 9.95e+07 0.5537976622581482 0.6838240027427673\n",
      "[Step 4408] Loss: 9.84e+07 0.5537477135658264 0.6837645769119263\n",
      "[Step 4409] Loss: 9.94e+07 0.5537906885147095 0.6837282776832581\n",
      "[Step 4410] Loss: 9.86e+07 0.5538424253463745 0.6837076544761658\n",
      "[Step 4411] Loss: 9.94e+07 0.553805947303772 0.683630108833313\n",
      "[Step 4412] Loss: 9.91e+07 0.5538650155067444 0.6836028695106506\n",
      "[Step 4413] Loss: 9.99e+07 0.5537522435188293 0.6835063099861145\n",
      "[Step 4414] Loss: 9.94e+07 0.5537455081939697 0.6834320425987244\n",
      "[Step 4415] Loss: 9.91e+07 0.553793728351593 0.6833487153053284\n",
      "[Step 4416] Loss: 9.79e+07 0.5538040399551392 0.6832802295684814\n",
      "[Step 4417] Loss: 9.88e+07 0.5538806319236755 0.6832505464553833\n",
      "[Step 4418] Loss: 9.86e+07 0.5539372563362122 0.6831977367401123\n",
      "[Step 4419] Loss: 9.89e+07 0.5540647506713867 0.6831531524658203\n",
      "[Step 4420] Loss: 9.84e+07 0.5541478395462036 0.6830747723579407\n",
      "[Step 4421] Loss: 9.79e+07 0.5542635917663574 0.6830178499221802\n",
      "[Step 4422] Loss: 9.85e+07 0.5543050169944763 0.6829493641853333\n",
      "[Step 4423] Loss: 9.91e+07 0.5543273091316223 0.6829056143760681\n",
      "[Step 4424] Loss: 9.90e+07 0.5542985200881958 0.6828214526176453\n",
      "[Step 4425] Loss: 9.83e+07 0.5542894601821899 0.6827282309532166\n",
      "[Step 4426] Loss: 9.83e+07 0.5542422533035278 0.682620108127594\n",
      "[Step 4427] Loss: 9.87e+07 0.5541926026344299 0.6825442314147949\n",
      "[Step 4428] Loss: 9.90e+07 0.5541002154350281 0.6824246048927307\n",
      "[Step 4429] Loss: 1.00e+08 0.553845226764679 0.6822694540023804\n",
      "[Step 4430] Loss: 9.95e+07 0.5533916354179382 0.68205326795578\n",
      "[Step 4431] Loss: 9.83e+07 0.5529509782791138 0.6818007826805115\n",
      "[Step 4432] Loss: 9.83e+07 0.5525642037391663 0.6815548539161682\n",
      "[Step 4433] Loss: 9.94e+07 0.5521514415740967 0.6813106536865234\n",
      "[Step 4434] Loss: 9.89e+07 0.5518405437469482 0.6810870170593262\n",
      "[Step 4435] Loss: 9.82e+07 0.5515797138214111 0.6808757781982422\n",
      "[Step 4436] Loss: 9.92e+07 0.5513595938682556 0.6806893348693848\n",
      "[Step 4437] Loss: 9.85e+07 0.5512076020240784 0.6805506944656372\n",
      "[Step 4438] Loss: 9.90e+07 0.5511159300804138 0.6804409623146057\n",
      "[Step 4439] Loss: 9.96e+07 0.5511319041252136 0.6804038286209106\n",
      "[Step 4440] Loss: 9.93e+07 0.5510377883911133 0.6803023219108582\n",
      "[Step 4441] Loss: 9.84e+07 0.5509359836578369 0.6802115440368652\n",
      "[Step 4442] Loss: 9.84e+07 0.5509201288223267 0.6801117062568665\n",
      "[Step 4443] Loss: 9.81e+07 0.5508296489715576 0.6799821853637695\n",
      "[Step 4444] Loss: 9.89e+07 0.5507906675338745 0.6798938512802124\n",
      "[Step 4445] Loss: 9.97e+07 0.55070561170578 0.6798328161239624\n",
      "[Step 4446] Loss: 9.96e+07 0.5504916906356812 0.6797255277633667\n",
      "[Step 4447] Loss: 9.88e+07 0.5503113865852356 0.6795852780342102\n",
      "[Step 4448] Loss: 9.85e+07 0.5501461625099182 0.6795027852058411\n",
      "[Step 4449] Loss: 9.86e+07 0.5500843524932861 0.6794590353965759\n",
      "[Step 4450] Loss: 9.85e+07 0.5500333905220032 0.6794202327728271\n",
      "[Step 4451] Loss: 9.80e+07 0.5499244928359985 0.6793583631515503\n",
      "[Step 4452] Loss: 9.84e+07 0.5498020052909851 0.6793088316917419\n",
      "[Step 4453] Loss: 9.80e+07 0.5496428608894348 0.6792453527450562\n",
      "[Step 4454] Loss: 9.77e+07 0.5494762659072876 0.6791760325431824\n",
      "[Step 4455] Loss: 9.90e+07 0.5493661165237427 0.6791446805000305\n",
      "[Step 4456] Loss: 9.84e+07 0.5492331385612488 0.6790530681610107\n",
      "[Step 4457] Loss: 9.86e+07 0.5491601824760437 0.6789581775665283\n",
      "[Step 4458] Loss: 9.85e+07 0.549135684967041 0.6788814663887024\n",
      "[Step 4459] Loss: 9.97e+07 0.5489259958267212 0.6787394881248474\n",
      "[Step 4460] Loss: 9.88e+07 0.5487915873527527 0.6786503791809082\n",
      "[Step 4461] Loss: 9.80e+07 0.5487074851989746 0.6785818934440613\n",
      "[Step 4462] Loss: 1.00e+08 0.5484926700592041 0.6783954501152039\n",
      "[Step 4463] Loss: 9.87e+07 0.5483202338218689 0.67825847864151\n",
      "[Step 4464] Loss: 9.83e+07 0.5481962561607361 0.6780983805656433\n",
      "[Step 4465] Loss: 9.88e+07 0.5481026768684387 0.677994430065155\n",
      "[Step 4466] Loss: 9.86e+07 0.547997772693634 0.677890419960022\n",
      "[Step 4467] Loss: 9.91e+07 0.5479350090026855 0.6777864694595337\n",
      "[Step 4468] Loss: 9.84e+07 0.5478296279907227 0.6776849627494812\n",
      "[Step 4469] Loss: 9.89e+07 0.5477134585380554 0.6775702834129333\n",
      "[Step 4470] Loss: 9.77e+07 0.5475662350654602 0.6774654984474182\n",
      "[Step 4471] Loss: 9.77e+07 0.5474337935447693 0.6773442029953003\n",
      "[Step 4472] Loss: 9.86e+07 0.5473480224609375 0.6772121787071228\n",
      "[Step 4473] Loss: 9.84e+07 0.5471773147583008 0.6770727634429932\n",
      "[Step 4474] Loss: 9.99e+07 0.5469089150428772 0.6769043803215027\n",
      "[Step 4475] Loss: 9.85e+07 0.5465602278709412 0.6767047047615051\n",
      "[Step 4476] Loss: 1.01e+08 0.5460399985313416 0.6764976382255554\n",
      "[Step 4477] Loss: 9.86e+07 0.5455365180969238 0.6762847304344177\n",
      "[Step 4478] Loss: 9.79e+07 0.5451416969299316 0.6760842204093933\n",
      "[Step 4479] Loss: 9.90e+07 0.5448192954063416 0.6759084463119507\n",
      "[Step 4480] Loss: 9.70e+07 0.5445297360420227 0.675738513469696\n",
      "[Step 4481] Loss: 9.92e+07 0.5441915392875671 0.6755717992782593\n",
      "[Step 4482] Loss: 9.88e+07 0.5439115166664124 0.6754183173179626\n",
      "[Step 4483] Loss: 9.82e+07 0.5436553359031677 0.6752690076828003\n",
      "[Step 4484] Loss: 9.85e+07 0.5434470176696777 0.6750973463058472\n",
      "[Step 4485] Loss: 9.90e+07 0.5431698560714722 0.6749736070632935\n",
      "[Step 4486] Loss: 9.79e+07 0.5429362058639526 0.6748316884040833\n",
      "[Step 4487] Loss: 9.96e+07 0.542818546295166 0.6747120022773743\n",
      "[Step 4488] Loss: 9.83e+07 0.5427401065826416 0.6746171116828918\n",
      "[Step 4489] Loss: 9.89e+07 0.5426639914512634 0.6745181083679199\n",
      "[Step 4490] Loss: 9.82e+07 0.5425902605056763 0.6744207739830017\n",
      "[Step 4491] Loss: 9.88e+07 0.5425021052360535 0.6743167638778687\n",
      "[Step 4492] Loss: 9.83e+07 0.5423266291618347 0.6742119789123535\n",
      "[Step 4493] Loss: 9.75e+07 0.5421887040138245 0.6741567254066467\n",
      "[Step 4494] Loss: 9.87e+07 0.5420173406600952 0.6740807890892029\n",
      "[Step 4495] Loss: 9.82e+07 0.5418787002563477 0.6740172505378723\n",
      "[Step 4496] Loss: 9.85e+07 0.5418248772621155 0.6739479303359985\n",
      "[Step 4497] Loss: 9.88e+07 0.5418017506599426 0.6738959550857544\n",
      "[Step 4498] Loss: 9.80e+07 0.5417804718017578 0.6738646030426025\n",
      "[Step 4499] Loss: 9.76e+07 0.5417858362197876 0.6738349199295044\n",
      "[Step 4500] Loss: 9.95e+07 0.5418701171875 0.6738027334213257\n",
      "[Step 4501] Loss: 9.84e+07 0.5420057773590088 0.6737961173057556\n",
      "[Step 4502] Loss: 9.80e+07 0.5420992970466614 0.6737507581710815\n",
      "[Step 4503] Loss: 9.88e+07 0.5422236323356628 0.67376309633255\n",
      "[Step 4504] Loss: 9.84e+07 0.5423849821090698 0.6737829446792603\n",
      "[Step 4505] Loss: 9.78e+07 0.5424925088882446 0.6737754940986633\n",
      "[Step 4506] Loss: 9.86e+07 0.5425428152084351 0.6737573146820068\n",
      "[Step 4507] Loss: 1.00e+08 0.5424520373344421 0.673687219619751\n",
      "[Step 4508] Loss: 9.74e+07 0.5423149466514587 0.6736038327217102\n",
      "[Step 4509] Loss: 9.90e+07 0.5421139001846313 0.673498272895813\n",
      "[Step 4510] Loss: 9.87e+07 0.5419088006019592 0.6733843684196472\n",
      "[Step 4511] Loss: 9.82e+07 0.5418062210083008 0.6732960939407349\n",
      "[Step 4512] Loss: 9.80e+07 0.5417011976242065 0.6731640696525574\n",
      "[Step 4513] Loss: 1.00e+08 0.541435718536377 0.6730039715766907\n",
      "[Step 4514] Loss: 9.92e+07 0.5412031412124634 0.6728233098983765\n",
      "[Step 4515] Loss: 9.90e+07 0.5408712029457092 0.6726409196853638\n",
      "[Step 4516] Loss: 9.87e+07 0.5405838489532471 0.6724470257759094\n",
      "[Step 4517] Loss: 9.91e+07 0.5403711795806885 0.6723182797431946\n",
      "[Step 4518] Loss: 9.88e+07 0.5402017831802368 0.6721928715705872\n",
      "[Step 4519] Loss: 9.99e+07 0.5399115681648254 0.6720319986343384\n",
      "[Step 4520] Loss: 9.90e+07 0.5396081209182739 0.6718867421150208\n",
      "[Step 4521] Loss: 9.89e+07 0.5392923355102539 0.6717151403427124\n",
      "[Step 4522] Loss: 9.91e+07 0.5390469431877136 0.6715814471244812\n",
      "[Step 4523] Loss: 9.84e+07 0.5388516783714294 0.6714296340942383\n",
      "[Step 4524] Loss: 9.89e+07 0.5386790037155151 0.6712613105773926\n",
      "[Step 4525] Loss: 9.86e+07 0.5385213494300842 0.6710995435714722\n",
      "[Step 4526] Loss: 9.87e+07 0.5384275913238525 0.6710162162780762\n",
      "[Step 4527] Loss: 9.86e+07 0.5384138822555542 0.670957624912262\n",
      "[Step 4528] Loss: 1.02e+08 0.5381320118904114 0.6708041429519653\n",
      "[Step 4529] Loss: 9.82e+07 0.537869393825531 0.670639157295227\n",
      "[Step 4530] Loss: 9.86e+07 0.5376632213592529 0.6705062985420227\n",
      "[Step 4531] Loss: 9.86e+07 0.537405788898468 0.6703478693962097\n",
      "[Step 4532] Loss: 9.82e+07 0.5370720624923706 0.6701960563659668\n",
      "[Step 4533] Loss: 9.83e+07 0.5368067026138306 0.6700648665428162\n",
      "[Step 4534] Loss: 9.87e+07 0.5365484356880188 0.669922947883606\n",
      "[Step 4535] Loss: 9.82e+07 0.5362702012062073 0.669764518737793\n",
      "[Step 4536] Loss: 9.77e+07 0.5360360145568848 0.6696200966835022\n",
      "[Step 4537] Loss: 9.81e+07 0.535949170589447 0.6695689558982849\n",
      "[Step 4538] Loss: 9.81e+07 0.5359771251678467 0.6695491671562195\n",
      "[Step 4539] Loss: 9.85e+07 0.5359499454498291 0.6694913506507874\n",
      "[Step 4540] Loss: 9.81e+07 0.5358788967132568 0.6694517731666565\n",
      "[Step 4541] Loss: 9.88e+07 0.5358773469924927 0.6694236993789673\n",
      "[Step 4542] Loss: 9.84e+07 0.5358280539512634 0.6694014668464661\n",
      "[Step 4543] Loss: 9.91e+07 0.5357520580291748 0.6693148016929626\n",
      "[Step 4544] Loss: 9.82e+07 0.5356159806251526 0.6692289710044861\n",
      "[Step 4545] Loss: 9.87e+07 0.5353905558586121 0.6691060662269592\n",
      "[Step 4546] Loss: 9.83e+07 0.5351966023445129 0.6690161228179932\n",
      "[Step 4547] Loss: 9.83e+07 0.5350655317306519 0.6689616441726685\n",
      "[Step 4548] Loss: 9.87e+07 0.5349799394607544 0.668882429599762\n",
      "[Step 4549] Loss: 9.77e+07 0.5349283218383789 0.6688427925109863\n",
      "[Step 4550] Loss: 9.86e+07 0.5349271893501282 0.6687809228897095\n",
      "[Step 4551] Loss: 9.78e+07 0.5349256992340088 0.6687536835670471\n",
      "[Step 4552] Loss: 9.77e+07 0.534915566444397 0.6686951518058777\n",
      "[Step 4553] Loss: 9.83e+07 0.5348820686340332 0.6686340570449829\n",
      "[Step 4554] Loss: 9.79e+07 0.5348698496818542 0.6685589551925659\n",
      "[Step 4555] Loss: 1.00e+08 0.5346946120262146 0.6684335470199585\n",
      "[Step 4556] Loss: 9.87e+07 0.5346409678459167 0.6683560013771057\n",
      "[Step 4557] Loss: 9.88e+07 0.5345408320426941 0.6682462692260742\n",
      "[Step 4558] Loss: 9.96e+07 0.5343441367149353 0.6681357026100159\n",
      "[Step 4559] Loss: 1.00e+08 0.5344062447547913 0.668067216873169\n",
      "[Step 4560] Loss: 9.74e+07 0.534512460231781 0.6680391430854797\n",
      "[Step 4561] Loss: 9.93e+07 0.5346918702125549 0.6679953932762146\n",
      "[Step 4562] Loss: 9.84e+07 0.5348675847053528 0.6680110692977905\n",
      "[Step 4563] Loss: 9.89e+07 0.5350911021232605 0.6680052876472473\n",
      "[Step 4564] Loss: 9.88e+07 0.5353361368179321 0.6680020093917847\n",
      "[Step 4565] Loss: 9.88e+07 0.5355961918830872 0.6680168509483337\n",
      "[Step 4566] Loss: 9.76e+07 0.5358075499534607 0.6680020093917847\n",
      "[Step 4567] Loss: 9.83e+07 0.5360025763511658 0.6679962277412415\n",
      "[Step 4568] Loss: 9.85e+07 0.5361030101776123 0.6679731011390686\n",
      "[Step 4569] Loss: 9.80e+07 0.5362274050712585 0.6679714918136597\n",
      "[Step 4570] Loss: 9.82e+07 0.5363542437553406 0.6679756045341492\n",
      "[Step 4571] Loss: 9.87e+07 0.5365421175956726 0.6679805517196655\n",
      "[Step 4572] Loss: 9.71e+07 0.5367304086685181 0.6680193543434143\n",
      "[Step 4573] Loss: 9.83e+07 0.5367978811264038 0.6679904460906982\n",
      "[Step 4574] Loss: 9.90e+07 0.5368902683258057 0.6679871678352356\n",
      "[Step 4575] Loss: 9.80e+07 0.5368970632553101 0.6679483652114868\n",
      "[Step 4576] Loss: 9.83e+07 0.5368797779083252 0.6679071187973022\n",
      "[Step 4577] Loss: 1.00e+08 0.5367200374603271 0.6678369641304016\n",
      "[Step 4578] Loss: 9.81e+07 0.5366077423095703 0.6677420735359192\n",
      "[Step 4579] Loss: 9.74e+07 0.5365139842033386 0.6676719784736633\n",
      "[Step 4580] Loss: 9.82e+07 0.536377489566803 0.6675786972045898\n",
      "[Step 4581] Loss: 9.77e+07 0.5362526178359985 0.6674838066101074\n",
      "[Step 4582] Loss: 9.83e+07 0.5360866785049438 0.6673996448516846\n",
      "[Step 4583] Loss: 9.91e+07 0.5359377264976501 0.6673394441604614\n",
      "[Step 4584] Loss: 9.81e+07 0.5357598066329956 0.6672824621200562\n",
      "[Step 4585] Loss: 9.90e+07 0.5355977416038513 0.6671991348266602\n",
      "[Step 4586] Loss: 9.81e+07 0.5354870557785034 0.6671273708343506\n",
      "[Step 4587] Loss: 9.82e+07 0.5353665351867676 0.6670423746109009\n",
      "[Step 4588] Loss: 9.84e+07 0.5351739525794983 0.6669021248817444\n",
      "[Step 4589] Loss: 9.77e+07 0.5349980592727661 0.6667841076850891\n",
      "[Step 4590] Loss: 9.81e+07 0.5348102450370789 0.6666529178619385\n",
      "[Step 4591] Loss: 9.83e+07 0.5346493721008301 0.6665374040603638\n",
      "[Step 4592] Loss: 9.83e+07 0.534436047077179 0.6664136052131653\n",
      "[Step 4593] Loss: 9.94e+07 0.5342159271240234 0.6663030385971069\n",
      "[Step 4594] Loss: 9.82e+07 0.5339399576187134 0.6661718487739563\n",
      "[Step 4595] Loss: 9.87e+07 0.5336912870407104 0.6660274267196655\n",
      "[Step 4596] Loss: 9.88e+07 0.5334062576293945 0.665894627571106\n",
      "[Step 4597] Loss: 9.83e+07 0.5331485271453857 0.6657848358154297\n",
      "[Step 4598] Loss: 9.85e+07 0.532892644405365 0.6656338572502136\n",
      "[Step 4599] Loss: 9.70e+07 0.5326672792434692 0.6654564738273621\n",
      "[Step 4600] Loss: 9.74e+07 0.5324918627738953 0.6653450727462769\n",
      "[Step 4601] Loss: 9.82e+07 0.5323367118835449 0.6652534604072571\n",
      "[Step 4602] Loss: 9.89e+07 0.5321445465087891 0.6651222705841064\n",
      "[Step 4603] Loss: 9.79e+07 0.5319649577140808 0.6649712920188904\n",
      "[Step 4604] Loss: 9.87e+07 0.5318310260772705 0.6648557782173157\n",
      "[Step 4605] Loss: 9.75e+07 0.5316900610923767 0.6647418737411499\n",
      "[Step 4606] Loss: 9.90e+07 0.53160560131073 0.6646643280982971\n",
      "[Step 4607] Loss: 9.85e+07 0.5315396189689636 0.6646181344985962\n",
      "[Step 4608] Loss: 9.81e+07 0.5313881635665894 0.6644737124443054\n",
      "[Step 4609] Loss: 9.80e+07 0.5313272476196289 0.6643878817558289\n",
      "[Step 4610] Loss: 9.86e+07 0.5312025547027588 0.6643301248550415\n",
      "[Step 4611] Loss: 9.85e+07 0.5311129093170166 0.6642723679542542\n",
      "[Step 4612] Loss: 9.92e+07 0.5309708714485168 0.6642038822174072\n",
      "[Step 4613] Loss: 9.79e+07 0.5308797955513 0.6642063856124878\n",
      "[Step 4614] Loss: 9.88e+07 0.5307362675666809 0.6640892028808594\n",
      "[Step 4615] Loss: 9.90e+07 0.5306388735771179 0.6640355587005615\n",
      "[Step 4616] Loss: 9.91e+07 0.530418872833252 0.6639621257781982\n",
      "[Step 4617] Loss: 9.79e+07 0.5302315354347229 0.6638845801353455\n",
      "[Step 4618] Loss: 9.85e+07 0.5300661325454712 0.6638045310974121\n",
      "[Step 4619] Loss: 9.88e+07 0.5297862887382507 0.6637459397315979\n",
      "[Step 4620] Loss: 9.75e+07 0.5296312570571899 0.663669228553772\n",
      "[Step 4621] Loss: 9.86e+07 0.5294932723045349 0.663594126701355\n",
      "[Step 4622] Loss: 9.82e+07 0.5294155478477478 0.6635305881500244\n",
      "[Step 4623] Loss: 9.78e+07 0.5293802618980408 0.6635322570800781\n",
      "[Step 4624] Loss: 9.88e+07 0.5292549133300781 0.6634860038757324\n",
      "[Step 4625] Loss: 9.96e+07 0.5290467143058777 0.6634068489074707\n",
      "[Step 4626] Loss: 9.89e+07 0.528917133808136 0.6633754372596741\n",
      "[Step 4627] Loss: 9.86e+07 0.5287466049194336 0.6633242964744568\n",
      "[Step 4628] Loss: 9.88e+07 0.5286624431610107 0.6632541418075562\n",
      "[Step 4629] Loss: 9.91e+07 0.5285084247589111 0.6631692051887512\n",
      "[Step 4630] Loss: 9.88e+07 0.5284538865089417 0.6631056666374207\n",
      "[Step 4631] Loss: 9.82e+07 0.52848219871521 0.6630743145942688\n",
      "[Step 4632] Loss: 9.88e+07 0.5284680724143982 0.6630000472068787\n",
      "[Step 4633] Loss: 9.83e+07 0.5284820795059204 0.662938117980957\n",
      "[Step 4634] Loss: 9.86e+07 0.5284001231193542 0.6628226041793823\n",
      "[Step 4635] Loss: 9.85e+07 0.5283203125 0.6627219319343567\n",
      "[Step 4636] Loss: 9.85e+07 0.5282180309295654 0.6626278758049011\n",
      "[Step 4637] Loss: 9.87e+07 0.5281352996826172 0.6625387668609619\n",
      "[Step 4638] Loss: 9.80e+07 0.528041422367096 0.6624265313148499\n",
      "[Step 4639] Loss: 9.86e+07 0.528022289276123 0.6623465418815613\n",
      "[Step 4640] Loss: 9.72e+07 0.5280207395553589 0.6622961759567261\n",
      "[Step 4641] Loss: 9.80e+07 0.5280490517616272 0.6622830033302307\n",
      "[Step 4642] Loss: 9.78e+07 0.5281955003738403 0.662281334400177\n",
      "[Step 4643] Loss: 9.83e+07 0.5283396244049072 0.662259042263031\n",
      "[Step 4644] Loss: 9.91e+07 0.5284960269927979 0.6621806621551514\n",
      "[Step 4645] Loss: 9.84e+07 0.5285673141479492 0.6621212363243103\n",
      "[Step 4646] Loss: 9.89e+07 0.5285085439682007 0.6620354652404785\n",
      "[Step 4647] Loss: 9.89e+07 0.5283730626106262 0.661903440952301\n",
      "[Step 4648] Loss: 9.83e+07 0.5282719135284424 0.6617235541343689\n",
      "[Step 4649] Loss: 9.82e+07 0.5281583070755005 0.6616294980049133\n",
      "[Step 4650] Loss: 9.83e+07 0.528167724609375 0.6615387201309204\n",
      "[Step 4651] Loss: 9.95e+07 0.5281801819801331 0.6614355444908142\n",
      "[Step 4652] Loss: 9.91e+07 0.5283182263374329 0.6613901853561401\n",
      "[Step 4653] Loss: 9.79e+07 0.5284669995307922 0.6613654494285583\n",
      "[Step 4654] Loss: 9.85e+07 0.5285320281982422 0.6613439917564392\n",
      "[Step 4655] Loss: 9.89e+07 0.5286383628845215 0.6613481044769287\n",
      "[Step 4656] Loss: 9.83e+07 0.5286022424697876 0.6612449884414673\n",
      "[Step 4657] Loss: 9.87e+07 0.5286167860031128 0.6612152457237244\n",
      "[Step 4658] Loss: 9.85e+07 0.528559148311615 0.6611335873603821\n",
      "[Step 4659] Loss: 9.87e+07 0.5285714268684387 0.6610832214355469\n",
      "[Step 4660] Loss: 9.87e+07 0.5286489725112915 0.6610692143440247\n",
      "[Step 4661] Loss: 9.86e+07 0.5287063121795654 0.6610535383224487\n",
      "[Step 4662] Loss: 9.78e+07 0.5288059115409851 0.6610411405563354\n",
      "[Step 4663] Loss: 9.78e+07 0.5288804173469543 0.6610329151153564\n",
      "[Step 4664] Loss: 9.71e+07 0.528940737247467 0.6609949469566345\n",
      "[Step 4665] Loss: 9.82e+07 0.5289514064788818 0.6609652638435364\n",
      "[Step 4666] Loss: 9.76e+07 0.5289832949638367 0.6609627604484558\n",
      "[Step 4667] Loss: 9.80e+07 0.529090166091919 0.6609264612197876\n",
      "[Step 4668] Loss: 9.88e+07 0.5293056964874268 0.6609726548194885\n",
      "[Step 4669] Loss: 9.81e+07 0.5295414328575134 0.6610122919082642\n",
      "[Step 4670] Loss: 9.79e+07 0.5297840237617493 0.6610568165779114\n",
      "[Step 4671] Loss: 9.79e+07 0.5299049615859985 0.661074161529541\n",
      "[Step 4672] Loss: 9.83e+07 0.5299113988876343 0.6610386967658997\n",
      "[Step 4673] Loss: 9.84e+07 0.5299021601676941 0.6610056757926941\n",
      "[Step 4674] Loss: 9.94e+07 0.5297672152519226 0.660968542098999\n",
      "[Step 4675] Loss: 9.80e+07 0.5295560956001282 0.6609000563621521\n",
      "[Step 4676] Loss: 9.82e+07 0.5294195413589478 0.6608348488807678\n",
      "[Step 4677] Loss: 9.85e+07 0.5292844176292419 0.6607911586761475\n",
      "[Step 4678] Loss: 9.79e+07 0.5291606783866882 0.6607474088668823\n",
      "[Step 4679] Loss: 9.76e+07 0.5290061831474304 0.660697877407074\n",
      "[Step 4680] Loss: 9.83e+07 0.5288236737251282 0.6606013774871826\n",
      "[Step 4681] Loss: 9.83e+07 0.5287858843803406 0.6605427861213684\n",
      "[Step 4682] Loss: 9.74e+07 0.5288352370262146 0.6605443954467773\n",
      "[Step 4683] Loss: 9.95e+07 0.5289934277534485 0.6605336666107178\n",
      "[Step 4684] Loss: 9.90e+07 0.529019832611084 0.6605097651481628\n",
      "[Step 4685] Loss: 9.93e+07 0.529186487197876 0.6605477333068848\n",
      "[Step 4686] Loss: 9.81e+07 0.5293733477592468 0.6605625748634338\n",
      "[Step 4687] Loss: 9.90e+07 0.5295529961585999 0.6606005430221558\n",
      "[Step 4688] Loss: 9.83e+07 0.5296242833137512 0.660584032535553\n",
      "[Step 4689] Loss: 9.91e+07 0.5296247601509094 0.6605303883552551\n",
      "[Step 4690] Loss: 9.82e+07 0.5296340584754944 0.6604924201965332\n",
      "[Step 4691] Loss: 9.86e+07 0.529662549495697 0.6604800820350647\n",
      "[Step 4692] Loss: 9.83e+07 0.5296927094459534 0.6604660153388977\n",
      "[Step 4693] Loss: 9.83e+07 0.529729962348938 0.6604173183441162\n",
      "[Step 4694] Loss: 9.79e+07 0.5297677516937256 0.6603373289108276\n",
      "[Step 4695] Loss: 9.85e+07 0.5298354029655457 0.660319983959198\n",
      "[Step 4696] Loss: 9.92e+07 0.5298067927360535 0.6602523326873779\n",
      "[Step 4697] Loss: 9.79e+07 0.5297254920005798 0.6601887941360474\n",
      "[Step 4698] Loss: 9.91e+07 0.5296854376792908 0.6601491570472717\n",
      "[Step 4699] Loss: 9.80e+07 0.5297133922576904 0.6600757241249084\n",
      "[Step 4700] Loss: 9.83e+07 0.5296635627746582 0.6600427627563477\n",
      "[Step 4701] Loss: 9.76e+07 0.5295886397361755 0.659980833530426\n",
      "[Step 4702] Loss: 9.90e+07 0.5293614864349365 0.65989089012146\n",
      "[Step 4703] Loss: 9.81e+07 0.5291440486907959 0.6597787141799927\n",
      "[Step 4704] Loss: 9.82e+07 0.5289481282234192 0.6597027778625488\n",
      "[Step 4705] Loss: 9.90e+07 0.5288082361221313 0.6596087217330933\n",
      "[Step 4706] Loss: 9.81e+07 0.5286858677864075 0.6595699191093445\n",
      "[Step 4707] Loss: 9.86e+07 0.5285815000534058 0.6595088839530945\n",
      "[Step 4708] Loss: 9.87e+07 0.528529942035675 0.6594354510307312\n",
      "[Step 4709] Loss: 9.82e+07 0.5285642147064209 0.6593760251998901\n",
      "[Step 4710] Loss: 9.80e+07 0.5286306738853455 0.659346342086792\n",
      "[Step 4711] Loss: 9.84e+07 0.5286459922790527 0.6592828035354614\n",
      "[Step 4712] Loss: 9.85e+07 0.5286083817481995 0.6592159271240234\n",
      "[Step 4713] Loss: 9.74e+07 0.5285207033157349 0.6591252088546753\n",
      "[Step 4714] Loss: 9.82e+07 0.5284366607666016 0.6590319275856018\n",
      "[Step 4715] Loss: 9.80e+07 0.5282759666442871 0.6589040756225586\n",
      "[Step 4716] Loss: 9.88e+07 0.528106153011322 0.6587860584259033\n",
      "[Step 4717] Loss: 9.86e+07 0.5279232859611511 0.6586416363716125\n",
      "[Step 4718] Loss: 9.79e+07 0.5277062654495239 0.658501386642456\n",
      "[Step 4719] Loss: 9.85e+07 0.527540922164917 0.65841144323349\n",
      "[Step 4720] Loss: 9.85e+07 0.5273435115814209 0.6582852005958557\n",
      "[Step 4721] Loss: 9.90e+07 0.527104914188385 0.6581606268882751\n",
      "[Step 4722] Loss: 9.95e+07 0.5267638564109802 0.6579831838607788\n",
      "[Step 4723] Loss: 9.79e+07 0.526449978351593 0.657830536365509\n",
      "[Step 4724] Loss: 9.88e+07 0.5262497663497925 0.6577092409133911\n",
      "[Step 4725] Loss: 9.80e+07 0.5260154008865356 0.657543420791626\n",
      "[Step 4726] Loss: 9.90e+07 0.5258966684341431 0.657454252243042\n",
      "[Step 4727] Loss: 9.81e+07 0.525799572467804 0.6573635339736938\n",
      "[Step 4728] Loss: 9.94e+07 0.5256038904190063 0.657204270362854\n",
      "[Step 4729] Loss: 9.82e+07 0.5253984332084656 0.6571225523948669\n",
      "[Step 4730] Loss: 9.83e+07 0.5251455307006836 0.6569839715957642\n",
      "[Step 4731] Loss: 9.93e+07 0.5248388648033142 0.6568371057510376\n",
      "[Step 4732] Loss: 9.90e+07 0.5245043039321899 0.6567100286483765\n",
      "[Step 4733] Loss: 9.81e+07 0.5241531729698181 0.656562328338623\n",
      "[Step 4734] Loss: 9.86e+07 0.523870587348938 0.6563964486122131\n",
      "[Step 4735] Loss: 9.84e+07 0.523639976978302 0.6562578082084656\n",
      "[Step 4736] Loss: 9.78e+07 0.5233667492866516 0.6561225056648254\n",
      "[Step 4737] Loss: 9.83e+07 0.5231590867042542 0.656012773513794\n",
      "[Step 4738] Loss: 9.81e+07 0.5230404734611511 0.6559146046638489\n",
      "[Step 4739] Loss: 9.78e+07 0.5229058861732483 0.6558485627174377\n",
      "[Step 4740] Loss: 9.79e+07 0.5227286219596863 0.6557669043540955\n",
      "[Step 4741] Loss: 9.82e+07 0.5225725769996643 0.655651330947876\n",
      "[Step 4742] Loss: 9.75e+07 0.5224082469940186 0.6555630564689636\n",
      "[Step 4743] Loss: 9.74e+07 0.5223538875579834 0.6554673314094543\n",
      "[Step 4744] Loss: 9.81e+07 0.5223889350891113 0.6554558277130127\n",
      "[Step 4745] Loss: 9.84e+07 0.5225503444671631 0.6554904580116272\n",
      "[Step 4746] Loss: 9.82e+07 0.5228179693222046 0.6555193066596985\n",
      "[Step 4747] Loss: 9.86e+07 0.5230534672737122 0.6555490493774414\n",
      "[Step 4748] Loss: 9.78e+07 0.5232086181640625 0.6555877923965454\n",
      "[Step 4749] Loss: 9.82e+07 0.5233175158500671 0.655582070350647\n",
      "[Step 4750] Loss: 9.78e+07 0.5234326720237732 0.655559778213501\n",
      "[Step 4751] Loss: 9.72e+07 0.5235040187835693 0.6555193066596985\n",
      "[Step 4752] Loss: 9.80e+07 0.523612380027771 0.6555127501487732\n",
      "[Step 4753] Loss: 9.86e+07 0.5237229466438293 0.6554830074310303\n",
      "[Step 4754] Loss: 9.79e+07 0.5238779187202454 0.6554986834526062\n",
      "[Step 4755] Loss: 9.82e+07 0.5239800214767456 0.6555110812187195\n",
      "[Step 4756] Loss: 9.78e+07 0.5240761637687683 0.6555061340332031\n",
      "[Step 4757] Loss: 9.83e+07 0.5241352319717407 0.6555020213127136\n",
      "[Step 4758] Loss: 9.84e+07 0.5243154168128967 0.6555275917053223\n",
      "[Step 4759] Loss: 9.76e+07 0.5244408249855042 0.6554954051971436\n",
      "[Step 4760] Loss: 9.88e+07 0.524662435054779 0.6555424332618713\n",
      "[Step 4761] Loss: 9.84e+07 0.5249387621879578 0.6556150317192078\n",
      "[Step 4762] Loss: 9.80e+07 0.5252372622489929 0.6556835174560547\n",
      "[Step 4763] Loss: 1.00e+08 0.5253203511238098 0.6556183695793152\n",
      "[Step 4764] Loss: 9.82e+07 0.5253925919532776 0.6556117534637451\n",
      "[Step 4765] Loss: 9.67e+07 0.525465190410614 0.6555754542350769\n",
      "[Step 4766] Loss: 9.96e+07 0.5253463387489319 0.6555044651031494\n",
      "[Step 4767] Loss: 9.80e+07 0.5253117680549622 0.6554822325706482\n",
      "[Step 4768] Loss: 9.78e+07 0.5252832174301147 0.6554112434387207\n",
      "[Step 4769] Loss: 9.83e+07 0.5251874923706055 0.6553105711936951\n",
      "[Step 4770] Loss: 9.94e+07 0.5249636769294739 0.6551802158355713\n",
      "[Step 4771] Loss: 9.74e+07 0.524783730506897 0.6550647020339966\n",
      "[Step 4772] Loss: 9.84e+07 0.5246641635894775 0.6549863219261169\n",
      "[Step 4773] Loss: 9.87e+07 0.5246096849441528 0.654933512210846\n",
      "[Step 4774] Loss: 9.85e+07 0.5245479345321655 0.6548129916191101\n",
      "[Step 4775] Loss: 9.86e+07 0.5243704319000244 0.6546974778175354\n",
      "[Step 4776] Loss: 9.84e+07 0.5241187214851379 0.6545522809028625\n",
      "[Step 4777] Loss: 9.93e+07 0.5237346887588501 0.6543921828269958\n",
      "[Step 4778] Loss: 9.79e+07 0.5234053134918213 0.6542362570762634\n",
      "[Step 4779] Loss: 9.80e+07 0.523110032081604 0.6540844440460205\n",
      "[Step 4780] Loss: 9.75e+07 0.5229597687721252 0.6539903283119202\n",
      "[Step 4781] Loss: 9.82e+07 0.5227276682853699 0.6538566946983337\n",
      "[Step 4782] Loss: 9.80e+07 0.5224350690841675 0.6537073254585266\n",
      "[Step 4783] Loss: 9.88e+07 0.5220421552658081 0.6535274386405945\n",
      "[Step 4784] Loss: 9.82e+07 0.5217682719230652 0.6533500552177429\n",
      "[Step 4785] Loss: 9.83e+07 0.5214971899986267 0.6532130837440491\n",
      "[Step 4786] Loss: 9.81e+07 0.5212737917900085 0.6530381441116333\n",
      "[Step 4787] Loss: 9.82e+07 0.5210628509521484 0.6529300808906555\n",
      "[Step 4788] Loss: 9.78e+07 0.5208436250686646 0.6528071165084839\n",
      "[Step 4789] Loss: 9.79e+07 0.5206517577171326 0.6526651978492737\n",
      "[Step 4790] Loss: 9.80e+07 0.5204067826271057 0.6525092124938965\n",
      "[Step 4791] Loss: 9.81e+07 0.5201795697212219 0.6524151563644409\n",
      "[Step 4792] Loss: 9.93e+07 0.519851565361023 0.652271568775177\n",
      "[Step 4793] Loss: 9.83e+07 0.5194969177246094 0.6521090269088745\n",
      "[Step 4794] Loss: 9.79e+07 0.519227921962738 0.6519868969917297\n",
      "[Step 4795] Loss: 9.77e+07 0.5190262198448181 0.6519052386283875\n",
      "[Step 4796] Loss: 9.78e+07 0.5188151597976685 0.6518375873565674\n",
      "[Step 4797] Loss: 9.78e+07 0.518678605556488 0.6517757177352905\n",
      "[Step 4798] Loss: 9.78e+07 0.5185166001319885 0.6517146229743958\n",
      "[Step 4799] Loss: 9.87e+07 0.5184946060180664 0.6516873836517334\n",
      "[Step 4800] Loss: 9.79e+07 0.5185185670852661 0.6516650915145874\n",
      "[Step 4801] Loss: 9.76e+07 0.5185580253601074 0.6516708731651306\n",
      "[Step 4802] Loss: 9.82e+07 0.5185306072235107 0.6516329646110535\n",
      "[Step 4803] Loss: 9.79e+07 0.5185654759407043 0.6516122817993164\n",
      "[Step 4804] Loss: 9.83e+07 0.5186178684234619 0.6516271829605103\n",
      "[Step 4805] Loss: 9.89e+07 0.5186194181442261 0.651576817035675\n",
      "[Step 4806] Loss: 1.00e+08 0.5184818506240845 0.6515281200408936\n",
      "[Step 4807] Loss: 9.80e+07 0.5182825922966003 0.6514456272125244\n",
      "[Step 4808] Loss: 9.87e+07 0.5181604623794556 0.6513697504997253\n",
      "[Step 4809] Loss: 9.87e+07 0.5180922746658325 0.6512954831123352\n",
      "[Step 4810] Loss: 9.81e+07 0.5180119872093201 0.6512261629104614\n",
      "[Step 4811] Loss: 9.86e+07 0.517976701259613 0.6511461138725281\n",
      "[Step 4812] Loss: 9.80e+07 0.5180230736732483 0.6511073112487793\n",
      "[Step 4813] Loss: 9.79e+07 0.5179787278175354 0.6510710120201111\n",
      "[Step 4814] Loss: 9.93e+07 0.5178476572036743 0.6509546637535095\n",
      "[Step 4815] Loss: 9.71e+07 0.5178049802780151 0.6508919596672058\n",
      "[Step 4816] Loss: 9.82e+07 0.5177590847015381 0.6508597731590271\n",
      "[Step 4817] Loss: 9.78e+07 0.5176655650138855 0.6507781147956848\n",
      "[Step 4818] Loss: 9.79e+07 0.5175070762634277 0.650693953037262\n",
      "[Step 4819] Loss: 9.81e+07 0.5173861384391785 0.6506006717681885\n",
      "[Step 4820] Loss: 9.86e+07 0.5171975493431091 0.6504587531089783\n",
      "[Step 4821] Loss: 9.76e+07 0.5170546770095825 0.6503522992134094\n",
      "[Step 4822] Loss: 9.72e+07 0.5168920159339905 0.6502557992935181\n",
      "[Step 4823] Loss: 9.81e+07 0.5166717171669006 0.6501171588897705\n",
      "[Step 4824] Loss: 9.77e+07 0.5165113806724548 0.6500396132469177\n",
      "[Step 4825] Loss: 9.76e+07 0.5163022875785828 0.649924099445343\n",
      "[Step 4826] Loss: 9.89e+07 0.5159911513328552 0.6497871279716492\n",
      "[Step 4827] Loss: 9.84e+07 0.5156329274177551 0.6496427059173584\n",
      "[Step 4828] Loss: 9.78e+07 0.5152267813682556 0.6494892239570618\n",
      "[Step 4829] Loss: 9.85e+07 0.5148155093193054 0.6493563652038574\n",
      "[Step 4830] Loss: 9.79e+07 0.5144475102424622 0.6492384076118469\n",
      "[Step 4831] Loss: 9.85e+07 0.5142159461975098 0.6491302847862244\n",
      "[Step 4832] Loss: 9.76e+07 0.5139352083206177 0.6490123271942139\n",
      "[Step 4833] Loss: 9.67e+07 0.5136894583702087 0.6489116549491882\n",
      "[Step 4834] Loss: 9.77e+07 0.5134762525558472 0.6488357186317444\n",
      "[Step 4835] Loss: 9.78e+07 0.5132616758346558 0.6487391591072083\n",
      "[Step 4836] Loss: 9.79e+07 0.5130184888839722 0.648664116859436\n",
      "[Step 4837] Loss: 9.86e+07 0.5127158761024475 0.6485196948051453\n",
      "[Step 4838] Loss: 9.83e+07 0.5123549699783325 0.6483513712882996\n",
      "[Step 4839] Loss: 9.82e+07 0.5120678544044495 0.6482292413711548\n",
      "[Step 4840] Loss: 9.86e+07 0.5118256211280823 0.6480749249458313\n",
      "[Step 4841] Loss: 9.78e+07 0.5115792751312256 0.6479387879371643\n",
      "[Step 4842] Loss: 1.00e+08 0.5111486315727234 0.6477358341217041\n",
      "[Step 4843] Loss: 9.89e+07 0.510723888874054 0.6475724577903748\n",
      "[Step 4844] Loss: 9.88e+07 0.5103102922439575 0.647367000579834\n",
      "[Step 4845] Loss: 9.84e+07 0.5099255442619324 0.6471928954124451\n",
      "[Step 4846] Loss: 9.76e+07 0.5095627903938293 0.6470072269439697\n",
      "[Step 4847] Loss: 9.80e+07 0.5092939138412476 0.6468438506126404\n",
      "[Step 4848] Loss: 9.77e+07 0.5091060400009155 0.6467233896255493\n",
      "[Step 4849] Loss: 9.77e+07 0.5088934302330017 0.6465765237808228\n",
      "[Step 4850] Loss: 9.80e+07 0.5086556673049927 0.6464560031890869\n",
      "[Step 4851] Loss: 9.77e+07 0.5084527730941772 0.6463198661804199\n",
      "[Step 4852] Loss: 9.78e+07 0.5083257555961609 0.6462612748146057\n",
      "[Step 4853] Loss: 9.78e+07 0.5081338882446289 0.6461341977119446\n",
      "[Step 4854] Loss: 9.94e+07 0.5081769824028015 0.6460599899291992\n",
      "[Step 4855] Loss: 9.87e+07 0.5083602070808411 0.6460327506065369\n",
      "[Step 4856] Loss: 9.78e+07 0.508613109588623 0.6460418105125427\n",
      "[Step 4857] Loss: 9.89e+07 0.5088547468185425 0.6460450887680054\n",
      "[Step 4858] Loss: 9.82e+07 0.5091086030006409 0.6460698843002319\n",
      "[Step 4859] Loss: 9.79e+07 0.5093282461166382 0.6460764408111572\n",
      "[Step 4860] Loss: 9.79e+07 0.509539783000946 0.6460574865341187\n",
      "[Step 4861] Loss: 9.81e+07 0.5096638798713684 0.6460789442062378\n",
      "[Step 4862] Loss: 9.84e+07 0.5097581744194031 0.6460558176040649\n",
      "[Step 4863] Loss: 9.89e+07 0.5097053647041321 0.6459931135177612\n",
      "[Step 4864] Loss: 9.84e+07 0.5096332430839539 0.6459237933158875\n",
      "[Step 4865] Loss: 9.79e+07 0.50953608751297 0.645865261554718\n",
      "[Step 4866] Loss: 9.82e+07 0.5095665454864502 0.6458190083503723\n",
      "[Step 4867] Loss: 9.80e+07 0.5095759630203247 0.6457324028015137\n",
      "[Step 4868] Loss: 9.77e+07 0.5095627903938293 0.6456630825996399\n",
      "[Step 4869] Loss: 9.77e+07 0.5095716714859009 0.6456135511398315\n",
      "[Step 4870] Loss: 9.79e+07 0.5096292495727539 0.645601212978363\n",
      "[Step 4871] Loss: 9.81e+07 0.5096839070320129 0.6455739736557007\n",
      "[Step 4872] Loss: 9.86e+07 0.5098022222518921 0.6455549597740173\n",
      "[Step 4873] Loss: 9.87e+07 0.5098987817764282 0.6455153822898865\n",
      "[Step 4874] Loss: 9.87e+07 0.5100436806678772 0.6454963684082031\n",
      "[Step 4875] Loss: 9.73e+07 0.5101786851882935 0.6454840302467346\n",
      "[Step 4876] Loss: 9.93e+07 0.5103521347045898 0.6455277800559998\n",
      "[Step 4877] Loss: 9.78e+07 0.5104571580886841 0.6455054879188538\n",
      "[Step 4878] Loss: 9.82e+07 0.5104694366455078 0.6454625725746155\n",
      "[Step 4879] Loss: 9.90e+07 0.5104705691337585 0.6454171538352966\n",
      "[Step 4880] Loss: 9.84e+07 0.510591983795166 0.6453808546066284\n",
      "[Step 4881] Loss: 9.85e+07 0.5106987953186035 0.6453346610069275\n",
      "[Step 4882] Loss: 9.80e+07 0.5108372569084167 0.6452966928482056\n",
      "[Step 4883] Loss: 9.83e+07 0.5110865235328674 0.6453090906143188\n",
      "[Step 4884] Loss: 9.80e+07 0.5113508105278015 0.6453222632408142\n",
      "[Step 4885] Loss: 9.74e+07 0.511532187461853 0.6453288793563843\n",
      "[Step 4886] Loss: 9.82e+07 0.5117374658584595 0.6453651785850525\n",
      "[Step 4887] Loss: 9.78e+07 0.5119144320487976 0.6453808546066284\n",
      "[Step 4888] Loss: 9.86e+07 0.5120883584022522 0.6454031467437744\n",
      "[Step 4889] Loss: 9.77e+07 0.5122920870780945 0.6454097628593445\n",
      "[Step 4890] Loss: 9.78e+07 0.5125097036361694 0.6454518437385559\n",
      "[Step 4891] Loss: 9.82e+07 0.5126727223396301 0.6454609036445618\n",
      "[Step 4892] Loss: 9.86e+07 0.5128925442695618 0.6454600691795349\n",
      "[Step 4893] Loss: 9.82e+07 0.5130600333213806 0.6454724669456482\n",
      "[Step 4894] Loss: 9.84e+07 0.5132495760917664 0.6454460620880127\n",
      "[Step 4895] Loss: 9.79e+07 0.5135030746459961 0.645466685295105\n",
      "[Step 4896] Loss: 9.68e+07 0.5137995481491089 0.6455252766609192\n",
      "[Step 4897] Loss: 9.85e+07 0.5141526460647583 0.645564079284668\n",
      "[Step 4898] Loss: 9.81e+07 0.5144833922386169 0.6455896496772766\n",
      "[Step 4899] Loss: 9.92e+07 0.5146262645721436 0.6455516815185547\n",
      "[Step 4900] Loss: 9.88e+07 0.5148274302482605 0.6455409526824951\n",
      "[Step 4901] Loss: 9.73e+07 0.5149797797203064 0.645511269569397\n",
      "[Step 4902] Loss: 9.76e+07 0.5151357650756836 0.6454906463623047\n",
      "[Step 4903] Loss: 9.76e+07 0.5153009295463562 0.6454535126686096\n",
      "[Step 4904] Loss: 9.73e+07 0.5154239535331726 0.6454386115074158\n",
      "[Step 4905] Loss: 9.76e+07 0.5155110359191895 0.645391583442688\n",
      "[Step 4906] Loss: 9.76e+07 0.5156617760658264 0.6453808546066284\n",
      "[Step 4907] Loss: 9.81e+07 0.5157792568206787 0.6453552842140198\n",
      "[Step 4908] Loss: 9.86e+07 0.5157541036605835 0.6452571153640747\n",
      "[Step 4909] Loss: 9.84e+07 0.515778660774231 0.6452199816703796\n",
      "[Step 4910] Loss: 9.77e+07 0.5157306790351868 0.6451531648635864\n",
      "[Step 4911] Loss: 9.82e+07 0.5156927704811096 0.6450780630111694\n",
      "[Step 4912] Loss: 9.88e+07 0.5155545473098755 0.6449782252311707\n",
      "[Step 4913] Loss: 9.76e+07 0.5154456496238708 0.6448907256126404\n",
      "[Step 4914] Loss: 9.76e+07 0.5153167843818665 0.6448131799697876\n",
      "[Step 4915] Loss: 9.78e+07 0.5151470303535461 0.6446762084960938\n",
      "[Step 4916] Loss: 9.76e+07 0.5150353908538818 0.6445978283882141\n",
      "[Step 4917] Loss: 9.78e+07 0.5148785710334778 0.6445425152778625\n",
      "[Step 4918] Loss: 9.80e+07 0.5147566199302673 0.6444418430328369\n",
      "[Step 4919] Loss: 9.82e+07 0.5146729350090027 0.6443634629249573\n",
      "[Step 4920] Loss: 9.75e+07 0.5146302580833435 0.644267737865448\n",
      "[Step 4921] Loss: 9.75e+07 0.5146215558052063 0.6442281603813171\n",
      "[Step 4922] Loss: 9.93e+07 0.5145207047462463 0.644176185131073\n",
      "[Step 4923] Loss: 9.79e+07 0.5144388675689697 0.6441184282302856\n",
      "[Step 4924] Loss: 9.78e+07 0.5144565105438232 0.6440920233726501\n",
      "[Step 4925] Loss: 9.89e+07 0.5143399238586426 0.6439847350120544\n",
      "[Step 4926] Loss: 9.73e+07 0.5142472982406616 0.643920361995697\n",
      "[Step 4927] Loss: 9.80e+07 0.5141497254371643 0.6438717246055603\n",
      "[Step 4928] Loss: 9.81e+07 0.5139847993850708 0.6438122987747192\n",
      "[Step 4929] Loss: 9.79e+07 0.5138381719589233 0.6437487602233887\n",
      "[Step 4930] Loss: 9.81e+07 0.5136538743972778 0.643663763999939\n",
      "[Step 4931] Loss: 9.83e+07 0.5134621858596802 0.6436018943786621\n",
      "[Step 4932] Loss: 9.86e+07 0.5132289528846741 0.6434756517410278\n",
      "[Step 4933] Loss: 9.84e+07 0.5130845904350281 0.6433823704719543\n",
      "[Step 4934] Loss: 9.97e+07 0.5127847790718079 0.6432627439498901\n",
      "[Step 4935] Loss: 9.85e+07 0.5125119090080261 0.6431348323822021\n",
      "[Step 4936] Loss: 9.89e+07 0.5121501088142395 0.6429582834243774\n",
      "[Step 4937] Loss: 9.81e+07 0.5117515325546265 0.6428245902061462\n",
      "[Step 4938] Loss: 9.86e+07 0.5113691687583923 0.6426727771759033\n",
      "[Step 4939] Loss: 9.81e+07 0.5110735297203064 0.6425589323043823\n",
      "[Step 4940] Loss: 9.76e+07 0.5107591152191162 0.642418622970581\n",
      "[Step 4941] Loss: 9.83e+07 0.5104374885559082 0.6423031091690063\n",
      "[Step 4942] Loss: 9.87e+07 0.5100027918815613 0.6421463489532471\n",
      "[Step 4943] Loss: 9.71e+07 0.5095576047897339 0.6419722437858582\n",
      "[Step 4944] Loss: 9.69e+07 0.5090961456298828 0.6418195962905884\n",
      "[Step 4945] Loss: 9.81e+07 0.5087376832962036 0.6416735649108887\n",
      "[Step 4946] Loss: 9.91e+07 0.5085223317146301 0.6415654420852661\n",
      "[Step 4947] Loss: 9.83e+07 0.5082831382751465 0.6414458155632019\n",
      "[Step 4948] Loss: 9.83e+07 0.5080602765083313 0.641302227973938\n",
      "[Step 4949] Loss: 9.82e+07 0.5078486204147339 0.6411545276641846\n",
      "[Step 4950] Loss: 9.77e+07 0.5077034831047058 0.6410521864891052\n",
      "[Step 4951] Loss: 9.87e+07 0.5074288845062256 0.6409276127815247\n",
      "[Step 4952] Loss: 9.78e+07 0.5071606636047363 0.6408129334449768\n",
      "[Step 4953] Loss: 9.75e+07 0.5069305300712585 0.640713095664978\n",
      "[Step 4954] Loss: 9.77e+07 0.5067059993743896 0.6406412720680237\n",
      "[Step 4955] Loss: 9.81e+07 0.5065452456474304 0.6405505537986755\n",
      "[Step 4956] Loss: 9.73e+07 0.506401777267456 0.6404993534088135\n",
      "[Step 4957] Loss: 9.86e+07 0.5064146518707275 0.6404589414596558\n",
      "[Step 4958] Loss: 9.76e+07 0.5064488649368286 0.6404449343681335\n",
      "[Step 4959] Loss: 9.87e+07 0.506525456905365 0.640426754951477\n",
      "[Step 4960] Loss: 9.88e+07 0.5065097808837891 0.6403788924217224\n",
      "[Step 4961] Loss: 9.74e+07 0.5064669847488403 0.6403178572654724\n",
      "[Step 4962] Loss: 9.78e+07 0.5063579082489014 0.6402485370635986\n",
      "[Step 4963] Loss: 9.83e+07 0.5062976479530334 0.6401948928833008\n",
      "[Step 4964] Loss: 9.83e+07 0.5063662528991699 0.6401891112327576\n",
      "[Step 4965] Loss: 9.75e+07 0.5064501166343689 0.6401849985122681\n",
      "[Step 4966] Loss: 9.76e+07 0.5065253973007202 0.6401445865631104\n",
      "[Step 4967] Loss: 9.74e+07 0.5065851211547852 0.6401288509368896\n",
      "[Step 4968] Loss: 9.75e+07 0.5067005753517151 0.6401528120040894\n",
      "[Step 4969] Loss: 9.85e+07 0.5067654848098755 0.6401388049125671\n",
      "[Step 4970] Loss: 9.86e+07 0.5067929029464722 0.6401025056838989\n",
      "[Step 4971] Loss: 9.80e+07 0.5068491697311401 0.6400925517082214\n",
      "[Step 4972] Loss: 9.78e+07 0.5069880485534668 0.6400967240333557\n",
      "[Step 4973] Loss: 9.81e+07 0.5071810483932495 0.6401206254959106\n",
      "[Step 4974] Loss: 9.86e+07 0.5074619054794312 0.6401495337486267\n",
      "[Step 4975] Loss: 9.84e+07 0.507803738117218 0.6401882767677307\n",
      "[Step 4976] Loss: 9.77e+07 0.5081392526626587 0.6402245759963989\n",
      "[Step 4977] Loss: 9.83e+07 0.5085698962211609 0.6403211355209351\n",
      "[Step 4978] Loss: 9.86e+07 0.5090586543083191 0.6403970718383789\n",
      "[Step 4979] Loss: 9.79e+07 0.5095579624176025 0.6405422687530518\n",
      "[Step 4980] Loss: 9.74e+07 0.5100071430206299 0.640653669834137\n",
      "[Step 4981] Loss: 9.75e+07 0.5103732347488403 0.6407419443130493\n",
      "[Step 4982] Loss: 9.81e+07 0.5106332302093506 0.6407980918884277\n",
      "[Step 4983] Loss: 9.72e+07 0.5109555721282959 0.6408814191818237\n",
      "[Step 4984] Loss: 9.72e+07 0.5112754106521606 0.6409366726875305\n",
      "[Step 4985] Loss: 9.86e+07 0.5116114020347595 0.6410233378410339\n",
      "[Step 4986] Loss: 9.68e+07 0.511864185333252 0.6410959362983704\n",
      "[Step 4987] Loss: 9.76e+07 0.5120836496353149 0.6411231756210327\n",
      "[Step 4988] Loss: 9.80e+07 0.5122666954994202 0.6411322355270386\n",
      "[Step 4989] Loss: 9.71e+07 0.5123648047447205 0.6410794258117676\n",
      "[Step 4990] Loss: 9.77e+07 0.5124802589416504 0.6410761475563049\n",
      "[Step 4991] Loss: 9.79e+07 0.5125691294670105 0.6410769820213318\n",
      "[Step 4992] Loss: 9.69e+07 0.5126465559005737 0.6410620808601379\n",
      "[Step 4993] Loss: 9.81e+07 0.512661337852478 0.6410546898841858\n",
      "[Step 4994] Loss: 9.83e+07 0.5127768516540527 0.6411083340644836\n",
      "[Step 4995] Loss: 9.87e+07 0.5127635598182678 0.6411008834838867\n",
      "[Step 4996] Loss: 9.77e+07 0.5128277540206909 0.641060471534729\n",
      "[Step 4997] Loss: 9.81e+07 0.512867271900177 0.6410126090049744\n",
      "[Step 4998] Loss: 9.82e+07 0.5129100680351257 0.6409738063812256\n",
      "[Step 4999] Loss: 9.81e+07 0.5130221843719482 0.6409763097763062\n",
      "[Step 5000] Loss: 9.80e+07 0.5130671262741089 0.6409276127815247\n",
      "[Step 5001] Loss: 9.83e+07 0.5130978226661682 0.640871524810791\n",
      "[Step 5002] Loss: 9.82e+07 0.5130674839019775 0.6408310532569885\n",
      "[Step 5003] Loss: 9.75e+07 0.512980580329895 0.6407708525657654\n",
      "[Step 5004] Loss: 9.92e+07 0.5127668380737305 0.6406511664390564\n",
      "[Step 5005] Loss: 9.75e+07 0.5125352144241333 0.640556275844574\n",
      "[Step 5006] Loss: 9.72e+07 0.5124015212059021 0.640471339225769\n",
      "[Step 5007] Loss: 9.84e+07 0.5123403668403625 0.6404746174812317\n",
      "[Step 5008] Loss: 9.76e+07 0.512357234954834 0.6404366493225098\n",
      "[Step 5009] Loss: 9.78e+07 0.5123488903045654 0.6404275894165039\n",
      "[Step 5010] Loss: 9.81e+07 0.5122198462486267 0.6403756141662598\n",
      "[Step 5011] Loss: 9.79e+07 0.5120594501495361 0.6403318643569946\n",
      "[Step 5012] Loss: 9.78e+07 0.5119255185127258 0.6402699947357178\n",
      "[Step 5013] Loss: 9.82e+07 0.5117679834365845 0.6401717662811279\n",
      "[Step 5014] Loss: 9.79e+07 0.5117208361625671 0.6400974988937378\n",
      "[Step 5015] Loss: 9.79e+07 0.511676013469696 0.6400843262672424\n",
      "[Step 5016] Loss: 9.81e+07 0.5115231275558472 0.6400257349014282\n",
      "[Step 5017] Loss: 9.81e+07 0.5113365054130554 0.6399564146995544\n",
      "[Step 5018] Loss: 9.78e+07 0.5112012028694153 0.639892041683197\n",
      "[Step 5019] Loss: 9.91e+07 0.5110148787498474 0.6398071050643921\n",
      "[Step 5020] Loss: 9.90e+07 0.510930061340332 0.6397592425346375\n",
      "[Step 5021] Loss: 9.76e+07 0.5107957124710083 0.6397055983543396\n",
      "[Step 5022] Loss: 9.84e+07 0.5107442140579224 0.6397122144699097\n",
      "[Step 5023] Loss: 9.90e+07 0.5106557607650757 0.639680802822113\n",
      "[Step 5024] Loss: 9.80e+07 0.5105472207069397 0.6395933628082275\n",
      "[Step 5025] Loss: 9.78e+07 0.5104259252548218 0.6395281553268433\n",
      "[Step 5026] Loss: 9.85e+07 0.5102240443229675 0.6394233703613281\n",
      "[Step 5027] Loss: 9.79e+07 0.5099431276321411 0.6393226981163025\n",
      "[Step 5028] Loss: 9.78e+07 0.509594202041626 0.6391948461532593\n",
      "[Step 5029] Loss: 9.89e+07 0.5092678070068359 0.6390950083732605\n",
      "[Step 5030] Loss: 9.79e+07 0.5089884400367737 0.638971209526062\n",
      "[Step 5031] Loss: 9.87e+07 0.5087573528289795 0.6388556957244873\n",
      "[Step 5032] Loss: 9.86e+07 0.5086513161659241 0.6388260126113892\n",
      "[Step 5033] Loss: 9.81e+07 0.5085330605506897 0.638745129108429\n",
      "[Step 5034] Loss: 9.79e+07 0.5083926320075989 0.6386584639549255\n",
      "[Step 5035] Loss: 9.78e+07 0.5082064867019653 0.6385776400566101\n",
      "[Step 5036] Loss: 9.76e+07 0.5080440640449524 0.638487696647644\n",
      "[Step 5037] Loss: 9.81e+07 0.5078937411308289 0.6384027004241943\n",
      "[Step 5038] Loss: 9.79e+07 0.5076910257339478 0.6383202075958252\n",
      "[Step 5039] Loss: 9.73e+07 0.5074672698974609 0.6382071375846863\n",
      "[Step 5040] Loss: 9.80e+07 0.5071872472763062 0.638050377368927\n",
      "[Step 5041] Loss: 9.78e+07 0.506882905960083 0.6378993391990662\n",
      "[Step 5042] Loss: 9.82e+07 0.5065813660621643 0.6377689838409424\n",
      "[Step 5043] Loss: 9.75e+07 0.506303608417511 0.6376410722732544\n",
      "[Step 5044] Loss: 9.76e+07 0.5060490965843201 0.6375008225440979\n",
      "[Step 5045] Loss: 9.78e+07 0.5058236122131348 0.6373910903930664\n",
      "[Step 5046] Loss: 9.71e+07 0.5055727362632751 0.6372838020324707\n",
      "[Step 5047] Loss: 9.78e+07 0.5053350925445557 0.6371212601661682\n",
      "[Step 5048] Loss: 9.81e+07 0.5050768256187439 0.6369776725769043\n",
      "[Step 5049] Loss: 9.84e+07 0.5048785209655762 0.6368398666381836\n",
      "[Step 5050] Loss: 9.82e+07 0.5047898292541504 0.6367648243904114\n",
      "[Step 5051] Loss: 9.83e+07 0.5048725605010986 0.6367111802101135\n",
      "[Step 5052] Loss: 9.84e+07 0.5049324631690979 0.6366484761238098\n",
      "[Step 5053] Loss: 9.76e+07 0.5050026178359985 0.6366286277770996\n",
      "[Step 5054] Loss: 9.78e+07 0.5050601363182068 0.6365824341773987\n",
      "[Step 5055] Loss: 9.82e+07 0.5050562024116516 0.636565089225769\n",
      "[Step 5056] Loss: 9.73e+07 0.5050802826881409 0.6365007758140564\n",
      "[Step 5057] Loss: 9.93e+07 0.5049574971199036 0.6364578604698181\n",
      "[Step 5058] Loss: 9.74e+07 0.5048376321792603 0.6363860368728638\n",
      "[Step 5059] Loss: 9.79e+07 0.5047191381454468 0.6362977623939514\n",
      "[Step 5060] Loss: 9.70e+07 0.5045472383499146 0.6362020373344421\n",
      "[Step 5061] Loss: 9.81e+07 0.504463791847229 0.6361665725708008\n",
      "[Step 5062] Loss: 9.76e+07 0.5043827891349792 0.6361187100410461\n",
      "[Step 5063] Loss: 9.75e+07 0.5042963624000549 0.6360700130462646\n",
      "[Step 5064] Loss: 9.72e+07 0.504253625869751 0.6360328793525696\n",
      "[Step 5065] Loss: 9.86e+07 0.5043056607246399 0.6359982490539551\n",
      "[Step 5066] Loss: 9.85e+07 0.5042958855628967 0.6359982490539551\n",
      "[Step 5067] Loss: 9.79e+07 0.5041953325271606 0.6359759569168091\n",
      "[Step 5068] Loss: 9.79e+07 0.5040253400802612 0.6359157562255859\n",
      "[Step 5069] Loss: 9.68e+07 0.503859281539917 0.6358529925346375\n",
      "[Step 5070] Loss: 9.90e+07 0.5036229491233826 0.6357482075691223\n",
      "[Step 5071] Loss: 9.73e+07 0.5034184455871582 0.635644257068634\n",
      "[Step 5072] Loss: 9.71e+07 0.5032201409339905 0.6355642080307007\n",
      "[Step 5073] Loss: 9.84e+07 0.5029322504997253 0.6354429125785828\n",
      "[Step 5074] Loss: 9.82e+07 0.5026600956916809 0.6353356838226318\n",
      "[Step 5075] Loss: 9.76e+07 0.502349853515625 0.6351830363273621\n",
      "[Step 5076] Loss: 9.94e+07 0.5019879341125488 0.6350253820419312\n",
      "[Step 5077] Loss: 9.85e+07 0.5016504526138306 0.6348661780357361\n",
      "[Step 5078] Loss: 9.83e+07 0.5014420747756958 0.6347704529762268\n",
      "[Step 5079] Loss: 9.82e+07 0.5012468695640564 0.6346871256828308\n",
      "[Step 5080] Loss: 9.86e+07 0.5009838938713074 0.6345542669296265\n",
      "[Step 5081] Loss: 9.76e+07 0.5006994009017944 0.6344164609909058\n",
      "[Step 5082] Loss: 9.80e+07 0.5003827214241028 0.6342836022377014\n",
      "[Step 5083] Loss: 9.75e+07 0.5000655651092529 0.6341482996940613\n",
      "[Step 5084] Loss: 9.79e+07 0.4997609555721283 0.6340154409408569\n",
      "[Step 5085] Loss: 9.83e+07 0.4995634853839874 0.633894145488739\n",
      "[Step 5086] Loss: 9.75e+07 0.49940258264541626 0.6337876915931702\n",
      "[Step 5087] Loss: 9.76e+07 0.499219685792923 0.633690357208252\n",
      "[Step 5088] Loss: 9.78e+07 0.4989505112171173 0.6335888504981995\n",
      "[Step 5089] Loss: 9.85e+07 0.4986485242843628 0.633471667766571\n",
      "[Step 5090] Loss: 9.79e+07 0.49843472242355347 0.633395791053772\n",
      "[Step 5091] Loss: 9.73e+07 0.4982726275920868 0.6333016753196716\n",
      "[Step 5092] Loss: 9.75e+07 0.4981197118759155 0.6332109570503235\n",
      "[Step 5093] Loss: 9.85e+07 0.49796098470687866 0.6330987215042114\n",
      "[Step 5094] Loss: 9.74e+07 0.4978099763393402 0.6330244541168213\n",
      "[Step 5095] Loss: 9.76e+07 0.49768733978271484 0.6329666972160339\n",
      "[Step 5096] Loss: 9.78e+07 0.4974720776081085 0.6328808665275574\n",
      "[Step 5097] Loss: 9.78e+07 0.497289776802063 0.632792592048645\n",
      "[Step 5098] Loss: 9.74e+07 0.4971465766429901 0.6327117085456848\n",
      "[Step 5099] Loss: 9.73e+07 0.49704280495643616 0.6326663494110107\n",
      "[Step 5100] Loss: 9.79e+07 0.49704745411872864 0.6326324939727783\n",
      "[Step 5101] Loss: 9.75e+07 0.4970799386501312 0.6325854659080505\n",
      "[Step 5102] Loss: 9.79e+07 0.4970567226409912 0.6325392723083496\n",
      "[Step 5103] Loss: 9.83e+07 0.49706166982650757 0.6325054168701172\n",
      "[Step 5104] Loss: 9.78e+07 0.49717772006988525 0.6324699521064758\n",
      "[Step 5105] Loss: 9.76e+07 0.4973202645778656 0.6324716210365295\n",
      "[Step 5106] Loss: 9.68e+07 0.4974440336227417 0.632475733757019\n",
      "[Step 5107] Loss: 9.78e+07 0.4975906014442444 0.6324922442436218\n",
      "[Step 5108] Loss: 9.80e+07 0.4977201521396637 0.6324765682220459\n",
      "[Step 5109] Loss: 9.78e+07 0.4977787733078003 0.6324765682220459\n",
      "[Step 5110] Loss: 9.69e+07 0.49777910113334656 0.6324583888053894\n",
      "[Step 5111] Loss: 9.75e+07 0.4977837800979614 0.6324682831764221\n",
      "[Step 5112] Loss: 9.71e+07 0.49781739711761475 0.6324212551116943\n",
      "[Step 5113] Loss: 9.72e+07 0.4978526830673218 0.6324245929718018\n",
      "[Step 5114] Loss: 9.78e+07 0.49788495898246765 0.6324179768562317\n",
      "[Step 5115] Loss: 9.71e+07 0.49793097376823425 0.6324212551116943\n",
      "[Step 5116] Loss: 9.79e+07 0.49803850054740906 0.6324443817138672\n",
      "[Step 5117] Loss: 9.75e+07 0.4981939196586609 0.6324881315231323\n",
      "[Step 5118] Loss: 9.73e+07 0.49833032488822937 0.6325029730796814\n",
      "[Step 5119] Loss: 9.76e+07 0.4983866512775421 0.6324930787086487\n",
      "[Step 5120] Loss: 9.75e+07 0.49842727184295654 0.6324748992919922\n",
      "[Step 5121] Loss: 9.84e+07 0.4984176456928253 0.6324501633644104\n",
      "[Step 5122] Loss: 9.79e+07 0.4983871579170227 0.6324262022972107\n",
      "[Step 5123] Loss: 9.78e+07 0.49834346771240234 0.6323758959770203\n",
      "[Step 5124] Loss: 9.71e+07 0.4983392655849457 0.6323445439338684\n",
      "[Step 5125] Loss: 9.84e+07 0.49833807349205017 0.632286787033081\n",
      "[Step 5126] Loss: 9.87e+07 0.49828195571899414 0.6322331428527832\n",
      "[Step 5127] Loss: 9.88e+07 0.4980503022670746 0.632121741771698\n",
      "[Step 5128] Loss: 9.79e+07 0.49778518080711365 0.6320235729217529\n",
      "[Step 5129] Loss: 9.81e+07 0.49750855565071106 0.6319261789321899\n",
      "[Step 5130] Loss: 9.83e+07 0.4972788989543915 0.6318461298942566\n",
      "[Step 5131] Loss: 9.80e+07 0.4969947934150696 0.6317380666732788\n",
      "[Step 5132] Loss: 9.87e+07 0.49675917625427246 0.6316184401512146\n",
      "[Step 5133] Loss: 9.77e+07 0.49653729796409607 0.6315400004386902\n",
      "[Step 5134] Loss: 9.90e+07 0.4962163269519806 0.6314072012901306\n",
      "[Step 5135] Loss: 9.83e+07 0.4959041178226471 0.6312974691390991\n",
      "[Step 5136] Loss: 9.80e+07 0.4956403970718384 0.6311621069908142\n",
      "[Step 5137] Loss: 9.77e+07 0.4953940808773041 0.6310548782348633\n",
      "[Step 5138] Loss: 9.89e+07 0.4950818717479706 0.6309285759925842\n",
      "[Step 5139] Loss: 9.73e+07 0.4947563409805298 0.6308262944221497\n",
      "[Step 5140] Loss: 9.89e+07 0.4944073259830475 0.6307305693626404\n",
      "[Step 5141] Loss: 9.83e+07 0.4941215217113495 0.6306158900260925\n",
      "[Step 5142] Loss: 9.82e+07 0.4938099682331085 0.6304607391357422\n",
      "[Step 5143] Loss: 9.80e+07 0.4935511350631714 0.6303369998931885\n",
      "[Step 5144] Loss: 9.76e+07 0.4932684302330017 0.6302065849304199\n",
      "[Step 5145] Loss: 9.81e+07 0.49304068088531494 0.6301224231719971\n",
      "[Step 5146] Loss: 9.88e+07 0.49284693598747253 0.630054771900177\n",
      "[Step 5147] Loss: 9.77e+07 0.4928033649921417 0.6299821734428406\n",
      "[Step 5148] Loss: 9.70e+07 0.49281924962997437 0.6299343109130859\n",
      "[Step 5149] Loss: 9.84e+07 0.4928780198097229 0.6299029588699341\n",
      "[Step 5150] Loss: 9.76e+07 0.49297937750816345 0.6298691034317017\n",
      "[Step 5151] Loss: 9.88e+07 0.49315497279167175 0.629859209060669\n",
      "[Step 5152] Loss: 9.82e+07 0.49326181411743164 0.6298534274101257\n",
      "[Step 5153] Loss: 9.78e+07 0.49333253502845764 0.6298113465309143\n",
      "[Step 5154] Loss: 9.78e+07 0.4934273064136505 0.629767656326294\n",
      "[Step 5155] Loss: 9.76e+07 0.4934590458869934 0.6297222375869751\n",
      "[Step 5156] Loss: 9.92e+07 0.4932989478111267 0.6296339631080627\n",
      "[Step 5157] Loss: 9.83e+07 0.4930848181247711 0.6295465230941772\n",
      "[Step 5158] Loss: 9.68e+07 0.4929364025592804 0.629443347454071\n",
      "[Step 5159] Loss: 9.80e+07 0.4926794767379761 0.6293113231658936\n",
      "[Step 5160] Loss: 9.76e+07 0.49244067072868347 0.6292114853858948\n",
      "[Step 5161] Loss: 9.94e+07 0.4920539855957031 0.6290662884712219\n",
      "[Step 5162] Loss: 9.82e+07 0.4915767014026642 0.6288864016532898\n",
      "[Step 5163] Loss: 9.78e+07 0.49103760719299316 0.6286957859992981\n",
      "[Step 5164] Loss: 9.85e+07 0.4904264509677887 0.6285043358802795\n",
      "[Step 5165] Loss: 9.80e+07 0.48976725339889526 0.6282724738121033\n",
      "[Step 5166] Loss: 9.78e+07 0.4892023503780365 0.6280785799026489\n",
      "[Step 5167] Loss: 9.83e+07 0.4887118637561798 0.6278929114341736\n",
      "[Step 5168] Loss: 9.68e+07 0.488258957862854 0.6277163624763489\n",
      "[Step 5169] Loss: 9.74e+07 0.4878535568714142 0.6275381445884705\n",
      "[Step 5170] Loss: 9.75e+07 0.48747432231903076 0.6274234056472778\n",
      "[Step 5171] Loss: 9.79e+07 0.4870748817920685 0.6273062229156494\n",
      "[Step 5172] Loss: 9.75e+07 0.4867284893989563 0.6271857619285583\n",
      "[Step 5173] Loss: 9.75e+07 0.48644375801086426 0.627097487449646\n",
      "[Step 5174] Loss: 9.73e+07 0.48622775077819824 0.6270017623901367\n",
      "[Step 5175] Loss: 9.75e+07 0.48601794242858887 0.6269473433494568\n",
      "[Step 5176] Loss: 9.72e+07 0.485725075006485 0.6268424987792969\n",
      "[Step 5177] Loss: 9.81e+07 0.48538750410079956 0.626704752445221\n",
      "[Step 5178] Loss: 9.75e+07 0.485120564699173 0.6265900135040283\n",
      "[Step 5179] Loss: 9.71e+07 0.4848873019218445 0.626516580581665\n",
      "[Step 5180] Loss: 9.71e+07 0.48467081785202026 0.6264448165893555\n",
      "[Step 5181] Loss: 9.83e+07 0.4844852685928345 0.6264060139656067\n",
      "[Step 5182] Loss: 9.90e+07 0.4844107925891876 0.6263705492019653\n",
      "[Step 5183] Loss: 9.82e+07 0.48429784178733826 0.6263078451156616\n",
      "[Step 5184] Loss: 9.87e+07 0.48413559794425964 0.6262096166610718\n",
      "[Step 5185] Loss: 9.93e+07 0.4838370084762573 0.6260776519775391\n",
      "[Step 5186] Loss: 9.77e+07 0.4836429953575134 0.6259926557540894\n",
      "[Step 5187] Loss: 1.00e+08 0.48322099447250366 0.6258630752563477\n",
      "[Step 5188] Loss: 9.90e+07 0.4830222427845001 0.6257690191268921\n",
      "[Step 5189] Loss: 9.76e+07 0.48283690214157104 0.6257129311561584\n",
      "[Step 5190] Loss: 9.82e+07 0.48259130120277405 0.6256064772605896\n",
      "[Step 5191] Loss: 9.81e+07 0.4823070466518402 0.6254620552062988\n",
      "[Step 5192] Loss: 9.84e+07 0.4820592403411865 0.625347375869751\n",
      "[Step 5193] Loss: 9.89e+07 0.48193618655204773 0.6252830028533936\n",
      "[Step 5194] Loss: 9.75e+07 0.48174363374710083 0.6251617074012756\n",
      "[Step 5195] Loss: 9.76e+07 0.4816212058067322 0.6250808835029602\n",
      "[Step 5196] Loss: 9.76e+07 0.4815520942211151 0.6250495314598083\n",
      "[Step 5197] Loss: 9.72e+07 0.48153266310691833 0.6249859929084778\n",
      "[Step 5198] Loss: 9.80e+07 0.48155477643013 0.6249347925186157\n",
      "[Step 5199] Loss: 9.77e+07 0.4814601540565491 0.6248679757118225\n",
      "[Step 5200] Loss: 9.74e+07 0.4814422130584717 0.6248151659965515\n",
      "[Step 5201] Loss: 9.75e+07 0.4814789593219757 0.6247747540473938\n",
      "[Step 5202] Loss: 9.78e+07 0.4815102815628052 0.6247458457946777\n",
      "[Step 5203] Loss: 9.84e+07 0.4815920293331146 0.6247186064720154\n",
      "[Step 5204] Loss: 9.79e+07 0.4817379117012024 0.624707043170929\n",
      "[Step 5205] Loss: 9.85e+07 0.48180222511291504 0.6246501207351685\n",
      "[Step 5206] Loss: 9.83e+07 0.48201313614845276 0.6246691346168518\n",
      "[Step 5207] Loss: 9.80e+07 0.4821733236312866 0.6246814727783203\n",
      "[Step 5208] Loss: 9.84e+07 0.4823024570941925 0.624660849571228\n",
      "[Step 5209] Loss: 9.74e+07 0.4824003279209137 0.624646008014679\n",
      "[Step 5210] Loss: 9.69e+07 0.4824608862400055 0.6245989799499512\n",
      "[Step 5211] Loss: 9.78e+07 0.4824267327785492 0.624585747718811\n",
      "[Step 5212] Loss: 9.91e+07 0.48241695761680603 0.6245412230491638\n",
      "[Step 5213] Loss: 9.79e+07 0.48233669996261597 0.6244628429412842\n",
      "[Step 5214] Loss: 9.84e+07 0.48216286301612854 0.6243679523468018\n",
      "[Step 5215] Loss: 9.78e+07 0.481981486082077 0.6243167519569397\n",
      "[Step 5216] Loss: 9.76e+07 0.4818430244922638 0.6242070198059082\n",
      "[Step 5217] Loss: 9.85e+07 0.4816375970840454 0.6241063475608826\n",
      "[Step 5218] Loss: 9.70e+07 0.4814606010913849 0.6239950060844421\n",
      "[Step 5219] Loss: 9.78e+07 0.4812432527542114 0.6239141225814819\n",
      "[Step 5220] Loss: 9.77e+07 0.481099009513855 0.6238266229629517\n",
      "[Step 5221] Loss: 9.99e+07 0.48076656460762024 0.623702883720398\n",
      "[Step 5222] Loss: 9.78e+07 0.4804005026817322 0.623552680015564\n",
      "[Step 5223] Loss: 9.82e+07 0.48012110590934753 0.6234371662139893\n",
      "[Step 5224] Loss: 9.79e+07 0.4799922704696655 0.6233645677566528\n",
      "[Step 5225] Loss: 9.78e+07 0.4798125922679901 0.6232729554176331\n",
      "[Step 5226] Loss: 9.78e+07 0.47962427139282227 0.6232078075408936\n",
      "[Step 5227] Loss: 9.76e+07 0.47938960790634155 0.6231030225753784\n",
      "[Step 5228] Loss: 9.76e+07 0.4792071580886841 0.6230105757713318\n",
      "[Step 5229] Loss: 9.80e+07 0.47903966903686523 0.6229247450828552\n",
      "[Step 5230] Loss: 9.83e+07 0.47888851165771484 0.6228381395339966\n",
      "[Step 5231] Loss: 9.72e+07 0.4786966145038605 0.6227465271949768\n",
      "[Step 5232] Loss: 9.78e+07 0.47841009497642517 0.6226178407669067\n",
      "[Step 5233] Loss: 9.81e+07 0.4782746136188507 0.6225476861000061\n",
      "[Step 5234] Loss: 9.84e+07 0.47826284170150757 0.6225320100784302\n",
      "[Step 5235] Loss: 9.81e+07 0.47827765345573425 0.6225295066833496\n",
      "[Step 5236] Loss: 9.76e+07 0.47832632064819336 0.6225138306617737\n",
      "[Step 5237] Loss: 9.81e+07 0.4782904386520386 0.6224346160888672\n",
      "[Step 5238] Loss: 9.78e+07 0.47834500670433044 0.622412383556366\n",
      "[Step 5239] Loss: 9.78e+07 0.4783087968826294 0.6223529577255249\n",
      "[Step 5240] Loss: 1.00e+08 0.4780357778072357 0.6222506165504456\n",
      "[Step 5241] Loss: 9.75e+07 0.47781527042388916 0.6221664547920227\n",
      "[Step 5242] Loss: 9.74e+07 0.4776705503463745 0.6220806837081909\n",
      "[Step 5243] Loss: 9.80e+07 0.47765684127807617 0.6220493316650391\n",
      "[Step 5244] Loss: 9.67e+07 0.4776718318462372 0.6220410466194153\n",
      "[Step 5245] Loss: 9.77e+07 0.4776389002799988 0.6219865679740906\n",
      "[Step 5246] Loss: 9.66e+07 0.4775691032409668 0.6219486594200134\n",
      "[Step 5247] Loss: 9.79e+07 0.4775133728981018 0.6219106912612915\n",
      "[Step 5248] Loss: 9.73e+07 0.47748252749443054 0.6218529343605042\n",
      "[Step 5249] Loss: 9.71e+07 0.47754961252212524 0.6218430399894714\n",
      "[Step 5250] Loss: 9.72e+07 0.47759386897087097 0.6218495965003967\n",
      "[Step 5251] Loss: 9.74e+07 0.47763898968696594 0.6218248605728149\n",
      "[Step 5252] Loss: 9.71e+07 0.47772109508514404 0.6217918395996094\n",
      "[Step 5253] Loss: 9.83e+07 0.47783753275871277 0.6218207478523254\n",
      "[Step 5254] Loss: 9.74e+07 0.47800153493881226 0.6218207478523254\n",
      "[Step 5255] Loss: 9.76e+07 0.478099524974823 0.6218116879463196\n",
      "[Step 5256] Loss: 9.71e+07 0.47820883989334106 0.6218446493148804\n",
      "[Step 5257] Loss: 9.81e+07 0.47837021946907043 0.6218677759170532\n",
      "[Step 5258] Loss: 9.88e+07 0.478628933429718 0.6218999624252319\n",
      "[Step 5259] Loss: 9.82e+07 0.47883909940719604 0.6219040751457214\n",
      "[Step 5260] Loss: 9.75e+07 0.4790196418762207 0.6219511032104492\n",
      "[Step 5261] Loss: 9.75e+07 0.4791854918003082 0.6219989657402039\n",
      "[Step 5262] Loss: 9.81e+07 0.47931328415870667 0.6219965219497681\n",
      "[Step 5263] Loss: 9.82e+07 0.4794214963912964 0.6219775080680847\n",
      "[Step 5264] Loss: 9.65e+07 0.4795169532299042 0.6219972968101501\n",
      "[Step 5265] Loss: 9.70e+07 0.4795568585395813 0.6219618320465088\n",
      "[Step 5266] Loss: 9.66e+07 0.47955721616744995 0.621937096118927\n",
      "[Step 5267] Loss: 9.76e+07 0.47972172498703003 0.6219387650489807\n",
      "[Step 5268] Loss: 9.75e+07 0.47988614439964294 0.6219511032104492\n",
      "[Step 5269] Loss: 9.91e+07 0.4801066517829895 0.6219750642776489\n",
      "[Step 5270] Loss: 9.77e+07 0.48027557134628296 0.6219692826271057\n",
      "[Step 5271] Loss: 9.73e+07 0.48045045137405396 0.6219832897186279\n",
      "[Step 5272] Loss: 9.78e+07 0.48066145181655884 0.6220072507858276\n",
      "[Step 5273] Loss: 9.79e+07 0.48089122772216797 0.6220336556434631\n",
      "[Step 5274] Loss: 9.78e+07 0.4811273515224457 0.6220749020576477\n",
      "[Step 5275] Loss: 9.82e+07 0.48144471645355225 0.6221252083778381\n",
      "[Step 5276] Loss: 9.80e+07 0.4816412031650543 0.6221359372138977\n",
      "[Step 5277] Loss: 9.76e+07 0.4817710816860199 0.6221499443054199\n",
      "[Step 5278] Loss: 9.79e+07 0.48186466097831726 0.6221309900283813\n",
      "[Step 5279] Loss: 9.94e+07 0.4820568859577179 0.6221491694450378\n",
      "[Step 5280] Loss: 9.80e+07 0.48225897550582886 0.6221780180931091\n",
      "[Step 5281] Loss: 9.78e+07 0.4824007451534271 0.6221805214881897\n",
      "[Step 5282] Loss: 9.79e+07 0.48247551918029785 0.6221442222595215\n",
      "[Step 5283] Loss: 9.80e+07 0.48251286149024963 0.6220839619636536\n",
      "[Step 5284] Loss: 9.89e+07 0.4826599359512329 0.6221095323562622\n",
      "[Step 5285] Loss: 9.78e+07 0.48278722167015076 0.6220914125442505\n",
      "[Step 5286] Loss: 9.75e+07 0.4829561710357666 0.6220880746841431\n",
      "[Step 5287] Loss: 9.80e+07 0.48298993706703186 0.6220641732215881\n",
      "[Step 5288] Loss: 9.72e+07 0.48295363783836365 0.6219972968101501\n",
      "[Step 5289] Loss: 9.76e+07 0.4829528331756592 0.6219733953475952\n",
      "[Step 5290] Loss: 9.82e+07 0.4830481708049774 0.6219560503959656\n",
      "[Step 5291] Loss: 9.87e+07 0.483039915561676 0.6219222545623779\n",
      "[Step 5292] Loss: 9.80e+07 0.48304662108421326 0.6219073534011841\n",
      "[Step 5293] Loss: 9.81e+07 0.48302897810935974 0.6218578815460205\n",
      "[Step 5294] Loss: 9.84e+07 0.4828875958919525 0.6217803359031677\n",
      "[Step 5295] Loss: 9.81e+07 0.48279738426208496 0.6217134594917297\n",
      "[Step 5296] Loss: 9.76e+07 0.482717901468277 0.6216994524002075\n",
      "[Step 5297] Loss: 9.86e+07 0.482654333114624 0.6216499209403992\n",
      "[Step 5298] Loss: 9.82e+07 0.48255205154418945 0.6216020584106445\n",
      "[Step 5299] Loss: 9.81e+07 0.48240914940834045 0.6214939951896667\n",
      "[Step 5300] Loss: 9.74e+07 0.482147753238678 0.6213776469230652\n",
      "[Step 5301] Loss: 9.80e+07 0.4819130003452301 0.6212687492370605\n",
      "[Step 5302] Loss: 9.78e+07 0.4817326068878174 0.6211928129196167\n",
      "[Step 5303] Loss: 9.78e+07 0.4815989136695862 0.6211045384407043\n",
      "[Step 5304] Loss: 9.80e+07 0.48142120242118835 0.6210294365882874\n",
      "[Step 5305] Loss: 9.89e+07 0.48136723041534424 0.6209609508514404\n",
      "[Step 5306] Loss: 9.90e+07 0.481425017118454 0.6209609508514404\n",
      "[Step 5307] Loss: 9.77e+07 0.48147648572921753 0.6209394931793213\n",
      "[Step 5308] Loss: 9.74e+07 0.4815175533294678 0.6209048628807068\n",
      "[Step 5309] Loss: 9.80e+07 0.4816015064716339 0.6208685040473938\n",
      "[Step 5310] Loss: 9.74e+07 0.48164018988609314 0.620821475982666\n",
      "[Step 5311] Loss: 9.81e+07 0.48163294792175293 0.6207447648048401\n",
      "[Step 5312] Loss: 9.80e+07 0.48166391253471375 0.6207183599472046\n",
      "[Step 5313] Loss: 9.83e+07 0.48177242279052734 0.6206960678100586\n",
      "[Step 5314] Loss: 9.78e+07 0.48186296224594116 0.6206341981887817\n",
      "[Step 5315] Loss: 9.77e+07 0.48200303316116333 0.620593786239624\n",
      "[Step 5316] Loss: 9.90e+07 0.48205655813217163 0.6205855011940002\n",
      "[Step 5317] Loss: 9.87e+07 0.4819954037666321 0.6205310225486755\n",
      "[Step 5318] Loss: 9.76e+07 0.48202604055404663 0.620489776134491\n",
      "[Step 5319] Loss: 9.70e+07 0.4820459485054016 0.6204749345779419\n",
      "[Step 5320] Loss: 9.79e+07 0.48203912377357483 0.6204006671905518\n",
      "[Step 5321] Loss: 9.75e+07 0.48204419016838074 0.620360255241394\n",
      "[Step 5322] Loss: 9.79e+07 0.4820464551448822 0.6203033328056335\n",
      "[Step 5323] Loss: 9.75e+07 0.4821106791496277 0.6202645301818848\n",
      "[Step 5324] Loss: 9.87e+07 0.4820534586906433 0.6202117204666138\n",
      "[Step 5325] Loss: 9.77e+07 0.4819689393043518 0.6201391220092773\n",
      "[Step 5326] Loss: 9.74e+07 0.4818643033504486 0.6200772523880005\n",
      "[Step 5327] Loss: 9.75e+07 0.4816870093345642 0.6200202703475952\n",
      "[Step 5328] Loss: 9.82e+07 0.4814104735851288 0.6199295520782471\n",
      "[Step 5329] Loss: 9.80e+07 0.4812031686306 0.6198428869247437\n",
      "[Step 5330] Loss: 9.77e+07 0.4809836745262146 0.6197454929351807\n",
      "[Step 5331] Loss: 9.77e+07 0.48072361946105957 0.6196423768997192\n",
      "[Step 5332] Loss: 9.74e+07 0.48040640354156494 0.619538426399231\n",
      "[Step 5333] Loss: 9.77e+07 0.47998371720314026 0.6194162964820862\n",
      "[Step 5334] Loss: 9.74e+07 0.47967708110809326 0.6192660927772522\n",
      "[Step 5335] Loss: 9.79e+07 0.47940605878829956 0.6191340684890747\n",
      "[Step 5336] Loss: 9.75e+07 0.4792279005050659 0.6190466284751892\n",
      "[Step 5337] Loss: 9.85e+07 0.4792361557483673 0.6190127730369568\n",
      "[Step 5338] Loss: 9.86e+07 0.4792887568473816 0.6190177798271179\n",
      "[Step 5339] Loss: 9.81e+07 0.4794663190841675 0.6190169453620911\n",
      "[Step 5340] Loss: 9.76e+07 0.47965916991233826 0.6190565228462219\n",
      "[Step 5341] Loss: 9.71e+07 0.47985127568244934 0.6190400123596191\n",
      "[Step 5342] Loss: 9.78e+07 0.48001450300216675 0.6190457940101624\n",
      "[Step 5343] Loss: 9.81e+07 0.4801225960254669 0.6189921498298645\n",
      "[Step 5344] Loss: 9.65e+07 0.4803019165992737 0.6189748644828796\n",
      "[Step 5345] Loss: 9.76e+07 0.48039019107818604 0.6189624667167664\n",
      "[Step 5346] Loss: 9.76e+07 0.48041248321533203 0.6188997626304626\n",
      "[Step 5347] Loss: 9.79e+07 0.48039117455482483 0.6188609600067139\n",
      "[Step 5348] Loss: 9.79e+07 0.4803643226623535 0.6188287734985352\n",
      "[Step 5349] Loss: 9.82e+07 0.4803833067417145 0.6187999248504639\n",
      "[Step 5350] Loss: 9.83e+07 0.48049086332321167 0.6188065409660339\n",
      "[Step 5351] Loss: 9.82e+07 0.48052120208740234 0.618776798248291\n",
      "[Step 5352] Loss: 9.75e+07 0.4806486666202545 0.6187751889228821\n",
      "[Step 5353] Loss: 9.74e+07 0.48076048493385315 0.6187669038772583\n",
      "[Step 5354] Loss: 9.82e+07 0.4808460474014282 0.6187553405761719\n",
      "[Step 5355] Loss: 9.78e+07 0.4808397591114044 0.6187182068824768\n",
      "[Step 5356] Loss: 9.74e+07 0.4808073043823242 0.618685245513916\n",
      "[Step 5357] Loss: 9.74e+07 0.48065435886383057 0.6185969114303589\n",
      "[Step 5358] Loss: 9.80e+07 0.48057326674461365 0.6185226440429688\n",
      "[Step 5359] Loss: 9.75e+07 0.4804791510105133 0.618475615978241\n",
      "[Step 5360] Loss: 9.78e+07 0.4803353250026703 0.6183757781982422\n",
      "[Step 5361] Loss: 9.71e+07 0.48016905784606934 0.6183188557624817\n",
      "[Step 5362] Loss: 9.78e+07 0.48003512620925903 0.6182528734207153\n",
      "[Step 5363] Loss: 9.82e+07 0.4798985719680786 0.618179440498352\n",
      "[Step 5364] Loss: 9.75e+07 0.479848176240921 0.6181274056434631\n",
      "[Step 5365] Loss: 9.81e+07 0.479752779006958 0.6180738210678101\n",
      "[Step 5366] Loss: 9.73e+07 0.4796520173549652 0.6180152297019958\n",
      "[Step 5367] Loss: 9.79e+07 0.4794936776161194 0.6179211735725403\n",
      "[Step 5368] Loss: 9.80e+07 0.47928595542907715 0.6178064346313477\n",
      "[Step 5369] Loss: 9.76e+07 0.4790690541267395 0.6177189946174622\n",
      "[Step 5370] Loss: 9.83e+07 0.4787552058696747 0.6175811886787415\n",
      "[Step 5371] Loss: 9.70e+07 0.4784703254699707 0.6174673438072205\n",
      "[Step 5372] Loss: 9.74e+07 0.47821781039237976 0.6173592209815979\n",
      "[Step 5373] Loss: 9.80e+07 0.4779655337333679 0.61723792552948\n",
      "[Step 5374] Loss: 9.74e+07 0.4776644706726074 0.6171182990074158\n",
      "[Step 5375] Loss: 9.81e+07 0.4773290455341339 0.6170027852058411\n",
      "[Step 5376] Loss: 9.80e+07 0.47703322768211365 0.6168723702430725\n",
      "[Step 5377] Loss: 9.76e+07 0.4767167568206787 0.6167337894439697\n",
      "[Step 5378] Loss: 9.72e+07 0.47641757130622864 0.6166108250617981\n",
      "[Step 5379] Loss: 9.73e+07 0.4760781526565552 0.6164763569831848\n",
      "[Step 5380] Loss: 9.78e+07 0.47580134868621826 0.6163368821144104\n",
      "[Step 5381] Loss: 9.69e+07 0.47559213638305664 0.616256833076477\n",
      "[Step 5382] Loss: 9.81e+07 0.4754798114299774 0.6161850690841675\n",
      "[Step 5383] Loss: 9.73e+07 0.47541525959968567 0.6161330938339233\n",
      "[Step 5384] Loss: 9.78e+07 0.47539395093917847 0.6161074638366699\n",
      "[Step 5385] Loss: 9.73e+07 0.4753481149673462 0.6160497069358826\n",
      "[Step 5386] Loss: 9.90e+07 0.47540250420570374 0.6160299181938171\n",
      "[Step 5387] Loss: 9.84e+07 0.4753475785255432 0.615969717502594\n",
      "[Step 5388] Loss: 9.73e+07 0.47532781958580017 0.6159268021583557\n",
      "[Step 5389] Loss: 9.76e+07 0.4753783345222473 0.6158855557441711\n",
      "[Step 5390] Loss: 9.82e+07 0.4753740429878235 0.6158599257469177\n",
      "[Step 5391] Loss: 9.73e+07 0.47527724504470825 0.6157963871955872\n",
      "[Step 5392] Loss: 9.69e+07 0.4752121567726135 0.6157650351524353\n",
      "[Step 5393] Loss: 9.68e+07 0.4751587212085724 0.6157237887382507\n",
      "[Step 5394] Loss: 9.73e+07 0.4750686287879944 0.615691602230072\n",
      "[Step 5395] Loss: 9.80e+07 0.47494038939476013 0.6156750917434692\n",
      "[Step 5396] Loss: 9.85e+07 0.4748546779155731 0.6156644225120544\n",
      "[Step 5397] Loss: 9.76e+07 0.4747829735279083 0.6156511902809143\n",
      "[Step 5398] Loss: 9.71e+07 0.47473761439323425 0.6156371831893921\n",
      "[Step 5399] Loss: 9.82e+07 0.47476842999458313 0.6156561374664307\n",
      "[Step 5400] Loss: 9.81e+07 0.47473517060279846 0.6156338453292847\n",
      "[Step 5401] Loss: 9.80e+07 0.4748075306415558 0.6156256198883057\n",
      "[Step 5402] Loss: 9.78e+07 0.4748668372631073 0.6156487464904785\n",
      "[Step 5403] Loss: 9.77e+07 0.4748300313949585 0.6156280636787415\n",
      "[Step 5404] Loss: 9.73e+07 0.47484034299850464 0.6156288981437683\n",
      "[Step 5405] Loss: 9.73e+07 0.4748218059539795 0.6156181693077087\n",
      "[Step 5406] Loss: 9.82e+07 0.4747677147388458 0.6155612468719482\n",
      "[Step 5407] Loss: 9.70e+07 0.4747624695301056 0.6155373454093933\n",
      "[Step 5408] Loss: 9.71e+07 0.4748084545135498 0.6155010461807251\n",
      "[Step 5409] Loss: 9.80e+07 0.47486865520477295 0.6154696345329285\n",
      "[Step 5410] Loss: 9.70e+07 0.47496116161346436 0.6154605746269226\n",
      "[Step 5411] Loss: 9.73e+07 0.47500374913215637 0.6154564619064331\n",
      "[Step 5412] Loss: 9.77e+07 0.47507596015930176 0.6154118776321411\n",
      "[Step 5413] Loss: 9.72e+07 0.47520437836647034 0.615419328212738\n",
      "[Step 5414] Loss: 9.72e+07 0.47539669275283813 0.6154168248176575\n",
      "[Step 5415] Loss: 9.75e+07 0.47554653882980347 0.6154152154922485\n",
      "[Step 5416] Loss: 9.73e+07 0.47564366459846497 0.6153854727745056\n",
      "[Step 5417] Loss: 9.81e+07 0.4756844937801361 0.615382194519043\n",
      "[Step 5418] Loss: 9.73e+07 0.47572940587997437 0.6153706312179565\n",
      "[Step 5419] Loss: 9.89e+07 0.4756447970867157 0.6152963638305664\n",
      "[Step 5420] Loss: 9.77e+07 0.47560688853263855 0.6152501702308655\n",
      "[Step 5421] Loss: 9.71e+07 0.4755614995956421 0.6151907444000244\n",
      "[Step 5422] Loss: 9.73e+07 0.4755590260028839 0.6151734590530396\n",
      "[Step 5423] Loss: 9.80e+07 0.47563013434410095 0.6151618957519531\n",
      "[Step 5424] Loss: 9.77e+07 0.47565335035324097 0.6151569485664368\n",
      "[Step 5425] Loss: 9.79e+07 0.4756077229976654 0.6151321530342102\n",
      "[Step 5426] Loss: 9.68e+07 0.47553783655166626 0.6150768995285034\n",
      "[Step 5427] Loss: 9.76e+07 0.47547847032546997 0.6150282025337219\n",
      "[Step 5428] Loss: 9.77e+07 0.4754279851913452 0.6150133609771729\n",
      "[Step 5429] Loss: 9.81e+07 0.4753526449203491 0.6149877905845642\n",
      "[Step 5430] Loss: 9.80e+07 0.47521498799324036 0.6149168014526367\n",
      "[Step 5431] Loss: 9.92e+07 0.4749149978160858 0.6148046255111694\n",
      "[Step 5432] Loss: 9.68e+07 0.47464853525161743 0.6147204637527466\n",
      "[Step 5433] Loss: 9.92e+07 0.47427037358283997 0.6145636439323425\n",
      "[Step 5434] Loss: 9.70e+07 0.47392407059669495 0.6144357919692993\n",
      "[Step 5435] Loss: 9.77e+07 0.47362035512924194 0.6142988204956055\n",
      "[Step 5436] Loss: 9.71e+07 0.4733397662639618 0.6142245531082153\n",
      "[Step 5437] Loss: 9.69e+07 0.4730795919895172 0.614144504070282\n",
      "[Step 5438] Loss: 9.81e+07 0.47276413440704346 0.6140124797821045\n",
      "[Step 5439] Loss: 9.74e+07 0.47244465351104736 0.6139258146286011\n",
      "[Step 5440] Loss: 9.73e+07 0.4721941649913788 0.6138235330581665\n",
      "[Step 5441] Loss: 9.71e+07 0.47192835807800293 0.6137467622756958\n",
      "[Step 5442] Loss: 9.73e+07 0.47169986367225647 0.6136832237243652\n",
      "[Step 5443] Loss: 9.77e+07 0.4714319109916687 0.6136031746864319\n",
      "[Step 5444] Loss: 9.69e+07 0.47118815779685974 0.6134951114654541\n",
      "[Step 5445] Loss: 9.72e+07 0.47091421484947205 0.6133713126182556\n",
      "[Step 5446] Loss: 9.71e+07 0.4706478714942932 0.6132888197898865\n",
      "[Step 5447] Loss: 9.73e+07 0.47034478187561035 0.6132128834724426\n",
      "[Step 5448] Loss: 9.80e+07 0.4699592888355255 0.6130792498588562\n",
      "[Step 5449] Loss: 9.82e+07 0.4696895182132721 0.6129942536354065\n",
      "[Step 5450] Loss: 9.82e+07 0.4693926274776459 0.6128647327423096\n",
      "[Step 5451] Loss: 9.68e+07 0.46910378336906433 0.6127302050590515\n",
      "[Step 5452] Loss: 9.75e+07 0.46894368529319763 0.6126559376716614\n",
      "[Step 5453] Loss: 9.73e+07 0.46882131695747375 0.612591564655304\n",
      "[Step 5454] Loss: 9.81e+07 0.4686339497566223 0.6125198006629944\n",
      "[Step 5455] Loss: 9.73e+07 0.4684276878833771 0.6124257445335388\n",
      "[Step 5456] Loss: 9.71e+07 0.46824079751968384 0.6123431921005249\n",
      "[Step 5457] Loss: 9.75e+07 0.46809256076812744 0.6122829914093018\n",
      "[Step 5458] Loss: 9.68e+07 0.4679599404335022 0.6122095584869385\n",
      "[Step 5459] Loss: 9.78e+07 0.4678705036640167 0.6121509671211243\n",
      "[Step 5460] Loss: 9.67e+07 0.4678681194782257 0.612099826335907\n",
      "[Step 5461] Loss: 9.78e+07 0.46796977519989014 0.612138569355011\n",
      "[Step 5462] Loss: 9.77e+07 0.4681550860404968 0.6121460199356079\n",
      "[Step 5463] Loss: 9.81e+07 0.4682943522930145 0.6121625304222107\n",
      "[Step 5464] Loss: 9.80e+07 0.4685380458831787 0.6121864318847656\n",
      "[Step 5465] Loss: 9.76e+07 0.46879810094833374 0.6122186183929443\n",
      "[Step 5466] Loss: 9.72e+07 0.46900510787963867 0.6122227311134338\n",
      "[Step 5467] Loss: 9.67e+07 0.46917974948883057 0.612250804901123\n",
      "[Step 5468] Loss: 9.75e+07 0.46922022104263306 0.6122384071350098\n",
      "[Step 5469] Loss: 9.79e+07 0.469192773103714 0.6122252345085144\n",
      "[Step 5470] Loss: 9.81e+07 0.46920692920684814 0.6121666431427002\n",
      "[Step 5471] Loss: 9.86e+07 0.469335675239563 0.6121683120727539\n",
      "[Step 5472] Loss: 9.82e+07 0.4693876802921295 0.612145185470581\n",
      "[Step 5473] Loss: 9.84e+07 0.4694696068763733 0.6121320128440857\n",
      "[Step 5474] Loss: 9.76e+07 0.4694991111755371 0.6121031045913696\n",
      "[Step 5475] Loss: 9.76e+07 0.46937766671180725 0.6120139956474304\n",
      "[Step 5476] Loss: 9.79e+07 0.4691922664642334 0.6119331121444702\n",
      "[Step 5477] Loss: 9.75e+07 0.4689953327178955 0.6118373870849609\n",
      "[Step 5478] Loss: 9.75e+07 0.4688284397125244 0.6117458343505859\n",
      "[Step 5479] Loss: 9.84e+07 0.4685091972351074 0.6116542220115662\n",
      "[Step 5480] Loss: 9.76e+07 0.46823254227638245 0.6115354299545288\n",
      "[Step 5481] Loss: 9.68e+07 0.4679776728153229 0.611451268196106\n",
      "[Step 5482] Loss: 9.85e+07 0.46776247024536133 0.611360490322113\n",
      "[Step 5483] Loss: 9.75e+07 0.4675672650337219 0.6112672686576843\n",
      "[Step 5484] Loss: 9.82e+07 0.4673217236995697 0.6111467480659485\n",
      "[Step 5485] Loss: 9.80e+07 0.4671344757080078 0.6110477447509766\n",
      "[Step 5486] Loss: 9.74e+07 0.46701329946517944 0.6109701991081238\n",
      "[Step 5487] Loss: 9.76e+07 0.46688976883888245 0.6109017133712769\n",
      "[Step 5488] Loss: 9.76e+07 0.4667551815509796 0.6108059883117676\n",
      "[Step 5489] Loss: 9.83e+07 0.4667396545410156 0.6107482314109802\n",
      "[Step 5490] Loss: 9.86e+07 0.46666115522384644 0.6106821894645691\n",
      "[Step 5491] Loss: 9.76e+07 0.46652480959892273 0.610591471195221\n",
      "[Step 5492] Loss: 9.78e+07 0.46648499369621277 0.6105344891548157\n",
      "[Step 5493] Loss: 9.77e+07 0.4664033055305481 0.6104421019554138\n",
      "[Step 5494] Loss: 9.80e+07 0.46642005443573 0.6104016900062561\n",
      "[Step 5495] Loss: 9.74e+07 0.4664422869682312 0.6103381514549255\n",
      "[Step 5496] Loss: 9.77e+07 0.46646958589553833 0.6102927327156067\n",
      "[Step 5497] Loss: 9.78e+07 0.46651655435562134 0.6102622151374817\n",
      "[Step 5498] Loss: 9.70e+07 0.4665925204753876 0.6102358102798462\n",
      "[Step 5499] Loss: 9.83e+07 0.46676212549209595 0.6102415919303894\n",
      "[Step 5500] Loss: 9.73e+07 0.46691906452178955 0.6102234125137329\n",
      "[Step 5501] Loss: 9.66e+07 0.46703124046325684 0.6102291941642761\n",
      "[Step 5502] Loss: 9.77e+07 0.4670698046684265 0.6102184653282166\n",
      "[Step 5503] Loss: 9.76e+07 0.46706563234329224 0.6102291941642761\n",
      "[Step 5504] Loss: 9.75e+07 0.4671156704425812 0.6101945638656616\n",
      "[Step 5505] Loss: 9.69e+07 0.4671678841114044 0.6102275848388672\n",
      "[Step 5506] Loss: 9.77e+07 0.4671606123447418 0.610214352607727\n",
      "[Step 5507] Loss: 9.67e+07 0.4671444296836853 0.6101945638656616\n",
      "[Step 5508] Loss: 9.73e+07 0.46707233786582947 0.610146701335907\n",
      "[Step 5509] Loss: 9.71e+07 0.4670464098453522 0.6101046204566956\n",
      "[Step 5510] Loss: 9.77e+07 0.4670662581920624 0.6100963950157166\n",
      "[Step 5511] Loss: 9.73e+07 0.4670814573764801 0.610085666179657\n",
      "[Step 5512] Loss: 9.70e+07 0.46703165769577026 0.6100279092788696\n",
      "[Step 5513] Loss: 9.71e+07 0.46698060631752014 0.6099891066551208\n",
      "[Step 5514] Loss: 9.77e+07 0.4668317437171936 0.6099305152893066\n",
      "[Step 5515] Loss: 9.84e+07 0.4667218029499054 0.6098793745040894\n",
      "[Step 5516] Loss: 9.77e+07 0.46658822894096375 0.6098422408103943\n",
      "[Step 5517] Loss: 9.76e+07 0.466430127620697 0.6097613573074341\n",
      "[Step 5518] Loss: 9.74e+07 0.4662919044494629 0.6097407341003418\n",
      "[Step 5519] Loss: 9.67e+07 0.46607401967048645 0.6096804738044739\n",
      "[Step 5520] Loss: 9.86e+07 0.4660017788410187 0.6096689701080322\n",
      "[Step 5521] Loss: 9.66e+07 0.46592143177986145 0.6096070408821106\n",
      "[Step 5522] Loss: 9.80e+07 0.46585720777511597 0.6095823049545288\n",
      "[Step 5523] Loss: 9.70e+07 0.4657817780971527 0.6095476746559143\n",
      "[Step 5524] Loss: 9.81e+07 0.46582818031311035 0.6095393896102905\n",
      "[Step 5525] Loss: 9.80e+07 0.46596798300743103 0.6095996499061584\n",
      "[Step 5526] Loss: 9.76e+07 0.4661409258842468 0.6095839738845825\n",
      "[Step 5527] Loss: 9.74e+07 0.4662500321865082 0.6095979809761047\n",
      "[Step 5528] Loss: 9.68e+07 0.4663035571575165 0.6096293330192566\n",
      "[Step 5529] Loss: 9.74e+07 0.4663999080657959 0.6096045970916748\n",
      "[Step 5530] Loss: 9.71e+07 0.4664565324783325 0.609595537185669\n",
      "[Step 5531] Loss: 9.70e+07 0.4665510654449463 0.609581470489502\n",
      "[Step 5532] Loss: 9.70e+07 0.46661752462387085 0.6095724105834961\n",
      "[Step 5533] Loss: 9.73e+07 0.4666065573692322 0.6095534563064575\n",
      "[Step 5534] Loss: 9.78e+07 0.4666057825088501 0.6095501184463501\n",
      "[Step 5535] Loss: 9.77e+07 0.46660444140434265 0.6095492839813232\n",
      "[Step 5536] Loss: 9.75e+07 0.4666844606399536 0.6095262169837952\n",
      "[Step 5537] Loss: 9.67e+07 0.4666760265827179 0.6095187664031982\n",
      "[Step 5538] Loss: 9.69e+07 0.4666158854961395 0.6094775199890137\n",
      "[Step 5539] Loss: 9.79e+07 0.46655982732772827 0.6094700694084167\n",
      "[Step 5540] Loss: 9.69e+07 0.4665512144565582 0.6094502806663513\n",
      "[Step 5541] Loss: 9.70e+07 0.46660351753234863 0.6094131469726562\n",
      "[Step 5542] Loss: 9.73e+07 0.4665418863296509 0.6093785166740417\n",
      "[Step 5543] Loss: 9.70e+07 0.46644312143325806 0.6093124747276306\n",
      "[Step 5544] Loss: 9.70e+07 0.46633031964302063 0.6092811226844788\n",
      "[Step 5545] Loss: 9.77e+07 0.46622398495674133 0.6092654466629028\n",
      "[Step 5546] Loss: 9.73e+07 0.466087281703949 0.6092192530632019\n",
      "[Step 5547] Loss: 9.84e+07 0.465972900390625 0.6091697216033936\n",
      "[Step 5548] Loss: 9.74e+07 0.4659038782119751 0.6091433167457581\n",
      "[Step 5549] Loss: 9.74e+07 0.46585318446159363 0.6090863943099976\n",
      "[Step 5550] Loss: 9.77e+07 0.4658248722553253 0.6090591549873352\n",
      "[Step 5551] Loss: 9.69e+07 0.46581095457077026 0.6090245246887207\n",
      "[Step 5552] Loss: 9.71e+07 0.4658282399177551 0.6090154647827148\n",
      "[Step 5553] Loss: 9.59e+07 0.46583643555641174 0.6089848875999451\n",
      "[Step 5554] Loss: 9.94e+07 0.4656851291656494 0.6089213490486145\n",
      "[Step 5555] Loss: 9.73e+07 0.46552401781082153 0.6088710427284241\n",
      "[Step 5556] Loss: 9.66e+07 0.4654083847999573 0.6088000535964966\n",
      "[Step 5557] Loss: 9.72e+07 0.4653300642967224 0.608750581741333\n",
      "[Step 5558] Loss: 9.72e+07 0.4652651250362396 0.6087002158164978\n",
      "[Step 5559] Loss: 9.76e+07 0.4651820957660675 0.6086598038673401\n",
      "[Step 5560] Loss: 9.69e+07 0.4651014506816864 0.6085805892944336\n",
      "[Step 5561] Loss: 9.80e+07 0.4650564193725586 0.6085434556007385\n",
      "[Step 5562] Loss: 9.67e+07 0.46496278047561646 0.6085261106491089\n",
      "[Step 5563] Loss: 9.74e+07 0.46478471159935 0.6084328889846802\n",
      "[Step 5564] Loss: 9.67e+07 0.46464431285858154 0.6083957552909851\n",
      "[Step 5565] Loss: 9.85e+07 0.46465256810188293 0.6083768010139465\n",
      "[Step 5566] Loss: 9.76e+07 0.464605450630188 0.6083347201347351\n",
      "[Step 5567] Loss: 9.77e+07 0.46458810567855835 0.608283519744873\n",
      "[Step 5568] Loss: 9.88e+07 0.46464869379997253 0.6083008646965027\n",
      "[Step 5569] Loss: 9.80e+07 0.46468502283096313 0.608283519744873\n",
      "[Step 5570] Loss: 9.72e+07 0.46464255452156067 0.6082422733306885\n",
      "[Step 5571] Loss: 9.77e+07 0.4646592140197754 0.6081911325454712\n",
      "[Step 5572] Loss: 9.69e+07 0.46467408537864685 0.6081350445747375\n",
      "[Step 5573] Loss: 9.70e+07 0.46476510167121887 0.6081119179725647\n",
      "[Step 5574] Loss: 9.75e+07 0.46502554416656494 0.6081218123435974\n",
      "[Step 5575] Loss: 9.76e+07 0.46539220213890076 0.6081960797309875\n",
      "[Step 5576] Loss: 9.67e+07 0.46565061807632446 0.608222484588623\n",
      "[Step 5577] Loss: 9.70e+07 0.4659590721130371 0.6082563400268555\n",
      "[Step 5578] Loss: 9.77e+07 0.4661596715450287 0.60829097032547\n",
      "[Step 5579] Loss: 9.77e+07 0.466279536485672 0.6083206534385681\n",
      "[Step 5580] Loss: 9.71e+07 0.4664272964000702 0.6083536744117737\n",
      "[Step 5581] Loss: 9.69e+07 0.4665423035621643 0.608396589756012\n",
      "[Step 5582] Loss: 9.83e+07 0.4665908217430115 0.6083454489707947\n",
      "[Step 5583] Loss: 9.74e+07 0.4666878879070282 0.60835862159729\n",
      "[Step 5584] Loss: 9.78e+07 0.46676915884017944 0.6083635687828064\n",
      "[Step 5585] Loss: 9.76e+07 0.46672093868255615 0.608319878578186\n",
      "[Step 5586] Loss: 9.71e+07 0.4667053520679474 0.6082802414894104\n",
      "[Step 5587] Loss: 9.89e+07 0.46679818630218506 0.6082628965377808\n",
      "[Step 5588] Loss: 9.72e+07 0.466880738735199 0.6082620620727539\n",
      "[Step 5589] Loss: 9.81e+07 0.46705666184425354 0.6082662343978882\n",
      "[Step 5590] Loss: 9.72e+07 0.46726515889167786 0.6082579493522644\n",
      "[Step 5591] Loss: 9.80e+07 0.4675440490245819 0.6082843542098999\n",
      "[Step 5592] Loss: 9.73e+07 0.46776360273361206 0.6083099246025085\n",
      "[Step 5593] Loss: 9.72e+07 0.4680473804473877 0.608372688293457\n",
      "[Step 5594] Loss: 9.75e+07 0.4682598114013672 0.6083768010139465\n",
      "[Step 5595] Loss: 9.76e+07 0.46852901577949524 0.6083759665489197\n",
      "[Step 5596] Loss: 9.76e+07 0.4687233865261078 0.6083833575248718\n",
      "[Step 5597] Loss: 9.78e+07 0.4688550531864166 0.608366072177887\n",
      "[Step 5598] Loss: 9.72e+07 0.4688543677330017 0.608321487903595\n",
      "[Step 5599] Loss: 9.74e+07 0.46877676248550415 0.608282744884491\n",
      "[Step 5600] Loss: 9.73e+07 0.46877020597457886 0.6082505583763123\n",
      "[Step 5601] Loss: 9.76e+07 0.4687257707118988 0.608207643032074\n",
      "[Step 5602] Loss: 9.78e+07 0.468641072511673 0.6081507205963135\n",
      "[Step 5603] Loss: 9.70e+07 0.46850234270095825 0.6080962419509888\n",
      "[Step 5604] Loss: 9.69e+07 0.4683813750743866 0.6080318689346313\n",
      "[Step 5605] Loss: 9.72e+07 0.46825501322746277 0.6079229712486267\n",
      "[Step 5606] Loss: 9.77e+07 0.4682403802871704 0.6078891158103943\n",
      "[Step 5607] Loss: 9.73e+07 0.46825382113456726 0.6078792214393616\n",
      "[Step 5608] Loss: 9.77e+07 0.4681898355484009 0.6078767776489258\n",
      "[Step 5609] Loss: 9.80e+07 0.46822184324264526 0.6078445911407471\n",
      "[Step 5610] Loss: 9.70e+07 0.468222051858902 0.6078470349311829\n",
      "[Step 5611] Loss: 9.79e+07 0.4681805372238159 0.6078585982322693\n",
      "[Step 5612] Loss: 9.76e+07 0.46808668971061707 0.6078165173530579\n",
      "[Step 5613] Loss: 9.75e+07 0.4680072069168091 0.6077455282211304\n",
      "[Step 5614] Loss: 9.69e+07 0.4679925739765167 0.607740581035614\n",
      "[Step 5615] Loss: 9.67e+07 0.4679373502731323 0.6076952219009399\n",
      "[Step 5616] Loss: 9.75e+07 0.4679661691188812 0.6076844930648804\n",
      "[Step 5617] Loss: 9.70e+07 0.46789753437042236 0.607649028301239\n",
      "[Step 5618] Loss: 9.74e+07 0.4677828252315521 0.6076052784919739\n",
      "[Step 5619] Loss: 9.76e+07 0.4676791727542877 0.6075549721717834\n",
      "[Step 5620] Loss: 9.81e+07 0.4676487445831299 0.6075178384780884\n",
      "[Step 5621] Loss: 9.65e+07 0.4676051139831543 0.6074856519699097\n",
      "[Step 5622] Loss: 9.77e+07 0.4676087200641632 0.6074625253677368\n",
      "[Step 5623] Loss: 9.84e+07 0.4674684405326843 0.6073676347732544\n",
      "[Step 5624] Loss: 9.71e+07 0.4673842489719391 0.6073139905929565\n",
      "[Step 5625] Loss: 9.77e+07 0.46740564703941345 0.6072760224342346\n",
      "[Step 5626] Loss: 9.71e+07 0.4674000144004822 0.6072521209716797\n",
      "[Step 5627] Loss: 9.70e+07 0.4672849178314209 0.6071497797966003\n",
      "[Step 5628] Loss: 9.69e+07 0.4671824276447296 0.607090413570404\n",
      "[Step 5629] Loss: 9.72e+07 0.4670540392398834 0.6070301532745361\n",
      "[Step 5630] Loss: 9.68e+07 0.46702998876571655 0.6070045828819275\n",
      "[Step 5631] Loss: 9.73e+07 0.4670400023460388 0.6069707274436951\n",
      "[Step 5632] Loss: 9.74e+07 0.4670143127441406 0.6069575548171997\n",
      "[Step 5633] Loss: 9.75e+07 0.4669843018054962 0.6069022417068481\n",
      "[Step 5634] Loss: 9.78e+07 0.46689334511756897 0.6068321466445923\n",
      "[Step 5635] Loss: 9.82e+07 0.466879665851593 0.6067991256713867\n",
      "[Step 5636] Loss: 9.89e+07 0.46702516078948975 0.6068354249000549\n",
      "[Step 5637] Loss: 9.78e+07 0.4670755863189697 0.606827974319458\n",
      "[Step 5638] Loss: 9.75e+07 0.46714168787002563 0.6068189144134521\n",
      "[Step 5639] Loss: 9.72e+07 0.4671579599380493 0.6068007946014404\n",
      "[Step 5640] Loss: 9.73e+07 0.4671098291873932 0.6068106889724731\n",
      "[Step 5641] Loss: 9.80e+07 0.4669332504272461 0.6067619919776917\n",
      "[Step 5642] Loss: 9.80e+07 0.46666219830513 0.6066819429397583\n",
      "[Step 5643] Loss: 9.77e+07 0.4664573669433594 0.6066184043884277\n",
      "[Step 5644] Loss: 9.81e+07 0.4664246439933777 0.6065953373908997\n",
      "[Step 5645] Loss: 9.75e+07 0.4664008915424347 0.6065821051597595\n",
      "[Step 5646] Loss: 9.83e+07 0.4663305878639221 0.6065127849578857\n",
      "[Step 5647] Loss: 9.73e+07 0.4661919176578522 0.6064558625221252\n",
      "[Step 5648] Loss: 9.73e+07 0.4660000205039978 0.606360137462616\n",
      "[Step 5649] Loss: 9.73e+07 0.46581172943115234 0.6062628030776978\n",
      "[Step 5650] Loss: 9.72e+07 0.4656467139720917 0.6061819195747375\n",
      "[Step 5651] Loss: 9.72e+07 0.46551835536956787 0.6060829162597656\n",
      "[Step 5652] Loss: 9.73e+07 0.46539488434791565 0.6059640645980835\n",
      "[Step 5653] Loss: 9.72e+07 0.46527576446533203 0.6059021949768066\n",
      "[Step 5654] Loss: 9.76e+07 0.46516746282577515 0.6058304309844971\n",
      "[Step 5655] Loss: 9.88e+07 0.4649260938167572 0.6057495474815369\n",
      "[Step 5656] Loss: 9.74e+07 0.46471264958381653 0.605665385723114\n",
      "[Step 5657] Loss: 9.66e+07 0.46456798911094666 0.605567216873169\n",
      "[Step 5658] Loss: 9.69e+07 0.4644513428211212 0.6055102348327637\n",
      "[Step 5659] Loss: 9.73e+07 0.4643349051475525 0.6054491996765137\n",
      "[Step 5660] Loss: 9.73e+07 0.4642949402332306 0.6054046154022217\n",
      "[Step 5661] Loss: 9.77e+07 0.46437501907348633 0.6054302453994751\n",
      "[Step 5662] Loss: 9.70e+07 0.4644145667552948 0.6054112315177917\n",
      "[Step 5663] Loss: 9.73e+07 0.4643729031085968 0.6053963899612427\n",
      "[Step 5664] Loss: 9.76e+07 0.46428436040878296 0.6053568124771118\n",
      "[Step 5665] Loss: 9.77e+07 0.464119017124176 0.6052998304367065\n",
      "[Step 5666] Loss: 9.67e+07 0.4639653265476227 0.6052404642105103\n",
      "[Step 5667] Loss: 9.77e+07 0.4637031853199005 0.6051793694496155\n",
      "[Step 5668] Loss: 9.79e+07 0.463438481092453 0.6051051020622253\n",
      "[Step 5669] Loss: 9.64e+07 0.4631727933883667 0.6050226092338562\n",
      "[Step 5670] Loss: 9.78e+07 0.4629063904285431 0.6049458384513855\n",
      "[Step 5671] Loss: 9.79e+07 0.4626583755016327 0.6048468351364136\n",
      "[Step 5672] Loss: 9.74e+07 0.46234723925590515 0.6047272086143494\n",
      "[Step 5673] Loss: 9.73e+07 0.4621748924255371 0.6047024726867676\n",
      "[Step 5674] Loss: 9.77e+07 0.4620521664619446 0.6046718955039978\n",
      "[Step 5675] Loss: 9.77e+07 0.4618590772151947 0.6046372652053833\n",
      "[Step 5676] Loss: 9.80e+07 0.46166548132896423 0.6045762300491333\n",
      "[Step 5677] Loss: 9.69e+07 0.46145355701446533 0.6045035719871521\n",
      "[Step 5678] Loss: 9.85e+07 0.46123236417770386 0.6044120192527771\n",
      "[Step 5679] Loss: 9.77e+07 0.46091800928115845 0.6043162941932678\n",
      "[Step 5680] Loss: 9.75e+07 0.4606224596500397 0.6042172908782959\n",
      "[Step 5681] Loss: 9.72e+07 0.46040862798690796 0.6041999459266663\n",
      "[Step 5682] Loss: 9.77e+07 0.4602451026439667 0.6041438579559326\n",
      "[Step 5683] Loss: 9.69e+07 0.4600822329521179 0.6040621399879456\n",
      "[Step 5684] Loss: 9.76e+07 0.4599686861038208 0.6040159463882446\n",
      "[Step 5685] Loss: 9.75e+07 0.4599538743495941 0.6039730310440063\n",
      "[Step 5686] Loss: 9.71e+07 0.45989835262298584 0.6038946509361267\n",
      "[Step 5687] Loss: 9.75e+07 0.45982295274734497 0.6038476228713989\n",
      "[Step 5688] Loss: 9.68e+07 0.4597513675689697 0.6037576794624329\n",
      "[Step 5689] Loss: 9.76e+07 0.4597460627555847 0.6037601232528687\n",
      "[Step 5690] Loss: 9.72e+07 0.45976632833480835 0.6037081480026245\n",
      "[Step 5691] Loss: 9.72e+07 0.4598274827003479 0.603695809841156\n",
      "[Step 5692] Loss: 9.63e+07 0.45988261699676514 0.6036710143089294\n",
      "[Step 5693] Loss: 9.68e+07 0.45989906787872314 0.6036404967308044\n",
      "[Step 5694] Loss: 9.72e+07 0.45991653203964233 0.6036157608032227\n",
      "[Step 5695] Loss: 9.62e+07 0.45997652411460876 0.6035827398300171\n",
      "[Step 5696] Loss: 9.74e+07 0.45992612838745117 0.6035505533218384\n",
      "[Step 5697] Loss: 9.74e+07 0.45989927649497986 0.603515088558197\n",
      "[Step 5698] Loss: 9.77e+07 0.45985835790634155 0.6034573316574097\n",
      "[Step 5699] Loss: 9.75e+07 0.45982757210731506 0.6033929586410522\n",
      "[Step 5700] Loss: 9.68e+07 0.4598374366760254 0.6033657193183899\n",
      "[Step 5701] Loss: 9.73e+07 0.45981618762016296 0.603334367275238\n",
      "[Step 5702] Loss: 9.73e+07 0.4598201513290405 0.6033087968826294\n",
      "[Step 5703] Loss: 9.67e+07 0.4598243832588196 0.6032642126083374\n",
      "[Step 5704] Loss: 9.80e+07 0.45980995893478394 0.60320645570755\n",
      "[Step 5705] Loss: 9.72e+07 0.4597387909889221 0.6031478643417358\n",
      "[Step 5706] Loss: 9.64e+07 0.459628164768219 0.6030893325805664\n",
      "[Step 5707] Loss: 9.71e+07 0.45955702662467957 0.6030372977256775\n",
      "[Step 5708] Loss: 9.68e+07 0.45949360728263855 0.602994441986084\n",
      "[Step 5709] Loss: 9.77e+07 0.4594602882862091 0.6029251217842102\n",
      "[Step 5710] Loss: 9.71e+07 0.45936131477355957 0.6028822064399719\n",
      "[Step 5711] Loss: 9.79e+07 0.459259569644928 0.6028599143028259\n",
      "[Step 5712] Loss: 9.67e+07 0.4590912461280823 0.6027633547782898\n",
      "[Step 5713] Loss: 9.74e+07 0.4588572680950165 0.602663516998291\n",
      "[Step 5714] Loss: 9.67e+07 0.45859667658805847 0.6025760769844055\n",
      "[Step 5715] Loss: 9.68e+07 0.458333820104599 0.6025009751319885\n",
      "[Step 5716] Loss: 9.80e+07 0.4580969512462616 0.602421760559082\n",
      "[Step 5717] Loss: 9.82e+07 0.45782873034477234 0.6023483276367188\n",
      "[Step 5718] Loss: 9.76e+07 0.45763716101646423 0.6022864580154419\n",
      "[Step 5719] Loss: 9.89e+07 0.45732370018959045 0.6021808385848999\n",
      "[Step 5720] Loss: 9.69e+07 0.4569830298423767 0.6020933389663696\n",
      "[Step 5721] Loss: 9.73e+07 0.4567297101020813 0.6019869446754456\n",
      "[Step 5722] Loss: 9.67e+07 0.45643267035484314 0.6018722057342529\n",
      "[Step 5723] Loss: 9.75e+07 0.45618459582328796 0.6017575263977051\n",
      "[Step 5724] Loss: 9.72e+07 0.4560527801513672 0.6017080545425415\n",
      "[Step 5725] Loss: 9.63e+07 0.45586830377578735 0.6016436815261841\n",
      "[Step 5726] Loss: 9.94e+07 0.4554704427719116 0.60148686170578\n",
      "[Step 5727] Loss: 9.69e+07 0.4550807774066925 0.601366400718689\n",
      "[Step 5728] Loss: 9.77e+07 0.4546685218811035 0.6012327671051025\n",
      "[Step 5729] Loss: 9.69e+07 0.45423728227615356 0.601078450679779\n",
      "[Step 5730] Loss: 9.77e+07 0.4538585841655731 0.6009554862976074\n",
      "[Step 5731] Loss: 9.74e+07 0.453540563583374 0.6008276343345642\n",
      "[Step 5732] Loss: 9.79e+07 0.453250527381897 0.6006947755813599\n",
      "[Step 5733] Loss: 9.74e+07 0.45297518372535706 0.6005858182907104\n",
      "[Step 5734] Loss: 9.70e+07 0.4527522325515747 0.6005074381828308\n",
      "[Step 5735] Loss: 9.67e+07 0.4524858295917511 0.600399374961853\n",
      "[Step 5736] Loss: 9.69e+07 0.4522551894187927 0.6003283858299255\n",
      "[Step 5737] Loss: 9.75e+07 0.4520399272441864 0.6002450585365295\n",
      "[Step 5738] Loss: 9.76e+07 0.45185330510139465 0.6001774072647095\n",
      "[Step 5739] Loss: 9.77e+07 0.4516630470752716 0.6001031398773193\n",
      "[Step 5740] Loss: 9.71e+07 0.45143815875053406 0.6000090837478638\n",
      "[Step 5741] Loss: 9.84e+07 0.451296865940094 0.5999504923820496\n",
      "[Step 5742] Loss: 9.75e+07 0.4512732923030853 0.5999414324760437\n",
      "[Step 5743] Loss: 9.68e+07 0.45127809047698975 0.5999150276184082\n",
      "[Step 5744] Loss: 9.68e+07 0.45123088359832764 0.5998704433441162\n",
      "[Step 5745] Loss: 9.72e+07 0.451178640127182 0.5998102426528931\n",
      "[Step 5746] Loss: 9.67e+07 0.4511185586452484 0.5997656583786011\n",
      "[Step 5747] Loss: 9.79e+07 0.4509848356246948 0.5997120141983032\n",
      "[Step 5748] Loss: 9.78e+07 0.4508732855319977 0.5996476411819458\n",
      "[Step 5749] Loss: 9.75e+07 0.45075860619544983 0.5996187925338745\n",
      "[Step 5750] Loss: 9.73e+07 0.4507245719432831 0.5996014475822449\n",
      "[Step 5751] Loss: 9.82e+07 0.450591117143631 0.5995354652404785\n",
      "[Step 5752] Loss: 9.70e+07 0.45043113827705383 0.5995016098022461\n",
      "[Step 5753] Loss: 9.73e+07 0.45027729868888855 0.5994256734848022\n",
      "[Step 5754] Loss: 9.72e+07 0.4501570761203766 0.5993497967720032\n",
      "[Step 5755] Loss: 9.74e+07 0.4499552845954895 0.5992771983146667\n",
      "[Step 5756] Loss: 9.75e+07 0.4498118758201599 0.5991979837417603\n",
      "[Step 5757] Loss: 9.68e+07 0.4496603012084961 0.5991385579109192\n",
      "[Step 5758] Loss: 9.71e+07 0.4495886564254761 0.5990659594535828\n",
      "[Step 5759] Loss: 9.76e+07 0.44946861267089844 0.5989974737167358\n",
      "[Step 5760] Loss: 9.74e+07 0.44936954975128174 0.5989512205123901\n",
      "[Step 5761] Loss: 9.71e+07 0.4492438733577728 0.5988934636116028\n",
      "[Step 5762] Loss: 9.79e+07 0.44914230704307556 0.5988406538963318\n",
      "[Step 5763] Loss: 9.78e+07 0.44911766052246094 0.5988126397132874\n",
      "[Step 5764] Loss: 9.82e+07 0.44900405406951904 0.5987300872802734\n",
      "[Step 5765] Loss: 9.69e+07 0.4489462375640869 0.598702073097229\n",
      "[Step 5766] Loss: 9.72e+07 0.44887682795524597 0.5986599922180176\n",
      "[Step 5767] Loss: 9.78e+07 0.448885440826416 0.5986236929893494\n",
      "[Step 5768] Loss: 9.81e+07 0.44875290989875793 0.5985617637634277\n",
      "[Step 5769] Loss: 9.74e+07 0.44865450263023376 0.5985122919082642\n",
      "[Step 5770] Loss: 9.75e+07 0.44859379529953003 0.5984693765640259\n",
      "[Step 5771] Loss: 9.71e+07 0.44848111271858215 0.5984182357788086\n",
      "[Step 5772] Loss: 9.71e+07 0.4484376013278961 0.5983860492706299\n",
      "[Step 5773] Loss: 9.75e+07 0.44833269715309143 0.5983150601387024\n",
      "[Step 5774] Loss: 9.89e+07 0.44816458225250244 0.5982564687728882\n",
      "[Step 5775] Loss: 9.85e+07 0.4478837251663208 0.5981649160385132\n",
      "[Step 5776] Loss: 9.77e+07 0.44765016436576843 0.5980402827262878\n",
      "[Step 5777] Loss: 9.76e+07 0.44747868180274963 0.5979949235916138\n",
      "[Step 5778] Loss: 9.73e+07 0.44718092679977417 0.5979066491127014\n",
      "[Step 5779] Loss: 9.74e+07 0.4468781352043152 0.5978249311447144\n",
      "[Step 5780] Loss: 9.71e+07 0.44667789340019226 0.5977506637573242\n",
      "[Step 5781] Loss: 9.82e+07 0.4464907944202423 0.5976706147193909\n",
      "[Step 5782] Loss: 9.83e+07 0.4461977779865265 0.5975856184959412\n",
      "[Step 5783] Loss: 9.69e+07 0.4458993375301361 0.5974651575088501\n",
      "[Step 5784] Loss: 9.74e+07 0.4454912543296814 0.5973306894302368\n",
      "[Step 5785] Loss: 9.69e+07 0.4451362192630768 0.5972176194190979\n",
      "[Step 5786] Loss: 9.76e+07 0.4448062777519226 0.5971087217330933\n",
      "[Step 5787] Loss: 9.75e+07 0.44454506039619446 0.5969981551170349\n",
      "[Step 5788] Loss: 9.79e+07 0.4442499279975891 0.5968917012214661\n",
      "[Step 5789] Loss: 9.77e+07 0.44390594959259033 0.5967472791671753\n",
      "[Step 5790] Loss: 9.78e+07 0.4436366558074951 0.5966367125511169\n",
      "[Step 5791] Loss: 9.68e+07 0.44333067536354065 0.5965138077735901\n",
      "[Step 5792] Loss: 9.76e+07 0.4430108666419983 0.5963999032974243\n",
      "[Step 5793] Loss: 9.78e+07 0.44275277853012085 0.5962976217269897\n",
      "[Step 5794] Loss: 9.83e+07 0.4424423575401306 0.5961358547210693\n",
      "[Step 5795] Loss: 9.75e+07 0.4421970248222351 0.5960228443145752\n",
      "[Step 5796] Loss: 9.67e+07 0.441957950592041 0.5959081649780273\n",
      "[Step 5797] Loss: 9.74e+07 0.44177213311195374 0.5958182215690613\n",
      "[Step 5798] Loss: 9.76e+07 0.4416961371898651 0.5957513451576233\n",
      "[Step 5799] Loss: 9.87e+07 0.44146236777305603 0.5956663489341736\n",
      "[Step 5800] Loss: 9.67e+07 0.44115668535232544 0.5955434441566467\n",
      "[Step 5801] Loss: 9.81e+07 0.44083788990974426 0.5954262614250183\n",
      "[Step 5802] Loss: 9.71e+07 0.4404982328414917 0.5953247547149658\n",
      "[Step 5803] Loss: 9.77e+07 0.4403054118156433 0.5952620506286621\n",
      "[Step 5804] Loss: 9.71e+07 0.44004496932029724 0.5951869487762451\n",
      "[Step 5805] Loss: 9.70e+07 0.4398193955421448 0.595059871673584\n",
      "[Step 5806] Loss: 9.77e+07 0.43952780961990356 0.5949394106864929\n",
      "[Step 5807] Loss: 9.68e+07 0.43921592831611633 0.5948165059089661\n",
      "[Step 5808] Loss: 9.78e+07 0.4387822449207306 0.5946952104568481\n",
      "[Step 5809] Loss: 9.81e+07 0.43850645422935486 0.5946341156959534\n",
      "[Step 5810] Loss: 9.66e+07 0.4382404386997223 0.5945714116096497\n",
      "[Step 5811] Loss: 9.75e+07 0.437959760427475 0.5945194363594055\n",
      "[Step 5812] Loss: 9.79e+07 0.4377581477165222 0.5944880843162537\n",
      "[Step 5813] Loss: 9.76e+07 0.43746230006217957 0.594358503818512\n",
      "[Step 5814] Loss: 9.79e+07 0.4372416138648987 0.5942925214767456\n",
      "[Step 5815] Loss: 9.68e+07 0.4370359182357788 0.5942165851593018\n",
      "[Step 5816] Loss: 9.69e+07 0.43686938285827637 0.5941283106803894\n",
      "[Step 5817] Loss: 9.75e+07 0.4367693364620209 0.5940911769866943\n",
      "[Step 5818] Loss: 9.70e+07 0.4366220533847809 0.5940515995025635\n",
      "[Step 5819] Loss: 9.70e+07 0.43652164936065674 0.5939971208572388\n",
      "[Step 5820] Loss: 9.76e+07 0.43636173009872437 0.5939170718193054\n",
      "[Step 5821] Loss: 9.73e+07 0.4362620413303375 0.593874990940094\n",
      "[Step 5822] Loss: 9.71e+07 0.4361346960067749 0.5937743186950684\n",
      "[Step 5823] Loss: 9.68e+07 0.4360479712486267 0.5937281250953674\n",
      "[Step 5824] Loss: 9.67e+07 0.4359872043132782 0.5936909914016724\n",
      "[Step 5825] Loss: 9.67e+07 0.4359530806541443 0.5936802625656128\n",
      "[Step 5826] Loss: 9.69e+07 0.43591728806495667 0.593655526638031\n",
      "[Step 5827] Loss: 9.65e+07 0.4358600974082947 0.5936241745948792\n",
      "[Step 5828] Loss: 9.79e+07 0.4358673691749573 0.5935853719711304\n",
      "[Step 5829] Loss: 9.68e+07 0.43597277998924255 0.5935779809951782\n",
      "[Step 5830] Loss: 9.66e+07 0.4360845685005188 0.5935878753662109\n",
      "[Step 5831] Loss: 9.70e+07 0.43609967827796936 0.5935713648796082\n",
      "[Step 5832] Loss: 9.64e+07 0.4361613094806671 0.5935688614845276\n",
      "[Step 5833] Loss: 9.77e+07 0.436143159866333 0.5935713648796082\n",
      "[Step 5834] Loss: 9.74e+07 0.43617182970046997 0.5936051607131958\n",
      "[Step 5835] Loss: 9.77e+07 0.4362594485282898 0.5936093330383301\n",
      "[Step 5836] Loss: 9.70e+07 0.4362727701663971 0.5935862064361572\n",
      "[Step 5837] Loss: 9.74e+07 0.43624722957611084 0.5935507416725159\n",
      "[Step 5838] Loss: 9.73e+07 0.4362667202949524 0.5936043858528137\n",
      "[Step 5839] Loss: 9.74e+07 0.4362986981868744 0.5936241745948792\n",
      "[Step 5840] Loss: 9.66e+07 0.43630582094192505 0.5935944318771362\n",
      "[Step 5841] Loss: 9.64e+07 0.4363066852092743 0.5936175584793091\n",
      "[Step 5842] Loss: 9.70e+07 0.4363044202327728 0.5936167240142822\n",
      "[Step 5843] Loss: 9.76e+07 0.4363638460636139 0.5936299562454224\n",
      "[Step 5844] Loss: 9.67e+07 0.436469703912735 0.59366375207901\n",
      "[Step 5845] Loss: 9.73e+07 0.4365326762199402 0.5936769843101501\n",
      "[Step 5846] Loss: 9.71e+07 0.436567485332489 0.5936868786811829\n",
      "[Step 5847] Loss: 9.74e+07 0.43665891885757446 0.5937289595603943\n",
      "[Step 5848] Loss: 9.76e+07 0.4368496835231781 0.5937603116035461\n",
      "[Step 5849] Loss: 9.69e+07 0.4369518458843231 0.5938048362731934\n",
      "[Step 5850] Loss: 9.65e+07 0.43709102272987366 0.5937660932540894\n",
      "[Step 5851] Loss: 9.66e+07 0.4372059404850006 0.5937710404396057\n",
      "[Step 5852] Loss: 9.69e+07 0.43726128339767456 0.593783438205719\n",
      "[Step 5853] Loss: 9.83e+07 0.4372937083244324 0.5937809348106384\n",
      "[Step 5854] Loss: 9.76e+07 0.43735766410827637 0.5937759876251221\n",
      "[Step 5855] Loss: 9.69e+07 0.4374554753303528 0.5937809348106384\n",
      "[Step 5856] Loss: 9.68e+07 0.4374908208847046 0.593769371509552\n",
      "[Step 5857] Loss: 9.69e+07 0.4375247359275818 0.5937578082084656\n",
      "[Step 5858] Loss: 9.68e+07 0.4376460313796997 0.5937339067459106\n",
      "[Step 5859] Loss: 9.70e+07 0.437785804271698 0.5937248468399048\n",
      "[Step 5860] Loss: 9.72e+07 0.4379236102104187 0.5937339067459106\n",
      "[Step 5861] Loss: 9.70e+07 0.43803784251213074 0.5937017202377319\n",
      "[Step 5862] Loss: 9.71e+07 0.4380647540092468 0.5936843752861023\n",
      "[Step 5863] Loss: 9.73e+07 0.4381623864173889 0.5936934947967529\n",
      "[Step 5864] Loss: 9.71e+07 0.438180536031723 0.5936967730522156\n",
      "[Step 5865] Loss: 9.69e+07 0.4382261037826538 0.5936769843101501\n",
      "[Step 5866] Loss: 9.77e+07 0.4383177161216736 0.5936390161514282\n",
      "[Step 5867] Loss: 9.72e+07 0.4384174942970276 0.5936183929443359\n",
      "[Step 5868] Loss: 9.75e+07 0.43843042850494385 0.5935870409011841\n",
      "[Step 5869] Loss: 9.70e+07 0.438472718000412 0.5935614705085754\n",
      "[Step 5870] Loss: 9.72e+07 0.438445508480072 0.5935037136077881\n",
      "[Step 5871] Loss: 9.81e+07 0.4382745921611786 0.5934244990348816\n",
      "[Step 5872] Loss: 9.74e+07 0.43810155987739563 0.5933436155319214\n",
      "[Step 5873] Loss: 9.71e+07 0.4379376173019409 0.5932742953300476\n",
      "[Step 5874] Loss: 9.71e+07 0.43775734305381775 0.5932099223136902\n",
      "[Step 5875] Loss: 9.69e+07 0.4376833736896515 0.593172013759613\n",
      "[Step 5876] Loss: 9.71e+07 0.43754956126213074 0.5930622220039368\n",
      "[Step 5877] Loss: 9.68e+07 0.4373733401298523 0.5929970741271973\n",
      "[Step 5878] Loss: 9.78e+07 0.4372798502445221 0.5929681658744812\n",
      "[Step 5879] Loss: 9.73e+07 0.4370330572128296 0.5929170250892639\n",
      "[Step 5880] Loss: 9.72e+07 0.43682003021240234 0.5928402543067932\n",
      "[Step 5881] Loss: 9.84e+07 0.4364682137966156 0.5927618741989136\n",
      "[Step 5882] Loss: 9.85e+07 0.4360411465167999 0.5926117300987244\n",
      "[Step 5883] Loss: 9.77e+07 0.43558844923973083 0.5924450159072876\n",
      "[Step 5884] Loss: 9.75e+07 0.43524184823036194 0.592312216758728\n",
      "[Step 5885] Loss: 9.75e+07 0.43496352434158325 0.5922016501426697\n",
      "[Step 5886] Loss: 9.72e+07 0.43472445011138916 0.5921455025672913\n",
      "[Step 5887] Loss: 9.75e+07 0.4344967007637024 0.5921059250831604\n",
      "[Step 5888] Loss: 9.70e+07 0.4342845380306244 0.5920374393463135\n",
      "[Step 5889] Loss: 9.74e+07 0.43411725759506226 0.5919705629348755\n",
      "[Step 5890] Loss: 9.75e+07 0.43388718366622925 0.5918905735015869\n",
      "[Step 5891] Loss: 9.76e+07 0.4335584342479706 0.5917832851409912\n",
      "[Step 5892] Loss: 9.74e+07 0.4332278072834015 0.5917090177536011\n",
      "[Step 5893] Loss: 9.74e+07 0.43297451734542847 0.5915976166725159\n",
      "[Step 5894] Loss: 9.75e+07 0.4326432943344116 0.5915117859840393\n",
      "[Step 5895] Loss: 9.71e+07 0.4323616623878479 0.5914061665534973\n",
      "[Step 5896] Loss: 9.72e+07 0.43207797408103943 0.5913154482841492\n",
      "[Step 5897] Loss: 9.63e+07 0.43178388476371765 0.5911941528320312\n",
      "[Step 5898] Loss: 9.68e+07 0.43151289224624634 0.5910819172859192\n",
      "[Step 5899] Loss: 9.70e+07 0.4312289357185364 0.5909408330917358\n",
      "[Step 5900] Loss: 9.69e+07 0.4310224652290344 0.5908483862876892\n",
      "[Step 5901] Loss: 9.67e+07 0.4307665228843689 0.5907840132713318\n",
      "[Step 5902] Loss: 9.76e+07 0.4305935800075531 0.5906742811203003\n",
      "[Step 5903] Loss: 9.75e+07 0.4304579794406891 0.5906000137329102\n",
      "[Step 5904] Loss: 9.63e+07 0.4303116202354431 0.5905166864395142\n",
      "[Step 5905] Loss: 9.74e+07 0.4302770495414734 0.5904853343963623\n",
      "[Step 5906] Loss: 9.74e+07 0.4301861822605133 0.5904234647750854\n",
      "[Step 5907] Loss: 9.72e+07 0.4300483763217926 0.5903607606887817\n",
      "[Step 5908] Loss: 9.70e+07 0.42983755469322205 0.5902559757232666\n",
      "[Step 5909] Loss: 9.68e+07 0.42966440320014954 0.5901841521263123\n",
      "[Step 5910] Loss: 9.73e+07 0.4294915795326233 0.5901321768760681\n",
      "[Step 5911] Loss: 9.69e+07 0.4292643070220947 0.5900306701660156\n",
      "[Step 5912] Loss: 9.81e+07 0.4292016923427582 0.5899919271469116\n",
      "[Step 5913] Loss: 9.75e+07 0.4291909337043762 0.5899531245231628\n",
      "[Step 5914] Loss: 9.70e+07 0.429188996553421 0.5899085402488708\n",
      "[Step 5915] Loss: 9.75e+07 0.4291086196899414 0.5898507833480835\n",
      "[Step 5916] Loss: 9.64e+07 0.429019033908844 0.5898112058639526\n",
      "[Step 5917] Loss: 9.66e+07 0.42895233631134033 0.5897468328475952\n",
      "[Step 5918] Loss: 9.71e+07 0.42886555194854736 0.589688241481781\n",
      "[Step 5919] Loss: 9.70e+07 0.4288555383682251 0.5896544456481934\n",
      "[Step 5920] Loss: 9.75e+07 0.42886224389076233 0.5896238684654236\n",
      "[Step 5921] Loss: 9.69e+07 0.4288695156574249 0.5896222591400146\n",
      "[Step 5922] Loss: 9.80e+07 0.4288392961025238 0.5896205902099609\n",
      "[Step 5923] Loss: 9.71e+07 0.42877405881881714 0.5895768404006958\n",
      "[Step 5924] Loss: 9.69e+07 0.42878350615501404 0.5895347595214844\n",
      "[Step 5925] Loss: 9.76e+07 0.4288139045238495 0.5895232558250427\n",
      "[Step 5926] Loss: 9.76e+07 0.4289303719997406 0.5895001292228699\n",
      "[Step 5927] Loss: 9.82e+07 0.4289037883281708 0.5894638299942017\n",
      "[Step 5928] Loss: 9.72e+07 0.42886823415756226 0.5894069075584412\n",
      "[Step 5929] Loss: 9.68e+07 0.4288138449192047 0.5893474817276001\n",
      "[Step 5930] Loss: 9.78e+07 0.42866984009742737 0.5893004536628723\n",
      "[Step 5931] Loss: 9.75e+07 0.4285140037536621 0.5892146229743958\n",
      "[Step 5932] Loss: 9.72e+07 0.42828771471977234 0.5891156196594238\n",
      "[Step 5933] Loss: 9.61e+07 0.4280867576599121 0.5890273451805115\n",
      "[Step 5934] Loss: 9.67e+07 0.4279049038887024 0.588925838470459\n",
      "[Step 5935] Loss: 9.69e+07 0.42777374386787415 0.5888614654541016\n",
      "[Step 5936] Loss: 9.69e+07 0.4277418255805969 0.5888012647628784\n",
      "[Step 5937] Loss: 9.78e+07 0.4277494549751282 0.5887665748596191\n",
      "[Step 5938] Loss: 9.72e+07 0.42771369218826294 0.5887410044670105\n",
      "[Step 5939] Loss: 9.79e+07 0.42765283584594727 0.5886972546577454\n",
      "[Step 5940] Loss: 9.84e+07 0.4275367856025696 0.5886403322219849\n",
      "[Step 5941] Loss: 9.77e+07 0.4274810254573822 0.5885965824127197\n",
      "[Step 5942] Loss: 9.61e+07 0.42743638157844543 0.5885974168777466\n",
      "[Step 5943] Loss: 9.76e+07 0.42734992504119873 0.5885636210441589\n",
      "[Step 5944] Loss: 9.66e+07 0.4272700548171997 0.5885140895843506\n",
      "[Step 5945] Loss: 9.81e+07 0.4272633194923401 0.588496744632721\n",
      "[Step 5946] Loss: 9.70e+07 0.4273272752761841 0.588481068611145\n",
      "[Step 5947] Loss: 9.65e+07 0.42738690972328186 0.5884497165679932\n",
      "[Step 5948] Loss: 9.77e+07 0.4275285303592682 0.5884530544281006\n",
      "[Step 5949] Loss: 9.75e+07 0.4277488589286804 0.5885173678398132\n",
      "[Step 5950] Loss: 9.73e+07 0.4279397130012512 0.5885636210441589\n",
      "[Step 5951] Loss: 9.63e+07 0.42805373668670654 0.5885379910469055\n",
      "[Step 5952] Loss: 9.66e+07 0.42810118198394775 0.5885347127914429\n",
      "[Step 5953] Loss: 9.76e+07 0.42817941308021545 0.5885149240493774\n",
      "[Step 5954] Loss: 9.66e+07 0.42821019887924194 0.588495135307312\n",
      "[Step 5955] Loss: 9.82e+07 0.42806437611579895 0.5884398221969604\n",
      "[Step 5956] Loss: 9.82e+07 0.4277980327606201 0.5883548259735107\n",
      "[Step 5957] Loss: 9.66e+07 0.42752933502197266 0.588261604309082\n",
      "[Step 5958] Loss: 9.71e+07 0.42734625935554504 0.5882195234298706\n",
      "[Step 5959] Loss: 9.74e+07 0.42716774344444275 0.5881378054618835\n",
      "[Step 5960] Loss: 9.72e+07 0.427002489566803 0.5880817174911499\n",
      "[Step 5961] Loss: 9.74e+07 0.4269169569015503 0.5880330204963684\n",
      "[Step 5962] Loss: 9.80e+07 0.4267435371875763 0.5879934430122375\n",
      "[Step 5963] Loss: 9.75e+07 0.42661547660827637 0.5879108905792236\n",
      "[Step 5964] Loss: 9.63e+07 0.4265219569206238 0.5878267288208008\n",
      "[Step 5965] Loss: 9.65e+07 0.42642655968666077 0.5877475142478943\n",
      "[Step 5966] Loss: 9.68e+07 0.42628130316734314 0.5877062678337097\n",
      "[Step 5967] Loss: 9.74e+07 0.4261683523654938 0.5876402854919434\n",
      "[Step 5968] Loss: 9.80e+07 0.42615842819213867 0.5876047611236572\n",
      "[Step 5969] Loss: 9.90e+07 0.4259251058101654 0.5874892473220825\n",
      "[Step 5970] Loss: 9.73e+07 0.42565199732780457 0.5874034762382507\n",
      "[Step 5971] Loss: 9.68e+07 0.42540761828422546 0.5873069167137146\n",
      "[Step 5972] Loss: 9.79e+07 0.4251386821269989 0.5871938467025757\n",
      "[Step 5973] Loss: 9.84e+07 0.4249975085258484 0.5871394276618958\n",
      "[Step 5974] Loss: 9.74e+07 0.42485031485557556 0.5870800018310547\n",
      "[Step 5975] Loss: 9.75e+07 0.424740195274353 0.5870445370674133\n",
      "[Step 5976] Loss: 9.79e+07 0.4245312809944153 0.586933970451355\n",
      "[Step 5977] Loss: 9.73e+07 0.42429378628730774 0.5868234038352966\n",
      "[Step 5978] Loss: 9.71e+07 0.4241390526294708 0.5867350697517395\n",
      "[Step 5979] Loss: 9.70e+07 0.4239795207977295 0.5866798162460327\n",
      "[Step 5980] Loss: 9.75e+07 0.423900306224823 0.5866137742996216\n",
      "[Step 5981] Loss: 9.74e+07 0.42377519607543945 0.5865601897239685\n",
      "[Step 5982] Loss: 9.73e+07 0.42367106676101685 0.5865032076835632\n",
      "[Step 5983] Loss: 9.73e+07 0.423494815826416 0.5864430069923401\n",
      "[Step 5984] Loss: 9.86e+07 0.42340323328971863 0.5863885283470154\n",
      "[Step 5985] Loss: 9.71e+07 0.4233177900314331 0.5863497257232666\n",
      "[Step 5986] Loss: 9.79e+07 0.4231010675430298 0.5862491130828857\n",
      "[Step 5987] Loss: 9.65e+07 0.42287006974220276 0.5861533880233765\n",
      "[Step 5988] Loss: 9.78e+07 0.4226881265640259 0.5860865116119385\n",
      "[Step 5989] Loss: 9.74e+07 0.4226093888282776 0.5860238075256348\n",
      "[Step 5990] Loss: 9.74e+07 0.4224749207496643 0.5859421491622925\n",
      "[Step 5991] Loss: 9.69e+07 0.42232146859169006 0.5858538746833801\n",
      "[Step 5992] Loss: 9.76e+07 0.4221009910106659 0.585726797580719\n",
      "[Step 5993] Loss: 9.75e+07 0.4218044579029083 0.58560711145401\n",
      "[Step 5994] Loss: 9.75e+07 0.42145681381225586 0.5855039954185486\n",
      "[Step 5995] Loss: 9.70e+07 0.421176016330719 0.585440456867218\n",
      "[Step 5996] Loss: 9.66e+07 0.42087873816490173 0.585342288017273\n",
      "[Step 5997] Loss: 9.70e+07 0.42060258984565735 0.5852242708206177\n",
      "[Step 5998] Loss: 9.74e+07 0.42032408714294434 0.5851268768310547\n",
      "[Step 5999] Loss: 9.73e+07 0.4201242923736572 0.5850600600242615\n",
      "[Step 6000] Loss: 9.76e+07 0.41999146342277527 0.5849717855453491\n",
      "[Step 6001] Loss: 9.69e+07 0.41994941234588623 0.5849189758300781\n",
      "[Step 6002] Loss: 9.70e+07 0.4199197292327881 0.5848942399024963\n",
      "[Step 6003] Loss: 9.79e+07 0.41999855637550354 0.584867000579834\n",
      "[Step 6004] Loss: 9.79e+07 0.42001885175704956 0.5848414301872253\n",
      "[Step 6005] Loss: 9.74e+07 0.4200390875339508 0.5848281979560852\n",
      "[Step 6006] Loss: 9.72e+07 0.42011967301368713 0.5848331451416016\n",
      "[Step 6007] Loss: 9.73e+07 0.42013996839523315 0.5848166346549988\n",
      "[Step 6008] Loss: 9.77e+07 0.4201480746269226 0.5847654938697815\n",
      "[Step 6009] Loss: 9.74e+07 0.420232892036438 0.5847539305686951\n",
      "[Step 6010] Loss: 9.73e+07 0.4203563332557678 0.5847440361976624\n",
      "[Step 6011] Loss: 9.68e+07 0.4204638600349426 0.5847729444503784\n",
      "[Step 6012] Loss: 9.82e+07 0.4206196963787079 0.5848009586334229\n",
      "[Step 6013] Loss: 9.70e+07 0.4208409786224365 0.5848422050476074\n",
      "[Step 6014] Loss: 9.73e+07 0.4209056794643402 0.5848298668861389\n",
      "[Step 6015] Loss: 9.73e+07 0.42098507285118103 0.5847943425178528\n",
      "[Step 6016] Loss: 9.73e+07 0.421082466840744 0.5847877860069275\n",
      "[Step 6017] Loss: 9.73e+07 0.42122766375541687 0.5848281979560852\n",
      "[Step 6018] Loss: 9.73e+07 0.42147761583328247 0.5848571062088013\n",
      "[Step 6019] Loss: 9.76e+07 0.42164644598960876 0.5848810076713562\n",
      "[Step 6020] Loss: 9.72e+07 0.4217877984046936 0.5849016308784485\n",
      "[Step 6021] Loss: 9.81e+07 0.4219631254673004 0.5849156379699707\n",
      "[Step 6022] Loss: 9.67e+07 0.4221220016479492 0.5849189758300781\n",
      "[Step 6023] Loss: 9.80e+07 0.4222318232059479 0.5849230885505676\n",
      "[Step 6024] Loss: 9.67e+07 0.4223443865776062 0.5849329829216003\n",
      "[Step 6025] Loss: 9.76e+07 0.42241260409355164 0.5849123597145081\n",
      "[Step 6026] Loss: 9.74e+07 0.422465443611145 0.5848983526229858\n",
      "[Step 6027] Loss: 9.76e+07 0.42255353927612305 0.5849230885505676\n",
      "[Step 6028] Loss: 9.68e+07 0.42266008257865906 0.5848909020423889\n",
      "[Step 6029] Loss: 9.70e+07 0.4227016270160675 0.5848851203918457\n",
      "[Step 6030] Loss: 9.74e+07 0.4227074980735779 0.5848644971847534\n",
      "[Step 6031] Loss: 9.84e+07 0.42256641387939453 0.5847745537757874\n",
      "[Step 6032] Loss: 9.69e+07 0.4223685562610626 0.5847052335739136\n",
      "[Step 6033] Loss: 9.92e+07 0.4219844937324524 0.5845740437507629\n",
      "[Step 6034] Loss: 9.70e+07 0.42163631319999695 0.5844370722770691\n",
      "[Step 6035] Loss: 9.71e+07 0.4213218688964844 0.5843256711959839\n",
      "[Step 6036] Loss: 9.69e+07 0.4210709035396576 0.5842580199241638\n",
      "[Step 6037] Loss: 9.66e+07 0.42088788747787476 0.5841845870018005\n",
      "[Step 6038] Loss: 9.67e+07 0.420742392539978 0.584112823009491\n",
      "[Step 6039] Loss: 9.78e+07 0.4206775724887848 0.5840731859207153\n",
      "[Step 6040] Loss: 9.64e+07 0.42063573002815247 0.584029495716095\n",
      "[Step 6041] Loss: 9.70e+07 0.4206601679325104 0.5840038657188416\n",
      "[Step 6042] Loss: 9.76e+07 0.4207492768764496 0.5839840769767761\n",
      "[Step 6043] Loss: 9.74e+07 0.4207657277584076 0.5839477777481079\n",
      "[Step 6044] Loss: 9.69e+07 0.42071226239204407 0.5838925242424011\n",
      "[Step 6045] Loss: 9.66e+07 0.4206130802631378 0.5838668942451477\n",
      "[Step 6046] Loss: 9.80e+07 0.4204750657081604 0.5837777853012085\n",
      "[Step 6047] Loss: 9.74e+07 0.42038658261299133 0.5836878418922424\n",
      "[Step 6048] Loss: 9.74e+07 0.4202824831008911 0.5836606025695801\n",
      "[Step 6049] Loss: 9.71e+07 0.4202556908130646 0.583637535572052\n",
      "[Step 6050] Loss: 9.70e+07 0.42021748423576355 0.5835946202278137\n",
      "[Step 6051] Loss: 9.66e+07 0.42020946741104126 0.5835657119750977\n",
      "[Step 6052] Loss: 9.72e+07 0.42021802067756653 0.5835500359535217\n",
      "[Step 6053] Loss: 9.75e+07 0.4203670024871826 0.5835615992546082\n",
      "[Step 6054] Loss: 9.78e+07 0.42040878534317017 0.5835335850715637\n",
      "[Step 6055] Loss: 9.69e+07 0.42042991518974304 0.5835195183753967\n",
      "[Step 6056] Loss: 9.71e+07 0.42046481370925903 0.5834898352622986\n",
      "[Step 6057] Loss: 9.74e+07 0.42042437195777893 0.5834510326385498\n",
      "[Step 6058] Loss: 9.74e+07 0.4202503263950348 0.5833941102027893\n",
      "[Step 6059] Loss: 9.74e+07 0.42009708285331726 0.5833421349525452\n",
      "[Step 6060] Loss: 9.71e+07 0.4199413061141968 0.583283543586731\n",
      "[Step 6061] Loss: 9.67e+07 0.41978296637535095 0.5832282900810242\n",
      "[Step 6062] Loss: 9.76e+07 0.41960522532463074 0.583155632019043\n",
      "[Step 6063] Loss: 9.69e+07 0.4194449782371521 0.5831053256988525\n",
      "[Step 6064] Loss: 9.76e+07 0.4192245900630951 0.5830137133598328\n",
      "[Step 6065] Loss: 9.68e+07 0.4190962016582489 0.582966685295105\n",
      "[Step 6066] Loss: 9.73e+07 0.4189710021018982 0.5829254388809204\n",
      "[Step 6067] Loss: 9.69e+07 0.41884368658065796 0.5828586220741272\n",
      "[Step 6068] Loss: 9.73e+07 0.41870439052581787 0.5828338265419006\n",
      "[Step 6069] Loss: 9.75e+07 0.41858047246932983 0.5827637314796448\n",
      "[Step 6070] Loss: 9.70e+07 0.4185430407524109 0.582747220993042\n",
      "[Step 6071] Loss: 9.76e+07 0.4185251295566559 0.5826935768127441\n",
      "[Step 6072] Loss: 9.71e+07 0.41857925057411194 0.5826646685600281\n",
      "[Step 6073] Loss: 9.63e+07 0.41865020990371704 0.5826317071914673\n",
      "[Step 6074] Loss: 9.71e+07 0.4187154769897461 0.5826118588447571\n",
      "[Step 6075] Loss: 9.71e+07 0.41873812675476074 0.5825722813606262\n",
      "[Step 6076] Loss: 9.70e+07 0.4187096953392029 0.582535982131958\n",
      "[Step 6077] Loss: 9.73e+07 0.4186154901981354 0.5824501514434814\n",
      "[Step 6078] Loss: 9.68e+07 0.4185710847377777 0.5824344754219055\n",
      "[Step 6079] Loss: 9.72e+07 0.41855114698410034 0.5824460387229919\n",
      "[Step 6080] Loss: 9.69e+07 0.41848427057266235 0.5824146866798401\n",
      "[Step 6081] Loss: 9.65e+07 0.41838276386260986 0.5823750495910645\n",
      "[Step 6082] Loss: 9.67e+07 0.4182072579860687 0.5822991728782654\n",
      "[Step 6083] Loss: 9.67e+07 0.41802117228507996 0.582243025302887\n",
      "[Step 6084] Loss: 9.73e+07 0.41790908575057983 0.5821927189826965\n",
      "[Step 6085] Loss: 9.75e+07 0.41779664158821106 0.5821481347084045\n",
      "[Step 6086] Loss: 9.78e+07 0.4176216125488281 0.5820928812026978\n",
      "[Step 6087] Loss: 9.72e+07 0.4175166189670563 0.5820367336273193\n",
      "[Step 6088] Loss: 9.68e+07 0.41744402050971985 0.5819782018661499\n",
      "[Step 6089] Loss: 9.69e+07 0.41738083958625793 0.5819368958473206\n",
      "[Step 6090] Loss: 9.71e+07 0.41728559136390686 0.5818684101104736\n",
      "[Step 6091] Loss: 9.71e+07 0.41710513830184937 0.5818255543708801\n",
      "[Step 6092] Loss: 9.61e+07 0.4169751703739166 0.5817669630050659\n",
      "[Step 6093] Loss: 9.69e+07 0.41687604784965515 0.5817264914512634\n",
      "[Step 6094] Loss: 9.76e+07 0.4168117046356201 0.5817124843597412\n",
      "[Step 6095] Loss: 9.77e+07 0.4168126881122589 0.5816720724105835\n",
      "[Step 6096] Loss: 9.74e+07 0.41668474674224854 0.5816258192062378\n",
      "[Step 6097] Loss: 9.66e+07 0.41657814383506775 0.5816192626953125\n",
      "[Step 6098] Loss: 9.72e+07 0.4164339303970337 0.5815664529800415\n",
      "[Step 6099] Loss: 9.63e+07 0.4162525534629822 0.5815037488937378\n",
      "[Step 6100] Loss: 9.66e+07 0.41611212491989136 0.5814492702484131\n",
      "[Step 6101] Loss: 9.67e+07 0.41586819291114807 0.581403911113739\n",
      "[Step 6102] Loss: 9.79e+07 0.41553908586502075 0.5812817811965942\n",
      "[Step 6103] Loss: 9.90e+07 0.41506266593933105 0.5811365246772766\n",
      "[Step 6104] Loss: 9.69e+07 0.41461873054504395 0.5809979438781738\n",
      "[Step 6105] Loss: 9.80e+07 0.4142492115497589 0.5808708667755127\n",
      "[Step 6106] Loss: 9.72e+07 0.4138950705528259 0.5807610750198364\n",
      "[Step 6107] Loss: 9.63e+07 0.4135890305042267 0.5806571245193481\n",
      "[Step 6108] Loss: 9.64e+07 0.4133460223674774 0.5805506706237793\n",
      "[Step 6109] Loss: 9.77e+07 0.41313162446022034 0.5804813504219055\n",
      "[Step 6110] Loss: 9.71e+07 0.4130204916000366 0.5804516673088074\n",
      "[Step 6111] Loss: 9.69e+07 0.4130062758922577 0.5804194808006287\n",
      "[Step 6112] Loss: 9.78e+07 0.4130344092845917 0.5804368257522583\n",
      "[Step 6113] Loss: 9.71e+07 0.41314005851745605 0.5804632306098938\n",
      "[Step 6114] Loss: 9.66e+07 0.4132319688796997 0.580499529838562\n",
      "[Step 6115] Loss: 9.74e+07 0.4132898151874542 0.5805234909057617\n",
      "[Step 6116] Loss: 9.71e+07 0.41343897581100464 0.5805490612983704\n",
      "[Step 6117] Loss: 1.01e+08 0.41331225633621216 0.5804896354675293\n",
      "[Step 6118] Loss: 9.68e+07 0.4131768047809601 0.5804252624511719\n",
      "[Step 6119] Loss: 9.80e+07 0.41319242119789124 0.58039391040802\n",
      "[Step 6120] Loss: 9.64e+07 0.4132171869277954 0.5803831815719604\n",
      "[Step 6121] Loss: 9.70e+07 0.41321516036987305 0.5803551077842712\n",
      "[Step 6122] Loss: 9.68e+07 0.41314443945884705 0.5803146958351135\n",
      "[Step 6123] Loss: 9.68e+07 0.4130198061466217 0.5802651643753052\n",
      "[Step 6124] Loss: 9.68e+07 0.4129001200199127 0.5802173614501953\n",
      "[Step 6125] Loss: 9.76e+07 0.4127785265445709 0.580167829990387\n",
      "[Step 6126] Loss: 9.71e+07 0.4126088619232178 0.5801141858100891\n",
      "[Step 6127] Loss: 9.71e+07 0.41240137815475464 0.5800407528877258\n",
      "[Step 6128] Loss: 9.75e+07 0.4121987819671631 0.5799384117126465\n",
      "[Step 6129] Loss: 9.70e+07 0.4119607210159302 0.5798649787902832\n",
      "[Step 6130] Loss: 9.74e+07 0.4117007851600647 0.579767644405365\n",
      "[Step 6131] Loss: 9.68e+07 0.41135987639427185 0.5796017646789551\n",
      "[Step 6132] Loss: 9.69e+07 0.41107895970344543 0.5794829726219177\n",
      "[Step 6133] Loss: 9.76e+07 0.4109472632408142 0.5794227123260498\n",
      "[Step 6134] Loss: 9.68e+07 0.41081732511520386 0.5793773531913757\n",
      "[Step 6135] Loss: 9.70e+07 0.4107307195663452 0.5793476700782776\n",
      "[Step 6136] Loss: 9.66e+07 0.41061311960220337 0.5792791843414307\n",
      "[Step 6137] Loss: 9.77e+07 0.4105246067047119 0.5792626738548279\n",
      "[Step 6138] Loss: 9.68e+07 0.4103911817073822 0.5791999697685242\n",
      "[Step 6139] Loss: 9.66e+07 0.4102950394153595 0.5791594982147217\n",
      "[Step 6140] Loss: 9.67e+07 0.41017916798591614 0.5791009068489075\n",
      "[Step 6141] Loss: 9.88e+07 0.4098866283893585 0.5790250301361084\n",
      "[Step 6142] Loss: 9.78e+07 0.40962520241737366 0.5789458155632019\n",
      "[Step 6143] Loss: 9.71e+07 0.4094749987125397 0.5788806080818176\n",
      "[Step 6144] Loss: 9.73e+07 0.4093570113182068 0.5788426399230957\n",
      "[Step 6145] Loss: 9.67e+07 0.40923359990119934 0.5787634253501892\n",
      "[Step 6146] Loss: 9.68e+07 0.4091779291629791 0.578704833984375\n",
      "[Step 6147] Loss: 9.75e+07 0.40911006927490234 0.5786685347557068\n",
      "[Step 6148] Loss: 9.70e+07 0.4090626537799835 0.578643798828125\n",
      "[Step 6149] Loss: 9.75e+07 0.4089682102203369 0.5785918235778809\n",
      "[Step 6150] Loss: 9.69e+07 0.4088926911354065 0.5785951018333435\n",
      "[Step 6151] Loss: 9.79e+07 0.4088808000087738 0.5785959362983704\n",
      "[Step 6152] Loss: 9.92e+07 0.4086357355117798 0.5784960985183716\n",
      "[Step 6153] Loss: 9.71e+07 0.40844500064849854 0.5783945918083191\n",
      "[Step 6154] Loss: 9.78e+07 0.4082662761211395 0.5783516764640808\n",
      "[Step 6155] Loss: 9.75e+07 0.4081496596336365 0.5783022046089172\n",
      "[Step 6156] Loss: 9.76e+07 0.4080941379070282 0.578236997127533\n",
      "[Step 6157] Loss: 9.72e+07 0.4080352187156677 0.5781974196434021\n",
      "[Step 6158] Loss: 9.70e+07 0.40800827741622925 0.5781800746917725\n",
      "[Step 6159] Loss: 9.73e+07 0.40792080760002136 0.578115701675415\n",
      "[Step 6160] Loss: 9.71e+07 0.40780404210090637 0.5780364871025085\n",
      "[Step 6161] Loss: 9.76e+07 0.4077238440513611 0.5780084729194641\n",
      "[Step 6162] Loss: 9.67e+07 0.4076491594314575 0.5779655575752258\n",
      "[Step 6163] Loss: 9.70e+07 0.4075916111469269 0.5778830051422119\n",
      "[Step 6164] Loss: 9.74e+07 0.4075194299221039 0.5778409242630005\n",
      "[Step 6165] Loss: 9.70e+07 0.40752196311950684 0.5778343677520752\n",
      "[Step 6166] Loss: 9.79e+07 0.40740036964416504 0.5777947306632996\n",
      "[Step 6167] Loss: 9.71e+07 0.4072507321834564 0.5777493715286255\n",
      "[Step 6168] Loss: 9.82e+07 0.4070899784564972 0.5776775479316711\n",
      "[Step 6169] Loss: 9.66e+07 0.40694722533226013 0.5776289105415344\n",
      "[Step 6170] Loss: 9.84e+07 0.40687695145606995 0.5776115655899048\n",
      "[Step 6171] Loss: 9.72e+07 0.4068489372730255 0.5775802135467529\n",
      "[Step 6172] Loss: 9.69e+07 0.40682706236839294 0.5775290131568909\n",
      "[Step 6173] Loss: 9.71e+07 0.40672677755355835 0.5774861574172974\n",
      "[Step 6174] Loss: 9.73e+07 0.4065956175327301 0.577436625957489\n",
      "[Step 6175] Loss: 9.70e+07 0.40654468536376953 0.5773962140083313\n",
      "[Step 6176] Loss: 9.69e+07 0.40639206767082214 0.5773359537124634\n",
      "[Step 6177] Loss: 9.77e+07 0.40627625584602356 0.5772657990455627\n",
      "[Step 6178] Loss: 9.75e+07 0.4060899317264557 0.5771998167037964\n",
      "[Step 6179] Loss: 9.67e+07 0.40591609477996826 0.5771552324295044\n",
      "[Step 6180] Loss: 9.76e+07 0.40580669045448303 0.577113151550293\n",
      "[Step 6181] Loss: 9.71e+07 0.40579310059547424 0.5770983099937439\n",
      "[Step 6182] Loss: 9.73e+07 0.4059177041053772 0.5771230459213257\n",
      "[Step 6183] Loss: 9.78e+07 0.40613019466400146 0.5771362781524658\n",
      "[Step 6184] Loss: 9.62e+07 0.4062860310077667 0.5771362781524658\n",
      "[Step 6185] Loss: 9.68e+07 0.40637317299842834 0.5771387219429016\n",
      "[Step 6186] Loss: 9.73e+07 0.40647995471954346 0.5771585702896118\n",
      "[Step 6187] Loss: 9.69e+07 0.4065864384174347 0.5771626830101013\n",
      "[Step 6188] Loss: 9.67e+07 0.4066353440284729 0.577164351940155\n",
      "[Step 6189] Loss: 9.65e+07 0.40665218234062195 0.5771445035934448\n",
      "[Step 6190] Loss: 9.75e+07 0.4067518711090088 0.5771709084510803\n",
      "[Step 6191] Loss: 9.73e+07 0.40681788325309753 0.5771453380584717\n",
      "[Step 6192] Loss: 9.83e+07 0.40689289569854736 0.5771519541740417\n",
      "[Step 6193] Loss: 9.70e+07 0.4070111811161041 0.5771824717521667\n",
      "[Step 6194] Loss: 9.69e+07 0.4071079194545746 0.5772006511688232\n",
      "[Step 6195] Loss: 9.70e+07 0.40713295340538025 0.577180027961731\n",
      "[Step 6196] Loss: 9.70e+07 0.4071201980113983 0.5771362781524658\n",
      "[Step 6197] Loss: 9.70e+07 0.4070684015750885 0.5770735740661621\n",
      "[Step 6198] Loss: 9.61e+07 0.4070168137550354 0.5770471692085266\n",
      "[Step 6199] Loss: 9.71e+07 0.40691691637039185 0.5769885778427124\n",
      "[Step 6200] Loss: 9.87e+07 0.40665602684020996 0.5769110321998596\n",
      "[Step 6201] Loss: 9.77e+07 0.40643009543418884 0.5768276453018188\n",
      "[Step 6202] Loss: 9.61e+07 0.40623414516448975 0.5767187476158142\n",
      "[Step 6203] Loss: 9.70e+07 0.4060412645339966 0.5766775012016296\n",
      "[Step 6204] Loss: 9.76e+07 0.40587595105171204 0.5766147971153259\n",
      "[Step 6205] Loss: 9.67e+07 0.4056096374988556 0.5765330791473389\n",
      "[Step 6206] Loss: 9.70e+07 0.4053557515144348 0.5764431357383728\n",
      "[Step 6207] Loss: 9.65e+07 0.405169278383255 0.576396107673645\n",
      "[Step 6208] Loss: 9.74e+07 0.40498214960098267 0.5763144493103027\n",
      "[Step 6209] Loss: 9.77e+07 0.40473315119743347 0.5762467980384827\n",
      "[Step 6210] Loss: 9.74e+07 0.40450215339660645 0.5761733651161194\n",
      "[Step 6211] Loss: 9.77e+07 0.404155969619751 0.5760619640350342\n",
      "[Step 6212] Loss: 9.74e+07 0.40381354093551636 0.5759488940238953\n",
      "[Step 6213] Loss: 9.77e+07 0.40347832441329956 0.5758581161499023\n",
      "[Step 6214] Loss: 9.70e+07 0.40309637784957886 0.5757426023483276\n",
      "[Step 6215] Loss: 9.71e+07 0.40281325578689575 0.5756757855415344\n",
      "[Step 6216] Loss: 9.73e+07 0.40245574712753296 0.5755569338798523\n",
      "[Step 6217] Loss: 9.76e+07 0.4021976888179779 0.5754785537719727\n",
      "[Step 6218] Loss: 9.73e+07 0.4020482301712036 0.5754381418228149\n",
      "[Step 6219] Loss: 9.68e+07 0.40183109045028687 0.5753440856933594\n",
      "[Step 6220] Loss: 9.67e+07 0.40164056420326233 0.5752846598625183\n",
      "[Step 6221] Loss: 9.66e+07 0.40153124928474426 0.5752326846122742\n",
      "[Step 6222] Loss: 9.79e+07 0.4014759361743927 0.575226902961731\n",
      "[Step 6223] Loss: 9.73e+07 0.4013589024543762 0.57517409324646\n",
      "[Step 6224] Loss: 9.63e+07 0.4011838734149933 0.5751253962516785\n",
      "[Step 6225] Loss: 9.63e+07 0.40104982256889343 0.5750899314880371\n",
      "[Step 6226] Loss: 9.68e+07 0.4009225070476532 0.5750454068183899\n",
      "[Step 6227] Loss: 9.67e+07 0.4008011817932129 0.5750066041946411\n",
      "[Step 6228] Loss: 9.70e+07 0.4007790684700012 0.5749727487564087\n",
      "[Step 6229] Loss: 9.72e+07 0.40074560046195984 0.5749340057373047\n",
      "[Step 6230] Loss: 9.70e+07 0.4006246328353882 0.5748828053474426\n",
      "[Step 6231] Loss: 9.64e+07 0.40052101016044617 0.5748580694198608\n",
      "[Step 6232] Loss: 9.67e+07 0.400474488735199 0.5748134851455688\n",
      "[Step 6233] Loss: 9.72e+07 0.4004558324813843 0.5748143196105957\n",
      "[Step 6234] Loss: 9.70e+07 0.4004307687282562 0.5747829675674438\n",
      "[Step 6235] Loss: 9.73e+07 0.4004291594028473 0.5747573971748352\n",
      "[Step 6236] Loss: 9.71e+07 0.4003448486328125 0.5746897459030151\n",
      "[Step 6237] Loss: 9.73e+07 0.40024247765541077 0.5746352672576904\n",
      "[Step 6238] Loss: 9.71e+07 0.40017378330230713 0.5745742321014404\n",
      "[Step 6239] Loss: 9.69e+07 0.40008169412612915 0.5745379328727722\n",
      "[Step 6240] Loss: 9.76e+07 0.39985576272010803 0.574448823928833\n",
      "[Step 6241] Loss: 9.92e+07 0.3997272551059723 0.5743910670280457\n",
      "[Step 6242] Loss: 9.80e+07 0.3995671570301056 0.5743563771247864\n",
      "[Step 6243] Loss: 9.65e+07 0.39939218759536743 0.5743110179901123\n",
      "[Step 6244] Loss: 9.70e+07 0.3992781937122345 0.5742590427398682\n",
      "[Step 6245] Loss: 9.72e+07 0.3991405665874481 0.5741987824440002\n",
      "[Step 6246] Loss: 9.66e+07 0.3990102708339691 0.5741443037986755\n",
      "[Step 6247] Loss: 9.74e+07 0.3988044261932373 0.5740717053413391\n",
      "[Step 6248] Loss: 9.71e+07 0.3985469937324524 0.5739636421203613\n",
      "[Step 6249] Loss: 9.65e+07 0.3982468247413635 0.573867917060852\n",
      "[Step 6250] Loss: 9.74e+07 0.3979278802871704 0.5737680792808533\n",
      "[Step 6251] Loss: 9.79e+07 0.3977751135826111 0.5737161040306091\n",
      "[Step 6252] Loss: 9.66e+07 0.3976794183254242 0.573650062084198\n",
      "[Step 6253] Loss: 9.71e+07 0.3976888358592987 0.5736517310142517\n",
      "[Step 6254] Loss: 9.74e+07 0.39768487215042114 0.5736170411109924\n",
      "[Step 6255] Loss: 9.63e+07 0.39771994948387146 0.5736261606216431\n",
      "[Step 6256] Loss: 9.70e+07 0.39768701791763306 0.5736187100410461\n",
      "[Step 6257] Loss: 9.79e+07 0.3975825607776642 0.5735626220703125\n",
      "[Step 6258] Loss: 9.72e+07 0.39756879210472107 0.5735394954681396\n",
      "[Step 6259] Loss: 9.67e+07 0.39748749136924744 0.5734957456588745\n",
      "[Step 6260] Loss: 9.68e+07 0.3974136412143707 0.5734685659408569\n",
      "[Step 6261] Loss: 9.66e+07 0.39731407165527344 0.5734256505966187\n",
      "[Step 6262] Loss: 9.67e+07 0.3971913456916809 0.5733662247657776\n",
      "[Step 6263] Loss: 9.72e+07 0.39704248309135437 0.5733059644699097\n",
      "[Step 6264] Loss: 9.70e+07 0.39694368839263916 0.5733035206794739\n",
      "[Step 6265] Loss: 9.74e+07 0.39686593413352966 0.5732680559158325\n",
      "[Step 6266] Loss: 9.66e+07 0.39684584736824036 0.5732449293136597\n",
      "[Step 6267] Loss: 9.71e+07 0.3968789577484131 0.5732457637786865\n",
      "[Step 6268] Loss: 9.75e+07 0.3969394266605377 0.5732358694076538\n",
      "[Step 6269] Loss: 9.67e+07 0.39695340394973755 0.5732210278511047\n",
      "[Step 6270] Loss: 9.66e+07 0.396931529045105 0.5732036828994751\n",
      "[Step 6271] Loss: 9.79e+07 0.3968125283718109 0.5731574892997742\n",
      "[Step 6272] Loss: 9.71e+07 0.3967228829860687 0.5731277465820312\n",
      "[Step 6273] Loss: 9.77e+07 0.3965558409690857 0.573060929775238\n",
      "[Step 6274] Loss: 9.65e+07 0.39641597867012024 0.5730518698692322\n",
      "[Step 6275] Loss: 9.66e+07 0.3962804973125458 0.5730221271514893\n",
      "[Step 6276] Loss: 9.75e+07 0.3961213231086731 0.572955310344696\n",
      "[Step 6277] Loss: 9.71e+07 0.3959368169307709 0.5728884935379028\n",
      "[Step 6278] Loss: 9.72e+07 0.3957795798778534 0.5728183388710022\n",
      "[Step 6279] Loss: 9.79e+07 0.39560651779174805 0.5727762579917908\n",
      "[Step 6280] Loss: 9.73e+07 0.39538076519966125 0.5726788640022278\n",
      "[Step 6281] Loss: 9.74e+07 0.3952433466911316 0.5726285576820374\n",
      "[Step 6282] Loss: 9.78e+07 0.3952326774597168 0.5726145505905151\n",
      "[Step 6283] Loss: 9.73e+07 0.39529934525489807 0.5726293921470642\n",
      "[Step 6284] Loss: 9.73e+07 0.3953716456890106 0.5726045966148376\n",
      "[Step 6285] Loss: 9.73e+07 0.39556339383125305 0.5726351737976074\n",
      "[Step 6286] Loss: 9.70e+07 0.39576759934425354 0.5726401209831238\n",
      "[Step 6287] Loss: 9.79e+07 0.39609435200691223 0.5727011561393738\n",
      "[Step 6288] Loss: 9.72e+07 0.3963637351989746 0.5727787017822266\n",
      "[Step 6289] Loss: 9.70e+07 0.3966974914073944 0.5728538036346436\n",
      "[Step 6290] Loss: 9.70e+07 0.3969500958919525 0.5728752613067627\n",
      "[Step 6291] Loss: 9.62e+07 0.3971572518348694 0.5729454159736633\n",
      "[Step 6292] Loss: 9.91e+07 0.3971286118030548 0.572910726070404\n",
      "[Step 6293] Loss: 9.67e+07 0.3970739543437958 0.5728818774223328\n",
      "[Step 6294] Loss: 9.66e+07 0.39703407883644104 0.5728538036346436\n",
      "[Step 6295] Loss: 9.67e+07 0.3971176743507385 0.5728628635406494\n",
      "[Step 6296] Loss: 9.67e+07 0.39718034863471985 0.5728521347045898\n",
      "[Step 6297] Loss: 9.71e+07 0.3972156345844269 0.5728183388710022\n",
      "[Step 6298] Loss: 9.71e+07 0.39725637435913086 0.5728150606155396\n",
      "[Step 6299] Loss: 9.70e+07 0.3972979187965393 0.5727993249893188\n",
      "[Step 6300] Loss: 9.62e+07 0.3972585201263428 0.5727449059486389\n",
      "[Step 6301] Loss: 9.63e+07 0.3972083628177643 0.5727209448814392\n",
      "[Step 6302] Loss: 9.74e+07 0.3972311317920685 0.5726929306983948\n",
      "[Step 6303] Loss: 9.68e+07 0.3972066640853882 0.5726772546768188\n",
      "[Step 6304] Loss: 9.73e+07 0.39724263548851013 0.5726822018623352\n",
      "[Step 6305] Loss: 9.68e+07 0.39723578095436096 0.572676420211792\n",
      "[Step 6306] Loss: 9.71e+07 0.39727723598480225 0.5726524591445923\n",
      "[Step 6307] Loss: 9.64e+07 0.3972950875759125 0.5726656913757324\n",
      "[Step 6308] Loss: 9.60e+07 0.3972787857055664 0.5726532936096191\n",
      "[Step 6309] Loss: 9.66e+07 0.397228479385376 0.5726351737976074\n",
      "[Step 6310] Loss: 9.77e+07 0.3971131443977356 0.572593092918396\n",
      "[Step 6311] Loss: 9.71e+07 0.3970528244972229 0.5725691318511963\n",
      "[Step 6312] Loss: 9.73e+07 0.3968793749809265 0.5725122094154358\n",
      "[Step 6313] Loss: 9.71e+07 0.39678487181663513 0.5725047588348389\n",
      "[Step 6314] Loss: 9.76e+07 0.396839439868927 0.5725154876708984\n",
      "[Step 6315] Loss: 9.81e+07 0.39693111181259155 0.5725080966949463\n",
      "[Step 6316] Loss: 9.82e+07 0.3968327045440674 0.5724998116493225\n",
      "[Step 6317] Loss: 9.70e+07 0.3966580331325531 0.5724602341651917\n",
      "[Step 6318] Loss: 9.62e+07 0.3964610993862152 0.5723999738693237\n",
      "[Step 6319] Loss: 9.67e+07 0.3962467610836029 0.5723215937614441\n",
      "[Step 6320] Loss: 9.71e+07 0.3960482180118561 0.5722877979278564\n",
      "[Step 6321] Loss: 9.76e+07 0.3957597613334656 0.5722225904464722\n",
      "[Step 6322] Loss: 9.78e+07 0.3955986201763153 0.5721442103385925\n",
      "[Step 6323] Loss: 9.75e+07 0.3954738676548004 0.5721054077148438\n",
      "[Step 6324] Loss: 9.72e+07 0.39531224966049194 0.5720410346984863\n",
      "[Step 6325] Loss: 9.78e+07 0.3952380418777466 0.5720146298408508\n",
      "[Step 6326] Loss: 9.68e+07 0.39513227343559265 0.5719890594482422\n",
      "[Step 6327] Loss: 9.66e+07 0.3950413167476654 0.5719634890556335\n",
      "[Step 6328] Loss: 9.59e+07 0.3949761390686035 0.5719494819641113\n",
      "[Step 6329] Loss: 9.61e+07 0.3948737382888794 0.5719016194343567\n",
      "[Step 6330] Loss: 9.74e+07 0.39484184980392456 0.5718834400177002\n",
      "[Step 6331] Loss: 9.68e+07 0.3948154151439667 0.5718331336975098\n",
      "[Step 6332] Loss: 9.68e+07 0.3947557806968689 0.5718125104904175\n",
      "[Step 6333] Loss: 9.65e+07 0.39472317695617676 0.5717431902885437\n",
      "[Step 6334] Loss: 9.64e+07 0.39469411969184875 0.5717200636863708\n",
      "[Step 6335] Loss: 9.58e+07 0.3947649598121643 0.5717077255249023\n",
      "[Step 6336] Loss: 9.69e+07 0.39483150839805603 0.5717035531997681\n",
      "[Step 6337] Loss: 9.75e+07 0.3947599530220032 0.5716936588287354\n",
      "[Step 6338] Loss: 9.59e+07 0.3947434723377228 0.5716813206672668\n",
      "[Step 6339] Loss: 9.67e+07 0.3946928083896637 0.5716524124145508\n",
      "[Step 6340] Loss: 9.87e+07 0.3944757580757141 0.5715707540512085\n",
      "[Step 6341] Loss: 9.66e+07 0.3942420482635498 0.5715154409408569\n",
      "[Step 6342] Loss: 9.71e+07 0.3939884305000305 0.5714032053947449\n",
      "[Step 6343] Loss: 9.74e+07 0.39392492175102234 0.5713933110237122\n",
      "[Step 6344] Loss: 9.68e+07 0.3938612639904022 0.5713883638381958\n",
      "[Step 6345] Loss: 9.72e+07 0.3938314914703369 0.571363627910614\n",
      "[Step 6346] Loss: 9.68e+07 0.39380156993865967 0.5713776350021362\n",
      "[Step 6347] Loss: 9.62e+07 0.39384979009628296 0.5713966488838196\n",
      "[Step 6348] Loss: 9.74e+07 0.39397576451301575 0.5714321136474609\n",
      "[Step 6349] Loss: 9.61e+07 0.3940894901752472 0.5714428424835205\n",
      "[Step 6350] Loss: 9.70e+07 0.39414745569229126 0.5714461207389832\n",
      "[Step 6351] Loss: 9.72e+07 0.3941923677921295 0.5714675784111023\n",
      "[Step 6352] Loss: 9.67e+07 0.39425575733184814 0.5714585185050964\n",
      "[Step 6353] Loss: 9.66e+07 0.3943345844745636 0.5714634656906128\n",
      "[Step 6354] Loss: 9.66e+07 0.39445817470550537 0.5714576840400696\n",
      "[Step 6355] Loss: 9.77e+07 0.39455482363700867 0.5714783072471619\n",
      "[Step 6356] Loss: 9.75e+07 0.39467954635620117 0.5714857578277588\n",
      "[Step 6357] Loss: 9.64e+07 0.3948337435722351 0.5714890360832214\n",
      "[Step 6358] Loss: 9.71e+07 0.39503607153892517 0.5715294480323792\n",
      "[Step 6359] Loss: 9.71e+07 0.39522725343704224 0.571544349193573\n",
      "[Step 6360] Loss: 9.62e+07 0.3953630030155182 0.5715888738632202\n",
      "[Step 6361] Loss: 9.59e+07 0.39550474286079407 0.5716441869735718\n",
      "[Step 6362] Loss: 9.69e+07 0.39562201499938965 0.5716573596000671\n",
      "[Step 6363] Loss: 9.62e+07 0.39578691124916077 0.5717043876647949\n",
      "[Step 6364] Loss: 9.67e+07 0.3959501087665558 0.57174152135849\n",
      "[Step 6365] Loss: 9.73e+07 0.39618217945098877 0.5717960000038147\n",
      "[Step 6366] Loss: 9.74e+07 0.3964083790779114 0.571838915348053\n",
      "[Step 6367] Loss: 9.79e+07 0.3966046869754791 0.5718669295310974\n",
      "[Step 6368] Loss: 9.72e+07 0.3969210088253021 0.571922242641449\n",
      "[Step 6369] Loss: 9.69e+07 0.39721402525901794 0.57198166847229\n",
      "[Step 6370] Loss: 9.72e+07 0.3974003493785858 0.5720179677009583\n",
      "[Step 6371] Loss: 9.69e+07 0.39764541387557983 0.5720757246017456\n",
      "[Step 6372] Loss: 9.70e+07 0.39778217673301697 0.57210373878479\n",
      "[Step 6373] Loss: 9.74e+07 0.3979171812534332 0.572119414806366\n",
      "[Step 6374] Loss: 9.78e+07 0.3980865478515625 0.572170615196228\n",
      "[Step 6375] Loss: 9.65e+07 0.3981725871562958 0.5721837878227234\n",
      "[Step 6376] Loss: 9.64e+07 0.39820876717567444 0.5721541047096252\n",
      "[Step 6377] Loss: 9.70e+07 0.3982127606868744 0.5721508264541626\n",
      "[Step 6378] Loss: 9.70e+07 0.3982596695423126 0.572133481502533\n",
      "[Step 6379] Loss: 9.81e+07 0.3981797695159912 0.5721004605293274\n",
      "[Step 6380] Loss: 9.66e+07 0.39813342690467834 0.5720567107200623\n",
      "[Step 6381] Loss: 9.73e+07 0.39815154671669006 0.5720352530479431\n",
      "[Step 6382] Loss: 9.70e+07 0.3982183635234833 0.5720253586769104\n",
      "[Step 6383] Loss: 9.72e+07 0.3982934057712555 0.5720377564430237\n",
      "[Step 6384] Loss: 9.71e+07 0.3982775807380676 0.5720270276069641\n",
      "[Step 6385] Loss: 9.66e+07 0.3982882499694824 0.5720418691635132\n",
      "[Step 6386] Loss: 9.71e+07 0.398351788520813 0.5720641613006592\n",
      "[Step 6387] Loss: 9.77e+07 0.3984293043613434 0.5720435380935669\n",
      "[Step 6388] Loss: 9.82e+07 0.39855092763900757 0.5720682740211487\n",
      "[Step 6389] Loss: 9.70e+07 0.3986143469810486 0.5720674395561218\n",
      "[Step 6390] Loss: 9.74e+07 0.39862361550331116 0.572066605091095\n",
      "[Step 6391] Loss: 9.68e+07 0.39860737323760986 0.5720402002334595\n",
      "[Step 6392] Loss: 9.78e+07 0.39852941036224365 0.5720229148864746\n",
      "[Step 6393] Loss: 9.70e+07 0.39848825335502625 0.5720171332359314\n",
      "[Step 6394] Loss: 9.69e+07 0.39849933981895447 0.57203608751297\n",
      "[Step 6395] Loss: 9.73e+07 0.39848169684410095 0.5720402002334595\n",
      "[Step 6396] Loss: 9.71e+07 0.3983951807022095 0.5720179677009583\n",
      "[Step 6397] Loss: 9.60e+07 0.3982942998409271 0.5720088481903076\n",
      "[Step 6398] Loss: 9.71e+07 0.3981737196445465 0.5719478130340576\n",
      "[Step 6399] Loss: 9.74e+07 0.3979748487472534 0.5718711018562317\n",
      "[Step 6400] Loss: 9.82e+07 0.3977060616016388 0.5718125104904175\n",
      "[Step 6401] Loss: 9.68e+07 0.3974614143371582 0.5717440247535706\n",
      "[Step 6402] Loss: 9.68e+07 0.3972017765045166 0.5715864300727844\n",
      "[Step 6403] Loss: 9.72e+07 0.3968922793865204 0.5714733600616455\n",
      "[Step 6404] Loss: 9.68e+07 0.39664971828460693 0.5713809728622437\n",
      "[Step 6405] Loss: 9.62e+07 0.3964363634586334 0.5713124871253967\n",
      "[Step 6406] Loss: 9.72e+07 0.39625030755996704 0.571251392364502\n",
      "[Step 6407] Loss: 9.69e+07 0.3960992097854614 0.5711928009986877\n",
      "[Step 6408] Loss: 9.71e+07 0.3960333466529846 0.5711614489555359\n",
      "[Step 6409] Loss: 9.72e+07 0.3960011899471283 0.571137547492981\n",
      "[Step 6410] Loss: 9.64e+07 0.3960039019584656 0.5711333751678467\n",
      "[Step 6411] Loss: 9.72e+07 0.39604029059410095 0.5711176991462708\n",
      "[Step 6412] Loss: 9.69e+07 0.3960355222225189 0.5710715055465698\n",
      "[Step 6413] Loss: 9.66e+07 0.3960340917110443 0.5710607767105103\n",
      "[Step 6414] Loss: 9.68e+07 0.3959943950176239 0.5709956288337708\n",
      "[Step 6415] Loss: 9.65e+07 0.39586368203163147 0.5709271430969238\n",
      "[Step 6416] Loss: 9.69e+07 0.3957039713859558 0.57085120677948\n",
      "[Step 6417] Loss: 9.75e+07 0.3955623209476471 0.5707992315292358\n",
      "[Step 6418] Loss: 9.60e+07 0.3954254686832428 0.5707694888114929\n",
      "[Step 6419] Loss: 9.82e+07 0.3951856195926666 0.5706812143325806\n",
      "[Step 6420] Loss: 9.61e+07 0.39496827125549316 0.5706152319908142\n",
      "[Step 6421] Loss: 9.63e+07 0.39480483531951904 0.5705376267433167\n",
      "[Step 6422] Loss: 9.70e+07 0.3946322798728943 0.5704774260520935\n",
      "[Step 6423] Loss: 9.69e+07 0.39450782537460327 0.5704559683799744\n",
      "[Step 6424] Loss: 9.62e+07 0.3944752812385559 0.5704584121704102\n",
      "[Step 6425] Loss: 9.71e+07 0.3945028781890869 0.5704568028450012\n",
      "[Step 6426] Loss: 9.59e+07 0.3945351839065552 0.5704526901245117\n",
      "[Step 6427] Loss: 9.68e+07 0.39453569054603577 0.5704353451728821\n",
      "[Step 6428] Loss: 9.71e+07 0.3945687413215637 0.5704485177993774\n",
      "[Step 6429] Loss: 9.64e+07 0.3946438729763031 0.5704691410064697\n",
      "[Step 6430] Loss: 9.71e+07 0.3946334421634674 0.5704625844955444\n",
      "[Step 6431] Loss: 9.66e+07 0.3946074843406677 0.5704625844955444\n",
      "[Step 6432] Loss: 9.68e+07 0.39456629753112793 0.5704270601272583\n",
      "[Step 6433] Loss: 9.70e+07 0.3945016860961914 0.5703924298286438\n",
      "[Step 6434] Loss: 9.74e+07 0.394456148147583 0.5704196691513062\n",
      "[Step 6435] Loss: 9.63e+07 0.39432764053344727 0.5703874826431274\n",
      "[Step 6436] Loss: 9.75e+07 0.3941105008125305 0.5703478455543518\n",
      "[Step 6437] Loss: 9.74e+07 0.39395421743392944 0.5703099370002747\n",
      "[Step 6438] Loss: 9.72e+07 0.3937542140483856 0.5702670216560364\n",
      "[Step 6439] Loss: 9.66e+07 0.39357173442840576 0.5701927542686462\n",
      "[Step 6440] Loss: 9.73e+07 0.39337173104286194 0.5701102614402771\n",
      "[Step 6441] Loss: 9.66e+07 0.3932173252105713 0.5700458884239197\n",
      "[Step 6442] Loss: 9.69e+07 0.3930291533470154 0.569999635219574\n",
      "[Step 6443] Loss: 9.63e+07 0.39287900924682617 0.5699707865715027\n",
      "[Step 6444] Loss: 9.67e+07 0.3926500678062439 0.5698915719985962\n",
      "[Step 6445] Loss: 9.74e+07 0.3924703001976013 0.5698239207267761\n",
      "[Step 6446] Loss: 9.71e+07 0.39239898324012756 0.5697743892669678\n",
      "[Step 6447] Loss: 9.73e+07 0.3922445476055145 0.5697281956672668\n",
      "[Step 6448] Loss: 9.64e+07 0.39213818311691284 0.5696844458580017\n",
      "[Step 6449] Loss: 9.77e+07 0.39195165038108826 0.5696184635162354\n",
      "[Step 6450] Loss: 9.64e+07 0.3917686939239502 0.5695722699165344\n",
      "[Step 6451] Loss: 9.74e+07 0.39169132709503174 0.5695309638977051\n",
      "[Step 6452] Loss: 9.72e+07 0.39171892404556274 0.5695549249649048\n",
      "[Step 6453] Loss: 9.73e+07 0.3916315734386444 0.5695194602012634\n",
      "[Step 6454] Loss: 9.64e+07 0.3915311396121979 0.5695103406906128\n",
      "[Step 6455] Loss: 9.73e+07 0.39140018820762634 0.5694798231124878\n",
      "[Step 6456] Loss: 9.62e+07 0.3913359045982361 0.5694484710693359\n",
      "[Step 6457] Loss: 9.76e+07 0.39142367243766785 0.569463312625885\n",
      "[Step 6458] Loss: 9.59e+07 0.39149385690689087 0.5694888830184937\n",
      "[Step 6459] Loss: 9.68e+07 0.3915243446826935 0.5694699287414551\n",
      "[Step 6460] Loss: 9.68e+07 0.39152562618255615 0.5694690942764282\n",
      "[Step 6461] Loss: 9.67e+07 0.3915897011756897 0.5694781541824341\n",
      "[Step 6462] Loss: 9.66e+07 0.3915269672870636 0.5694732069969177\n",
      "[Step 6463] Loss: 9.62e+07 0.3913830816745758 0.5694394111633301\n",
      "[Step 6464] Loss: 9.67e+07 0.3912578821182251 0.5693923830986023\n",
      "[Step 6465] Loss: 9.71e+07 0.39111587405204773 0.5693395733833313\n",
      "[Step 6466] Loss: 9.67e+07 0.39094048738479614 0.5692850947380066\n",
      "[Step 6467] Loss: 9.71e+07 0.39076104760169983 0.5692075490951538\n",
      "[Step 6468] Loss: 9.68e+07 0.39056217670440674 0.5691481232643127\n",
      "[Step 6469] Loss: 9.62e+07 0.39037060737609863 0.5690895318984985\n",
      "[Step 6470] Loss: 9.63e+07 0.3901689648628235 0.569032609462738\n",
      "[Step 6471] Loss: 9.74e+07 0.3900311291217804 0.5689467787742615\n",
      "[Step 6472] Loss: 9.72e+07 0.39001062512397766 0.5688865780830383\n",
      "[Step 6473] Loss: 9.60e+07 0.3900032043457031 0.5688832402229309\n",
      "[Step 6474] Loss: 9.69e+07 0.3900502324104309 0.5688857436180115\n",
      "[Step 6475] Loss: 9.72e+07 0.390162855386734 0.5688807964324951\n",
      "[Step 6476] Loss: 9.65e+07 0.39024224877357483 0.5688791275024414\n",
      "[Step 6477] Loss: 9.72e+07 0.3902421295642853 0.5688642859458923\n",
      "[Step 6478] Loss: 9.76e+07 0.39022305607795715 0.5688436627388\n",
      "[Step 6479] Loss: 9.64e+07 0.39023712277412415 0.5688419938087463\n",
      "[Step 6480] Loss: 9.71e+07 0.39029330015182495 0.568867564201355\n",
      "[Step 6481] Loss: 9.70e+07 0.3904034495353699 0.5688642859458923\n",
      "[Step 6482] Loss: 9.61e+07 0.3905406594276428 0.5688774585723877\n",
      "[Step 6483] Loss: 9.61e+07 0.3906755745410919 0.568920373916626\n",
      "[Step 6484] Loss: 9.87e+07 0.3905993700027466 0.5688948035240173\n",
      "[Step 6485] Loss: 9.70e+07 0.3905322253704071 0.5688477754592896\n",
      "[Step 6486] Loss: 9.72e+07 0.39047807455062866 0.5688254833221436\n",
      "[Step 6487] Loss: 9.78e+07 0.39047327637672424 0.5688056945800781\n",
      "[Step 6488] Loss: 9.72e+07 0.3904055058956146 0.5687966346740723\n",
      "[Step 6489] Loss: 9.71e+07 0.3903012275695801 0.5687767863273621\n",
      "[Step 6490] Loss: 9.68e+07 0.39010903239250183 0.5687347054481506\n",
      "[Step 6491] Loss: 9.77e+07 0.38994091749191284 0.5686720013618469\n",
      "[Step 6492] Loss: 9.75e+07 0.38986918330192566 0.5686439871788025\n",
      "[Step 6493] Loss: 9.66e+07 0.38977330923080444 0.5686076879501343\n",
      "[Step 6494] Loss: 9.67e+07 0.3896681070327759 0.5685853958129883\n",
      "[Step 6495] Loss: 9.68e+07 0.38951337337493896 0.5685762763023376\n",
      "[Step 6496] Loss: 9.64e+07 0.3894079327583313 0.5685853958129883\n",
      "[Step 6497] Loss: 9.75e+07 0.3892688453197479 0.56854248046875\n",
      "[Step 6498] Loss: 9.65e+07 0.38921213150024414 0.5685490965843201\n",
      "[Step 6499] Loss: 9.71e+07 0.3891313970088959 0.5685020685195923\n",
      "[Step 6500] Loss: 9.65e+07 0.3890366852283478 0.5684847235679626\n",
      "[Step 6501] Loss: 9.70e+07 0.3889074921607971 0.5684641003608704\n",
      "[Step 6502] Loss: 9.72e+07 0.38872119784355164 0.5683997273445129\n",
      "[Step 6503] Loss: 9.66e+07 0.3885667026042938 0.5683543682098389\n",
      "[Step 6504] Loss: 9.74e+07 0.38849005103111267 0.5683065056800842\n",
      "[Step 6505] Loss: 9.72e+07 0.388422429561615 0.5682487487792969\n",
      "[Step 6506] Loss: 9.71e+07 0.3883187472820282 0.5682223439216614\n",
      "[Step 6507] Loss: 9.75e+07 0.3882109522819519 0.5681843757629395\n",
      "[Step 6508] Loss: 9.69e+07 0.3880467414855957 0.5680993795394897\n",
      "[Step 6509] Loss: 9.70e+07 0.387984961271286 0.5680416226387024\n",
      "[Step 6510] Loss: 9.80e+07 0.3880477249622345 0.568052351474762\n",
      "[Step 6511] Loss: 9.63e+07 0.38815194368362427 0.5680556297302246\n",
      "[Step 6512] Loss: 9.69e+07 0.38823401927948 0.5680935978889465\n",
      "[Step 6513] Loss: 9.68e+07 0.38830968737602234 0.5680993795394897\n",
      "[Step 6514] Loss: 9.72e+07 0.3883582353591919 0.5681002140045166\n",
      "[Step 6515] Loss: 9.68e+07 0.38838016986846924 0.56807541847229\n",
      "[Step 6516] Loss: 9.67e+07 0.38839811086654663 0.568067193031311\n",
      "[Step 6517] Loss: 9.84e+07 0.3882749676704407 0.5680168867111206\n",
      "[Step 6518] Loss: 9.77e+07 0.3882368206977844 0.5679929256439209\n",
      "[Step 6519] Loss: 9.68e+07 0.38831332325935364 0.5680201649665833\n",
      "[Step 6520] Loss: 9.76e+07 0.3882530927658081 0.56801438331604\n",
      "[Step 6521] Loss: 9.75e+07 0.3881997764110565 0.5679855346679688\n",
      "[Step 6522] Loss: 9.79e+07 0.38804227113723755 0.567902147769928\n",
      "[Step 6523] Loss: 9.69e+07 0.38779354095458984 0.5678278803825378\n",
      "[Step 6524] Loss: 9.77e+07 0.3874182105064392 0.567704975605011\n",
      "[Step 6525] Loss: 9.69e+07 0.3870837092399597 0.5676141977310181\n",
      "[Step 6526] Loss: 9.74e+07 0.3866141736507416 0.5674887895584106\n",
      "[Step 6527] Loss: 9.68e+07 0.3861865699291229 0.5673699378967285\n",
      "[Step 6528] Loss: 9.69e+07 0.3857910931110382 0.5672478079795837\n",
      "[Step 6529] Loss: 9.74e+07 0.3853238523006439 0.5671405792236328\n",
      "[Step 6530] Loss: 9.73e+07 0.38481324911117554 0.5669944882392883\n",
      "[Step 6531] Loss: 9.70e+07 0.384278804063797 0.5668368935585022\n",
      "[Step 6532] Loss: 9.72e+07 0.38379448652267456 0.5666925311088562\n",
      "[Step 6533] Loss: 9.67e+07 0.3833945691585541 0.5665910243988037\n",
      "[Step 6534] Loss: 9.77e+07 0.3829945921897888 0.5664879083633423\n",
      "[Step 6535] Loss: 9.68e+07 0.38257747888565063 0.5663649439811707\n",
      "[Step 6536] Loss: 9.69e+07 0.38214001059532166 0.5662651062011719\n",
      "[Step 6537] Loss: 9.65e+07 0.38169345259666443 0.5661454200744629\n",
      "[Step 6538] Loss: 9.71e+07 0.3812739849090576 0.5660637617111206\n",
      "[Step 6539] Loss: 9.72e+07 0.3809153437614441 0.5659449696540833\n",
      "[Step 6540] Loss: 9.71e+07 0.380539208650589 0.5658318996429443\n",
      "[Step 6541] Loss: 9.74e+07 0.3801492154598236 0.5657593011856079\n",
      "[Step 6542] Loss: 9.78e+07 0.3795996308326721 0.5656214952468872\n",
      "[Step 6543] Loss: 9.68e+07 0.3790518343448639 0.5654540061950684\n",
      "[Step 6544] Loss: 9.67e+07 0.37864017486572266 0.5653351545333862\n",
      "[Step 6545] Loss: 9.72e+07 0.37831956148147583 0.5652385950088501\n",
      "[Step 6546] Loss: 9.75e+07 0.3780992925167084 0.565132200717926\n",
      "[Step 6547] Loss: 9.66e+07 0.3778844177722931 0.565079391002655\n",
      "[Step 6548] Loss: 9.63e+07 0.37770241498947144 0.5649918913841248\n",
      "[Step 6549] Loss: 9.73e+07 0.3775066137313843 0.5649407505989075\n",
      "[Step 6550] Loss: 9.73e+07 0.37722811102867126 0.5648441910743713\n",
      "[Step 6551] Loss: 9.64e+07 0.3769862651824951 0.5647872686386108\n",
      "[Step 6552] Loss: 9.68e+07 0.376653254032135 0.5646643042564392\n",
      "[Step 6553] Loss: 9.68e+07 0.3763410747051239 0.5645603537559509\n",
      "[Step 6554] Loss: 9.81e+07 0.37589195370674133 0.5644415616989136\n",
      "[Step 6555] Loss: 9.82e+07 0.37554314732551575 0.5643441677093506\n",
      "[Step 6556] Loss: 9.77e+07 0.37510567903518677 0.5642146468162537\n",
      "[Step 6557] Loss: 9.70e+07 0.37472379207611084 0.5640875697135925\n",
      "[Step 6558] Loss: 9.70e+07 0.3743748068809509 0.56397944688797\n",
      "[Step 6559] Loss: 9.77e+07 0.37412771582603455 0.5638969540596008\n",
      "[Step 6560] Loss: 9.74e+07 0.3738364577293396 0.563797116279602\n",
      "[Step 6561] Loss: 9.78e+07 0.37369823455810547 0.5637500882148743\n",
      "[Step 6562] Loss: 9.73e+07 0.3735012412071228 0.5636444687843323\n",
      "[Step 6563] Loss: 9.75e+07 0.37323427200317383 0.5635702013969421\n",
      "[Step 6564] Loss: 9.66e+07 0.37307223677635193 0.5635025501251221\n",
      "[Step 6565] Loss: 9.69e+07 0.3729556202888489 0.5634530186653137\n",
      "[Step 6566] Loss: 9.68e+07 0.37296274304389954 0.5634225010871887\n",
      "[Step 6567] Loss: 9.70e+07 0.3729017376899719 0.5633647441864014\n",
      "[Step 6568] Loss: 9.74e+07 0.37285906076431274 0.5633333921432495\n",
      "[Step 6569] Loss: 9.64e+07 0.37278369069099426 0.5632739663124084\n",
      "[Step 6570] Loss: 9.68e+07 0.37277719378471375 0.5632277727127075\n",
      "[Step 6571] Loss: 9.77e+07 0.372804194688797 0.5632458925247192\n",
      "[Step 6572] Loss: 9.67e+07 0.372907429933548 0.5632715225219727\n",
      "[Step 6573] Loss: 9.70e+07 0.37294530868530273 0.5632706880569458\n",
      "[Step 6574] Loss: 9.63e+07 0.3729783892631531 0.563262403011322\n",
      "[Step 6575] Loss: 9.63e+07 0.3730081617832184 0.5632722973823547\n",
      "[Step 6576] Loss: 9.70e+07 0.37312301993370056 0.5632945895195007\n",
      "[Step 6577] Loss: 9.70e+07 0.3731920123100281 0.5632871985435486\n",
      "[Step 6578] Loss: 9.62e+07 0.3732748329639435 0.5633127689361572\n",
      "[Step 6579] Loss: 9.64e+07 0.37324127554893494 0.5632748007774353\n",
      "[Step 6580] Loss: 9.70e+07 0.37324512004852295 0.5632797479629517\n",
      "[Step 6581] Loss: 9.70e+07 0.37329551577568054 0.563284695148468\n",
      "[Step 6582] Loss: 9.67e+07 0.37334975600242615 0.5633094310760498\n",
      "[Step 6583] Loss: 9.69e+07 0.3734806180000305 0.5633507370948792\n",
      "[Step 6584] Loss: 9.65e+07 0.3736230134963989 0.5633993744850159\n",
      "[Step 6585] Loss: 9.67e+07 0.3738005459308624 0.5634662508964539\n",
      "[Step 6586] Loss: 9.66e+07 0.3740215003490448 0.5635173916816711\n",
      "[Step 6587] Loss: 9.73e+07 0.37411075830459595 0.5635240077972412\n",
      "[Step 6588] Loss: 9.65e+07 0.37416669726371765 0.5635536909103394\n",
      "[Step 6589] Loss: 9.71e+07 0.37428316473960876 0.5635891556739807\n",
      "[Step 6590] Loss: 9.62e+07 0.37444835901260376 0.5636205077171326\n",
      "[Step 6591] Loss: 9.75e+07 0.3747576177120209 0.5637080073356628\n",
      "[Step 6592] Loss: 9.71e+07 0.374984472990036 0.5637525320053101\n",
      "[Step 6593] Loss: 9.72e+07 0.37526485323905945 0.563819408416748\n",
      "[Step 6594] Loss: 9.71e+07 0.37549054622650146 0.5638771653175354\n",
      "[Step 6595] Loss: 9.76e+07 0.37577834725379944 0.5639579892158508\n",
      "[Step 6596] Loss: 9.75e+07 0.37595024704933167 0.5640157461166382\n",
      "[Step 6597] Loss: 9.74e+07 0.3760324716567993 0.5640124678611755\n",
      "[Step 6598] Loss: 9.70e+07 0.37606385350227356 0.5640479326248169\n",
      "[Step 6599] Loss: 9.67e+07 0.37611839175224304 0.5640364289283752\n",
      "[Step 6600] Loss: 9.66e+07 0.3761516809463501 0.564046323299408\n",
      "[Step 6601] Loss: 9.67e+07 0.37620699405670166 0.5640429854393005\n",
      "[Step 6602] Loss: 9.71e+07 0.3762649595737457 0.5640512704849243\n",
      "[Step 6603] Loss: 9.77e+07 0.37634730339050293 0.5640330910682678\n",
      "[Step 6604] Loss: 9.60e+07 0.3763945698738098 0.5640257000923157\n",
      "[Step 6605] Loss: 9.64e+07 0.3764886260032654 0.5640504360198975\n",
      "[Step 6606] Loss: 9.66e+07 0.3765803277492523 0.5640521049499512\n",
      "[Step 6607] Loss: 9.62e+07 0.37661656737327576 0.5640504360198975\n",
      "[Step 6608] Loss: 9.71e+07 0.3766743540763855 0.5640669465065002\n",
      "[Step 6609] Loss: 9.73e+07 0.37668344378471375 0.564030647277832\n",
      "[Step 6610] Loss: 9.67e+07 0.37667885422706604 0.5639910101890564\n",
      "[Step 6611] Loss: 9.74e+07 0.37674763798713684 0.5639910101890564\n",
      "[Step 6612] Loss: 9.69e+07 0.37678617238998413 0.5639811158180237\n",
      "[Step 6613] Loss: 9.69e+07 0.3768915832042694 0.563971221446991\n",
      "[Step 6614] Loss: 9.71e+07 0.3769742250442505 0.5639547109603882\n",
      "[Step 6615] Loss: 9.66e+07 0.3771221339702606 0.56397944688797\n",
      "[Step 6616] Loss: 9.67e+07 0.37730151414871216 0.5640133023262024\n",
      "[Step 6617] Loss: 9.60e+07 0.37749403715133667 0.5640421509742737\n",
      "[Step 6618] Loss: 9.69e+07 0.37768685817718506 0.5640628337860107\n",
      "[Step 6619] Loss: 9.70e+07 0.37786585092544556 0.5641032457351685\n",
      "[Step 6620] Loss: 9.64e+07 0.37808725237846375 0.5641543865203857\n",
      "[Step 6621] Loss: 9.67e+07 0.37832194566726685 0.5642088651657104\n",
      "[Step 6622] Loss: 9.70e+07 0.3785451650619507 0.5642492771148682\n",
      "[Step 6623] Loss: 9.70e+07 0.37875664234161377 0.5642748475074768\n",
      "[Step 6624] Loss: 9.74e+07 0.3789180517196655 0.5642781853675842\n",
      "[Step 6625] Loss: 9.72e+07 0.37900158762931824 0.5642938613891602\n",
      "[Step 6626] Loss: 9.70e+07 0.3790753185749054 0.5643128156661987\n",
      "[Step 6627] Loss: 9.66e+07 0.37922295928001404 0.5643598437309265\n",
      "[Step 6628] Loss: 9.65e+07 0.3792977035045624 0.5643887519836426\n",
      "[Step 6629] Loss: 9.64e+07 0.3793785274028778 0.5644522905349731\n",
      "[Step 6630] Loss: 9.71e+07 0.37938785552978516 0.5644398927688599\n",
      "[Step 6631] Loss: 9.79e+07 0.3792558014392853 0.5643936991691589\n",
      "[Step 6632] Loss: 9.78e+07 0.3792409896850586 0.5643581748008728\n",
      "[Step 6633] Loss: 9.71e+07 0.3791104555130005 0.5643144845962524\n",
      "[Step 6634] Loss: 9.67e+07 0.37907853722572327 0.5643045902252197\n",
      "[Step 6635] Loss: 9.57e+07 0.37912967801094055 0.564311146736145\n",
      "[Step 6636] Loss: 9.65e+07 0.37913569808006287 0.5643136501312256\n",
      "[Step 6637] Loss: 9.94e+07 0.3789019286632538 0.5642509460449219\n",
      "[Step 6638] Loss: 9.66e+07 0.37873464822769165 0.5641832947731018\n",
      "[Step 6639] Loss: 9.67e+07 0.3784647285938263 0.5641049146652222\n",
      "[Step 6640] Loss: 9.74e+07 0.3781887888908386 0.5640231966972351\n",
      "[Step 6641] Loss: 9.74e+07 0.37792593240737915 0.563955545425415\n",
      "[Step 6642] Loss: 9.73e+07 0.37762629985809326 0.5638862252235413\n",
      "[Step 6643] Loss: 9.74e+07 0.3772849440574646 0.563790500164032\n",
      "[Step 6644] Loss: 9.66e+07 0.37703582644462585 0.5637096166610718\n",
      "[Step 6645] Loss: 9.83e+07 0.3766876459121704 0.5636056661605835\n",
      "[Step 6646] Loss: 9.70e+07 0.3763817250728607 0.5634901523590088\n",
      "[Step 6647] Loss: 9.64e+07 0.3760074973106384 0.5633870363235474\n",
      "[Step 6648] Loss: 9.71e+07 0.3757232427597046 0.5632591247558594\n",
      "[Step 6649] Loss: 9.71e+07 0.37536588311195374 0.5631221532821655\n",
      "[Step 6650] Loss: 9.71e+07 0.37500569224357605 0.5629826784133911\n",
      "[Step 6651] Loss: 9.71e+07 0.3746827244758606 0.5628787279129028\n",
      "[Step 6652] Loss: 9.75e+07 0.37429872155189514 0.5627846717834473\n",
      "[Step 6653] Loss: 9.77e+07 0.37406888604164124 0.5627236366271973\n",
      "[Step 6654] Loss: 9.65e+07 0.3738933801651001 0.5626823306083679\n",
      "[Step 6655] Loss: 9.73e+07 0.37374669313430786 0.562658429145813\n",
      "[Step 6656] Loss: 9.68e+07 0.37362584471702576 0.5626328587532043\n",
      "[Step 6657] Loss: 9.67e+07 0.37358999252319336 0.5625923871994019\n",
      "[Step 6658] Loss: 9.74e+07 0.3736957013607025 0.5626204609870911\n",
      "[Step 6659] Loss: 9.77e+07 0.3739054501056671 0.5626650452613831\n",
      "[Step 6660] Loss: 9.81e+07 0.3739664554595947 0.5626567602157593\n",
      "[Step 6661] Loss: 9.63e+07 0.3739670217037201 0.5626303553581238\n",
      "[Step 6662] Loss: 9.68e+07 0.3739885687828064 0.562627911567688\n",
      "[Step 6663] Loss: 9.78e+07 0.3739417493343353 0.5625981688499451\n",
      "[Step 6664] Loss: 9.76e+07 0.3738524317741394 0.5625470280647278\n",
      "[Step 6665] Loss: 9.67e+07 0.3737717270851135 0.5625272393226624\n",
      "[Step 6666] Loss: 9.72e+07 0.3737469017505646 0.5625024437904358\n",
      "[Step 6667] Loss: 9.79e+07 0.37383419275283813 0.5624991655349731\n",
      "[Step 6668] Loss: 9.72e+07 0.3738410472869873 0.5625049471855164\n",
      "[Step 6669] Loss: 9.71e+07 0.37381449341773987 0.5624925494194031\n",
      "[Step 6670] Loss: 9.69e+07 0.3738565146923065 0.5624587535858154\n",
      "[Step 6671] Loss: 9.72e+07 0.3738201856613159 0.5624158382415771\n",
      "[Step 6672] Loss: 9.76e+07 0.3737747371196747 0.5623762011528015\n",
      "[Step 6673] Loss: 9.80e+07 0.3738054633140564 0.562386155128479\n",
      "[Step 6674] Loss: 9.66e+07 0.3738113045692444 0.5623671412467957\n",
      "[Step 6675] Loss: 9.72e+07 0.3738425076007843 0.5623490214347839\n",
      "[Step 6676] Loss: 9.70e+07 0.3737923502922058 0.5622986555099487\n",
      "[Step 6677] Loss: 9.65e+07 0.37377241253852844 0.5622755289077759\n",
      "[Step 6678] Loss: 9.65e+07 0.3737626075744629 0.56226646900177\n",
      "[Step 6679] Loss: 9.64e+07 0.37376847863197327 0.5622507929801941\n",
      "[Step 6680] Loss: 9.77e+07 0.3736412525177002 0.5622004866600037\n",
      "[Step 6681] Loss: 9.70e+07 0.37336456775665283 0.562123715877533\n",
      "[Step 6682] Loss: 9.65e+07 0.3730907440185547 0.5620313286781311\n",
      "[Step 6683] Loss: 9.61e+07 0.37287113070487976 0.5619182586669922\n",
      "[Step 6684] Loss: 9.75e+07 0.37261900305747986 0.5618184208869934\n",
      "[Step 6685] Loss: 9.71e+07 0.3723088502883911 0.5617054104804993\n",
      "[Step 6686] Loss: 9.70e+07 0.37196338176727295 0.5615989565849304\n",
      "[Step 6687] Loss: 9.71e+07 0.3715262711048126 0.5614776611328125\n",
      "[Step 6688] Loss: 9.65e+07 0.3711070418357849 0.5613489151000977\n",
      "[Step 6689] Loss: 9.70e+07 0.37075120210647583 0.5612713694572449\n",
      "[Step 6690] Loss: 9.61e+07 0.3704208433628082 0.5611756443977356\n",
      "[Step 6691] Loss: 9.73e+07 0.3701755702495575 0.5611013770103455\n",
      "[Step 6692] Loss: 9.65e+07 0.3700045049190521 0.5610345602035522\n",
      "[Step 6693] Loss: 9.66e+07 0.36985960602760315 0.5609768033027649\n",
      "[Step 6694] Loss: 9.81e+07 0.36982423067092896 0.5609577894210815\n",
      "[Step 6695] Loss: 9.67e+07 0.3697786033153534 0.5609272718429565\n",
      "[Step 6696] Loss: 9.68e+07 0.36972227692604065 0.5609264373779297\n",
      "[Step 6697] Loss: 9.74e+07 0.36969760060310364 0.5609132647514343\n",
      "[Step 6698] Loss: 9.63e+07 0.36969637870788574 0.5609091520309448\n",
      "[Step 6699] Loss: 9.66e+07 0.3697088956832886 0.5608984231948853\n",
      "[Step 6700] Loss: 9.69e+07 0.3697250485420227 0.5609033703804016\n",
      "[Step 6701] Loss: 9.69e+07 0.36972999572753906 0.5608934760093689\n",
      "[Step 6702] Loss: 9.69e+07 0.3697279691696167 0.5608587861061096\n",
      "[Step 6703] Loss: 9.65e+07 0.3697144687175751 0.5608934760093689\n",
      "[Step 6704] Loss: 9.54e+07 0.36966830492019653 0.5608885288238525\n",
      "[Step 6705] Loss: 9.74e+07 0.36974868178367615 0.5609182119369507\n",
      "[Step 6706] Loss: 9.69e+07 0.3698148727416992 0.5608984231948853\n",
      "[Step 6707] Loss: 9.72e+07 0.36993348598480225 0.5609223246574402\n",
      "[Step 6708] Loss: 9.84e+07 0.3699122965335846 0.5608934760093689\n",
      "[Step 6709] Loss: 9.68e+07 0.3699556887149811 0.560900866985321\n",
      "[Step 6710] Loss: 9.65e+07 0.3699803650379181 0.560886025428772\n",
      "[Step 6711] Loss: 9.67e+07 0.36997997760772705 0.56084805727005\n",
      "[Step 6712] Loss: 9.68e+07 0.3699173629283905 0.560839831829071\n",
      "[Step 6713] Loss: 9.70e+07 0.3698973059654236 0.560810923576355\n",
      "[Step 6714] Loss: 9.65e+07 0.36995160579681396 0.5608076453208923\n",
      "[Step 6715] Loss: 9.62e+07 0.36997976899147034 0.5608100891113281\n",
      "[Step 6716] Loss: 9.62e+07 0.3700006604194641 0.560810923576355\n",
      "[Step 6717] Loss: 9.65e+07 0.37000003457069397 0.5608043670654297\n",
      "[Step 6718] Loss: 9.68e+07 0.36992648243904114 0.5607713460922241\n",
      "[Step 6719] Loss: 9.71e+07 0.3698165714740753 0.5607160329818726\n",
      "[Step 6720] Loss: 9.74e+07 0.36980217695236206 0.5607416033744812\n",
      "[Step 6721] Loss: 9.66e+07 0.3698056936264038 0.560705304145813\n",
      "[Step 6722] Loss: 9.68e+07 0.36980313062667847 0.5607383251190186\n",
      "[Step 6723] Loss: 9.69e+07 0.3696730136871338 0.56071937084198\n",
      "[Step 6724] Loss: 9.64e+07 0.36952871084213257 0.5606723427772522\n",
      "[Step 6725] Loss: 9.62e+07 0.36933162808418274 0.560613751411438\n",
      "[Step 6726] Loss: 9.73e+07 0.3690940737724304 0.5605444312095642\n",
      "[Step 6727] Loss: 9.70e+07 0.3688441216945648 0.5604709982872009\n",
      "[Step 6728] Loss: 9.71e+07 0.3685406744480133 0.5603727698326111\n",
      "[Step 6729] Loss: 9.73e+07 0.3681717813014984 0.5602597594261169\n",
      "[Step 6730] Loss: 9.68e+07 0.3678552806377411 0.560116171836853\n",
      "[Step 6731] Loss: 9.73e+07 0.3675108850002289 0.5600171685218811\n",
      "[Step 6732] Loss: 9.73e+07 0.36713707447052 0.5599222779273987\n",
      "[Step 6733] Loss: 9.66e+07 0.36684367060661316 0.5598512887954712\n",
      "[Step 6734] Loss: 9.68e+07 0.3666009306907654 0.5597605109214783\n",
      "[Step 6735] Loss: 9.70e+07 0.3663282096385956 0.559654951095581\n",
      "[Step 6736] Loss: 9.67e+07 0.3660760819911957 0.5595988035202026\n",
      "[Step 6737] Loss: 9.66e+07 0.3658585250377655 0.5595270395278931\n",
      "[Step 6738] Loss: 9.70e+07 0.36571693420410156 0.5594701170921326\n",
      "[Step 6739] Loss: 9.77e+07 0.3656214475631714 0.5594626665115356\n",
      "[Step 6740] Loss: 9.68e+07 0.36547157168388367 0.5594246983528137\n",
      "[Step 6741] Loss: 9.77e+07 0.3652317225933075 0.5593413710594177\n",
      "[Step 6742] Loss: 9.66e+07 0.3650606870651245 0.5593050718307495\n",
      "[Step 6743] Loss: 9.69e+07 0.36489927768707275 0.5592299699783325\n",
      "[Step 6744] Loss: 9.74e+07 0.3646869659423828 0.5591590404510498\n",
      "[Step 6745] Loss: 9.74e+07 0.36457785964012146 0.5590929985046387\n",
      "[Step 6746] Loss: 9.77e+07 0.36463186144828796 0.559089720249176\n",
      "[Step 6747] Loss: 9.76e+07 0.36452803015708923 0.5590541958808899\n",
      "[Step 6748] Loss: 9.66e+07 0.3644665479660034 0.5589865446090698\n",
      "[Step 6749] Loss: 9.72e+07 0.36435410380363464 0.5589519143104553\n",
      "[Step 6750] Loss: 9.81e+07 0.36408957839012146 0.5588652491569519\n",
      "[Step 6751] Loss: 9.78e+07 0.36385077238082886 0.5587447881698608\n",
      "[Step 6752] Loss: 9.58e+07 0.36361783742904663 0.5586622953414917\n",
      "[Step 6753] Loss: 9.69e+07 0.36345234513282776 0.5585863590240479\n",
      "[Step 6754] Loss: 9.69e+07 0.3632659614086151 0.5585187077522278\n",
      "[Step 6755] Loss: 9.63e+07 0.3631967306137085 0.5585088133811951\n",
      "[Step 6756] Loss: 9.72e+07 0.36324241757392883 0.5584873557090759\n",
      "[Step 6757] Loss: 9.63e+07 0.3632413446903229 0.5584749579429626\n",
      "[Step 6758] Loss: 9.70e+07 0.3633221983909607 0.5585145950317383\n",
      "[Step 6759] Loss: 9.68e+07 0.363480806350708 0.5585393309593201\n",
      "[Step 6760] Loss: 9.69e+07 0.3636164963245392 0.5585476160049438\n",
      "[Step 6761] Loss: 9.69e+07 0.36370763182640076 0.5585682392120361\n",
      "[Step 6762] Loss: 9.68e+07 0.36381644010543823 0.5585938096046448\n",
      "[Step 6763] Loss: 9.76e+07 0.36377638578414917 0.5585913062095642\n",
      "[Step 6764] Loss: 9.63e+07 0.36366069316864014 0.5585698485374451\n",
      "[Step 6765] Loss: 9.70e+07 0.3635741174221039 0.5585426092147827\n",
      "[Step 6766] Loss: 9.65e+07 0.36342403292655945 0.5585376620292664\n",
      "[Step 6767] Loss: 9.61e+07 0.3632861375808716 0.5585005283355713\n",
      "[Step 6768] Loss: 9.73e+07 0.3631831705570221 0.5584667325019836\n",
      "[Step 6769] Loss: 9.73e+07 0.3630882799625397 0.5584279298782349\n",
      "[Step 6770] Loss: 9.69e+07 0.36298325657844543 0.5583858489990234\n",
      "[Step 6771] Loss: 9.61e+07 0.3628929555416107 0.5583478808403015\n",
      "[Step 6772] Loss: 9.70e+07 0.36286675930023193 0.5583314299583435\n",
      "[Step 6773] Loss: 9.66e+07 0.3627558946609497 0.5583223104476929\n",
      "[Step 6774] Loss: 9.85e+07 0.3624843955039978 0.5582497119903564\n",
      "[Step 6775] Loss: 9.63e+07 0.3622925877571106 0.5581861734390259\n",
      "[Step 6776] Loss: 9.69e+07 0.36223775148391724 0.5581507086753845\n",
      "[Step 6777] Loss: 9.69e+07 0.3621031939983368 0.5581234693527222\n",
      "[Step 6778] Loss: 9.71e+07 0.36196139454841614 0.558040976524353\n",
      "[Step 6779] Loss: 9.71e+07 0.3617843985557556 0.5579848289489746\n",
      "[Step 6780] Loss: 9.63e+07 0.3617197871208191 0.5579411387443542\n",
      "[Step 6781] Loss: 9.64e+07 0.3616407811641693 0.5579279065132141\n",
      "[Step 6782] Loss: 9.73e+07 0.3615918457508087 0.5579089522361755\n",
      "[Step 6783] Loss: 9.71e+07 0.36169907450675964 0.55793696641922\n",
      "[Step 6784] Loss: 9.65e+07 0.3617737293243408 0.5579468607902527\n",
      "[Step 6785] Loss: 9.71e+07 0.36173683404922485 0.5579229593276978\n",
      "[Step 6786] Loss: 9.64e+07 0.36170849204063416 0.557921290397644\n",
      "[Step 6787] Loss: 9.81e+07 0.36178484559059143 0.5579311847686768\n",
      "[Step 6788] Loss: 9.69e+07 0.3618622124195099 0.5579229593276978\n",
      "[Step 6789] Loss: 9.76e+07 0.3617745339870453 0.55788254737854\n",
      "[Step 6790] Loss: 9.63e+07 0.3616560399532318 0.5578437447547913\n",
      "[Step 6791] Loss: 9.70e+07 0.36146095395088196 0.5577892661094666\n",
      "[Step 6792] Loss: 9.62e+07 0.3612426519393921 0.5577356815338135\n",
      "[Step 6793] Loss: 9.71e+07 0.36095190048217773 0.5576589107513428\n",
      "[Step 6794] Loss: 9.69e+07 0.360808402299881 0.5576283931732178\n",
      "[Step 6795] Loss: 9.68e+07 0.36066994071006775 0.5575987100601196\n",
      "[Step 6796] Loss: 9.70e+07 0.36062493920326233 0.5575838088989258\n",
      "[Step 6797] Loss: 9.67e+07 0.3605364263057709 0.5575574040412903\n",
      "[Step 6798] Loss: 9.65e+07 0.36048340797424316 0.5575309991836548\n",
      "[Step 6799] Loss: 9.72e+07 0.3603866994380951 0.5575128793716431\n",
      "[Step 6800] Loss: 9.71e+07 0.36023983359336853 0.5574938654899597\n",
      "[Step 6801] Loss: 9.68e+07 0.3601074516773224 0.5574774146080017\n",
      "[Step 6802] Loss: 9.66e+07 0.35993778705596924 0.5573940277099609\n",
      "[Step 6803] Loss: 9.64e+07 0.3597302734851837 0.5573140382766724\n",
      "[Step 6804] Loss: 9.61e+07 0.3595006763935089 0.5572620034217834\n",
      "[Step 6805] Loss: 9.69e+07 0.35918480157852173 0.5571770071983337\n",
      "[Step 6806] Loss: 9.64e+07 0.3589654564857483 0.5571374297142029\n",
      "[Step 6807] Loss: 9.61e+07 0.3587670624256134 0.5570573806762695\n",
      "[Step 6808] Loss: 9.75e+07 0.3585689067840576 0.5570251941680908\n",
      "[Step 6809] Loss: 9.76e+07 0.3583751320838928 0.5569757223129272\n",
      "[Step 6810] Loss: 9.68e+07 0.3582080602645874 0.5568774938583374\n",
      "[Step 6811] Loss: 9.74e+07 0.3582325279712677 0.5568684339523315\n",
      "[Step 6812] Loss: 9.71e+07 0.3583005666732788 0.556865930557251\n",
      "[Step 6813] Loss: 9.71e+07 0.35848188400268555 0.5569121837615967\n",
      "[Step 6814] Loss: 9.78e+07 0.3587324023246765 0.5569336414337158\n",
      "[Step 6815] Loss: 9.85e+07 0.3591032028198242 0.5570070743560791\n",
      "[Step 6816] Loss: 9.68e+07 0.35943177342414856 0.5570706129074097\n",
      "[Step 6817] Loss: 9.66e+07 0.35964900255203247 0.5570730566978455\n",
      "[Step 6818] Loss: 9.69e+07 0.3598169982433319 0.5570854544639587\n",
      "[Step 6819] Loss: 9.62e+07 0.3599241375923157 0.5570895671844482\n",
      "[Step 6820] Loss: 9.70e+07 0.3600172996520996 0.5570672750473022\n",
      "[Step 6821] Loss: 9.65e+07 0.36020001769065857 0.5571052432060242\n",
      "[Step 6822] Loss: 9.63e+07 0.3603326678276062 0.5571415424346924\n",
      "[Step 6823] Loss: 9.82e+07 0.3602905869483948 0.5571118593215942\n",
      "[Step 6824] Loss: 9.59e+07 0.3602392077445984 0.5570780038833618\n",
      "[Step 6825] Loss: 9.74e+07 0.36029812693595886 0.5570590496063232\n",
      "[Step 6826] Loss: 9.70e+07 0.3603854775428772 0.5570350885391235\n",
      "[Step 6827] Loss: 9.67e+07 0.3604229688644409 0.5570474863052368\n",
      "[Step 6828] Loss: 9.70e+07 0.36056050658226013 0.5570656657218933\n",
      "[Step 6829] Loss: 9.60e+07 0.36075323820114136 0.5570805072784424\n",
      "[Step 6830] Loss: 9.66e+07 0.360964834690094 0.5571126937866211\n",
      "[Step 6831] Loss: 9.69e+07 0.3612639904022217 0.557196855545044\n",
      "[Step 6832] Loss: 9.62e+07 0.3615378737449646 0.557264506816864\n",
      "[Step 6833] Loss: 9.65e+07 0.3618086576461792 0.557339608669281\n",
      "[Step 6834] Loss: 9.59e+07 0.3620976209640503 0.5573775172233582\n",
      "[Step 6835] Loss: 9.64e+07 0.3622952997684479 0.5574188232421875\n",
      "[Step 6836] Loss: 9.67e+07 0.36247149109840393 0.5574625134468079\n",
      "[Step 6837] Loss: 9.63e+07 0.3625437915325165 0.5574749112129211\n",
      "[Step 6838] Loss: 9.64e+07 0.3626462519168854 0.5575401186943054\n",
      "[Step 6839] Loss: 9.67e+07 0.36285343766212463 0.5575821995735168\n",
      "[Step 6840] Loss: 9.67e+07 0.36302265524864197 0.5576267242431641\n",
      "[Step 6841] Loss: 9.63e+07 0.3631506562232971 0.5576193332672119\n",
      "[Step 6842] Loss: 9.74e+07 0.3631422817707062 0.5576069355010986\n",
      "[Step 6843] Loss: 9.67e+07 0.363091379404068 0.5575904250144958\n",
      "[Step 6844] Loss: 9.68e+07 0.3630181550979614 0.5575838088989258\n",
      "[Step 6845] Loss: 9.65e+07 0.3628529906272888 0.5575475096702576\n",
      "[Step 6846] Loss: 9.76e+07 0.3627965450286865 0.5575161576271057\n",
      "[Step 6847] Loss: 9.68e+07 0.362800657749176 0.5575169920921326\n",
      "[Step 6848] Loss: 9.75e+07 0.3627174198627472 0.5575087666511536\n",
      "[Step 6849] Loss: 9.68e+07 0.3627341687679291 0.5575070977210999\n",
      "[Step 6850] Loss: 9.68e+07 0.36277538537979126 0.5575244426727295\n",
      "[Step 6851] Loss: 9.59e+07 0.3627954125404358 0.5575219392776489\n",
      "[Step 6852] Loss: 9.73e+07 0.36269137263298035 0.5575178265571594\n",
      "[Step 6853] Loss: 9.71e+07 0.3626585602760315 0.5574864745140076\n",
      "[Step 6854] Loss: 9.74e+07 0.36264026165008545 0.557498037815094\n",
      "[Step 6855] Loss: 9.68e+07 0.36255019903182983 0.5574815273284912\n",
      "[Step 6856] Loss: 9.71e+07 0.36233848333358765 0.5574179887771606\n",
      "[Step 6857] Loss: 9.63e+07 0.3621445894241333 0.5573858022689819\n",
      "[Step 6858] Loss: 9.63e+07 0.3619510233402252 0.5573445558547974\n",
      "[Step 6859] Loss: 9.71e+07 0.3619266152381897 0.5573503375053406\n",
      "[Step 6860] Loss: 9.64e+07 0.36194664239883423 0.5573247075080872\n",
      "[Step 6861] Loss: 9.65e+07 0.3619305491447449 0.557325541973114\n",
      "[Step 6862] Loss: 9.64e+07 0.36189785599708557 0.5573123693466187\n",
      "[Step 6863] Loss: 9.63e+07 0.3618297278881073 0.5572834610939026\n",
      "[Step 6864] Loss: 9.81e+07 0.36187899112701416 0.5572744011878967\n",
      "[Step 6865] Loss: 9.63e+07 0.3618776798248291 0.5572595596313477\n",
      "[Step 6866] Loss: 9.63e+07 0.36191579699516296 0.5572752356529236\n",
      "[Step 6867] Loss: 9.73e+07 0.36199671030044556 0.5572793483734131\n",
      "[Step 6868] Loss: 9.64e+07 0.362057626247406 0.5572554469108582\n",
      "[Step 6869] Loss: 9.67e+07 0.36218345165252686 0.5572653412818909\n",
      "[Step 6870] Loss: 9.61e+07 0.36226189136505127 0.557264506816864\n",
      "[Step 6871] Loss: 9.59e+07 0.3624032139778137 0.5572537779808044\n",
      "[Step 6872] Loss: 9.60e+07 0.36257079243659973 0.5573247075080872\n",
      "[Step 6873] Loss: 9.72e+07 0.3627578020095825 0.5573874711990356\n",
      "[Step 6874] Loss: 9.65e+07 0.36307036876678467 0.5574542880058289\n",
      "[Step 6875] Loss: 9.64e+07 0.36339789628982544 0.5575309991836548\n",
      "[Step 6876] Loss: 9.73e+07 0.36355987191200256 0.5575706362724304\n",
      "[Step 6877] Loss: 9.67e+07 0.3635809123516083 0.5575846433639526\n",
      "[Step 6878] Loss: 9.62e+07 0.36355143785476685 0.5575739145278931\n",
      "[Step 6879] Loss: 9.65e+07 0.3635137677192688 0.5575516223907471\n",
      "[Step 6880] Loss: 9.67e+07 0.3634122908115387 0.5575211048126221\n",
      "[Step 6881] Loss: 9.69e+07 0.3633744418621063 0.5575112104415894\n",
      "[Step 6882] Loss: 9.61e+07 0.363307386636734 0.5574765801429749\n",
      "[Step 6883] Loss: 9.70e+07 0.36334946751594543 0.5574972033500671\n",
      "[Step 6884] Loss: 9.68e+07 0.3634568452835083 0.5575021505355835\n",
      "[Step 6885] Loss: 9.72e+07 0.3636310398578644 0.5575202703475952\n",
      "[Step 6886] Loss: 9.69e+07 0.3638698160648346 0.5575681328773499\n",
      "[Step 6887] Loss: 9.73e+07 0.3641773462295532 0.5576234459877014\n",
      "[Step 6888] Loss: 9.61e+07 0.3644253611564636 0.5576853156089783\n",
      "[Step 6889] Loss: 9.60e+07 0.36465179920196533 0.5577439069747925\n",
      "[Step 6890] Loss: 9.63e+07 0.3648211658000946 0.5577513575553894\n",
      "[Step 6891] Loss: 9.67e+07 0.3649356961250305 0.5578057765960693\n",
      "[Step 6892] Loss: 9.61e+07 0.3650725483894348 0.5578305721282959\n",
      "[Step 6893] Loss: 9.66e+07 0.3651726543903351 0.5578693151473999\n",
      "[Step 6894] Loss: 9.67e+07 0.36526918411254883 0.5578808784484863\n",
      "[Step 6895] Loss: 9.69e+07 0.36544275283813477 0.5579229593276978\n",
      "[Step 6896] Loss: 9.80e+07 0.36566588282585144 0.5580112338066101\n",
      "[Step 6897] Loss: 9.71e+07 0.36585482954978943 0.5580376386642456\n",
      "[Step 6898] Loss: 9.69e+07 0.3660162091255188 0.5580706596374512\n",
      "[Step 6899] Loss: 9.73e+07 0.3661915957927704 0.5581119060516357\n",
      "[Step 6900] Loss: 9.78e+07 0.36629146337509155 0.5581185221672058\n",
      "[Step 6901] Loss: 9.61e+07 0.3663896322250366 0.5581251382827759\n",
      "[Step 6902] Loss: 9.69e+07 0.3665379583835602 0.5581531524658203\n",
      "[Step 6903] Loss: 9.67e+07 0.3666746914386749 0.5582084655761719\n",
      "[Step 6904] Loss: 9.61e+07 0.3667169213294983 0.5582340359687805\n",
      "[Step 6905] Loss: 9.66e+07 0.36663371324539185 0.5582216382026672\n",
      "[Step 6906] Loss: 9.62e+07 0.3665536344051361 0.5581762790679932\n",
      "[Step 6907] Loss: 9.70e+07 0.3663751482963562 0.5580912828445435\n",
      "[Step 6908] Loss: 9.65e+07 0.36619436740875244 0.5580459237098694\n",
      "[Step 6909] Loss: 9.76e+07 0.36616554856300354 0.5580244660377502\n",
      "[Step 6910] Loss: 9.67e+07 0.36612528562545776 0.558012068271637\n",
      "[Step 6911] Loss: 9.71e+07 0.3662101626396179 0.5580442547798157\n",
      "[Step 6912] Loss: 9.59e+07 0.3662914037704468 0.5580739378929138\n",
      "[Step 6913] Loss: 9.69e+07 0.3663138449192047 0.5580756068229675\n",
      "[Step 6914] Loss: 9.70e+07 0.36630895733833313 0.5580739378929138\n",
      "[Step 6915] Loss: 9.70e+07 0.3664204180240631 0.5581144094467163\n",
      "[Step 6916] Loss: 9.71e+07 0.3665934205055237 0.5581737756729126\n",
      "[Step 6917] Loss: 9.65e+07 0.3666633367538452 0.5582001805305481\n",
      "[Step 6918] Loss: 9.69e+07 0.3666689097881317 0.5582224726676941\n",
      "[Step 6919] Loss: 9.72e+07 0.3666088283061981 0.5582125782966614\n",
      "[Step 6920] Loss: 9.64e+07 0.36663269996643066 0.5582216382026672\n",
      "[Step 6921] Loss: 9.71e+07 0.3666727840900421 0.5582035183906555\n",
      "[Step 6922] Loss: 9.73e+07 0.3667658865451813 0.5582150816917419\n",
      "[Step 6923] Loss: 9.71e+07 0.3668929934501648 0.5582357048988342\n",
      "[Step 6924] Loss: 9.74e+07 0.36691349744796753 0.5582315325737\n",
      "[Step 6925] Loss: 9.63e+07 0.36684489250183105 0.5582208633422852\n",
      "[Step 6926] Loss: 9.68e+07 0.3667808473110199 0.5581894516944885\n",
      "[Step 6927] Loss: 9.62e+07 0.3666936457157135 0.5581878423690796\n",
      "[Step 6928] Loss: 9.72e+07 0.3666344881057739 0.5581573247909546\n",
      "[Step 6929] Loss: 9.65e+07 0.3665446937084198 0.5581218004226685\n",
      "[Step 6930] Loss: 9.70e+07 0.3664356470108032 0.558079719543457\n",
      "[Step 6931] Loss: 9.65e+07 0.36633235216140747 0.5580145716667175\n",
      "[Step 6932] Loss: 9.68e+07 0.3663092851638794 0.5579988956451416\n",
      "[Step 6933] Loss: 9.80e+07 0.3663840591907501 0.5580079555511475\n",
      "[Step 6934] Loss: 9.62e+07 0.3664129972457886 0.5580087900161743\n",
      "[Step 6935] Loss: 9.65e+07 0.3664717674255371 0.5580417513847351\n",
      "[Step 6936] Loss: 9.61e+07 0.3664451241493225 0.5580137372016907\n",
      "[Step 6937] Loss: 9.69e+07 0.3664711117744446 0.5580244660377502\n",
      "[Step 6938] Loss: 9.63e+07 0.3665013313293457 0.5580302476882935\n",
      "[Step 6939] Loss: 9.74e+07 0.36660200357437134 0.5580302476882935\n",
      "[Step 6940] Loss: 9.58e+07 0.3666973114013672 0.5580756068229675\n",
      "[Step 6941] Loss: 9.62e+07 0.3667987585067749 0.5581069588661194\n",
      "[Step 6942] Loss: 9.63e+07 0.3669796586036682 0.5581713318824768\n",
      "[Step 6943] Loss: 9.74e+07 0.36715325713157654 0.5582183599472046\n",
      "[Step 6944] Loss: 9.60e+07 0.367279589176178 0.5582430958747864\n",
      "[Step 6945] Loss: 9.62e+07 0.3674638271331787 0.5582777857780457\n",
      "[Step 6946] Loss: 9.61e+07 0.367607980966568 0.5583190321922302\n",
      "[Step 6947] Loss: 9.63e+07 0.3677228093147278 0.5583396553993225\n",
      "[Step 6948] Loss: 9.66e+07 0.3677126467227936 0.5583404898643494\n",
      "[Step 6949] Loss: 9.69e+07 0.3677235245704651 0.558313250541687\n",
      "[Step 6950] Loss: 9.72e+07 0.36777567863464355 0.558313250541687\n",
      "[Step 6951] Loss: 9.61e+07 0.3677848279476166 0.5583413243293762\n",
      "[Step 6952] Loss: 9.59e+07 0.3677263557910919 0.5583330392837524\n",
      "[Step 6953] Loss: 9.70e+07 0.36764267086982727 0.5583099722862244\n",
      "[Step 6954] Loss: 9.68e+07 0.36756032705307007 0.558284342288971\n",
      "[Step 6955] Loss: 9.67e+07 0.36745354533195496 0.5582596063613892\n",
      "[Step 6956] Loss: 9.75e+07 0.3673136532306671 0.5582389831542969\n",
      "[Step 6957] Loss: 9.73e+07 0.36710813641548157 0.5581960678100586\n",
      "[Step 6958] Loss: 9.68e+07 0.3668596148490906 0.5581341981887817\n",
      "[Step 6959] Loss: 9.68e+07 0.36665859818458557 0.5580970644950867\n",
      "[Step 6960] Loss: 9.61e+07 0.36643919348716736 0.5580277442932129\n",
      "[Step 6961] Loss: 9.70e+07 0.3661591112613678 0.5579411387443542\n",
      "[Step 6962] Loss: 9.59e+07 0.36591851711273193 0.5578619241714478\n",
      "[Step 6963] Loss: 9.61e+07 0.3656163811683655 0.5577868223190308\n",
      "[Step 6964] Loss: 9.65e+07 0.36532336473464966 0.5577133893966675\n",
      "[Step 6965] Loss: 9.72e+07 0.36492109298706055 0.557611882686615\n",
      "[Step 6966] Loss: 9.72e+07 0.3645995855331421 0.557514488697052\n",
      "[Step 6967] Loss: 9.72e+07 0.3643151819705963 0.5574295520782471\n",
      "[Step 6968] Loss: 9.60e+07 0.36407941579818726 0.5573643445968628\n",
      "[Step 6969] Loss: 9.72e+07 0.3639293909072876 0.5573090314865112\n",
      "[Step 6970] Loss: 9.66e+07 0.3638014495372772 0.5572917461395264\n",
      "[Step 6971] Loss: 9.68e+07 0.3637283146381378 0.5572620034217834\n",
      "[Step 6972] Loss: 9.65e+07 0.36363935470581055 0.5572141408920288\n",
      "[Step 6973] Loss: 9.70e+07 0.3635089695453644 0.5571885704994202\n",
      "[Step 6974] Loss: 9.60e+07 0.3634186089038849 0.5571613311767578\n",
      "[Step 6975] Loss: 9.69e+07 0.36333003640174866 0.557144045829773\n",
      "[Step 6976] Loss: 9.71e+07 0.36318451166152954 0.55711430311203\n",
      "[Step 6977] Loss: 9.66e+07 0.36301523447036743 0.5570639967918396\n",
      "[Step 6978] Loss: 9.68e+07 0.36281758546829224 0.5569831132888794\n",
      "[Step 6979] Loss: 9.76e+07 0.3625594973564148 0.5569369196891785\n",
      "[Step 6980] Loss: 9.68e+07 0.3622872531414032 0.5568593740463257\n",
      "[Step 6981] Loss: 9.66e+07 0.3620545268058777 0.5567727088928223\n",
      "[Step 6982] Loss: 9.67e+07 0.36174124479293823 0.5566811561584473\n",
      "[Step 6983] Loss: 9.64e+07 0.361477792263031 0.5565697550773621\n",
      "[Step 6984] Loss: 9.73e+07 0.3613848388195038 0.556532621383667\n",
      "[Step 6985] Loss: 9.66e+07 0.3613508939743042 0.5565086603164673\n",
      "[Step 6986] Loss: 9.67e+07 0.36130577325820923 0.5564789772033691\n",
      "[Step 6987] Loss: 9.63e+07 0.36123427748680115 0.5564789772033691\n",
      "[Step 6988] Loss: 9.72e+07 0.3611172139644623 0.5564509034156799\n",
      "[Step 6989] Loss: 9.65e+07 0.3609851896762848 0.5564203858375549\n",
      "[Step 6990] Loss: 9.62e+07 0.3608333468437195 0.5563675761222839\n",
      "[Step 6991] Loss: 9.73e+07 0.3607943058013916 0.5563287734985352\n",
      "[Step 6992] Loss: 9.66e+07 0.3606308698654175 0.5563023686408997\n",
      "[Step 6993] Loss: 9.71e+07 0.36052820086479187 0.5562850832939148\n",
      "[Step 6994] Loss: 9.66e+07 0.3604286313056946 0.556239664554596\n",
      "[Step 6995] Loss: 9.66e+07 0.36034977436065674 0.5562314391136169\n",
      "[Step 6996] Loss: 9.70e+07 0.3602294921875 0.5562264919281006\n",
      "[Step 6997] Loss: 9.64e+07 0.36014777421951294 0.5561860203742981\n",
      "[Step 6998] Loss: 9.68e+07 0.3601500689983368 0.5561563372612\n",
      "[Step 6999] Loss: 9.71e+07 0.3601078689098358 0.5561588406562805\n",
      "[Step 7000] Loss: 9.68e+07 0.36013028025627136 0.5561538934707642\n",
      "[Step 7001] Loss: 9.71e+07 0.3600757420063019 0.5561373829841614\n",
      "[Step 7002] Loss: 9.74e+07 0.3600727617740631 0.5561142563819885\n",
      "[Step 7003] Loss: 9.63e+07 0.3600924611091614 0.5561093091964722\n",
      "[Step 7004] Loss: 9.71e+07 0.36023396253585815 0.556125819683075\n",
      "[Step 7005] Loss: 9.67e+07 0.3603377342224121 0.5561200380325317\n",
      "[Step 7006] Loss: 9.78e+07 0.36028972268104553 0.5560804009437561\n",
      "[Step 7007] Loss: 9.59e+07 0.36023253202438354 0.5560688972473145\n",
      "[Step 7008] Loss: 9.72e+07 0.36002153158187866 0.5560069680213928\n",
      "[Step 7009] Loss: 9.70e+07 0.3598809540271759 0.5559789538383484\n",
      "[Step 7010] Loss: 9.69e+07 0.35969647765159607 0.5559269785881042\n",
      "[Step 7011] Loss: 9.72e+07 0.3595149517059326 0.5559055209159851\n",
      "[Step 7012] Loss: 9.63e+07 0.35937264561653137 0.5558626055717468\n",
      "[Step 7013] Loss: 9.73e+07 0.35933491587638855 0.555823802947998\n",
      "[Step 7014] Loss: 9.64e+07 0.3592512905597687 0.5558031797409058\n",
      "[Step 7015] Loss: 9.59e+07 0.3591466546058655 0.5557743310928345\n",
      "[Step 7016] Loss: 9.71e+07 0.3591166138648987 0.555762767791748\n",
      "[Step 7017] Loss: 9.72e+07 0.3590090870857239 0.5557379722595215\n",
      "[Step 7018] Loss: 9.68e+07 0.3588273525238037 0.5556786060333252\n",
      "[Step 7019] Loss: 9.66e+07 0.35859838128089905 0.5555968880653381\n",
      "[Step 7020] Loss: 9.76e+07 0.3582032322883606 0.5555045008659363\n",
      "[Step 7021] Loss: 9.66e+07 0.3578021228313446 0.5553947687149048\n",
      "[Step 7022] Loss: 9.74e+07 0.35747554898262024 0.5552965402603149\n",
      "[Step 7023] Loss: 9.79e+07 0.3572063446044922 0.5552256107330322\n",
      "[Step 7024] Loss: 9.84e+07 0.3567734956741333 0.5550960302352905\n",
      "[Step 7025] Loss: 9.65e+07 0.3563517928123474 0.555008590221405\n",
      "[Step 7026] Loss: 9.80e+07 0.3559364378452301 0.554896354675293\n",
      "[Step 7027] Loss: 9.69e+07 0.35560959577560425 0.5547783374786377\n",
      "[Step 7028] Loss: 9.62e+07 0.3553336262702942 0.5546925663948059\n",
      "[Step 7029] Loss: 9.64e+07 0.35513585805892944 0.5546520948410034\n",
      "[Step 7030] Loss: 9.68e+07 0.3550070524215698 0.5546273589134216\n",
      "[Step 7031] Loss: 9.65e+07 0.35499677062034607 0.5546281933784485\n",
      "[Step 7032] Loss: 9.57e+07 0.35500144958496094 0.5546174645423889\n",
      "[Step 7033] Loss: 9.67e+07 0.35509324073791504 0.5546331405639648\n",
      "[Step 7034] Loss: 9.61e+07 0.35515522956848145 0.5546529293060303\n",
      "[Step 7035] Loss: 9.60e+07 0.35518908500671387 0.5546810030937195\n",
      "[Step 7036] Loss: 9.81e+07 0.3550110161304474 0.554632306098938\n",
      "[Step 7037] Loss: 9.75e+07 0.35482075810432434 0.5545687675476074\n",
      "[Step 7038] Loss: 9.60e+07 0.35466268658638 0.5544936656951904\n",
      "[Step 7039] Loss: 9.69e+07 0.3544289767742157 0.5544087290763855\n",
      "[Step 7040] Loss: 9.66e+07 0.3541179597377777 0.5543130040168762\n",
      "[Step 7041] Loss: 9.67e+07 0.35388949513435364 0.5542634725570679\n",
      "[Step 7042] Loss: 9.69e+07 0.35377365350723267 0.554232120513916\n",
      "[Step 7043] Loss: 9.68e+07 0.3536684215068817 0.5541933178901672\n",
      "[Step 7044] Loss: 9.64e+07 0.3535458743572235 0.5541768670082092\n",
      "[Step 7045] Loss: 9.65e+07 0.35343560576438904 0.5541595220565796\n",
      "[Step 7046] Loss: 9.79e+07 0.35320979356765747 0.5540910363197327\n",
      "[Step 7047] Loss: 9.68e+07 0.35300499200820923 0.5540489554405212\n",
      "[Step 7048] Loss: 9.68e+07 0.3527531921863556 0.5540002584457397\n",
      "[Step 7049] Loss: 9.90e+07 0.35234537720680237 0.5538723468780518\n",
      "[Step 7050] Loss: 9.71e+07 0.35203808546066284 0.5537766218185425\n",
      "[Step 7051] Loss: 9.64e+07 0.3517303168773651 0.5537048578262329\n",
      "[Step 7052] Loss: 9.75e+07 0.3515130281448364 0.553636372089386\n",
      "[Step 7053] Loss: 9.57e+07 0.3513232469558716 0.5535719990730286\n",
      "[Step 7054] Loss: 9.66e+07 0.35118281841278076 0.5535241365432739\n",
      "[Step 7055] Loss: 9.60e+07 0.35111919045448303 0.5534977316856384\n",
      "[Step 7056] Loss: 9.65e+07 0.35102641582489014 0.5534375309944153\n",
      "[Step 7057] Loss: 9.56e+07 0.35092946887016296 0.5533871650695801\n",
      "[Step 7058] Loss: 9.74e+07 0.3509312868118286 0.5533764362335205\n",
      "[Step 7059] Loss: 9.72e+07 0.35082104802131653 0.5533360242843628\n",
      "[Step 7060] Loss: 9.65e+07 0.35076937079429626 0.5533360242843628\n",
      "[Step 7061] Loss: 9.65e+07 0.35072028636932373 0.5533467531204224\n",
      "[Step 7062] Loss: 9.69e+07 0.3506270945072174 0.5533277988433838\n",
      "[Step 7063] Loss: 9.60e+07 0.3506026864051819 0.5533046722412109\n",
      "[Step 7064] Loss: 9.69e+07 0.35056886076927185 0.5532840490341187\n",
      "[Step 7065] Loss: 9.72e+07 0.3504098653793335 0.5532279014587402\n",
      "[Step 7066] Loss: 9.71e+07 0.3501889407634735 0.553146243095398\n",
      "[Step 7067] Loss: 9.74e+07 0.3498944342136383 0.553062915802002\n",
      "[Step 7068] Loss: 9.65e+07 0.34950920939445496 0.5529696345329285\n",
      "[Step 7069] Loss: 9.67e+07 0.3490884304046631 0.552888810634613\n",
      "[Step 7070] Loss: 9.69e+07 0.34871211647987366 0.552783191204071\n",
      "[Step 7071] Loss: 9.69e+07 0.3483106791973114 0.5526618957519531\n",
      "[Step 7072] Loss: 9.61e+07 0.34800776839256287 0.5525818467140198\n",
      "[Step 7073] Loss: 9.67e+07 0.34766605496406555 0.5524696111679077\n",
      "[Step 7074] Loss: 9.64e+07 0.34733664989471436 0.552376389503479\n",
      "[Step 7075] Loss: 9.77e+07 0.34687426686286926 0.5522476434707642\n",
      "[Step 7076] Loss: 9.58e+07 0.34646108746528625 0.5521337985992432\n",
      "[Step 7077] Loss: 9.72e+07 0.34595057368278503 0.5519943237304688\n",
      "[Step 7078] Loss: 9.64e+07 0.3454790711402893 0.5518664717674255\n",
      "[Step 7079] Loss: 9.67e+07 0.345114529132843 0.55177241563797\n",
      "[Step 7080] Loss: 9.73e+07 0.34487384557724 0.5517154335975647\n",
      "[Step 7081] Loss: 9.70e+07 0.3447279930114746 0.5516766905784607\n",
      "[Step 7082] Loss: 9.60e+07 0.3446049690246582 0.5517080426216125\n",
      "[Step 7083] Loss: 9.69e+07 0.34443241357803345 0.5516535639762878\n",
      "[Step 7084] Loss: 9.72e+07 0.3441164195537567 0.551613986492157\n",
      "[Step 7085] Loss: 9.64e+07 0.34383901953697205 0.5515496134757996\n",
      "[Step 7086] Loss: 9.65e+07 0.34363704919815063 0.5514910221099854\n",
      "[Step 7087] Loss: 9.65e+07 0.3435160219669342 0.5514745116233826\n",
      "[Step 7088] Loss: 9.72e+07 0.3433443009853363 0.5514217019081116\n",
      "[Step 7089] Loss: 9.71e+07 0.3430800139904022 0.5513606667518616\n",
      "[Step 7090] Loss: 9.73e+07 0.34262070059776306 0.5512467622756958\n",
      "[Step 7091] Loss: 9.68e+07 0.3422057628631592 0.5511535406112671\n",
      "[Step 7092] Loss: 9.65e+07 0.3418772220611572 0.5510652661323547\n",
      "[Step 7093] Loss: 9.67e+07 0.34152624011039734 0.5509703755378723\n",
      "[Step 7094] Loss: 9.61e+07 0.34115347266197205 0.5508663654327393\n",
      "[Step 7095] Loss: 9.59e+07 0.3408518433570862 0.5508036613464355\n",
      "[Step 7096] Loss: 9.72e+07 0.3406844437122345 0.5507533550262451\n",
      "[Step 7097] Loss: 9.62e+07 0.34051474928855896 0.55070960521698\n",
      "[Step 7098] Loss: 9.62e+07 0.3403632342815399 0.5506609082221985\n",
      "[Step 7099] Loss: 9.71e+07 0.34031760692596436 0.5506279468536377\n",
      "[Step 7100] Loss: 9.69e+07 0.34017887711524963 0.5505940914154053\n",
      "[Step 7101] Loss: 9.64e+07 0.34006044268608093 0.5505346655845642\n",
      "[Step 7102] Loss: 9.72e+07 0.3398902118206024 0.5504513382911682\n",
      "[Step 7103] Loss: 9.74e+07 0.33966800570487976 0.5503869652748108\n",
      "[Step 7104] Loss: 9.61e+07 0.3395030200481415 0.5503515005111694\n",
      "[Step 7105] Loss: 9.62e+07 0.33931243419647217 0.5502706170082092\n",
      "[Step 7106] Loss: 9.67e+07 0.33911406993865967 0.5502170324325562\n",
      "[Step 7107] Loss: 9.80e+07 0.3387730121612549 0.5501221418380737\n",
      "[Step 7108] Loss: 9.71e+07 0.3385304808616638 0.5500577688217163\n",
      "[Step 7109] Loss: 9.71e+07 0.338364839553833 0.5499950647354126\n",
      "[Step 7110] Loss: 9.54e+07 0.33824360370635986 0.5499760508537292\n",
      "[Step 7111] Loss: 9.63e+07 0.33809131383895874 0.5499380826950073\n",
      "[Step 7112] Loss: 9.61e+07 0.3380289375782013 0.5498861074447632\n",
      "[Step 7113] Loss: 9.75e+07 0.3380475640296936 0.5498836636543274\n",
      "[Step 7114] Loss: 9.68e+07 0.33806753158569336 0.5498795509338379\n",
      "[Step 7115] Loss: 9.58e+07 0.3380982577800751 0.5499001741409302\n",
      "[Step 7116] Loss: 9.68e+07 0.3381803035736084 0.5499389171600342\n",
      "[Step 7117] Loss: 9.73e+07 0.3382677733898163 0.5499405860900879\n",
      "[Step 7118] Loss: 9.65e+07 0.33836379647254944 0.549939751625061\n",
      "[Step 7119] Loss: 9.68e+07 0.3385004997253418 0.5499545931816101\n",
      "[Step 7120] Loss: 9.65e+07 0.33857133984565735 0.5499752163887024\n",
      "[Step 7121] Loss: 9.75e+07 0.3386729657649994 0.5499950647354126\n",
      "[Step 7122] Loss: 9.63e+07 0.3386423587799072 0.5499892830848694\n",
      "[Step 7123] Loss: 9.70e+07 0.33857500553131104 0.5499545931816101\n",
      "[Step 7124] Loss: 9.77e+07 0.338557630777359 0.5499480366706848\n",
      "[Step 7125] Loss: 9.65e+07 0.33859288692474365 0.5499455332756042\n",
      "[Step 7126] Loss: 9.69e+07 0.33861464262008667 0.5499405860900879\n",
      "[Step 7127] Loss: 9.66e+07 0.33861464262008667 0.5499240756034851\n",
      "[Step 7128] Loss: 9.70e+07 0.33853331208229065 0.5498877763748169\n",
      "[Step 7129] Loss: 9.66e+07 0.33856239914894104 0.5498729348182678\n",
      "[Step 7130] Loss: 9.64e+07 0.33868375420570374 0.5498927235603333\n",
      "[Step 7131] Loss: 9.67e+07 0.3387904167175293 0.5498844981193542\n",
      "[Step 7132] Loss: 9.61e+07 0.33884814381599426 0.549902617931366\n",
      "[Step 7133] Loss: 9.61e+07 0.33887889981269836 0.5499059557914734\n",
      "[Step 7134] Loss: 9.71e+07 0.3390365540981293 0.549939751625061\n",
      "[Step 7135] Loss: 9.63e+07 0.33918294310569763 0.5499793887138367\n",
      "[Step 7136] Loss: 9.69e+07 0.3393722176551819 0.5500172972679138\n",
      "[Step 7137] Loss: 9.63e+07 0.33956679701805115 0.5500577688217163\n",
      "[Step 7138] Loss: 9.70e+07 0.33979177474975586 0.5501155257225037\n",
      "[Step 7139] Loss: 9.72e+07 0.3398939371109009 0.550128698348999\n",
      "[Step 7140] Loss: 9.67e+07 0.33992260694503784 0.5501518249511719\n",
      "[Step 7141] Loss: 9.66e+07 0.33996349573135376 0.5501592755317688\n",
      "[Step 7142] Loss: 9.65e+07 0.3399784564971924 0.5501765608787537\n",
      "[Step 7143] Loss: 9.66e+07 0.3399654030799866 0.5501262545585632\n",
      "[Step 7144] Loss: 9.74e+07 0.339790403842926 0.5500792264938354\n",
      "[Step 7145] Loss: 9.60e+07 0.3396797180175781 0.5500206351280212\n",
      "[Step 7146] Loss: 9.75e+07 0.3394326865673065 0.5499760508537292\n",
      "[Step 7147] Loss: 9.65e+07 0.33912113308906555 0.5499059557914734\n",
      "[Step 7148] Loss: 9.64e+07 0.3388039767742157 0.5498209595680237\n",
      "[Step 7149] Loss: 9.69e+07 0.33847367763519287 0.5497458577156067\n",
      "[Step 7150] Loss: 9.69e+07 0.3382432758808136 0.5496782064437866\n",
      "[Step 7151] Loss: 9.58e+07 0.3380802869796753 0.5496097207069397\n",
      "[Step 7152] Loss: 9.62e+07 0.33795878291130066 0.5495593547821045\n",
      "[Step 7153] Loss: 9.64e+07 0.3378048241138458 0.5495313405990601\n",
      "[Step 7154] Loss: 9.66e+07 0.3376805782318115 0.5495065450668335\n",
      "[Step 7155] Loss: 9.62e+07 0.3375677168369293 0.5494809746742249\n",
      "[Step 7156] Loss: 9.61e+07 0.33750608563423157 0.5494595170021057\n",
      "[Step 7157] Loss: 9.60e+07 0.3374636769294739 0.5494685769081116\n",
      "[Step 7158] Loss: 9.72e+07 0.3374256193637848 0.5494446754455566\n",
      "[Step 7159] Loss: 9.61e+07 0.33740195631980896 0.5494380593299866\n",
      "[Step 7160] Loss: 9.72e+07 0.33746832609176636 0.5494223833084106\n",
      "[Step 7161] Loss: 9.59e+07 0.33754613995552063 0.5493976473808289\n",
      "[Step 7162] Loss: 9.66e+07 0.3376636803150177 0.5494215488433838\n",
      "[Step 7163] Loss: 9.66e+07 0.3377835154533386 0.5494133234024048\n",
      "[Step 7164] Loss: 9.65e+07 0.33784517645835876 0.5493993163108826\n",
      "[Step 7165] Loss: 9.69e+07 0.337863564491272 0.5494092106819153\n",
      "[Step 7166] Loss: 9.60e+07 0.33778631687164307 0.5494083762168884\n",
      "[Step 7167] Loss: 9.74e+07 0.33763280510902405 0.5493555665016174\n",
      "[Step 7168] Loss: 9.71e+07 0.3374638557434082 0.5492763519287109\n",
      "[Step 7169] Loss: 9.67e+07 0.337321013212204 0.5492466688156128\n",
      "[Step 7170] Loss: 9.62e+07 0.33709022402763367 0.5491913557052612\n",
      "[Step 7171] Loss: 9.68e+07 0.33674681186676025 0.5490857362747192\n",
      "[Step 7172] Loss: 9.69e+07 0.336465984582901 0.5490164160728455\n",
      "[Step 7173] Loss: 9.67e+07 0.3362516462802887 0.5489429831504822\n",
      "[Step 7174] Loss: 9.72e+07 0.33594152331352234 0.5488712191581726\n",
      "[Step 7175] Loss: 9.65e+07 0.335629940032959 0.5487796068191528\n",
      "[Step 7176] Loss: 9.66e+07 0.33534884452819824 0.5486814379692078\n",
      "[Step 7177] Loss: 9.66e+07 0.3350813686847687 0.548603892326355\n",
      "[Step 7178] Loss: 9.71e+07 0.3349044919013977 0.5485411286354065\n",
      "[Step 7179] Loss: 9.62e+07 0.3346576690673828 0.5484784245491028\n",
      "[Step 7180] Loss: 9.61e+07 0.334398090839386 0.5483877062797546\n",
      "[Step 7181] Loss: 9.60e+07 0.33411166071891785 0.5483109354972839\n",
      "[Step 7182] Loss: 9.70e+07 0.3336966335773468 0.5482226610183716\n",
      "[Step 7183] Loss: 9.64e+07 0.33329838514328003 0.5481038093566895\n",
      "[Step 7184] Loss: 9.62e+07 0.332912802696228 0.5480287671089172\n",
      "[Step 7185] Loss: 9.62e+07 0.33263567090034485 0.5479495525360107\n",
      "[Step 7186] Loss: 9.62e+07 0.3323512077331543 0.5478925704956055\n",
      "[Step 7187] Loss: 9.63e+07 0.33216601610183716 0.5478018522262573\n",
      "[Step 7188] Loss: 9.65e+07 0.33204689621925354 0.547767162322998\n",
      "[Step 7189] Loss: 9.61e+07 0.33195096254348755 0.547744870185852\n",
      "[Step 7190] Loss: 9.65e+07 0.33192288875579834 0.5477333664894104\n",
      "[Step 7191] Loss: 9.56e+07 0.3318423330783844 0.5477003455162048\n",
      "[Step 7192] Loss: 9.63e+07 0.3318100869655609 0.5477044582366943\n",
      "[Step 7193] Loss: 9.67e+07 0.33181726932525635 0.5476664900779724\n",
      "[Step 7194] Loss: 9.73e+07 0.3319629430770874 0.5476871132850647\n",
      "[Step 7195] Loss: 9.72e+07 0.3321119546890259 0.547714352607727\n",
      "[Step 7196] Loss: 9.61e+07 0.3321726620197296 0.5477168560028076\n",
      "[Step 7197] Loss: 9.59e+07 0.33227142691612244 0.5477341413497925\n",
      "[Step 7198] Loss: 9.70e+07 0.33244869112968445 0.547767162322998\n",
      "[Step 7199] Loss: 9.72e+07 0.3326674699783325 0.5478389859199524\n",
      "[Step 7200] Loss: 9.81e+07 0.33275118470191956 0.5478983521461487\n",
      "[Step 7201] Loss: 9.64e+07 0.33278757333755493 0.547918975353241\n",
      "[Step 7202] Loss: 9.76e+07 0.332699716091156 0.5479049682617188\n",
      "[Step 7203] Loss: 9.65e+07 0.33260270953178406 0.5478711128234863\n",
      "[Step 7204] Loss: 9.70e+07 0.33240267634391785 0.5478249192237854\n",
      "[Step 7205] Loss: 9.70e+07 0.33224743604660034 0.5477820038795471\n",
      "[Step 7206] Loss: 9.67e+07 0.33200085163116455 0.547706127166748\n",
      "[Step 7207] Loss: 9.58e+07 0.33179205656051636 0.5476780533790588\n",
      "[Step 7208] Loss: 9.62e+07 0.3315511643886566 0.5476104021072388\n",
      "[Step 7209] Loss: 9.76e+07 0.33146169781684875 0.5475930571556091\n",
      "[Step 7210] Loss: 9.61e+07 0.33144208788871765 0.5476104021072388\n",
      "[Step 7211] Loss: 9.63e+07 0.33141016960144043 0.5476178526878357\n",
      "[Step 7212] Loss: 9.70e+07 0.3312924802303314 0.5475732684135437\n",
      "[Step 7213] Loss: 9.62e+07 0.33128058910369873 0.5475823283195496\n",
      "[Step 7214] Loss: 9.63e+07 0.3313075006008148 0.5476046204566956\n",
      "[Step 7215] Loss: 9.72e+07 0.3312282860279083 0.5475658178329468\n",
      "[Step 7216] Loss: 9.66e+07 0.33113184571266174 0.5475378036499023\n",
      "[Step 7217] Loss: 9.67e+07 0.3310827910900116 0.5475262403488159\n",
      "[Step 7218] Loss: 9.66e+07 0.3310636579990387 0.5475171804428101\n",
      "[Step 7219] Loss: 9.63e+07 0.33104124665260315 0.5475204586982727\n",
      "[Step 7220] Loss: 9.70e+07 0.33108291029930115 0.5475451946258545\n",
      "[Step 7221] Loss: 9.63e+07 0.3311529755592346 0.5475782155990601\n",
      "[Step 7222] Loss: 9.63e+07 0.33113566040992737 0.5476078987121582\n",
      "[Step 7223] Loss: 9.61e+07 0.33107537031173706 0.5475848317146301\n",
      "[Step 7224] Loss: 9.65e+07 0.3309342861175537 0.5475427508354187\n",
      "[Step 7225] Loss: 9.70e+07 0.33066290616989136 0.5474693179130554\n",
      "[Step 7226] Loss: 9.83e+07 0.33025890588760376 0.5473545789718628\n",
      "[Step 7227] Loss: 9.71e+07 0.32985013723373413 0.5472332835197449\n",
      "[Step 7228] Loss: 9.70e+07 0.3293822109699249 0.5470848083496094\n",
      "[Step 7229] Loss: 9.76e+07 0.3288412094116211 0.5469618439674377\n",
      "[Step 7230] Loss: 9.69e+07 0.32842162251472473 0.546854555606842\n",
      "[Step 7231] Loss: 9.71e+07 0.32800912857055664 0.546786904335022\n",
      "[Step 7232] Loss: 9.68e+07 0.32763585448265076 0.5466788411140442\n",
      "[Step 7233] Loss: 9.64e+07 0.32732343673706055 0.5465633273124695\n",
      "[Step 7234] Loss: 9.66e+07 0.32703688740730286 0.5464659333229065\n",
      "[Step 7235] Loss: 9.66e+07 0.32675981521606445 0.5463966131210327\n",
      "[Step 7236] Loss: 9.64e+07 0.3265019655227661 0.5463306307792664\n",
      "[Step 7237] Loss: 9.65e+07 0.32626816630363464 0.5462827682495117\n",
      "[Step 7238] Loss: 9.66e+07 0.32616525888442993 0.5462744832038879\n",
      "[Step 7239] Loss: 9.63e+07 0.32611027359962463 0.5462514162063599\n",
      "[Step 7240] Loss: 9.67e+07 0.3259924054145813 0.5461961030960083\n",
      "[Step 7241] Loss: 9.64e+07 0.32589831948280334 0.5461845397949219\n",
      "[Step 7242] Loss: 9.65e+07 0.3258481025695801 0.5461746454238892\n",
      "[Step 7243] Loss: 9.68e+07 0.32573401927948 0.5461614727973938\n",
      "[Step 7244] Loss: 9.70e+07 0.32571759819984436 0.5461424589157104\n",
      "[Step 7245] Loss: 9.64e+07 0.3257386088371277 0.546167254447937\n",
      "[Step 7246] Loss: 9.84e+07 0.32556384801864624 0.5461020469665527\n",
      "[Step 7247] Loss: 9.57e+07 0.3253907561302185 0.5460582971572876\n",
      "[Step 7248] Loss: 9.64e+07 0.3252260982990265 0.5460426211357117\n",
      "[Step 7249] Loss: 9.62e+07 0.3250167667865753 0.5459997057914734\n",
      "[Step 7250] Loss: 9.64e+07 0.32480376958847046 0.5459667444229126\n",
      "[Step 7251] Loss: 9.75e+07 0.3246207535266876 0.5459320545196533\n",
      "[Step 7252] Loss: 9.72e+07 0.32442039251327515 0.5458768010139465\n",
      "[Step 7253] Loss: 9.65e+07 0.3241831362247467 0.5458025336265564\n",
      "[Step 7254] Loss: 9.65e+07 0.3239791989326477 0.5457257628440857\n",
      "[Step 7255] Loss: 9.72e+07 0.32382437586784363 0.5456432700157166\n",
      "[Step 7256] Loss: 9.71e+07 0.32371681928634644 0.5456284284591675\n",
      "[Step 7257] Loss: 9.73e+07 0.32373932003974915 0.5455986857414246\n",
      "[Step 7258] Loss: 9.72e+07 0.3236142694950104 0.5455665588378906\n",
      "[Step 7259] Loss: 9.68e+07 0.32354605197906494 0.5455549955368042\n",
      "[Step 7260] Loss: 9.73e+07 0.32332155108451843 0.5454766154289246\n",
      "[Step 7261] Loss: 9.67e+07 0.3230988681316376 0.5453948974609375\n",
      "[Step 7262] Loss: 9.61e+07 0.3228306472301483 0.5453197956085205\n",
      "[Step 7263] Loss: 9.78e+07 0.32247766852378845 0.5452199578285217\n",
      "[Step 7264] Loss: 9.64e+07 0.32215869426727295 0.5450921058654785\n",
      "[Step 7265] Loss: 9.64e+07 0.32193171977996826 0.5450252294540405\n",
      "[Step 7266] Loss: 9.67e+07 0.32167649269104004 0.5449592471122742\n",
      "[Step 7267] Loss: 9.66e+07 0.32144689559936523 0.5448948740959167\n",
      "[Step 7268] Loss: 9.69e+07 0.32142630219459534 0.5448684692382812\n",
      "[Step 7269] Loss: 9.61e+07 0.3214482367038727 0.5448437333106995\n",
      "[Step 7270] Loss: 9.65e+07 0.321407288312912 0.5448214411735535\n",
      "[Step 7271] Loss: 9.73e+07 0.32133588194847107 0.5447917580604553\n",
      "[Step 7272] Loss: 9.57e+07 0.3212333917617798 0.5447480082511902\n",
      "[Step 7273] Loss: 9.69e+07 0.32107627391815186 0.5446968674659729\n",
      "[Step 7274] Loss: 9.74e+07 0.3208545744419098 0.5446497797966003\n",
      "[Step 7275] Loss: 9.64e+07 0.3206791281700134 0.544583797454834\n",
      "[Step 7276] Loss: 9.67e+07 0.32057371735572815 0.544553279876709\n",
      "[Step 7277] Loss: 9.60e+07 0.3204774856567383 0.5445054173469543\n",
      "[Step 7278] Loss: 9.67e+07 0.32040899991989136 0.5444740653038025\n",
      "[Step 7279] Loss: 9.66e+07 0.32033801078796387 0.5444451570510864\n",
      "[Step 7280] Loss: 9.75e+07 0.3201347589492798 0.5443849563598633\n",
      "[Step 7281] Loss: 9.64e+07 0.31996893882751465 0.5443222522735596\n",
      "[Step 7282] Loss: 9.66e+07 0.31983256340026855 0.5442900657653809\n",
      "[Step 7283] Loss: 9.66e+07 0.31965500116348267 0.5442438125610352\n",
      "[Step 7284] Loss: 9.65e+07 0.3195193409919739 0.5442298054695129\n",
      "[Step 7285] Loss: 9.66e+07 0.3194655776023865 0.5441902279853821\n",
      "[Step 7286] Loss: 9.61e+07 0.3193315267562866 0.5441456437110901\n",
      "[Step 7287] Loss: 9.56e+07 0.3192758560180664 0.5441638231277466\n",
      "[Step 7288] Loss: 9.66e+07 0.3193295896053314 0.5441960096359253\n",
      "[Step 7289] Loss: 9.70e+07 0.3192242980003357 0.5441621541976929\n",
      "[Step 7290] Loss: 9.76e+07 0.3189520835876465 0.544101893901825\n",
      "[Step 7291] Loss: 9.63e+07 0.3187815546989441 0.5440639853477478\n",
      "[Step 7292] Loss: 9.60e+07 0.3186216354370117 0.5440375804901123\n",
      "[Step 7293] Loss: 9.61e+07 0.31844767928123474 0.5440045595169067\n",
      "[Step 7294] Loss: 9.76e+07 0.31817230582237244 0.5439715385437012\n",
      "[Step 7295] Loss: 9.77e+07 0.3179149627685547 0.5439261794090271\n",
      "[Step 7296] Loss: 9.67e+07 0.3176390528678894 0.5438626408576965\n",
      "[Step 7297] Loss: 9.75e+07 0.3172801733016968 0.5437842607498169\n",
      "[Step 7298] Loss: 9.64e+07 0.31691810488700867 0.5437149405479431\n",
      "[Step 7299] Loss: 9.64e+07 0.31657594442367554 0.5436241626739502\n",
      "[Step 7300] Loss: 9.71e+07 0.31619206070899963 0.543535053730011\n",
      "[Step 7301] Loss: 9.73e+07 0.3159268796443939 0.5434921383857727\n",
      "[Step 7302] Loss: 9.76e+07 0.3155772387981415 0.543376624584198\n",
      "[Step 7303] Loss: 9.63e+07 0.3152409791946411 0.5432957410812378\n",
      "[Step 7304] Loss: 9.61e+07 0.3149603009223938 0.5432214736938477\n",
      "[Step 7305] Loss: 9.69e+07 0.314678430557251 0.5431406497955322\n",
      "[Step 7306] Loss: 9.73e+07 0.3145698308944702 0.5430919528007507\n",
      "[Step 7307] Loss: 9.64e+07 0.3144007623195648 0.5430457592010498\n",
      "[Step 7308] Loss: 9.77e+07 0.3142087459564209 0.5429533123970032\n",
      "[Step 7309] Loss: 9.71e+07 0.31402525305747986 0.5428815484046936\n",
      "[Step 7310] Loss: 9.61e+07 0.3138504922389984 0.5428229570388794\n",
      "[Step 7311] Loss: 9.73e+07 0.3136139512062073 0.5427684783935547\n",
      "[Step 7312] Loss: 9.60e+07 0.31337055563926697 0.5427156686782837\n",
      "[Step 7313] Loss: 9.64e+07 0.3131037652492523 0.542644739151001\n",
      "[Step 7314] Loss: 9.66e+07 0.3128962218761444 0.542606770992279\n",
      "[Step 7315] Loss: 9.62e+07 0.31270360946655273 0.5425704717636108\n",
      "[Step 7316] Loss: 9.59e+07 0.31253182888031006 0.5425036549568176\n",
      "[Step 7317] Loss: 9.61e+07 0.31243157386779785 0.5424796938896179\n",
      "[Step 7318] Loss: 9.81e+07 0.312165766954422 0.5423864722251892\n",
      "[Step 7319] Loss: 9.57e+07 0.31190451979637146 0.5422725677490234\n",
      "[Step 7320] Loss: 9.67e+07 0.3116180896759033 0.5421875715255737\n",
      "[Step 7321] Loss: 9.68e+07 0.3112625479698181 0.5420696139335632\n",
      "[Step 7322] Loss: 9.65e+07 0.311017245054245 0.5420390963554382\n",
      "[Step 7323] Loss: 9.75e+07 0.31060686707496643 0.541949987411499\n",
      "[Step 7324] Loss: 9.64e+07 0.310354083776474 0.5419161319732666\n",
      "[Step 7325] Loss: 9.57e+07 0.31008481979370117 0.5418715476989746\n",
      "[Step 7326] Loss: 9.63e+07 0.3098321259021759 0.5417956709861755\n",
      "[Step 7327] Loss: 9.68e+07 0.3096270263195038 0.541732132434845\n",
      "[Step 7328] Loss: 9.71e+07 0.30937284231185913 0.5416842699050903\n",
      "[Step 7329] Loss: 9.65e+07 0.309200257062912 0.5416289567947388\n",
      "[Step 7330] Loss: 9.67e+07 0.3090600073337555 0.5415769815444946\n",
      "[Step 7331] Loss: 9.60e+07 0.30892473459243774 0.541520893573761\n",
      "[Step 7332] Loss: 9.59e+07 0.308800607919693 0.5414854288101196\n",
      "[Step 7333] Loss: 9.61e+07 0.3086554706096649 0.5414779782295227\n",
      "[Step 7334] Loss: 9.69e+07 0.30853399634361267 0.5414697527885437\n",
      "[Step 7335] Loss: 9.62e+07 0.3084547519683838 0.5414317846298218\n",
      "[Step 7336] Loss: 9.60e+07 0.30835679173469543 0.5414169430732727\n",
      "[Step 7337] Loss: 9.67e+07 0.30829668045043945 0.5414078235626221\n",
      "[Step 7338] Loss: 9.74e+07 0.3081245720386505 0.5413641333580017\n",
      "[Step 7339] Loss: 9.61e+07 0.3079984486103058 0.5413079857826233\n",
      "[Step 7340] Loss: 9.60e+07 0.3079100251197815 0.5412980914115906\n",
      "[Step 7341] Loss: 9.68e+07 0.307815283536911 0.5412733554840088\n",
      "[Step 7342] Loss: 9.64e+07 0.3077322840690613 0.5412634611129761\n",
      "[Step 7343] Loss: 9.66e+07 0.30758053064346313 0.5412378907203674\n",
      "[Step 7344] Loss: 9.67e+07 0.307591050863266 0.5412518978118896\n",
      "[Step 7345] Loss: 9.68e+07 0.3074674904346466 0.5412081480026245\n",
      "[Step 7346] Loss: 9.66e+07 0.30737075209617615 0.5412130951881409\n",
      "[Step 7347] Loss: 9.65e+07 0.3073318600654602 0.5411875247955322\n",
      "[Step 7348] Loss: 9.60e+07 0.3072730302810669 0.541181743144989\n",
      "[Step 7349] Loss: 9.68e+07 0.30719342827796936 0.5411495566368103\n",
      "[Step 7350] Loss: 9.77e+07 0.30695047974586487 0.541067898273468\n",
      "[Step 7351] Loss: 9.64e+07 0.306782603263855 0.5410290956497192\n",
      "[Step 7352] Loss: 9.68e+07 0.30662789940834045 0.540970504283905\n",
      "[Step 7353] Loss: 9.75e+07 0.30643147230148315 0.5408995747566223\n",
      "[Step 7354] Loss: 9.98e+07 0.3065142333507538 0.5409127473831177\n",
      "[Step 7355] Loss: 9.64e+07 0.30657386779785156 0.5409259796142578\n",
      "[Step 7356] Loss: 9.65e+07 0.30658382177352905 0.5408962368965149\n",
      "[Step 7357] Loss: 9.71e+07 0.3065524697303772 0.5408921241760254\n",
      "[Step 7358] Loss: 9.70e+07 0.30649441480636597 0.5408756136894226\n",
      "[Step 7359] Loss: 9.61e+07 0.3064025044441223 0.5408475995063782\n",
      "[Step 7360] Loss: 9.65e+07 0.3063548803329468 0.5408178567886353\n",
      "[Step 7361] Loss: 9.70e+07 0.30634158849716187 0.5408013463020325\n",
      "[Step 7362] Loss: 9.72e+07 0.30640709400177 0.5408228039741516\n",
      "[Step 7363] Loss: 9.69e+07 0.3065260946750641 0.5408591032028198\n",
      "[Step 7364] Loss: 9.63e+07 0.30660027265548706 0.5408756136894226\n",
      "[Step 7365] Loss: 9.61e+07 0.30673161149024963 0.5409004092216492\n",
      "[Step 7366] Loss: 9.72e+07 0.3067920207977295 0.5408690571784973\n",
      "[Step 7367] Loss: 9.64e+07 0.306888222694397 0.5408912897109985\n",
      "[Step 7368] Loss: 9.72e+07 0.30711251497268677 0.5409036874771118\n",
      "[Step 7369] Loss: 9.67e+07 0.3072233200073242 0.5409111380577087\n",
      "[Step 7370] Loss: 9.71e+07 0.3072763681411743 0.5409243106842041\n",
      "[Step 7371] Loss: 9.65e+07 0.3073081374168396 0.540931761264801\n",
      "[Step 7372] Loss: 9.67e+07 0.3073635995388031 0.5409309267997742\n",
      "[Step 7373] Loss: 9.62e+07 0.30739450454711914 0.540925145149231\n",
      "[Step 7374] Loss: 9.75e+07 0.30749765038490295 0.540917694568634\n",
      "[Step 7375] Loss: 9.73e+07 0.3076106309890747 0.5409548282623291\n",
      "[Step 7376] Loss: 9.67e+07 0.3077765107154846 0.5409919619560242\n",
      "[Step 7377] Loss: 9.65e+07 0.3079545795917511 0.5410522222518921\n",
      "[Step 7378] Loss: 9.69e+07 0.30803269147872925 0.5410513877868652\n",
      "[Step 7379] Loss: 9.63e+07 0.3081042468547821 0.5410769581794739\n",
      "[Step 7380] Loss: 9.68e+07 0.3081224858760834 0.5410588383674622\n",
      "[Step 7381] Loss: 9.63e+07 0.30820974707603455 0.5410481095314026\n",
      "[Step 7382] Loss: 9.63e+07 0.3082432150840759 0.5410571694374084\n",
      "[Step 7383] Loss: 9.83e+07 0.3081257939338684 0.5409994125366211\n",
      "[Step 7384] Loss: 9.54e+07 0.3080790340900421 0.540986180305481\n",
      "[Step 7385] Loss: 9.58e+07 0.30806514620780945 0.5409515500068665\n",
      "[Step 7386] Loss: 9.70e+07 0.30799371004104614 0.5409111380577087\n",
      "[Step 7387] Loss: 9.74e+07 0.30800148844718933 0.5409284234046936\n",
      "[Step 7388] Loss: 9.75e+07 0.30792486667633057 0.5409210324287415\n",
      "[Step 7389] Loss: 9.58e+07 0.3078172206878662 0.5409036874771118\n",
      "[Step 7390] Loss: 9.62e+07 0.3077165186405182 0.5408731698989868\n",
      "[Step 7391] Loss: 9.56e+07 0.30763956904411316 0.5408541560173035\n",
      "[Step 7392] Loss: 9.67e+07 0.3075447678565979 0.5408310890197754\n",
      "[Step 7393] Loss: 9.69e+07 0.30748480558395386 0.5408079624176025\n",
      "[Step 7394] Loss: 9.71e+07 0.3073539137840271 0.5407832264900208\n",
      "[Step 7395] Loss: 9.66e+07 0.3073352873325348 0.5407955646514893\n",
      "[Step 7396] Loss: 9.63e+07 0.30732056498527527 0.5407906174659729\n",
      "[Step 7397] Loss: 9.72e+07 0.30741578340530396 0.5407922863960266\n",
      "[Step 7398] Loss: 9.70e+07 0.3076308071613312 0.540827751159668\n",
      "[Step 7399] Loss: 9.61e+07 0.30780866742134094 0.5408781170845032\n",
      "[Step 7400] Loss: 9.68e+07 0.30793318152427673 0.5408838987350464\n",
      "[Step 7401] Loss: 9.72e+07 0.30801403522491455 0.5408740043640137\n",
      "[Step 7402] Loss: 9.54e+07 0.3081126809120178 0.5409127473831177\n",
      "[Step 7403] Loss: 9.67e+07 0.3081139624118805 0.5409078001976013\n",
      "[Step 7404] Loss: 9.63e+07 0.3080528676509857 0.5408921241760254\n",
      "[Step 7405] Loss: 9.72e+07 0.3081159293651581 0.540931761264801\n",
      "[Step 7406] Loss: 9.61e+07 0.3081696033477783 0.5409482717514038\n",
      "[Step 7407] Loss: 9.74e+07 0.3083171546459198 0.5409746170043945\n",
      "[Step 7408] Loss: 9.63e+07 0.3084791600704193 0.5410241484642029\n",
      "[Step 7409] Loss: 9.76e+07 0.308491587638855 0.5410357117652893\n",
      "[Step 7410] Loss: 9.69e+07 0.30839139223098755 0.541030764579773\n",
      "[Step 7411] Loss: 9.64e+07 0.3083011209964752 0.5410035252571106\n",
      "[Step 7412] Loss: 9.68e+07 0.30826592445373535 0.5409746170043945\n",
      "[Step 7413] Loss: 9.61e+07 0.30823150277137756 0.5409597754478455\n",
      "[Step 7414] Loss: 9.76e+07 0.30823689699172974 0.5409878492355347\n",
      "[Step 7415] Loss: 9.68e+07 0.3083234429359436 0.5409911274909973\n",
      "[Step 7416] Loss: 9.64e+07 0.3083571791648865 0.5410076379776001\n",
      "[Step 7417] Loss: 9.64e+07 0.3083392381668091 0.5409903526306152\n",
      "[Step 7418] Loss: 9.75e+07 0.3084336221218109 0.5410125851631165\n",
      "[Step 7419] Loss: 9.69e+07 0.308509886264801 0.541008472442627\n",
      "[Step 7420] Loss: 9.74e+07 0.30863502621650696 0.5410274267196655\n",
      "[Step 7421] Loss: 9.69e+07 0.30874237418174744 0.5410563349723816\n",
      "[Step 7422] Loss: 9.58e+07 0.30883026123046875 0.5410777926445007\n",
      "[Step 7423] Loss: 9.60e+07 0.3089219331741333 0.5410934686660767\n",
      "[Step 7424] Loss: 9.54e+07 0.3090006709098816 0.5410909652709961\n",
      "[Step 7425] Loss: 9.66e+07 0.3090400993824005 0.541083574295044\n",
      "[Step 7426] Loss: 9.65e+07 0.30904263257980347 0.5410926342010498\n",
      "[Step 7427] Loss: 9.66e+07 0.3091239631175995 0.5411099791526794\n",
      "[Step 7428] Loss: 9.60e+07 0.30922651290893555 0.5411256551742554\n",
      "[Step 7429] Loss: 9.60e+07 0.30932119488716125 0.5411404967308044\n",
      "[Step 7430] Loss: 9.69e+07 0.30950433015823364 0.5411834120750427\n",
      "[Step 7431] Loss: 9.68e+07 0.30971837043762207 0.5412444472312927\n",
      "[Step 7432] Loss: 9.68e+07 0.3099484145641327 0.5412766337394714\n",
      "[Step 7433] Loss: 9.60e+07 0.31021764874458313 0.5413343906402588\n",
      "[Step 7434] Loss: 9.71e+07 0.31058335304260254 0.5414384007453918\n",
      "[Step 7435] Loss: 9.58e+07 0.3108741044998169 0.5415357351303101\n",
      "[Step 7436] Loss: 9.63e+07 0.3111703395843506 0.5415918231010437\n",
      "[Step 7437] Loss: 9.68e+07 0.3115067780017853 0.5416677594184875\n",
      "[Step 7438] Loss: 9.65e+07 0.31182458996772766 0.5417502522468567\n",
      "[Step 7439] Loss: 9.68e+07 0.3121229112148285 0.5418418645858765\n",
      "[Step 7440] Loss: 9.61e+07 0.31235426664352417 0.5419235825538635\n",
      "[Step 7441] Loss: 9.64e+07 0.31255042552948 0.5419631600379944\n",
      "[Step 7442] Loss: 9.76e+07 0.31268468499183655 0.5420225858688354\n",
      "[Step 7443] Loss: 9.69e+07 0.3126961886882782 0.5420613288879395\n",
      "[Step 7444] Loss: 9.61e+07 0.3125942647457123 0.5420539379119873\n",
      "[Step 7445] Loss: 9.59e+07 0.3125039041042328 0.5420118570327759\n",
      "[Step 7446] Loss: 9.57e+07 0.3123842179775238 0.5419796705245972\n",
      "[Step 7447] Loss: 9.63e+07 0.31223663687705994 0.5419161319732666\n",
      "[Step 7448] Loss: 9.70e+07 0.31217458844184875 0.5419152975082397\n",
      "[Step 7449] Loss: 9.62e+07 0.31211429834365845 0.541929304599762\n",
      "[Step 7450] Loss: 9.64e+07 0.3120419979095459 0.541912853717804\n",
      "[Step 7451] Loss: 9.78e+07 0.31173381209373474 0.5418476462364197\n",
      "[Step 7452] Loss: 9.65e+07 0.31137099862098694 0.5417602062225342\n",
      "[Step 7453] Loss: 9.68e+07 0.3110119104385376 0.5416735410690308\n",
      "[Step 7454] Loss: 9.67e+07 0.3106493353843689 0.5415852665901184\n",
      "[Step 7455] Loss: 9.62e+07 0.31028735637664795 0.5414540767669678\n",
      "[Step 7456] Loss: 9.72e+07 0.30987364053726196 0.5413377285003662\n",
      "[Step 7457] Loss: 9.71e+07 0.3093828856945038 0.5412015318870544\n",
      "[Step 7458] Loss: 9.85e+07 0.3087223172187805 0.5410134196281433\n",
      "[Step 7459] Loss: 9.71e+07 0.30807995796203613 0.5408170223236084\n",
      "[Step 7460] Loss: 9.68e+07 0.3075176179409027 0.5406660437583923\n",
      "[Step 7461] Loss: 9.74e+07 0.3068358302116394 0.5404754281044006\n",
      "[Step 7462] Loss: 9.68e+07 0.3060881197452545 0.5402469038963318\n",
      "[Step 7463] Loss: 9.60e+07 0.3054066598415375 0.5400537848472595\n",
      "[Step 7464] Loss: 9.67e+07 0.30473482608795166 0.5398953557014465\n",
      "[Step 7465] Loss: 9.57e+07 0.30407071113586426 0.5397253632545471\n",
      "[Step 7466] Loss: 9.68e+07 0.3034974932670593 0.5396040678024292\n",
      "[Step 7467] Loss: 9.57e+07 0.30300962924957275 0.5394720435142517\n",
      "[Step 7468] Loss: 9.72e+07 0.3024325668811798 0.5393573641777039\n",
      "[Step 7469] Loss: 9.60e+07 0.30186837911605835 0.5392418503761292\n",
      "[Step 7470] Loss: 9.57e+07 0.3013196289539337 0.5391188859939575\n",
      "[Step 7471] Loss: 9.66e+07 0.3008311688899994 0.5390099883079529\n",
      "[Step 7472] Loss: 9.63e+07 0.3004263639450073 0.5389093160629272\n",
      "[Step 7473] Loss: 9.74e+07 0.299922376871109 0.5387806296348572\n",
      "[Step 7474] Loss: 9.82e+07 0.29929736256599426 0.538600742816925\n",
      "[Step 7475] Loss: 9.64e+07 0.29874223470687866 0.5384810566902161\n",
      "[Step 7476] Loss: 9.63e+07 0.29830649495124817 0.5383647680282593\n",
      "[Step 7477] Loss: 9.80e+07 0.2980589270591736 0.5383242964744568\n",
      "[Step 7478] Loss: 9.60e+07 0.2978765666484833 0.5382591485977173\n",
      "[Step 7479] Loss: 9.72e+07 0.2978166341781616 0.5382302403450012\n",
      "[Step 7480] Loss: 9.61e+07 0.2977391183376312 0.5381997227668762\n",
      "[Step 7481] Loss: 9.59e+07 0.29764243960380554 0.5381823778152466\n",
      "[Step 7482] Loss: 9.61e+07 0.2976360321044922 0.5381609201431274\n",
      "[Step 7483] Loss: 9.65e+07 0.2976677119731903 0.5381699800491333\n",
      "[Step 7484] Loss: 9.61e+07 0.29766443371772766 0.5381658673286438\n",
      "[Step 7485] Loss: 9.60e+07 0.2976781725883484 0.5381600856781006\n",
      "[Step 7486] Loss: 9.62e+07 0.2976476848125458 0.5381444096565247\n",
      "[Step 7487] Loss: 9.64e+07 0.29755520820617676 0.5381295680999756\n",
      "[Step 7488] Loss: 9.61e+07 0.2975284159183502 0.5381221771240234\n",
      "[Step 7489] Loss: 9.67e+07 0.2974746525287628 0.5380833745002747\n",
      "[Step 7490] Loss: 9.72e+07 0.2973465025424957 0.5380520224571228\n",
      "[Step 7491] Loss: 9.76e+07 0.29710081219673157 0.5379843711853027\n",
      "[Step 7492] Loss: 9.63e+07 0.29689183831214905 0.5379133820533752\n",
      "[Step 7493] Loss: 9.64e+07 0.29669666290283203 0.5378646850585938\n",
      "[Step 7494] Loss: 9.61e+07 0.29652994871139526 0.5377821922302246\n",
      "[Step 7495] Loss: 9.67e+07 0.29649436473846436 0.5377508401870728\n",
      "[Step 7496] Loss: 9.64e+07 0.2965114712715149 0.5377401113510132\n",
      "[Step 7497] Loss: 9.64e+07 0.2964976727962494 0.5377417802810669\n",
      "[Step 7498] Loss: 9.63e+07 0.2965088188648224 0.5377376079559326\n",
      "[Step 7499] Loss: 9.62e+07 0.29657891392707825 0.5377739667892456\n",
      "[Step 7500] Loss: 9.60e+07 0.2965874969959259 0.5377879738807678\n",
      "[Step 7501] Loss: 9.69e+07 0.29666024446487427 0.5378135442733765\n",
      "[Step 7502] Loss: 9.63e+07 0.2966770529747009 0.53780198097229\n",
      "[Step 7503] Loss: 9.64e+07 0.2966673672199249 0.5378036499023438\n",
      "[Step 7504] Loss: 9.58e+07 0.29669275879859924 0.537817656993866\n",
      "[Step 7505] Loss: 9.60e+07 0.2967882454395294 0.5378655195236206\n",
      "[Step 7506] Loss: 9.58e+07 0.2968901991844177 0.537868857383728\n",
      "[Step 7507] Loss: 9.67e+07 0.2970823347568512 0.537921667098999\n",
      "[Step 7508] Loss: 9.61e+07 0.2972906827926636 0.5379876494407654\n",
      "[Step 7509] Loss: 9.62e+07 0.29735299944877625 0.5379801988601685\n",
      "[Step 7510] Loss: 9.61e+07 0.29740196466445923 0.5379893183708191\n",
      "[Step 7511] Loss: 9.63e+07 0.29756131768226624 0.5380190014839172\n",
      "[Step 7512] Loss: 9.60e+07 0.2977590560913086 0.5380842089653015\n",
      "[Step 7513] Loss: 9.65e+07 0.29797059297561646 0.538149356842041\n",
      "[Step 7514] Loss: 9.64e+07 0.2981104850769043 0.5381864905357361\n",
      "[Step 7515] Loss: 9.72e+07 0.2983441650867462 0.5382500290870667\n",
      "[Step 7516] Loss: 9.66e+07 0.29864445328712463 0.5383680462837219\n",
      "[Step 7517] Loss: 9.69e+07 0.29882434010505676 0.5384035110473633\n",
      "[Step 7518] Loss: 9.75e+07 0.29887810349464417 0.5384076237678528\n",
      "[Step 7519] Loss: 9.65e+07 0.29898107051849365 0.5384497046470642\n",
      "[Step 7520] Loss: 9.66e+07 0.2991200089454651 0.5384951233863831\n",
      "[Step 7521] Loss: 9.80e+07 0.2993864119052887 0.5385429859161377\n",
      "[Step 7522] Loss: 9.71e+07 0.2995908558368683 0.5385990738868713\n",
      "[Step 7523] Loss: 9.68e+07 0.2998615801334381 0.538669228553772\n",
      "[Step 7524] Loss: 9.72e+07 0.30019962787628174 0.5387632846832275\n",
      "[Step 7525] Loss: 9.67e+07 0.3004223704338074 0.538760781288147\n",
      "[Step 7526] Loss: 9.60e+07 0.300613135099411 0.538797914981842\n",
      "[Step 7527] Loss: 9.70e+07 0.30084285140037537 0.5388622879981995\n",
      "[Step 7528] Loss: 9.71e+07 0.30114415287971497 0.5389382243156433\n",
      "[Step 7529] Loss: 9.79e+07 0.30152785778045654 0.5390256643295288\n",
      "[Step 7530] Loss: 9.58e+07 0.3019334077835083 0.5391519069671631\n",
      "[Step 7531] Loss: 9.63e+07 0.3022878170013428 0.5392195582389832\n",
      "[Step 7532] Loss: 9.62e+07 0.3025951683521271 0.5392996072769165\n",
      "[Step 7533] Loss: 9.59e+07 0.3029024600982666 0.5393978357315063\n",
      "[Step 7534] Loss: 9.65e+07 0.30310073494911194 0.5394663214683533\n",
      "[Step 7535] Loss: 9.79e+07 0.3030814528465271 0.5394209027290344\n",
      "[Step 7536] Loss: 9.69e+07 0.30309638381004333 0.5394275188446045\n",
      "[Step 7537] Loss: 9.59e+07 0.3030919134616852 0.5394250154495239\n",
      "[Step 7538] Loss: 9.70e+07 0.30302199721336365 0.5394142866134644\n",
      "[Step 7539] Loss: 9.59e+07 0.3029575049877167 0.5393689274787903\n",
      "[Step 7540] Loss: 9.73e+07 0.30298659205436707 0.5393771529197693\n",
      "[Step 7541] Loss: 9.67e+07 0.3029292821884155 0.5393499732017517\n",
      "[Step 7542] Loss: 9.60e+07 0.30289384722709656 0.5393441915512085\n",
      "[Step 7543] Loss: 9.74e+07 0.3027231693267822 0.5393086671829224\n",
      "[Step 7544] Loss: 9.62e+07 0.30247947573661804 0.5392575263977051\n",
      "[Step 7545] Loss: 9.62e+07 0.30224403738975525 0.5392302870750427\n",
      "[Step 7546] Loss: 9.65e+07 0.30210816860198975 0.5392130017280579\n",
      "[Step 7547] Loss: 9.69e+07 0.30203405022621155 0.5392063856124878\n",
      "[Step 7548] Loss: 9.68e+07 0.30197378993034363 0.5391956567764282\n",
      "[Step 7549] Loss: 9.70e+07 0.3018653094768524 0.5391667485237122\n",
      "[Step 7550] Loss: 9.66e+07 0.3017636239528656 0.5391527414321899\n",
      "[Step 7551] Loss: 9.62e+07 0.30169200897216797 0.5391544103622437\n",
      "[Step 7552] Loss: 9.64e+07 0.3015455901622772 0.5391280055046082\n",
      "[Step 7553] Loss: 9.64e+07 0.30134159326553345 0.5390883684158325\n",
      "[Step 7554] Loss: 9.67e+07 0.30126360058784485 0.539076030254364\n",
      "[Step 7555] Loss: 9.72e+07 0.3013494908809662 0.5391032099723816\n",
      "[Step 7556] Loss: 9.67e+07 0.30141493678092957 0.5391098260879517\n",
      "[Step 7557] Loss: 9.70e+07 0.3015361428260803 0.5391502976417542\n",
      "[Step 7558] Loss: 9.58e+07 0.3015674352645874 0.5391667485237122\n",
      "[Step 7559] Loss: 9.67e+07 0.3016340434551239 0.5391931533813477\n",
      "[Step 7560] Loss: 9.63e+07 0.30171138048171997 0.5392245054244995\n",
      "[Step 7561] Loss: 9.67e+07 0.3018350303173065 0.5392418503761292\n",
      "[Step 7562] Loss: 9.62e+07 0.3019508421421051 0.5392385721206665\n",
      "[Step 7563] Loss: 9.69e+07 0.30192095041275024 0.5392311215400696\n",
      "[Step 7564] Loss: 9.71e+07 0.30184289813041687 0.5391915440559387\n",
      "[Step 7565] Loss: 9.62e+07 0.3017837107181549 0.5391997694969177\n",
      "[Step 7566] Loss: 9.69e+07 0.30169013142585754 0.539167582988739\n",
      "[Step 7567] Loss: 9.66e+07 0.3015722930431366 0.5391263365745544\n",
      "[Step 7568] Loss: 9.69e+07 0.3015934228897095 0.5391280055046082\n",
      "[Step 7569] Loss: 9.63e+07 0.30168792605400085 0.5391535758972168\n",
      "[Step 7570] Loss: 9.69e+07 0.3016980290412903 0.5391436815261841\n",
      "[Step 7571] Loss: 9.69e+07 0.30175837874412537 0.5391403436660767\n",
      "[Step 7572] Loss: 9.69e+07 0.301836758852005 0.5391774773597717\n",
      "[Step 7573] Loss: 9.70e+07 0.3020639717578888 0.5392228960990906\n",
      "[Step 7574] Loss: 9.70e+07 0.30235886573791504 0.5392690896987915\n",
      "[Step 7575] Loss: 9.62e+07 0.30264919996261597 0.5393218994140625\n",
      "[Step 7576] Loss: 9.65e+07 0.30275729298591614 0.5393458008766174\n",
      "[Step 7577] Loss: 9.65e+07 0.3029305040836334 0.5393738746643066\n",
      "[Step 7578] Loss: 9.61e+07 0.3031218945980072 0.5394019484519958\n",
      "[Step 7579] Loss: 9.69e+07 0.303371399641037 0.5394275188446045\n",
      "[Step 7580] Loss: 9.68e+07 0.3036251962184906 0.5394695997238159\n",
      "[Step 7581] Loss: 9.67e+07 0.3037717640399933 0.5394861102104187\n",
      "[Step 7582] Loss: 9.64e+07 0.30398276448249817 0.5395273566246033\n",
      "[Step 7583] Loss: 9.59e+07 0.30420002341270447 0.5395867824554443\n",
      "[Step 7584] Loss: 9.77e+07 0.3042670488357544 0.5396098494529724\n",
      "[Step 7585] Loss: 9.63e+07 0.3043704926967621 0.539634644985199\n",
      "[Step 7586] Loss: 9.64e+07 0.30437466502189636 0.5396255254745483\n",
      "[Step 7587] Loss: 9.66e+07 0.304460734128952 0.5396610498428345\n",
      "[Step 7588] Loss: 9.70e+07 0.30460524559020996 0.5397014617919922\n",
      "[Step 7589] Loss: 9.68e+07 0.30480626225471497 0.53975510597229\n",
      "[Step 7590] Loss: 9.64e+07 0.3050248324871063 0.5398169755935669\n",
      "[Step 7591] Loss: 9.63e+07 0.30524832010269165 0.539891242980957\n",
      "[Step 7592] Loss: 9.71e+07 0.3055269122123718 0.5399498343467712\n",
      "[Step 7593] Loss: 9.62e+07 0.30574092268943787 0.5400117039680481\n",
      "[Step 7594] Loss: 9.70e+07 0.3059026300907135 0.5400397777557373\n",
      "[Step 7595] Loss: 9.64e+07 0.30600592494010925 0.5400620698928833\n",
      "[Step 7596] Loss: 9.59e+07 0.30603596568107605 0.5400941967964172\n",
      "[Step 7597] Loss: 9.70e+07 0.3061513304710388 0.5401404500007629\n",
      "[Step 7598] Loss: 9.76e+07 0.3063875436782837 0.540216326713562\n",
      "[Step 7599] Loss: 9.72e+07 0.3066979944705963 0.5402930974960327\n",
      "[Step 7600] Loss: 9.70e+07 0.3069297969341278 0.5403723120689392\n",
      "[Step 7601] Loss: 9.70e+07 0.3071533143520355 0.5404176712036133\n",
      "[Step 7602] Loss: 9.66e+07 0.3072908818721771 0.5404284000396729\n",
      "[Step 7603] Loss: 9.71e+07 0.30729973316192627 0.5404185056686401\n",
      "[Step 7604] Loss: 9.75e+07 0.307324081659317 0.5404341816902161\n",
      "[Step 7605] Loss: 9.73e+07 0.30740317702293396 0.5404655337333679\n",
      "[Step 7606] Loss: 9.66e+07 0.3074144721031189 0.5404523611068726\n",
      "[Step 7607] Loss: 9.68e+07 0.3073784112930298 0.5404399633407593\n",
      "[Step 7608] Loss: 9.60e+07 0.30732280015945435 0.5404201745986938\n",
      "[Step 7609] Loss: 9.74e+07 0.30718767642974854 0.5403764247894287\n",
      "[Step 7610] Loss: 9.70e+07 0.3069625198841095 0.5402988791465759\n",
      "[Step 7611] Loss: 9.66e+07 0.30671992897987366 0.5402188301086426\n",
      "[Step 7612] Loss: 9.69e+07 0.3066149055957794 0.5401973724365234\n",
      "[Step 7613] Loss: 9.62e+07 0.30656853318214417 0.5401718020439148\n",
      "[Step 7614] Loss: 9.61e+07 0.3065451681613922 0.540155291557312\n",
      "[Step 7615] Loss: 9.62e+07 0.30654576420783997 0.5401198267936707\n",
      "[Step 7616] Loss: 9.63e+07 0.30653777718544006 0.540132999420166\n",
      "[Step 7617] Loss: 9.65e+07 0.30653566122055054 0.5401156544685364\n",
      "[Step 7618] Loss: 9.63e+07 0.30649396777153015 0.540080189704895\n",
      "[Step 7619] Loss: 9.65e+07 0.3063734471797943 0.5400604009628296\n",
      "[Step 7620] Loss: 9.84e+07 0.3060322701931 0.5399795174598694\n",
      "[Step 7621] Loss: 9.64e+07 0.30572181940078735 0.539906919002533\n",
      "[Step 7622] Loss: 9.66e+07 0.3054262101650238 0.5398070812225342\n",
      "[Step 7623] Loss: 9.65e+07 0.3052344024181366 0.539741039276123\n",
      "[Step 7624] Loss: 9.75e+07 0.30499666929244995 0.539688229560852\n",
      "[Step 7625] Loss: 9.62e+07 0.3047490417957306 0.5396214127540588\n",
      "[Step 7626] Loss: 9.65e+07 0.3044658899307251 0.5395331382751465\n",
      "[Step 7627] Loss: 9.68e+07 0.30414003133773804 0.5394440293312073\n",
      "[Step 7628] Loss: 9.68e+07 0.30383095145225525 0.5393639802932739\n",
      "[Step 7629] Loss: 9.66e+07 0.30348116159439087 0.5392451882362366\n",
      "[Step 7630] Loss: 9.63e+07 0.30317801237106323 0.5391634702682495\n",
      "[Step 7631] Loss: 9.72e+07 0.3029860854148865 0.5391089916229248\n",
      "[Step 7632] Loss: 9.68e+07 0.30283910036087036 0.539069414138794\n",
      "[Step 7633] Loss: 9.61e+07 0.3026808798313141 0.5390363931655884\n",
      "[Step 7634] Loss: 9.78e+07 0.3023962080478668 0.5389464497566223\n",
      "[Step 7635] Loss: 9.71e+07 0.30201175808906555 0.5388639569282532\n",
      "[Step 7636] Loss: 9.59e+07 0.30170556902885437 0.5388070344924927\n",
      "[Step 7637] Loss: 9.66e+07 0.30144399404525757 0.538744330406189\n",
      "[Step 7638] Loss: 9.59e+07 0.3012370765209198 0.5387137532234192\n",
      "[Step 7639] Loss: 9.75e+07 0.3011196553707123 0.5386857390403748\n",
      "[Step 7640] Loss: 9.67e+07 0.300952285528183 0.538639485836029\n",
      "[Step 7641] Loss: 9.68e+07 0.30071109533309937 0.5385743379592896\n",
      "[Step 7642] Loss: 9.61e+07 0.3004830777645111 0.5385033488273621\n",
      "[Step 7643] Loss: 9.64e+07 0.3002329170703888 0.5384084582328796\n",
      "[Step 7644] Loss: 9.78e+07 0.3000873029232025 0.5383234620094299\n",
      "[Step 7645] Loss: 9.62e+07 0.29997915029525757 0.538299560546875\n",
      "[Step 7646] Loss: 9.62e+07 0.29982656240463257 0.5382566452026367\n",
      "[Step 7647] Loss: 9.64e+07 0.29964473843574524 0.5382071137428284\n",
      "[Step 7648] Loss: 9.61e+07 0.2994775176048279 0.5381757616996765\n",
      "[Step 7649] Loss: 9.62e+07 0.2993054986000061 0.5381394624710083\n",
      "[Step 7650] Loss: 9.62e+07 0.29911258816719055 0.5380668640136719\n",
      "[Step 7651] Loss: 9.58e+07 0.298947274684906 0.5380091071128845\n",
      "[Step 7652] Loss: 9.51e+07 0.29871153831481934 0.5379224419593811\n",
      "[Step 7653] Loss: 9.66e+07 0.2985108196735382 0.5378910899162292\n",
      "[Step 7654] Loss: 9.64e+07 0.2983381450176239 0.5378424525260925\n",
      "[Step 7655] Loss: 9.72e+07 0.2981184422969818 0.5378053188323975\n",
      "[Step 7656] Loss: 9.59e+07 0.2979152798652649 0.5377376079559326\n",
      "[Step 7657] Loss: 9.59e+07 0.29769256711006165 0.5376551151275635\n",
      "[Step 7658] Loss: 9.65e+07 0.2974579632282257 0.537604808807373\n",
      "[Step 7659] Loss: 9.69e+07 0.2971177399158478 0.5375156998634338\n",
      "[Step 7660] Loss: 9.65e+07 0.2967450022697449 0.5374100804328918\n",
      "[Step 7661] Loss: 9.79e+07 0.29624494910240173 0.5372937321662903\n",
      "[Step 7662] Loss: 9.75e+07 0.29590535163879395 0.5371782183647156\n",
      "[Step 7663] Loss: 9.64e+07 0.29551565647125244 0.5371212363243103\n",
      "[Step 7664] Loss: 9.83e+07 0.29496657848358154 0.5370057225227356\n",
      "[Step 7665] Loss: 9.64e+07 0.2945261597633362 0.5368976593017578\n",
      "[Step 7666] Loss: 9.56e+07 0.2941757142543793 0.5368085503578186\n",
      "[Step 7667] Loss: 9.70e+07 0.29399731755256653 0.5367549061775208\n",
      "[Step 7668] Loss: 9.73e+07 0.2939870059490204 0.5367210507392883\n",
      "[Step 7669] Loss: 9.69e+07 0.2940448820590973 0.5367474555969238\n",
      "[Step 7670] Loss: 9.63e+07 0.2941776514053345 0.5367813110351562\n",
      "[Step 7671] Loss: 9.58e+07 0.2943560481071472 0.5368415117263794\n",
      "[Step 7672] Loss: 9.75e+07 0.29436632990837097 0.536836564540863\n",
      "[Step 7673] Loss: 9.64e+07 0.2944251000881195 0.5368382334709167\n",
      "[Step 7674] Loss: 9.60e+07 0.29451724886894226 0.5368728637695312\n",
      "[Step 7675] Loss: 9.71e+07 0.2944842576980591 0.5368778705596924\n",
      "[Step 7676] Loss: 9.70e+07 0.29445281624794006 0.5368902087211609\n",
      "[Step 7677] Loss: 9.59e+07 0.29442012310028076 0.53690505027771\n",
      "[Step 7678] Loss: 9.66e+07 0.29427555203437805 0.5368596911430359\n",
      "[Step 7679] Loss: 9.63e+07 0.2940589189529419 0.5368167757987976\n",
      "[Step 7680] Loss: 9.63e+07 0.29388463497161865 0.5367664694786072\n",
      "[Step 7681] Loss: 9.64e+07 0.29377081990242004 0.5367648005485535\n",
      "[Step 7682] Loss: 9.58e+07 0.2937156856060028 0.5367730259895325\n",
      "[Step 7683] Loss: 9.71e+07 0.29367300868034363 0.5368027687072754\n",
      "[Step 7684] Loss: 9.60e+07 0.29365187883377075 0.536799430847168\n",
      "[Step 7685] Loss: 9.67e+07 0.2937134802341461 0.5368225574493408\n",
      "[Step 7686] Loss: 9.74e+07 0.29384657740592957 0.5368736982345581\n",
      "[Step 7687] Loss: 9.62e+07 0.29392650723457336 0.5368959903717041\n",
      "[Step 7688] Loss: 9.62e+07 0.2939991354942322 0.5369215607643127\n",
      "[Step 7689] Loss: 9.61e+07 0.29404670000076294 0.5369256734848022\n",
      "[Step 7690] Loss: 9.69e+07 0.294082373380661 0.5369446873664856\n",
      "[Step 7691] Loss: 9.68e+07 0.2941574156284332 0.5369545817375183\n",
      "[Step 7692] Loss: 9.87e+07 0.29391857981681824 0.5369232296943665\n",
      "[Step 7693] Loss: 9.65e+07 0.2937355041503906 0.536874532699585\n",
      "[Step 7694] Loss: 9.64e+07 0.29362770915031433 0.53684401512146\n",
      "[Step 7695] Loss: 9.67e+07 0.2935771942138672 0.53684401512146\n",
      "[Step 7696] Loss: 9.72e+07 0.29361507296562195 0.5368184447288513\n",
      "[Step 7697] Loss: 9.68e+07 0.29360073804855347 0.5368275046348572\n",
      "[Step 7698] Loss: 9.65e+07 0.29359349608421326 0.536828339099884\n",
      "[Step 7699] Loss: 9.62e+07 0.2935865521430969 0.5368382334709167\n",
      "[Step 7700] Loss: 9.68e+07 0.2936418056488037 0.5368225574493408\n",
      "[Step 7701] Loss: 9.59e+07 0.29371437430381775 0.536828339099884\n",
      "[Step 7702] Loss: 9.69e+07 0.2938670516014099 0.5368770360946655\n",
      "[Step 7703] Loss: 9.55e+07 0.2939663231372833 0.5369108319282532\n",
      "[Step 7704] Loss: 9.66e+07 0.29408687353134155 0.5369058847427368\n",
      "[Step 7705] Loss: 9.66e+07 0.2941911816596985 0.536927342414856\n",
      "[Step 7706] Loss: 9.60e+07 0.2941870093345642 0.5369042754173279\n",
      "[Step 7707] Loss: 9.77e+07 0.29402396082878113 0.5368530750274658\n",
      "[Step 7708] Loss: 9.65e+07 0.2939201891422272 0.53684401512146\n",
      "[Step 7709] Loss: 9.65e+07 0.29374533891677856 0.5368010997772217\n",
      "[Step 7710] Loss: 9.63e+07 0.2935889959335327 0.5367515683174133\n",
      "[Step 7711] Loss: 9.73e+07 0.29339465498924255 0.5366806387901306\n",
      "[Step 7712] Loss: 9.59e+07 0.29320016503334045 0.5366302728652954\n",
      "[Step 7713] Loss: 9.57e+07 0.2930176854133606 0.536588191986084\n",
      "[Step 7714] Loss: 9.61e+07 0.2927691340446472 0.5365304350852966\n",
      "[Step 7715] Loss: 9.65e+07 0.29257550835609436 0.536482572555542\n",
      "[Step 7716] Loss: 9.70e+07 0.29230666160583496 0.5364322662353516\n",
      "[Step 7717] Loss: 9.63e+07 0.2920529544353485 0.5363811254501343\n",
      "[Step 7718] Loss: 9.69e+07 0.2918785810470581 0.5363414883613586\n",
      "[Step 7719] Loss: 9.63e+07 0.291676789522171 0.5363093018531799\n",
      "[Step 7720] Loss: 9.65e+07 0.29149433970451355 0.5362697243690491\n",
      "[Step 7721] Loss: 9.54e+07 0.2913311719894409 0.5362523794174194\n",
      "[Step 7722] Loss: 9.75e+07 0.29099249839782715 0.5361921787261963\n",
      "[Step 7723] Loss: 9.67e+07 0.29056718945503235 0.536104679107666\n",
      "[Step 7724] Loss: 9.67e+07 0.2902827262878418 0.5360237956047058\n",
      "[Step 7725] Loss: 9.57e+07 0.2900654673576355 0.5359817147254944\n",
      "[Step 7726] Loss: 9.70e+07 0.2898176908493042 0.5359082818031311\n",
      "[Step 7727] Loss: 9.62e+07 0.2895355224609375 0.535870373249054\n",
      "[Step 7728] Loss: 9.59e+07 0.28933003544807434 0.535825788974762\n",
      "[Step 7729] Loss: 9.67e+07 0.28917694091796875 0.5357977151870728\n",
      "[Step 7730] Loss: 9.64e+07 0.2890840172767639 0.5357589721679688\n",
      "[Step 7731] Loss: 9.64e+07 0.2889794111251831 0.535764753818512\n",
      "[Step 7732] Loss: 9.64e+07 0.2889658808708191 0.535742461681366\n",
      "[Step 7733] Loss: 9.60e+07 0.2889862060546875 0.5357564687728882\n",
      "[Step 7734] Loss: 9.58e+07 0.28898581862449646 0.5357845425605774\n",
      "[Step 7735] Loss: 9.59e+07 0.2889919579029083 0.5357605814933777\n",
      "[Step 7736] Loss: 9.66e+07 0.28906992077827454 0.535772979259491\n",
      "[Step 7737] Loss: 9.69e+07 0.28899070620536804 0.5357697010040283\n",
      "[Step 7738] Loss: 9.64e+07 0.28889650106430054 0.5357259511947632\n",
      "[Step 7739] Loss: 9.63e+07 0.28873950242996216 0.5356492400169373\n",
      "[Step 7740] Loss: 9.71e+07 0.28865891695022583 0.5356426239013672\n",
      "[Step 7741] Loss: 9.60e+07 0.2886294424533844 0.5356343388557434\n",
      "[Step 7742] Loss: 9.68e+07 0.2885441482067108 0.5356071591377258\n",
      "[Step 7743] Loss: 9.60e+07 0.28850919008255005 0.535614550113678\n",
      "[Step 7744] Loss: 9.56e+07 0.28850480914115906 0.5356121063232422\n",
      "[Step 7745] Loss: 9.60e+07 0.28854674100875854 0.5356261134147644\n",
      "[Step 7746] Loss: 9.69e+07 0.28859707713127136 0.5356731414794922\n",
      "[Step 7747] Loss: 9.64e+07 0.28854048252105713 0.5356343388557434\n",
      "[Step 7748] Loss: 9.77e+07 0.2886618971824646 0.5356797575950623\n",
      "[Step 7749] Loss: 9.61e+07 0.2888076603412628 0.5357474088668823\n",
      "[Step 7750] Loss: 9.68e+07 0.289000004529953 0.5357961058616638\n",
      "[Step 7751] Loss: 9.64e+07 0.28917503356933594 0.5358472466468811\n",
      "[Step 7752] Loss: 9.69e+07 0.28926146030426025 0.5358827114105225\n",
      "[Step 7753] Loss: 9.57e+07 0.2892688810825348 0.5358942747116089\n",
      "[Step 7754] Loss: 9.89e+07 0.28904908895492554 0.5358414649963379\n",
      "[Step 7755] Loss: 9.64e+07 0.28881433606147766 0.5357812643051147\n",
      "[Step 7756] Loss: 9.86e+07 0.2883457541465759 0.5356525182723999\n",
      "[Step 7757] Loss: 9.62e+07 0.2878897786140442 0.5355477333068848\n",
      "[Step 7758] Loss: 9.61e+07 0.28756535053253174 0.5354751348495483\n",
      "[Step 7759] Loss: 9.61e+07 0.28723806142807007 0.5353966951370239\n",
      "[Step 7760] Loss: 9.62e+07 0.2870190739631653 0.5353472232818604\n",
      "[Step 7761] Loss: 9.61e+07 0.2868131399154663 0.5353298783302307\n",
      "[Step 7762] Loss: 9.67e+07 0.28657403588294983 0.5352457165718079\n",
      "[Step 7763] Loss: 9.68e+07 0.28643909096717834 0.5352399349212646\n",
      "[Step 7764] Loss: 9.60e+07 0.28622981905937195 0.5351970195770264\n",
      "[Step 7765] Loss: 9.60e+07 0.286051869392395 0.5351739525794983\n",
      "[Step 7766] Loss: 9.63e+07 0.285801500082016 0.5350798964500427\n",
      "[Step 7767] Loss: 9.59e+07 0.2855129837989807 0.535010576248169\n",
      "[Step 7768] Loss: 9.67e+07 0.2853204905986786 0.534965991973877\n",
      "[Step 7769] Loss: 9.61e+07 0.2852155268192291 0.5349511504173279\n",
      "[Step 7770] Loss: 9.61e+07 0.2850669324398041 0.5349255800247192\n",
      "[Step 7771] Loss: 9.71e+07 0.28496041893959045 0.5348950624465942\n",
      "[Step 7772] Loss: 9.58e+07 0.2849348187446594 0.5348793864250183\n",
      "[Step 7773] Loss: 9.62e+07 0.2849653959274292 0.5348736047744751\n",
      "[Step 7774] Loss: 9.64e+07 0.2850499451160431 0.5348851084709167\n",
      "[Step 7775] Loss: 9.61e+07 0.28516823053359985 0.5349181294441223\n",
      "[Step 7776] Loss: 9.63e+07 0.2853069603443146 0.5349404215812683\n",
      "[Step 7777] Loss: 9.60e+07 0.28548455238342285 0.534942090511322\n",
      "[Step 7778] Loss: 9.60e+07 0.2856822907924652 0.5349998474121094\n",
      "[Step 7779] Loss: 9.68e+07 0.28598567843437195 0.535064160823822\n",
      "[Step 7780] Loss: 9.62e+07 0.28630638122558594 0.535139262676239\n",
      "[Step 7781] Loss: 9.66e+07 0.28673654794692993 0.5352540016174316\n",
      "[Step 7782] Loss: 9.67e+07 0.2871440649032593 0.5353232622146606\n",
      "[Step 7783] Loss: 9.60e+07 0.28759077191352844 0.5354264378547668\n",
      "[Step 7784] Loss: 9.64e+07 0.28800106048583984 0.5354874730110168\n",
      "[Step 7785] Loss: 9.72e+07 0.28842154145240784 0.5355716347694397\n",
      "[Step 7786] Loss: 9.60e+07 0.28876909613609314 0.5356112718582153\n",
      "[Step 7787] Loss: 9.65e+07 0.2890620231628418 0.5356656908988953\n",
      "[Step 7788] Loss: 9.70e+07 0.28937846422195435 0.535704493522644\n",
      "[Step 7789] Loss: 9.62e+07 0.2896867096424103 0.5357746481895447\n",
      "[Step 7790] Loss: 9.83e+07 0.2897506356239319 0.5357779264450073\n",
      "[Step 7791] Loss: 9.70e+07 0.2897915840148926 0.5357564687728882\n",
      "[Step 7792] Loss: 9.59e+07 0.28990569710731506 0.5357721447944641\n",
      "[Step 7793] Loss: 9.60e+07 0.2900004982948303 0.5358068346977234\n",
      "[Step 7794] Loss: 9.66e+07 0.2901965081691742 0.5358604192733765\n",
      "[Step 7795] Loss: 9.68e+07 0.29028230905532837 0.5359050035476685\n",
      "[Step 7796] Loss: 9.66e+07 0.2902514934539795 0.5359041690826416\n",
      "[Step 7797] Loss: 9.66e+07 0.2901797890663147 0.5358827114105225\n",
      "[Step 7798] Loss: 9.58e+07 0.2901240587234497 0.5358579754829407\n",
      "[Step 7799] Loss: 9.60e+07 0.29011768102645874 0.5358266234397888\n",
      "[Step 7800] Loss: 9.73e+07 0.2902050316333771 0.5358571410179138\n",
      "[Step 7801] Loss: 9.64e+07 0.2902114689350128 0.5358802676200867\n",
      "[Step 7802] Loss: 9.75e+07 0.2900240123271942 0.5358216762542725\n",
      "[Step 7803] Loss: 9.62e+07 0.2898348867893219 0.5357828736305237\n",
      "[Step 7804] Loss: 9.58e+07 0.2896582782268524 0.5357441306114197\n",
      "[Step 7805] Loss: 9.59e+07 0.2894456088542938 0.5357334017753601\n",
      "[Step 7806] Loss: 9.63e+07 0.2892313003540039 0.5356748104095459\n",
      "[Step 7807] Loss: 9.62e+07 0.28903669118881226 0.5356252789497375\n",
      "[Step 7808] Loss: 9.63e+07 0.2888098955154419 0.5355526804924011\n",
      "[Step 7809] Loss: 9.53e+07 0.28863734006881714 0.5355204939842224\n",
      "[Step 7810] Loss: 9.64e+07 0.2885700762271881 0.5355122685432434\n",
      "[Step 7811] Loss: 9.65e+07 0.28856515884399414 0.5355188250541687\n",
      "[Step 7812] Loss: 9.58e+07 0.28852662444114685 0.5355188250541687\n",
      "[Step 7813] Loss: 9.69e+07 0.28857120871543884 0.5355774164199829\n",
      "[Step 7814] Loss: 9.68e+07 0.2886649966239929 0.5355955958366394\n",
      "[Step 7815] Loss: 9.57e+07 0.28877195715904236 0.5356459021568298\n",
      "[Step 7816] Loss: 9.68e+07 0.2889806926250458 0.5357077717781067\n",
      "[Step 7817] Loss: 9.58e+07 0.289143830537796 0.5357605814933777\n",
      "[Step 7818] Loss: 9.67e+07 0.2893388569355011 0.535832405090332\n",
      "[Step 7819] Loss: 9.77e+07 0.2893451452255249 0.5358455777168274\n",
      "[Step 7820] Loss: 9.89e+07 0.2890583276748657 0.5357936024665833\n",
      "[Step 7821] Loss: 9.60e+07 0.2888815104961395 0.5357523560523987\n",
      "[Step 7822] Loss: 9.67e+07 0.28869566321372986 0.5357407927513123\n",
      "[Step 7823] Loss: 9.72e+07 0.28847062587738037 0.5356813669204712\n",
      "[Step 7824] Loss: 9.55e+07 0.2882707118988037 0.5356252789497375\n",
      "[Step 7825] Loss: 9.65e+07 0.2881891429424286 0.535621166229248\n",
      "[Step 7826] Loss: 9.70e+07 0.2879999279975891 0.5355708003044128\n",
      "[Step 7827] Loss: 9.65e+07 0.28785577416419983 0.5355402827262878\n",
      "[Step 7828] Loss: 9.58e+07 0.2877422869205475 0.5354990363121033\n",
      "[Step 7829] Loss: 9.68e+07 0.28771132230758667 0.5354520082473755\n",
      "[Step 7830] Loss: 9.58e+07 0.2876608073711395 0.5354429483413696\n",
      "[Step 7831] Loss: 9.60e+07 0.2876478433609009 0.5354619026184082\n",
      "[Step 7832] Loss: 9.65e+07 0.2876145839691162 0.5354346632957458\n",
      "[Step 7833] Loss: 9.63e+07 0.2876647710800171 0.535447895526886\n",
      "[Step 7834] Loss: 9.68e+07 0.28772684931755066 0.5354743003845215\n",
      "[Step 7835] Loss: 9.68e+07 0.2877204120159149 0.5354627370834351\n",
      "[Step 7836] Loss: 9.67e+07 0.2877930700778961 0.5354816913604736\n",
      "[Step 7837] Loss: 9.63e+07 0.2879026234149933 0.5354940891265869\n",
      "[Step 7838] Loss: 9.62e+07 0.2880362868309021 0.5354891419410706\n",
      "[Step 7839] Loss: 9.66e+07 0.2880723476409912 0.5354858636856079\n",
      "[Step 7840] Loss: 9.69e+07 0.2881668508052826 0.5354717969894409\n",
      "[Step 7841] Loss: 9.64e+07 0.28821226954460144 0.5354619026184082\n",
      "[Step 7842] Loss: 9.71e+07 0.28810495138168335 0.5354198217391968\n",
      "[Step 7843] Loss: 9.61e+07 0.287935346364975 0.5353628993034363\n",
      "[Step 7844] Loss: 9.63e+07 0.28771454095840454 0.5352811813354492\n",
      "[Step 7845] Loss: 9.68e+07 0.2875189483165741 0.5352424383163452\n",
      "[Step 7846] Loss: 9.64e+07 0.28738701343536377 0.5351830124855042\n",
      "[Step 7847] Loss: 9.76e+07 0.28707295656204224 0.5351293683052063\n",
      "[Step 7848] Loss: 9.66e+07 0.2868152856826782 0.5350741147994995\n",
      "[Step 7849] Loss: 9.65e+07 0.28653091192245483 0.5349816679954529\n",
      "[Step 7850] Loss: 9.62e+07 0.2862445116043091 0.5348859429359436\n",
      "[Step 7851] Loss: 9.72e+07 0.2859695851802826 0.5348306894302368\n",
      "[Step 7852] Loss: 9.75e+07 0.28553807735443115 0.5347275137901306\n",
      "[Step 7853] Loss: 9.63e+07 0.2851444482803345 0.5346763730049133\n",
      "[Step 7854] Loss: 9.61e+07 0.28475725650787354 0.5345839858055115\n",
      "[Step 7855] Loss: 9.57e+07 0.28432393074035645 0.5344923734664917\n",
      "[Step 7856] Loss: 9.70e+07 0.283855676651001 0.5343826413154602\n",
      "[Step 7857] Loss: 9.68e+07 0.28350308537483215 0.5343083739280701\n",
      "[Step 7858] Loss: 9.63e+07 0.2831561863422394 0.5341986417770386\n",
      "[Step 7859] Loss: 9.63e+07 0.28279662132263184 0.5341070294380188\n",
      "[Step 7860] Loss: 9.69e+07 0.28249818086624146 0.5340476036071777\n",
      "[Step 7861] Loss: 9.68e+07 0.28222334384918213 0.533992350101471\n",
      "[Step 7862] Loss: 9.63e+07 0.2820039689540863 0.5339444875717163\n",
      "[Step 7863] Loss: 9.71e+07 0.2817060351371765 0.5338504314422607\n",
      "[Step 7864] Loss: 9.67e+07 0.28134554624557495 0.5337332487106323\n",
      "[Step 7865] Loss: 9.60e+07 0.2811053991317749 0.5336878895759583\n",
      "[Step 7866] Loss: 9.70e+07 0.2809721529483795 0.5336433053016663\n",
      "[Step 7867] Loss: 9.76e+07 0.2807712256908417 0.5335789322853088\n",
      "[Step 7868] Loss: 9.63e+07 0.28053420782089233 0.5335046648979187\n",
      "[Step 7869] Loss: 9.65e+07 0.280178040266037 0.5333966016769409\n",
      "[Step 7870] Loss: 9.73e+07 0.27972906827926636 0.5333049893379211\n",
      "[Step 7871] Loss: 9.69e+07 0.27939361333847046 0.5331894755363464\n",
      "[Step 7872] Loss: 9.66e+07 0.27920302748680115 0.5331226587295532\n",
      "[Step 7873] Loss: 9.66e+07 0.2790047526359558 0.5330615639686584\n",
      "[Step 7874] Loss: 9.67e+07 0.2788334786891937 0.5329691767692566\n",
      "[Step 7875] Loss: 9.61e+07 0.27872341871261597 0.5329254269599915\n",
      "[Step 7876] Loss: 9.60e+07 0.278619647026062 0.5328783988952637\n",
      "[Step 7877] Loss: 9.65e+07 0.2784236669540405 0.5328165292739868\n",
      "[Step 7878] Loss: 9.55e+07 0.2782358229160309 0.5327521562576294\n",
      "[Step 7879] Loss: 9.59e+07 0.27809491753578186 0.5327150225639343\n",
      "[Step 7880] Loss: 9.62e+07 0.27798521518707275 0.5326869487762451\n",
      "[Step 7881] Loss: 9.60e+07 0.277848482131958 0.5326523184776306\n",
      "[Step 7882] Loss: 9.67e+07 0.27765488624572754 0.5325928926467896\n",
      "[Step 7883] Loss: 9.70e+07 0.27760374546051025 0.5325673222541809\n",
      "[Step 7884] Loss: 9.64e+07 0.2775816023349762 0.5325615406036377\n",
      "[Step 7885] Loss: 9.63e+07 0.2774989902973175 0.5325425863265991\n",
      "[Step 7886] Loss: 9.80e+07 0.2772524058818817 0.5325128436088562\n",
      "[Step 7887] Loss: 9.67e+07 0.2769765555858612 0.5324410796165466\n",
      "[Step 7888] Loss: 9.68e+07 0.2766750156879425 0.5323866009712219\n",
      "[Step 7889] Loss: 9.57e+07 0.276397168636322 0.532309889793396\n",
      "[Step 7890] Loss: 9.64e+07 0.27613338828086853 0.5322545766830444\n",
      "[Step 7891] Loss: 9.61e+07 0.27586668729782104 0.5321935415267944\n",
      "[Step 7892] Loss: 9.58e+07 0.2755582928657532 0.5321176052093506\n",
      "[Step 7893] Loss: 9.65e+07 0.27528294920921326 0.5320359468460083\n",
      "[Step 7894] Loss: 9.61e+07 0.2750526964664459 0.5319773554801941\n",
      "[Step 7895] Loss: 9.64e+07 0.2748904228210449 0.5318989753723145\n",
      "[Step 7896] Loss: 9.67e+07 0.2748662829399109 0.5318989753723145\n",
      "[Step 7897] Loss: 9.55e+07 0.27478736639022827 0.5318775177001953\n",
      "[Step 7898] Loss: 9.63e+07 0.27467671036720276 0.5318535566329956\n",
      "[Step 7899] Loss: 9.62e+07 0.27453380823135376 0.5318032503128052\n",
      "[Step 7900] Loss: 9.56e+07 0.27435800433158875 0.5317842960357666\n",
      "[Step 7901] Loss: 9.74e+07 0.2740623652935028 0.5317133069038391\n",
      "[Step 7902] Loss: 9.70e+07 0.27379947900772095 0.5316712260246277\n",
      "[Step 7903] Loss: 9.56e+07 0.273638516664505 0.5316630005836487\n",
      "[Step 7904] Loss: 9.68e+07 0.27361881732940674 0.5316926836967468\n",
      "[Step 7905] Loss: 9.56e+07 0.27362820506095886 0.531714141368866\n",
      "[Step 7906] Loss: 9.58e+07 0.27370890974998474 0.5317413806915283\n",
      "[Step 7907] Loss: 9.65e+07 0.27388137578964233 0.531789243221283\n",
      "[Step 7908] Loss: 9.67e+07 0.2740808427333832 0.5318709015846252\n",
      "[Step 7909] Loss: 9.59e+07 0.27434125542640686 0.5319154858589172\n",
      "[Step 7910] Loss: 9.67e+07 0.27470022439956665 0.5320029258728027\n",
      "[Step 7911] Loss: 9.57e+07 0.27502408623695374 0.5320615172386169\n",
      "[Step 7912] Loss: 9.67e+07 0.27540791034698486 0.5321630239486694\n",
      "[Step 7913] Loss: 9.60e+07 0.2757401466369629 0.5322273969650269\n",
      "[Step 7914] Loss: 9.57e+07 0.2760750949382782 0.5322669744491577\n",
      "[Step 7915] Loss: 9.75e+07 0.2761966288089752 0.5322958827018738\n",
      "[Step 7916] Loss: 9.59e+07 0.276327908039093 0.5323230624198914\n",
      "[Step 7917] Loss: 9.66e+07 0.2764340341091156 0.5323610305786133\n",
      "[Step 7918] Loss: 9.61e+07 0.27644532918930054 0.5323503017425537\n",
      "[Step 7919] Loss: 9.72e+07 0.27631667256355286 0.5323238968849182\n",
      "[Step 7920] Loss: 9.61e+07 0.2761818766593933 0.532279372215271\n",
      "[Step 7921] Loss: 9.61e+07 0.27608299255371094 0.5322381258010864\n",
      "[Step 7922] Loss: 9.62e+07 0.27606457471847534 0.5321952104568481\n",
      "[Step 7923] Loss: 9.67e+07 0.2759174406528473 0.5321506261825562\n",
      "[Step 7924] Loss: 9.66e+07 0.2758265733718872 0.5321184396743774\n",
      "[Step 7925] Loss: 9.72e+07 0.2756524085998535 0.5320574045181274\n",
      "[Step 7926] Loss: 9.60e+07 0.27543267607688904 0.5319963097572327\n",
      "[Step 7927] Loss: 9.59e+07 0.27526187896728516 0.5319344401359558\n",
      "[Step 7928] Loss: 9.62e+07 0.275078684091568 0.5318783521652222\n",
      "[Step 7929] Loss: 9.63e+07 0.2750212848186493 0.5318742394447327\n",
      "[Step 7930] Loss: 9.67e+07 0.2748904526233673 0.531865119934082\n",
      "[Step 7931] Loss: 9.57e+07 0.27476245164871216 0.5318296551704407\n",
      "[Step 7932] Loss: 9.73e+07 0.27454307675361633 0.5317768454551697\n",
      "[Step 7933] Loss: 9.64e+07 0.27430790662765503 0.5317281484603882\n",
      "[Step 7934] Loss: 9.67e+07 0.2741343677043915 0.5316646099090576\n",
      "[Step 7935] Loss: 9.62e+07 0.2739501893520355 0.5316266417503357\n",
      "[Step 7936] Loss: 9.60e+07 0.2737240195274353 0.531563937664032\n",
      "[Step 7937] Loss: 9.59e+07 0.2735863924026489 0.5315359234809875\n",
      "[Step 7938] Loss: 9.60e+07 0.2734659016132355 0.531509518623352\n",
      "[Step 7939] Loss: 9.63e+07 0.27338656783103943 0.5314979553222656\n",
      "[Step 7940] Loss: 9.73e+07 0.2734646499156952 0.5314698815345764\n",
      "[Step 7941] Loss: 9.59e+07 0.27353137731552124 0.5314732193946838\n",
      "[Step 7942] Loss: 9.61e+07 0.27352508902549744 0.5314896702766418\n",
      "[Step 7943] Loss: 9.61e+07 0.2734481692314148 0.5314831137657166\n",
      "[Step 7944] Loss: 9.60e+07 0.2733837366104126 0.531487226486206\n",
      "[Step 7945] Loss: 9.58e+07 0.27328363060951233 0.5314739942550659\n",
      "[Step 7946] Loss: 9.70e+07 0.2730545699596405 0.5314121246337891\n",
      "[Step 7947] Loss: 9.60e+07 0.2728549540042877 0.5313510894775391\n",
      "[Step 7948] Loss: 9.61e+07 0.27268800139427185 0.5313279628753662\n",
      "[Step 7949] Loss: 9.57e+07 0.2726365327835083 0.5313238501548767\n",
      "[Step 7950] Loss: 9.63e+07 0.27259281277656555 0.5313494205474854\n",
      "[Step 7951] Loss: 9.61e+07 0.27256351709365845 0.5313593149185181\n",
      "[Step 7952] Loss: 9.53e+07 0.27255651354789734 0.5313997864723206\n",
      "[Step 7953] Loss: 9.56e+07 0.2725704312324524 0.5314269661903381\n",
      "[Step 7954] Loss: 9.60e+07 0.2725185453891754 0.5314319133758545\n",
      "[Step 7955] Loss: 9.58e+07 0.27253419160842896 0.5314475893974304\n",
      "[Step 7956] Loss: 9.65e+07 0.27243635058403015 0.5314385294914246\n",
      "[Step 7957] Loss: 9.80e+07 0.2721385657787323 0.5313956141471863\n",
      "[Step 7958] Loss: 9.67e+07 0.2717988193035126 0.5313246846199036\n",
      "[Step 7959] Loss: 9.55e+07 0.2714424729347229 0.5312297940254211\n",
      "[Step 7960] Loss: 9.59e+07 0.2711831331253052 0.5311686992645264\n",
      "[Step 7961] Loss: 9.70e+07 0.2708227038383484 0.5311018824577332\n",
      "[Step 7962] Loss: 9.52e+07 0.2705037295818329 0.5310763120651245\n",
      "[Step 7963] Loss: 9.59e+07 0.2702055275440216 0.5309962630271912\n",
      "[Step 7964] Loss: 9.61e+07 0.2698814570903778 0.5309327244758606\n",
      "[Step 7965] Loss: 9.65e+07 0.26960229873657227 0.5309095978736877\n",
      "[Step 7966] Loss: 9.64e+07 0.2693226635456085 0.5308601260185242\n",
      "[Step 7967] Loss: 9.53e+07 0.2690931558609009 0.5308271050453186\n",
      "[Step 7968] Loss: 9.72e+07 0.2688216269016266 0.5307767987251282\n",
      "[Step 7969] Loss: 9.68e+07 0.268637478351593 0.5307652354240417\n",
      "[Step 7970] Loss: 9.66e+07 0.2684475779533386 0.5307437777519226\n",
      "[Step 7971] Loss: 9.64e+07 0.2683732211589813 0.5307272672653198\n",
      "[Step 7972] Loss: 9.67e+07 0.2683676779270172 0.5307577848434448\n",
      "[Step 7973] Loss: 9.63e+07 0.2683999538421631 0.5307742953300476\n",
      "[Step 7974] Loss: 9.71e+07 0.2683129906654358 0.5307437777519226\n",
      "[Step 7975] Loss: 9.62e+07 0.26828446984291077 0.5307561755180359\n",
      "[Step 7976] Loss: 9.71e+07 0.26820170879364014 0.530771017074585\n",
      "[Step 7977] Loss: 9.65e+07 0.2681249678134918 0.5307924747467041\n",
      "[Step 7978] Loss: 9.60e+07 0.2680341899394989 0.530763566493988\n",
      "[Step 7979] Loss: 9.59e+07 0.26789453625679016 0.5307437777519226\n",
      "[Step 7980] Loss: 9.66e+07 0.26775774359703064 0.53074049949646\n",
      "[Step 7981] Loss: 9.65e+07 0.2675964832305908 0.530665397644043\n",
      "[Step 7982] Loss: 9.68e+07 0.2673273980617523 0.5306134223937988\n",
      "[Step 7983] Loss: 9.64e+07 0.2671383023262024 0.530582845211029\n",
      "[Step 7984] Loss: 9.62e+07 0.26701056957244873 0.5305688381195068\n",
      "[Step 7985] Loss: 9.67e+07 0.2669258415699005 0.5305729508399963\n",
      "[Step 7986] Loss: 9.60e+07 0.266872376203537 0.5305564403533936\n",
      "[Step 7987] Loss: 9.53e+07 0.26683273911476135 0.5305572748184204\n",
      "[Step 7988] Loss: 9.65e+07 0.2667836546897888 0.5305342078208923\n",
      "[Step 7989] Loss: 9.71e+07 0.2668236494064331 0.5305399894714355\n",
      "[Step 7990] Loss: 9.61e+07 0.26689159870147705 0.530545711517334\n",
      "[Step 7991] Loss: 9.65e+07 0.2669007480144501 0.5305589437484741\n",
      "[Step 7992] Loss: 9.67e+07 0.2669409215450287 0.5306035280227661\n",
      "[Step 7993] Loss: 9.66e+07 0.26694390177726746 0.5306092500686646\n",
      "[Step 7994] Loss: 9.65e+07 0.2671160101890564 0.5306727886199951\n",
      "[Step 7995] Loss: 9.56e+07 0.267193078994751 0.5306819081306458\n",
      "[Step 7996] Loss: 9.66e+07 0.2672131359577179 0.5306695103645325\n",
      "[Step 7997] Loss: 9.62e+07 0.2672625482082367 0.5306744575500488\n",
      "[Step 7998] Loss: 9.61e+07 0.2672266662120819 0.5306381583213806\n",
      "[Step 7999] Loss: 9.59e+07 0.267119437456131 0.5306167006492615\n",
      "[Step 8000] Loss: 9.68e+07 0.2669861912727356 0.530582070350647\n",
      "[Step 8001] Loss: 9.65e+07 0.26684117317199707 0.5305737853050232\n",
      "[Step 8002] Loss: 9.56e+07 0.2667510211467743 0.5305267572402954\n",
      "[Step 8003] Loss: 9.73e+07 0.2665858268737793 0.5304690003395081\n",
      "[Step 8004] Loss: 9.61e+07 0.2664060592651367 0.5304244160652161\n",
      "[Step 8005] Loss: 9.57e+07 0.2662447690963745 0.5304021835327148\n",
      "[Step 8006] Loss: 9.67e+07 0.2661074995994568 0.5303534865379333\n",
      "[Step 8007] Loss: 9.68e+07 0.2658452093601227 0.5302610397338867\n",
      "[Step 8008] Loss: 9.67e+07 0.2655408978462219 0.5301958918571472\n",
      "[Step 8009] Loss: 9.64e+07 0.2652328610420227 0.5300861597061157\n",
      "[Step 8010] Loss: 9.62e+07 0.2649463415145874 0.5299970507621765\n",
      "[Step 8011] Loss: 9.67e+07 0.26454880833625793 0.529888927936554\n",
      "[Step 8012] Loss: 9.60e+07 0.2641293704509735 0.5297816395759583\n",
      "[Step 8013] Loss: 9.64e+07 0.26377514004707336 0.5296909213066101\n",
      "[Step 8014] Loss: 9.61e+07 0.263423353433609 0.5296521186828613\n",
      "[Step 8015] Loss: 9.64e+07 0.2631295621395111 0.5295490026473999\n",
      "[Step 8016] Loss: 9.71e+07 0.2629026174545288 0.5294994711875916\n",
      "[Step 8017] Loss: 9.69e+07 0.2626872658729553 0.5294111967086792\n",
      "[Step 8018] Loss: 9.67e+07 0.26257839798927307 0.5293996334075928\n",
      "[Step 8019] Loss: 9.63e+07 0.26253944635391235 0.5294185876846313\n",
      "[Step 8020] Loss: 9.74e+07 0.26263609528541565 0.5294689536094666\n",
      "[Step 8021] Loss: 9.70e+07 0.26277443766593933 0.529496967792511\n",
      "[Step 8022] Loss: 9.69e+07 0.26302003860473633 0.5295580625534058\n",
      "[Step 8023] Loss: 9.58e+07 0.26320669054985046 0.5296108722686768\n",
      "[Step 8024] Loss: 9.63e+07 0.2632303535938263 0.5296174883842468\n",
      "[Step 8025] Loss: 9.63e+07 0.26328301429748535 0.5296364426612854\n",
      "[Step 8026] Loss: 9.61e+07 0.2633492648601532 0.5296744108200073\n",
      "[Step 8027] Loss: 9.64e+07 0.26347318291664124 0.5296851396560669\n",
      "[Step 8028] Loss: 9.62e+07 0.2636498212814331 0.5297156572341919\n",
      "[Step 8029] Loss: 9.60e+07 0.26391980051994324 0.5297865867614746\n",
      "[Step 8030] Loss: 9.66e+07 0.2642064094543457 0.5298386216163635\n",
      "[Step 8031] Loss: 9.58e+07 0.2644827961921692 0.5299054384231567\n",
      "[Step 8032] Loss: 9.69e+07 0.26457852125167847 0.5299384593963623\n",
      "[Step 8033] Loss: 9.62e+07 0.26461732387542725 0.529964029788971\n",
      "[Step 8034] Loss: 9.57e+07 0.26470947265625 0.5299904346466064\n",
      "[Step 8035] Loss: 9.62e+07 0.26479968428611755 0.5300300121307373\n",
      "[Step 8036] Loss: 9.64e+07 0.26477062702178955 0.5300069451332092\n",
      "[Step 8037] Loss: 9.67e+07 0.2648603618144989 0.5300605893135071\n",
      "[Step 8038] Loss: 9.68e+07 0.2650250494480133 0.5301083922386169\n",
      "[Step 8039] Loss: 9.64e+07 0.2652702331542969 0.5301513075828552\n",
      "[Step 8040] Loss: 9.59e+07 0.26560312509536743 0.5302305221557617\n",
      "[Step 8041] Loss: 9.62e+07 0.2658764719963074 0.5303188562393188\n",
      "[Step 8042] Loss: 9.68e+07 0.26614493131637573 0.5303807258605957\n",
      "[Step 8043] Loss: 9.63e+07 0.2663101255893707 0.5304483771324158\n",
      "[Step 8044] Loss: 9.71e+07 0.26639944314956665 0.5304945707321167\n",
      "[Step 8045] Loss: 9.67e+07 0.26651373505592346 0.5305284261703491\n",
      "[Step 8046] Loss: 9.56e+07 0.26663005352020264 0.5305614471435547\n",
      "[Step 8047] Loss: 9.59e+07 0.2667331397533417 0.530582845211029\n",
      "[Step 8048] Loss: 9.66e+07 0.26675155758857727 0.5306010246276855\n",
      "[Step 8049] Loss: 9.68e+07 0.26672953367233276 0.5306035280227661\n",
      "[Step 8050] Loss: 9.62e+07 0.2667861580848694 0.5306628942489624\n",
      "[Step 8051] Loss: 9.65e+07 0.26684635877609253 0.5306819081306458\n",
      "[Step 8052] Loss: 9.59e+07 0.26689648628234863 0.5306934118270874\n",
      "[Step 8053] Loss: 9.65e+07 0.26689761877059937 0.5306645631790161\n",
      "[Step 8054] Loss: 9.65e+07 0.26691484451293945 0.5306819081306458\n",
      "[Step 8055] Loss: 9.60e+07 0.26683881878852844 0.5306571125984192\n",
      "[Step 8056] Loss: 9.73e+07 0.2667711079120636 0.5306356549263\n",
      "[Step 8057] Loss: 9.68e+07 0.26682525873184204 0.5306488871574402\n",
      "[Step 8058] Loss: 9.59e+07 0.2668808698654175 0.5306612849235535\n",
      "[Step 8059] Loss: 9.65e+07 0.2668418288230896 0.5306620597839355\n",
      "[Step 8060] Loss: 9.69e+07 0.26678910851478577 0.5306224822998047\n",
      "[Step 8061] Loss: 9.73e+07 0.2665485739707947 0.5305482149124146\n",
      "[Step 8062] Loss: 9.72e+07 0.26620346307754517 0.5304393172264099\n",
      "[Step 8063] Loss: 9.59e+07 0.26590797305107117 0.5303749442100525\n",
      "[Step 8064] Loss: 9.70e+07 0.2657472789287567 0.5303369760513306\n",
      "[Step 8065] Loss: 9.61e+07 0.26559188961982727 0.5302800536155701\n",
      "[Step 8066] Loss: 9.58e+07 0.26551875472068787 0.5302684903144836\n",
      "[Step 8067] Loss: 9.57e+07 0.26543015241622925 0.5302338600158691\n",
      "[Step 8068] Loss: 9.60e+07 0.2653765082359314 0.5301810503005981\n",
      "[Step 8069] Loss: 9.67e+07 0.26536640524864197 0.5301381349563599\n",
      "[Step 8070] Loss: 9.70e+07 0.265214204788208 0.5301274061203003\n",
      "[Step 8071] Loss: 9.71e+07 0.26495859026908875 0.5300580859184265\n",
      "[Step 8072] Loss: 9.67e+07 0.2645672857761383 0.5299780368804932\n",
      "[Step 8073] Loss: 9.68e+07 0.2642207741737366 0.5299153327941895\n",
      "[Step 8074] Loss: 9.66e+07 0.2639111280441284 0.5298336744308472\n",
      "[Step 8075] Loss: 9.66e+07 0.2636832296848297 0.5297890901565552\n",
      "[Step 8076] Loss: 9.80e+07 0.2635807693004608 0.5297693014144897\n",
      "[Step 8077] Loss: 9.56e+07 0.2634997069835663 0.5297569036483765\n",
      "[Step 8078] Loss: 9.59e+07 0.2634439170360565 0.5297247171401978\n",
      "[Step 8079] Loss: 9.60e+07 0.26330116391181946 0.5296603441238403\n",
      "[Step 8080] Loss: 9.59e+07 0.26312729716300964 0.529600977897644\n",
      "[Step 8081] Loss: 9.60e+07 0.26297324895858765 0.5295778512954712\n",
      "[Step 8082] Loss: 9.58e+07 0.26292142271995544 0.5295704007148743\n",
      "[Step 8083] Loss: 9.67e+07 0.2629474997520447 0.5295737385749817\n",
      "[Step 8084] Loss: 9.65e+07 0.26295724511146545 0.5295712351799011\n",
      "[Step 8085] Loss: 9.64e+07 0.2629354000091553 0.529548168182373\n",
      "[Step 8086] Loss: 9.59e+07 0.2629055082798004 0.5295324921607971\n",
      "[Step 8087] Loss: 9.62e+07 0.26287877559661865 0.5295200943946838\n",
      "[Step 8088] Loss: 9.59e+07 0.262909471988678 0.5295588970184326\n",
      "[Step 8089] Loss: 9.65e+07 0.2630331516265869 0.5295803546905518\n",
      "[Step 8090] Loss: 9.60e+07 0.26312845945358276 0.5295754075050354\n",
      "[Step 8091] Loss: 9.57e+07 0.2632254958152771 0.5295745730400085\n",
      "[Step 8092] Loss: 9.62e+07 0.2632552981376648 0.5295860767364502\n",
      "[Step 8093] Loss: 9.69e+07 0.2632836699485779 0.5295696258544922\n",
      "[Step 8094] Loss: 9.62e+07 0.2633262276649475 0.5295473337173462\n",
      "[Step 8095] Loss: 9.86e+07 0.26308175921440125 0.5294862389564514\n",
      "[Step 8096] Loss: 9.61e+07 0.26292359828948975 0.5294260382652283\n",
      "[Step 8097] Loss: 9.75e+07 0.26288121938705444 0.5294260382652283\n",
      "[Step 8098] Loss: 9.68e+07 0.262889564037323 0.5294243693351746\n",
      "[Step 8099] Loss: 9.65e+07 0.2629072666168213 0.529413640499115\n",
      "[Step 8100] Loss: 9.58e+07 0.26290228962898254 0.5294219255447388\n",
      "[Step 8101] Loss: 9.66e+07 0.26296427845954895 0.5294252038002014\n",
      "[Step 8102] Loss: 9.62e+07 0.2629771828651428 0.5294532775878906\n",
      "[Step 8103] Loss: 9.71e+07 0.26292121410369873 0.5294713973999023\n",
      "[Step 8104] Loss: 9.68e+07 0.2627960443496704 0.5294507741928101\n",
      "[Step 8105] Loss: 9.65e+07 0.2626076340675354 0.5294177532196045\n",
      "[Step 8106] Loss: 9.67e+07 0.26235881447792053 0.5293616652488708\n",
      "[Step 8107] Loss: 9.67e+07 0.2621130645275116 0.5292923450469971\n",
      "[Step 8108] Loss: 9.62e+07 0.26193341612815857 0.5292601585388184\n",
      "[Step 8109] Loss: 9.66e+07 0.2617579996585846 0.529255211353302\n",
      "[Step 8110] Loss: 9.71e+07 0.2615952491760254 0.5292304754257202\n",
      "[Step 8111] Loss: 9.74e+07 0.2616649568080902 0.5292478203773499\n",
      "[Step 8112] Loss: 9.61e+07 0.2616443932056427 0.5292444825172424\n",
      "[Step 8113] Loss: 9.71e+07 0.2615358233451843 0.5292568802833557\n",
      "[Step 8114] Loss: 9.63e+07 0.261453241109848 0.5292494297027588\n",
      "[Step 8115] Loss: 9.76e+07 0.261231929063797 0.5291974544525146\n",
      "[Step 8116] Loss: 9.57e+07 0.26108258962631226 0.5291677713394165\n",
      "[Step 8117] Loss: 9.53e+07 0.26091450452804565 0.5291446447372437\n",
      "[Step 8118] Loss: 9.72e+07 0.26061517000198364 0.5290555357933044\n",
      "[Step 8119] Loss: 9.77e+07 0.26019811630249023 0.5289771556854248\n",
      "[Step 8120] Loss: 9.62e+07 0.2598646879196167 0.5288946628570557\n",
      "[Step 8121] Loss: 9.66e+07 0.25948458909988403 0.5288277864456177\n",
      "[Step 8122] Loss: 9.66e+07 0.25901365280151367 0.5287163853645325\n",
      "[Step 8123] Loss: 9.72e+07 0.2586442530155182 0.5286281108856201\n",
      "[Step 8124] Loss: 9.62e+07 0.2582281231880188 0.5285323858261108\n",
      "[Step 8125] Loss: 9.78e+07 0.25769442319869995 0.5284127593040466\n",
      "[Step 8126] Loss: 9.60e+07 0.25718268752098083 0.5282559990882874\n",
      "[Step 8127] Loss: 9.57e+07 0.25672024488449097 0.528123140335083\n",
      "[Step 8128] Loss: 9.58e+07 0.2562824785709381 0.5280447602272034\n",
      "[Step 8129] Loss: 9.68e+07 0.2559697926044464 0.5279696583747864\n",
      "[Step 8130] Loss: 9.65e+07 0.25555476546287537 0.5278846621513367\n",
      "[Step 8131] Loss: 9.62e+07 0.25514307618141174 0.5277642011642456\n",
      "[Step 8132] Loss: 9.72e+07 0.25471869111061096 0.5276709794998169\n",
      "[Step 8133] Loss: 9.64e+07 0.25426557660102844 0.5275397896766663\n",
      "[Step 8134] Loss: 9.65e+07 0.25389647483825684 0.5274325013160706\n",
      "[Step 8135] Loss: 9.59e+07 0.25352466106414795 0.5273532867431641\n",
      "[Step 8136] Loss: 9.61e+07 0.2531139552593231 0.5272485017776489\n",
      "[Step 8137] Loss: 9.73e+07 0.25261208415031433 0.5271280407905579\n",
      "[Step 8138] Loss: 9.85e+07 0.2518935799598694 0.5269415378570557\n",
      "[Step 8139] Loss: 9.63e+07 0.2512025237083435 0.5267385840415955\n",
      "[Step 8140] Loss: 9.56e+07 0.2505837678909302 0.5265949964523315\n",
      "[Step 8141] Loss: 9.67e+07 0.2500370144844055 0.5264711976051331\n",
      "[Step 8142] Loss: 9.63e+07 0.24946719408035278 0.5263152718544006\n",
      "[Step 8143] Loss: 9.59e+07 0.24892479181289673 0.5261799693107605\n",
      "[Step 8144] Loss: 9.62e+07 0.24852736294269562 0.526086688041687\n",
      "[Step 8145] Loss: 9.62e+07 0.24823637306690216 0.5259959101676941\n",
      "[Step 8146] Loss: 9.65e+07 0.24795734882354736 0.52588951587677\n",
      "[Step 8147] Loss: 9.56e+07 0.24772527813911438 0.5258268117904663\n",
      "[Step 8148] Loss: 9.77e+07 0.24768680334091187 0.5257880091667175\n",
      "[Step 8149] Loss: 9.64e+07 0.2476072758436203 0.5257409811019897\n",
      "[Step 8150] Loss: 9.66e+07 0.247537299990654 0.5257384777069092\n",
      "[Step 8151] Loss: 9.63e+07 0.24749095737934113 0.5257269144058228\n",
      "[Step 8152] Loss: 9.60e+07 0.2474813461303711 0.5256955623626709\n",
      "[Step 8153] Loss: 9.61e+07 0.2474663108587265 0.5256733298301697\n",
      "[Step 8154] Loss: 9.57e+07 0.24747046828269958 0.5256733298301697\n",
      "[Step 8155] Loss: 9.59e+07 0.2474680095911026 0.5256724953651428\n",
      "[Step 8156] Loss: 9.61e+07 0.24748851358890533 0.5256733298301697\n",
      "[Step 8157] Loss: 9.66e+07 0.24754951894283295 0.5257071256637573\n",
      "[Step 8158] Loss: 9.66e+07 0.24751974642276764 0.5256881713867188\n",
      "[Step 8159] Loss: 9.72e+07 0.24737060070037842 0.5256378054618835\n",
      "[Step 8160] Loss: 9.65e+07 0.24712681770324707 0.5255684852600098\n",
      "[Step 8161] Loss: 9.63e+07 0.24691073596477509 0.5255511999130249\n",
      "[Step 8162] Loss: 9.64e+07 0.2466663420200348 0.5254810452461243\n",
      "[Step 8163] Loss: 9.71e+07 0.24655690789222717 0.5254554748535156\n",
      "[Step 8164] Loss: 9.65e+07 0.24635550379753113 0.5253927707672119\n",
      "[Step 8165] Loss: 9.62e+07 0.24617022275924683 0.5253531336784363\n",
      "[Step 8166] Loss: 9.56e+07 0.24604320526123047 0.5253382921218872\n",
      "[Step 8167] Loss: 9.58e+07 0.24593299627304077 0.5253522992134094\n",
      "[Step 8168] Loss: 9.73e+07 0.24576586484909058 0.5252987146377563\n",
      "[Step 8169] Loss: 9.60e+07 0.24562682211399078 0.5252524614334106\n",
      "[Step 8170] Loss: 9.62e+07 0.24540656805038452 0.5252054333686829\n",
      "[Step 8171] Loss: 9.56e+07 0.2451999932527542 0.5251377820968628\n",
      "[Step 8172] Loss: 9.62e+07 0.24503043293952942 0.5251055955886841\n",
      "[Step 8173] Loss: 9.62e+07 0.24491620063781738 0.5250775814056396\n",
      "[Step 8174] Loss: 9.61e+07 0.24479226768016815 0.5250998139381409\n",
      "[Step 8175] Loss: 9.61e+07 0.2447807490825653 0.5250940322875977\n",
      "[Step 8176] Loss: 9.61e+07 0.24472729861736298 0.525090754032135\n",
      "[Step 8177] Loss: 9.60e+07 0.24472253024578094 0.52512127161026\n",
      "[Step 8178] Loss: 9.57e+07 0.2447919398546219 0.5251732468605042\n",
      "[Step 8179] Loss: 9.58e+07 0.2449185699224472 0.5252227783203125\n",
      "[Step 8180] Loss: 9.64e+07 0.24504929780960083 0.5252450704574585\n",
      "[Step 8181] Loss: 9.57e+07 0.245224729180336 0.5252945423126221\n",
      "[Step 8182] Loss: 9.62e+07 0.24529388546943665 0.5252962112426758\n",
      "[Step 8183] Loss: 9.64e+07 0.24531832337379456 0.5252755880355835\n",
      "[Step 8184] Loss: 9.67e+07 0.2451503574848175 0.5252417325973511\n",
      "[Step 8185] Loss: 9.65e+07 0.2450834959745407 0.5252293944358826\n",
      "[Step 8186] Loss: 9.88e+07 0.24472598731517792 0.5251014828681946\n",
      "[Step 8187] Loss: 9.62e+07 0.24438999593257904 0.5250346660614014\n",
      "[Step 8188] Loss: 9.61e+07 0.24403631687164307 0.5249249339103699\n",
      "[Step 8189] Loss: 9.65e+07 0.24382717907428741 0.5248679518699646\n",
      "[Step 8190] Loss: 9.64e+07 0.2435055524110794 0.5248060822486877\n",
      "[Step 8191] Loss: 9.68e+07 0.24319709837436676 0.5247343182563782\n",
      "[Step 8192] Loss: 9.67e+07 0.24300459027290344 0.5246888995170593\n",
      "[Step 8193] Loss: 9.64e+07 0.2429698258638382 0.5246831178665161\n",
      "[Step 8194] Loss: 9.62e+07 0.24293586611747742 0.5246955156326294\n",
      "[Step 8195] Loss: 9.55e+07 0.24292676150798798 0.524706244468689\n",
      "[Step 8196] Loss: 9.63e+07 0.24291975796222687 0.5246856212615967\n",
      "[Step 8197] Loss: 9.70e+07 0.24281635880470276 0.5246666669845581\n",
      "[Step 8198] Loss: 9.66e+07 0.2427722066640854 0.524645209312439\n",
      "[Step 8199] Loss: 9.66e+07 0.24266068637371063 0.5246121883392334\n",
      "[Step 8200] Loss: 9.66e+07 0.24256375432014465 0.5246121883392334\n",
      "[Step 8201] Loss: 9.65e+07 0.2425207495689392 0.5245997905731201\n",
      "[Step 8202] Loss: 9.60e+07 0.24249593913555145 0.5246055722236633\n",
      "[Step 8203] Loss: 9.67e+07 0.24255801737308502 0.5246261954307556\n",
      "[Step 8204] Loss: 9.74e+07 0.24243327975273132 0.5246113538742065\n",
      "[Step 8205] Loss: 9.63e+07 0.2423664778470993 0.5246138572692871\n",
      "[Step 8206] Loss: 9.68e+07 0.24220694601535797 0.5245808362960815\n",
      "[Step 8207] Loss: 9.68e+07 0.24210768938064575 0.5245709419250488\n",
      "[Step 8208] Loss: 9.58e+07 0.24198350310325623 0.5245387554168701\n",
      "[Step 8209] Loss: 9.75e+07 0.24176518619060516 0.5244760513305664\n",
      "[Step 8210] Loss: 9.61e+07 0.24162344634532928 0.5244595408439636\n",
      "[Step 8211] Loss: 9.60e+07 0.24153847992420197 0.5244479775428772\n",
      "[Step 8212] Loss: 9.63e+07 0.24146266281604767 0.5244471430778503\n",
      "[Step 8213] Loss: 9.68e+07 0.24128548800945282 0.524411678314209\n",
      "[Step 8214] Loss: 9.56e+07 0.24110226333141327 0.5243638157844543\n",
      "[Step 8215] Loss: 9.70e+07 0.24105530977249146 0.5243332982063293\n",
      "[Step 8216] Loss: 9.63e+07 0.2410348802804947 0.5243307948112488\n",
      "[Step 8217] Loss: 9.71e+07 0.24109914898872375 0.5243571996688843\n",
      "[Step 8218] Loss: 9.61e+07 0.24108651280403137 0.5243489742279053\n",
      "[Step 8219] Loss: 9.56e+07 0.24111811816692352 0.5243621468544006\n",
      "[Step 8220] Loss: 9.67e+07 0.24123065173625946 0.5243827700614929\n",
      "[Step 8221] Loss: 9.61e+07 0.2413281947374344 0.5243992805480957\n",
      "[Step 8222] Loss: 9.62e+07 0.24145005643367767 0.5244504809379578\n",
      "[Step 8223] Loss: 9.70e+07 0.2414264678955078 0.5244545936584473\n",
      "[Step 8224] Loss: 9.67e+07 0.2412574589252472 0.5244314670562744\n",
      "[Step 8225] Loss: 9.63e+07 0.24105922877788544 0.5243869423866272\n",
      "[Step 8226] Loss: 9.63e+07 0.24091993272304535 0.5243786573410034\n",
      "[Step 8227] Loss: 9.60e+07 0.24076934158802032 0.5243316292762756\n",
      "[Step 8228] Loss: 9.58e+07 0.24073262512683868 0.5243440270423889\n",
      "[Step 8229] Loss: 9.65e+07 0.24063490331172943 0.5243241786956787\n",
      "[Step 8230] Loss: 9.65e+07 0.24061457812786102 0.5243126749992371\n",
      "[Step 8231] Loss: 9.66e+07 0.24053242802619934 0.5242771506309509\n",
      "[Step 8232] Loss: 9.53e+07 0.24047528207302094 0.5242871046066284\n",
      "[Step 8233] Loss: 9.63e+07 0.24045225977897644 0.5242920517921448\n",
      "[Step 8234] Loss: 9.64e+07 0.2404652237892151 0.5243291854858398\n",
      "[Step 8235] Loss: 9.66e+07 0.24049805104732513 0.5243852734565735\n",
      "[Step 8236] Loss: 9.61e+07 0.24053706228733063 0.5243877172470093\n",
      "[Step 8237] Loss: 9.68e+07 0.24064859747886658 0.5244281888008118\n",
      "[Step 8238] Loss: 9.76e+07 0.24058672785758972 0.5244331359863281\n",
      "[Step 8239] Loss: 9.61e+07 0.2406827062368393 0.5244364142417908\n",
      "[Step 8240] Loss: 9.60e+07 0.24080884456634521 0.5244174599647522\n",
      "[Step 8241] Loss: 9.61e+07 0.24099063873291016 0.52446448802948\n",
      "[Step 8242] Loss: 9.66e+07 0.24112941324710846 0.5244982838630676\n",
      "[Step 8243] Loss: 9.73e+07 0.24115720391273499 0.5244809985160828\n",
      "[Step 8244] Loss: 9.62e+07 0.24112436175346375 0.5244397521018982\n",
      "[Step 8245] Loss: 9.60e+07 0.24106711149215698 0.5244026184082031\n",
      "[Step 8246] Loss: 9.68e+07 0.24087390303611755 0.5243456363677979\n",
      "[Step 8247] Loss: 9.57e+07 0.2407563179731369 0.5243324637413025\n",
      "[Step 8248] Loss: 9.57e+07 0.24066326022148132 0.5242747068405151\n",
      "[Step 8249] Loss: 9.65e+07 0.24063289165496826 0.5243068933486938\n",
      "[Step 8250] Loss: 9.64e+07 0.24065472185611725 0.5242977738380432\n",
      "[Step 8251] Loss: 9.68e+07 0.24079017341136932 0.5243605375289917\n",
      "[Step 8252] Loss: 9.58e+07 0.24095559120178223 0.5244141221046448\n",
      "[Step 8253] Loss: 9.64e+07 0.2411767542362213 0.52446448802948\n",
      "[Step 8254] Loss: 9.63e+07 0.24142558872699738 0.5245156288146973\n",
      "[Step 8255] Loss: 9.55e+07 0.24169009923934937 0.5245709419250488\n",
      "[Step 8256] Loss: 9.63e+07 0.24192528426647186 0.5246567130088806\n",
      "[Step 8257] Loss: 9.61e+07 0.24220742285251617 0.5247095227241516\n",
      "[Step 8258] Loss: 9.63e+07 0.24253098666667938 0.5247474908828735\n",
      "[Step 8259] Loss: 9.66e+07 0.24272295832633972 0.5247722864151001\n",
      "[Step 8260] Loss: 9.66e+07 0.2429344803094864 0.5247953534126282\n",
      "[Step 8261] Loss: 9.60e+07 0.24311138689517975 0.5248464941978455\n",
      "[Step 8262] Loss: 9.60e+07 0.24334748089313507 0.5248985290527344\n",
      "[Step 8263] Loss: 9.67e+07 0.24350625276565552 0.5249488353729248\n",
      "[Step 8264] Loss: 9.64e+07 0.24353428184986115 0.5249735713005066\n",
      "[Step 8265] Loss: 9.70e+07 0.24343250691890717 0.5249670147895813\n",
      "[Step 8266] Loss: 9.54e+07 0.24336573481559753 0.5249578952789307\n",
      "[Step 8267] Loss: 9.61e+07 0.24327687919139862 0.5249050855636597\n",
      "[Step 8268] Loss: 9.62e+07 0.24320177733898163 0.524872899055481\n",
      "[Step 8269] Loss: 9.79e+07 0.24296307563781738 0.5248077511787415\n",
      "[Step 8270] Loss: 9.64e+07 0.2426840215921402 0.5247301459312439\n",
      "[Step 8271] Loss: 9.86e+07 0.24218043684959412 0.5246204137802124\n",
      "[Step 8272] Loss: 9.63e+07 0.24172382056713104 0.524495005607605\n",
      "[Step 8273] Loss: 9.69e+07 0.24145472049713135 0.524419903755188\n",
      "[Step 8274] Loss: 9.64e+07 0.24114660918712616 0.5243291854858398\n",
      "[Step 8275] Loss: 9.55e+07 0.24085766077041626 0.5242590308189392\n",
      "[Step 8276] Loss: 9.57e+07 0.24063748121261597 0.5241897106170654\n",
      "[Step 8277] Loss: 9.67e+07 0.24048931896686554 0.5241517424583435\n",
      "[Step 8278] Loss: 9.55e+07 0.2403687685728073 0.5241137742996216\n",
      "[Step 8279] Loss: 9.67e+07 0.2401609569787979 0.5240254998207092\n",
      "[Step 8280] Loss: 9.64e+07 0.23993007838726044 0.5239999294281006\n",
      "[Step 8281] Loss: 9.62e+07 0.2397543489933014 0.5239685773849487\n",
      "[Step 8282] Loss: 9.61e+07 0.23960894346237183 0.5239561796188354\n",
      "[Step 8283] Loss: 9.59e+07 0.2394372671842575 0.5239067077636719\n",
      "[Step 8284] Loss: 9.65e+07 0.2393709421157837 0.5239099860191345\n",
      "[Step 8285] Loss: 9.75e+07 0.2394465208053589 0.5239025354385376\n",
      "[Step 8286] Loss: 9.67e+07 0.2395673245191574 0.5239496231079102\n",
      "[Step 8287] Loss: 9.63e+07 0.2397678941488266 0.5240123271942139\n",
      "[Step 8288] Loss: 9.62e+07 0.23989619314670563 0.5240288376808167\n",
      "[Step 8289] Loss: 9.60e+07 0.2400338351726532 0.5240750312805176\n",
      "[Step 8290] Loss: 9.61e+07 0.24027183651924133 0.5241137742996216\n",
      "[Step 8291] Loss: 9.68e+07 0.2403813749551773 0.524155855178833\n",
      "[Step 8292] Loss: 9.55e+07 0.24042773246765137 0.524169921875\n",
      "[Step 8293] Loss: 9.54e+07 0.24054387211799622 0.5242070555686951\n",
      "[Step 8294] Loss: 9.64e+07 0.24051880836486816 0.5241773128509521\n",
      "[Step 8295] Loss: 9.58e+07 0.2405027449131012 0.5241600275039673\n",
      "[Step 8296] Loss: 9.73e+07 0.24024352431297302 0.5240923166275024\n",
      "[Step 8297] Loss: 9.61e+07 0.2399899959564209 0.5240123271942139\n",
      "[Step 8298] Loss: 9.67e+07 0.23973116278648376 0.5239372253417969\n",
      "[Step 8299] Loss: 9.63e+07 0.2395077645778656 0.5238811373710632\n",
      "[Step 8300] Loss: 9.75e+07 0.239191472530365 0.5237928032875061\n",
      "[Step 8301] Loss: 9.65e+07 0.23880361020565033 0.5236542224884033\n",
      "[Step 8302] Loss: 9.62e+07 0.2384306937456131 0.5235857367515564\n",
      "[Step 8303] Loss: 9.64e+07 0.23804925382137299 0.5234850645065308\n",
      "[Step 8304] Loss: 9.68e+07 0.2376241236925125 0.5233818888664246\n",
      "[Step 8305] Loss: 9.59e+07 0.2372341752052307 0.5232919454574585\n",
      "[Step 8306] Loss: 9.54e+07 0.2369319498538971 0.5232086181640625\n",
      "[Step 8307] Loss: 9.64e+07 0.23658300936222076 0.5231128931045532\n",
      "[Step 8308] Loss: 9.67e+07 0.2363627552986145 0.5230345129966736\n",
      "[Step 8309] Loss: 9.54e+07 0.23619303107261658 0.5229619145393372\n",
      "[Step 8310] Loss: 9.64e+07 0.2359859198331833 0.5229091048240662\n",
      "[Step 8311] Loss: 9.62e+07 0.23570516705513 0.5228472352027893\n",
      "[Step 8312] Loss: 9.60e+07 0.23542916774749756 0.5227960348129272\n",
      "[Step 8313] Loss: 9.63e+07 0.23510266840457916 0.5227094292640686\n",
      "[Step 8314] Loss: 9.65e+07 0.23478034138679504 0.5226433873176575\n",
      "[Step 8315] Loss: 9.62e+07 0.23448938131332397 0.5225988626480103\n",
      "[Step 8316] Loss: 9.54e+07 0.23428523540496826 0.5225831866264343\n",
      "[Step 8317] Loss: 9.68e+07 0.23417417705059052 0.5225583910942078\n",
      "[Step 8318] Loss: 9.59e+07 0.2339523434638977 0.5225055813789368\n",
      "[Step 8319] Loss: 9.63e+07 0.2337641417980194 0.5224734544754028\n",
      "[Step 8320] Loss: 9.67e+07 0.23357687890529633 0.5224379301071167\n",
      "[Step 8321] Loss: 9.66e+07 0.2335340529680252 0.5224610567092896\n",
      "[Step 8322] Loss: 9.65e+07 0.23339499533176422 0.5224329829216003\n",
      "[Step 8323] Loss: 9.65e+07 0.23343387246131897 0.5224833488464355\n",
      "[Step 8324] Loss: 9.62e+07 0.2335747480392456 0.5225732922554016\n",
      "[Step 8325] Loss: 9.61e+07 0.2337195873260498 0.5226359963417053\n",
      "[Step 8326] Loss: 9.62e+07 0.2339002788066864 0.5226945877075195\n",
      "[Step 8327] Loss: 9.75e+07 0.23423181474208832 0.522773802280426\n",
      "[Step 8328] Loss: 9.56e+07 0.23456446826457977 0.5228636860847473\n",
      "[Step 8329] Loss: 9.62e+07 0.2348092794418335 0.5229396224021912\n",
      "[Step 8330] Loss: 9.58e+07 0.23495203256607056 0.5229808688163757\n",
      "[Step 8331] Loss: 9.65e+07 0.23515944182872772 0.5230559706687927\n",
      "[Step 8332] Loss: 9.93e+07 0.23502923548221588 0.5230402946472168\n",
      "[Step 8333] Loss: 9.62e+07 0.234893798828125 0.5230106115341187\n",
      "[Step 8334] Loss: 9.56e+07 0.23476910591125488 0.5230246186256409\n",
      "[Step 8335] Loss: 9.58e+07 0.23466704785823822 0.5230039954185486\n",
      "[Step 8336] Loss: 9.74e+07 0.2344091683626175 0.5229635834693909\n",
      "[Step 8337] Loss: 9.68e+07 0.23425105214118958 0.5229198336601257\n",
      "[Step 8338] Loss: 9.66e+07 0.23405760526657104 0.5229148864746094\n",
      "[Step 8339] Loss: 9.71e+07 0.23385216295719147 0.522881031036377\n",
      "[Step 8340] Loss: 9.56e+07 0.23368486762046814 0.5228315591812134\n",
      "[Step 8341] Loss: 9.70e+07 0.23357801139354706 0.52281254529953\n",
      "[Step 8342] Loss: 9.63e+07 0.23342838883399963 0.5228009819984436\n",
      "[Step 8343] Loss: 9.62e+07 0.23328527808189392 0.5227581262588501\n",
      "[Step 8344] Loss: 9.61e+07 0.23312872648239136 0.5227440595626831\n",
      "[Step 8345] Loss: 9.62e+07 0.23294860124588013 0.5226747393608093\n",
      "[Step 8346] Loss: 9.67e+07 0.2328152358531952 0.5226137042045593\n",
      "[Step 8347] Loss: 9.67e+07 0.23267018795013428 0.5225650072097778\n",
      "[Step 8348] Loss: 9.60e+07 0.23251214623451233 0.52251797914505\n",
      "[Step 8349] Loss: 9.59e+07 0.23234760761260986 0.5224676728248596\n",
      "[Step 8350] Loss: 9.61e+07 0.2322474867105484 0.522428035736084\n",
      "[Step 8351] Loss: 9.62e+07 0.23213598132133484 0.5223892331123352\n",
      "[Step 8352] Loss: 9.58e+07 0.2319933921098709 0.5223521590232849\n",
      "[Step 8353] Loss: 9.73e+07 0.23172743618488312 0.5222893953323364\n",
      "[Step 8354] Loss: 9.59e+07 0.23149451613426208 0.5222432017326355\n",
      "[Step 8355] Loss: 9.58e+07 0.2312714010477066 0.5221854448318481\n",
      "[Step 8356] Loss: 9.71e+07 0.23097892105579376 0.5221145153045654\n",
      "[Step 8357] Loss: 9.57e+07 0.23076961934566498 0.5220624804496765\n",
      "[Step 8358] Loss: 9.63e+07 0.23056043684482574 0.5220080614089966\n",
      "[Step 8359] Loss: 9.59e+07 0.23042172193527222 0.52198326587677\n",
      "[Step 8360] Loss: 9.58e+07 0.23030653595924377 0.52192223072052\n",
      "[Step 8361] Loss: 9.72e+07 0.2300868183374405 0.5218636393547058\n",
      "[Step 8362] Loss: 9.78e+07 0.22972272336483002 0.5217481255531311\n",
      "[Step 8363] Loss: 9.61e+07 0.22934862971305847 0.5216549038887024\n",
      "[Step 8364] Loss: 9.56e+07 0.22903265058994293 0.5215756893157959\n",
      "[Step 8365] Loss: 9.59e+07 0.22873280942440033 0.5214948058128357\n",
      "[Step 8366] Loss: 9.64e+07 0.22827571630477905 0.52138751745224\n",
      "[Step 8367] Loss: 9.62e+07 0.22786502540111542 0.521273672580719\n",
      "[Step 8368] Loss: 9.62e+07 0.22741800546646118 0.5211663842201233\n",
      "[Step 8369] Loss: 9.59e+07 0.22695299983024597 0.521040141582489\n",
      "[Step 8370] Loss: 9.80e+07 0.22634832561016083 0.5208545327186584\n",
      "[Step 8371] Loss: 9.56e+07 0.2258669137954712 0.5207018852233887\n",
      "[Step 8372] Loss: 9.59e+07 0.2254268229007721 0.5205920934677124\n",
      "[Step 8373] Loss: 9.65e+07 0.22508065402507782 0.5205079317092896\n",
      "[Step 8374] Loss: 9.75e+07 0.22465702891349792 0.5203998684883118\n",
      "[Step 8375] Loss: 9.65e+07 0.22428110241889954 0.5203239321708679\n",
      "[Step 8376] Loss: 9.69e+07 0.22384795546531677 0.5202034711837769\n",
      "[Step 8377] Loss: 9.59e+07 0.22345606982707977 0.5200879573822021\n",
      "[Step 8378] Loss: 9.56e+07 0.2231103628873825 0.5200153589248657\n",
      "[Step 8379] Loss: 9.59e+07 0.22282683849334717 0.5199262499809265\n",
      "[Step 8380] Loss: 9.73e+07 0.22265763580799103 0.5198635458946228\n",
      "[Step 8381] Loss: 9.64e+07 0.22254712879657745 0.519855260848999\n",
      "[Step 8382] Loss: 9.63e+07 0.22231771051883698 0.5198016166687012\n",
      "[Step 8383] Loss: 9.63e+07 0.22209636867046356 0.5197587013244629\n",
      "[Step 8384] Loss: 9.62e+07 0.22181259095668793 0.5197058916091919\n",
      "[Step 8385] Loss: 9.64e+07 0.22158463299274445 0.5196506381034851\n",
      "[Step 8386] Loss: 9.60e+07 0.22139380872249603 0.5196366310119629\n",
      "[Step 8387] Loss: 9.68e+07 0.22127243876457214 0.5196044445037842\n",
      "[Step 8388] Loss: 9.61e+07 0.22110454738140106 0.5195615291595459\n",
      "[Step 8389] Loss: 9.60e+07 0.2209901362657547 0.5195243954658508\n",
      "[Step 8390] Loss: 9.55e+07 0.220893993973732 0.5194979906082153\n",
      "[Step 8391] Loss: 9.59e+07 0.22086110711097717 0.5195087194442749\n",
      "[Step 8392] Loss: 9.56e+07 0.22088591754436493 0.5195268392562866\n",
      "[Step 8393] Loss: 9.66e+07 0.22094228863716125 0.519538402557373\n",
      "[Step 8394] Loss: 9.59e+07 0.22104883193969727 0.5195598602294922\n",
      "[Step 8395] Loss: 9.71e+07 0.22099700570106506 0.5195293426513672\n",
      "[Step 8396] Loss: 9.64e+07 0.22098208963871002 0.5195285081863403\n",
      "[Step 8397] Loss: 9.56e+07 0.22098436951637268 0.5195516347885132\n",
      "[Step 8398] Loss: 9.66e+07 0.22102206945419312 0.5195838212966919\n",
      "[Step 8399] Loss: 9.64e+07 0.2210952192544937 0.5196036100387573\n",
      "[Step 8400] Loss: 9.57e+07 0.221160888671875 0.519635796546936\n",
      "[Step 8401] Loss: 9.67e+07 0.2211722880601883 0.5196572542190552\n",
      "[Step 8402] Loss: 9.73e+07 0.22106754779815674 0.5196036100387573\n",
      "[Step 8403] Loss: 9.62e+07 0.22098080813884735 0.5196011066436768\n",
      "[Step 8404] Loss: 9.65e+07 0.22090624272823334 0.5195945501327515\n",
      "[Step 8405] Loss: 9.74e+07 0.2207271307706833 0.5195359587669373\n",
      "[Step 8406] Loss: 9.56e+07 0.22055083513259888 0.5195186138153076\n",
      "[Step 8407] Loss: 9.80e+07 0.22017790377140045 0.5193890929222107\n",
      "[Step 8408] Loss: 9.63e+07 0.21976043283939362 0.5193156003952026\n",
      "[Step 8409] Loss: 9.51e+07 0.21942217648029327 0.5192207098007202\n",
      "[Step 8410] Loss: 9.61e+07 0.2190820872783661 0.5191143155097961\n",
      "[Step 8411] Loss: 9.55e+07 0.218787282705307 0.5190342664718628\n",
      "[Step 8412] Loss: 9.67e+07 0.21856923401355743 0.5189698934555054\n",
      "[Step 8413] Loss: 9.65e+07 0.21840797364711761 0.5189269781112671\n",
      "[Step 8414] Loss: 9.60e+07 0.21817313134670258 0.5188700556755066\n",
      "[Step 8415] Loss: 9.57e+07 0.2179596722126007 0.5187768340110779\n",
      "[Step 8416] Loss: 9.67e+07 0.21771669387817383 0.5187058448791504\n",
      "[Step 8417] Loss: 9.67e+07 0.21737472712993622 0.5186423063278198\n",
      "[Step 8418] Loss: 9.64e+07 0.2169477492570877 0.5185325741767883\n",
      "[Step 8419] Loss: 9.66e+07 0.2166842669248581 0.5184615850448608\n",
      "[Step 8420] Loss: 9.61e+07 0.21640093624591827 0.518375813961029\n",
      "[Step 8421] Loss: 9.65e+07 0.21621054410934448 0.5183502435684204\n",
      "[Step 8422] Loss: 9.74e+07 0.2162332385778427 0.5183733105659485\n",
      "[Step 8423] Loss: 9.61e+07 0.2162194550037384 0.5184162259101868\n",
      "[Step 8424] Loss: 9.66e+07 0.21608975529670715 0.5183708667755127\n",
      "[Step 8425] Loss: 9.66e+07 0.2159349024295807 0.5183551907539368\n",
      "[Step 8426] Loss: 9.59e+07 0.21579837799072266 0.5183138847351074\n",
      "[Step 8427] Loss: 9.61e+07 0.21569755673408508 0.5183238387107849\n",
      "[Step 8428] Loss: 9.58e+07 0.21574288606643677 0.5183485746383667\n",
      "[Step 8429] Loss: 9.59e+07 0.21569696068763733 0.5183370113372803\n",
      "[Step 8430] Loss: 9.56e+07 0.21564729511737823 0.5183238387107849\n",
      "[Step 8431] Loss: 9.58e+07 0.2155901938676834 0.518285870552063\n",
      "[Step 8432] Loss: 9.67e+07 0.21538759768009186 0.5182371735572815\n",
      "[Step 8433] Loss: 9.63e+07 0.21528294682502747 0.5182082653045654\n",
      "[Step 8434] Loss: 9.58e+07 0.21512508392333984 0.5181455612182617\n",
      "[Step 8435] Loss: 9.68e+07 0.21480019390583038 0.5180589556694031\n",
      "[Step 8436] Loss: 9.58e+07 0.21461723744869232 0.5180251002311707\n",
      "[Step 8437] Loss: 9.65e+07 0.21437300741672516 0.5179747939109802\n",
      "[Step 8438] Loss: 9.59e+07 0.21414537727832794 0.5179516673088074\n",
      "[Step 8439] Loss: 9.71e+07 0.21405519545078278 0.5179186463356018\n",
      "[Step 8440] Loss: 9.68e+07 0.21394939720630646 0.5178996920585632\n",
      "[Step 8441] Loss: 9.66e+07 0.21378375589847565 0.5178295373916626\n",
      "[Step 8442] Loss: 9.64e+07 0.21375282108783722 0.5178221464157104\n",
      "[Step 8443] Loss: 9.57e+07 0.21373391151428223 0.5178089141845703\n",
      "[Step 8444] Loss: 9.61e+07 0.21382740139961243 0.517834484577179\n",
      "[Step 8445] Loss: 9.70e+07 0.21397583186626434 0.5178460478782654\n",
      "[Step 8446] Loss: 9.70e+07 0.2141832709312439 0.5178881287574768\n",
      "[Step 8447] Loss: 9.56e+07 0.21441476047039032 0.5179640650749207\n",
      "[Step 8448] Loss: 9.67e+07 0.21476928889751434 0.5180515050888062\n",
      "[Step 8449] Loss: 9.62e+07 0.21516911685466766 0.518180251121521\n",
      "[Step 8450] Loss: 9.59e+07 0.21553950011730194 0.5183064937591553\n",
      "[Step 8451] Loss: 9.56e+07 0.2158205360174179 0.5183873176574707\n",
      "[Step 8452] Loss: 9.61e+07 0.21602338552474976 0.5184615850448608\n",
      "[Step 8453] Loss: 9.50e+07 0.21619312465190887 0.5185070037841797\n",
      "[Step 8454] Loss: 9.60e+07 0.21632084250450134 0.5185309052467346\n",
      "[Step 8455] Loss: 9.61e+07 0.2163126915693283 0.518535852432251\n",
      "[Step 8456] Loss: 9.60e+07 0.21631218492984772 0.5185713768005371\n",
      "[Step 8457] Loss: 9.61e+07 0.21627990901470184 0.5185771584510803\n",
      "[Step 8458] Loss: 9.67e+07 0.21611793339252472 0.5185523629188538\n",
      "[Step 8459] Loss: 9.63e+07 0.21594074368476868 0.518511950969696\n",
      "[Step 8460] Loss: 9.68e+07 0.21575473248958588 0.5184756517410278\n",
      "[Step 8461] Loss: 9.61e+07 0.21567749977111816 0.5184789299964905\n",
      "[Step 8462] Loss: 9.64e+07 0.21562348306179047 0.5184599757194519\n",
      "[Step 8463] Loss: 9.58e+07 0.21556393802165985 0.5184566378593445\n",
      "[Step 8464] Loss: 9.62e+07 0.2154875546693802 0.518430233001709\n",
      "[Step 8465] Loss: 9.61e+07 0.215468630194664 0.5184228420257568\n",
      "[Step 8466] Loss: 9.61e+07 0.21556560695171356 0.5184533596038818\n",
      "[Step 8467] Loss: 9.59e+07 0.21559108793735504 0.5184632539749146\n",
      "[Step 8468] Loss: 9.55e+07 0.2156085968017578 0.5184872150421143\n",
      "[Step 8469] Loss: 9.66e+07 0.2156212031841278 0.5184756517410278\n",
      "[Step 8470] Loss: 9.68e+07 0.21563810110092163 0.518467366695404\n",
      "[Step 8471] Loss: 9.64e+07 0.2156350016593933 0.5184822678565979\n",
      "[Step 8472] Loss: 9.67e+07 0.21563725173473358 0.5184872150421143\n",
      "[Step 8473] Loss: 9.76e+07 0.21572382748126984 0.518474817276001\n",
      "[Step 8474] Loss: 9.61e+07 0.21581168472766876 0.5184847116470337\n",
      "[Step 8475] Loss: 9.66e+07 0.21588066220283508 0.5184995532035828\n",
      "[Step 8476] Loss: 9.62e+07 0.21600860357284546 0.5185251235961914\n",
      "[Step 8477] Loss: 9.56e+07 0.2161841243505478 0.5185523629188538\n",
      "[Step 8478] Loss: 9.55e+07 0.21641646325588226 0.5186266303062439\n",
      "[Step 8479] Loss: 9.57e+07 0.21658474206924438 0.518708348274231\n",
      "[Step 8480] Loss: 9.60e+07 0.21673831343650818 0.5187421441078186\n",
      "[Step 8481] Loss: 9.66e+07 0.2168368101119995 0.5187685489654541\n",
      "[Step 8482] Loss: 9.74e+07 0.21684704720973969 0.5187636017799377\n",
      "[Step 8483] Loss: 9.55e+07 0.2168596088886261 0.518753707408905\n",
      "[Step 8484] Loss: 9.74e+07 0.21702226996421814 0.51878422498703\n",
      "[Step 8485] Loss: 9.70e+07 0.21724414825439453 0.5188213586807251\n",
      "[Step 8486] Loss: 9.63e+07 0.2175336480140686 0.5189253091812134\n",
      "[Step 8487] Loss: 9.61e+07 0.21782241761684418 0.5189822912216187\n",
      "[Step 8488] Loss: 9.57e+07 0.2181532233953476 0.51907879114151\n",
      "[Step 8489] Loss: 9.64e+07 0.21853187680244446 0.5191802978515625\n",
      "[Step 8490] Loss: 9.56e+07 0.21892069280147552 0.5192611813545227\n",
      "[Step 8491] Loss: 9.59e+07 0.21925653517246246 0.5193610191345215\n",
      "[Step 8492] Loss: 9.70e+07 0.2195499688386917 0.5194319486618042\n",
      "[Step 8493] Loss: 9.57e+07 0.2199188768863678 0.519516110420227\n",
      "[Step 8494] Loss: 9.77e+07 0.22019429504871368 0.5195854306221008\n",
      "[Step 8495] Loss: 9.67e+07 0.2203121930360794 0.5196588635444641\n",
      "[Step 8496] Loss: 9.60e+07 0.22043120861053467 0.5196844339370728\n",
      "[Step 8497] Loss: 9.61e+07 0.2205212116241455 0.519696831703186\n",
      "[Step 8498] Loss: 9.69e+07 0.22051511704921722 0.5196811556816101\n",
      "[Step 8499] Loss: 9.64e+07 0.22058886289596558 0.5197298526763916\n",
      "[Step 8500] Loss: 9.65e+07 0.2207024246454239 0.5197644829750061\n",
      "[Step 8501] Loss: 9.62e+07 0.22079363465309143 0.519765317440033\n",
      "[Step 8502] Loss: 9.71e+07 0.22096551954746246 0.5197950601577759\n",
      "[Step 8503] Loss: 9.63e+07 0.22110013663768768 0.5198338031768799\n",
      "[Step 8504] Loss: 9.60e+07 0.2212308943271637 0.5198528170585632\n",
      "[Step 8505] Loss: 9.72e+07 0.22138208150863647 0.5198940634727478\n",
      "[Step 8506] Loss: 9.63e+07 0.22150647640228271 0.5198990106582642\n",
      "[Step 8507] Loss: 9.85e+07 0.22144784033298492 0.5198668241500854\n",
      "[Step 8508] Loss: 9.71e+07 0.22125521302223206 0.5198346376419067\n",
      "[Step 8509] Loss: 9.68e+07 0.22100120782852173 0.5197793245315552\n",
      "[Step 8510] Loss: 9.62e+07 0.2207135409116745 0.5196844339370728\n",
      "[Step 8511] Loss: 9.55e+07 0.22042307257652283 0.5196167826652527\n",
      "[Step 8512] Loss: 9.62e+07 0.22015927731990814 0.5195804834365845\n",
      "[Step 8513] Loss: 9.57e+07 0.2199413925409317 0.5195070505142212\n",
      "[Step 8514] Loss: 9.65e+07 0.2197902649641037 0.5194649696350098\n",
      "[Step 8515] Loss: 9.66e+07 0.21965527534484863 0.5194559097290039\n",
      "[Step 8516] Loss: 9.61e+07 0.21948398649692535 0.5194162726402283\n",
      "[Step 8517] Loss: 9.65e+07 0.21926601231098175 0.5193247199058533\n",
      "[Step 8518] Loss: 9.72e+07 0.2189655601978302 0.5192446708679199\n",
      "[Step 8519] Loss: 9.70e+07 0.2186507284641266 0.5191571712493896\n",
      "[Step 8520] Loss: 9.68e+07 0.21842823922634125 0.5191002488136292\n",
      "[Step 8521] Loss: 9.54e+07 0.21818147599697113 0.5190358757972717\n",
      "[Step 8522] Loss: 9.57e+07 0.21800552308559418 0.5189937949180603\n",
      "[Step 8523] Loss: 9.57e+07 0.21789370477199554 0.5189558863639832\n",
      "[Step 8524] Loss: 9.62e+07 0.2176654040813446 0.5188824534416199\n",
      "[Step 8525] Loss: 9.64e+07 0.21742534637451172 0.5187925100326538\n",
      "[Step 8526] Loss: 9.63e+07 0.21714910864830017 0.5187355279922485\n",
      "[Step 8527] Loss: 9.58e+07 0.21697033941745758 0.518694281578064\n",
      "[Step 8528] Loss: 9.60e+07 0.21675744652748108 0.5186356902122498\n",
      "[Step 8529] Loss: 9.69e+07 0.21657021343708038 0.5185845494270325\n",
      "[Step 8530] Loss: 9.65e+07 0.21653518080711365 0.5185738205909729\n",
      "[Step 8531] Loss: 9.57e+07 0.21644093096256256 0.5185309052467346\n",
      "[Step 8532] Loss: 9.61e+07 0.2163272351026535 0.5184682011604309\n",
      "[Step 8533] Loss: 9.67e+07 0.21631953120231628 0.5184723138809204\n",
      "[Step 8534] Loss: 9.70e+07 0.21620161831378937 0.518459141254425\n",
      "[Step 8535] Loss: 9.60e+07 0.21615669131278992 0.5184723138809204\n",
      "[Step 8536] Loss: 9.65e+07 0.21614551544189453 0.5184772610664368\n",
      "[Step 8537] Loss: 9.61e+07 0.21606242656707764 0.5184574723243713\n",
      "[Step 8538] Loss: 9.64e+07 0.2159731388092041 0.5184129476547241\n",
      "[Step 8539] Loss: 9.63e+07 0.21598660945892334 0.5184187293052673\n",
      "[Step 8540] Loss: 9.66e+07 0.21607697010040283 0.5184475779533386\n",
      "[Step 8541] Loss: 9.61e+07 0.21618714928627014 0.5184888243675232\n",
      "[Step 8542] Loss: 9.65e+07 0.2162346988916397 0.5185036659240723\n",
      "[Step 8543] Loss: 9.56e+07 0.21629135310649872 0.5185251235961914\n",
      "[Step 8544] Loss: 9.65e+07 0.21636365354061127 0.5185672044754028\n",
      "[Step 8545] Loss: 9.63e+07 0.21645866334438324 0.5186043381690979\n",
      "[Step 8546] Loss: 9.65e+07 0.21637164056301117 0.5185705423355103\n",
      "[Step 8547] Loss: 9.65e+07 0.21622975170612335 0.5185350179672241\n",
      "[Step 8548] Loss: 9.59e+07 0.21616126596927643 0.5185185670852661\n",
      "[Step 8549] Loss: 9.64e+07 0.2160336673259735 0.5184962749481201\n",
      "[Step 8550] Loss: 9.62e+07 0.215971902012825 0.5184962749481201\n",
      "[Step 8551] Loss: 9.73e+07 0.21599926054477692 0.518505334854126\n",
      "[Step 8552] Loss: 9.58e+07 0.21597184240818024 0.5185078382492065\n",
      "[Step 8553] Loss: 9.66e+07 0.21597081422805786 0.518481433391571\n",
      "[Step 8554] Loss: 9.59e+07 0.21592563390731812 0.518474817276001\n",
      "[Step 8555] Loss: 9.63e+07 0.21592146158218384 0.5184484124183655\n",
      "[Step 8556] Loss: 9.70e+07 0.21579477190971375 0.5183939337730408\n",
      "[Step 8557] Loss: 9.63e+07 0.21557532250881195 0.5183254480361938\n",
      "[Step 8558] Loss: 9.74e+07 0.2154875546693802 0.5182850360870361\n",
      "[Step 8559] Loss: 9.58e+07 0.21538099646568298 0.5182346701622009\n",
      "[Step 8560] Loss: 9.57e+07 0.2153119146823883 0.5182124376296997\n",
      "[Step 8561] Loss: 9.72e+07 0.21508359909057617 0.518157958984375\n",
      "[Step 8562] Loss: 9.53e+07 0.21487395465373993 0.5181167125701904\n",
      "[Step 8563] Loss: 9.64e+07 0.21471662819385529 0.5180597901344299\n",
      "[Step 8564] Loss: 9.64e+07 0.21458281576633453 0.5180152058601379\n",
      "[Step 8565] Loss: 9.60e+07 0.21450626850128174 0.5179945826530457\n",
      "[Step 8566] Loss: 9.66e+07 0.21446119248867035 0.5180061459541321\n",
      "[Step 8567] Loss: 9.66e+07 0.21442292630672455 0.5179731249809265\n",
      "[Step 8568] Loss: 9.68e+07 0.21427130699157715 0.5179170370101929\n",
      "[Step 8569] Loss: 9.63e+07 0.21412354707717896 0.5178452134132385\n",
      "[Step 8570] Loss: 9.59e+07 0.21400921046733856 0.5178080797195435\n",
      "[Step 8571] Loss: 9.60e+07 0.2138962596654892 0.5176959037780762\n",
      "[Step 8572] Loss: 9.62e+07 0.2137819230556488 0.5176768898963928\n",
      "[Step 8573] Loss: 9.72e+07 0.21346431970596313 0.5175679922103882\n",
      "[Step 8574] Loss: 9.51e+07 0.21316681802272797 0.5174731016159058\n",
      "[Step 8575] Loss: 9.57e+07 0.21291476488113403 0.5174177885055542\n",
      "[Step 8576] Loss: 9.62e+07 0.212580606341362 0.517327070236206\n",
      "[Step 8577] Loss: 9.61e+07 0.212239608168602 0.517267644405365\n",
      "[Step 8578] Loss: 9.57e+07 0.21193595230579376 0.5171455144882202\n",
      "[Step 8579] Loss: 9.60e+07 0.21170906722545624 0.5171298384666443\n",
      "[Step 8580] Loss: 9.61e+07 0.21156395971775055 0.5170688033103943\n",
      "[Step 8581] Loss: 9.63e+07 0.21140725910663605 0.5170547366142273\n",
      "[Step 8582] Loss: 9.53e+07 0.21126142144203186 0.5170308351516724\n",
      "[Step 8583] Loss: 9.56e+07 0.2111245095729828 0.5170134902000427\n",
      "[Step 8584] Loss: 9.95e+07 0.2107199728488922 0.5169475078582764\n",
      "[Step 8585] Loss: 9.59e+07 0.21027426421642303 0.5168426632881165\n",
      "[Step 8586] Loss: 9.64e+07 0.20977802574634552 0.5167403817176819\n",
      "[Step 8587] Loss: 9.59e+07 0.20929455757141113 0.516649603843689\n",
      "[Step 8588] Loss: 9.69e+07 0.208938330411911 0.5166000723838806\n",
      "[Step 8589] Loss: 9.54e+07 0.20865628123283386 0.5165579915046692\n",
      "[Step 8590] Loss: 9.65e+07 0.2083747684955597 0.5164936780929565\n",
      "[Step 8591] Loss: 9.63e+07 0.20801764726638794 0.5164095163345337\n",
      "[Step 8592] Loss: 9.59e+07 0.20762871205806732 0.516310453414917\n",
      "[Step 8593] Loss: 9.60e+07 0.20728161931037903 0.5162255167961121\n",
      "[Step 8594] Loss: 9.66e+07 0.20685309171676636 0.5161231756210327\n",
      "[Step 8595] Loss: 9.70e+07 0.20645993947982788 0.5160323977470398\n",
      "[Step 8596] Loss: 9.57e+07 0.20607785880565643 0.5159507393836975\n",
      "[Step 8597] Loss: 9.70e+07 0.2058473825454712 0.5159267783164978\n",
      "[Step 8598] Loss: 9.58e+07 0.2055540531873703 0.5158657431602478\n",
      "[Step 8599] Loss: 9.68e+07 0.20509125292301178 0.5157535076141357\n",
      "[Step 8600] Loss: 9.57e+07 0.20473264157772064 0.515684187412262\n",
      "[Step 8601] Loss: 9.75e+07 0.20447289943695068 0.5155918002128601\n",
      "[Step 8602] Loss: 9.66e+07 0.2043178826570511 0.5155604481697083\n",
      "[Step 8603] Loss: 9.60e+07 0.20412442088127136 0.5154548287391663\n",
      "[Step 8604] Loss: 9.66e+07 0.20390932261943817 0.5153788924217224\n",
      "[Step 8605] Loss: 9.67e+07 0.2037004977464676 0.5153029561042786\n",
      "[Step 8606] Loss: 9.59e+07 0.203525111079216 0.5152386426925659\n",
      "[Step 8607] Loss: 9.57e+07 0.20341067016124725 0.5152369737625122\n",
      "[Step 8608] Loss: 9.64e+07 0.20338329672813416 0.5152270793914795\n",
      "[Step 8609] Loss: 9.59e+07 0.20337960124015808 0.5151957273483276\n",
      "[Step 8610] Loss: 9.57e+07 0.20340780913829803 0.5151957273483276\n",
      "[Step 8611] Loss: 9.67e+07 0.20355209708213806 0.5151973962783813\n",
      "[Step 8612] Loss: 9.58e+07 0.20369865000247955 0.5152427554130554\n",
      "[Step 8613] Loss: 9.62e+07 0.2039177417755127 0.5153021812438965\n",
      "[Step 8614] Loss: 9.59e+07 0.20419427752494812 0.5153409242630005\n",
      "[Step 8615] Loss: 9.54e+07 0.2044687569141388 0.5154028534889221\n",
      "[Step 8616] Loss: 9.53e+07 0.20478761196136475 0.515503466129303\n",
      "[Step 8617] Loss: 9.60e+07 0.2050675004720688 0.5155505537986755\n",
      "[Step 8618] Loss: 9.59e+07 0.20534421503543854 0.5156223177909851\n",
      "[Step 8619] Loss: 9.61e+07 0.20551876723766327 0.5156710147857666\n",
      "[Step 8620] Loss: 9.65e+07 0.2056528478860855 0.5156899690628052\n",
      "[Step 8621] Loss: 9.60e+07 0.20576857030391693 0.5157155394554138\n",
      "[Step 8622] Loss: 9.69e+07 0.20573008060455322 0.5156742930412292\n",
      "[Step 8623] Loss: 9.53e+07 0.2057151347398758 0.5156701803207397\n",
      "[Step 8624] Loss: 9.57e+07 0.20571675896644592 0.515660285949707\n",
      "[Step 8625] Loss: 9.56e+07 0.20574526488780975 0.5156817436218262\n",
      "[Step 8626] Loss: 9.59e+07 0.20580027997493744 0.5156693458557129\n",
      "[Step 8627] Loss: 9.71e+07 0.20574651658535004 0.515660285949707\n",
      "[Step 8628] Loss: 9.55e+07 0.20563285052776337 0.5156354904174805\n",
      "[Step 8629] Loss: 9.54e+07 0.20561538636684418 0.5156198143959045\n",
      "[Step 8630] Loss: 9.57e+07 0.205571249127388 0.5156140327453613\n",
      "[Step 8631] Loss: 9.61e+07 0.20560897886753082 0.515623152256012\n",
      "[Step 8632] Loss: 9.61e+07 0.20574951171875 0.5156660676002502\n",
      "[Step 8633] Loss: 9.65e+07 0.2058718204498291 0.5157312154769897\n",
      "[Step 8634] Loss: 9.67e+07 0.20598798990249634 0.5157683491706848\n",
      "[Step 8635] Loss: 9.57e+07 0.20617109537124634 0.5157683491706848\n",
      "[Step 8636] Loss: 9.72e+07 0.20625245571136475 0.5157683491706848\n",
      "[Step 8637] Loss: 9.63e+07 0.20624442398548126 0.5157551765441895\n",
      "[Step 8638] Loss: 9.56e+07 0.20625519752502441 0.5157535076141357\n",
      "[Step 8639] Loss: 9.61e+07 0.20622853934764862 0.515751838684082\n",
      "[Step 8640] Loss: 9.72e+07 0.20601876080036163 0.515706479549408\n",
      "[Step 8641] Loss: 9.79e+07 0.20560918748378754 0.5155802369117737\n",
      "[Step 8642] Loss: 9.66e+07 0.20525066554546356 0.5154606103897095\n",
      "[Step 8643] Loss: 9.68e+07 0.2047998160123825 0.5153574347496033\n",
      "[Step 8644] Loss: 9.61e+07 0.20435830950737 0.5152196288108826\n",
      "[Step 8645] Loss: 9.57e+07 0.203983336687088 0.5151016712188721\n",
      "[Step 8646] Loss: 9.61e+07 0.20370109379291534 0.5150446891784668\n",
      "[Step 8647] Loss: 9.65e+07 0.2034182846546173 0.5149911046028137\n",
      "[Step 8648] Loss: 9.56e+07 0.20320020616054535 0.5149688124656677\n",
      "[Step 8649] Loss: 9.67e+07 0.20306448638439178 0.5149473547935486\n",
      "[Step 8650] Loss: 9.56e+07 0.20293033123016357 0.5148870944976807\n",
      "[Step 8651] Loss: 9.64e+07 0.20272605121135712 0.514793872833252\n",
      "[Step 8652] Loss: 9.54e+07 0.20261617004871368 0.5147493481636047\n",
      "[Step 8653] Loss: 9.61e+07 0.20250780880451202 0.5146957039833069\n",
      "[Step 8654] Loss: 9.56e+07 0.20245014131069183 0.5146601796150208\n",
      "[Step 8655] Loss: 9.62e+07 0.2023225575685501 0.5145966410636902\n",
      "[Step 8656] Loss: 9.59e+07 0.20225609838962555 0.5145645141601562\n",
      "[Step 8657] Loss: 9.59e+07 0.2022850066423416 0.5145611763000488\n",
      "[Step 8658] Loss: 9.60e+07 0.20234866440296173 0.5145785212516785\n",
      "[Step 8659] Loss: 9.66e+07 0.20237594842910767 0.5145537853240967\n",
      "[Step 8660] Loss: 9.61e+07 0.2024858593940735 0.5145875811576843\n",
      "[Step 8661] Loss: 9.56e+07 0.2025071233510971 0.514536440372467\n",
      "[Step 8662] Loss: 9.57e+07 0.20249928534030914 0.5145232081413269\n",
      "[Step 8663] Loss: 9.76e+07 0.20229768753051758 0.5144572257995605\n",
      "[Step 8664] Loss: 9.50e+07 0.20205184817314148 0.5144044160842896\n",
      "[Step 8665] Loss: 9.61e+07 0.20176921784877777 0.5143020749092102\n",
      "[Step 8666] Loss: 9.61e+07 0.20142945647239685 0.5141642689704895\n",
      "[Step 8667] Loss: 9.67e+07 0.20101110637187958 0.514024019241333\n",
      "[Step 8668] Loss: 9.61e+07 0.20062027871608734 0.5139027237892151\n",
      "[Step 8669] Loss: 9.65e+07 0.2002539038658142 0.5137773156166077\n",
      "[Step 8670] Loss: 9.57e+07 0.19991400837898254 0.5136824250221252\n",
      "[Step 8671] Loss: 9.63e+07 0.1995391696691513 0.5135669112205505\n",
      "[Step 8672] Loss: 9.55e+07 0.1992044895887375 0.5134538412094116\n",
      "[Step 8673] Loss: 9.60e+07 0.19889359176158905 0.5133664011955261\n",
      "[Step 8674] Loss: 9.66e+07 0.19863009452819824 0.5132781267166138\n",
      "[Step 8675] Loss: 9.57e+07 0.1984410583972931 0.5132219791412354\n",
      "[Step 8676] Loss: 9.57e+07 0.1982109397649765 0.5131543278694153\n",
      "[Step 8677] Loss: 9.62e+07 0.19786322116851807 0.5130272507667542\n",
      "[Step 8678] Loss: 9.70e+07 0.1976519376039505 0.5129703283309937\n",
      "[Step 8679] Loss: 9.61e+07 0.19746263325214386 0.5128968954086304\n",
      "[Step 8680] Loss: 9.56e+07 0.1972889006137848 0.5128762722015381\n",
      "[Step 8681] Loss: 9.64e+07 0.19714711606502533 0.5128374695777893\n",
      "[Step 8682] Loss: 9.57e+07 0.1970120072364807 0.5127755999565125\n",
      "[Step 8683] Loss: 9.56e+07 0.19695673882961273 0.5127401351928711\n",
      "[Step 8684] Loss: 9.69e+07 0.1968897432088852 0.5127310156822205\n",
      "[Step 8685] Loss: 9.66e+07 0.19674107432365417 0.5126667022705078\n",
      "[Step 8686] Loss: 9.52e+07 0.19662590324878693 0.5126221179962158\n",
      "[Step 8687] Loss: 9.61e+07 0.19641496241092682 0.5126006603240967\n",
      "[Step 8688] Loss: 9.58e+07 0.19620761275291443 0.5125330090522766\n",
      "[Step 8689] Loss: 9.58e+07 0.1960669606924057 0.5125164985656738\n",
      "[Step 8690] Loss: 9.71e+07 0.1958066076040268 0.512477695941925\n",
      "[Step 8691] Loss: 9.58e+07 0.1955258995294571 0.5124397873878479\n",
      "[Step 8692] Loss: 9.57e+07 0.19527262449264526 0.5123687982559204\n",
      "[Step 8693] Loss: 9.63e+07 0.1951698213815689 0.512334942817688\n",
      "[Step 8694] Loss: 9.57e+07 0.19510315358638763 0.5123357772827148\n",
      "[Step 8695] Loss: 9.61e+07 0.1951267123222351 0.5123696327209473\n",
      "[Step 8696] Loss: 9.62e+07 0.19511567056179047 0.5123630166053772\n",
      "[Step 8697] Loss: 9.60e+07 0.19508466124534607 0.5123522877693176\n",
      "[Step 8698] Loss: 9.60e+07 0.19500088691711426 0.5123299956321716\n",
      "[Step 8699] Loss: 9.66e+07 0.19479893147945404 0.5122268795967102\n",
      "[Step 8700] Loss: 9.64e+07 0.19457043707370758 0.5121501088142395\n",
      "[Step 8701] Loss: 9.56e+07 0.1943749338388443 0.5121023058891296\n",
      "[Step 8702] Loss: 9.58e+07 0.1943112164735794 0.5120379328727722\n",
      "[Step 8703] Loss: 9.61e+07 0.19437865912914276 0.5120824575424194\n",
      "[Step 8704] Loss: 9.65e+07 0.1944301426410675 0.5120907425880432\n",
      "[Step 8705] Loss: 9.65e+07 0.19451747834682465 0.5120684504508972\n",
      "[Step 8706] Loss: 9.54e+07 0.19454745948314667 0.5120304822921753\n",
      "[Step 8707] Loss: 9.65e+07 0.194449320435524 0.5119859576225281\n",
      "[Step 8708] Loss: 9.69e+07 0.19447769224643707 0.511979341506958\n",
      "[Step 8709] Loss: 9.63e+07 0.1944563090801239 0.5119611620903015\n",
      "[Step 8710] Loss: 9.64e+07 0.19435052573680878 0.5119009613990784\n",
      "[Step 8711] Loss: 9.69e+07 0.1941576451063156 0.5118555426597595\n",
      "[Step 8712] Loss: 9.64e+07 0.19395975768566132 0.5117672681808472\n",
      "[Step 8713] Loss: 9.73e+07 0.19366398453712463 0.5116468071937561\n",
      "[Step 8714] Loss: 9.60e+07 0.19343969225883484 0.5114966034889221\n",
      "[Step 8715] Loss: 9.64e+07 0.19319747388362885 0.5114190578460693\n",
      "[Step 8716] Loss: 9.68e+07 0.19316178560256958 0.5113976001739502\n",
      "[Step 8717] Loss: 9.59e+07 0.19309388101100922 0.5113645792007446\n",
      "[Step 8718] Loss: 9.57e+07 0.19311097264289856 0.5113555192947388\n",
      "[Step 8719] Loss: 9.56e+07 0.19310195744037628 0.5113489031791687\n",
      "[Step 8720] Loss: 9.60e+07 0.19303005933761597 0.5113291144371033\n",
      "[Step 8721] Loss: 9.58e+07 0.19305600225925446 0.5112804174423218\n",
      "[Step 8722] Loss: 9.54e+07 0.19306907057762146 0.5112548470497131\n",
      "[Step 8723] Loss: 9.52e+07 0.1930638700723648 0.5112284421920776\n",
      "[Step 8724] Loss: 9.61e+07 0.19297507405281067 0.5112284421920776\n",
      "[Step 8725] Loss: 9.61e+07 0.1929953545331955 0.5112226605415344\n",
      "[Step 8726] Loss: 9.62e+07 0.19314055144786835 0.511277973651886\n",
      "[Step 8727] Loss: 9.63e+07 0.19334381818771362 0.5113481283187866\n",
      "[Step 8728] Loss: 9.53e+07 0.19352373480796814 0.511383593082428\n",
      "[Step 8729] Loss: 9.57e+07 0.1937500685453415 0.5114306211471558\n",
      "[Step 8730] Loss: 9.57e+07 0.19393879175186157 0.5114916563034058\n",
      "[Step 8731] Loss: 9.75e+07 0.19384600222110748 0.5114685893058777\n",
      "[Step 8732] Loss: 9.57e+07 0.1937592625617981 0.5114809274673462\n",
      "[Step 8733] Loss: 9.59e+07 0.19371217489242554 0.5114875435829163\n",
      "[Step 8734] Loss: 9.59e+07 0.1936376988887787 0.511436402797699\n",
      "[Step 8735] Loss: 9.62e+07 0.19367431104183197 0.5114306211471558\n",
      "[Step 8736] Loss: 9.63e+07 0.1937306821346283 0.5114454627037048\n",
      "[Step 8737] Loss: 9.58e+07 0.1937524974346161 0.5114545226097107\n",
      "[Step 8738] Loss: 9.58e+07 0.19373494386672974 0.5114042162895203\n",
      "[Step 8739] Loss: 9.64e+07 0.19374409317970276 0.5113753080368042\n",
      "[Step 8740] Loss: 9.61e+07 0.19380523264408112 0.5113629698753357\n",
      "[Step 8741] Loss: 9.57e+07 0.19385042786598206 0.5113481283187866\n",
      "[Step 8742] Loss: 9.53e+07 0.19392578303813934 0.5113415122032166\n",
      "[Step 8743] Loss: 9.61e+07 0.19402208924293518 0.511361300945282\n",
      "[Step 8744] Loss: 9.69e+07 0.19395269453525543 0.5113332271575928\n",
      "[Step 8745] Loss: 9.50e+07 0.19394515454769135 0.5113208889961243\n",
      "[Step 8746] Loss: 9.61e+07 0.19388990104198456 0.5112936496734619\n",
      "[Step 8747] Loss: 9.61e+07 0.1938670426607132 0.5112994313240051\n",
      "[Step 8748] Loss: 9.64e+07 0.19388045370578766 0.5112696886062622\n",
      "[Step 8749] Loss: 9.61e+07 0.19392703473567963 0.511286199092865\n",
      "[Step 8750] Loss: 9.63e+07 0.19396482408046722 0.5112696886062622\n",
      "[Step 8751] Loss: 9.64e+07 0.194071963429451 0.5112573504447937\n",
      "[Step 8752] Loss: 9.74e+07 0.19430187344551086 0.5113381743431091\n",
      "[Step 8753] Loss: 9.56e+07 0.19450727105140686 0.511391818523407\n",
      "[Step 8754] Loss: 9.55e+07 0.1946130394935608 0.5113819241523743\n",
      "[Step 8755] Loss: 9.60e+07 0.1947641372680664 0.5114314556121826\n",
      "[Step 8756] Loss: 9.73e+07 0.19509930908679962 0.5115007758140564\n",
      "[Step 8757] Loss: 9.56e+07 0.19542358815670013 0.511572539806366\n",
      "[Step 8758] Loss: 9.53e+07 0.19570964574813843 0.5116451382637024\n",
      "[Step 8759] Loss: 9.55e+07 0.19599169492721558 0.5117120146751404\n",
      "[Step 8760] Loss: 9.76e+07 0.1960022896528244 0.5116905570030212\n",
      "[Step 8761] Loss: 9.56e+07 0.19608363509178162 0.511700451374054\n",
      "[Step 8762] Loss: 9.77e+07 0.1962466835975647 0.5117251873016357\n",
      "[Step 8763] Loss: 9.66e+07 0.19631272554397583 0.5117020606994629\n",
      "[Step 8764] Loss: 9.64e+07 0.19635337591171265 0.5116839408874512\n",
      "[Step 8765] Loss: 9.60e+07 0.1964244544506073 0.5116822719573975\n",
      "[Step 8766] Loss: 9.61e+07 0.19652584195137024 0.5117161273956299\n",
      "[Step 8767] Loss: 9.55e+07 0.19656234979629517 0.5117177367210388\n",
      "[Step 8768] Loss: 9.59e+07 0.19653503596782684 0.511693000793457\n",
      "[Step 8769] Loss: 9.73e+07 0.19662052392959595 0.5116913318634033\n",
      "[Step 8770] Loss: 9.63e+07 0.1968124657869339 0.5117408633232117\n",
      "[Step 8771] Loss: 9.60e+07 0.19699525833129883 0.5117582082748413\n",
      "[Step 8772] Loss: 9.63e+07 0.19722965359687805 0.5118101835250854\n",
      "[Step 8773] Loss: 9.56e+07 0.19743412733078003 0.5118464827537537\n",
      "[Step 8774] Loss: 9.58e+07 0.19764962792396545 0.5118968486785889\n",
      "[Step 8775] Loss: 9.59e+07 0.1979168802499771 0.5119999647140503\n",
      "[Step 8776] Loss: 9.58e+07 0.19812551140785217 0.5120643377304077\n",
      "[Step 8777] Loss: 9.68e+07 0.19843262434005737 0.5121262073516846\n",
      "[Step 8778] Loss: 9.76e+07 0.1985238492488861 0.5121732354164124\n",
      "[Step 8779] Loss: 9.56e+07 0.19853895902633667 0.51214599609375\n",
      "[Step 8780] Loss: 9.61e+07 0.1985754817724228 0.5121749043464661\n",
      "[Step 8781] Loss: 9.72e+07 0.1984647512435913 0.5120981335639954\n",
      "[Step 8782] Loss: 9.65e+07 0.1984938383102417 0.5121113657951355\n",
      "[Step 8783] Loss: 9.64e+07 0.19866088032722473 0.5121386051177979\n",
      "[Step 8784] Loss: 9.56e+07 0.1987961381673813 0.5121707916259766\n",
      "[Step 8785] Loss: 9.82e+07 0.1986694633960724 0.5121220946311951\n",
      "[Step 8786] Loss: 9.57e+07 0.19862060248851776 0.5120659470558167\n",
      "[Step 8787] Loss: 9.64e+07 0.19845694303512573 0.5119933485984802\n",
      "[Step 8788] Loss: 9.59e+07 0.19830524921417236 0.511926531791687\n",
      "[Step 8789] Loss: 9.62e+07 0.1981063336133957 0.5118604898452759\n",
      "[Step 8790] Loss: 9.71e+07 0.19783158600330353 0.5117540955543518\n",
      "[Step 8791] Loss: 9.64e+07 0.19770817458629608 0.511678159236908\n",
      "[Step 8792] Loss: 9.64e+07 0.1975986659526825 0.511640191078186\n",
      "[Step 8793] Loss: 9.61e+07 0.19745226204395294 0.5116154551506042\n",
      "[Step 8794] Loss: 9.59e+07 0.19732488691806793 0.5115428566932678\n",
      "[Step 8795] Loss: 9.56e+07 0.19720473885536194 0.5114776492118835\n",
      "[Step 8796] Loss: 9.59e+07 0.19709977507591248 0.5114611387252808\n",
      "[Step 8797] Loss: 9.65e+07 0.1970166265964508 0.511420726776123\n",
      "[Step 8798] Loss: 9.67e+07 0.1969655156135559 0.5113654136657715\n",
      "[Step 8799] Loss: 9.61e+07 0.19685138761997223 0.5113076567649841\n",
      "[Step 8800] Loss: 9.79e+07 0.1965789496898651 0.5111830830574036\n",
      "[Step 8801] Loss: 9.61e+07 0.1961943805217743 0.5110518932342529\n",
      "[Step 8802] Loss: 9.67e+07 0.19590437412261963 0.5109643936157227\n",
      "[Step 8803] Loss: 9.65e+07 0.19575338065624237 0.5108851790428162\n",
      "[Step 8804] Loss: 9.58e+07 0.19560009241104126 0.5108125805854797\n",
      "[Step 8805] Loss: 9.59e+07 0.19544728100299835 0.5107449293136597\n",
      "[Step 8806] Loss: 9.73e+07 0.1954495906829834 0.510765552520752\n",
      "[Step 8807] Loss: 9.59e+07 0.19553706049919128 0.510796070098877\n",
      "[Step 8808] Loss: 9.60e+07 0.19551146030426025 0.5107638835906982\n",
      "[Step 8809] Loss: 9.57e+07 0.1954343318939209 0.5107234716415405\n",
      "[Step 8810] Loss: 9.66e+07 0.19530460238456726 0.5106846690177917\n",
      "[Step 8811] Loss: 9.61e+07 0.19514121115207672 0.5106558203697205\n",
      "[Step 8812] Loss: 9.62e+07 0.19491219520568848 0.5105312466621399\n",
      "[Step 8813] Loss: 9.68e+07 0.19460062682628632 0.5103934407234192\n",
      "[Step 8814] Loss: 9.64e+07 0.19437946379184723 0.5102985501289368\n",
      "[Step 8815] Loss: 9.65e+07 0.19432207942008972 0.5102688074111938\n",
      "[Step 8816] Loss: 9.63e+07 0.19427195191383362 0.5102407932281494\n",
      "[Step 8817] Loss: 9.57e+07 0.19427549839019775 0.5102382898330688\n",
      "[Step 8818] Loss: 9.62e+07 0.19427981972694397 0.5102110505104065\n",
      "[Step 8819] Loss: 9.72e+07 0.19404488801956177 0.5101268887519836\n",
      "[Step 8820] Loss: 9.61e+07 0.19385474920272827 0.5100361108779907\n",
      "[Step 8821] Loss: 9.61e+07 0.19371378421783447 0.5099461674690247\n",
      "[Step 8822] Loss: 9.60e+07 0.19351820647716522 0.5098570585250854\n",
      "[Step 8823] Loss: 9.62e+07 0.1933968961238861 0.5097943544387817\n",
      "[Step 8824] Loss: 9.60e+07 0.1934167742729187 0.5097745656967163\n",
      "[Step 8825] Loss: 9.60e+07 0.19346369802951813 0.5097927451133728\n",
      "[Step 8826] Loss: 9.54e+07 0.19351421296596527 0.5097663402557373\n",
      "[Step 8827] Loss: 9.65e+07 0.19359399378299713 0.5097481608390808\n",
      "[Step 8828] Loss: 9.67e+07 0.19356794655323029 0.5097357630729675\n",
      "[Step 8829] Loss: 9.62e+07 0.19355078041553497 0.5097209215164185\n",
      "[Step 8830] Loss: 9.57e+07 0.1934768557548523 0.5096665024757385\n",
      "[Step 8831] Loss: 9.58e+07 0.19344159960746765 0.5095847845077515\n",
      "[Step 8832] Loss: 9.58e+07 0.19340869784355164 0.5095452070236206\n",
      "[Step 8833] Loss: 9.59e+07 0.19339606165885925 0.509497344493866\n",
      "[Step 8834] Loss: 9.50e+07 0.19341826438903809 0.5095195770263672\n",
      "[Step 8835] Loss: 9.66e+07 0.19333575665950775 0.5094684362411499\n",
      "[Step 8836] Loss: 9.67e+07 0.19337491691112518 0.5094602108001709\n",
      "[Step 8837] Loss: 9.57e+07 0.1934479922056198 0.5095022916793823\n",
      "[Step 8838] Loss: 9.58e+07 0.19352607429027557 0.5095245242118835\n",
      "[Step 8839] Loss: 9.52e+07 0.19358891248703003 0.5095336437225342\n",
      "[Step 8840] Loss: 9.59e+07 0.19372621178627014 0.5095567107200623\n",
      "[Step 8841] Loss: 9.61e+07 0.1939159333705902 0.5095922350883484\n",
      "[Step 8842] Loss: 9.68e+07 0.19391615688800812 0.5095707774162292\n",
      "[Step 8843] Loss: 9.61e+07 0.1939879208803177 0.509558379650116\n",
      "[Step 8844] Loss: 9.60e+07 0.19402030110359192 0.5095385909080505\n",
      "[Step 8845] Loss: 9.56e+07 0.19404132664203644 0.5095435380935669\n",
      "[Step 8846] Loss: 9.60e+07 0.19404493272304535 0.5095559358596802\n",
      "[Step 8847] Loss: 9.58e+07 0.19396546483039856 0.5095006227493286\n",
      "[Step 8848] Loss: 9.53e+07 0.19384607672691345 0.5094387531280518\n",
      "[Step 8849] Loss: 9.53e+07 0.19378574192523956 0.5094230771064758\n",
      "[Step 8850] Loss: 9.56e+07 0.1936914175748825 0.5094214081764221\n",
      "[Step 8851] Loss: 9.60e+07 0.19366773962974548 0.5094164609909058\n",
      "[Step 8852] Loss: 9.63e+07 0.19358985126018524 0.509414792060852\n",
      "[Step 8853] Loss: 9.62e+07 0.19353429973125458 0.5093702673912048\n",
      "[Step 8854] Loss: 9.55e+07 0.19346459209918976 0.5093347430229187\n",
      "[Step 8855] Loss: 9.62e+07 0.19349585473537445 0.5093355774879456\n",
      "[Step 8856] Loss: 9.55e+07 0.19354230165481567 0.5093224048614502\n",
      "[Step 8857] Loss: 9.59e+07 0.19371840357780457 0.5093875527381897\n",
      "[Step 8858] Loss: 9.72e+07 0.19366970658302307 0.5094082355499268\n",
      "[Step 8859] Loss: 9.49e+07 0.19359064102172852 0.5093875527381897\n",
      "[Step 8860] Loss: 9.56e+07 0.1934356689453125 0.5093207359313965\n",
      "[Step 8861] Loss: 9.56e+07 0.19331273436546326 0.5092431902885437\n",
      "[Step 8862] Loss: 9.52e+07 0.19315385818481445 0.5092052221298218\n",
      "[Step 8863] Loss: 9.58e+07 0.19292718172073364 0.5091268420219421\n",
      "[Step 8864] Loss: 9.59e+07 0.19267237186431885 0.5090401768684387\n",
      "[Step 8865] Loss: 9.55e+07 0.1924540400505066 0.5089766383171082\n",
      "[Step 8866] Loss: 9.55e+07 0.1922309696674347 0.5088528990745544\n",
      "[Step 8867] Loss: 9.58e+07 0.19210049510002136 0.5088182091712952\n",
      "[Step 8868] Loss: 9.55e+07 0.19199398159980774 0.5087481141090393\n",
      "[Step 8869] Loss: 9.70e+07 0.19198700785636902 0.5087183713912964\n",
      "[Step 8870] Loss: 9.54e+07 0.19194439053535461 0.5087241530418396\n",
      "[Step 8871] Loss: 9.63e+07 0.19174601137638092 0.5086391568183899\n",
      "[Step 8872] Loss: 9.57e+07 0.19161777198314667 0.5085715055465698\n",
      "[Step 8873] Loss: 9.61e+07 0.1915491372346878 0.5085500478744507\n",
      "[Step 8874] Loss: 9.63e+07 0.19160984456539154 0.508577287197113\n",
      "[Step 8875] Loss: 9.57e+07 0.1917268931865692 0.5086119771003723\n",
      "[Step 8876] Loss: 9.54e+07 0.19175772368907928 0.5086111426353455\n",
      "[Step 8877] Loss: 9.63e+07 0.19172106683254242 0.5086053609848022\n",
      "[Step 8878] Loss: 9.61e+07 0.19176854193210602 0.508668065071106\n",
      "[Step 8879] Loss: 9.64e+07 0.19187194108963013 0.5087183713912964\n",
      "[Step 8880] Loss: 9.60e+07 0.1919066607952118 0.5087365508079529\n",
      "[Step 8881] Loss: 9.62e+07 0.19190320372581482 0.5087118148803711\n",
      "[Step 8882] Loss: 9.55e+07 0.19195009768009186 0.5087307691574097\n",
      "[Step 8883] Loss: 9.53e+07 0.19201916456222534 0.5087084770202637\n",
      "[Step 8884] Loss: 9.62e+07 0.19200818240642548 0.5086383819580078\n",
      "[Step 8885] Loss: 9.67e+07 0.1918400377035141 0.5085377097129822\n",
      "[Step 8886] Loss: 9.62e+07 0.1917884200811386 0.5084922909736633\n",
      "[Step 8887] Loss: 9.69e+07 0.19157838821411133 0.50841224193573\n",
      "[Step 8888] Loss: 9.59e+07 0.19135813415050507 0.5083215236663818\n",
      "[Step 8889] Loss: 9.54e+07 0.19120341539382935 0.5082620978355408\n",
      "[Step 8890] Loss: 9.83e+07 0.19084125757217407 0.5081028342247009\n",
      "[Step 8891] Loss: 9.64e+07 0.19057492911815643 0.5079939365386963\n",
      "[Step 8892] Loss: 9.59e+07 0.19030791521072388 0.5079039931297302\n",
      "[Step 8893] Loss: 9.65e+07 0.1901034414768219 0.5078115463256836\n",
      "[Step 8894] Loss: 9.70e+07 0.18996913731098175 0.5077571272850037\n",
      "[Step 8895] Loss: 9.59e+07 0.18994680047035217 0.5077208280563354\n",
      "[Step 8896] Loss: 9.61e+07 0.190023273229599 0.5077571272850037\n",
      "[Step 8897] Loss: 9.56e+07 0.19012050330638885 0.5078016519546509\n",
      "[Step 8898] Loss: 9.68e+07 0.19009961187839508 0.50776207447052\n",
      "[Step 8899] Loss: 9.65e+07 0.19023001194000244 0.5077711343765259\n",
      "[Step 8900] Loss: 9.60e+07 0.19039951264858246 0.5077983736991882\n",
      "[Step 8901] Loss: 9.59e+07 0.19054362177848816 0.5078256130218506\n",
      "[Step 8902] Loss: 9.60e+07 0.1907493770122528 0.5078602433204651\n",
      "[Step 8903] Loss: 9.68e+07 0.19077302515506744 0.5078338384628296\n",
      "[Step 8904] Loss: 9.65e+07 0.19081714749336243 0.5078305602073669\n",
      "[Step 8905] Loss: 9.65e+07 0.19089871644973755 0.5078396201133728\n",
      "[Step 8906] Loss: 9.62e+07 0.1908651441335678 0.5078338384628296\n",
      "[Step 8907] Loss: 9.65e+07 0.19078022241592407 0.5077835321426392\n",
      "[Step 8908] Loss: 9.56e+07 0.19073832035064697 0.5077513456344604\n",
      "[Step 8909] Loss: 9.68e+07 0.19060908257961273 0.507686972618103\n",
      "[Step 8910] Loss: 9.67e+07 0.19057635962963104 0.5076267123222351\n",
      "[Step 8911] Loss: 9.60e+07 0.19049577414989471 0.5075623989105225\n",
      "[Step 8912] Loss: 9.67e+07 0.19033406674861908 0.5074889659881592\n",
      "[Step 8913] Loss: 9.56e+07 0.19023102521896362 0.5074468851089478\n",
      "[Step 8914] Loss: 9.57e+07 0.1901109367609024 0.5073783993721008\n",
      "[Step 8915] Loss: 9.54e+07 0.1899990290403366 0.507309079170227\n",
      "[Step 8916] Loss: 9.62e+07 0.18993856012821198 0.5072991847991943\n",
      "[Step 8917] Loss: 9.61e+07 0.18994401395320892 0.5072884559631348\n",
      "[Step 8918] Loss: 9.61e+07 0.18997065722942352 0.5072677731513977\n",
      "[Step 8919] Loss: 9.60e+07 0.18999356031417847 0.5072149634361267\n",
      "[Step 8920] Loss: 9.64e+07 0.18992455303668976 0.5071844458580017\n",
      "[Step 8921] Loss: 9.64e+07 0.18988050520420074 0.5071679353713989\n",
      "[Step 8922] Loss: 9.61e+07 0.18981561064720154 0.5071052312850952\n",
      "[Step 8923] Loss: 9.60e+07 0.18986065685749054 0.5071101784706116\n",
      "[Step 8924] Loss: 9.52e+07 0.18992376327514648 0.507113516330719\n",
      "[Step 8925] Loss: 9.62e+07 0.1900090128183365 0.5071052312850952\n",
      "[Step 8926] Loss: 9.57e+07 0.19006304442882538 0.5071431994438171\n",
      "[Step 8927] Loss: 9.66e+07 0.19024883210659027 0.5071902275085449\n",
      "[Step 8928] Loss: 9.68e+07 0.19025734066963196 0.507174551486969\n",
      "[Step 8929] Loss: 9.57e+07 0.19021566212177277 0.5071564316749573\n",
      "[Step 8930] Loss: 9.58e+07 0.19002528488636017 0.5070862770080566\n",
      "[Step 8931] Loss: 9.72e+07 0.18956464529037476 0.5069229006767273\n",
      "[Step 8932] Loss: 9.60e+07 0.18912312388420105 0.5067389011383057\n",
      "[Step 8933] Loss: 9.57e+07 0.18880680203437805 0.5065994262695312\n",
      "[Step 8934] Loss: 9.61e+07 0.1884668469429016 0.5064409971237183\n",
      "[Step 8935] Loss: 9.66e+07 0.1881813108921051 0.5063395500183105\n",
      "[Step 8936] Loss: 9.61e+07 0.18797443807125092 0.5062636137008667\n",
      "[Step 8937] Loss: 9.56e+07 0.1878000646829605 0.5061769485473633\n",
      "[Step 8938] Loss: 9.63e+07 0.18751992285251617 0.5060622692108154\n",
      "[Step 8939] Loss: 9.66e+07 0.18727275729179382 0.5059566497802734\n",
      "[Step 8940] Loss: 9.77e+07 0.18684357404708862 0.505771815776825\n",
      "[Step 8941] Loss: 9.62e+07 0.1864180564880371 0.5056232810020447\n",
      "[Step 8942] Loss: 9.55e+07 0.18598338961601257 0.5054830312728882\n",
      "[Step 8943] Loss: 9.67e+07 0.18553784489631653 0.5053204894065857\n",
      "[Step 8944] Loss: 9.61e+07 0.1850166916847229 0.5051670074462891\n",
      "[Step 8945] Loss: 9.65e+07 0.18442529439926147 0.5049334764480591\n",
      "[Step 8946] Loss: 9.63e+07 0.18391981720924377 0.5047329664230347\n",
      "[Step 8947] Loss: 9.59e+07 0.183560311794281 0.5046141743659973\n",
      "[Step 8948] Loss: 9.56e+07 0.18326912820339203 0.5044928789138794\n",
      "[Step 8949] Loss: 9.61e+07 0.18297182023525238 0.5043922066688538\n",
      "[Step 8950] Loss: 9.55e+07 0.1826671063899994 0.5042890310287476\n",
      "[Step 8951] Loss: 9.58e+07 0.18238192796707153 0.5042040944099426\n",
      "[Step 8952] Loss: 9.59e+07 0.1821121871471405 0.5040761828422546\n",
      "[Step 8953] Loss: 9.60e+07 0.18179893493652344 0.5039375424385071\n",
      "[Step 8954] Loss: 9.63e+07 0.18134404718875885 0.503772497177124\n",
      "[Step 8955] Loss: 9.52e+07 0.1810448318719864 0.5036693811416626\n",
      "[Step 8956] Loss: 9.63e+07 0.18085157871246338 0.5035934448242188\n",
      "[Step 8957] Loss: 9.61e+07 0.18076783418655396 0.5035315752029419\n",
      "[Step 8958] Loss: 9.62e+07 0.18076300621032715 0.5035274624824524\n",
      "[Step 8959] Loss: 9.57e+07 0.18078137934207916 0.5034894943237305\n",
      "[Step 8960] Loss: 9.59e+07 0.18080896139144897 0.5034729838371277\n",
      "[Step 8961] Loss: 9.61e+07 0.18090519309043884 0.5034820437431335\n",
      "[Step 8962] Loss: 9.57e+07 0.1810336858034134 0.5035117864608765\n",
      "[Step 8963] Loss: 9.53e+07 0.18112267553806305 0.5035431385040283\n",
      "[Step 8964] Loss: 9.56e+07 0.18124739825725555 0.5035547018051147\n",
      "[Step 8965] Loss: 9.67e+07 0.18127189576625824 0.5035719871520996\n",
      "[Step 8966] Loss: 9.58e+07 0.18129950761795044 0.5035241842269897\n",
      "[Step 8967] Loss: 9.62e+07 0.18138514459133148 0.5034969449043274\n",
      "[Step 8968] Loss: 9.59e+07 0.18144099414348602 0.5034614205360413\n",
      "[Step 8969] Loss: 9.58e+07 0.18156908452510834 0.5034878253936768\n",
      "[Step 8970] Loss: 9.59e+07 0.18171364068984985 0.5035051703453064\n",
      "[Step 8971] Loss: 9.61e+07 0.18183369934558868 0.5035340785980225\n",
      "[Step 8972] Loss: 9.60e+07 0.1819521188735962 0.5035356879234314\n",
      "[Step 8973] Loss: 9.58e+07 0.18202891945838928 0.5035216808319092\n",
      "[Step 8974] Loss: 9.66e+07 0.1820257306098938 0.5034911632537842\n",
      "[Step 8975] Loss: 9.57e+07 0.1820545494556427 0.503463089466095\n",
      "[Step 8976] Loss: 9.59e+07 0.1820615828037262 0.5034177303314209\n",
      "[Step 8977] Loss: 9.61e+07 0.18209519982337952 0.5033830404281616\n",
      "[Step 8978] Loss: 9.62e+07 0.18219642341136932 0.5033814311027527\n",
      "[Step 8979] Loss: 9.60e+07 0.18219903111457825 0.5033137202262878\n",
      "[Step 8980] Loss: 9.59e+07 0.18209806084632874 0.5032477378845215\n",
      "[Step 8981] Loss: 9.65e+07 0.1820165514945984 0.5031957626342773\n",
      "[Step 8982] Loss: 9.62e+07 0.18207284808158875 0.5031412839889526\n",
      "[Step 8983] Loss: 9.60e+07 0.18212270736694336 0.5031313896179199\n",
      "[Step 8984] Loss: 9.58e+07 0.18217706680297852 0.5031198263168335\n",
      "[Step 8985] Loss: 9.65e+07 0.18230850994586945 0.5031569600105286\n",
      "[Step 8986] Loss: 9.60e+07 0.1825101524591446 0.5031940937042236\n",
      "[Step 8987] Loss: 9.58e+07 0.18262039124965668 0.5031627416610718\n",
      "[Step 8988] Loss: 9.55e+07 0.18277013301849365 0.5031635761260986\n",
      "[Step 8989] Loss: 9.54e+07 0.18286378681659698 0.5031388401985168\n",
      "[Step 8990] Loss: 9.64e+07 0.18290658295154572 0.5031116008758545\n",
      "[Step 8991] Loss: 9.57e+07 0.1829310655593872 0.5030810832977295\n",
      "[Step 8992] Loss: 9.59e+07 0.18294666707515717 0.5030975341796875\n",
      "[Step 8993] Loss: 9.64e+07 0.18304826319217682 0.5030860304832458\n",
      "[Step 8994] Loss: 9.62e+07 0.18324317038059235 0.5031058192253113\n",
      "[Step 8995] Loss: 9.81e+07 0.18319855630397797 0.5030686855316162\n",
      "[Step 8996] Loss: 9.82e+07 0.1828863024711609 0.5029333829879761\n",
      "[Step 8997] Loss: 9.63e+07 0.18249455094337463 0.502851665019989\n",
      "[Step 8998] Loss: 9.70e+07 0.18201979994773865 0.5026775598526001\n",
      "[Step 8999] Loss: 9.60e+07 0.18159642815589905 0.5024935603141785\n",
      "[Step 9000] Loss: 9.65e+07 0.1812416911125183 0.5023524761199951\n",
      "[Step 9001] Loss: 9.58e+07 0.18093372881412506 0.5022121667861938\n",
      "[Step 9002] Loss: 9.60e+07 0.18066923320293427 0.5020925402641296\n",
      "[Step 9003] Loss: 9.59e+07 0.18040931224822998 0.5019522905349731\n",
      "[Step 9004] Loss: 9.57e+07 0.18019863963127136 0.5018499493598938\n",
      "[Step 9005] Loss: 9.63e+07 0.1800585836172104 0.5017954707145691\n",
      "[Step 9006] Loss: 9.74e+07 0.1797349601984024 0.5016758441925049\n",
      "[Step 9007] Loss: 9.58e+07 0.17926618456840515 0.5015347599983215\n",
      "[Step 9008] Loss: 9.63e+07 0.17878979444503784 0.5013664364814758\n",
      "[Step 9009] Loss: 9.58e+07 0.1783517748117447 0.5012170672416687\n",
      "[Step 9010] Loss: 9.59e+07 0.17787417769432068 0.5010652542114258\n",
      "[Step 9011] Loss: 9.60e+07 0.17736077308654785 0.5008564591407776\n",
      "[Step 9012] Loss: 9.68e+07 0.17675025761127472 0.5006452798843384\n",
      "[Step 9013] Loss: 9.71e+07 0.1759839951992035 0.5003861784934998\n",
      "[Step 9014] Loss: 9.56e+07 0.17525777220726013 0.5001163482666016\n",
      "[Step 9015] Loss: 9.63e+07 0.17455007135868073 0.49987292289733887\n",
      "[Step 9016] Loss: 9.63e+07 0.17376990616321564 0.49958083033561707\n",
      "[Step 9017] Loss: 9.58e+07 0.17300550639629364 0.4993002712726593\n",
      "[Step 9018] Loss: 9.48e+07 0.1722680926322937 0.4989966154098511\n",
      "[Step 9019] Loss: 9.57e+07 0.17160257697105408 0.49874579906463623\n",
      "[Step 9020] Loss: 9.63e+07 0.17095543444156647 0.4984685480594635\n",
      "[Step 9021] Loss: 9.76e+07 0.1701825112104416 0.4981384873390198\n",
      "[Step 9022] Loss: 9.61e+07 0.16959935426712036 0.4978826940059662\n",
      "[Step 9023] Loss: 9.66e+07 0.16908183693885803 0.49767228960990906\n",
      "[Step 9024] Loss: 9.66e+07 0.16850236058235168 0.49740907549858093\n",
      "[Step 9025] Loss: 9.54e+07 0.16790898144245148 0.4971582293510437\n",
      "[Step 9026] Loss: 9.64e+07 0.16729995608329773 0.49689334630966187\n",
      "[Step 9027] Loss: 9.68e+07 0.16666297614574432 0.49665406346321106\n",
      "[Step 9028] Loss: 9.63e+07 0.1660289764404297 0.49643951654434204\n",
      "[Step 9029] Loss: 9.58e+07 0.16547778248786926 0.49622416496276855\n",
      "[Step 9030] Loss: 9.51e+07 0.16498057544231415 0.49601954221725464\n",
      "[Step 9031] Loss: 9.69e+07 0.1645130217075348 0.495813250541687\n",
      "[Step 9032] Loss: 9.58e+07 0.16422802209854126 0.4956836998462677\n",
      "[Step 9033] Loss: 9.63e+07 0.16391822695732117 0.4955434203147888\n",
      "[Step 9034] Loss: 9.61e+07 0.16377590596675873 0.49546587467193604\n",
      "[Step 9035] Loss: 9.69e+07 0.1635146588087082 0.49533796310424805\n",
      "[Step 9036] Loss: 9.65e+07 0.163291335105896 0.4952331781387329\n",
      "[Step 9037] Loss: 9.58e+07 0.16319455206394196 0.495168000459671\n",
      "[Step 9038] Loss: 9.73e+07 0.16299737989902496 0.49506649374961853\n",
      "[Step 9039] Loss: 9.60e+07 0.16272170841693878 0.4949187934398651\n",
      "[Step 9040] Loss: 9.61e+07 0.16251085698604584 0.49480491876602173\n",
      "[Step 9041] Loss: 9.61e+07 0.16227373480796814 0.4947240650653839\n",
      "[Step 9042] Loss: 9.67e+07 0.16188406944274902 0.49453017115592957\n",
      "[Step 9043] Loss: 9.69e+07 0.1614844799041748 0.4944014549255371\n",
      "[Step 9044] Loss: 9.53e+07 0.16111284494400024 0.49422487616539\n",
      "[Step 9045] Loss: 9.60e+07 0.1608094573020935 0.4940928518772125\n",
      "[Step 9046] Loss: 9.55e+07 0.16057583689689636 0.4939814507961273\n",
      "[Step 9047] Loss: 9.60e+07 0.16034327447414398 0.4938725233078003\n",
      "[Step 9048] Loss: 9.57e+07 0.1600462794303894 0.4937875270843506\n",
      "[Step 9049] Loss: 9.59e+07 0.15973114967346191 0.4936489164829254\n",
      "[Step 9050] Loss: 9.54e+07 0.1594272404909134 0.4935721755027771\n",
      "[Step 9051] Loss: 9.56e+07 0.15912577509880066 0.49342530965805054\n",
      "[Step 9052] Loss: 9.58e+07 0.15893344581127167 0.4933873414993286\n",
      "[Step 9053] Loss: 9.57e+07 0.15869756042957306 0.493278443813324\n",
      "[Step 9054] Loss: 9.63e+07 0.15860341489315033 0.4932132363319397\n",
      "[Step 9055] Loss: 9.55e+07 0.1584986299276352 0.49316951632499695\n",
      "[Step 9056] Loss: 9.65e+07 0.1583816409111023 0.4931142330169678\n",
      "[Step 9057] Loss: 9.59e+07 0.158259779214859 0.49308040738105774\n",
      "[Step 9058] Loss: 9.57e+07 0.15807004272937775 0.4929310381412506\n",
      "[Step 9059] Loss: 9.60e+07 0.15792594850063324 0.49287164211273193\n",
      "[Step 9060] Loss: 9.54e+07 0.15774163603782654 0.4927726089954376\n",
      "[Step 9061] Loss: 9.61e+07 0.15761199593544006 0.492694228887558\n",
      "[Step 9062] Loss: 9.52e+07 0.15746958553791046 0.492591917514801\n",
      "[Step 9063] Loss: 9.59e+07 0.15727239847183228 0.49249786138534546\n",
      "[Step 9064] Loss: 9.57e+07 0.15709999203681946 0.4924219250679016\n",
      "[Step 9065] Loss: 9.60e+07 0.15700148046016693 0.4923229217529297\n",
      "[Step 9066] Loss: 9.62e+07 0.15701183676719666 0.49231135845184326\n",
      "[Step 9067] Loss: 9.52e+07 0.15702690184116364 0.49231961369514465\n",
      "[Step 9068] Loss: 9.61e+07 0.15699754655361176 0.4922536015510559\n",
      "[Step 9069] Loss: 9.68e+07 0.15689696371555328 0.4922131896018982\n",
      "[Step 9070] Loss: 9.65e+07 0.15679438412189484 0.49215129017829895\n",
      "[Step 9071] Loss: 9.52e+07 0.1568181812763214 0.4921059012413025\n",
      "[Step 9072] Loss: 9.70e+07 0.15699255466461182 0.49212902784347534\n",
      "[Step 9073] Loss: 9.65e+07 0.15724706649780273 0.49217110872268677\n",
      "[Step 9074] Loss: 9.62e+07 0.15740470588207245 0.49213314056396484\n",
      "[Step 9075] Loss: 9.54e+07 0.15759535133838654 0.4921315014362335\n",
      "[Step 9076] Loss: 9.57e+07 0.15780159831047058 0.49212077260017395\n",
      "[Step 9077] Loss: 9.61e+07 0.15798154473304749 0.49213066697120667\n",
      "[Step 9078] Loss: 9.69e+07 0.15823179483413696 0.49219751358032227\n",
      "[Step 9079] Loss: 9.69e+07 0.15829525887966156 0.4921925365924835\n",
      "[Step 9080] Loss: 9.56e+07 0.1583811491727829 0.4921702742576599\n",
      "[Step 9081] Loss: 9.60e+07 0.15847237408161163 0.49213066697120667\n",
      "[Step 9082] Loss: 9.57e+07 0.15848253667354584 0.49209022521972656\n",
      "[Step 9083] Loss: 9.62e+07 0.15857729315757751 0.4921174645423889\n",
      "[Step 9084] Loss: 9.58e+07 0.1586834043264389 0.492105096578598\n",
      "[Step 9085] Loss: 9.69e+07 0.15889909863471985 0.4921364486217499\n",
      "[Step 9086] Loss: 9.61e+07 0.15914751589298248 0.4921620190143585\n",
      "[Step 9087] Loss: 9.55e+07 0.15935897827148438 0.49220573902130127\n",
      "[Step 9088] Loss: 9.71e+07 0.15967635810375214 0.49226516485214233\n",
      "[Step 9089] Loss: 9.63e+07 0.15998110175132751 0.49231135845184326\n",
      "[Step 9090] Loss: 9.60e+07 0.16020382940769196 0.49234849214553833\n",
      "[Step 9091] Loss: 9.60e+07 0.16035687923431396 0.4923650026321411\n",
      "[Step 9092] Loss: 9.53e+07 0.16047312319278717 0.4923427104949951\n",
      "[Step 9093] Loss: 9.58e+07 0.16063466668128967 0.49232208728790283\n",
      "[Step 9094] Loss: 9.55e+07 0.16069579124450684 0.4923146665096283\n",
      "[Step 9095] Loss: 9.61e+07 0.1608160436153412 0.49230560660362244\n",
      "[Step 9096] Loss: 9.55e+07 0.16087035834789276 0.49225690960884094\n",
      "[Step 9097] Loss: 9.55e+07 0.16099518537521362 0.4922924041748047\n",
      "[Step 9098] Loss: 9.53e+07 0.16113169491291046 0.4923385977745056\n",
      "[Step 9099] Loss: 9.54e+07 0.16133001446723938 0.49236005544662476\n",
      "[Step 9100] Loss: 9.55e+07 0.1615799069404602 0.4924037754535675\n",
      "[Step 9101] Loss: 9.58e+07 0.16189470887184143 0.4924582540988922\n",
      "[Step 9102] Loss: 9.55e+07 0.16223321855068207 0.4925300180912018\n",
      "[Step 9103] Loss: 9.61e+07 0.16255275905132294 0.49259355664253235\n",
      "[Step 9104] Loss: 9.66e+07 0.16283899545669556 0.4926917552947998\n",
      "[Step 9105] Loss: 9.65e+07 0.16318140923976898 0.4927643835544586\n",
      "[Step 9106] Loss: 9.60e+07 0.16346056759357452 0.492830365896225\n",
      "[Step 9107] Loss: 9.82e+07 0.1634652018547058 0.49278581142425537\n",
      "[Step 9108] Loss: 9.67e+07 0.16335321962833405 0.49271073937416077\n",
      "[Step 9109] Loss: 9.66e+07 0.16333580017089844 0.4927024841308594\n",
      "[Step 9110] Loss: 9.59e+07 0.163296177983284 0.4926529824733734\n",
      "[Step 9111] Loss: 9.71e+07 0.16339996457099915 0.4926595687866211\n",
      "[Step 9112] Loss: 9.64e+07 0.16351215541362762 0.4926719665527344\n",
      "[Step 9113] Loss: 9.62e+07 0.16363482177257538 0.4926529824733734\n",
      "[Step 9114] Loss: 9.55e+07 0.1637844741344452 0.4926851689815521\n",
      "[Step 9115] Loss: 9.62e+07 0.1639021933078766 0.4926892817020416\n",
      "[Step 9116] Loss: 9.60e+07 0.1640518754720688 0.49268680810928345\n",
      "[Step 9117] Loss: 9.58e+07 0.1640925258398056 0.4926570951938629\n",
      "[Step 9118] Loss: 9.60e+07 0.1641199290752411 0.4926472008228302\n",
      "[Step 9119] Loss: 9.65e+07 0.16417185962200165 0.49266865849494934\n",
      "[Step 9120] Loss: 9.65e+07 0.16426360607147217 0.49266287684440613\n",
      "[Step 9121] Loss: 9.59e+07 0.16434647142887115 0.49261170625686646\n",
      "[Step 9122] Loss: 9.61e+07 0.16452784836292267 0.49264225363731384\n",
      "[Step 9123] Loss: 9.60e+07 0.16473880410194397 0.4926917552947998\n",
      "[Step 9124] Loss: 9.58e+07 0.16492004692554474 0.49272724986076355\n",
      "[Step 9125] Loss: 9.58e+07 0.1650911420583725 0.49273547530174255\n",
      "[Step 9126] Loss: 9.61e+07 0.16521835327148438 0.4927330017089844\n",
      "[Step 9127] Loss: 9.63e+07 0.16526761651039124 0.49271899461746216\n",
      "[Step 9128] Loss: 9.58e+07 0.1652742177248001 0.49265629053115845\n",
      "[Step 9129] Loss: 9.65e+07 0.16529580950737 0.49266865849494934\n",
      "[Step 9130] Loss: 9.59e+07 0.16526134312152863 0.49259522557258606\n",
      "[Step 9131] Loss: 9.62e+07 0.1651042401790619 0.4924788773059845\n",
      "[Step 9132] Loss: 9.56e+07 0.1649923175573349 0.49242937564849854\n",
      "[Step 9133] Loss: 9.60e+07 0.16499407589435577 0.4924103915691376\n",
      "[Step 9134] Loss: 9.67e+07 0.16482801735401154 0.49234849214553833\n",
      "[Step 9135] Loss: 9.63e+07 0.1645844578742981 0.4922007918357849\n",
      "[Step 9136] Loss: 9.65e+07 0.16421140730381012 0.49204981327056885\n",
      "[Step 9137] Loss: 9.59e+07 0.16375970840454102 0.49183279275894165\n",
      "[Step 9138] Loss: 9.61e+07 0.16332031786441803 0.49161824584007263\n",
      "[Step 9139] Loss: 9.60e+07 0.16281050443649292 0.4913872182369232\n",
      "[Step 9140] Loss: 9.65e+07 0.16241201758384705 0.491219699382782\n",
      "[Step 9141] Loss: 9.74e+07 0.16184933483600616 0.4910027086734772\n",
      "[Step 9142] Loss: 9.56e+07 0.16126765310764313 0.490736186504364\n",
      "[Step 9143] Loss: 9.64e+07 0.1608336716890335 0.49060332775115967\n",
      "[Step 9144] Loss: 9.60e+07 0.16042189300060272 0.49042758345603943\n",
      "[Step 9145] Loss: 9.63e+07 0.16006913781166077 0.49028071761131287\n",
      "[Step 9146] Loss: 9.60e+07 0.15984408557415009 0.490193247795105\n",
      "[Step 9147] Loss: 9.60e+07 0.15963824093341827 0.49007606506347656\n",
      "[Step 9148] Loss: 9.68e+07 0.1592973917722702 0.4899151623249054\n",
      "[Step 9149] Loss: 9.62e+07 0.15889568626880646 0.48976004123687744\n",
      "[Step 9150] Loss: 9.52e+07 0.15853101015090942 0.48962801694869995\n",
      "[Step 9151] Loss: 9.69e+07 0.15831898152828217 0.4895702600479126\n",
      "[Step 9152] Loss: 9.68e+07 0.15796847641468048 0.4893878996372223\n",
      "[Step 9153] Loss: 9.55e+07 0.15758082270622253 0.48924019932746887\n",
      "[Step 9154] Loss: 9.66e+07 0.15721666812896729 0.4890595078468323\n",
      "[Step 9155] Loss: 9.63e+07 0.1568276435136795 0.4888779819011688\n",
      "[Step 9156] Loss: 9.70e+07 0.1563500016927719 0.48866426944732666\n",
      "[Step 9157] Loss: 9.63e+07 0.15596142411231995 0.4884852170944214\n",
      "[Step 9158] Loss: 9.59e+07 0.15561451017856598 0.4883243143558502\n",
      "[Step 9159] Loss: 9.62e+07 0.15523095428943634 0.48812296986579895\n",
      "[Step 9160] Loss: 9.50e+07 0.15487805008888245 0.4879637360572815\n",
      "[Step 9161] Loss: 9.67e+07 0.15459170937538147 0.4878201484680176\n",
      "[Step 9162] Loss: 9.52e+07 0.15427258610725403 0.4876435697078705\n",
      "[Step 9163] Loss: 9.63e+07 0.15401875972747803 0.48751649260520935\n",
      "[Step 9164] Loss: 9.67e+07 0.15392246842384338 0.4874298572540283\n",
      "[Step 9165] Loss: 9.55e+07 0.15384428203105927 0.4873473346233368\n",
      "[Step 9166] Loss: 9.64e+07 0.15366314351558685 0.4872277081012726\n",
      "[Step 9167] Loss: 9.65e+07 0.15358515083789825 0.487130343914032\n",
      "[Step 9168] Loss: 9.53e+07 0.1535811573266983 0.48709815740585327\n",
      "[Step 9169] Loss: 9.57e+07 0.15363812446594238 0.487077534198761\n",
      "[Step 9170] Loss: 9.54e+07 0.15368996560573578 0.48703792691230774\n",
      "[Step 9171] Loss: 9.60e+07 0.15373781323432922 0.4869677722454071\n",
      "[Step 9172] Loss: 9.57e+07 0.1538608968257904 0.48697271943092346\n",
      "[Step 9173] Loss: 9.60e+07 0.15393969416618347 0.4869595170021057\n",
      "[Step 9174] Loss: 9.56e+07 0.1540018916130066 0.4869520962238312\n",
      "[Step 9175] Loss: 9.53e+07 0.15405823290348053 0.48693808913230896\n",
      "[Step 9176] Loss: 9.70e+07 0.15394383668899536 0.4868564009666443\n",
      "[Step 9177] Loss: 9.61e+07 0.15367750823497772 0.4867119789123535\n",
      "[Step 9178] Loss: 9.68e+07 0.15337318181991577 0.48657089471817017\n",
      "[Step 9179] Loss: 9.62e+07 0.1530665010213852 0.48642978072166443\n",
      "[Step 9180] Loss: 9.63e+07 0.1527571976184845 0.48625651001930237\n",
      "[Step 9181] Loss: 9.52e+07 0.1525082290172577 0.4861525595188141\n",
      "[Step 9182] Loss: 9.66e+07 0.15216515958309174 0.4859800934791565\n",
      "[Step 9183] Loss: 9.64e+07 0.15176524221897125 0.4858200252056122\n",
      "[Step 9184] Loss: 9.61e+07 0.1512601673603058 0.48560217022895813\n",
      "[Step 9185] Loss: 9.61e+07 0.15081727504730225 0.4854503571987152\n",
      "[Step 9186] Loss: 9.61e+07 0.15036414563655853 0.48523664474487305\n",
      "[Step 9187] Loss: 9.56e+07 0.14996308088302612 0.48507410287857056\n",
      "[Step 9188] Loss: 9.65e+07 0.14949898421764374 0.48484551906585693\n",
      "[Step 9189] Loss: 9.71e+07 0.14906036853790283 0.48463594913482666\n",
      "[Step 9190] Loss: 9.67e+07 0.14880916476249695 0.48449236154556274\n",
      "[Step 9191] Loss: 9.60e+07 0.1485721617937088 0.48436281085014343\n",
      "[Step 9192] Loss: 9.64e+07 0.14823895692825317 0.48417800664901733\n",
      "[Step 9193] Loss: 9.61e+07 0.1478804349899292 0.4839774966239929\n",
      "[Step 9194] Loss: 9.49e+07 0.14752477407455444 0.4838009178638458\n",
      "[Step 9195] Loss: 9.53e+07 0.1472047120332718 0.48364412784576416\n",
      "[Step 9196] Loss: 9.55e+07 0.14691704511642456 0.48349231481552124\n",
      "[Step 9197] Loss: 9.54e+07 0.14665764570236206 0.4833371937274933\n",
      "[Step 9198] Loss: 9.59e+07 0.1464773267507553 0.4832175374031067\n",
      "[Step 9199] Loss: 9.62e+07 0.14638786017894745 0.4830814003944397\n",
      "[Step 9200] Loss: 9.60e+07 0.14635786414146423 0.48301371932029724\n",
      "[Step 9201] Loss: 9.64e+07 0.14633060991764069 0.4829518496990204\n",
      "[Step 9202] Loss: 9.55e+07 0.14628374576568604 0.48287180066108704\n",
      "[Step 9203] Loss: 9.63e+07 0.14616405963897705 0.4827752709388733\n",
      "[Step 9204] Loss: 9.62e+07 0.1460043489933014 0.48266634345054626\n",
      "[Step 9205] Loss: 9.55e+07 0.14578783512115479 0.48256155848503113\n",
      "[Step 9206] Loss: 9.85e+07 0.14529752731323242 0.4823346436023712\n",
      "[Step 9207] Loss: 9.56e+07 0.14487963914871216 0.4821489751338959\n",
      "[Step 9208] Loss: 9.65e+07 0.14446720480918884 0.4819839596748352\n",
      "[Step 9209] Loss: 9.53e+07 0.14410504698753357 0.48180821537971497\n",
      "[Step 9210] Loss: 9.52e+07 0.14374183118343353 0.4816530644893646\n",
      "[Step 9211] Loss: 9.53e+07 0.143314391374588 0.4814179241657257\n",
      "[Step 9212] Loss: 9.60e+07 0.14297187328338623 0.4812561869621277\n",
      "[Step 9213] Loss: 9.60e+07 0.14267683029174805 0.4811043441295624\n",
      "[Step 9214] Loss: 9.62e+07 0.14229963719844818 0.48091623187065125\n",
      "[Step 9215] Loss: 9.62e+07 0.1420043408870697 0.48071572184562683\n",
      "[Step 9216] Loss: 9.72e+07 0.14160680770874023 0.4805077910423279\n",
      "[Step 9217] Loss: 9.51e+07 0.14124415814876556 0.48033037781715393\n",
      "[Step 9218] Loss: 9.93e+07 0.1405865103006363 0.48001599311828613\n",
      "[Step 9219] Loss: 9.63e+07 0.14015959203243256 0.4798031151294708\n",
      "[Step 9220] Loss: 9.54e+07 0.13981203734874725 0.47966036200523376\n",
      "[Step 9221] Loss: 9.65e+07 0.13951055705547333 0.4794672727584839\n",
      "[Step 9222] Loss: 9.51e+07 0.13920293748378754 0.47928905487060547\n",
      "[Step 9223] Loss: 9.72e+07 0.13877876102924347 0.47910505533218384\n",
      "[Step 9224] Loss: 9.61e+07 0.1385178118944168 0.4789837598800659\n",
      "[Step 9225] Loss: 9.55e+07 0.13829442858695984 0.478892982006073\n",
      "[Step 9226] Loss: 9.54e+07 0.13814736902713776 0.47879481315612793\n",
      "[Step 9227] Loss: 9.60e+07 0.13798876106739044 0.47872301936149597\n",
      "[Step 9228] Loss: 9.61e+07 0.13791199028491974 0.47872301936149597\n",
      "[Step 9229] Loss: 9.58e+07 0.13775141537189484 0.47864875197410583\n",
      "[Step 9230] Loss: 9.58e+07 0.13756093382835388 0.4785200357437134\n",
      "[Step 9231] Loss: 9.56e+07 0.13745352625846863 0.4784853756427765\n",
      "[Step 9232] Loss: 9.57e+07 0.13730743527412415 0.4784391522407532\n",
      "[Step 9233] Loss: 9.57e+07 0.1373182237148285 0.4784466028213501\n",
      "[Step 9234] Loss: 9.63e+07 0.13740666210651398 0.4784201979637146\n",
      "[Step 9235] Loss: 9.60e+07 0.13741934299468994 0.478383868932724\n",
      "[Step 9236] Loss: 9.63e+07 0.1375485062599182 0.47839459776878357\n",
      "[Step 9237] Loss: 9.59e+07 0.13762573897838593 0.47837480902671814\n",
      "[Step 9238] Loss: 9.54e+07 0.13773351907730103 0.47839459776878357\n",
      "[Step 9239] Loss: 9.63e+07 0.13774582743644714 0.47835665941238403\n",
      "[Step 9240] Loss: 9.62e+07 0.1376388520002365 0.4782947599887848\n",
      "[Step 9241] Loss: 9.50e+07 0.13755761086940765 0.4782394766807556\n",
      "[Step 9242] Loss: 9.65e+07 0.13750091195106506 0.47816193103790283\n",
      "[Step 9243] Loss: 9.63e+07 0.13755148649215698 0.47815200686454773\n",
      "[Step 9244] Loss: 9.65e+07 0.1374901384115219 0.4780736267566681\n",
      "[Step 9245] Loss: 9.60e+07 0.13746006786823273 0.47802165150642395\n",
      "[Step 9246] Loss: 9.52e+07 0.13745525479316711 0.4779638946056366\n",
      "[Step 9247] Loss: 9.51e+07 0.13747142255306244 0.4779176712036133\n",
      "[Step 9248] Loss: 9.60e+07 0.13746212422847748 0.4778401255607605\n",
      "[Step 9249] Loss: 9.60e+07 0.13750411570072174 0.47782444953918457\n",
      "[Step 9250] Loss: 9.61e+07 0.13744595646858215 0.4777122139930725\n",
      "[Step 9251] Loss: 9.68e+07 0.13723941147327423 0.4776008129119873\n",
      "[Step 9252] Loss: 9.51e+07 0.13705334067344666 0.477444052696228\n",
      "[Step 9253] Loss: 9.60e+07 0.1367986649274826 0.4772880971431732\n",
      "[Step 9254] Loss: 9.65e+07 0.13667021691799164 0.477146178483963\n",
      "[Step 9255] Loss: 9.59e+07 0.13663776218891144 0.47710493206977844\n",
      "[Step 9256] Loss: 9.58e+07 0.1365681141614914 0.4770265221595764\n",
      "[Step 9257] Loss: 9.54e+07 0.13657738268375397 0.4770125150680542\n",
      "[Step 9258] Loss: 9.60e+07 0.1366327852010727 0.4769926965236664\n",
      "[Step 9259] Loss: 9.64e+07 0.1368076503276825 0.4770248830318451\n",
      "[Step 9260] Loss: 9.57e+07 0.13692091405391693 0.4770125150680542\n",
      "[Step 9261] Loss: 9.59e+07 0.13693392276763916 0.47693493962287903\n",
      "[Step 9262] Loss: 9.61e+07 0.13688498735427856 0.4768722355365753\n",
      "[Step 9263] Loss: 9.52e+07 0.13682152330875397 0.4767872393131256\n",
      "[Step 9264] Loss: 9.55e+07 0.13679245114326477 0.4767104983329773\n",
      "[Step 9265] Loss: 9.62e+07 0.1367158144712448 0.4766535758972168\n",
      "[Step 9266] Loss: 9.71e+07 0.13641957938671112 0.476528137922287\n",
      "[Step 9267] Loss: 9.59e+07 0.13612550497055054 0.4763631224632263\n",
      "[Step 9268] Loss: 9.54e+07 0.13582657277584076 0.4762459397315979\n",
      "[Step 9269] Loss: 9.62e+07 0.13556598126888275 0.4761196970939636\n",
      "[Step 9270] Loss: 9.63e+07 0.13520996272563934 0.47598934173583984\n",
      "[Step 9271] Loss: 9.63e+07 0.13490216434001923 0.47586721181869507\n",
      "[Step 9272] Loss: 9.65e+07 0.13454669713974 0.47573354840278625\n",
      "[Step 9273] Loss: 9.57e+07 0.13430124521255493 0.4756328761577606\n",
      "[Step 9274] Loss: 9.66e+07 0.13416455686092377 0.4755586087703705\n",
      "[Step 9275] Loss: 9.56e+07 0.13409286737442017 0.47551241517066956\n",
      "[Step 9276] Loss: 9.62e+07 0.13420641422271729 0.47550827264785767\n",
      "[Step 9277] Loss: 9.64e+07 0.1341664046049118 0.47550249099731445\n",
      "[Step 9278] Loss: 9.67e+07 0.13404574990272522 0.4754257798194885\n",
      "[Step 9279] Loss: 9.58e+07 0.13383975625038147 0.47532016038894653\n",
      "[Step 9280] Loss: 9.56e+07 0.13370075821876526 0.4752079248428345\n",
      "[Step 9281] Loss: 9.55e+07 0.1335485875606537 0.47512540221214294\n",
      "[Step 9282] Loss: 9.58e+07 0.13341230154037476 0.47508251667022705\n",
      "[Step 9283] Loss: 9.60e+07 0.13326965272426605 0.475026398897171\n",
      "[Step 9284] Loss: 9.62e+07 0.1331874132156372 0.47499173879623413\n",
      "[Step 9285] Loss: 9.64e+07 0.13306108117103577 0.4749199450016022\n",
      "[Step 9286] Loss: 9.53e+07 0.13301943242549896 0.4748407304286957\n",
      "[Step 9287] Loss: 9.59e+07 0.1330435425043106 0.4748052656650543\n",
      "[Step 9288] Loss: 9.55e+07 0.13308066129684448 0.474803626537323\n",
      "[Step 9289] Loss: 9.74e+07 0.1331852674484253 0.47480031847953796\n",
      "[Step 9290] Loss: 9.73e+07 0.13336946070194244 0.47486549615859985\n",
      "[Step 9291] Loss: 9.50e+07 0.13358159363269806 0.47488200664520264\n",
      "[Step 9292] Loss: 9.58e+07 0.13383160531520844 0.4749414026737213\n",
      "[Step 9293] Loss: 9.66e+07 0.13404566049575806 0.47496864199638367\n",
      "[Step 9294] Loss: 9.61e+07 0.13421545922756195 0.4750107228755951\n",
      "[Step 9295] Loss: 9.61e+07 0.13428053259849548 0.4749694764614105\n",
      "[Step 9296] Loss: 9.65e+07 0.13439279794692993 0.4749694764614105\n",
      "[Step 9297] Loss: 9.65e+07 0.13449789583683014 0.4749521315097809\n",
      "[Step 9298] Loss: 9.62e+07 0.13454416394233704 0.47490426898002625\n",
      "[Step 9299] Loss: 9.53e+07 0.13453857600688934 0.4749092161655426\n",
      "[Step 9300] Loss: 9.60e+07 0.13448414206504822 0.47483745217323303\n",
      "[Step 9301] Loss: 9.70e+07 0.1343483328819275 0.47471532225608826\n",
      "[Step 9302] Loss: 9.67e+07 0.13423587381839752 0.4746435284614563\n",
      "[Step 9303] Loss: 9.59e+07 0.13411873579025269 0.4745445251464844\n",
      "[Step 9304] Loss: 9.66e+07 0.13398367166519165 0.47442322969436646\n",
      "[Step 9305] Loss: 9.67e+07 0.13372060656547546 0.4742524325847626\n",
      "[Step 9306] Loss: 9.64e+07 0.13346627354621887 0.474057674407959\n",
      "[Step 9307] Loss: 9.59e+07 0.13336387276649475 0.47391659021377563\n",
      "[Step 9308] Loss: 9.62e+07 0.13335388898849487 0.4738283157348633\n",
      "[Step 9309] Loss: 9.60e+07 0.13326725363731384 0.47370782494544983\n",
      "[Step 9310] Loss: 9.61e+07 0.1331344097852707 0.4735725224018097\n",
      "[Step 9311] Loss: 9.67e+07 0.13310812413692474 0.4734933078289032\n",
      "[Step 9312] Loss: 9.72e+07 0.13292674720287323 0.47334808111190796\n",
      "[Step 9313] Loss: 9.67e+07 0.13276423513889313 0.4731813967227936\n",
      "[Step 9314] Loss: 9.60e+07 0.13260631263256073 0.47303205728530884\n",
      "[Step 9315] Loss: 9.59e+07 0.13240313529968262 0.4728843569755554\n",
      "[Step 9316] Loss: 9.69e+07 0.13211625814437866 0.47270941734313965\n",
      "[Step 9317] Loss: 9.67e+07 0.1317334920167923 0.4725055992603302\n",
      "[Step 9318] Loss: 9.61e+07 0.13139483332633972 0.4723356366157532\n",
      "[Step 9319] Loss: 9.56e+07 0.13102734088897705 0.4721648395061493\n",
      "[Step 9320] Loss: 9.64e+07 0.13060306012630463 0.4719865918159485\n",
      "[Step 9321] Loss: 9.61e+07 0.1302601844072342 0.4718281626701355\n",
      "[Step 9322] Loss: 9.67e+07 0.1299879401922226 0.4716779887676239\n",
      "[Step 9323] Loss: 9.92e+07 0.12943197786808014 0.47141146659851074\n",
      "[Step 9324] Loss: 9.72e+07 0.12905430793762207 0.47121840715408325\n",
      "[Step 9325] Loss: 9.64e+07 0.12875120341777802 0.47113752365112305\n",
      "[Step 9326] Loss: 9.63e+07 0.1285317987203598 0.471017062664032\n",
      "[Step 9327] Loss: 9.59e+07 0.1283450722694397 0.4709411561489105\n",
      "[Step 9328] Loss: 9.55e+07 0.12818947434425354 0.4708264470100403\n",
      "[Step 9329] Loss: 9.60e+07 0.12798279523849487 0.4707587957382202\n",
      "[Step 9330] Loss: 9.53e+07 0.12776565551757812 0.4706110954284668\n",
      "[Step 9331] Loss: 9.57e+07 0.12749817967414856 0.4704815447330475\n",
      "[Step 9332] Loss: 9.61e+07 0.12737800180912018 0.4703759253025055\n",
      "[Step 9333] Loss: 9.66e+07 0.12714259326457977 0.47025877237319946\n",
      "[Step 9334] Loss: 9.66e+07 0.12688827514648438 0.4701242744922638\n",
      "[Step 9335] Loss: 9.52e+07 0.12666910886764526 0.47001203894615173\n",
      "[Step 9336] Loss: 9.64e+07 0.12641975283622742 0.46987342834472656\n",
      "[Step 9337] Loss: 9.63e+07 0.12604103982448578 0.46968117356300354\n",
      "[Step 9338] Loss: 9.54e+07 0.12564069032669067 0.4695260226726532\n",
      "[Step 9339] Loss: 9.75e+07 0.1250794678926468 0.4692768454551697\n",
      "[Step 9340] Loss: 9.53e+07 0.12460605055093765 0.4690796434879303\n",
      "[Step 9341] Loss: 9.57e+07 0.12426583468914032 0.4689055383205414\n",
      "[Step 9342] Loss: 9.62e+07 0.12381936609745026 0.4687025547027588\n",
      "[Step 9343] Loss: 9.74e+07 0.12344510853290558 0.46849626302719116\n",
      "[Step 9344] Loss: 9.63e+07 0.1229996383190155 0.4682850241661072\n",
      "[Step 9345] Loss: 9.64e+07 0.12253428250551224 0.4680812358856201\n",
      "[Step 9346] Loss: 9.58e+07 0.12208367884159088 0.4678642153739929\n",
      "[Step 9347] Loss: 9.54e+07 0.12159238755702972 0.46765875816345215\n",
      "[Step 9348] Loss: 9.70e+07 0.12104930728673935 0.46739718317985535\n",
      "[Step 9349] Loss: 9.68e+07 0.12047426402568817 0.4671463370323181\n",
      "[Step 9350] Loss: 9.63e+07 0.12005848437547684 0.4669763743877411\n",
      "[Step 9351] Loss: 9.57e+07 0.11966592818498611 0.4667956531047821\n",
      "[Step 9352] Loss: 9.55e+07 0.1193852350115776 0.4666694104671478\n",
      "[Step 9353] Loss: 9.56e+07 0.11909687519073486 0.46651512384414673\n",
      "[Step 9354] Loss: 9.55e+07 0.11872878670692444 0.4663310945034027\n",
      "[Step 9355] Loss: 9.66e+07 0.11819283664226532 0.46608439087867737\n",
      "[Step 9356] Loss: 9.52e+07 0.1177111268043518 0.4658178687095642\n",
      "[Step 9357] Loss: 9.57e+07 0.11725858598947525 0.4655406177043915\n",
      "[Step 9358] Loss: 9.56e+07 0.11692897230386734 0.4653962254524231\n",
      "[Step 9359] Loss: 9.56e+07 0.11664311587810516 0.4652377963066101\n",
      "[Step 9360] Loss: 9.64e+07 0.11651131510734558 0.46514785289764404\n",
      "[Step 9361] Loss: 9.75e+07 0.11619804054498672 0.4650133550167084\n",
      "[Step 9362] Loss: 9.61e+07 0.11579433083534241 0.4648326635360718\n",
      "[Step 9363] Loss: 9.58e+07 0.11543340981006622 0.46468329429626465\n",
      "[Step 9364] Loss: 9.63e+07 0.11517122387886047 0.4645446836948395\n",
      "[Step 9365] Loss: 9.55e+07 0.11490259319543839 0.46441102027893066\n",
      "[Step 9366] Loss: 9.58e+07 0.1146828755736351 0.464276522397995\n",
      "[Step 9367] Loss: 9.55e+07 0.11445576697587967 0.46413955092430115\n",
      "[Step 9368] Loss: 9.53e+07 0.11421699076890945 0.46401742100715637\n",
      "[Step 9369] Loss: 9.68e+07 0.11413928866386414 0.4639737010002136\n",
      "[Step 9370] Loss: 9.57e+07 0.11415660381317139 0.4639604985713959\n",
      "[Step 9371] Loss: 9.50e+07 0.11413910984992981 0.46393078565597534\n",
      "[Step 9372] Loss: 9.64e+07 0.11423343420028687 0.46390190720558167\n",
      "[Step 9373] Loss: 9.65e+07 0.11440825462341309 0.46389034390449524\n",
      "[Step 9374] Loss: 9.56e+07 0.1146465390920639 0.4639555513858795\n",
      "[Step 9375] Loss: 9.61e+07 0.114751897752285 0.46398112177848816\n",
      "[Step 9376] Loss: 9.61e+07 0.1147342249751091 0.4639439880847931\n",
      "[Step 9377] Loss: 9.59e+07 0.11469940096139908 0.46387550234794617\n",
      "[Step 9378] Loss: 9.50e+07 0.11469899117946625 0.46383506059646606\n",
      "[Step 9379] Loss: 9.66e+07 0.11468768119812012 0.463797926902771\n",
      "[Step 9380] Loss: 9.56e+07 0.11470229923725128 0.4637649357318878\n",
      "[Step 9381] Loss: 9.49e+07 0.11477255821228027 0.4637492597103119\n",
      "[Step 9382] Loss: 9.64e+07 0.1148553267121315 0.4637632668018341\n",
      "[Step 9383] Loss: 9.59e+07 0.11486916989088058 0.46376246213912964\n",
      "[Step 9384] Loss: 9.64e+07 0.1147625520825386 0.4637030363082886\n",
      "[Step 9385] Loss: 9.58e+07 0.11465618759393692 0.4636560082435608\n",
      "[Step 9386] Loss: 9.57e+07 0.11449878662824631 0.4636007249355316\n",
      "[Step 9387] Loss: 9.63e+07 0.11441831290721893 0.4635297656059265\n",
      "[Step 9388] Loss: 9.55e+07 0.11434950679540634 0.4634794294834137\n",
      "[Step 9389] Loss: 9.62e+07 0.11418221890926361 0.4634225070476532\n",
      "[Step 9390] Loss: 9.68e+07 0.11412366479635239 0.4633779525756836\n",
      "[Step 9391] Loss: 9.59e+07 0.11419730633497238 0.46339690685272217\n",
      "[Step 9392] Loss: 9.64e+07 0.1142912432551384 0.46340930461883545\n",
      "[Step 9393] Loss: 9.60e+07 0.11434827744960785 0.46334245800971985\n",
      "[Step 9394] Loss: 9.62e+07 0.11427798867225647 0.4632945954799652\n",
      "[Step 9395] Loss: 9.51e+07 0.11419396847486496 0.4632112681865692\n",
      "[Step 9396] Loss: 9.55e+07 0.11409775912761688 0.4631444215774536\n",
      "[Step 9397] Loss: 9.67e+07 0.11404185742139816 0.4631403088569641\n",
      "[Step 9398] Loss: 9.57e+07 0.11396335065364838 0.46307429671287537\n",
      "[Step 9399] Loss: 9.63e+07 0.11399183422327042 0.4630313813686371\n",
      "[Step 9400] Loss: 9.61e+07 0.11409904062747955 0.46303799748420715\n",
      "[Step 9401] Loss: 9.54e+07 0.11417409777641296 0.4630429446697235\n",
      "[Step 9402] Loss: 9.61e+07 0.11414433270692825 0.4630107581615448\n",
      "[Step 9403] Loss: 9.55e+07 0.11416829377412796 0.46299177408218384\n",
      "[Step 9404] Loss: 9.58e+07 0.11422141641378403 0.4629983901977539\n",
      "[Step 9405] Loss: 9.55e+07 0.11418890208005905 0.4629678428173065\n",
      "[Step 9406] Loss: 9.57e+07 0.11423396319150925 0.46294721961021423\n",
      "[Step 9407] Loss: 9.60e+07 0.11427968740463257 0.46291670203208923\n",
      "[Step 9408] Loss: 9.56e+07 0.11434897780418396 0.46294310688972473\n",
      "[Step 9409] Loss: 9.55e+07 0.11436456441879272 0.4629422724246979\n",
      "[Step 9410] Loss: 9.63e+07 0.11424093693494797 0.46290844678878784\n",
      "[Step 9411] Loss: 9.65e+07 0.11396613717079163 0.4627813696861267\n",
      "[Step 9412] Loss: 9.59e+07 0.11372300982475281 0.462665855884552\n",
      "[Step 9413] Loss: 9.60e+07 0.1134776845574379 0.4625560939311981\n",
      "[Step 9414] Loss: 9.68e+07 0.11337054520845413 0.4625239372253418\n",
      "[Step 9415] Loss: 9.59e+07 0.1133435070514679 0.46247193217277527\n",
      "[Step 9416] Loss: 9.65e+07 0.11341135203838348 0.46245792508125305\n",
      "[Step 9417] Loss: 9.62e+07 0.11328329890966415 0.46238282322883606\n",
      "[Step 9418] Loss: 9.56e+07 0.11312122642993927 0.4623308479785919\n",
      "[Step 9419] Loss: 9.58e+07 0.11294260621070862 0.4622260630130768\n",
      "[Step 9420] Loss: 9.59e+07 0.112833172082901 0.4621715843677521\n",
      "[Step 9421] Loss: 9.64e+07 0.1127643808722496 0.46209484338760376\n",
      "[Step 9422] Loss: 9.61e+07 0.11273328214883804 0.462051123380661\n",
      "[Step 9423] Loss: 9.64e+07 0.11259932816028595 0.4619867503643036\n",
      "[Step 9424] Loss: 9.56e+07 0.11251942813396454 0.4619314670562744\n",
      "[Step 9425] Loss: 9.60e+07 0.11237377673387527 0.46189185976982117\n",
      "[Step 9426] Loss: 9.56e+07 0.1121571809053421 0.4617548882961273\n",
      "[Step 9427] Loss: 9.66e+07 0.11196485906839371 0.46167486906051636\n",
      "[Step 9428] Loss: 9.64e+07 0.11174280941486359 0.4615667760372162\n",
      "[Step 9429] Loss: 9.57e+07 0.1115487813949585 0.4614768326282501\n",
      "[Step 9430] Loss: 9.60e+07 0.1112738698720932 0.4613596498966217\n",
      "[Step 9431] Loss: 9.65e+07 0.11115265637636185 0.46131014823913574\n",
      "[Step 9432] Loss: 9.60e+07 0.11102882772684097 0.46120452880859375\n",
      "[Step 9433] Loss: 9.52e+07 0.1108858734369278 0.4611533582210541\n",
      "[Step 9434] Loss: 9.58e+07 0.1108071431517601 0.4611319303512573\n",
      "[Step 9435] Loss: 9.57e+07 0.1106337159872055 0.4610436260700226\n",
      "[Step 9436] Loss: 9.57e+07 0.11045100539922714 0.4609281122684479\n",
      "[Step 9437] Loss: 9.69e+07 0.11042940616607666 0.4608810842037201\n",
      "[Step 9438] Loss: 9.48e+07 0.1103811264038086 0.46084064245224\n",
      "[Step 9439] Loss: 9.59e+07 0.1102534607052803 0.46077051758766174\n",
      "[Step 9440] Loss: 9.66e+07 0.11013082414865494 0.4607102870941162\n",
      "[Step 9441] Loss: 9.64e+07 0.11012402921915054 0.4606904685497284\n",
      "[Step 9442] Loss: 9.66e+07 0.11019667983055115 0.4606615900993347\n",
      "[Step 9443] Loss: 9.60e+07 0.11035937815904617 0.4606558084487915\n",
      "[Step 9444] Loss: 9.57e+07 0.11057735234498978 0.4606599509716034\n",
      "[Step 9445] Loss: 9.71e+07 0.11061301082372665 0.46065250039100647\n",
      "[Step 9446] Loss: 9.60e+07 0.11065810918807983 0.4606277644634247\n",
      "[Step 9447] Loss: 9.60e+07 0.11076491326093674 0.4606904685497284\n",
      "[Step 9448] Loss: 9.57e+07 0.1108800619840622 0.4606929421424866\n",
      "[Step 9449] Loss: 9.57e+07 0.11108839511871338 0.4606657028198242\n",
      "[Step 9450] Loss: 9.66e+07 0.11111833155155182 0.4606624245643616\n",
      "[Step 9451] Loss: 9.74e+07 0.11094152182340622 0.4605518579483032\n",
      "[Step 9452] Loss: 9.63e+07 0.11073633283376694 0.4604024887084961\n",
      "[Step 9453] Loss: 9.55e+07 0.11048965901136398 0.46023663878440857\n",
      "[Step 9454] Loss: 9.67e+07 0.11016838252544403 0.46010133624076843\n",
      "[Step 9455] Loss: 9.60e+07 0.10988699644804001 0.4599725902080536\n",
      "[Step 9456] Loss: 9.65e+07 0.10954317450523376 0.4598281979560852\n",
      "[Step 9457] Loss: 9.64e+07 0.10920499265193939 0.4596706032752991\n",
      "[Step 9458] Loss: 9.59e+07 0.10888125747442245 0.4595195949077606\n",
      "[Step 9459] Loss: 9.68e+07 0.10839146375656128 0.4593124985694885\n",
      "[Step 9460] Loss: 9.63e+07 0.10782567411661148 0.4590699076652527\n",
      "[Step 9461] Loss: 9.59e+07 0.10725948959589005 0.4587918221950531\n",
      "[Step 9462] Loss: 9.55e+07 0.10682480037212372 0.45863011479377747\n",
      "[Step 9463] Loss: 9.63e+07 0.10651174932718277 0.4584914743900299\n",
      "[Step 9464] Loss: 9.49e+07 0.10625078529119492 0.45836853981018066\n",
      "[Step 9465] Loss: 9.63e+07 0.10586559772491455 0.45821917057037354\n",
      "[Step 9466] Loss: 9.57e+07 0.10554622113704681 0.4580632448196411\n",
      "[Step 9467] Loss: 9.55e+07 0.10523366928100586 0.4578709900379181\n",
      "[Step 9468] Loss: 9.54e+07 0.10498074442148209 0.4577571153640747\n",
      "[Step 9469] Loss: 9.55e+07 0.10473030805587769 0.45764240622520447\n",
      "[Step 9470] Loss: 9.62e+07 0.10459700226783752 0.4575986862182617\n",
      "[Step 9471] Loss: 9.60e+07 0.10450421273708344 0.4575648605823517\n",
      "[Step 9472] Loss: 9.64e+07 0.10434518754482269 0.45743200182914734\n",
      "[Step 9473] Loss: 9.61e+07 0.10425448417663574 0.45736435055732727\n",
      "[Step 9474] Loss: 9.74e+07 0.10389593243598938 0.45721250772476196\n",
      "[Step 9475] Loss: 9.65e+07 0.10349695384502411 0.4570417106151581\n",
      "[Step 9476] Loss: 9.58e+07 0.10314300656318665 0.45688411593437195\n",
      "[Step 9477] Loss: 9.55e+07 0.1027975082397461 0.4567347764968872\n",
      "[Step 9478] Loss: 9.57e+07 0.10241107642650604 0.4565969705581665\n",
      "[Step 9479] Loss: 9.65e+07 0.10217208415269852 0.4564740061759949\n",
      "[Step 9480] Loss: 9.65e+07 0.10196283459663391 0.45633623003959656\n",
      "[Step 9481] Loss: 9.57e+07 0.10187920928001404 0.4562990963459015\n",
      "[Step 9482] Loss: 9.71e+07 0.10160975158214569 0.4562017321586609\n",
      "[Step 9483] Loss: 9.56e+07 0.10138773173093796 0.45611757040023804\n",
      "[Step 9484] Loss: 9.61e+07 0.10125032067298889 0.4560251533985138\n",
      "[Step 9485] Loss: 9.56e+07 0.10112464427947998 0.45592448115348816\n",
      "[Step 9486] Loss: 9.67e+07 0.10086026787757874 0.45576441287994385\n",
      "[Step 9487] Loss: 9.66e+07 0.10054673254489899 0.45561009645462036\n",
      "[Step 9488] Loss: 9.64e+07 0.10026957094669342 0.455465704202652\n",
      "[Step 9489] Loss: 9.60e+07 0.1000644788146019 0.45538732409477234\n",
      "[Step 9490] Loss: 9.70e+07 0.09971710294485092 0.45523878931999207\n",
      "[Step 9491] Loss: 9.55e+07 0.09938764572143555 0.4550795257091522\n",
      "[Step 9492] Loss: 9.53e+07 0.09908302128314972 0.45495495200157166\n",
      "[Step 9493] Loss: 9.60e+07 0.09875432401895523 0.45479074120521545\n",
      "[Step 9494] Loss: 9.57e+07 0.09838932007551193 0.4546273648738861\n",
      "[Step 9495] Loss: 9.59e+07 0.09802264720201492 0.45445820689201355\n",
      "[Step 9496] Loss: 9.66e+07 0.0975259467959404 0.4542238712310791\n",
      "[Step 9497] Loss: 9.58e+07 0.09711509943008423 0.45407286286354065\n",
      "[Step 9498] Loss: 9.59e+07 0.09680365025997162 0.4539928436279297\n",
      "[Step 9499] Loss: 9.52e+07 0.09651710093021393 0.4538995921611786\n",
      "[Step 9500] Loss: 9.61e+07 0.09637641906738281 0.45380058884620667\n",
      "[Step 9501] Loss: 9.53e+07 0.09629132598638535 0.45376014709472656\n",
      "[Step 9502] Loss: 9.59e+07 0.09622412174940109 0.4537048637866974\n",
      "[Step 9503] Loss: 9.63e+07 0.09628540277481079 0.45371559262275696\n",
      "[Step 9504] Loss: 9.54e+07 0.09630744904279709 0.45369991660118103\n",
      "[Step 9505] Loss: 9.56e+07 0.09620267897844315 0.45365452766418457\n",
      "[Step 9506] Loss: 9.60e+07 0.09615817666053772 0.45365700125694275\n",
      "[Step 9507] Loss: 9.67e+07 0.09595251828432083 0.4535621106624603\n",
      "[Step 9508] Loss: 9.60e+07 0.09570284932851791 0.4534573256969452\n",
      "[Step 9509] Loss: 9.56e+07 0.09545543044805527 0.45334839820861816\n",
      "[Step 9510] Loss: 9.67e+07 0.09512706100940704 0.4532114267349243\n",
      "[Step 9511] Loss: 9.61e+07 0.0948079377412796 0.45308518409729004\n",
      "[Step 9512] Loss: 9.56e+07 0.0945097953081131 0.45296141505241394\n",
      "[Step 9513] Loss: 9.66e+07 0.09413790702819824 0.4528508484363556\n",
      "[Step 9514] Loss: 9.61e+07 0.093824602663517 0.45272213220596313\n",
      "[Step 9515] Loss: 9.72e+07 0.0935949832201004 0.4526313543319702\n",
      "[Step 9516] Loss: 9.54e+07 0.09344994276762009 0.4525224268436432\n",
      "[Step 9517] Loss: 9.57e+07 0.0933678150177002 0.4524753987789154\n",
      "[Step 9518] Loss: 9.63e+07 0.09339141100645065 0.45245230197906494\n",
      "[Step 9519] Loss: 9.58e+07 0.0933922827243805 0.4524729251861572\n",
      "[Step 9520] Loss: 9.63e+07 0.09342211484909058 0.45246633887290955\n",
      "[Step 9521] Loss: 9.73e+07 0.0932745635509491 0.452402800321579\n",
      "[Step 9522] Loss: 9.60e+07 0.09315259754657745 0.4523417353630066\n",
      "[Step 9523] Loss: 9.61e+07 0.09291201084852219 0.4522113502025604\n",
      "[Step 9524] Loss: 9.55e+07 0.09271914511919022 0.45213133096694946\n",
      "[Step 9525] Loss: 9.60e+07 0.09263280034065247 0.4520843029022217\n",
      "[Step 9526] Loss: 9.63e+07 0.09261845052242279 0.45206695795059204\n",
      "[Step 9527] Loss: 9.69e+07 0.09280063211917877 0.45208510756492615\n",
      "[Step 9528] Loss: 9.66e+07 0.09293016791343689 0.4520999789237976\n",
      "[Step 9529] Loss: 9.54e+07 0.09303087741136551 0.452108234167099\n",
      "[Step 9530] Loss: 9.59e+07 0.09315866976976395 0.45213213562965393\n",
      "[Step 9531] Loss: 9.59e+07 0.0933978408575058 0.452191561460495\n",
      "[Step 9532] Loss: 9.66e+07 0.09377282112836838 0.45227572321891785\n",
      "[Step 9533] Loss: 9.62e+07 0.09413612633943558 0.45235082507133484\n",
      "[Step 9534] Loss: 9.63e+07 0.09442242234945297 0.45243746042251587\n",
      "[Step 9535] Loss: 9.63e+07 0.0945957750082016 0.45246219635009766\n",
      "[Step 9536] Loss: 9.55e+07 0.09475671499967575 0.4524935483932495\n",
      "[Step 9537] Loss: 9.61e+07 0.09485190361738205 0.45250511169433594\n",
      "[Step 9538] Loss: 9.76e+07 0.09475699067115784 0.45244982838630676\n",
      "[Step 9539] Loss: 9.66e+07 0.09479374438524246 0.4524407386779785\n",
      "[Step 9540] Loss: 9.52e+07 0.09469261020421982 0.45239949226379395\n",
      "[Step 9541] Loss: 9.56e+07 0.09459519386291504 0.4523112177848816\n",
      "[Step 9542] Loss: 9.57e+07 0.09446541219949722 0.45222207903862\n",
      "[Step 9543] Loss: 9.57e+07 0.09434709697961807 0.4521940350532532\n",
      "[Step 9544] Loss: 9.59e+07 0.0942235141992569 0.45215773582458496\n",
      "[Step 9545] Loss: 9.59e+07 0.0940580815076828 0.4520801603794098\n",
      "[Step 9546] Loss: 9.68e+07 0.09371667355298996 0.4519176185131073\n",
      "[Step 9547] Loss: 9.61e+07 0.09345414489507675 0.4518086910247803\n",
      "[Step 9548] Loss: 9.49e+07 0.09322427213191986 0.45173031091690063\n",
      "[Step 9549] Loss: 9.55e+07 0.09294849634170532 0.45160654187202454\n",
      "[Step 9550] Loss: 9.48e+07 0.09263318032026291 0.45152485370635986\n",
      "[Step 9551] Loss: 9.53e+07 0.09236212074756622 0.4514728784561157\n",
      "[Step 9552] Loss: 9.53e+07 0.09201797842979431 0.45136478543281555\n",
      "[Step 9553] Loss: 9.60e+07 0.09166426956653595 0.45122697949409485\n",
      "[Step 9554] Loss: 9.63e+07 0.09136892855167389 0.4511065185070038\n",
      "[Step 9555] Loss: 9.63e+07 0.09117307513952255 0.45100995898246765\n",
      "[Step 9556] Loss: 9.62e+07 0.09107695519924164 0.4509645700454712\n",
      "[Step 9557] Loss: 9.59e+07 0.09103310853242874 0.4509134292602539\n",
      "[Step 9558] Loss: 9.56e+07 0.09099311381578445 0.4508878290653229\n",
      "[Step 9559] Loss: 9.55e+07 0.09095931798219681 0.4508828818798065\n",
      "[Step 9560] Loss: 9.54e+07 0.09091684967279434 0.45084574818611145\n",
      "[Step 9561] Loss: 9.60e+07 0.09090258181095123 0.4508309066295624\n",
      "[Step 9562] Loss: 9.62e+07 0.09092776477336884 0.4507962465286255\n",
      "[Step 9563] Loss: 9.53e+07 0.090924471616745 0.4507797360420227\n",
      "[Step 9564] Loss: 9.65e+07 0.09084462374448776 0.45070797204971313\n",
      "[Step 9565] Loss: 9.59e+07 0.0907677710056305 0.4506625831127167\n",
      "[Step 9566] Loss: 9.64e+07 0.09063476324081421 0.4506015181541443\n",
      "[Step 9567] Loss: 9.53e+07 0.0904034748673439 0.4505264461040497\n",
      "[Step 9568] Loss: 9.57e+07 0.09025930613279343 0.4504810571670532\n",
      "[Step 9569] Loss: 9.60e+07 0.09014937281608582 0.45039689540863037\n",
      "[Step 9570] Loss: 9.64e+07 0.09001854807138443 0.4503292143344879\n",
      "[Step 9571] Loss: 9.58e+07 0.08984152972698212 0.45027393102645874\n",
      "[Step 9572] Loss: 9.72e+07 0.08965077251195908 0.45022937655448914\n",
      "[Step 9573] Loss: 9.58e+07 0.08952866494655609 0.45016419887542725\n",
      "[Step 9574] Loss: 9.71e+07 0.08921454846858978 0.45008087158203125\n",
      "[Step 9575] Loss: 9.68e+07 0.0890611931681633 0.45001155138015747\n",
      "[Step 9576] Loss: 9.57e+07 0.0889599472284317 0.44996121525764465\n",
      "[Step 9577] Loss: 9.56e+07 0.08889366686344147 0.44990262389183044\n",
      "[Step 9578] Loss: 9.62e+07 0.08886867016553879 0.44986385107040405\n",
      "[Step 9579] Loss: 9.56e+07 0.0889069214463234 0.449857234954834\n",
      "[Step 9580] Loss: 1.00e+08 0.08854532986879349 0.4497367739677429\n",
      "[Step 9581] Loss: 9.58e+07 0.08828135579824448 0.44959568977355957\n",
      "[Step 9582] Loss: 9.62e+07 0.08794432878494263 0.44942158460617065\n",
      "[Step 9583] Loss: 9.56e+07 0.08765783160924911 0.44923675060272217\n",
      "[Step 9584] Loss: 9.65e+07 0.087332583963871 0.4490593373775482\n",
      "[Step 9585] Loss: 9.57e+07 0.08700723946094513 0.4489198923110962\n",
      "[Step 9586] Loss: 9.58e+07 0.08667804300785065 0.4488060176372528\n",
      "[Step 9587] Loss: 9.65e+07 0.0864308774471283 0.44867151975631714\n",
      "[Step 9588] Loss: 9.59e+07 0.08623505383729935 0.4485766291618347\n",
      "[Step 9589] Loss: 9.57e+07 0.08613334596157074 0.44853702187538147\n",
      "[Step 9590] Loss: 9.62e+07 0.0860755518078804 0.448491632938385\n",
      "[Step 9591] Loss: 9.54e+07 0.08606378734111786 0.4484842121601105\n",
      "[Step 9592] Loss: 9.67e+07 0.0859469622373581 0.4484248161315918\n",
      "[Step 9593] Loss: 9.62e+07 0.08587752282619476 0.4483967423439026\n",
      "[Step 9594] Loss: 9.62e+07 0.08574070781469345 0.4483257830142975\n",
      "[Step 9595] Loss: 9.63e+07 0.08548668771982193 0.44824492931365967\n",
      "[Step 9596] Loss: 9.70e+07 0.0850261002779007 0.44806423783302307\n",
      "[Step 9597] Loss: 9.56e+07 0.08459524810314178 0.44791486859321594\n",
      "[Step 9598] Loss: 9.53e+07 0.08416608721017838 0.4477514922618866\n",
      "[Step 9599] Loss: 9.57e+07 0.08382730931043625 0.4476194679737091\n",
      "[Step 9600] Loss: 9.64e+07 0.08336850255727768 0.44744783639907837\n",
      "[Step 9601] Loss: 9.51e+07 0.0829344168305397 0.4472564160823822\n",
      "[Step 9602] Loss: 9.59e+07 0.08247803151607513 0.44709715247154236\n",
      "[Step 9603] Loss: 9.57e+07 0.08202334493398666 0.44695112109184265\n",
      "[Step 9604] Loss: 9.62e+07 0.0815526694059372 0.44680094718933105\n",
      "[Step 9605] Loss: 9.56e+07 0.08116862922906876 0.4466482996940613\n",
      "[Step 9606] Loss: 9.59e+07 0.08076728135347366 0.4464510679244995\n",
      "[Step 9607] Loss: 9.58e+07 0.08038514852523804 0.446341335773468\n",
      "[Step 9608] Loss: 9.62e+07 0.0799756646156311 0.4461919963359833\n",
      "[Step 9609] Loss: 9.61e+07 0.07964668422937393 0.4460640847682953\n",
      "[Step 9610] Loss: 9.55e+07 0.07928671687841415 0.44590237736701965\n",
      "[Step 9611] Loss: 9.70e+07 0.07909773290157318 0.4458058178424835\n",
      "[Step 9612] Loss: 9.54e+07 0.07888513058423996 0.4457167088985443\n",
      "[Step 9613] Loss: 9.58e+07 0.07868578284978867 0.4455970525741577\n",
      "[Step 9614] Loss: 9.49e+07 0.07846996188163757 0.4454873204231262\n",
      "[Step 9615] Loss: 9.54e+07 0.07830662280321121 0.44539985060691833\n",
      "[Step 9616] Loss: 9.62e+07 0.07819350808858871 0.4453412592411041\n",
      "[Step 9617] Loss: 9.56e+07 0.07818605750799179 0.44531485438346863\n",
      "[Step 9618] Loss: 9.59e+07 0.07821808010339737 0.44533056020736694\n",
      "[Step 9619] Loss: 9.59e+07 0.07833680510520935 0.4453660249710083\n",
      "[Step 9620] Loss: 9.61e+07 0.07855481654405594 0.4454411268234253\n",
      "[Step 9621] Loss: 9.56e+07 0.07882905751466751 0.4455401301383972\n",
      "[Step 9622] Loss: 9.59e+07 0.07901133596897125 0.44559788703918457\n",
      "[Step 9623] Loss: 9.61e+07 0.07937520742416382 0.44574064016342163\n",
      "[Step 9624] Loss: 9.68e+07 0.07982275635004044 0.44590070843696594\n",
      "[Step 9625] Loss: 9.51e+07 0.08016858994960785 0.44599807262420654\n",
      "[Step 9626] Loss: 9.57e+07 0.08048374205827713 0.4461226761341095\n",
      "[Step 9627] Loss: 9.56e+07 0.08085314929485321 0.44624313712120056\n",
      "[Step 9628] Loss: 9.53e+07 0.08121953904628754 0.4463314414024353\n",
      "[Step 9629] Loss: 9.58e+07 0.08159749209880829 0.44647252559661865\n",
      "[Step 9630] Loss: 9.59e+07 0.08181603997945786 0.4465410113334656\n",
      "[Step 9631] Loss: 9.55e+07 0.08202653378248215 0.44662022590637207\n",
      "[Step 9632] Loss: 9.55e+07 0.08225895464420319 0.44670358300209045\n",
      "[Step 9633] Loss: 9.71e+07 0.08230998367071152 0.44674646854400635\n",
      "[Step 9634] Loss: 9.56e+07 0.08241064101457596 0.4467613399028778\n",
      "[Step 9635] Loss: 9.61e+07 0.08264350146055222 0.4468240439891815\n",
      "[Step 9636] Loss: 9.58e+07 0.08274181932210922 0.44678032398223877\n",
      "[Step 9637] Loss: 9.50e+07 0.08284361660480499 0.4467778503894806\n",
      "[Step 9638] Loss: 9.54e+07 0.08285637199878693 0.4467737078666687\n",
      "[Step 9639] Loss: 9.55e+07 0.08287030458450317 0.4467621445655823\n",
      "[Step 9640] Loss: 9.59e+07 0.08294257521629333 0.44675225019454956\n",
      "[Step 9641] Loss: 9.54e+07 0.08296975493431091 0.44675472378730774\n",
      "[Step 9642] Loss: 9.59e+07 0.08296769112348557 0.44671759009361267\n",
      "[Step 9643] Loss: 9.55e+07 0.08297082036733627 0.4467250406742096\n",
      "[Step 9644] Loss: 9.51e+07 0.08293862640857697 0.44672420620918274\n",
      "[Step 9645] Loss: 9.58e+07 0.08293645828962326 0.4466862380504608\n",
      "[Step 9646] Loss: 9.63e+07 0.08285682648420334 0.44662436842918396\n",
      "[Step 9647] Loss: 9.47e+07 0.08279109746217728 0.4465583562850952\n",
      "[Step 9648] Loss: 9.60e+07 0.08268103748559952 0.4465138018131256\n",
      "[Step 9649] Loss: 9.81e+07 0.08232524245977402 0.446390837430954\n",
      "[Step 9650] Loss: 9.59e+07 0.08199439197778702 0.4462670683860779\n",
      "[Step 9651] Loss: 9.52e+07 0.0816006064414978 0.4461127817630768\n",
      "[Step 9652] Loss: 9.57e+07 0.08130599558353424 0.44597581028938293\n",
      "[Step 9653] Loss: 9.67e+07 0.08091282844543457 0.44583553075790405\n",
      "[Step 9654] Loss: 9.65e+07 0.08063562959432602 0.44570350646972656\n",
      "[Step 9655] Loss: 9.57e+07 0.08038485050201416 0.4456028342247009\n",
      "[Step 9656] Loss: 9.56e+07 0.08020155131816864 0.445478230714798\n",
      "[Step 9657] Loss: 9.60e+07 0.07997839152812958 0.44535860419273376\n",
      "[Step 9658] Loss: 9.63e+07 0.07971490919589996 0.4452340006828308\n",
      "[Step 9659] Loss: 9.58e+07 0.07943128794431686 0.44511932134628296\n",
      "[Step 9660] Loss: 9.54e+07 0.07914865761995316 0.44502854347229004\n",
      "[Step 9661] Loss: 9.57e+07 0.07886814326047897 0.4449377655982971\n",
      "[Step 9662] Loss: 9.51e+07 0.07854272425174713 0.444832980632782\n",
      "[Step 9663] Loss: 9.58e+07 0.0781845673918724 0.44472983479499817\n",
      "[Step 9664] Loss: 9.53e+07 0.07778916507959366 0.44458380341529846\n",
      "[Step 9665] Loss: 9.52e+07 0.07744666188955307 0.44446828961372375\n",
      "[Step 9666] Loss: 9.61e+07 0.07720693200826645 0.444349467754364\n",
      "[Step 9667] Loss: 9.62e+07 0.0768490806221962 0.44422486424446106\n",
      "[Step 9668] Loss: 9.66e+07 0.07665009051561356 0.4441728889942169\n",
      "[Step 9669] Loss: 9.58e+07 0.076480433344841 0.4441085159778595\n",
      "[Step 9670] Loss: 9.61e+07 0.07631164789199829 0.44401198625564575\n",
      "[Step 9671] Loss: 9.58e+07 0.07622049003839493 0.4439558684825897\n",
      "[Step 9672] Loss: 9.54e+07 0.07607917487621307 0.4439154267311096\n",
      "[Step 9673] Loss: 9.54e+07 0.07596717774868011 0.4438849091529846\n",
      "[Step 9674] Loss: 9.57e+07 0.07584404200315475 0.443806529045105\n",
      "[Step 9675] Loss: 9.72e+07 0.07557433098554611 0.44368770718574524\n",
      "[Step 9676] Loss: 9.67e+07 0.07541187852621078 0.44366130232810974\n",
      "[Step 9677] Loss: 9.61e+07 0.07526028156280518 0.44362911581993103\n",
      "[Step 9678] Loss: 9.61e+07 0.075095035135746 0.4435754716396332\n",
      "[Step 9679] Loss: 9.66e+07 0.07494093477725983 0.4435078203678131\n",
      "[Step 9680] Loss: 9.63e+07 0.07490541785955429 0.4434937834739685\n",
      "[Step 9681] Loss: 9.65e+07 0.07493161410093307 0.4434814155101776\n",
      "[Step 9682] Loss: 9.55e+07 0.07499384880065918 0.44347894191741943\n",
      "[Step 9683] Loss: 9.58e+07 0.07506944239139557 0.44348883628845215\n",
      "[Step 9684] Loss: 9.64e+07 0.07519877701997757 0.44350287318229675\n",
      "[Step 9685] Loss: 9.60e+07 0.07535314559936523 0.4435400068759918\n",
      "[Step 9686] Loss: 9.57e+07 0.07548483461141586 0.44354578852653503\n",
      "[Step 9687] Loss: 9.62e+07 0.0757119283080101 0.44358620047569275\n",
      "[Step 9688] Loss: 9.56e+07 0.07593069970607758 0.4436357021331787\n",
      "[Step 9689] Loss: 9.61e+07 0.0761612132191658 0.44371163845062256\n",
      "[Step 9690] Loss: 9.67e+07 0.07643411308526993 0.44379907846450806\n",
      "[Step 9691] Loss: 9.62e+07 0.07663289457559586 0.44383540749549866\n",
      "[Step 9692] Loss: 9.60e+07 0.07685510814189911 0.44386181235313416\n",
      "[Step 9693] Loss: 9.61e+07 0.07710537314414978 0.44393688440322876\n",
      "[Step 9694] Loss: 9.61e+07 0.07737448811531067 0.44401198625564575\n",
      "[Step 9695] Loss: 9.58e+07 0.07758333534002304 0.4440251886844635\n",
      "[Step 9696] Loss: 9.55e+07 0.07784393429756165 0.4440680742263794\n",
      "[Step 9697] Loss: 9.61e+07 0.07809548079967499 0.44410109519958496\n",
      "[Step 9698] Loss: 9.68e+07 0.07841600477695465 0.44417205452919006\n",
      "[Step 9699] Loss: 9.58e+07 0.0787489041686058 0.44426530599594116\n",
      "[Step 9700] Loss: 9.54e+07 0.07905346900224686 0.44431066513061523\n",
      "[Step 9701] Loss: 9.57e+07 0.07938189059495926 0.44439154863357544\n",
      "[Step 9702] Loss: 9.59e+07 0.07970377057790756 0.44446414709091187\n",
      "[Step 9703] Loss: 9.54e+07 0.08005651086568832 0.4445804953575134\n",
      "[Step 9704] Loss: 9.54e+07 0.08037223666906357 0.4446605443954468\n",
      "[Step 9705] Loss: 9.53e+07 0.08066485077142715 0.44471830129623413\n",
      "[Step 9706] Loss: 9.81e+07 0.08064817637205124 0.4447133541107178\n",
      "[Step 9707] Loss: 9.57e+07 0.08058939129114151 0.44465887546539307\n",
      "[Step 9708] Loss: 9.54e+07 0.08046340197324753 0.4445524513721466\n",
      "[Step 9709] Loss: 9.69e+07 0.08042415231466293 0.4445565640926361\n",
      "[Step 9710] Loss: 9.61e+07 0.08041848987340927 0.44451117515563965\n",
      "[Step 9711] Loss: 9.61e+07 0.08025424927473068 0.4444426894187927\n",
      "[Step 9712] Loss: 9.57e+07 0.08010474592447281 0.4443560540676117\n",
      "[Step 9713] Loss: 9.59e+07 0.0799710750579834 0.44429251551628113\n",
      "[Step 9714] Loss: 9.61e+07 0.07984782755374908 0.44422733783721924\n",
      "[Step 9715] Loss: 9.54e+07 0.07971010357141495 0.44415968656539917\n",
      "[Step 9716] Loss: 9.61e+07 0.07965146750211716 0.4441505968570709\n",
      "[Step 9717] Loss: 9.63e+07 0.07959384471178055 0.4441225528717041\n",
      "[Step 9718] Loss: 9.67e+07 0.07952729612588882 0.44404497742652893\n",
      "[Step 9719] Loss: 9.83e+07 0.07926209270954132 0.44389647245407104\n",
      "[Step 9720] Loss: 9.53e+07 0.07899772375822067 0.44378092885017395\n",
      "[Step 9721] Loss: 9.59e+07 0.07877696305513382 0.4436621069908142\n",
      "[Step 9722] Loss: 9.57e+07 0.0785941407084465 0.44355401396751404\n",
      "[Step 9723] Loss: 9.57e+07 0.07845740765333176 0.4434995651245117\n",
      "[Step 9724] Loss: 9.52e+07 0.07833176106214523 0.44340384006500244\n",
      "[Step 9725] Loss: 9.55e+07 0.07822677493095398 0.4433460831642151\n",
      "[Step 9726] Loss: 9.52e+07 0.07810427248477936 0.44325119256973267\n",
      "[Step 9727] Loss: 9.57e+07 0.07802639901638031 0.4432016909122467\n",
      "[Step 9728] Loss: 9.65e+07 0.07794498652219772 0.443172812461853\n",
      "[Step 9729] Loss: 9.57e+07 0.07779297232627869 0.4431125819683075\n",
      "[Step 9730] Loss: 9.60e+07 0.07765977084636688 0.4430457353591919\n",
      "[Step 9731] Loss: 9.74e+07 0.07732492685317993 0.44293931126594543\n",
      "[Step 9732] Loss: 9.57e+07 0.07692182064056396 0.44273796677589417\n",
      "[Step 9733] Loss: 9.64e+07 0.07642562687397003 0.4425407648086548\n",
      "[Step 9734] Loss: 9.78e+07 0.0756606012582779 0.442279189825058\n",
      "[Step 9735] Loss: 9.66e+07 0.07477247714996338 0.4419557452201843\n",
      "[Step 9736] Loss: 9.55e+07 0.0739787220954895 0.4416496157646179\n",
      "[Step 9737] Loss: 9.51e+07 0.07326176017522812 0.44137483835220337\n",
      "[Step 9738] Loss: 9.67e+07 0.07247196137905121 0.4410926401615143\n",
      "[Step 9739] Loss: 9.60e+07 0.07171114534139633 0.44079476594924927\n",
      "[Step 9740] Loss: 9.64e+07 0.07108531147241592 0.44056621193885803\n",
      "[Step 9741] Loss: 9.54e+07 0.07053208351135254 0.440348356962204\n",
      "[Step 9742] Loss: 9.51e+07 0.07001087069511414 0.44018664956092834\n",
      "[Step 9743] Loss: 9.61e+07 0.06955792754888535 0.44001665711402893\n",
      "[Step 9744] Loss: 9.69e+07 0.06902071833610535 0.4398037791252136\n",
      "[Step 9745] Loss: 9.62e+07 0.06843776255846024 0.43960821628570557\n",
      "[Step 9746] Loss: 9.54e+07 0.06791822612285614 0.4393903911113739\n",
      "[Step 9747] Loss: 9.55e+07 0.06747803837060928 0.439216285943985\n",
      "[Step 9748] Loss: 9.59e+07 0.06701208651065826 0.4390520751476288\n",
      "[Step 9749] Loss: 9.53e+07 0.06654679030179977 0.43891510367393494\n",
      "[Step 9750] Loss: 9.62e+07 0.06619726121425629 0.43879544734954834\n",
      "[Step 9751] Loss: 9.57e+07 0.06582509726285934 0.4386749863624573\n",
      "[Step 9752] Loss: 9.61e+07 0.06535439193248749 0.4385066628456116\n",
      "[Step 9753] Loss: 9.63e+07 0.0648324191570282 0.43831440806388855\n",
      "[Step 9754] Loss: 9.63e+07 0.06441766023635864 0.43819722533226013\n",
      "[Step 9755] Loss: 9.52e+07 0.0639292374253273 0.4379991888999939\n",
      "[Step 9756] Loss: 9.51e+07 0.0634637176990509 0.43782839179039\n",
      "[Step 9757] Loss: 9.54e+07 0.06306327879428864 0.4376782178878784\n",
      "[Step 9758] Loss: 9.56e+07 0.06268157809972763 0.43757426738739014\n",
      "[Step 9759] Loss: 9.53e+07 0.06223257631063461 0.43740758299827576\n",
      "[Step 9760] Loss: 9.55e+07 0.061901479959487915 0.4372805058956146\n",
      "[Step 9761] Loss: 9.51e+07 0.061592232435941696 0.43714436888694763\n",
      "[Step 9762] Loss: 9.60e+07 0.06123541295528412 0.4370296597480774\n",
      "[Step 9763] Loss: 9.63e+07 0.06099221482872963 0.43694549798965454\n",
      "[Step 9764] Loss: 9.57e+07 0.06082254648208618 0.4368935227394104\n",
      "[Step 9765] Loss: 9.61e+07 0.0606226846575737 0.43678873777389526\n",
      "[Step 9766] Loss: 9.68e+07 0.060326091945171356 0.4366583526134491\n",
      "[Step 9767] Loss: 9.59e+07 0.060027554631233215 0.4365593492984772\n",
      "[Step 9768] Loss: 9.71e+07 0.059622328728437424 0.4364083409309387\n",
      "[Step 9769] Loss: 9.61e+07 0.05927473306655884 0.436292827129364\n",
      "[Step 9770] Loss: 9.63e+07 0.05904010310769081 0.43622514605522156\n",
      "[Step 9771] Loss: 9.58e+07 0.05874445289373398 0.43611130118370056\n",
      "[Step 9772] Loss: 9.57e+07 0.05845952406525612 0.436025470495224\n",
      "[Step 9773] Loss: 9.60e+07 0.058301981538534164 0.4359363615512848\n",
      "[Step 9774] Loss: 9.52e+07 0.058157071471214294 0.43584147095680237\n",
      "[Step 9775] Loss: 9.64e+07 0.05789763852953911 0.435730904340744\n",
      "[Step 9776] Loss: 9.53e+07 0.05769830197095871 0.4356211721897125\n",
      "[Step 9777] Loss: 9.62e+07 0.05763150379061699 0.4355997145175934\n",
      "[Step 9778] Loss: 9.59e+07 0.05754727125167847 0.43555596470832825\n",
      "[Step 9779] Loss: 9.59e+07 0.057495176792144775 0.4355204999446869\n",
      "[Step 9780] Loss: 9.68e+07 0.05730729177594185 0.4354775846004486\n",
      "[Step 9781] Loss: 9.60e+07 0.05704505741596222 0.43537527322769165\n",
      "[Step 9782] Loss: 9.59e+07 0.056697189807891846 0.43525230884552\n",
      "[Step 9783] Loss: 9.59e+07 0.056363023817539215 0.4351434111595154\n",
      "[Step 9784] Loss: 9.60e+07 0.05606487765908241 0.4350056052207947\n",
      "[Step 9785] Loss: 9.71e+07 0.05560809373855591 0.4348570704460144\n",
      "[Step 9786] Loss: 9.55e+07 0.055293574929237366 0.43474650382995605\n",
      "[Step 9787] Loss: 9.55e+07 0.055001694709062576 0.4346376061439514\n",
      "[Step 9788] Loss: 9.62e+07 0.0546991340816021 0.4345526099205017\n",
      "[Step 9789] Loss: 9.59e+07 0.05434694513678551 0.4344313144683838\n",
      "[Step 9790] Loss: 9.48e+07 0.053997911512851715 0.43432238698005676\n",
      "[Step 9791] Loss: 9.65e+07 0.053551726043224335 0.4341515898704529\n",
      "[Step 9792] Loss: 9.53e+07 0.05318158119916916 0.4340517520904541\n",
      "[Step 9793] Loss: 9.58e+07 0.05285825952887535 0.4339519143104553\n",
      "[Step 9794] Loss: 9.59e+07 0.052482835948467255 0.4338149428367615\n",
      "[Step 9795] Loss: 9.67e+07 0.05224156007170677 0.43372663855552673\n",
      "[Step 9796] Loss: 9.55e+07 0.052053965628147125 0.43363094329833984\n",
      "[Step 9797] Loss: 9.62e+07 0.051958054304122925 0.43359875679016113\n",
      "[Step 9798] Loss: 9.85e+07 0.051555339246988297 0.4334560036659241\n",
      "[Step 9799] Loss: 9.64e+07 0.05121338367462158 0.4333231449127197\n",
      "[Step 9800] Loss: 9.56e+07 0.050873640924692154 0.43320268392562866\n",
      "[Step 9801] Loss: 9.57e+07 0.05049283802509308 0.43308550119400024\n",
      "[Step 9802] Loss: 9.62e+07 0.05018050968647003 0.4329245984554291\n",
      "[Step 9803] Loss: 9.69e+07 0.04998793825507164 0.4328453838825226\n",
      "[Step 9804] Loss: 9.54e+07 0.04980604350566864 0.4327802062034607\n",
      "[Step 9805] Loss: 9.56e+07 0.04964751750230789 0.43268531560897827\n",
      "[Step 9806] Loss: 9.57e+07 0.049455106258392334 0.4326135218143463\n",
      "[Step 9807] Loss: 9.63e+07 0.04931236803531647 0.4325343072414398\n",
      "[Step 9808] Loss: 9.57e+07 0.049203041940927505 0.43248069286346436\n",
      "[Step 9809] Loss: 9.54e+07 0.04908159002661705 0.4324476718902588\n",
      "[Step 9810] Loss: 9.47e+07 0.0489550419151783 0.4324146807193756\n",
      "[Step 9811] Loss: 9.73e+07 0.048677004873752594 0.43232885003089905\n",
      "[Step 9812] Loss: 9.56e+07 0.04839686304330826 0.4322282075881958\n",
      "[Step 9813] Loss: 9.58e+07 0.048082608729600906 0.43210113048553467\n",
      "[Step 9814] Loss: 9.64e+07 0.04776039719581604 0.43199220299720764\n",
      "[Step 9815] Loss: 9.58e+07 0.04754196107387543 0.4319022595882416\n",
      "[Step 9816] Loss: 9.61e+07 0.04738472402095795 0.43184202909469604\n",
      "[Step 9817] Loss: 9.68e+07 0.04733164981007576 0.4318346083164215\n",
      "[Step 9818] Loss: 9.58e+07 0.04720055311918259 0.43173229694366455\n",
      "[Step 9819] Loss: 9.52e+07 0.04707664996385574 0.43167781829833984\n",
      "[Step 9820] Loss: 9.57e+07 0.046908702701330185 0.4316217303276062\n",
      "[Step 9821] Loss: 9.57e+07 0.04672250524163246 0.43153589963912964\n",
      "[Step 9822] Loss: 9.60e+07 0.04647267609834671 0.43147650361061096\n",
      "[Step 9823] Loss: 9.58e+07 0.046200960874557495 0.43137088418006897\n",
      "[Step 9824] Loss: 9.62e+07 0.045849766582250595 0.43123143911361694\n",
      "[Step 9825] Loss: 9.50e+07 0.045607779175043106 0.43115881085395813\n",
      "[Step 9826] Loss: 9.60e+07 0.045375339686870575 0.43105319142341614\n",
      "[Step 9827] Loss: 9.55e+07 0.045158062130212784 0.43097150325775146\n",
      "[Step 9828] Loss: 9.56e+07 0.044957634061574936 0.43087249994277954\n",
      "[Step 9829] Loss: 9.56e+07 0.044816210865974426 0.4308469295501709\n",
      "[Step 9830] Loss: 9.55e+07 0.04464316740632057 0.43075698614120483\n",
      "[Step 9831] Loss: 9.55e+07 0.044551651924848557 0.4307289123535156\n",
      "[Step 9832] Loss: 9.46e+07 0.044519588351249695 0.4306827187538147\n",
      "[Step 9833] Loss: 9.57e+07 0.0444825142621994 0.43061918020248413\n",
      "[Step 9834] Loss: 9.55e+07 0.044490255415439606 0.43060845136642456\n",
      "[Step 9835] Loss: 9.54e+07 0.044538915157318115 0.4305869936943054\n",
      "[Step 9836] Loss: 9.59e+07 0.04457051306962967 0.4305531680583954\n",
      "[Step 9837] Loss: 9.57e+07 0.04458240419626236 0.4305408000946045\n",
      "[Step 9838] Loss: 9.57e+07 0.04447808489203453 0.43049126863479614\n",
      "[Step 9839] Loss: 9.60e+07 0.04427419975399971 0.43041208386421204\n",
      "[Step 9840] Loss: 9.56e+07 0.04400034621357918 0.43031468987464905\n",
      "[Step 9841] Loss: 9.59e+07 0.04372387379407883 0.43021732568740845\n",
      "[Step 9842] Loss: 9.59e+07 0.04344642162322998 0.4301067590713501\n",
      "[Step 9843] Loss: 9.66e+07 0.04307694733142853 0.43002259731292725\n",
      "[Step 9844] Loss: 9.60e+07 0.042752884328365326 0.4299178123474121\n",
      "[Step 9845] Loss: 9.54e+07 0.042493321001529694 0.4297924041748047\n",
      "[Step 9846] Loss: 9.52e+07 0.04219773784279823 0.4296785295009613\n",
      "[Step 9847] Loss: 9.58e+07 0.04197688028216362 0.4295918941497803\n",
      "[Step 9848] Loss: 9.62e+07 0.04191436618566513 0.42955803871154785\n",
      "[Step 9849] Loss: 9.62e+07 0.04189436510205269 0.4295184314250946\n",
      "[Step 9850] Loss: 9.68e+07 0.04192904010415077 0.4294821321964264\n",
      "[Step 9851] Loss: 9.64e+07 0.041893962770700455 0.4294408857822418\n",
      "[Step 9852] Loss: 9.67e+07 0.04173174127936363 0.42943593859672546\n",
      "[Step 9853] Loss: 9.57e+07 0.04164736345410347 0.4294053912162781\n",
      "[Step 9854] Loss: 9.57e+07 0.041606463491916656 0.4294045865535736\n",
      "[Step 9855] Loss: 9.54e+07 0.04158320277929306 0.4293963313102722\n",
      "[Step 9856] Loss: 9.55e+07 0.041523609310388565 0.42937982082366943\n",
      "[Step 9857] Loss: 9.60e+07 0.041462305933237076 0.42935919761657715\n",
      "[Step 9858] Loss: 9.50e+07 0.04134666174650192 0.42928656935691833\n",
      "[Step 9859] Loss: 9.56e+07 0.04114224389195442 0.4292222261428833\n",
      "[Step 9860] Loss: 9.50e+07 0.04099695757031441 0.4291669428348541\n",
      "[Step 9861] Loss: 9.55e+07 0.040873851627111435 0.42914465069770813\n",
      "[Step 9862] Loss: 9.51e+07 0.04072872921824455 0.4290819466114044\n",
      "[Step 9863] Loss: 9.59e+07 0.04049984738230705 0.4289722144603729\n",
      "[Step 9864] Loss: 9.72e+07 0.04024757444858551 0.4288492500782013\n",
      "[Step 9865] Loss: 9.66e+07 0.0399215966463089 0.4286974370479584\n",
      "[Step 9866] Loss: 9.59e+07 0.03962743282318115 0.42853817343711853\n",
      "[Step 9867] Loss: 9.58e+07 0.039366625249385834 0.42845648527145386\n",
      "[Step 9868] Loss: 9.53e+07 0.03921916335821152 0.4283904731273651\n",
      "[Step 9869] Loss: 9.52e+07 0.03913054242730141 0.42828404903411865\n",
      "[Step 9870] Loss: 9.58e+07 0.03898962587118149 0.428213894367218\n",
      "[Step 9871] Loss: 9.56e+07 0.03889163210988045 0.42814046144485474\n",
      "[Step 9872] Loss: 9.58e+07 0.038746342062950134 0.42807528376579285\n",
      "[Step 9873] Loss: 9.57e+07 0.038547154515981674 0.42797625064849854\n",
      "[Step 9874] Loss: 9.58e+07 0.038492314517498016 0.4279135465621948\n",
      "[Step 9875] Loss: 9.57e+07 0.03856213763356209 0.42789292335510254\n",
      "[Step 9876] Loss: 9.59e+07 0.03862714767456055 0.42788466811180115\n",
      "[Step 9877] Loss: 9.55e+07 0.038726456463336945 0.4279020130634308\n",
      "[Step 9878] Loss: 9.61e+07 0.0389150008559227 0.4279284179210663\n",
      "[Step 9879] Loss: 9.58e+07 0.03917516767978668 0.42797791957855225\n",
      "[Step 9880] Loss: 9.54e+07 0.039411623030900955 0.42804309725761414\n",
      "[Step 9881] Loss: 9.52e+07 0.039491068571805954 0.42804476618766785\n",
      "[Step 9882] Loss: 9.57e+07 0.039570171386003494 0.42803898453712463\n",
      "[Step 9883] Loss: 9.54e+07 0.03963479772210121 0.4280703365802765\n",
      "[Step 9884] Loss: 9.53e+07 0.039722248911857605 0.428077757358551\n",
      "[Step 9885] Loss: 9.64e+07 0.039924103766679764 0.42813965678215027\n",
      "[Step 9886] Loss: 9.71e+07 0.039884988218545914 0.4281091094017029\n",
      "[Step 9887] Loss: 9.64e+07 0.03982335701584816 0.42806291580200195\n",
      "[Step 9888] Loss: 9.59e+07 0.03980836272239685 0.4280719757080078\n",
      "[Step 9889] Loss: 9.53e+07 0.039760470390319824 0.42810332775115967\n",
      "[Step 9890] Loss: 9.61e+07 0.03968643769621849 0.42803072929382324\n",
      "[Step 9891] Loss: 9.68e+07 0.0397377535700798 0.42799028754234314\n",
      "[Step 9892] Loss: 9.61e+07 0.03972911834716797 0.42798203229904175\n",
      "[Step 9893] Loss: 9.60e+07 0.03978762775659561 0.4280117452144623\n",
      "[Step 9894] Loss: 9.63e+07 0.03987865522503853 0.4280175268650055\n",
      "[Step 9895] Loss: 9.58e+07 0.03993380069732666 0.42803651094436646\n",
      "[Step 9896] Loss: 9.52e+07 0.03992833197116852 0.4279803931713104\n",
      "[Step 9897] Loss: 9.61e+07 0.039976589381694794 0.4279787540435791\n",
      "[Step 9898] Loss: 9.56e+07 0.04006195440888405 0.42800596356391907\n",
      "[Step 9899] Loss: 9.53e+07 0.04019961506128311 0.4280274212360382\n",
      "[Step 9900] Loss: 9.63e+07 0.040435343980789185 0.4280719757080078\n",
      "[Step 9901] Loss: 9.62e+07 0.040541160851716995 0.4280785918235779\n",
      "[Step 9902] Loss: 9.59e+07 0.040552761405706406 0.4280645549297333\n",
      "[Step 9903] Loss: 9.64e+07 0.04056007042527199 0.4280480444431305\n",
      "[Step 9904] Loss: 9.55e+07 0.040540505200624466 0.42802247405052185\n",
      "[Step 9905] Loss: 9.59e+07 0.04054824635386467 0.42801836133003235\n",
      "[Step 9906] Loss: 9.61e+07 0.04058969020843506 0.4280298948287964\n",
      "[Step 9907] Loss: 9.54e+07 0.040566373616456985 0.4279704988002777\n",
      "[Step 9908] Loss: 9.54e+07 0.04053962975740433 0.42795729637145996\n",
      "[Step 9909] Loss: 9.63e+07 0.040474072098731995 0.42788633704185486\n",
      "[Step 9910] Loss: 9.58e+07 0.040305979549884796 0.4278244376182556\n",
      "[Step 9911] Loss: 9.55e+07 0.04012478142976761 0.42775511741638184\n",
      "[Step 9912] Loss: 9.54e+07 0.039974577724933624 0.4277089238166809\n",
      "[Step 9913] Loss: 9.68e+07 0.039810679852962494 0.42764949798583984\n",
      "[Step 9914] Loss: 9.65e+07 0.03975324332714081 0.4276338219642639\n",
      "[Step 9915] Loss: 9.61e+07 0.039803873747587204 0.4276420772075653\n",
      "[Step 9916] Loss: 9.57e+07 0.03990933671593666 0.4276618957519531\n",
      "[Step 9917] Loss: 9.56e+07 0.03999185562133789 0.42766767740249634\n",
      "[Step 9918] Loss: 9.61e+07 0.04000287130475044 0.42768168449401855\n",
      "[Step 9919] Loss: 9.57e+07 0.04001355543732643 0.427727073431015\n",
      "[Step 9920] Loss: 9.53e+07 0.04001379385590553 0.42775678634643555\n",
      "[Step 9921] Loss: 9.57e+07 0.04001916944980621 0.4277782440185547\n",
      "[Step 9922] Loss: 9.68e+07 0.03983459621667862 0.4277311861515045\n",
      "[Step 9923] Loss: 9.62e+07 0.03971976414322853 0.427693247795105\n",
      "[Step 9924] Loss: 9.54e+07 0.0396326445043087 0.42766931653022766\n",
      "[Step 9925] Loss: 9.50e+07 0.0395270437002182 0.42762723565101624\n",
      "[Step 9926] Loss: 9.65e+07 0.039482682943344116 0.42761239409446716\n",
      "[Step 9927] Loss: 9.53e+07 0.039414118975400925 0.42757853865623474\n",
      "[Step 9928] Loss: 9.64e+07 0.039323125034570694 0.42754387855529785\n",
      "[Step 9929] Loss: 9.65e+07 0.03912624716758728 0.4274721145629883\n",
      "[Step 9930] Loss: 9.61e+07 0.03886055201292038 0.4273788630962372\n",
      "[Step 9931] Loss: 9.62e+07 0.038587383925914764 0.42724931240081787\n",
      "[Step 9932] Loss: 9.62e+07 0.0382252037525177 0.4270760416984558\n",
      "[Step 9933] Loss: 9.56e+07 0.03782491013407707 0.42695310711860657\n",
      "[Step 9934] Loss: 9.54e+07 0.037419337779283524 0.42680293321609497\n",
      "[Step 9935] Loss: 9.52e+07 0.03710593283176422 0.4267253577709198\n",
      "[Step 9936] Loss: 9.55e+07 0.03691551089286804 0.42666345834732056\n",
      "[Step 9937] Loss: 9.60e+07 0.036689843982458115 0.42660075426101685\n",
      "[Step 9938] Loss: 9.60e+07 0.03648514673113823 0.4264984428882599\n",
      "[Step 9939] Loss: 9.61e+07 0.036206357181072235 0.42640355229377747\n",
      "[Step 9940] Loss: 9.60e+07 0.03579247370362282 0.42622366547584534\n",
      "[Step 9941] Loss: 9.56e+07 0.035466793924570084 0.4260900020599365\n",
      "[Step 9942] Loss: 9.63e+07 0.03517638519406319 0.4259868562221527\n",
      "[Step 9943] Loss: 9.53e+07 0.03484177961945534 0.42585235834121704\n",
      "[Step 9944] Loss: 9.56e+07 0.03458871319890022 0.42576903104782104\n",
      "[Step 9945] Loss: 9.55e+07 0.03435849770903587 0.42569392919540405\n",
      "[Step 9946] Loss: 9.58e+07 0.034166064113378525 0.42560070753097534\n",
      "[Step 9947] Loss: 9.58e+07 0.03399024158716202 0.42548269033432007\n",
      "[Step 9948] Loss: 9.55e+07 0.033728472888469696 0.4254051446914673\n",
      "[Step 9949] Loss: 9.60e+07 0.0334080345928669 0.4252425730228424\n",
      "[Step 9950] Loss: 9.58e+07 0.03310569375753403 0.42512211203575134\n",
      "[Step 9951] Loss: 9.66e+07 0.032878000289201736 0.4250198006629944\n",
      "[Step 9952] Loss: 9.54e+07 0.03272593766450882 0.4248993396759033\n",
      "[Step 9953] Loss: 9.54e+07 0.032617539167404175 0.42482176423072815\n",
      "[Step 9954] Loss: 9.54e+07 0.032523419708013535 0.4247334897518158\n",
      "[Step 9955] Loss: 9.58e+07 0.03246307373046875 0.4246583878993988\n",
      "[Step 9956] Loss: 9.54e+07 0.0324268713593483 0.4245997965335846\n",
      "[Step 9957] Loss: 9.51e+07 0.032419346272945404 0.4245915412902832\n",
      "[Step 9958] Loss: 9.61e+07 0.03238847479224205 0.4245626628398895\n",
      "[Step 9959] Loss: 9.51e+07 0.03238418325781822 0.424577534198761\n",
      "[Step 9960] Loss: 9.63e+07 0.032297536730766296 0.4245469868183136\n",
      "[Step 9961] Loss: 9.61e+07 0.032121945172548294 0.4244702458381653\n",
      "[Step 9962] Loss: 9.62e+07 0.03178472816944122 0.42435887455940247\n",
      "[Step 9963] Loss: 9.53e+07 0.0314151830971241 0.4242400527000427\n",
      "[Step 9964] Loss: 9.56e+07 0.031076299026608467 0.424121230840683\n",
      "[Step 9965] Loss: 9.54e+07 0.03067021258175373 0.4239743649959564\n",
      "[Step 9966] Loss: 9.54e+07 0.030342377722263336 0.4238530695438385\n",
      "[Step 9967] Loss: 9.58e+07 0.02998724952340126 0.4237556755542755\n",
      "[Step 9968] Loss: 9.54e+07 0.02970300242304802 0.423664927482605\n",
      "[Step 9969] Loss: 9.63e+07 0.029383020475506783 0.42353206872940063\n",
      "[Step 9970] Loss: 9.56e+07 0.029029767960309982 0.4234256446361542\n",
      "[Step 9971] Loss: 9.59e+07 0.028672780841588974 0.42327794432640076\n",
      "[Step 9972] Loss: 9.57e+07 0.02831554226577282 0.42314672470092773\n",
      "[Step 9973] Loss: 9.52e+07 0.027980497106909752 0.4230295717716217\n",
      "[Step 9974] Loss: 9.57e+07 0.027776625007390976 0.4229429364204407\n",
      "[Step 9975] Loss: 9.55e+07 0.027645276859402657 0.4228975474834442\n",
      "[Step 9976] Loss: 9.54e+07 0.027546200901269913 0.4228142201900482\n",
      "[Step 9977] Loss: 9.59e+07 0.027442585676908493 0.42272675037384033\n",
      "[Step 9978] Loss: 9.67e+07 0.027117764577269554 0.42261698842048645\n",
      "[Step 9979] Loss: 9.61e+07 0.0269108135253191 0.42250972986221313\n",
      "[Step 9980] Loss: 9.63e+07 0.026801764965057373 0.4224635362625122\n",
      "[Step 9981] Loss: 9.57e+07 0.026739083230495453 0.42244040966033936\n",
      "[Step 9982] Loss: 9.61e+07 0.026562461629509926 0.42236781120300293\n",
      "[Step 9983] Loss: 9.63e+07 0.026455333456397057 0.42228859663009644\n",
      "[Step 9984] Loss: 9.64e+07 0.026424361392855644 0.4222572445869446\n",
      "[Step 9985] Loss: 9.63e+07 0.02626163698732853 0.4222085475921631\n",
      "[Step 9986] Loss: 9.61e+07 0.02622682973742485 0.4222002923488617\n",
      "[Step 9987] Loss: 9.60e+07 0.026205267757177353 0.42220526933670044\n",
      "[Step 9988] Loss: 9.56e+07 0.026167387142777443 0.4221879243850708\n",
      "[Step 9989] Loss: 9.80e+07 0.02585567533969879 0.42206084728240967\n",
      "[Step 9990] Loss: 9.60e+07 0.025620542466640472 0.42196184396743774\n",
      "[Step 9991] Loss: 9.64e+07 0.025575704872608185 0.4219379127025604\n",
      "[Step 9992] Loss: 9.56e+07 0.025387024506926537 0.4218595325946808\n",
      "[Step 9993] Loss: 9.61e+07 0.025188172236084938 0.42177700996398926\n",
      "[Step 9994] Loss: 9.63e+07 0.025017913430929184 0.42170026898384094\n",
      "[Step 9995] Loss: 9.57e+07 0.0247788242995739 0.4216053783893585\n",
      "[Step 9996] Loss: 9.62e+07 0.024570560082793236 0.4215022325515747\n",
      "[Step 9997] Loss: 9.61e+07 0.024327868595719337 0.42138671875\n",
      "[Step 9998] Loss: 9.50e+07 0.024063659831881523 0.4212728440761566\n",
      "[Step 9999] Loss: 9.58e+07 0.02372763864696026 0.4211045205593109\n",
      "[Step 10000] Loss: 9.59e+07 0.023510480299592018 0.4210013747215271\n",
      "[Step 10001] Loss: 9.55e+07 0.0233027171343565 0.42092299461364746\n",
      "[Step 10002] Loss: 9.58e+07 0.023108934983611107 0.42082810401916504\n",
      "[Step 10003] Loss: 9.65e+07 0.022797461599111557 0.42076125741004944\n",
      "[Step 10004] Loss: 9.60e+07 0.02255670726299286 0.42066967487335205\n",
      "[Step 10005] Loss: 9.54e+07 0.022374946624040604 0.42061686515808105\n",
      "[Step 10006] Loss: 9.54e+07 0.02219751477241516 0.42055001854896545\n",
      "[Step 10007] Loss: 9.55e+07 0.022029226645827293 0.42047742009162903\n",
      "[Step 10008] Loss: 9.58e+07 0.021975837647914886 0.4204237759113312\n",
      "[Step 10009] Loss: 9.60e+07 0.02184457704424858 0.4203627407550812\n",
      "[Step 10010] Loss: 9.64e+07 0.021699970588088036 0.4203033149242401\n",
      "[Step 10011] Loss: 9.54e+07 0.021492116153240204 0.42025133967399597\n",
      "[Step 10012] Loss: 9.67e+07 0.021093785762786865 0.4201168417930603\n",
      "[Step 10013] Loss: 9.67e+07 0.020521581172943115 0.41993778944015503\n",
      "[Step 10014] Loss: 9.64e+07 0.019856641069054604 0.4197463393211365\n",
      "[Step 10015] Loss: 9.56e+07 0.019291076809167862 0.41955655813217163\n",
      "[Step 10016] Loss: 9.62e+07 0.018618080765008926 0.4193436801433563\n",
      "[Step 10017] Loss: 9.58e+07 0.018014635890722275 0.41912996768951416\n",
      "[Step 10018] Loss: 9.62e+07 0.017338119447231293 0.4188939929008484\n",
      "[Step 10019] Loss: 9.57e+07 0.01670857146382332 0.41869017481803894\n",
      "[Step 10020] Loss: 9.54e+07 0.016188353300094604 0.4185449481010437\n",
      "[Step 10021] Loss: 9.59e+07 0.015804892405867577 0.41840797662734985\n",
      "[Step 10022] Loss: 9.60e+07 0.015431203879415989 0.4182808995246887\n",
      "[Step 10023] Loss: 9.53e+07 0.015061402693390846 0.4181678593158722\n",
      "[Step 10024] Loss: 9.59e+07 0.014700123108923435 0.4180539846420288\n",
      "[Step 10025] Loss: 9.49e+07 0.014370712451636791 0.4179409444332123\n",
      "[Step 10026] Loss: 9.69e+07 0.0142283346503973 0.4178658723831177\n",
      "[Step 10027] Loss: 9.58e+07 0.014011889696121216 0.4178204834461212\n",
      "[Step 10028] Loss: 9.60e+07 0.01389314979314804 0.4177660346031189\n",
      "[Step 10029] Loss: 9.50e+07 0.013787427917122841 0.4177272319793701\n",
      "[Step 10030] Loss: 9.58e+07 0.013693958520889282 0.4176620543003082\n",
      "[Step 10031] Loss: 9.53e+07 0.013649112544953823 0.41760513186454773\n",
      "[Step 10032] Loss: 9.55e+07 0.013513016514480114 0.41750940680503845\n",
      "[Step 10033] Loss: 9.72e+07 0.013205609284341335 0.4173418879508972\n",
      "[Step 10034] Loss: 9.57e+07 0.01287880726158619 0.41718512773513794\n",
      "[Step 10035] Loss: 9.65e+07 0.012400642037391663 0.4169994592666626\n",
      "[Step 10036] Loss: 9.58e+07 0.011969061568379402 0.4168286621570587\n",
      "[Step 10037] Loss: 9.56e+07 0.011549627408385277 0.41666117310523987\n",
      "[Step 10038] Loss: 9.60e+07 0.011218991130590439 0.4165712296962738\n",
      "[Step 10039] Loss: 9.54e+07 0.010936010628938675 0.416498601436615\n",
      "[Step 10040] Loss: 9.52e+07 0.0106433667242527 0.41639792919158936\n",
      "[Step 10041] Loss: 9.55e+07 0.01045166701078415 0.41635504364967346\n",
      "[Step 10042] Loss: 9.49e+07 0.010385817848145962 0.416331946849823\n",
      "[Step 10043] Loss: 9.66e+07 0.010438733734190464 0.41635337471961975\n",
      "[Step 10044] Loss: 9.54e+07 0.01050256472080946 0.41638392210006714\n",
      "[Step 10045] Loss: 9.66e+07 0.010519515722990036 0.4163789749145508\n",
      "[Step 10046] Loss: 9.56e+07 0.010619414038956165 0.416392982006073\n",
      "[Step 10047] Loss: 9.62e+07 0.010524525307118893 0.4163459539413452\n",
      "[Step 10048] Loss: 9.68e+07 0.010311931371688843 0.4162733554840088\n",
      "[Step 10049] Loss: 9.58e+07 0.01020668726414442 0.4162485897541046\n",
      "[Step 10050] Loss: 9.62e+07 0.010029599070549011 0.41617351770401\n",
      "[Step 10051] Loss: 9.60e+07 0.00988159328699112 0.4161314368247986\n",
      "[Step 10052] Loss: 9.58e+07 0.009731088764965534 0.41606542468070984\n",
      "[Step 10053] Loss: 9.63e+07 0.009544501081109047 0.415992796421051\n",
      "[Step 10054] Loss: 9.56e+07 0.00936608575284481 0.41593092679977417\n",
      "[Step 10055] Loss: 9.58e+07 0.00917046144604683 0.41585418581962585\n",
      "[Step 10056] Loss: 9.58e+07 0.00909875426441431 0.4158046841621399\n",
      "[Step 10057] Loss: 9.64e+07 0.008946901187300682 0.41572627425193787\n",
      "[Step 10058] Loss: 9.52e+07 0.008866161108016968 0.4156850278377533\n",
      "[Step 10059] Loss: 9.65e+07 0.008932340890169144 0.4156875014305115\n",
      "[Step 10060] Loss: 9.49e+07 0.008929675444960594 0.41563963890075684\n",
      "[Step 10061] Loss: 9.58e+07 0.008855297230184078 0.4155917763710022\n",
      "[Step 10062] Loss: 9.59e+07 0.008790828287601471 0.4155265986919403\n",
      "[Step 10063] Loss: 9.58e+07 0.008665970526635647 0.4154655337333679\n",
      "[Step 10064] Loss: 9.49e+07 0.008519449271261692 0.41537559032440186\n",
      "[Step 10065] Loss: 9.53e+07 0.00835354533046484 0.41527822613716125\n",
      "[Step 10066] Loss: 9.63e+07 0.008271361701190472 0.41525596380233765\n",
      "[Step 10067] Loss: 9.56e+07 0.00820364709943533 0.41518911719322205\n",
      "[Step 10068] Loss: 9.55e+07 0.0081255491822958 0.4151412546634674\n",
      "[Step 10069] Loss: 9.49e+07 0.008123505860567093 0.41511979699134827\n",
      "[Step 10070] Loss: 9.59e+07 0.008037494495511055 0.41506123542785645\n",
      "[Step 10071] Loss: 9.57e+07 0.007971220649778843 0.41503316164016724\n",
      "[Step 10072] Loss: 9.60e+07 0.007899345830082893 0.41492921113967896\n",
      "[Step 10073] Loss: 9.58e+07 0.00777560006827116 0.41485247015953064\n",
      "[Step 10074] Loss: 9.52e+07 0.007718577515333891 0.414804607629776\n",
      "[Step 10075] Loss: 9.55e+07 0.007620468735694885 0.41474518179893494\n",
      "[Step 10076] Loss: 9.62e+07 0.007633205037564039 0.41471877694129944\n",
      "[Step 10077] Loss: 9.49e+07 0.007634468376636505 0.414698988199234\n",
      "[Step 10078] Loss: 9.55e+07 0.007618794217705727 0.4146791696548462\n",
      "[Step 10079] Loss: 9.66e+07 0.007702450733631849 0.414695680141449\n",
      "[Step 10080] Loss: 9.68e+07 0.007641632109880447 0.41469404101371765\n",
      "[Step 10081] Loss: 9.54e+07 0.007546612527221441 0.4146709442138672\n",
      "[Step 10082] Loss: 9.49e+07 0.007448885124176741 0.4146346151828766\n",
      "[Step 10083] Loss: 9.54e+07 0.0073517062701284885 0.4145851135253906\n",
      "[Step 10084] Loss: 9.57e+07 0.007334639318287373 0.4145776927471161\n",
      "[Step 10085] Loss: 9.54e+07 0.007307253312319517 0.4145570695400238\n",
      "[Step 10086] Loss: 9.56e+07 0.007275776471942663 0.414537250995636\n",
      "[Step 10087] Loss: 9.50e+07 0.007234241813421249 0.4144918620586395\n",
      "[Step 10088] Loss: 9.66e+07 0.0072359056212008 0.4144861102104187\n",
      "[Step 10089] Loss: 9.54e+07 0.0071852183900773525 0.41442257165908813\n",
      "[Step 10090] Loss: 9.56e+07 0.007076650392264128 0.4144093692302704\n",
      "[Step 10091] Loss: 9.58e+07 0.006982943043112755 0.4143400490283966\n",
      "[Step 10092] Loss: 9.53e+07 0.006799926515668631 0.4142913818359375\n",
      "[Step 10093] Loss: 9.59e+07 0.006651406642049551 0.41428887844085693\n",
      "[Step 10094] Loss: 9.59e+07 0.006510288920253515 0.4142080247402191\n",
      "[Step 10095] Loss: 9.58e+07 0.00644091609865427 0.41418904066085815\n",
      "[Step 10096] Loss: 9.62e+07 0.006380478385835886 0.4141412079334259\n",
      "[Step 10097] Loss: 9.60e+07 0.006190011743456125 0.41405290365219116\n",
      "[Step 10098] Loss: 9.58e+07 0.005946062039583921 0.41392749547958374\n",
      "[Step 10099] Loss: 9.53e+07 0.005836375989019871 0.41392502188682556\n",
      "[Step 10100] Loss: 9.53e+07 0.005780619569122791 0.4138878881931305\n",
      "[Step 10101] Loss: 9.55e+07 0.005677295848727226 0.4138515591621399\n",
      "[Step 10102] Loss: 9.55e+07 0.005628759507089853 0.4138226807117462\n",
      "[Step 10103] Loss: 9.55e+07 0.0055651310831308365 0.41378143429756165\n",
      "[Step 10104] Loss: 9.61e+07 0.005596202332526445 0.4138185679912567\n",
      "[Step 10105] Loss: 9.52e+07 0.005581455305218697 0.41378143429756165\n",
      "[Step 10106] Loss: 9.62e+07 0.005595257505774498 0.4137764871120453\n",
      "[Step 10107] Loss: 9.65e+07 0.0054729897528886795 0.413730263710022\n",
      "[Step 10108] Loss: 9.62e+07 0.00546649657189846 0.4137352406978607\n",
      "[Step 10109] Loss: 9.66e+07 0.005599471274763346 0.4137962758541107\n",
      "[Step 10110] Loss: 9.58e+07 0.0057226913049817085 0.41381195187568665\n",
      "[Step 10111] Loss: 9.63e+07 0.005826844833791256 0.41384580731391907\n",
      "[Step 10112] Loss: 9.61e+07 0.005885813385248184 0.41388291120529175\n",
      "[Step 10113] Loss: 9.56e+07 0.005937740206718445 0.4138862192630768\n",
      "[Step 10114] Loss: 9.59e+07 0.00591723108664155 0.41384828090667725\n",
      "[Step 10115] Loss: 9.59e+07 0.005851454101502895 0.413808673620224\n",
      "[Step 10116] Loss: 9.55e+07 0.005765516310930252 0.41377896070480347\n",
      "[Step 10117] Loss: 9.63e+07 0.005709082819521427 0.41372451186180115\n",
      "[Step 10118] Loss: 9.57e+07 0.005674965679645538 0.4136824309825897\n",
      "[Step 10119] Loss: 9.61e+07 0.005704707466065884 0.4136601388454437\n",
      "[Step 10120] Loss: 9.56e+07 0.0056798928417265415 0.41363126039505005\n",
      "[Step 10121] Loss: 9.58e+07 0.0057126861065626144 0.4136444628238678\n",
      "[Step 10122] Loss: 9.57e+07 0.005749327130615711 0.4136337339878082\n",
      "[Step 10123] Loss: 9.60e+07 0.005717018619179726 0.41361311078071594\n",
      "[Step 10124] Loss: 9.61e+07 0.0056905667297542095 0.41355782747268677\n",
      "[Step 10125] Loss: 9.56e+07 0.0057176752015948296 0.41354626417160034\n",
      "[Step 10126] Loss: 9.65e+07 0.005745598115026951 0.4135487377643585\n",
      "[Step 10127] Loss: 9.54e+07 0.0057433489710092545 0.41356194019317627\n",
      "[Step 10128] Loss: 9.58e+07 0.005723224021494389 0.41354626417160034\n",
      "[Step 10129] Loss: 9.49e+07 0.005647650919854641 0.41351160407066345\n",
      "[Step 10130] Loss: 9.59e+07 0.00552193121984601 0.41342827677726746\n",
      "[Step 10131] Loss: 9.61e+07 0.005481033120304346 0.41340023279190063\n",
      "[Step 10132] Loss: 9.55e+07 0.005456701386719942 0.41337957978248596\n",
      "[Step 10133] Loss: 9.58e+07 0.005394140258431435 0.4133441150188446\n",
      "[Step 10134] Loss: 9.57e+07 0.00531109981238842 0.41327396035194397\n",
      "[Step 10135] Loss: 9.61e+07 0.005108740646392107 0.41317906975746155\n",
      "[Step 10136] Loss: 9.62e+07 0.005016273353248835 0.4131328761577606\n",
      "[Step 10137] Loss: 9.62e+07 0.004967415239661932 0.41307181119918823\n",
      "[Step 10138] Loss: 9.60e+07 0.004988870117813349 0.41305696964263916\n",
      "[Step 10139] Loss: 9.59e+07 0.005031159613281488 0.41299259662628174\n",
      "[Step 10140] Loss: 9.60e+07 0.004945534281432629 0.41297197341918945\n",
      "[Step 10141] Loss: 9.58e+07 0.004771778360009193 0.4129043221473694\n",
      "[Step 10142] Loss: 9.49e+07 0.004633553326129913 0.4128531515598297\n",
      "[Step 10143] Loss: 9.62e+07 0.004526638425886631 0.4128069579601288\n",
      "[Step 10144] Loss: 9.59e+07 0.004385908134281635 0.41274258494377136\n",
      "[Step 10145] Loss: 9.65e+07 0.004384273197501898 0.41274669766426086\n",
      "[Step 10146] Loss: 9.54e+07 0.0043264045380055904 0.4127236008644104\n",
      "[Step 10147] Loss: 9.54e+07 0.004329977091401815 0.4126955568790436\n",
      "[Step 10148] Loss: 9.59e+07 0.0042481026612222195 0.41266173124313354\n",
      "[Step 10149] Loss: 9.54e+07 0.0042312778532505035 0.41263696551322937\n",
      "[Step 10150] Loss: 9.48e+07 0.004244309850037098 0.41263118386268616\n",
      "[Step 10151] Loss: 9.48e+07 0.004202686250209808 0.41259241104125977\n",
      "[Step 10152] Loss: 9.57e+07 0.004130186978727579 0.4125668406486511\n",
      "[Step 10153] Loss: 9.57e+07 0.0040305862203240395 0.41254371404647827\n",
      "[Step 10154] Loss: 9.57e+07 0.0040366435423493385 0.4125552773475647\n",
      "[Step 10155] Loss: 9.59e+07 0.00410380819812417 0.4125429093837738\n",
      "[Step 10156] Loss: 9.55e+07 0.004022390116006136 0.412470281124115\n",
      "[Step 10157] Loss: 9.58e+07 0.003858672920614481 0.4124133586883545\n",
      "[Step 10158] Loss: 9.67e+07 0.00382976233959198 0.41240426898002625\n",
      "[Step 10159] Loss: 9.61e+07 0.0036404121201485395 0.412334144115448\n",
      "[Step 10160] Loss: 9.72e+07 0.0032310602255165577 0.4121814966201782\n",
      "[Step 10161] Loss: 9.67e+07 0.0027007535099983215 0.41197437047958374\n",
      "[Step 10162] Loss: 9.58e+07 0.0022468105889856815 0.4118349254131317\n",
      "[Step 10163] Loss: 9.54e+07 0.001787033979780972 0.41168805956840515\n",
      "[Step 10164] Loss: 9.53e+07 0.0013186007272452116 0.41149911284446716\n",
      "[Step 10165] Loss: 9.62e+07 0.0008898008381947875 0.4113579988479614\n",
      "[Step 10166] Loss: 9.58e+07 0.0005066478042863309 0.41121938824653625\n",
      "[Step 10167] Loss: 9.59e+07 8.046374568948522e-05 0.4110865294933319\n",
      "[Step 10168] Loss: 9.58e+07 -0.00040035531856119633 0.4109248220920563\n",
      "[Step 10169] Loss: 9.67e+07 -0.0006896218983456492 0.4108084738254547\n",
      "[Step 10170] Loss: 9.60e+07 -0.0008925021393224597 0.4107804000377655\n",
      "[Step 10171] Loss: 9.58e+07 -0.001092014485038817 0.41071274876594543\n",
      "[Step 10172] Loss: 9.60e+07 -0.0012119461316615343 0.41067561507225037\n",
      "[Step 10173] Loss: 9.63e+07 -0.0013594093034043908 0.410617858171463\n",
      "[Step 10174] Loss: 9.56e+07 -0.001463602064177394 0.41059476137161255\n",
      "[Step 10175] Loss: 9.58e+07 -0.0015069593209773302 0.41057413816452026\n",
      "[Step 10176] Loss: 9.56e+07 -0.001569643267430365 0.41054028272628784\n",
      "[Step 10177] Loss: 9.55e+07 -0.0016432406846433878 0.41049572825431824\n",
      "[Step 10178] Loss: 9.52e+07 -0.0016708396142348647 0.41044870018959045\n",
      "[Step 10179] Loss: 9.58e+07 -0.0016503777587786317 0.4104412794113159\n",
      "[Step 10180] Loss: 9.55e+07 -0.0015853815712034702 0.4104520082473755\n",
      "[Step 10181] Loss: 9.57e+07 -0.0015630890848115087 0.41042229533195496\n",
      "[Step 10182] Loss: 9.61e+07 -0.0016130652511492372 0.4103934168815613\n",
      "[Step 10183] Loss: 9.51e+07 -0.0016121527878567576 0.4103670120239258\n",
      "[Step 10184] Loss: 9.63e+07 -0.0016853129491209984 0.41032493114471436\n",
      "[Step 10185] Loss: 9.56e+07 -0.0017725130310282111 0.4102473855018616\n",
      "[Step 10186] Loss: 9.55e+07 -0.0018775822827592492 0.41018712520599365\n",
      "[Step 10187] Loss: 9.63e+07 -0.0019374832045286894 0.41017311811447144\n",
      "[Step 10188] Loss: 9.57e+07 -0.0020354706794023514 0.4100889563560486\n",
      "[Step 10189] Loss: 9.54e+07 -0.0021063059102743864 0.4100138545036316\n",
      "[Step 10190] Loss: 9.53e+07 -0.002069551032036543 0.41001054644584656\n",
      "[Step 10191] Loss: 9.56e+07 -0.0019744671881198883 0.4100039601325989\n",
      "[Step 10192] Loss: 9.67e+07 -0.0017278746236115694 0.4100320041179657\n",
      "[Step 10193] Loss: 9.60e+07 -0.0014640188310295343 0.4100848138332367\n",
      "[Step 10194] Loss: 9.53e+07 -0.0012661117361858487 0.4100864827632904\n",
      "[Step 10195] Loss: 9.66e+07 -0.000949655775912106 0.4101557731628418\n",
      "[Step 10196] Loss: 9.57e+07 -0.0006397308316081762 0.41023004055023193\n",
      "[Step 10197] Loss: 9.58e+07 -0.00038979219971224666 0.41028863191604614\n",
      "[Step 10198] Loss: 9.50e+07 -0.00017415406182408333 0.4103076159954071\n",
      "[Step 10199] Loss: 9.53e+07 2.6508783776080236e-05 0.4103340208530426\n",
      "[Step 10200] Loss: 9.54e+07 0.0002337169280508533 0.4103868305683136\n",
      "[Step 10201] Loss: 9.58e+07 0.000403904530685395 0.4103851616382599\n",
      "[Step 10202] Loss: 9.69e+07 0.0003920698363799602 0.4103686809539795\n",
      "[Step 10203] Loss: 9.53e+07 0.000344949250575155 0.4103480279445648\n",
      "[Step 10204] Loss: 9.55e+07 0.00033511570654809475 0.410350501537323\n",
      "[Step 10205] Loss: 9.67e+07 0.000436021393397823 0.4103843569755554\n",
      "[Step 10206] Loss: 9.62e+07 0.000567656010389328 0.41039589047431946\n",
      "[Step 10207] Loss: 9.60e+07 0.0006108643719926476 0.41034969687461853\n",
      "[Step 10208] Loss: 9.73e+07 0.00042367313290014863 0.4102556109428406\n",
      "[Step 10209] Loss: 9.53e+07 0.0002968996705021709 0.4101656973361969\n",
      "[Step 10210] Loss: 9.56e+07 0.0002946966851595789 0.4101335108280182\n",
      "[Step 10211] Loss: 9.51e+07 0.0003040550509467721 0.41009801626205444\n",
      "[Step 10212] Loss: 9.63e+07 0.0003031087981071323 0.4100418984889984\n",
      "[Step 10213] Loss: 9.61e+07 0.00017467662109993398 0.409969300031662\n",
      "[Step 10214] Loss: 9.58e+07 0.0001194112774101086 0.4099099040031433\n",
      "[Step 10215] Loss: 9.56e+07 2.5276063752244227e-05 0.40984389185905457\n",
      "[Step 10216] Loss: 9.64e+07 8.086578600341454e-05 0.4098430573940277\n",
      "[Step 10217] Loss: 9.53e+07 0.00014291574188973755 0.40983396768569946\n",
      "[Step 10218] Loss: 9.58e+07 0.0001896868197945878 0.40984058380126953\n",
      "[Step 10219] Loss: 9.58e+07 0.0002702675119508058 0.40985873341560364\n",
      "[Step 10220] Loss: 9.58e+07 0.0003548399545252323 0.40986284613609314\n",
      "[Step 10221] Loss: 9.54e+07 0.0004874479491263628 0.40987688302993774\n",
      "[Step 10222] Loss: 9.52e+07 0.0006184609956108034 0.4099239110946655\n",
      "[Step 10223] Loss: 9.55e+07 0.0007731137447990477 0.4099305272102356\n",
      "[Step 10224] Loss: 9.60e+07 0.0009022608865052462 0.40997177362442017\n",
      "[Step 10225] Loss: 9.51e+07 0.0009355660295113921 0.40992310643196106\n",
      "[Step 10226] Loss: 9.53e+07 0.000865497044287622 0.4098306894302368\n",
      "[Step 10227] Loss: 9.72e+07 0.0006037209532223642 0.4097300171852112\n",
      "[Step 10228] Loss: 9.51e+07 0.0003707813157234341 0.40960705280303955\n",
      "[Step 10229] Loss: 9.57e+07 4.6974186261650175e-05 0.4094659686088562\n",
      "[Step 10230] Loss: 9.58e+07 -0.00019057914323639125 0.4093405604362488\n",
      "[Step 10231] Loss: 9.71e+07 -0.000638569938018918 0.40917056798934937\n",
      "[Step 10232] Loss: 9.56e+07 -0.0011420694645494223 0.4089584946632385\n",
      "[Step 10233] Loss: 9.50e+07 -0.0015786610310897231 0.4087843894958496\n",
      "[Step 10234] Loss: 9.64e+07 -0.0021070651710033417 0.40858060121536255\n",
      "[Step 10235] Loss: 9.55e+07 -0.002672094851732254 0.4083685278892517\n",
      "[Step 10236] Loss: 9.62e+07 -0.0032677610870450735 0.40814656019210815\n",
      "[Step 10237] Loss: 9.66e+07 -0.0039646499790251255 0.40792790055274963\n",
      "[Step 10238] Loss: 9.54e+07 -0.00461551733314991 0.4076713025569916\n",
      "[Step 10239] Loss: 9.59e+07 -0.005147785879671574 0.4074476957321167\n",
      "[Step 10240] Loss: 9.54e+07 -0.005622105207294226 0.4072752296924591\n",
      "[Step 10241] Loss: 9.55e+07 -0.006105388049036264 0.40708380937576294\n",
      "[Step 10242] Loss: 9.50e+07 -0.006586926989257336 0.4069022536277771\n",
      "[Step 10243] Loss: 9.59e+07 -0.007005041465163231 0.4067380726337433\n",
      "[Step 10244] Loss: 9.55e+07 -0.007349441759288311 0.40657222270965576\n",
      "[Step 10245] Loss: 9.59e+07 -0.007689287886023521 0.40644267201423645\n",
      "[Step 10246] Loss: 9.60e+07 -0.008068577386438847 0.406261146068573\n",
      "[Step 10247] Loss: 9.64e+07 -0.008339394815266132 0.4061373770236969\n",
      "[Step 10248] Loss: 9.64e+07 -0.00868875253945589 0.4060136079788208\n",
      "[Step 10249] Loss: 9.56e+07 -0.009092315100133419 0.4058493971824646\n",
      "[Step 10250] Loss: 9.61e+07 -0.009411131963133812 0.4056909680366516\n",
      "[Step 10251] Loss: 9.52e+07 -0.009627793915569782 0.40560927987098694\n",
      "[Step 10252] Loss: 9.56e+07 -0.009821552783250809 0.40548962354660034\n",
      "[Step 10253] Loss: 9.67e+07 -0.00985950231552124 0.40545910596847534\n",
      "[Step 10254] Loss: 9.62e+07 -0.009953959845006466 0.4053947329521179\n",
      "[Step 10255] Loss: 9.55e+07 -0.01011556014418602 0.4053015112876892\n",
      "[Step 10256] Loss: 9.55e+07 -0.010257488116621971 0.4052371382713318\n",
      "[Step 10257] Loss: 9.58e+07 -0.010408041998744011 0.4051702916622162\n",
      "[Step 10258] Loss: 9.63e+07 -0.010621913708746433 0.4050704538822174\n",
      "[Step 10259] Loss: 9.57e+07 -0.01082443818449974 0.4049772322177887\n",
      "[Step 10260] Loss: 9.57e+07 -0.01108173280954361 0.40489718317985535\n",
      "[Step 10261] Loss: 9.54e+07 -0.011353607289493084 0.40477341413497925\n",
      "[Step 10262] Loss: 9.60e+07 -0.01166535448282957 0.40464964509010315\n",
      "[Step 10263] Loss: 9.61e+07 -0.012022037990391254 0.4044961631298065\n",
      "[Step 10264] Loss: 9.53e+07 -0.012321706861257553 0.40437403321266174\n",
      "[Step 10265] Loss: 9.61e+07 -0.012645605020225048 0.4042676091194153\n",
      "[Step 10266] Loss: 9.56e+07 -0.012958407402038574 0.4041694104671478\n",
      "[Step 10267] Loss: 9.59e+07 -0.013237214647233486 0.4040547311306\n",
      "[Step 10268] Loss: 9.65e+07 -0.013547554612159729 0.4039548635482788\n",
      "[Step 10269] Loss: 9.60e+07 -0.013768833130598068 0.40384265780448914\n",
      "[Step 10270] Loss: 9.56e+07 -0.01390552707016468 0.40378326177597046\n",
      "[Step 10271] Loss: 9.54e+07 -0.014080643653869629 0.4036561846733093\n",
      "[Step 10272] Loss: 9.62e+07 -0.014197803102433681 0.4035975933074951\n",
      "[Step 10273] Loss: 9.55e+07 -0.014239434152841568 0.4035695493221283\n",
      "[Step 10274] Loss: 9.64e+07 -0.014342387206852436 0.4035125970840454\n",
      "[Step 10275] Loss: 9.51e+07 -0.014457081444561481 0.40346887707710266\n",
      "[Step 10276] Loss: 9.52e+07 -0.014620997942984104 0.4033640921115875\n",
      "[Step 10277] Loss: 9.67e+07 -0.014877946116030216 0.40326422452926636\n",
      "[Step 10278] Loss: 9.58e+07 -0.015115829184651375 0.4031479060649872\n",
      "[Step 10279] Loss: 9.60e+07 -0.015310732647776604 0.40307116508483887\n",
      "[Step 10280] Loss: 9.61e+07 -0.01559432316571474 0.4029325246810913\n",
      "[Step 10281] Loss: 9.53e+07 -0.01587992161512375 0.40279722213745117\n",
      "[Step 10282] Loss: 9.58e+07 -0.016156800091266632 0.4026907682418823\n",
      "[Step 10283] Loss: 9.59e+07 -0.016417676582932472 0.4025818407535553\n",
      "[Step 10284] Loss: 9.50e+07 -0.01669503189623356 0.40250593423843384\n",
      "[Step 10285] Loss: 9.56e+07 -0.016918357461690903 0.4023772180080414\n",
      "[Step 10286] Loss: 9.56e+07 -0.017178570851683617 0.40228480100631714\n",
      "[Step 10287] Loss: 9.58e+07 -0.017321961000561714 0.40223610401153564\n",
      "[Step 10288] Loss: 9.60e+07 -0.01746709831058979 0.40215030312538147\n",
      "[Step 10289] Loss: 9.52e+07 -0.01752588152885437 0.40212059020996094\n",
      "[Step 10290] Loss: 9.58e+07 -0.017583632841706276 0.40208181738853455\n",
      "[Step 10291] Loss: 9.51e+07 -0.01759084314107895 0.4020842909812927\n",
      "[Step 10292] Loss: 9.52e+07 -0.017632881179451942 0.40204551815986633\n",
      "[Step 10293] Loss: 9.64e+07 -0.017552580684423447 0.40205541253089905\n",
      "[Step 10294] Loss: 9.53e+07 -0.017525088042020798 0.4020306468009949\n",
      "[Step 10295] Loss: 9.57e+07 -0.017479930073022842 0.4020034372806549\n",
      "[Step 10296] Loss: 9.53e+07 -0.017452599480748177 0.40200671553611755\n",
      "[Step 10297] Loss: 9.55e+07 -0.017447462305426598 0.4020174443721771\n",
      "[Step 10298] Loss: 9.50e+07 -0.017390653491020203 0.40202075242996216\n",
      "[Step 10299] Loss: 9.55e+07 -0.01739060878753662 0.40201911330223083\n",
      "[Step 10300] Loss: 9.55e+07 -0.017420262098312378 0.4019778370857239\n",
      "[Step 10301] Loss: 9.61e+07 -0.01745472103357315 0.40193164348602295\n",
      "[Step 10302] Loss: 9.51e+07 -0.01750805974006653 0.40191513299942017\n",
      "[Step 10303] Loss: 9.61e+07 -0.017490198835730553 0.4019085466861725\n",
      "[Step 10304] Loss: 9.47e+07 -0.017481038346886635 0.40191182494163513\n",
      "[Step 10305] Loss: 9.60e+07 -0.01738166995346546 0.4019423723220825\n",
      "[Step 10306] Loss: 9.59e+07 -0.01732981950044632 0.4019300043582916\n",
      "[Step 10307] Loss: 9.50e+07 -0.01729404181241989 0.4019473195075989\n",
      "[Step 10308] Loss: 9.58e+07 -0.01724649965763092 0.40195804834365845\n",
      "[Step 10309] Loss: 9.60e+07 -0.017318056896328926 0.401915967464447\n",
      "[Step 10310] Loss: 9.60e+07 -0.017277348786592484 0.4018945097923279\n",
      "[Step 10311] Loss: 9.55e+07 -0.01715303398668766 0.40185078978538513\n",
      "[Step 10312] Loss: 9.56e+07 -0.01705983281135559 0.40185901522636414\n",
      "[Step 10313] Loss: 9.62e+07 -0.017108215019106865 0.4017781615257263\n",
      "[Step 10314] Loss: 9.56e+07 -0.017211005091667175 0.40172287821769714\n",
      "[Step 10315] Loss: 9.62e+07 -0.01734248362481594 0.4016816318035126\n",
      "[Step 10316] Loss: 9.63e+07 -0.01753690093755722 0.40161561965942383\n",
      "[Step 10317] Loss: 9.60e+07 -0.01767241768538952 0.40154629945755005\n",
      "[Step 10318] Loss: 9.52e+07 -0.017751816660165787 0.4015248417854309\n",
      "[Step 10319] Loss: 9.57e+07 -0.01778578571975231 0.4015108346939087\n",
      "[Step 10320] Loss: 9.51e+07 -0.017808983102440834 0.40151163935661316\n",
      "[Step 10321] Loss: 9.61e+07 -0.017805537208914757 0.40149348974227905\n",
      "[Step 10322] Loss: 9.62e+07 -0.01787937432527542 0.40144315361976624\n",
      "[Step 10323] Loss: 9.59e+07 -0.017878156155347824 0.4014208912849426\n",
      "[Step 10324] Loss: 9.53e+07 -0.01779746077954769 0.40146297216415405\n",
      "[Step 10325] Loss: 9.51e+07 -0.017662033438682556 0.40150585770606995\n",
      "[Step 10326] Loss: 9.60e+07 -0.017476065084338188 0.40153226256370544\n",
      "[Step 10327] Loss: 9.66e+07 -0.017472559586167336 0.40150585770606995\n",
      "[Step 10328] Loss: 9.46e+07 -0.017507262527942657 0.4014662504196167\n",
      "[Step 10329] Loss: 9.52e+07 -0.017507292330265045 0.40142667293548584\n",
      "[Step 10330] Loss: 9.64e+07 -0.017409278079867363 0.4014175832271576\n",
      "[Step 10331] Loss: 9.57e+07 -0.017341719940304756 0.4014192223548889\n",
      "[Step 10332] Loss: 9.62e+07 -0.017395008355379105 0.4013952910900116\n",
      "[Step 10333] Loss: 9.63e+07 -0.017570285126566887 0.4013367295265198\n",
      "[Step 10334] Loss: 9.62e+07 -0.017800364643335342 0.40123358368873596\n",
      "[Step 10335] Loss: 9.57e+07 -0.01793271116912365 0.4011898338794708\n",
      "[Step 10336] Loss: 9.58e+07 -0.01816384866833687 0.40112218260765076\n",
      "[Step 10337] Loss: 9.59e+07 -0.0185041893273592 0.4009670615196228\n",
      "[Step 10338] Loss: 9.52e+07 -0.018737392500042915 0.40084823966026306\n",
      "[Step 10339] Loss: 9.56e+07 -0.018976906314492226 0.4007500410079956\n",
      "[Step 10340] Loss: 9.54e+07 -0.019294757395982742 0.40062710642814636\n",
      "[Step 10341] Loss: 9.56e+07 -0.019557571038603783 0.40053054690361023\n",
      "[Step 10342] Loss: 9.68e+07 -0.019922949373722076 0.40041834115982056\n",
      "[Step 10343] Loss: 9.61e+07 -0.02019677497446537 0.4002954065799713\n",
      "[Step 10344] Loss: 9.49e+07 -0.02039177529513836 0.40022194385528564\n",
      "[Step 10345] Loss: 9.66e+07 -0.020391413941979408 0.40026405453681946\n",
      "[Step 10346] Loss: 9.53e+07 -0.020438414067029953 0.4002062678337097\n",
      "[Step 10347] Loss: 9.61e+07 -0.020419621840119362 0.4001840054988861\n",
      "[Step 10348] Loss: 9.60e+07 -0.020385224372148514 0.40018317103385925\n",
      "[Step 10349] Loss: 9.54e+07 -0.020440133288502693 0.4001633822917938\n",
      "[Step 10350] Loss: 9.62e+07 -0.02055569551885128 0.4001270532608032\n",
      "[Step 10351] Loss: 9.51e+07 -0.02064545638859272 0.40009158849716187\n",
      "[Step 10352] Loss: 9.55e+07 -0.02070026844739914 0.4000701308250427\n",
      "[Step 10353] Loss: 9.63e+07 -0.02099127136170864 0.40000906586647034\n",
      "[Step 10354] Loss: 9.67e+07 -0.02135365456342697 0.39989107847213745\n",
      "[Step 10355] Loss: 9.56e+07 -0.021762551739811897 0.39977389574050903\n",
      "[Step 10356] Loss: 9.56e+07 -0.022116471081972122 0.39964354038238525\n",
      "[Step 10357] Loss: 9.73e+07 -0.02270977944135666 0.3994298279285431\n",
      "[Step 10358] Loss: 9.53e+07 -0.02314377948641777 0.39928048849105835\n",
      "[Step 10359] Loss: 9.61e+07 -0.02352318726480007 0.3991435170173645\n",
      "[Step 10360] Loss: 9.51e+07 -0.023900825530290604 0.39901065826416016\n",
      "[Step 10361] Loss: 9.57e+07 -0.02432091161608696 0.39884892106056213\n",
      "[Step 10362] Loss: 9.55e+07 -0.024714041501283646 0.3987358808517456\n",
      "[Step 10363] Loss: 9.61e+07 -0.02502840757369995 0.39862367510795593\n",
      "[Step 10364] Loss: 9.59e+07 -0.025365760549902916 0.3984817564487457\n",
      "[Step 10365] Loss: 9.56e+07 -0.025686023756861687 0.3983505368232727\n",
      "[Step 10366] Loss: 9.58e+07 -0.025967540219426155 0.3982556462287903\n",
      "[Step 10367] Loss: 9.58e+07 -0.026286331936717033 0.39812198281288147\n",
      "[Step 10368] Loss: 9.53e+07 -0.02662103995680809 0.39797264337539673\n",
      "[Step 10369] Loss: 9.53e+07 -0.02691725641489029 0.3978356719017029\n",
      "[Step 10370] Loss: 9.55e+07 -0.027286706492304802 0.3976896107196808\n",
      "[Step 10371] Loss: 9.63e+07 -0.027687061578035355 0.39753201603889465\n",
      "[Step 10372] Loss: 9.47e+07 -0.02800544537603855 0.397400826215744\n",
      "[Step 10373] Loss: 9.59e+07 -0.028302539139986038 0.397239089012146\n",
      "[Step 10374] Loss: 9.51e+07 -0.028541510924696922 0.3971194326877594\n",
      "[Step 10375] Loss: 9.52e+07 -0.028814295306801796 0.396997332572937\n",
      "[Step 10376] Loss: 9.58e+07 -0.029098639264702797 0.39686116576194763\n",
      "[Step 10377] Loss: 9.53e+07 -0.02927718684077263 0.39674732089042664\n",
      "[Step 10378] Loss: 9.58e+07 -0.029515674337744713 0.3966342508792877\n",
      "[Step 10379] Loss: 9.64e+07 -0.029911911115050316 0.3964807987213135\n",
      "[Step 10380] Loss: 9.59e+07 -0.03031100705265999 0.39633309841156006\n",
      "[Step 10381] Loss: 9.64e+07 -0.030710523948073387 0.39616888761520386\n",
      "[Step 10382] Loss: 9.59e+07 -0.03108229674398899 0.39599066972732544\n",
      "[Step 10383] Loss: 9.63e+07 -0.03128410875797272 0.3958998918533325\n",
      "[Step 10384] Loss: 9.62e+07 -0.03137921914458275 0.3958231508731842\n",
      "[Step 10385] Loss: 9.58e+07 -0.03136395663022995 0.39580169320106506\n",
      "[Step 10386] Loss: 9.53e+07 -0.03136996552348137 0.395786851644516\n",
      "[Step 10387] Loss: 9.49e+07 -0.03139020875096321 0.3957587778568268\n",
      "[Step 10388] Loss: 9.53e+07 -0.03142104297876358 0.3957059979438782\n",
      "[Step 10389] Loss: 9.62e+07 -0.03143778070807457 0.39568454027175903\n",
      "[Step 10390] Loss: 9.54e+07 -0.03138718381524086 0.3956564664840698\n",
      "[Step 10391] Loss: 9.59e+07 -0.031321439892053604 0.395658940076828\n",
      "[Step 10392] Loss: 9.55e+07 -0.03137728571891785 0.39562347531318665\n",
      "[Step 10393] Loss: 9.59e+07 -0.0314754955470562 0.39557725191116333\n",
      "[Step 10394] Loss: 9.58e+07 -0.0314265675842762 0.3955855071544647\n",
      "[Step 10395] Loss: 9.48e+07 -0.03132832795381546 0.39559870958328247\n",
      "[Step 10396] Loss: 9.66e+07 -0.031348809599876404 0.39559707045555115\n",
      "[Step 10397] Loss: 9.60e+07 -0.03125646710395813 0.395572304725647\n",
      "[Step 10398] Loss: 9.51e+07 -0.03118152916431427 0.3956226408481598\n",
      "[Step 10399] Loss: 9.61e+07 -0.031199492514133453 0.39556241035461426\n",
      "[Step 10400] Loss: 9.60e+07 -0.03125108778476715 0.3955557942390442\n",
      "[Step 10401] Loss: 9.52e+07 -0.031267132610082626 0.3955129086971283\n",
      "[Step 10402] Loss: 9.54e+07 -0.031214473769068718 0.3955104351043701\n",
      "[Step 10403] Loss: 9.57e+07 -0.031076034530997276 0.39550381898880005\n",
      "[Step 10404] Loss: 9.60e+07 -0.031011290848255157 0.3955326974391937\n",
      "[Step 10405] Loss: 9.58e+07 -0.030999567359685898 0.39549803733825684\n",
      "[Step 10406] Loss: 9.63e+07 -0.031164173036813736 0.39544275403022766\n",
      "[Step 10407] Loss: 9.54e+07 -0.03137525916099548 0.39536768198013306\n",
      "[Step 10408] Loss: 9.59e+07 -0.031555868685245514 0.39526453614234924\n",
      "[Step 10409] Loss: 9.53e+07 -0.03178238123655319 0.39520263671875\n",
      "[Step 10410] Loss: 9.55e+07 -0.03187635540962219 0.39515891671180725\n",
      "[Step 10411] Loss: 9.59e+07 -0.03200911357998848 0.3951250910758972\n",
      "[Step 10412] Loss: 9.57e+07 -0.03211117908358574 0.39507392048835754\n",
      "[Step 10413] Loss: 9.53e+07 -0.032175712287425995 0.39504504203796387\n",
      "[Step 10414] Loss: 9.48e+07 -0.03230564668774605 0.3950219452381134\n",
      "[Step 10415] Loss: 9.51e+07 -0.0323953740298748 0.3949757516384125\n",
      "[Step 10416] Loss: 9.47e+07 -0.032435908913612366 0.3949328362941742\n",
      "[Step 10417] Loss: 9.58e+07 -0.03240841254591942 0.3949386179447174\n",
      "[Step 10418] Loss: 9.61e+07 -0.032450586557388306 0.39492952823638916\n",
      "[Step 10419] Loss: 9.61e+07 -0.032574839890003204 0.39487671852111816\n",
      "[Step 10420] Loss: 9.61e+07 -0.03280787542462349 0.3948049247264862\n",
      "[Step 10421] Loss: 9.62e+07 -0.032941848039627075 0.39475294947624207\n",
      "[Step 10422] Loss: 9.54e+07 -0.033112719655036926 0.3946646749973297\n",
      "[Step 10423] Loss: 9.54e+07 -0.03326665982604027 0.39461350440979004\n",
      "[Step 10424] Loss: 9.52e+07 -0.03348817676305771 0.3945210874080658\n",
      "[Step 10425] Loss: 9.60e+07 -0.033741701394319534 0.3944360911846161\n",
      "[Step 10426] Loss: 9.54e+07 -0.033944468945264816 0.3943469822406769\n",
      "[Step 10427] Loss: 9.62e+07 -0.03407849743962288 0.39429333806037903\n",
      "[Step 10428] Loss: 9.55e+07 -0.03415793552994728 0.39427438378334045\n",
      "[Step 10429] Loss: 9.51e+07 -0.03429551050066948 0.394228994846344\n",
      "[Step 10430] Loss: 9.59e+07 -0.03434202820062637 0.3942388892173767\n",
      "[Step 10431] Loss: 9.60e+07 -0.03445908799767494 0.3942496180534363\n",
      "[Step 10432] Loss: 9.54e+07 -0.0345776304602623 0.39422979950904846\n",
      "[Step 10433] Loss: 9.53e+07 -0.03466562181711197 0.39417123794555664\n",
      "[Step 10434] Loss: 9.71e+07 -0.03486119210720062 0.3941076993942261\n",
      "[Step 10435] Loss: 9.62e+07 -0.03512824326753616 0.39401859045028687\n",
      "[Step 10436] Loss: 9.56e+07 -0.03541097044944763 0.39390304684638977\n",
      "[Step 10437] Loss: 9.54e+07 -0.03569938987493515 0.3937710225582123\n",
      "[Step 10438] Loss: 9.52e+07 -0.03602724149823189 0.39364561438560486\n",
      "[Step 10439] Loss: 9.65e+07 -0.03653055429458618 0.39344099164009094\n",
      "[Step 10440] Loss: 9.56e+07 -0.03702463582158089 0.3932313919067383\n",
      "[Step 10441] Loss: 9.56e+07 -0.037553783506155014 0.3930407762527466\n",
      "[Step 10442] Loss: 9.72e+07 -0.037848006933927536 0.3928864896297455\n",
      "[Step 10443] Loss: 9.65e+07 -0.037943825125694275 0.3928477168083191\n",
      "[Step 10444] Loss: 9.52e+07 -0.03802388161420822 0.39276355504989624\n",
      "[Step 10445] Loss: 9.54e+07 -0.038066525012254715 0.3927000164985657\n",
      "[Step 10446] Loss: 9.48e+07 -0.038024283945560455 0.3926793932914734\n",
      "[Step 10447] Loss: 9.55e+07 -0.03802608698606491 0.39268267154693604\n",
      "[Step 10448] Loss: 9.56e+07 -0.037959303706884384 0.39267030358314514\n",
      "[Step 10449] Loss: 9.56e+07 -0.037977851927280426 0.39262986183166504\n",
      "[Step 10450] Loss: 9.49e+07 -0.037969090044498444 0.3925977051258087\n",
      "[Step 10451] Loss: 9.54e+07 -0.03797305375337601 0.39253416657447815\n",
      "[Step 10452] Loss: 9.51e+07 -0.03797280788421631 0.3925011456012726\n",
      "[Step 10453] Loss: 9.52e+07 -0.03797200322151184 0.392512708902359\n",
      "[Step 10454] Loss: 9.55e+07 -0.038036786019802094 0.39243680238723755\n",
      "[Step 10455] Loss: 9.52e+07 -0.0381244495511055 0.39234766364097595\n",
      "[Step 10456] Loss: 9.52e+07 -0.038245122879743576 0.3922717571258545\n",
      "[Step 10457] Loss: 9.54e+07 -0.038307465612888336 0.39223793148994446\n",
      "[Step 10458] Loss: 9.58e+07 -0.03832946717739105 0.39225029945373535\n",
      "[Step 10459] Loss: 9.52e+07 -0.03837793320417404 0.39220163226127625\n",
      "[Step 10460] Loss: 9.55e+07 -0.038331642746925354 0.39221978187561035\n",
      "[Step 10461] Loss: 9.58e+07 -0.03822606801986694 0.3922247290611267\n",
      "[Step 10462] Loss: 9.70e+07 -0.03794388473033905 0.39232125878334045\n",
      "[Step 10463] Loss: 9.54e+07 -0.037648510187864304 0.39240461587905884\n",
      "[Step 10464] Loss: 9.58e+07 -0.037311624735593796 0.3925069272518158\n",
      "[Step 10465] Loss: 9.85e+07 -0.036789268255233765 0.39264968037605286\n",
      "[Step 10466] Loss: 9.51e+07 -0.03634415194392204 0.39277923107147217\n",
      "[Step 10467] Loss: 9.60e+07 -0.035882677882909775 0.39286503195762634\n",
      "[Step 10468] Loss: 9.53e+07 -0.035514261573553085 0.3929533362388611\n",
      "[Step 10469] Loss: 9.56e+07 -0.03514528647065163 0.3930911123752594\n",
      "[Step 10470] Loss: 9.49e+07 -0.034794263541698456 0.39316457509994507\n",
      "[Step 10471] Loss: 9.62e+07 -0.03460307419300079 0.39322808384895325\n",
      "[Step 10472] Loss: 9.59e+07 -0.03440158814191818 0.39325615763664246\n",
      "[Step 10473] Loss: 9.59e+07 -0.03415428847074509 0.393319696187973\n",
      "[Step 10474] Loss: 9.53e+07 -0.03393173962831497 0.39337167143821716\n",
      "[Step 10475] Loss: 9.67e+07 -0.03366608917713165 0.39343932271003723\n",
      "[Step 10476] Loss: 9.51e+07 -0.033432260155677795 0.3934987485408783\n",
      "[Step 10477] Loss: 9.59e+07 -0.03318433463573456 0.39354246854782104\n",
      "[Step 10478] Loss: 9.62e+07 -0.03287223353981972 0.3935862183570862\n",
      "[Step 10479] Loss: 9.52e+07 -0.03262762352824211 0.3936241567134857\n",
      "[Step 10480] Loss: 9.66e+07 -0.032591331750154495 0.3936002254486084\n",
      "[Step 10481] Loss: 9.61e+07 -0.03264337405562401 0.3935680389404297\n",
      "[Step 10482] Loss: 9.55e+07 -0.03267444297671318 0.3934904932975769\n",
      "[Step 10483] Loss: 9.54e+07 -0.032695382833480835 0.3934640884399414\n",
      "[Step 10484] Loss: 9.46e+07 -0.03273077309131622 0.3934261202812195\n",
      "[Step 10485] Loss: 9.60e+07 -0.03290422633290291 0.3932751417160034\n",
      "[Step 10486] Loss: 9.51e+07 -0.03305508941411972 0.393210768699646\n",
      "[Step 10487] Loss: 9.54e+07 -0.03315798193216324 0.3931703269481659\n",
      "[Step 10488] Loss: 9.55e+07 -0.033125173300504684 0.393105149269104\n",
      "[Step 10489] Loss: 9.55e+07 -0.033195577561855316 0.39305317401885986\n",
      "[Step 10490] Loss: 9.63e+07 -0.03337961435317993 0.3929648697376251\n",
      "[Step 10491] Loss: 9.63e+07 -0.033498939126729965 0.39289310574531555\n",
      "[Step 10492] Loss: 9.53e+07 -0.03370213136076927 0.39277923107147217\n",
      "[Step 10493] Loss: 9.59e+07 -0.033876124769449234 0.39268845319747925\n",
      "[Step 10494] Loss: 9.53e+07 -0.03400081768631935 0.39259272813796997\n",
      "[Step 10495] Loss: 9.60e+07 -0.03410864248871803 0.3925572633743286\n",
      "[Step 10496] Loss: 9.49e+07 -0.03422756493091583 0.3924863040447235\n",
      "[Step 10497] Loss: 9.57e+07 -0.03434203937649727 0.3924153447151184\n",
      "[Step 10498] Loss: 9.67e+07 -0.034570932388305664 0.392320454120636\n",
      "[Step 10499] Loss: 9.59e+07 -0.034909311681985855 0.3921818137168884\n",
      "[Step 10500] Loss: 9.56e+07 -0.035292383283376694 0.3920357823371887\n",
      "[Step 10501] Loss: 9.58e+07 -0.035607967525720596 0.39191365242004395\n",
      "[Step 10502] Loss: 9.46e+07 -0.03587598726153374 0.3918616771697998\n",
      "[Step 10503] Loss: 9.53e+07 -0.03615075349807739 0.3917255103588104\n",
      "[Step 10504] Loss: 9.59e+07 -0.03627314418554306 0.39167848229408264\n",
      "[Step 10505] Loss: 9.59e+07 -0.03629655763506889 0.3916594982147217\n",
      "[Step 10506] Loss: 9.63e+07 -0.036376774311065674 0.39161577820777893\n",
      "[Step 10507] Loss: 9.54e+07 -0.03639182820916176 0.39159101247787476\n",
      "[Step 10508] Loss: 9.50e+07 -0.036394909024238586 0.3915761709213257\n",
      "[Step 10509] Loss: 9.58e+07 -0.036460209637880325 0.39155885577201843\n",
      "[Step 10510] Loss: 9.58e+07 -0.036468133330345154 0.39152172207832336\n",
      "[Step 10511] Loss: 9.55e+07 -0.036564067006111145 0.39145901799201965\n",
      "[Step 10512] Loss: 9.60e+07 -0.036751892417669296 0.3913872241973877\n",
      "[Step 10513] Loss: 9.68e+07 -0.03708192706108093 0.39122632145881653\n",
      "[Step 10514] Loss: 9.53e+07 -0.03741094470024109 0.39109840989112854\n",
      "[Step 10515] Loss: 9.55e+07 -0.03760825842618942 0.39098042249679565\n",
      "[Step 10516] Loss: 9.63e+07 -0.03764691203832626 0.39097878336906433\n",
      "[Step 10517] Loss: 9.57e+07 -0.03773533180356026 0.39094576239585876\n",
      "[Step 10518] Loss: 9.55e+07 -0.03769950196146965 0.39092597365379333\n",
      "[Step 10519] Loss: 9.54e+07 -0.03762857988476753 0.390902042388916\n",
      "[Step 10520] Loss: 9.57e+07 -0.03758303448557854 0.3909086287021637\n",
      "[Step 10521] Loss: 9.65e+07 -0.03755095228552818 0.39092183113098145\n",
      "[Step 10522] Loss: 9.54e+07 -0.03759650141000748 0.39086902141571045\n",
      "[Step 10523] Loss: 9.60e+07 -0.03759549558162689 0.39086902141571045\n",
      "[Step 10524] Loss: 9.55e+07 -0.037592291831970215 0.390849232673645\n",
      "[Step 10525] Loss: 9.48e+07 -0.03765830397605896 0.39080795645713806\n",
      "[Step 10526] Loss: 9.62e+07 -0.03783886507153511 0.3907361924648285\n",
      "[Step 10527] Loss: 9.54e+07 -0.03802240267395973 0.39065203070640564\n",
      "[Step 10528] Loss: 9.54e+07 -0.03820694237947464 0.39058518409729004\n",
      "[Step 10529] Loss: 9.68e+07 -0.03858480975031853 0.3904779255390167\n",
      "[Step 10530] Loss: 9.57e+07 -0.038976456969976425 0.39032360911369324\n",
      "[Step 10531] Loss: 9.55e+07 -0.03927653282880783 0.39021551609039307\n",
      "[Step 10532] Loss: 9.62e+07 -0.03962898999452591 0.39008763432502747\n",
      "[Step 10533] Loss: 9.60e+07 -0.03994391858577728 0.38993826508522034\n",
      "[Step 10534] Loss: 9.59e+07 -0.04033549875020981 0.3898178040981293\n",
      "[Step 10535] Loss: 9.55e+07 -0.04073292016983032 0.38970065116882324\n",
      "[Step 10536] Loss: 9.65e+07 -0.041065994650125504 0.3895884156227112\n",
      "[Step 10537] Loss: 9.57e+07 -0.04141684249043465 0.3894638121128082\n",
      "[Step 10538] Loss: 9.57e+07 -0.04177021235227585 0.38936397433280945\n",
      "[Step 10539] Loss: 9.51e+07 -0.04211844131350517 0.3892468214035034\n",
      "[Step 10540] Loss: 9.53e+07 -0.042527686804533005 0.3891131281852722\n",
      "[Step 10541] Loss: 9.54e+07 -0.04293354973196983 0.3889637887477875\n",
      "[Step 10542] Loss: 9.56e+07 -0.04335461184382439 0.3888177275657654\n",
      "[Step 10543] Loss: 9.59e+07 -0.04364229366183281 0.38873687386512756\n",
      "[Step 10544] Loss: 9.57e+07 -0.04394970089197159 0.38863787055015564\n",
      "[Step 10545] Loss: 9.57e+07 -0.044190663844347 0.3885594606399536\n",
      "[Step 10546] Loss: 9.56e+07 -0.04435060918331146 0.3885050117969513\n",
      "[Step 10547] Loss: 9.56e+07 -0.044367384165525436 0.38850831985473633\n",
      "[Step 10548] Loss: 9.60e+07 -0.04440074786543846 0.38848522305488586\n",
      "[Step 10549] Loss: 9.70e+07 -0.04457531496882439 0.3883993923664093\n",
      "[Step 10550] Loss: 9.64e+07 -0.04456331953406334 0.38835978507995605\n",
      "[Step 10551] Loss: 9.57e+07 -0.04453311860561371 0.3883688747882843\n",
      "[Step 10552] Loss: 9.60e+07 -0.044593993574380875 0.38835814595222473\n",
      "[Step 10553] Loss: 9.51e+07 -0.044625356793403625 0.38832512497901917\n",
      "[Step 10554] Loss: 9.48e+07 -0.04465985670685768 0.38829708099365234\n",
      "[Step 10555] Loss: 9.56e+07 -0.044750891625881195 0.38824015855789185\n",
      "[Step 10556] Loss: 9.52e+07 -0.04478452727198601 0.38822034001350403\n",
      "[Step 10557] Loss: 9.59e+07 -0.04490584135055542 0.3881881535053253\n",
      "[Step 10558] Loss: 9.59e+07 -0.04487743601202965 0.3881840407848358\n",
      "[Step 10559] Loss: 9.55e+07 -0.04489010572433472 0.3881584703922272\n",
      "[Step 10560] Loss: 9.58e+07 -0.04480009153485298 0.38813701272010803\n",
      "[Step 10561] Loss: 9.56e+07 -0.04479314759373665 0.38812875747680664\n",
      "[Step 10562] Loss: 9.53e+07 -0.04479975253343582 0.38809987902641296\n",
      "[Step 10563] Loss: 9.54e+07 -0.044811420142650604 0.38807347416877747\n",
      "[Step 10564] Loss: 9.49e+07 -0.044813647866249084 0.3880610764026642\n",
      "[Step 10565] Loss: 9.57e+07 -0.04478370025753975 0.38803550601005554\n",
      "[Step 10566] Loss: 9.58e+07 -0.04457657411694527 0.38810068368911743\n",
      "[Step 10567] Loss: 9.58e+07 -0.04441133514046669 0.3881229758262634\n",
      "[Step 10568] Loss: 9.68e+07 -0.04443676024675369 0.38810235261917114\n",
      "[Step 10569] Loss: 9.55e+07 -0.044503647834062576 0.38807180523872375\n",
      "[Step 10570] Loss: 9.58e+07 -0.04447349160909653 0.38809409737586975\n",
      "[Step 10571] Loss: 9.52e+07 -0.04440369829535484 0.38811060786247253\n",
      "[Step 10572] Loss: 9.50e+07 -0.0442701019346714 0.388164222240448\n",
      "[Step 10573] Loss: 9.51e+07 -0.044149067252874374 0.3881807327270508\n",
      "[Step 10574] Loss: 9.55e+07 -0.04402712360024452 0.3882368505001068\n",
      "[Step 10575] Loss: 9.53e+07 -0.0438847690820694 0.3882715106010437\n",
      "[Step 10576] Loss: 9.54e+07 -0.043903645128011703 0.3882574737071991\n",
      "[Step 10577] Loss: 9.57e+07 -0.043769557029008865 0.38825252652168274\n",
      "[Step 10578] Loss: 9.51e+07 -0.043638817965984344 0.3883061408996582\n",
      "[Step 10579] Loss: 9.50e+07 -0.0435110442340374 0.38831523060798645\n",
      "[Step 10580] Loss: 9.59e+07 -0.04333272576332092 0.38836392760276794\n",
      "[Step 10581] Loss: 9.56e+07 -0.04312046989798546 0.3884241580963135\n",
      "[Step 10582] Loss: 9.54e+07 -0.04286028444766998 0.3885050117969513\n",
      "[Step 10583] Loss: 9.59e+07 -0.04264893755316734 0.3885470926761627\n",
      "[Step 10584] Loss: 9.63e+07 -0.0425189845263958 0.38857513666152954\n",
      "[Step 10585] Loss: 9.51e+07 -0.042467013001441956 0.38860321044921875\n",
      "[Step 10586] Loss: 9.61e+07 -0.04246436432003975 0.3885817527770996\n",
      "[Step 10587] Loss: 9.66e+07 -0.04258708283305168 0.3885206878185272\n",
      "[Step 10588] Loss: 9.51e+07 -0.042747169733047485 0.38845303654670715\n",
      "[Step 10589] Loss: 9.70e+07 -0.043055832386016846 0.388356477022171\n",
      "[Step 10590] Loss: 9.61e+07 -0.043438319116830826 0.3881988823413849\n",
      "[Step 10591] Loss: 9.64e+07 -0.043924421072006226 0.38807594776153564\n",
      "[Step 10592] Loss: 9.67e+07 -0.044315773993730545 0.3879653811454773\n",
      "[Step 10593] Loss: 9.60e+07 -0.044723350554704666 0.38781026005744934\n",
      "[Step 10594] Loss: 9.58e+07 -0.04505785554647446 0.3876856565475464\n",
      "[Step 10595] Loss: 9.52e+07 -0.04547066241502762 0.38756105303764343\n",
      "[Step 10596] Loss: 9.54e+07 -0.04587966576218605 0.3874397575855255\n",
      "[Step 10597] Loss: 9.55e+07 -0.04633459448814392 0.3872854709625244\n",
      "[Step 10598] Loss: 9.64e+07 -0.04665863886475563 0.38717490434646606\n",
      "[Step 10599] Loss: 9.54e+07 -0.046913813799619675 0.3871088922023773\n",
      "[Step 10600] Loss: 9.55e+07 -0.04705626890063286 0.38707834482192993\n",
      "[Step 10601] Loss: 9.54e+07 -0.0471918061375618 0.3870461583137512\n",
      "[Step 10602] Loss: 9.59e+07 -0.04734515771269798 0.38700079917907715\n",
      "[Step 10603] Loss: 9.52e+07 -0.04757886752486229 0.3869306445121765\n",
      "[Step 10604] Loss: 9.59e+07 -0.04769963026046753 0.386904239654541\n",
      "[Step 10605] Loss: 9.54e+07 -0.047882549464702606 0.38687288761138916\n",
      "[Step 10606] Loss: 9.51e+07 -0.048051618039608 0.3868118226528168\n",
      "[Step 10607] Loss: 9.51e+07 -0.048279814422130585 0.38677141070365906\n",
      "[Step 10608] Loss: 9.66e+07 -0.04844812676310539 0.38671693205833435\n",
      "[Step 10609] Loss: 9.63e+07 -0.048544470220804214 0.38667404651641846\n",
      "[Step 10610] Loss: 9.67e+07 -0.04846535250544548 0.3867218792438507\n",
      "[Step 10611] Loss: 9.52e+07 -0.04840731993317604 0.38676315546035767\n",
      "[Step 10612] Loss: 9.57e+07 -0.04840311408042908 0.38676974177360535\n",
      "[Step 10613] Loss: 9.62e+07 -0.048582155257463455 0.38670456409454346\n",
      "[Step 10614] Loss: 9.48e+07 -0.04867583513259888 0.38670867681503296\n",
      "[Step 10615] Loss: 9.60e+07 -0.04872996732592583 0.38669052720069885\n",
      "[Step 10616] Loss: 9.48e+07 -0.04877806082367897 0.38666000962257385\n",
      "[Step 10617] Loss: 9.62e+07 -0.048965103924274445 0.3866105079650879\n",
      "[Step 10618] Loss: 9.65e+07 -0.04922093451023102 0.38651561737060547\n",
      "[Step 10619] Loss: 9.55e+07 -0.0494009293615818 0.38643309473991394\n",
      "[Step 10620] Loss: 9.51e+07 -0.04955378547310829 0.38636544346809387\n",
      "[Step 10621] Loss: 9.54e+07 -0.04958745837211609 0.3863225281238556\n",
      "[Step 10622] Loss: 9.54e+07 -0.04955914244055748 0.3862994313240051\n",
      "[Step 10623] Loss: 9.52e+07 -0.049478739500045776 0.386330783367157\n",
      "[Step 10624] Loss: 9.65e+07 -0.04953864589333534 0.38630685210227966\n",
      "[Step 10625] Loss: 9.57e+07 -0.049502938985824585 0.38629528880119324\n",
      "[Step 10626] Loss: 9.63e+07 -0.04960722103714943 0.3862457871437073\n",
      "[Step 10627] Loss: 9.49e+07 -0.049631647765636444 0.386225163936615\n",
      "[Step 10628] Loss: 9.58e+07 -0.04974811524152756 0.3861616253852844\n",
      "[Step 10629] Loss: 9.49e+07 -0.04982924461364746 0.38610219955444336\n",
      "[Step 10630] Loss: 9.63e+07 -0.050051137804985046 0.3860320746898651\n",
      "[Step 10631] Loss: 9.54e+07 -0.050332218408584595 0.3859347105026245\n",
      "[Step 10632] Loss: 9.56e+07 -0.05061674490571022 0.3858315646648407\n",
      "[Step 10633] Loss: 9.62e+07 -0.05107865855097771 0.3856591284275055\n",
      "[Step 10634] Loss: 9.57e+07 -0.05155337229371071 0.3854841887950897\n",
      "[Step 10635] Loss: 9.60e+07 -0.05208061635494232 0.38527706265449524\n",
      "[Step 10636] Loss: 9.55e+07 -0.052484724670648575 0.3851301968097687\n",
      "[Step 10637] Loss: 9.63e+07 -0.05297176167368889 0.3849593997001648\n",
      "[Step 10638] Loss: 9.59e+07 -0.05339012295007706 0.3848108649253845\n",
      "[Step 10639] Loss: 9.66e+07 -0.05363528057932854 0.38471269607543945\n",
      "[Step 10640] Loss: 9.53e+07 -0.05385783687233925 0.3846342861652374\n",
      "[Step 10641] Loss: 9.53e+07 -0.054080791771411896 0.38452044129371643\n",
      "[Step 10642] Loss: 9.50e+07 -0.054223064333200455 0.3844379186630249\n",
      "[Step 10643] Loss: 9.57e+07 -0.05430925264954567 0.384399950504303\n",
      "[Step 10644] Loss: 9.50e+07 -0.05437891185283661 0.384403258562088\n",
      "[Step 10645] Loss: 9.49e+07 -0.0544634610414505 0.38434797525405884\n",
      "[Step 10646] Loss: 9.51e+07 -0.05449654534459114 0.38427287340164185\n",
      "[Step 10647] Loss: 9.58e+07 -0.054570212960243225 0.38423824310302734\n",
      "[Step 10648] Loss: 9.52e+07 -0.05471821129322052 0.38418129086494446\n",
      "[Step 10649] Loss: 9.57e+07 -0.05476319417357445 0.3841598331928253\n",
      "[Step 10650] Loss: 9.61e+07 -0.054923154413700104 0.3841070234775543\n",
      "[Step 10651] Loss: 9.59e+07 -0.055154673755168915 0.3840319514274597\n",
      "[Step 10652] Loss: 9.47e+07 -0.055398792028427124 0.38396263122558594\n",
      "[Step 10653] Loss: 9.52e+07 -0.055594686418771744 0.3839065134525299\n",
      "[Step 10654] Loss: 9.53e+07 -0.05579386651515961 0.3838033974170685\n",
      "[Step 10655] Loss: 9.62e+07 -0.05618558079004288 0.3836953043937683\n",
      "[Step 10656] Loss: 9.54e+07 -0.05652662739157677 0.3835698664188385\n",
      "[Step 10657] Loss: 9.52e+07 -0.05680736526846886 0.383456826210022\n",
      "[Step 10658] Loss: 9.56e+07 -0.05705806612968445 0.38335120677948\n",
      "[Step 10659] Loss: 9.63e+07 -0.057148050516843796 0.38329675793647766\n",
      "[Step 10660] Loss: 9.62e+07 -0.05712489038705826 0.3832818865776062\n",
      "[Step 10661] Loss: 9.51e+07 -0.05715804174542427 0.38325878977775574\n",
      "[Step 10662] Loss: 9.49e+07 -0.05721784010529518 0.3832637369632721\n",
      "[Step 10663] Loss: 9.56e+07 -0.057340025901794434 0.3832109272480011\n",
      "[Step 10664] Loss: 9.57e+07 -0.05744392052292824 0.38316473364830017\n",
      "[Step 10665] Loss: 9.58e+07 -0.05746913328766823 0.38314080238342285\n",
      "[Step 10666] Loss: 9.60e+07 -0.0576179139316082 0.3830896317958832\n",
      "[Step 10667] Loss: 9.52e+07 -0.05776134878396988 0.38301950693130493\n",
      "[Step 10668] Loss: 9.58e+07 -0.05799311399459839 0.38291800022125244\n",
      "[Step 10669] Loss: 9.57e+07 -0.05814840644598007 0.3828379809856415\n",
      "[Step 10670] Loss: 9.54e+07 -0.05833709239959717 0.3828091025352478\n",
      "[Step 10671] Loss: 9.60e+07 -0.05859658122062683 0.3826828598976135\n",
      "[Step 10672] Loss: 9.63e+07 -0.05874373018741608 0.3825978636741638\n",
      "[Step 10673] Loss: 9.56e+07 -0.058858901262283325 0.3825615644454956\n",
      "[Step 10674] Loss: 9.59e+07 -0.05898234248161316 0.3825433850288391\n",
      "[Step 10675] Loss: 9.58e+07 -0.05910893902182579 0.38246169686317444\n",
      "[Step 10676] Loss: 9.57e+07 -0.05923644080758095 0.3823808431625366\n",
      "[Step 10677] Loss: 9.54e+07 -0.05942457169294357 0.3822900950908661\n",
      "[Step 10678] Loss: 9.59e+07 -0.05943197384476662 0.38222983479499817\n",
      "[Step 10679] Loss: 9.58e+07 -0.05951055511832237 0.3822084069252014\n",
      "[Step 10680] Loss: 9.55e+07 -0.0595322921872139 0.38218364119529724\n",
      "[Step 10681] Loss: 9.52e+07 -0.05950659513473511 0.38217538595199585\n",
      "[Step 10682] Loss: 9.66e+07 -0.05948355048894882 0.3821720778942108\n",
      "[Step 10683] Loss: 9.56e+07 -0.059364691376686096 0.38219931721687317\n",
      "[Step 10684] Loss: 9.58e+07 -0.05926685407757759 0.3822174668312073\n",
      "[Step 10685] Loss: 9.52e+07 -0.05927438288927078 0.38218528032302856\n",
      "[Step 10686] Loss: 9.51e+07 -0.059271715581417084 0.38214319944381714\n",
      "[Step 10687] Loss: 9.53e+07 -0.0592220313847065 0.38215723633766174\n",
      "[Step 10688] Loss: 9.59e+07 -0.05930580571293831 0.38208213448524475\n",
      "[Step 10689] Loss: 9.58e+07 -0.05939691886305809 0.3820219039916992\n",
      "[Step 10690] Loss: 9.52e+07 -0.05942272022366524 0.382016122341156\n",
      "[Step 10691] Loss: 9.54e+07 -0.05940087512135506 0.38200291991233826\n",
      "[Step 10692] Loss: 9.45e+07 -0.059386394917964935 0.3819674551486969\n",
      "[Step 10693] Loss: 9.53e+07 -0.059330906718969345 0.3819394111633301\n",
      "[Step 10694] Loss: 9.57e+07 -0.059339459985494614 0.38192373514175415\n",
      "[Step 10695] Loss: 9.55e+07 -0.05935731157660484 0.3819162845611572\n",
      "[Step 10696] Loss: 9.54e+07 -0.05935509130358696 0.3819105327129364\n",
      "[Step 10697] Loss: 9.61e+07 -0.05944298207759857 0.3818857669830322\n",
      "[Step 10698] Loss: 9.56e+07 -0.059475935995578766 0.3818601965904236\n",
      "[Step 10699] Loss: 9.61e+07 -0.05937451124191284 0.38189154863357544\n",
      "[Step 10700] Loss: 9.54e+07 -0.05923551321029663 0.3819146454334259\n",
      "[Step 10701] Loss: 9.54e+07 -0.05906128138303757 0.38197651505470276\n",
      "[Step 10702] Loss: 9.49e+07 -0.05894320830702782 0.3819979727268219\n",
      "[Step 10703] Loss: 9.53e+07 -0.05884232372045517 0.3820400536060333\n",
      "[Step 10704] Loss: 9.53e+07 -0.05875178426504135 0.3820144832134247\n",
      "[Step 10705] Loss: 9.50e+07 -0.05860244482755661 0.382068932056427\n",
      "[Step 10706] Loss: 9.54e+07 -0.05851510539650917 0.3820590376853943\n",
      "[Step 10707] Loss: 9.56e+07 -0.05840117111802101 0.38212093710899353\n",
      "[Step 10708] Loss: 9.53e+07 -0.05830296501517296 0.3821242153644562\n",
      "[Step 10709] Loss: 9.50e+07 -0.0581643171608448 0.3821399211883545\n",
      "[Step 10710] Loss: 9.54e+07 -0.05802746117115021 0.38215145468711853\n",
      "[Step 10711] Loss: 9.62e+07 -0.057888709008693695 0.38217127323150635\n",
      "[Step 10712] Loss: 9.57e+07 -0.057832758873701096 0.3821564018726349\n",
      "[Step 10713] Loss: 9.66e+07 -0.05776331201195717 0.3822067379951477\n",
      "[Step 10714] Loss: 9.59e+07 -0.05772743374109268 0.3821828067302704\n",
      "[Step 10715] Loss: 9.59e+07 -0.057643648236989975 0.382196843624115\n",
      "[Step 10716] Loss: 9.59e+07 -0.05753956735134125 0.3822331428527832\n",
      "[Step 10717] Loss: 9.51e+07 -0.05751319229602814 0.38226285576820374\n",
      "[Step 10718] Loss: 9.53e+07 -0.057457633316516876 0.3822958469390869\n",
      "[Step 10719] Loss: 9.55e+07 -0.05738655477762222 0.38229256868362427\n",
      "[Step 10720] Loss: 9.56e+07 -0.05737317353487015 0.3822900950908661\n",
      "[Step 10721] Loss: 9.61e+07 -0.057371824979782104 0.3822711110115051\n",
      "[Step 10722] Loss: 9.45e+07 -0.0573292151093483 0.38225460052490234\n",
      "[Step 10723] Loss: 9.49e+07 -0.0573255717754364 0.38226863741874695\n",
      "[Step 10724] Loss: 9.51e+07 -0.05738117918372154 0.38225048780441284\n",
      "[Step 10725] Loss: 9.57e+07 -0.05753999948501587 0.3821720778942108\n",
      "[Step 10726] Loss: 9.58e+07 -0.057795654982328415 0.3820771872997284\n",
      "[Step 10727] Loss: 9.72e+07 -0.058207713067531586 0.381929486989975\n",
      "[Step 10728] Loss: 9.60e+07 -0.058704499155282974 0.3817562162876129\n",
      "[Step 10729] Loss: 9.56e+07 -0.05912325531244278 0.38163328170776367\n",
      "[Step 10730] Loss: 9.63e+07 -0.05966600775718689 0.3814748525619507\n",
      "[Step 10731] Loss: 9.64e+07 -0.060363370925188065 0.3812916576862335\n",
      "[Step 10732] Loss: 9.61e+07 -0.060839321464300156 0.3811109662055969\n",
      "[Step 10733] Loss: 9.57e+07 -0.06130167469382286 0.38093438744544983\n",
      "[Step 10734] Loss: 9.57e+07 -0.0617314875125885 0.3808015286922455\n",
      "[Step 10735] Loss: 9.57e+07 -0.0621582493185997 0.38063982129096985\n",
      "[Step 10736] Loss: 9.55e+07 -0.0625055581331253 0.38050365447998047\n",
      "[Step 10737] Loss: 9.53e+07 -0.06279771775007248 0.3803732991218567\n",
      "[Step 10738] Loss: 9.59e+07 -0.06321652978658676 0.3802288770675659\n",
      "[Step 10739] Loss: 9.56e+07 -0.06364254653453827 0.3801051080226898\n",
      "[Step 10740] Loss: 9.58e+07 -0.0640605166554451 0.37996071577072144\n",
      "[Step 10741] Loss: 9.54e+07 -0.064492367208004 0.37985262274742126\n",
      "[Step 10742] Loss: 9.63e+07 -0.06489354372024536 0.3797445297241211\n",
      "[Step 10743] Loss: 9.61e+07 -0.06517870724201202 0.3796587288379669\n",
      "[Step 10744] Loss: 9.62e+07 -0.06545200198888779 0.37957867980003357\n",
      "[Step 10745] Loss: 9.61e+07 -0.06574871391057968 0.3794945180416107\n",
      "[Step 10746] Loss: 9.55e+07 -0.06600801646709442 0.3794326186180115\n",
      "[Step 10747] Loss: 9.55e+07 -0.06629379838705063 0.37934350967407227\n",
      "[Step 10748] Loss: 9.55e+07 -0.06648994982242584 0.3792981207370758\n",
      "[Step 10749] Loss: 9.55e+07 -0.06656578183174133 0.3792453408241272\n",
      "[Step 10750] Loss: 9.62e+07 -0.06654731184244156 0.37924450635910034\n",
      "[Step 10751] Loss: 9.58e+07 -0.06645280867815018 0.379270076751709\n",
      "[Step 10752] Loss: 9.67e+07 -0.06632698327302933 0.379273384809494\n",
      "[Step 10753] Loss: 9.65e+07 -0.06608302146196365 0.3793187737464905\n",
      "[Step 10754] Loss: 9.69e+07 -0.06610656529664993 0.3792882263660431\n",
      "[Step 10755] Loss: 9.55e+07 -0.06610458344221115 0.3792783319950104\n",
      "[Step 10756] Loss: 9.55e+07 -0.0661252811551094 0.37927502393722534\n",
      "[Step 10757] Loss: 9.59e+07 -0.06606782972812653 0.3792816400527954\n",
      "[Step 10758] Loss: 9.63e+07 -0.0658963993191719 0.37931957840919495\n",
      "[Step 10759] Loss: 9.57e+07 -0.06561219692230225 0.3793955147266388\n",
      "[Step 10760] Loss: 9.56e+07 -0.06541518867015839 0.3794681131839752\n",
      "[Step 10761] Loss: 9.47e+07 -0.06524723768234253 0.37950193881988525\n",
      "[Step 10762] Loss: 9.52e+07 -0.06518290936946869 0.3794945180416107\n",
      "[Step 10763] Loss: 9.57e+07 -0.06510314345359802 0.37951019406318665\n",
      "[Step 10764] Loss: 9.50e+07 -0.06494957208633423 0.3795440196990967\n",
      "[Step 10765] Loss: 9.58e+07 -0.06480726599693298 0.37957704067230225\n",
      "[Step 10766] Loss: 9.57e+07 -0.06471962481737137 0.37958940863609314\n",
      "[Step 10767] Loss: 9.57e+07 -0.06465993076562881 0.3795918822288513\n",
      "[Step 10768] Loss: 9.59e+07 -0.06456480175256729 0.3796067237854004\n",
      "[Step 10769] Loss: 9.52e+07 -0.06444007903337479 0.3796182870864868\n",
      "[Step 10770] Loss: 9.50e+07 -0.06437890231609344 0.3796364367008209\n",
      "[Step 10771] Loss: 9.64e+07 -0.064167819917202 0.37968018651008606\n",
      "[Step 10772] Loss: 9.51e+07 -0.06390462815761566 0.379748672246933\n",
      "[Step 10773] Loss: 9.47e+07 -0.06368819624185562 0.3798006474971771\n",
      "[Step 10774] Loss: 9.72e+07 -0.06371733546257019 0.3797404170036316\n",
      "[Step 10775] Loss: 9.55e+07 -0.06369893997907639 0.3797239065170288\n",
      "[Step 10776] Loss: 9.53e+07 -0.06376542150974274 0.37968429923057556\n",
      "[Step 10777] Loss: 9.57e+07 -0.06372241675853729 0.3796488046646118\n",
      "[Step 10778] Loss: 9.72e+07 -0.06351219862699509 0.3796793520450592\n",
      "[Step 10779] Loss: 9.53e+07 -0.0633496567606926 0.37968018651008606\n",
      "[Step 10780] Loss: 9.58e+07 -0.06321050226688385 0.37969088554382324\n",
      "[Step 10781] Loss: 9.58e+07 -0.06311061233282089 0.37970906496047974\n",
      "[Step 10782] Loss: 9.63e+07 -0.06312183290719986 0.3796917200088501\n",
      "[Step 10783] Loss: 9.74e+07 -0.06334416568279266 0.3796059191226959\n",
      "[Step 10784] Loss: 9.51e+07 -0.0635548084974289 0.37953659892082214\n",
      "[Step 10785] Loss: 9.55e+07 -0.06378833204507828 0.3794466555118561\n",
      "[Step 10786] Loss: 9.62e+07 -0.06396111845970154 0.3793996274471283\n",
      "[Step 10787] Loss: 9.61e+07 -0.06401724368333817 0.3793410360813141\n",
      "[Step 10788] Loss: 9.64e+07 -0.06418594717979431 0.3792577087879181\n",
      "[Step 10789] Loss: 9.55e+07 -0.06436096876859665 0.3791809678077698\n",
      "[Step 10790] Loss: 9.64e+07 -0.06445194780826569 0.37916281819343567\n",
      "[Step 10791] Loss: 9.51e+07 -0.0645434632897377 0.3791405260562897\n",
      "[Step 10792] Loss: 9.55e+07 -0.06465618312358856 0.3790852427482605\n",
      "[Step 10793] Loss: 9.51e+07 -0.06482964754104614 0.37900933623313904\n",
      "[Step 10794] Loss: 9.55e+07 -0.06499685347080231 0.3789920210838318\n",
      "[Step 10795] Loss: 9.54e+07 -0.06524226814508438 0.3789028823375702\n",
      "[Step 10796] Loss: 9.59e+07 -0.06543458253145218 0.37881624698638916\n",
      "[Step 10797] Loss: 9.55e+07 -0.06548431515693665 0.37879809737205505\n",
      "[Step 10798] Loss: 9.56e+07 -0.06563789397478104 0.3787527084350586\n",
      "[Step 10799] Loss: 9.54e+07 -0.06576626747846603 0.37868836522102356\n",
      "[Step 10800] Loss: 9.57e+07 -0.06592251360416412 0.3786734938621521\n",
      "[Step 10801] Loss: 9.47e+07 -0.06607229262590408 0.3786545395851135\n",
      "[Step 10802] Loss: 9.51e+07 -0.0661199539899826 0.3786083161830902\n",
      "[Step 10803] Loss: 9.47e+07 -0.06620410829782486 0.3785786032676697\n",
      "[Step 10804] Loss: 9.66e+07 -0.06629012525081635 0.3785414695739746\n",
      "[Step 10805] Loss: 9.55e+07 -0.0663772001862526 0.3785373568534851\n",
      "[Step 10806] Loss: 9.51e+07 -0.06647062301635742 0.3785555064678192\n",
      "[Step 10807] Loss: 9.61e+07 -0.0666298195719719 0.3784985840320587\n",
      "[Step 10808] Loss: 9.58e+07 -0.06688087433576584 0.3784300982952118\n",
      "[Step 10809] Loss: 9.54e+07 -0.06715705990791321 0.3783756196498871\n",
      "[Step 10810] Loss: 9.60e+07 -0.0674920380115509 0.3782757818698883\n",
      "[Step 10811] Loss: 9.52e+07 -0.06785307824611664 0.3781454265117645\n",
      "[Step 10812] Loss: 9.63e+07 -0.06831993907690048 0.37805381417274475\n",
      "[Step 10813] Loss: 9.64e+07 -0.06869415938854218 0.3779086172580719\n",
      "[Step 10814] Loss: 9.58e+07 -0.06909948587417603 0.37779638171195984\n",
      "[Step 10815] Loss: 9.64e+07 -0.06958896666765213 0.3776528239250183\n",
      "[Step 10816] Loss: 9.49e+07 -0.06998310983181 0.37756866216659546\n",
      "[Step 10817] Loss: 9.60e+07 -0.07041794061660767 0.3774564266204834\n",
      "[Step 10818] Loss: 9.62e+07 -0.07100308686494827 0.37730872631073\n",
      "[Step 10819] Loss: 9.59e+07 -0.07163532078266144 0.37714534997940063\n",
      "[Step 10820] Loss: 9.61e+07 -0.07203402370214462 0.37702322006225586\n",
      "[Step 10821] Loss: 9.54e+07 -0.07236773520708084 0.37692832946777344\n",
      "[Step 10822] Loss: 9.51e+07 -0.07266540080308914 0.37687140703201294\n",
      "[Step 10823] Loss: 9.56e+07 -0.07307660579681396 0.3767410218715668\n",
      "[Step 10824] Loss: 9.53e+07 -0.07339852303266525 0.3766486346721649\n",
      "[Step 10825] Loss: 9.46e+07 -0.0736793801188469 0.37658756971359253\n",
      "[Step 10826] Loss: 9.54e+07 -0.07401552051305771 0.37649431824684143\n",
      "[Step 10827] Loss: 9.71e+07 -0.07455629110336304 0.376343309879303\n",
      "[Step 10828] Loss: 9.55e+07 -0.07507945597171783 0.37619397044181824\n",
      "[Step 10829] Loss: 9.51e+07 -0.07558885216712952 0.3760503828525543\n",
      "[Step 10830] Loss: 9.56e+07 -0.07613379508256912 0.37594395875930786\n",
      "[Step 10831] Loss: 9.62e+07 -0.07673376798629761 0.375773161649704\n",
      "[Step 10832] Loss: 9.52e+07 -0.07730366289615631 0.3756271004676819\n",
      "[Step 10833] Loss: 9.52e+07 -0.07779879122972488 0.3754975497722626\n",
      "[Step 10834] Loss: 9.52e+07 -0.07823062688112259 0.3753894567489624\n",
      "[Step 10835] Loss: 9.57e+07 -0.07867935299873352 0.37526485323905945\n",
      "[Step 10836] Loss: 9.54e+07 -0.0791698768734932 0.3751014769077301\n",
      "[Step 10837] Loss: 9.54e+07 -0.0796353742480278 0.37500494718551636\n",
      "[Step 10838] Loss: 9.56e+07 -0.08011693507432938 0.37486302852630615\n",
      "[Step 10839] Loss: 9.62e+07 -0.08049749583005905 0.3747607171535492\n",
      "[Step 10840] Loss: 9.57e+07 -0.08084030449390411 0.37467655539512634\n",
      "[Step 10841] Loss: 9.56e+07 -0.08124850690364838 0.37458083033561707\n",
      "[Step 10842] Loss: 9.56e+07 -0.08166995644569397 0.37447109818458557\n",
      "[Step 10843] Loss: 9.55e+07 -0.08205596357584 0.37440672516822815\n",
      "[Step 10844] Loss: 9.54e+07 -0.0824335515499115 0.37430688738822937\n",
      "[Step 10845] Loss: 9.52e+07 -0.08275187760591507 0.37422436475753784\n",
      "[Step 10846] Loss: 9.52e+07 -0.0830921083688736 0.3741377294063568\n",
      "[Step 10847] Loss: 9.58e+07 -0.08338899165391922 0.3740552067756653\n",
      "[Step 10848] Loss: 9.58e+07 -0.08371186256408691 0.3739718794822693\n",
      "[Step 10849] Loss: 9.56e+07 -0.08401825278997421 0.3738844096660614\n",
      "[Step 10850] Loss: 9.52e+07 -0.08426279574632645 0.3738134503364563\n",
      "[Step 10851] Loss: 9.54e+07 -0.08450371772050858 0.3737565279006958\n",
      "[Step 10852] Loss: 9.57e+07 -0.0847143605351448 0.3736962676048279\n",
      "[Step 10853] Loss: 9.55e+07 -0.08495942503213882 0.3736385107040405\n",
      "[Step 10854] Loss: 9.55e+07 -0.08507933467626572 0.37359148263931274\n",
      "[Step 10855] Loss: 9.52e+07 -0.0851852223277092 0.373525470495224\n",
      "[Step 10856] Loss: 9.64e+07 -0.08516653627157211 0.37351474165916443\n",
      "[Step 10857] Loss: 9.50e+07 -0.08522213995456696 0.3734850585460663\n",
      "[Step 10858] Loss: 9.54e+07 -0.08530212938785553 0.37345781922340393\n",
      "[Step 10859] Loss: 9.60e+07 -0.08531751483678818 0.3734404742717743\n",
      "[Step 10860] Loss: 9.70e+07 -0.08551134914159775 0.3733711838722229\n",
      "[Step 10861] Loss: 9.58e+07 -0.08569002151489258 0.37330350279808044\n",
      "[Step 10862] Loss: 9.49e+07 -0.08583725988864899 0.3732556700706482\n",
      "[Step 10863] Loss: 9.57e+07 -0.08605426549911499 0.37318387627601624\n",
      "[Step 10864] Loss: 9.59e+07 -0.08613389730453491 0.37312692403793335\n",
      "[Step 10865] Loss: 9.53e+07 -0.0861840769648552 0.37309888005256653\n",
      "[Step 10866] Loss: 9.53e+07 -0.08628284186124802 0.37304607033729553\n",
      "[Step 10867] Loss: 9.53e+07 -0.08640340715646744 0.3730279207229614\n",
      "[Step 10868] Loss: 9.61e+07 -0.08663038164377213 0.37297511100769043\n",
      "[Step 10869] Loss: 9.66e+07 -0.0867438092827797 0.3729552924633026\n",
      "[Step 10870] Loss: 9.55e+07 -0.08682244271039963 0.3729470670223236\n",
      "[Step 10871] Loss: 9.62e+07 -0.08680304139852524 0.3729594349861145\n",
      "[Step 10872] Loss: 9.58e+07 -0.08665946871042252 0.3729577958583832\n",
      "[Step 10873] Loss: 9.62e+07 -0.0866713747382164 0.3729577958583832\n",
      "[Step 10874] Loss: 9.53e+07 -0.08663889020681381 0.37297511100769043\n",
      "[Step 10875] Loss: 9.55e+07 -0.08655013889074326 0.37299326062202454\n",
      "[Step 10876] Loss: 9.57e+07 -0.08635635673999786 0.3730361759662628\n",
      "[Step 10877] Loss: 9.55e+07 -0.08631917834281921 0.3730402886867523\n",
      "[Step 10878] Loss: 9.54e+07 -0.08633779734373093 0.37300315499305725\n",
      "[Step 10879] Loss: 9.53e+07 -0.08634673804044724 0.37295860052108765\n",
      "[Step 10880] Loss: 9.53e+07 -0.08640822023153305 0.37292641401290894\n",
      "[Step 10881] Loss: 9.51e+07 -0.08651932328939438 0.37288764119148254\n",
      "[Step 10882] Loss: 9.54e+07 -0.08652934432029724 0.37288764119148254\n",
      "[Step 10883] Loss: 9.58e+07 -0.08658057451248169 0.3728661835193634\n",
      "[Step 10884] Loss: 9.50e+07 -0.08668014407157898 0.37281832098960876\n",
      "[Step 10885] Loss: 9.68e+07 -0.08691390603780746 0.37273335456848145\n",
      "[Step 10886] Loss: 9.52e+07 -0.08715952932834625 0.3726838231086731\n",
      "[Step 10887] Loss: 9.51e+07 -0.08735908567905426 0.37262606620788574\n",
      "[Step 10888] Loss: 9.55e+07 -0.08752305060625076 0.3725658357143402\n",
      "[Step 10889] Loss: 9.56e+07 -0.08766026794910431 0.3725188076496124\n",
      "[Step 10890] Loss: 9.59e+07 -0.08783091604709625 0.37246763706207275\n",
      "[Step 10891] Loss: 9.54e+07 -0.08805292844772339 0.3723834753036499\n",
      "[Step 10892] Loss: 9.59e+07 -0.08812382817268372 0.37236863374710083\n",
      "[Step 10893] Loss: 9.52e+07 -0.0882805734872818 0.37232160568237305\n",
      "[Step 10894] Loss: 9.46e+07 -0.08845358341932297 0.372265487909317\n",
      "[Step 10895] Loss: 9.49e+07 -0.08867675811052322 0.3722267150878906\n",
      "[Step 10896] Loss: 9.69e+07 -0.08912984281778336 0.3721029460430145\n",
      "[Step 10897] Loss: 9.57e+07 -0.0894722044467926 0.3719841241836548\n",
      "[Step 10898] Loss: 9.55e+07 -0.0897851288318634 0.37187767028808594\n",
      "[Step 10899] Loss: 9.52e+07 -0.08997289836406708 0.37183642387390137\n",
      "[Step 10900] Loss: 9.51e+07 -0.09013230353593826 0.37178608775138855\n",
      "[Step 10901] Loss: 9.63e+07 -0.0904177576303482 0.37170523405075073\n",
      "[Step 10902] Loss: 9.54e+07 -0.09064526110887527 0.3716515898704529\n",
      "[Step 10903] Loss: 9.54e+07 -0.09088389575481415 0.3715740144252777\n",
      "[Step 10904] Loss: 9.64e+07 -0.0909821093082428 0.37154102325439453\n",
      "[Step 10905] Loss: 9.58e+07 -0.09102880954742432 0.37150636315345764\n",
      "[Step 10906] Loss: 9.68e+07 -0.09125736355781555 0.3714164197444916\n",
      "[Step 10907] Loss: 9.49e+07 -0.09151334315538406 0.37133556604385376\n",
      "[Step 10908] Loss: 9.54e+07 -0.09169387817382812 0.37129348516464233\n",
      "[Step 10909] Loss: 9.66e+07 -0.09192050993442535 0.3712332546710968\n",
      "[Step 10910] Loss: 9.56e+07 -0.09223955124616623 0.3711598217487335\n",
      "[Step 10911] Loss: 9.54e+07 -0.09258006513118744 0.3710607886314392\n",
      "[Step 10912] Loss: 9.57e+07 -0.09283680468797684 0.3709881901741028\n",
      "[Step 10913] Loss: 9.51e+07 -0.09313591569662094 0.37090978026390076\n",
      "[Step 10914] Loss: 9.60e+07 -0.09341990202665329 0.370809942483902\n",
      "[Step 10915] Loss: 9.56e+07 -0.09367026388645172 0.37073981761932373\n",
      "[Step 10916] Loss: 9.60e+07 -0.09411747753620148 0.3706185221672058\n",
      "[Step 10917] Loss: 9.54e+07 -0.09454398602247238 0.3705112636089325\n",
      "[Step 10918] Loss: 9.54e+07 -0.0949215218424797 0.3703932464122772\n",
      "[Step 10919] Loss: 9.51e+07 -0.09522436559200287 0.3703387975692749\n",
      "[Step 10920] Loss: 9.54e+07 -0.09558941423892975 0.37027525901794434\n",
      "[Step 10921] Loss: 9.58e+07 -0.09595132619142532 0.3702034652233124\n",
      "[Step 10922] Loss: 9.52e+07 -0.09633897244930267 0.3701135218143463\n",
      "[Step 10923] Loss: 9.57e+07 -0.0968070700764656 0.3699798583984375\n",
      "[Step 10924] Loss: 9.65e+07 -0.09719310700893402 0.3699146807193756\n",
      "[Step 10925] Loss: 9.57e+07 -0.09750451892614365 0.36983463168144226\n",
      "[Step 10926] Loss: 9.58e+07 -0.09793137013912201 0.3697100579738617\n",
      "[Step 10927] Loss: 9.49e+07 -0.09835489839315414 0.36958298087120056\n",
      "[Step 10928] Loss: 9.54e+07 -0.0987916886806488 0.3694765269756317\n",
      "[Step 10929] Loss: 9.55e+07 -0.09918566793203354 0.36934202909469604\n",
      "[Step 10930] Loss: 9.54e+07 -0.09950802475214005 0.36925208568573\n",
      "[Step 10931] Loss: 9.59e+07 -0.09968730807304382 0.36919599771499634\n",
      "[Step 10932] Loss: 9.52e+07 -0.09982748329639435 0.36915719509124756\n",
      "[Step 10933] Loss: 9.44e+07 -0.09991870075464249 0.36913904547691345\n",
      "[Step 10934] Loss: 9.61e+07 -0.10009630769491196 0.36909037828445435\n",
      "[Step 10935] Loss: 9.55e+07 -0.10025440901517868 0.369040846824646\n",
      "[Step 10936] Loss: 9.54e+07 -0.10040216892957687 0.3690218925476074\n",
      "[Step 10937] Loss: 9.56e+07 -0.10060235857963562 0.36895835399627686\n",
      "[Step 10938] Loss: 9.59e+07 -0.10077942162752151 0.36889150738716125\n",
      "[Step 10939] Loss: 9.55e+07 -0.10095619410276413 0.3688156008720398\n",
      "[Step 10940] Loss: 9.56e+07 -0.10114506632089615 0.3687512278556824\n",
      "[Step 10941] Loss: 9.49e+07 -0.10121988505125046 0.36868852376937866\n",
      "[Step 10942] Loss: 9.59e+07 -0.10136530548334122 0.3686249852180481\n",
      "[Step 10943] Loss: 9.62e+07 -0.10140961408615112 0.3686142563819885\n",
      "[Step 10944] Loss: 9.62e+07 -0.10137087851762772 0.3685820698738098\n",
      "[Step 10945] Loss: 9.58e+07 -0.10150569677352905 0.36852678656578064\n",
      "[Step 10946] Loss: 9.49e+07 -0.10159976780414581 0.3684954345226288\n",
      "[Step 10947] Loss: 9.51e+07 -0.10178273916244507 0.36843109130859375\n",
      "[Step 10948] Loss: 9.74e+07 -0.10211735963821411 0.3683040142059326\n",
      "[Step 10949] Loss: 9.53e+07 -0.10249799489974976 0.3681827187538147\n",
      "[Step 10950] Loss: 9.57e+07 -0.10288264602422714 0.3680614233016968\n",
      "[Step 10951] Loss: 9.49e+07 -0.10326573997735977 0.3679376542568207\n",
      "[Step 10952] Loss: 9.60e+07 -0.10378468036651611 0.3677792251110077\n",
      "[Step 10953] Loss: 9.51e+07 -0.10422227531671524 0.36765629053115845\n",
      "[Step 10954] Loss: 9.55e+07 -0.10467790067195892 0.3675118684768677\n",
      "[Step 10955] Loss: 9.61e+07 -0.10528291016817093 0.36731961369514465\n",
      "[Step 10956] Loss: 9.55e+07 -0.10587231814861298 0.3671240508556366\n",
      "[Step 10957] Loss: 9.67e+07 -0.1065734326839447 0.3669053912162781\n",
      "[Step 10958] Loss: 9.62e+07 -0.10710090398788452 0.36671561002731323\n",
      "[Step 10959] Loss: 9.51e+07 -0.10763636231422424 0.36656710505485535\n",
      "[Step 10960] Loss: 9.57e+07 -0.1081443578004837 0.3664383888244629\n",
      "[Step 10961] Loss: 9.61e+07 -0.10853424668312073 0.36631131172180176\n",
      "[Step 10962] Loss: 9.57e+07 -0.10896225273609161 0.36619332432746887\n",
      "[Step 10963] Loss: 9.56e+07 -0.10951592773199081 0.3660447895526886\n",
      "[Step 10964] Loss: 9.54e+07 -0.1099877655506134 0.3658962547779083\n",
      "[Step 10965] Loss: 9.57e+07 -0.11043060570955276 0.3657815754413605\n",
      "[Step 10966] Loss: 9.63e+07 -0.11072957515716553 0.3657015264034271\n",
      "[Step 10967] Loss: 9.66e+07 -0.11108971387147903 0.3656049966812134\n",
      "[Step 10968] Loss: 9.58e+07 -0.11142100393772125 0.36550843715667725\n",
      "[Step 10969] Loss: 9.57e+07 -0.11168071627616882 0.36541685461997986\n",
      "[Step 10970] Loss: 9.57e+07 -0.11185291409492493 0.365385502576828\n",
      "[Step 10971] Loss: 9.56e+07 -0.1120866984128952 0.3653590977191925\n",
      "[Step 10972] Loss: 9.56e+07 -0.11223488301038742 0.3653211295604706\n",
      "[Step 10973] Loss: 9.58e+07 -0.1122022271156311 0.3653310537338257\n",
      "[Step 10974] Loss: 9.57e+07 -0.11217446625232697 0.36531370878219604\n",
      "[Step 10975] Loss: 9.55e+07 -0.11228705942630768 0.3652980327606201\n",
      "[Step 10976] Loss: 9.57e+07 -0.1123613640666008 0.3652675151824951\n",
      "[Step 10977] Loss: 9.61e+07 -0.11235026270151138 0.36526668071746826\n",
      "[Step 10978] Loss: 9.56e+07 -0.11235234141349792 0.3652757704257965\n",
      "[Step 10979] Loss: 9.55e+07 -0.11236946284770966 0.3652741014957428\n",
      "[Step 10980] Loss: 9.54e+07 -0.1123800203204155 0.36526668071746826\n",
      "[Step 10981] Loss: 9.55e+07 -0.11245355755090714 0.36523616313934326\n",
      "[Step 10982] Loss: 9.52e+07 -0.11251983046531677 0.365204781293869\n",
      "[Step 10983] Loss: 9.51e+07 -0.11250635236501694 0.36521387100219727\n",
      "[Step 10984] Loss: 9.54e+07 -0.11247599124908447 0.3652089238166809\n",
      "[Step 10985] Loss: 9.49e+07 -0.11243069916963577 0.36518993973731995\n",
      "[Step 10986] Loss: 9.52e+07 -0.11235973984003067 0.36523038148880005\n",
      "[Step 10987] Loss: 9.59e+07 -0.11235947906970978 0.3652518391609192\n",
      "[Step 10988] Loss: 9.53e+07 -0.11226050555706024 0.3652782440185547\n",
      "[Step 10989] Loss: 9.60e+07 -0.11230640113353729 0.36526668071746826\n",
      "[Step 10990] Loss: 9.55e+07 -0.11222753673791885 0.365246057510376\n",
      "[Step 10991] Loss: 9.60e+07 -0.11202418059110641 0.36529555916786194\n",
      "[Step 10992] Loss: 9.55e+07 -0.1118868738412857 0.3653203248977661\n",
      "[Step 10993] Loss: 9.58e+07 -0.11195819079875946 0.3653211295604706\n",
      "[Step 10994] Loss: 9.49e+07 -0.11195626109838486 0.365332692861557\n",
      "[Step 10995] Loss: 9.52e+07 -0.11184512078762054 0.3653450608253479\n",
      "[Step 10996] Loss: 9.63e+07 -0.11167503148317337 0.36537066102027893\n",
      "[Step 10997] Loss: 9.56e+07 -0.11152023822069168 0.3653698265552521\n",
      "[Step 10998] Loss: 9.49e+07 -0.11144851893186569 0.36538466811180115\n",
      "[Step 10999] Loss: 9.56e+07 -0.11138660460710526 0.3653739392757416\n",
      "[Step 11000] Loss: 9.55e+07 -0.11129076033830643 0.3654003441333771\n",
      "[Step 11001] Loss: 9.54e+07 -0.11128725111484528 0.365385502576828\n",
      "[Step 11002] Loss: 9.60e+07 -0.1114526018500328 0.3653384745121002\n",
      "[Step 11003] Loss: 9.47e+07 -0.11155614256858826 0.3652757704257965\n",
      "[Step 11004] Loss: 9.53e+07 -0.11158120632171631 0.3652501702308655\n",
      "[Step 11005] Loss: 9.59e+07 -0.11166569590568542 0.36521387100219727\n",
      "[Step 11006] Loss: 9.56e+07 -0.11162882298231125 0.3652006685733795\n",
      "[Step 11007] Loss: 9.52e+07 -0.11148899048566818 0.36523863673210144\n",
      "[Step 11008] Loss: 9.50e+07 -0.11132719367742538 0.36525100469589233\n",
      "[Step 11009] Loss: 9.55e+07 -0.11118180304765701 0.3652856647968292\n",
      "[Step 11010] Loss: 9.46e+07 -0.11106468737125397 0.36531537771224976\n",
      "[Step 11011] Loss: 9.57e+07 -0.11102818697690964 0.3653203248977661\n",
      "[Step 11012] Loss: 9.58e+07 -0.11080986261367798 0.36537230014801025\n",
      "[Step 11013] Loss: 9.61e+07 -0.11070187389850616 0.365363210439682\n",
      "[Step 11014] Loss: 9.65e+07 -0.11081413924694061 0.36529308557510376\n",
      "[Step 11015] Loss: 9.59e+07 -0.11089843511581421 0.36528319120407104\n",
      "[Step 11016] Loss: 9.58e+07 -0.11090406775474548 0.3652864694595337\n",
      "[Step 11017] Loss: 9.58e+07 -0.11099037528038025 0.3652336895465851\n",
      "[Step 11018] Loss: 9.65e+07 -0.11095860600471497 0.3652411103248596\n",
      "[Step 11019] Loss: 9.57e+07 -0.11083364486694336 0.36527904868125916\n",
      "[Step 11020] Loss: 9.48e+07 -0.11072269082069397 0.3653120696544647\n",
      "[Step 11021] Loss: 9.60e+07 -0.11076793074607849 0.36533021926879883\n",
      "[Step 11022] Loss: 9.48e+07 -0.11080924421548843 0.3653269112110138\n",
      "[Step 11023] Loss: 9.52e+07 -0.1108950823545456 0.36531537771224976\n",
      "[Step 11024] Loss: 9.56e+07 -0.11091439425945282 0.3653062880039215\n",
      "[Step 11025] Loss: 9.49e+07 -0.11092063784599304 0.3653211295604706\n",
      "[Step 11026] Loss: 9.51e+07 -0.11091051250696182 0.36530134081840515\n",
      "[Step 11027] Loss: 9.42e+07 -0.11089155077934265 0.3652839958667755\n",
      "[Step 11028] Loss: 9.51e+07 -0.11079007387161255 0.3653170168399811\n",
      "[Step 11029] Loss: 9.56e+07 -0.11071818321943283 0.3653203248977661\n",
      "[Step 11030] Loss: 9.63e+07 -0.1107998788356781 0.36526668071746826\n",
      "[Step 11031] Loss: 9.62e+07 -0.11084022372961044 0.3652839958667755\n",
      "[Step 11032] Loss: 9.49e+07 -0.11087594926357269 0.3652839958667755\n",
      "[Step 11033] Loss: 9.58e+07 -0.11087997257709503 0.3652864694595337\n",
      "[Step 11034] Loss: 9.73e+07 -0.11110645532608032 0.36523038148880005\n",
      "[Step 11035] Loss: 9.54e+07 -0.1112438291311264 0.36518746614456177\n",
      "[Step 11036] Loss: 9.50e+07 -0.11139189451932907 0.3651198148727417\n",
      "[Step 11037] Loss: 9.48e+07 -0.1115354374051094 0.3650670051574707\n",
      "[Step 11038] Loss: 9.59e+07 -0.11151739209890366 0.36506205797195435\n",
      "[Step 11039] Loss: 9.54e+07 -0.11141468584537506 0.365068644285202\n",
      "[Step 11040] Loss: 9.48e+07 -0.11134851723909378 0.3650892674922943\n",
      "[Step 11041] Loss: 9.58e+07 -0.11133571714162827 0.36509835720062256\n",
      "[Step 11042] Loss: 9.52e+07 -0.1112644299864769 0.36509421467781067\n",
      "[Step 11043] Loss: 9.50e+07 -0.11119978874921799 0.3651016652584076\n",
      "[Step 11044] Loss: 9.48e+07 -0.11116325110197067 0.3650999963283539\n",
      "[Step 11045] Loss: 9.59e+07 -0.11106588691473007 0.3651057779788971\n",
      "[Step 11046] Loss: 9.52e+07 -0.11086057126522064 0.3651486933231354\n",
      "[Step 11047] Loss: 9.50e+07 -0.11068236082792282 0.36519572138786316\n",
      "[Step 11048] Loss: 9.57e+07 -0.11065427213907242 0.3651866316795349\n",
      "[Step 11049] Loss: 9.53e+07 -0.11056725680828094 0.3652229607105255\n",
      "[Step 11050] Loss: 9.48e+07 -0.11044419556856155 0.36522623896598816\n",
      "[Step 11051] Loss: 9.53e+07 -0.11044450849294662 0.3652031421661377\n",
      "[Step 11052] Loss: 9.56e+07 -0.11048769950866699 0.3651783764362335\n",
      "[Step 11053] Loss: 9.55e+07 -0.11054081469774246 0.36514949798583984\n",
      "[Step 11054] Loss: 9.68e+07 -0.11072489619255066 0.3650834858417511\n",
      "[Step 11055] Loss: 9.50e+07 -0.11089931428432465 0.3650463819503784\n",
      "[Step 11056] Loss: 9.58e+07 -0.1110067069530487 0.36500924825668335\n",
      "[Step 11057] Loss: 9.51e+07 -0.11108032613992691 0.3650084137916565\n",
      "[Step 11058] Loss: 9.49e+07 -0.11110849678516388 0.36501750349998474\n",
      "[Step 11059] Loss: 9.50e+07 -0.11116912961006165 0.3650017976760864\n",
      "[Step 11060] Loss: 9.59e+07 -0.11135271191596985 0.36498942971229553\n",
      "[Step 11061] Loss: 9.66e+07 -0.11168551445007324 0.3648747503757477\n",
      "[Step 11062] Loss: 9.59e+07 -0.11209315806627274 0.3647567331790924\n",
      "[Step 11063] Loss: 9.53e+07 -0.11249122023582458 0.3646494746208191\n",
      "[Step 11064] Loss: 9.53e+07 -0.11292499303817749 0.3645215928554535\n",
      "[Step 11065] Loss: 9.59e+07 -0.11331938207149506 0.3644365966320038\n",
      "[Step 11066] Loss: 9.61e+07 -0.11357953399419785 0.3643714189529419\n",
      "[Step 11067] Loss: 9.57e+07 -0.11377077549695969 0.36432188749313354\n",
      "[Step 11068] Loss: 9.61e+07 -0.11407401412725449 0.36422452330589294\n",
      "[Step 11069] Loss: 9.52e+07 -0.11437764763832092 0.3641098439693451\n",
      "[Step 11070] Loss: 9.54e+07 -0.11456820368766785 0.36407187581062317\n",
      "[Step 11071] Loss: 9.54e+07 -0.11474859714508057 0.36401328444480896\n",
      "[Step 11072] Loss: 9.56e+07 -0.11487811803817749 0.3639901876449585\n",
      "[Step 11073] Loss: 9.52e+07 -0.11490437388420105 0.36396297812461853\n",
      "[Step 11074] Loss: 9.50e+07 -0.11487352102994919 0.36395883560180664\n",
      "[Step 11075] Loss: 9.57e+07 -0.11480429768562317 0.36396709084510803\n",
      "[Step 11076] Loss: 9.51e+07 -0.11474277079105377 0.3639753460884094\n",
      "[Step 11077] Loss: 9.52e+07 -0.11467508226633072 0.3640207350254059\n",
      "[Step 11078] Loss: 9.59e+07 -0.11465118080377579 0.36402568221092224\n",
      "[Step 11079] Loss: 9.49e+07 -0.11473198235034943 0.36396709084510803\n",
      "[Step 11080] Loss: 9.60e+07 -0.11469144374132156 0.3639836013317108\n",
      "[Step 11081] Loss: 9.50e+07 -0.11467204242944717 0.3639802932739258\n",
      "[Step 11082] Loss: 9.57e+07 -0.11465227603912354 0.36399760842323303\n",
      "[Step 11083] Loss: 9.56e+07 -0.1146155446767807 0.36397120356559753\n",
      "[Step 11084] Loss: 9.61e+07 -0.11464916169643402 0.36396047472953796\n",
      "[Step 11085] Loss: 9.56e+07 -0.11470651626586914 0.363963782787323\n",
      "[Step 11086] Loss: 9.57e+07 -0.1148180142045021 0.36392584443092346\n",
      "[Step 11087] Loss: 9.56e+07 -0.11486754566431046 0.3639010787010193\n",
      "[Step 11088] Loss: 9.49e+07 -0.1149214655160904 0.36391016840934753\n",
      "[Step 11089] Loss: 9.60e+07 -0.11495644599199295 0.3639307916164398\n",
      "[Step 11090] Loss: 9.58e+07 -0.11512419581413269 0.36386725306510925\n",
      "[Step 11091] Loss: 9.50e+07 -0.11532168090343475 0.3638317584991455\n",
      "[Step 11092] Loss: 9.53e+07 -0.11553715914487839 0.3637789487838745\n",
      "[Step 11093] Loss: 9.56e+07 -0.11577872931957245 0.36372944712638855\n",
      "[Step 11094] Loss: 9.49e+07 -0.11600884050130844 0.3636675775051117\n",
      "[Step 11095] Loss: 9.55e+07 -0.11629744619131088 0.363582581281662\n",
      "[Step 11096] Loss: 9.54e+07 -0.11653226613998413 0.3635355532169342\n",
      "[Step 11097] Loss: 9.55e+07 -0.11677663028240204 0.36348769068717957\n",
      "[Step 11098] Loss: 9.56e+07 -0.1170373484492302 0.36340269446372986\n",
      "[Step 11099] Loss: 9.51e+07 -0.1173248216509819 0.363349050283432\n",
      "[Step 11100] Loss: 9.56e+07 -0.11771398782730103 0.3632450997829437\n",
      "[Step 11101] Loss: 9.54e+07 -0.11797574907541275 0.36316588521003723\n",
      "[Step 11102] Loss: 9.63e+07 -0.11839482933282852 0.36308255791664124\n",
      "[Step 11103] Loss: 9.51e+07 -0.11870389431715012 0.36301571130752563\n",
      "[Step 11104] Loss: 9.54e+07 -0.11905274540185928 0.36292576789855957\n",
      "[Step 11105] Loss: 9.58e+07 -0.11942955106496811 0.3628152012825012\n",
      "[Step 11106] Loss: 9.54e+07 -0.1197555810213089 0.3626996874809265\n",
      "[Step 11107] Loss: 9.53e+07 -0.12001702189445496 0.3626518249511719\n",
      "[Step 11108] Loss: 9.63e+07 -0.12041065096855164 0.3625049591064453\n",
      "[Step 11109] Loss: 9.59e+07 -0.12086044251918793 0.36238035559654236\n",
      "[Step 11110] Loss: 9.45e+07 -0.12135090678930283 0.36225906014442444\n",
      "[Step 11111] Loss: 9.61e+07 -0.12165676057338715 0.3622029423713684\n",
      "[Step 11112] Loss: 9.54e+07 -0.12202117592096329 0.3621344566345215\n",
      "[Step 11113] Loss: 9.52e+07 -0.12225408852100372 0.36207011342048645\n",
      "[Step 11114] Loss: 9.58e+07 -0.12252247333526611 0.36202389001846313\n",
      "[Step 11115] Loss: 9.59e+07 -0.1227402612566948 0.3619471490383148\n",
      "[Step 11116] Loss: 9.53e+07 -0.12301572412252426 0.36187782883644104\n",
      "[Step 11117] Loss: 9.63e+07 -0.12312755733728409 0.36183658242225647\n",
      "[Step 11118] Loss: 9.54e+07 -0.12318384647369385 0.3618175983428955\n",
      "[Step 11119] Loss: 9.84e+07 -0.12362774461507797 0.3616938292980194\n",
      "[Step 11120] Loss: 9.59e+07 -0.12399966269731522 0.3615981340408325\n",
      "[Step 11121] Loss: 9.52e+07 -0.12433290481567383 0.3615477979183197\n",
      "[Step 11122] Loss: 9.58e+07 -0.12461142241954803 0.3614479601383209\n",
      "[Step 11123] Loss: 9.54e+07 -0.1248241439461708 0.36141908168792725\n",
      "[Step 11124] Loss: 9.62e+07 -0.125159353017807 0.36132335662841797\n",
      "[Step 11125] Loss: 9.61e+07 -0.12556461989879608 0.3612045347690582\n",
      "[Step 11126] Loss: 9.59e+07 -0.12589651346206665 0.3611080050468445\n",
      "[Step 11127] Loss: 9.52e+07 -0.12624458968639374 0.36103126406669617\n",
      "[Step 11128] Loss: 9.60e+07 -0.12655571103096008 0.3609520494937897\n",
      "[Step 11129] Loss: 9.54e+07 -0.12680567800998688 0.36088109016418457\n",
      "[Step 11130] Loss: 9.64e+07 -0.1269078403711319 0.3608769476413727\n",
      "[Step 11131] Loss: 9.59e+07 -0.12689438462257385 0.36087116599082947\n",
      "[Step 11132] Loss: 9.53e+07 -0.12686148285865784 0.3609050214290619\n",
      "[Step 11133] Loss: 9.56e+07 -0.12683330476284027 0.36087942123413086\n",
      "[Step 11134] Loss: 9.59e+07 -0.12681983411312103 0.360870361328125\n",
      "[Step 11135] Loss: 9.53e+07 -0.12675200402736664 0.3608678877353668\n",
      "[Step 11136] Loss: 9.54e+07 -0.12673698365688324 0.3608678877353668\n",
      "[Step 11137] Loss: 9.57e+07 -0.12666520476341248 0.3609050214290619\n",
      "[Step 11138] Loss: 9.71e+07 -0.1267806589603424 0.3608860373497009\n",
      "[Step 11139] Loss: 9.52e+07 -0.12686902284622192 0.36082908511161804\n",
      "[Step 11140] Loss: 9.49e+07 -0.12701793015003204 0.360791951417923\n",
      "[Step 11141] Loss: 9.55e+07 -0.12724243104457855 0.3607564866542816\n",
      "[Step 11142] Loss: 9.60e+07 -0.12731587886810303 0.3607185184955597\n",
      "[Step 11143] Loss: 9.54e+07 -0.12750665843486786 0.3606945872306824\n",
      "[Step 11144] Loss: 9.60e+07 -0.1277584582567215 0.3606269359588623\n",
      "[Step 11145] Loss: 9.61e+07 -0.1280452460050583 0.3605576157569885\n",
      "[Step 11146] Loss: 9.48e+07 -0.1282888650894165 0.3605138957500458\n",
      "[Step 11147] Loss: 9.55e+07 -0.12846915423870087 0.36049407720565796\n",
      "[Step 11148] Loss: 9.69e+07 -0.12878738343715668 0.3604123890399933\n",
      "[Step 11149] Loss: 9.47e+07 -0.1290534883737564 0.36034637689590454\n",
      "[Step 11150] Loss: 9.54e+07 -0.12926407158374786 0.3602457344532013\n",
      "[Step 11151] Loss: 9.44e+07 -0.12946322560310364 0.3602011501789093\n",
      "[Step 11152] Loss: 9.69e+07 -0.12982438504695892 0.3600996732711792\n",
      "[Step 11153] Loss: 9.50e+07 -0.13010163605213165 0.36002376675605774\n",
      "[Step 11154] Loss: 9.50e+07 -0.1303602159023285 0.3599676489830017\n",
      "[Step 11155] Loss: 9.66e+07 -0.13073936104774475 0.35987937450408936\n",
      "[Step 11156] Loss: 9.58e+07 -0.13113677501678467 0.3597910702228546\n",
      "[Step 11157] Loss: 9.60e+07 -0.13156193494796753 0.3596739172935486\n",
      "[Step 11158] Loss: 9.68e+07 -0.13213127851486206 0.35949981212615967\n",
      "[Step 11159] Loss: 9.59e+07 -0.1325782686471939 0.3593900501728058\n",
      "[Step 11160] Loss: 9.59e+07 -0.13288304209709167 0.35928112268447876\n",
      "[Step 11161] Loss: 9.51e+07 -0.1331830769777298 0.3591953217983246\n",
      "[Step 11162] Loss: 9.48e+07 -0.13345131278038025 0.3591177463531494\n",
      "[Step 11163] Loss: 9.52e+07 -0.1336960643529892 0.35905176401138306\n",
      "[Step 11164] Loss: 9.53e+07 -0.13393568992614746 0.35896429419517517\n",
      "[Step 11165] Loss: 9.53e+07 -0.13415294885635376 0.3589189052581787\n",
      "[Step 11166] Loss: 9.55e+07 -0.13434620201587677 0.35883885622024536\n",
      "[Step 11167] Loss: 9.56e+07 -0.13453784584999084 0.35879266262054443\n",
      "[Step 11168] Loss: 9.51e+07 -0.13472753763198853 0.35872912406921387\n",
      "[Step 11169] Loss: 9.50e+07 -0.13489194214344025 0.3586961030960083\n",
      "[Step 11170] Loss: 9.53e+07 -0.1350572109222412 0.35867631435394287\n",
      "[Step 11171] Loss: 9.54e+07 -0.13521572947502136 0.35864660143852234\n",
      "[Step 11172] Loss: 9.57e+07 -0.13533708453178406 0.3586251437664032\n",
      "[Step 11173] Loss: 9.61e+07 -0.13558658957481384 0.35857564210891724\n",
      "[Step 11174] Loss: 9.51e+07 -0.13583971560001373 0.35855087637901306\n",
      "[Step 11175] Loss: 9.50e+07 -0.13608582317829132 0.35849064588546753\n",
      "[Step 11176] Loss: 9.59e+07 -0.13625025749206543 0.35843372344970703\n",
      "[Step 11177] Loss: 9.54e+07 -0.13643908500671387 0.35838422179222107\n",
      "[Step 11178] Loss: 9.60e+07 -0.13675323128700256 0.3583206832408905\n",
      "[Step 11179] Loss: 9.62e+07 -0.1371288001537323 0.358238160610199\n",
      "[Step 11180] Loss: 9.56e+07 -0.13745220005512238 0.35819196701049805\n",
      "[Step 11181] Loss: 9.55e+07 -0.13772983849048615 0.358132541179657\n",
      "[Step 11182] Loss: 9.53e+07 -0.13804224133491516 0.35808220505714417\n",
      "[Step 11183] Loss: 9.69e+07 -0.138508141040802 0.3579378128051758\n",
      "[Step 11184] Loss: 9.54e+07 -0.13889390230178833 0.3578355014324188\n",
      "[Step 11185] Loss: 9.56e+07 -0.13931883871555328 0.35775214433670044\n",
      "[Step 11186] Loss: 9.73e+07 -0.13990706205368042 0.3576349914073944\n",
      "[Step 11187] Loss: 9.56e+07 -0.140425905585289 0.35750049352645874\n",
      "[Step 11188] Loss: 9.52e+07 -0.14085157215595245 0.3573841452598572\n",
      "[Step 11189] Loss: 9.53e+07 -0.14134511351585388 0.3572702705860138\n",
      "[Step 11190] Loss: 9.52e+07 -0.14168384671211243 0.35718199610710144\n",
      "[Step 11191] Loss: 9.56e+07 -0.14201435446739197 0.35709288716316223\n",
      "[Step 11192] Loss: 9.56e+07 -0.1423148512840271 0.3570244014263153\n",
      "[Step 11193] Loss: 9.62e+07 -0.14262418448925018 0.35693278908729553\n",
      "[Step 11194] Loss: 9.59e+07 -0.14292654395103455 0.3568395674228668\n",
      "[Step 11195] Loss: 9.53e+07 -0.14312905073165894 0.35676199197769165\n",
      "[Step 11196] Loss: 9.65e+07 -0.1434931755065918 0.3566662669181824\n",
      "[Step 11197] Loss: 9.55e+07 -0.14372774958610535 0.356608510017395\n",
      "[Step 11198] Loss: 9.50e+07 -0.14391624927520752 0.3565524220466614\n",
      "[Step 11199] Loss: 9.59e+07 -0.14398778975009918 0.35652104020118713\n",
      "[Step 11200] Loss: 9.57e+07 -0.14411842823028564 0.35648804903030396\n",
      "[Step 11201] Loss: 9.56e+07 -0.14416280388832092 0.35647648572921753\n",
      "[Step 11202] Loss: 9.58e+07 -0.14413492381572723 0.35645174980163574\n",
      "[Step 11203] Loss: 9.58e+07 -0.14418268203735352 0.3564426600933075\n",
      "[Step 11204] Loss: 9.56e+07 -0.14428290724754333 0.35644596815109253\n",
      "[Step 11205] Loss: 9.56e+07 -0.14427559077739716 0.35644349455833435\n",
      "[Step 11206] Loss: 9.52e+07 -0.14422011375427246 0.3564443290233612\n",
      "[Step 11207] Loss: 9.50e+07 -0.14418596029281616 0.3564368784427643\n",
      "[Step 11208] Loss: 9.60e+07 -0.14418204128742218 0.35645174980163574\n",
      "[Step 11209] Loss: 9.47e+07 -0.1441585123538971 0.35646411776542664\n",
      "[Step 11210] Loss: 9.54e+07 -0.14416123926639557 0.3565053641796112\n",
      "[Step 11211] Loss: 9.56e+07 -0.14418691396713257 0.35650208592414856\n",
      "[Step 11212] Loss: 9.54e+07 -0.14415733516216278 0.3565037250518799\n",
      "[Step 11213] Loss: 9.59e+07 -0.1442202478647232 0.35647648572921753\n",
      "[Step 11214] Loss: 9.48e+07 -0.1442050337791443 0.35647568106651306\n",
      "[Step 11215] Loss: 9.54e+07 -0.14418886601924896 0.35647153854370117\n",
      "[Step 11216] Loss: 9.55e+07 -0.14424081146717072 0.3564583361148834\n",
      "[Step 11217] Loss: 9.65e+07 -0.1445370763540268 0.35637831687927246\n",
      "[Step 11218] Loss: 9.64e+07 -0.1448950618505478 0.35628342628479004\n",
      "[Step 11219] Loss: 9.50e+07 -0.1452135145664215 0.356205016374588\n",
      "[Step 11220] Loss: 9.56e+07 -0.14559310674667358 0.3561159074306488\n",
      "[Step 11221] Loss: 9.54e+07 -0.14589107036590576 0.35605815052986145\n",
      "[Step 11222] Loss: 9.55e+07 -0.14606241881847382 0.3560408353805542\n",
      "[Step 11223] Loss: 9.51e+07 -0.14619868993759155 0.35603010654449463\n",
      "[Step 11224] Loss: 9.60e+07 -0.14619995653629303 0.35605403780937195\n",
      "[Step 11225] Loss: 9.55e+07 -0.14609059691429138 0.35605815052986145\n",
      "[Step 11226] Loss: 9.59e+07 -0.14592459797859192 0.35609281063079834\n",
      "[Step 11227] Loss: 9.58e+07 -0.1457328498363495 0.35612910985946655\n",
      "[Step 11228] Loss: 9.55e+07 -0.14556409418582916 0.35619595646858215\n",
      "[Step 11229] Loss: 9.54e+07 -0.1454293578863144 0.3562116324901581\n",
      "[Step 11230] Loss: 9.83e+07 -0.14566147327423096 0.3561910092830658\n",
      "[Step 11231] Loss: 9.60e+07 -0.14584672451019287 0.356143981218338\n",
      "[Step 11232] Loss: 9.58e+07 -0.14595019817352295 0.3561175763607025\n",
      "[Step 11233] Loss: 9.65e+07 -0.14624105393886566 0.3560325801372528\n",
      "[Step 11234] Loss: 9.54e+07 -0.14652179181575775 0.3559739887714386\n",
      "[Step 11235] Loss: 9.61e+07 -0.14665654301643372 0.35591623187065125\n",
      "[Step 11236] Loss: 9.59e+07 -0.14671690762043 0.3559005558490753\n",
      "[Step 11237] Loss: 9.54e+07 -0.14677214622497559 0.3558667302131653\n",
      "[Step 11238] Loss: 9.55e+07 -0.14694152772426605 0.35583701729774475\n",
      "[Step 11239] Loss: 9.59e+07 -0.1470518559217453 0.35583290457725525\n",
      "[Step 11240] Loss: 9.48e+07 -0.14715193212032318 0.355823814868927\n",
      "[Step 11241] Loss: 9.58e+07 -0.14733996987342834 0.35578009486198425\n",
      "[Step 11242] Loss: 9.53e+07 -0.14757798612117767 0.35571983456611633\n",
      "[Step 11243] Loss: 9.63e+07 -0.14778879284858704 0.355643093585968\n",
      "[Step 11244] Loss: 9.54e+07 -0.1480332612991333 0.3555968999862671\n",
      "[Step 11245] Loss: 9.62e+07 -0.14830529689788818 0.3555135726928711\n",
      "[Step 11246] Loss: 9.57e+07 -0.14843302965164185 0.35546818375587463\n",
      "[Step 11247] Loss: 9.55e+07 -0.14859385788440704 0.35544341802597046\n",
      "[Step 11248] Loss: 9.51e+07 -0.14872251451015472 0.3553939163684845\n",
      "[Step 11249] Loss: 9.57e+07 -0.14874252676963806 0.35536009073257446\n",
      "[Step 11250] Loss: 9.71e+07 -0.14896699786186218 0.35532212257385254\n",
      "[Step 11251] Loss: 9.50e+07 -0.14912541210651398 0.3552536368370056\n",
      "[Step 11252] Loss: 9.78e+07 -0.14959710836410522 0.35512575507164\n",
      "[Step 11253] Loss: 9.55e+07 -0.15004467964172363 0.3550226092338562\n",
      "[Step 11254] Loss: 9.59e+07 -0.15050195157527924 0.3548905849456787\n",
      "[Step 11255] Loss: 9.55e+07 -0.15094096958637238 0.3547849655151367\n",
      "[Step 11256] Loss: 9.56e+07 -0.15133003890514374 0.35471564531326294\n",
      "[Step 11257] Loss: 9.67e+07 -0.15184031426906586 0.3545927107334137\n",
      "[Step 11258] Loss: 9.57e+07 -0.15233905613422394 0.3545242249965668\n",
      "[Step 11259] Loss: 9.60e+07 -0.1528707891702652 0.35437899827957153\n",
      "[Step 11260] Loss: 9.56e+07 -0.15337377786636353 0.3542115092277527\n",
      "[Step 11261] Loss: 9.62e+07 -0.15395689010620117 0.3540951609611511\n",
      "[Step 11262] Loss: 9.51e+07 -0.154576376080513 0.35397303104400635\n",
      "[Step 11263] Loss: 9.57e+07 -0.15522828698158264 0.35380470752716064\n",
      "[Step 11264] Loss: 9.47e+07 -0.1558523029088974 0.3536660671234131\n",
      "[Step 11265] Loss: 9.56e+07 -0.15638145804405212 0.35358357429504395\n",
      "[Step 11266] Loss: 9.61e+07 -0.15700750052928925 0.3534564971923828\n",
      "[Step 11267] Loss: 9.54e+07 -0.15766796469688416 0.35328981280326843\n",
      "[Step 11268] Loss: 9.56e+07 -0.15831243991851807 0.35314542055130005\n",
      "[Step 11269] Loss: 9.54e+07 -0.15888136625289917 0.353005975484848\n",
      "[Step 11270] Loss: 9.63e+07 -0.1595756858587265 0.35283929109573364\n",
      "[Step 11271] Loss: 9.56e+07 -0.1601320058107376 0.35265859961509705\n",
      "[Step 11272] Loss: 9.52e+07 -0.16070392727851868 0.35252904891967773\n",
      "[Step 11273] Loss: 9.63e+07 -0.16140078008174896 0.35232439637184143\n",
      "[Step 11274] Loss: 9.48e+07 -0.16199003159999847 0.35220807790756226\n",
      "[Step 11275] Loss: 9.58e+07 -0.16249148547649384 0.35209500789642334\n",
      "[Step 11276] Loss: 9.62e+07 -0.1630503088235855 0.3519456684589386\n",
      "[Step 11277] Loss: 9.54e+07 -0.16366098821163177 0.3518078625202179\n",
      "[Step 11278] Loss: 9.55e+07 -0.1641387790441513 0.3516981303691864\n",
      "[Step 11279] Loss: 9.64e+07 -0.16469822824001312 0.35157105326652527\n",
      "[Step 11280] Loss: 9.60e+07 -0.1650736778974533 0.3514654338359833\n",
      "[Step 11281] Loss: 9.50e+07 -0.16537407040596008 0.35139116644859314\n",
      "[Step 11282] Loss: 9.57e+07 -0.16572272777557373 0.35130372643470764\n",
      "[Step 11283] Loss: 9.58e+07 -0.16604037582874298 0.351203054189682\n",
      "[Step 11284] Loss: 9.48e+07 -0.16639475524425507 0.3511428236961365\n",
      "[Step 11285] Loss: 9.53e+07 -0.16672371327877045 0.3510272800922394\n",
      "[Step 11286] Loss: 9.56e+07 -0.16693250834941864 0.35097119212150574\n",
      "[Step 11287] Loss: 9.59e+07 -0.16726291179656982 0.35089030861854553\n",
      "[Step 11288] Loss: 9.51e+07 -0.16756819188594818 0.3508177101612091\n",
      "[Step 11289] Loss: 9.47e+07 -0.16777169704437256 0.35075169801712036\n",
      "[Step 11290] Loss: 9.59e+07 -0.16792114078998566 0.35071703791618347\n",
      "[Step 11291] Loss: 9.62e+07 -0.16799934208393097 0.3506840467453003\n",
      "[Step 11292] Loss: 9.50e+07 -0.16802333295345306 0.3506774306297302\n",
      "[Step 11293] Loss: 9.64e+07 -0.16817721724510193 0.35064277052879333\n",
      "[Step 11294] Loss: 9.50e+07 -0.16838757693767548 0.35059162974357605\n",
      "[Step 11295] Loss: 9.56e+07 -0.16862298548221588 0.3505231440067291\n",
      "[Step 11296] Loss: 9.57e+07 -0.16881296038627625 0.3504851758480072\n",
      "[Step 11297] Loss: 9.56e+07 -0.16903255879878998 0.350426584482193\n",
      "[Step 11298] Loss: 9.56e+07 -0.16919326782226562 0.3503878116607666\n",
      "[Step 11299] Loss: 9.58e+07 -0.16925719380378723 0.350373774766922\n",
      "[Step 11300] Loss: 9.53e+07 -0.1692756563425064 0.3503679931163788\n",
      "[Step 11301] Loss: 9.50e+07 -0.16927680373191833 0.3503762483596802\n",
      "[Step 11302] Loss: 9.53e+07 -0.16920986771583557 0.35040101408958435\n",
      "[Step 11303] Loss: 9.50e+07 -0.16905976831912994 0.3504018485546112\n",
      "[Step 11304] Loss: 9.52e+07 -0.16890670359134674 0.35043731331825256\n",
      "[Step 11305] Loss: 9.57e+07 -0.1687411069869995 0.35047444701194763\n",
      "[Step 11306] Loss: 9.53e+07 -0.16853806376457214 0.35053882002830505\n",
      "[Step 11307] Loss: 9.49e+07 -0.16839730739593506 0.35058584809303284\n",
      "[Step 11308] Loss: 9.55e+07 -0.16813983023166656 0.3506633937358856\n",
      "[Step 11309] Loss: 9.51e+07 -0.16784384846687317 0.35072776675224304\n",
      "[Step 11310] Loss: 9.52e+07 -0.16768263280391693 0.35074591636657715\n",
      "[Step 11311] Loss: 9.55e+07 -0.16749180853366852 0.3507814109325409\n",
      "[Step 11312] Loss: 9.59e+07 -0.167223259806633 0.3508242964744568\n",
      "[Step 11313] Loss: 9.50e+07 -0.16705405712127686 0.35085567831993103\n",
      "[Step 11314] Loss: 9.57e+07 -0.16691936552524567 0.3508845567703247\n",
      "[Step 11315] Loss: 9.47e+07 -0.16691835224628448 0.350905179977417\n",
      "[Step 11316] Loss: 9.55e+07 -0.16681146621704102 0.3509249687194824\n",
      "[Step 11317] Loss: 9.51e+07 -0.16669367253780365 0.3509472608566284\n",
      "[Step 11318] Loss: 9.64e+07 -0.16673244535923004 0.3509439527988434\n",
      "[Step 11319] Loss: 9.52e+07 -0.16673831641674042 0.3509299159049988\n",
      "[Step 11320] Loss: 9.53e+07 -0.16677172482013702 0.3509258031845093\n",
      "[Step 11321] Loss: 9.46e+07 -0.16678860783576965 0.35091012716293335\n",
      "[Step 11322] Loss: 9.51e+07 -0.16671299934387207 0.3509208559989929\n",
      "[Step 11323] Loss: 9.45e+07 -0.16661062836647034 0.35093817114830017\n",
      "[Step 11324] Loss: 9.56e+07 -0.16662459075450897 0.3509439527988434\n",
      "[Step 11325] Loss: 9.55e+07 -0.1667749136686325 0.35090765357017517\n",
      "[Step 11326] Loss: 9.57e+07 -0.16688761115074158 0.35085153579711914\n",
      "[Step 11327] Loss: 9.58e+07 -0.16700035333633423 0.35082265734672546\n",
      "[Step 11328] Loss: 9.54e+07 -0.16718178987503052 0.35074013471603394\n",
      "[Step 11329] Loss: 9.59e+07 -0.1672898381948471 0.3506922721862793\n",
      "[Step 11330] Loss: 9.52e+07 -0.1673518568277359 0.3506436049938202\n",
      "[Step 11331] Loss: 9.57e+07 -0.16744068264961243 0.3506147265434265\n",
      "[Step 11332] Loss: 9.61e+07 -0.16765965521335602 0.350554496049881\n",
      "[Step 11333] Loss: 9.49e+07 -0.16789273917675018 0.3504769206047058\n",
      "[Step 11334] Loss: 9.49e+07 -0.1681632548570633 0.3504059612751007\n",
      "[Step 11335] Loss: 9.61e+07 -0.16833098232746124 0.35035645961761475\n",
      "[Step 11336] Loss: 9.63e+07 -0.1685245782136917 0.35029375553131104\n",
      "[Step 11337] Loss: 9.50e+07 -0.16870394349098206 0.3502524793148041\n",
      "[Step 11338] Loss: 9.61e+07 -0.1687687486410141 0.35021039843559265\n",
      "[Step 11339] Loss: 9.45e+07 -0.16885556280612946 0.3501774072647095\n",
      "[Step 11340] Loss: 9.54e+07 -0.16885359585285187 0.3501955568790436\n",
      "[Step 11341] Loss: 9.48e+07 -0.16885146498680115 0.35018235445022583\n",
      "[Step 11342] Loss: 9.51e+07 -0.16880708932876587 0.3501873016357422\n",
      "[Step 11343] Loss: 9.50e+07 -0.16880880296230316 0.35018566250801086\n",
      "[Step 11344] Loss: 9.60e+07 -0.1686374992132187 0.35023269057273865\n",
      "[Step 11345] Loss: 9.57e+07 -0.16845615208148956 0.35028383135795593\n",
      "[Step 11346] Loss: 9.51e+07 -0.16824454069137573 0.3503457307815552\n",
      "[Step 11347] Loss: 9.60e+07 -0.16806913912296295 0.3504059612751007\n",
      "[Step 11348] Loss: 9.48e+07 -0.16789691150188446 0.35043978691101074\n",
      "[Step 11349] Loss: 9.52e+07 -0.16773124039173126 0.35048601031303406\n",
      "[Step 11350] Loss: 9.62e+07 -0.1674705445766449 0.35053715109825134\n",
      "[Step 11351] Loss: 9.55e+07 -0.16713722050189972 0.3506270945072174\n",
      "[Step 11352] Loss: 9.54e+07 -0.1668902486562729 0.3507162034511566\n",
      "[Step 11353] Loss: 9.58e+07 -0.16676267981529236 0.35077232122421265\n",
      "[Step 11354] Loss: 9.60e+07 -0.1667252480983734 0.35076573491096497\n",
      "[Step 11355] Loss: 9.58e+07 -0.1667403280735016 0.3507797420024872\n",
      "[Step 11356] Loss: 9.49e+07 -0.16677643358707428 0.3507797420024872\n",
      "[Step 11357] Loss: 9.53e+07 -0.16677968204021454 0.35080286860466003\n",
      "[Step 11358] Loss: 9.58e+07 -0.16678039729595184 0.35087794065475464\n",
      "[Step 11359] Loss: 9.61e+07 -0.1669611930847168 0.3508424758911133\n",
      "[Step 11360] Loss: 9.48e+07 -0.16704042255878448 0.35086143016815186\n",
      "[Step 11361] Loss: 9.59e+07 -0.16721253097057343 0.35082513093948364\n",
      "[Step 11362] Loss: 9.53e+07 -0.1673097461462021 0.3507747948169708\n",
      "[Step 11363] Loss: 9.59e+07 -0.16734902560710907 0.3507649004459381\n",
      "[Step 11364] Loss: 9.66e+07 -0.16727718710899353 0.35078468918800354\n",
      "[Step 11365] Loss: 9.58e+07 -0.16711848974227905 0.35084494948387146\n",
      "[Step 11366] Loss: 9.57e+07 -0.166879341006279 0.3508952558040619\n",
      "[Step 11367] Loss: 9.51e+07 -0.16659986972808838 0.35100501775741577\n",
      "[Step 11368] Loss: 9.57e+07 -0.16629517078399658 0.3510594666004181\n",
      "[Step 11369] Loss: 9.59e+07 -0.16616763174533844 0.3511205315589905\n",
      "[Step 11370] Loss: 9.61e+07 -0.16609761118888855 0.3511428236961365\n",
      "[Step 11371] Loss: 9.76e+07 -0.16626353561878204 0.35111722350120544\n",
      "[Step 11372] Loss: 9.53e+07 -0.1663280874490738 0.3511337339878082\n",
      "[Step 11373] Loss: 9.51e+07 -0.16649241745471954 0.3510957658290863\n",
      "[Step 11374] Loss: 9.51e+07 -0.16656845808029175 0.35107845067977905\n",
      "[Step 11375] Loss: 9.51e+07 -0.166716068983078 0.35105615854263306\n",
      "[Step 11376] Loss: 9.52e+07 -0.16683655977249146 0.35100334882736206\n",
      "[Step 11377] Loss: 9.56e+07 -0.16698017716407776 0.350935697555542\n",
      "[Step 11378] Loss: 9.51e+07 -0.16702520847320557 0.3509134352207184\n",
      "[Step 11379] Loss: 9.55e+07 -0.16714206337928772 0.35089609026908875\n",
      "[Step 11380] Loss: 9.51e+07 -0.16734524071216583 0.3508721590042114\n",
      "[Step 11381] Loss: 9.58e+07 -0.16757172346115112 0.35080286860466003\n",
      "[Step 11382] Loss: 9.62e+07 -0.1678996980190277 0.35072198510169983\n",
      "[Step 11383] Loss: 9.59e+07 -0.16813325881958008 0.3506576418876648\n",
      "[Step 11384] Loss: 9.58e+07 -0.16827622056007385 0.35060977935791016\n",
      "[Step 11385] Loss: 9.65e+07 -0.16856315732002258 0.3505478799343109\n",
      "[Step 11386] Loss: 9.57e+07 -0.16888602077960968 0.3504628837108612\n",
      "[Step 11387] Loss: 9.53e+07 -0.16915032267570496 0.3504199981689453\n",
      "[Step 11388] Loss: 9.52e+07 -0.1693761795759201 0.35034820437431335\n",
      "[Step 11389] Loss: 9.57e+07 -0.16960589587688446 0.3503184914588928\n",
      "[Step 11390] Loss: 9.51e+07 -0.1698574423789978 0.35024920105934143\n",
      "[Step 11391] Loss: 9.62e+07 -0.17000457644462585 0.35023102164268494\n",
      "[Step 11392] Loss: 9.58e+07 -0.17017614841461182 0.3501707911491394\n",
      "[Step 11393] Loss: 9.54e+07 -0.1702815443277359 0.3501237630844116\n",
      "[Step 11394] Loss: 9.50e+07 -0.17042210698127747 0.35007011890411377\n",
      "[Step 11395] Loss: 9.56e+07 -0.17054399847984314 0.3500445485115051\n",
      "[Step 11396] Loss: 9.65e+07 -0.1707763522863388 0.3499966859817505\n",
      "[Step 11397] Loss: 9.54e+07 -0.17099423706531525 0.34993812441825867\n",
      "[Step 11398] Loss: 9.50e+07 -0.1711559146642685 0.349864661693573\n",
      "[Step 11399] Loss: 9.51e+07 -0.17138834297657013 0.3498234152793884\n",
      "[Step 11400] Loss: 9.58e+07 -0.17162686586380005 0.3497829735279083\n",
      "[Step 11401] Loss: 9.54e+07 -0.17189979553222656 0.3496839702129364\n",
      "[Step 11402] Loss: 9.53e+07 -0.17213347554206848 0.3496072292327881\n",
      "[Step 11403] Loss: 9.59e+07 -0.17235518991947174 0.34953543543815613\n",
      "[Step 11404] Loss: 9.54e+07 -0.1725156605243683 0.3494735658168793\n",
      "[Step 11405] Loss: 9.55e+07 -0.17266105115413666 0.3494166135787964\n",
      "[Step 11406] Loss: 9.61e+07 -0.1727413684129715 0.3493918776512146\n",
      "[Step 11407] Loss: 9.52e+07 -0.17282386124134064 0.34937041997909546\n",
      "[Step 11408] Loss: 9.58e+07 -0.17302660644054413 0.3493365943431854\n",
      "[Step 11409] Loss: 9.52e+07 -0.17324307560920715 0.3492681086063385\n",
      "[Step 11410] Loss: 9.58e+07 -0.17355018854141235 0.3492152988910675\n",
      "[Step 11411] Loss: 9.55e+07 -0.17376376688480377 0.3491773307323456\n",
      "[Step 11412] Loss: 9.55e+07 -0.17391186952590942 0.3491567075252533\n",
      "[Step 11413] Loss: 9.46e+07 -0.17410069704055786 0.3491038978099823\n",
      "[Step 11414] Loss: 9.60e+07 -0.17417672276496887 0.34908822178840637\n",
      "[Step 11415] Loss: 9.59e+07 -0.17438821494579315 0.34904199838638306\n",
      "[Step 11416] Loss: 9.59e+07 -0.17458757758140564 0.34899085760116577\n",
      "[Step 11417] Loss: 9.55e+07 -0.17476886510849 0.3489537239074707\n",
      "[Step 11418] Loss: 9.53e+07 -0.1748960316181183 0.34894877672195435\n",
      "[Step 11419] Loss: 9.58e+07 -0.17510299384593964 0.3488992750644684\n",
      "[Step 11420] Loss: 9.50e+07 -0.17532970011234283 0.3488827645778656\n",
      "[Step 11421] Loss: 9.75e+07 -0.1757737696170807 0.3488019108772278\n",
      "[Step 11422] Loss: 9.64e+07 -0.17632098495960236 0.3486938178539276\n",
      "[Step 11423] Loss: 9.58e+07 -0.1767776608467102 0.34859147667884827\n",
      "[Step 11424] Loss: 9.61e+07 -0.1772574782371521 0.3484767973423004\n",
      "[Step 11425] Loss: 9.61e+07 -0.17781253159046173 0.3483249545097351\n",
      "[Step 11426] Loss: 9.55e+07 -0.1783129721879959 0.3482441008090973\n",
      "[Step 11427] Loss: 9.57e+07 -0.1788094937801361 0.34812116622924805\n",
      "[Step 11428] Loss: 9.58e+07 -0.17912836372852325 0.34805184602737427\n",
      "[Step 11429] Loss: 9.52e+07 -0.17945680022239685 0.34793633222579956\n",
      "[Step 11430] Loss: 9.59e+07 -0.17978568375110626 0.347872793674469\n",
      "[Step 11431] Loss: 9.58e+07 -0.18000304698944092 0.3478323519229889\n",
      "[Step 11432] Loss: 9.54e+07 -0.18010155856609344 0.34782660007476807\n",
      "[Step 11433] Loss: 9.66e+07 -0.18033094704151154 0.3477630615234375\n",
      "[Step 11434] Loss: 9.58e+07 -0.18059852719306946 0.3476541340351105\n",
      "[Step 11435] Loss: 9.55e+07 -0.18089111149311066 0.34758150577545166\n",
      "[Step 11436] Loss: 9.53e+07 -0.18118685483932495 0.3475179970264435\n",
      "[Step 11437] Loss: 9.59e+07 -0.18139220774173737 0.34749653935432434\n",
      "[Step 11438] Loss: 9.57e+07 -0.18145950138568878 0.3474808633327484\n",
      "[Step 11439] Loss: 9.58e+07 -0.18147191405296326 0.3474263846874237\n",
      "[Step 11440] Loss: 9.63e+07 -0.18158480525016785 0.3473876118659973\n",
      "[Step 11441] Loss: 9.59e+07 -0.18167904019355774 0.34736037254333496\n",
      "[Step 11442] Loss: 9.50e+07 -0.18181079626083374 0.3473273813724518\n",
      "[Step 11443] Loss: 9.44e+07 -0.18187429010868073 0.34732159972190857\n",
      "[Step 11444] Loss: 9.48e+07 -0.18196411430835724 0.3472927212715149\n",
      "[Step 11445] Loss: 9.51e+07 -0.18206031620502472 0.3472440540790558\n",
      "[Step 11446] Loss: 9.53e+07 -0.18203428387641907 0.347280353307724\n",
      "[Step 11447] Loss: 9.51e+07 -0.18193835020065308 0.3472902476787567\n",
      "[Step 11448] Loss: 9.52e+07 -0.18175789713859558 0.3473273813724518\n",
      "[Step 11449] Loss: 9.50e+07 -0.18153686821460724 0.3473471701145172\n",
      "[Step 11450] Loss: 9.60e+07 -0.18122053146362305 0.34745609760284424\n",
      "[Step 11451] Loss: 9.51e+07 -0.1809055209159851 0.34751302003860474\n",
      "[Step 11452] Loss: 9.50e+07 -0.18072494864463806 0.347578227519989\n",
      "[Step 11453] Loss: 9.59e+07 -0.18043547868728638 0.34765002131462097\n",
      "[Step 11454] Loss: 9.54e+07 -0.18022753298282623 0.3476945757865906\n",
      "[Step 11455] Loss: 9.52e+07 -0.18007807433605194 0.34772178530693054\n",
      "[Step 11456] Loss: 9.49e+07 -0.1798824816942215 0.3477787375450134\n",
      "[Step 11457] Loss: 9.54e+07 -0.1795690953731537 0.3478628993034363\n",
      "[Step 11458] Loss: 9.43e+07 -0.17929542064666748 0.3479313850402832\n",
      "[Step 11459] Loss: 9.60e+07 -0.17893441021442413 0.34805184602737427\n",
      "[Step 11460] Loss: 9.49e+07 -0.17861466109752655 0.3481582999229431\n",
      "[Step 11461] Loss: 9.62e+07 -0.1783025711774826 0.34821605682373047\n",
      "[Step 11462] Loss: 9.57e+07 -0.1781359612941742 0.3482903242111206\n",
      "[Step 11463] Loss: 9.66e+07 -0.17811115086078644 0.3483167290687561\n",
      "[Step 11464] Loss: 9.56e+07 -0.17798785865306854 0.34833404421806335\n",
      "[Step 11465] Loss: 9.54e+07 -0.1778765320777893 0.3483711779117584\n",
      "[Step 11466] Loss: 9.59e+07 -0.1777331382036209 0.34841984510421753\n",
      "[Step 11467] Loss: 9.50e+07 -0.17765356600284576 0.3484264612197876\n",
      "[Step 11468] Loss: 9.53e+07 -0.1775476336479187 0.348446249961853\n",
      "[Step 11469] Loss: 9.51e+07 -0.17739975452423096 0.34848669171333313\n",
      "[Step 11470] Loss: 9.48e+07 -0.17720486223697662 0.34853455424308777\n",
      "[Step 11471] Loss: 9.57e+07 -0.17693115770816803 0.3486005663871765\n",
      "[Step 11472] Loss: 9.51e+07 -0.17670857906341553 0.34865832328796387\n",
      "[Step 11473] Loss: 9.55e+07 -0.17632056772708893 0.3487672507762909\n",
      "[Step 11474] Loss: 9.54e+07 -0.17605926096439362 0.34883078932762146\n",
      "[Step 11475] Loss: 9.53e+07 -0.17579448223114014 0.34890833497047424\n",
      "[Step 11476] Loss: 9.49e+07 -0.17558184266090393 0.34897929430007935\n",
      "[Step 11477] Loss: 9.57e+07 -0.1754438579082489 0.3490205705165863\n",
      "[Step 11478] Loss: 9.53e+07 -0.17530277371406555 0.3490445017814636\n",
      "[Step 11479] Loss: 9.51e+07 -0.17508620023727417 0.34912121295928955\n",
      "[Step 11480] Loss: 9.59e+07 -0.1748259961605072 0.3492012619972229\n",
      "[Step 11481] Loss: 9.52e+07 -0.1745954155921936 0.34923675656318665\n",
      "[Step 11482] Loss: 9.57e+07 -0.1743149310350418 0.3492920398712158\n",
      "[Step 11483] Loss: 9.49e+07 -0.17410913109779358 0.34935227036476135\n",
      "[Step 11484] Loss: 9.57e+07 -0.1738206148147583 0.3493984639644623\n",
      "[Step 11485] Loss: 9.62e+07 -0.1736813336610794 0.349430650472641\n",
      "[Step 11486] Loss: 9.50e+07 -0.17356321215629578 0.3494793474674225\n",
      "[Step 11487] Loss: 9.61e+07 -0.17328621447086334 0.3495577275753021\n",
      "[Step 11488] Loss: 9.59e+07 -0.17293012142181396 0.34968313574790955\n",
      "[Step 11489] Loss: 9.63e+07 -0.17271436750888824 0.34975987672805786\n",
      "[Step 11490] Loss: 9.48e+07 -0.17255200445652008 0.3498061001300812\n",
      "[Step 11491] Loss: 9.53e+07 -0.1724296659231186 0.3498457074165344\n",
      "[Step 11492] Loss: 9.56e+07 -0.17231276631355286 0.34986549615859985\n",
      "[Step 11493] Loss: 9.58e+07 -0.17206524312496185 0.34993645548820496\n",
      "[Step 11494] Loss: 9.51e+07 -0.17177408933639526 0.3500008285045624\n",
      "[Step 11495] Loss: 9.60e+07 -0.17160236835479736 0.35008084774017334\n",
      "[Step 11496] Loss: 9.48e+07 -0.17145191133022308 0.35011303424835205\n",
      "[Step 11497] Loss: 9.61e+07 -0.17123404145240784 0.3501377999782562\n",
      "[Step 11498] Loss: 9.51e+07 -0.17106512188911438 0.3501608967781067\n",
      "[Step 11499] Loss: 9.55e+07 -0.17094668745994568 0.3502095937728882\n",
      "[Step 11500] Loss: 9.56e+07 -0.1709400713443756 0.35021039843559265\n",
      "[Step 11501] Loss: 9.55e+07 -0.1710176318883896 0.35021865367889404\n",
      "[Step 11502] Loss: 9.56e+07 -0.1710641235113144 0.3502054512500763\n",
      "[Step 11503] Loss: 9.55e+07 -0.1710965782403946 0.3501666784286499\n",
      "[Step 11504] Loss: 9.62e+07 -0.17128047347068787 0.3501262366771698\n",
      "[Step 11505] Loss: 9.59e+07 -0.1713256984949112 0.3501056134700775\n",
      "[Step 11506] Loss: 9.52e+07 -0.17128030955791473 0.3501237630844116\n",
      "[Step 11507] Loss: 9.53e+07 -0.17128081619739532 0.35011550784111023\n",
      "[Step 11508] Loss: 9.54e+07 -0.17133799195289612 0.35008084774017334\n",
      "[Step 11509] Loss: 9.57e+07 -0.1713862270116806 0.35008662939071655\n",
      "[Step 11510] Loss: 9.52e+07 -0.17137761414051056 0.3501245975494385\n",
      "[Step 11511] Loss: 9.48e+07 -0.17139822244644165 0.3501039743423462\n",
      "[Step 11512] Loss: 9.57e+07 -0.17148008942604065 0.35011717677116394\n",
      "[Step 11513] Loss: 9.49e+07 -0.17150986194610596 0.35012707114219666\n",
      "[Step 11514] Loss: 9.55e+07 -0.1715248078107834 0.3501377999782562\n",
      "[Step 11515] Loss: 9.53e+07 -0.17154397070407867 0.35014769434928894\n",
      "[Step 11516] Loss: 9.56e+07 -0.1715242564678192 0.3501608967781067\n",
      "[Step 11517] Loss: 9.57e+07 -0.17161326110363007 0.35013118386268616\n",
      "[Step 11518] Loss: 9.55e+07 -0.17168572545051575 0.350109726190567\n",
      "[Step 11519] Loss: 9.48e+07 -0.17174945771694183 0.35009652376174927\n",
      "[Step 11520] Loss: 9.55e+07 -0.171833798289299 0.35009077191352844\n",
      "[Step 11521] Loss: 9.58e+07 -0.17195086181163788 0.35008004307746887\n",
      "[Step 11522] Loss: 9.54e+07 -0.1720513552427292 0.3500668406486511\n",
      "[Step 11523] Loss: 9.56e+07 -0.17230108380317688 0.350026398897171\n",
      "[Step 11524] Loss: 9.72e+07 -0.17279231548309326 0.34988778829574585\n",
      "[Step 11525] Loss: 9.55e+07 -0.17317526042461395 0.3498052656650543\n",
      "[Step 11526] Loss: 9.50e+07 -0.1735592484474182 0.34971532225608826\n",
      "[Step 11527] Loss: 9.59e+07 -0.1737866848707199 0.3496897518634796\n",
      "[Step 11528] Loss: 9.57e+07 -0.1738710254430771 0.34967902302742004\n",
      "[Step 11529] Loss: 9.62e+07 -0.17403806746006012 0.34963446855545044\n",
      "[Step 11530] Loss: 9.56e+07 -0.17435874044895172 0.3495684564113617\n",
      "[Step 11531] Loss: 9.54e+07 -0.17463484406471252 0.34951233863830566\n",
      "[Step 11532] Loss: 9.53e+07 -0.1748557984828949 0.34947025775909424\n",
      "[Step 11533] Loss: 9.52e+07 -0.17496705055236816 0.3494512736797333\n",
      "[Step 11534] Loss: 9.57e+07 -0.17507214844226837 0.34942981600761414\n",
      "[Step 11535] Loss: 9.52e+07 -0.17517665028572083 0.3494100272655487\n",
      "[Step 11536] Loss: 9.56e+07 -0.17528003454208374 0.34936878085136414\n",
      "[Step 11537] Loss: 9.59e+07 -0.17551083862781525 0.34932833909988403\n",
      "[Step 11538] Loss: 9.53e+07 -0.17566397786140442 0.3492845892906189\n",
      "[Step 11539] Loss: 9.58e+07 -0.17569589614868164 0.34926149249076843\n",
      "[Step 11540] Loss: 9.50e+07 -0.17570866644382477 0.34924086928367615\n",
      "[Step 11541] Loss: 9.58e+07 -0.17558303475379944 0.34926149249076843\n",
      "[Step 11542] Loss: 9.69e+07 -0.17565245926380157 0.3492433428764343\n",
      "[Step 11543] Loss: 9.58e+07 -0.17572063207626343 0.3492359220981598\n",
      "[Step 11544] Loss: 9.56e+07 -0.17569801211357117 0.3492152988910675\n",
      "[Step 11545] Loss: 9.59e+07 -0.17553256452083588 0.3492359220981598\n",
      "[Step 11546] Loss: 9.60e+07 -0.17553751170635223 0.34924250841140747\n",
      "[Step 11547] Loss: 9.49e+07 -0.1754879653453827 0.3492499589920044\n",
      "[Step 11548] Loss: 9.46e+07 -0.1754758656024933 0.3492177724838257\n",
      "[Step 11549] Loss: 9.60e+07 -0.17562079429626465 0.34920209646224976\n",
      "[Step 11550] Loss: 9.57e+07 -0.17582882940769196 0.3491764962673187\n",
      "[Step 11551] Loss: 9.53e+07 -0.17607218027114868 0.34911131858825684\n",
      "[Step 11552] Loss: 9.60e+07 -0.1763892024755478 0.34904778003692627\n",
      "[Step 11553] Loss: 9.42e+07 -0.17674720287322998 0.34899333119392395\n",
      "[Step 11554] Loss: 9.53e+07 -0.17715303599834442 0.34890174865722656\n",
      "[Step 11555] Loss: 9.47e+07 -0.17754006385803223 0.3488423228263855\n",
      "[Step 11556] Loss: 9.62e+07 -0.17806978523731232 0.34873342514038086\n",
      "[Step 11557] Loss: 9.54e+07 -0.17863111197948456 0.34858405590057373\n",
      "[Step 11558] Loss: 9.52e+07 -0.17914830148220062 0.34844544529914856\n",
      "[Step 11559] Loss: 9.55e+07 -0.17959798872470856 0.3483488857746124\n",
      "[Step 11560] Loss: 9.59e+07 -0.17992496490478516 0.34825897216796875\n",
      "[Step 11561] Loss: 9.48e+07 -0.18020400404930115 0.34819296002388\n",
      "[Step 11562] Loss: 9.63e+07 -0.18035031855106354 0.3481624126434326\n",
      "[Step 11563] Loss: 9.62e+07 -0.1803964525461197 0.34813767671585083\n",
      "[Step 11564] Loss: 9.59e+07 -0.18031635880470276 0.3481549918651581\n",
      "[Step 11565] Loss: 9.57e+07 -0.18013297021389008 0.34816983342170715\n",
      "[Step 11566] Loss: 9.54e+07 -0.17996323108673096 0.3482094407081604\n",
      "[Step 11567] Loss: 9.54e+07 -0.1798127442598343 0.34822842478752136\n",
      "[Step 11568] Loss: 9.51e+07 -0.17970536649227142 0.34824493527412415\n",
      "[Step 11569] Loss: 9.62e+07 -0.1794499158859253 0.34830600023269653\n",
      "[Step 11570] Loss: 9.64e+07 -0.17941713333129883 0.34832414984703064\n",
      "[Step 11571] Loss: 9.53e+07 -0.17943312227725983 0.3482903242111206\n",
      "[Step 11572] Loss: 9.56e+07 -0.17943762242794037 0.34826719760894775\n",
      "[Step 11573] Loss: 9.54e+07 -0.1793668270111084 0.34827959537506104\n",
      "[Step 11574] Loss: 9.53e+07 -0.17925149202346802 0.3482985496520996\n",
      "[Step 11575] Loss: 9.55e+07 -0.17907127737998962 0.3483315706253052\n",
      "[Step 11576] Loss: 9.54e+07 -0.17889906466007233 0.3483794331550598\n",
      "[Step 11577] Loss: 9.53e+07 -0.17872905731201172 0.3484182059764862\n",
      "[Step 11578] Loss: 9.53e+07 -0.1786590963602066 0.3484421372413635\n",
      "[Step 11579] Loss: 9.58e+07 -0.17852941155433655 0.3484767973423004\n",
      "[Step 11580] Loss: 9.54e+07 -0.17843759059906006 0.34850403666496277\n",
      "[Step 11581] Loss: 9.56e+07 -0.17841802537441254 0.34847843647003174\n",
      "[Step 11582] Loss: 9.50e+07 -0.1783987134695053 0.34848669171333313\n",
      "[Step 11583] Loss: 9.46e+07 -0.17829684913158417 0.3485172390937805\n",
      "[Step 11584] Loss: 9.54e+07 -0.17814214527606964 0.3485766351222992\n",
      "[Step 11585] Loss: 9.50e+07 -0.17795613408088684 0.34863853454589844\n",
      "[Step 11586] Loss: 9.45e+07 -0.17783862352371216 0.34868061542510986\n",
      "[Step 11587] Loss: 9.56e+07 -0.17765706777572632 0.3487185537815094\n",
      "[Step 11588] Loss: 9.51e+07 -0.17753368616104126 0.3487383723258972\n",
      "[Step 11589] Loss: 9.49e+07 -0.17741847038269043 0.3487573266029358\n",
      "[Step 11590] Loss: 9.72e+07 -0.1775825172662735 0.3487185537815094\n",
      "[Step 11591] Loss: 9.53e+07 -0.1777227222919464 0.348710298538208\n",
      "[Step 11592] Loss: 9.49e+07 -0.17773529887199402 0.3487185537815094\n",
      "[Step 11593] Loss: 9.54e+07 -0.1777891218662262 0.348710298538208\n",
      "[Step 11594] Loss: 9.53e+07 -0.17783331871032715 0.3487020432949066\n",
      "[Step 11595] Loss: 9.54e+07 -0.1778123527765274 0.3487004041671753\n",
      "[Step 11596] Loss: 9.58e+07 -0.17782916128635406 0.3487185537815094\n",
      "[Step 11597] Loss: 9.54e+07 -0.17777222394943237 0.34874001145362854\n",
      "[Step 11598] Loss: 9.49e+07 -0.17771892249584198 0.34875237941741943\n",
      "[Step 11599] Loss: 9.65e+07 -0.1775749772787094 0.3487688899040222\n",
      "[Step 11600] Loss: 9.47e+07 -0.17737533152103424 0.34880518913269043\n",
      "[Step 11601] Loss: 9.57e+07 -0.17725124955177307 0.3488481044769287\n",
      "[Step 11602] Loss: 9.51e+07 -0.17715656757354736 0.34890255331993103\n",
      "[Step 11603] Loss: 9.61e+07 -0.17730771005153656 0.3488621413707733\n",
      "[Step 11604] Loss: 9.51e+07 -0.17731629312038422 0.3488621413707733\n",
      "[Step 11605] Loss: 9.53e+07 -0.1772114634513855 0.34890586137771606\n",
      "[Step 11606] Loss: 9.50e+07 -0.1770540475845337 0.34894299507141113\n",
      "[Step 11607] Loss: 9.63e+07 -0.1767842024564743 0.3489924967288971\n",
      "[Step 11608] Loss: 9.56e+07 -0.1765839159488678 0.3490428328514099\n",
      "[Step 11609] Loss: 9.61e+07 -0.17650549113750458 0.3490717113018036\n",
      "[Step 11610] Loss: 9.60e+07 -0.17664356529712677 0.3490189015865326\n",
      "[Step 11611] Loss: 9.50e+07 -0.17674781382083893 0.34901973605155945\n",
      "[Step 11612] Loss: 9.55e+07 -0.17677150666713715 0.34899580478668213\n",
      "[Step 11613] Loss: 9.51e+07 -0.17679913341999054 0.3489801287651062\n",
      "[Step 11614] Loss: 9.43e+07 -0.17684100568294525 0.3489842414855957\n",
      "[Step 11615] Loss: 9.56e+07 -0.17686337232589722 0.34897270798683167\n",
      "[Step 11616] Loss: 9.63e+07 -0.1770629733800888 0.34890833497047424\n",
      "[Step 11617] Loss: 9.63e+07 -0.17740099132061005 0.34879282116889954\n",
      "[Step 11618] Loss: 9.58e+07 -0.17785832285881042 0.3486905097961426\n",
      "[Step 11619] Loss: 9.70e+07 -0.17808683216571808 0.34859395027160645\n",
      "[Step 11620] Loss: 9.53e+07 -0.1783369779586792 0.3484998941421509\n",
      "[Step 11621] Loss: 9.57e+07 -0.17865003645420074 0.3484025299549103\n",
      "[Step 11622] Loss: 9.50e+07 -0.17895902693271637 0.3482911288738251\n",
      "[Step 11623] Loss: 9.53e+07 -0.17927707731723785 0.3481995463371277\n",
      "[Step 11624] Loss: 9.55e+07 -0.17946523427963257 0.3481508791446686\n",
      "[Step 11625] Loss: 9.47e+07 -0.1796361654996872 0.34811949729919434\n",
      "[Step 11626] Loss: 9.67e+07 -0.17961934208869934 0.34812280535697937\n",
      "[Step 11627] Loss: 9.52e+07 -0.17958304286003113 0.34812527894973755\n",
      "[Step 11628] Loss: 9.51e+07 -0.17954564094543457 0.34815168380737305\n",
      "[Step 11629] Loss: 9.50e+07 -0.17954717576503754 0.3481607735157013\n",
      "[Step 11630] Loss: 9.52e+07 -0.17952099442481995 0.3481789231300354\n",
      "[Step 11631] Loss: 9.61e+07 -0.1794074922800064 0.3482036590576172\n",
      "[Step 11632] Loss: 9.55e+07 -0.17929676175117493 0.3482399880886078\n",
      "[Step 11633] Loss: 9.57e+07 -0.1791645735502243 0.3482828736305237\n",
      "[Step 11634] Loss: 9.61e+07 -0.17910136282444 0.3482911288738251\n",
      "[Step 11635] Loss: 9.58e+07 -0.17912812530994415 0.3482787609100342\n",
      "[Step 11636] Loss: 9.70e+07 -0.1793021261692047 0.3482383191585541\n",
      "[Step 11637] Loss: 9.56e+07 -0.17956650257110596 0.3481805622577667\n",
      "[Step 11638] Loss: 9.57e+07 -0.1797550618648529 0.3481261134147644\n",
      "[Step 11639] Loss: 9.52e+07 -0.17989887297153473 0.34808897972106934\n",
      "[Step 11640] Loss: 9.49e+07 -0.18007157742977142 0.3480534851551056\n",
      "[Step 11641] Loss: 9.56e+07 -0.18014542758464813 0.3480435907840729\n",
      "[Step 11642] Loss: 9.60e+07 -0.18021957576274872 0.3480270802974701\n",
      "[Step 11643] Loss: 9.60e+07 -0.18033917248249054 0.34800565242767334\n",
      "[Step 11644] Loss: 9.59e+07 -0.18036912381649017 0.3480048179626465\n",
      "[Step 11645] Loss: 9.52e+07 -0.18040595948696136 0.3480163812637329\n",
      "[Step 11646] Loss: 9.59e+07 -0.1803540736436844 0.34802380204200745\n",
      "[Step 11647] Loss: 9.57e+07 -0.1802625060081482 0.3480609357357025\n",
      "[Step 11648] Loss: 9.51e+07 -0.18026700615882874 0.34807413816452026\n",
      "[Step 11649] Loss: 9.56e+07 -0.18027637898921967 0.34806421399116516\n",
      "[Step 11650] Loss: 9.53e+07 -0.18024425208568573 0.3480634093284607\n",
      "[Step 11651] Loss: 9.51e+07 -0.18015722930431366 0.34809640049934387\n",
      "[Step 11652] Loss: 9.56e+07 -0.18016161024570465 0.34809887409210205\n",
      "[Step 11653] Loss: 9.53e+07 -0.1801474541425705 0.34811291098594666\n",
      "[Step 11654] Loss: 9.49e+07 -0.1801060438156128 0.34811538457870483\n",
      "[Step 11655] Loss: 9.50e+07 -0.1799590140581131 0.3481285870075226\n",
      "[Step 11656] Loss: 9.54e+07 -0.17987991869449615 0.34813767671585083\n",
      "[Step 11657] Loss: 9.58e+07 -0.17989324033260345 0.3481326997280121\n",
      "[Step 11658] Loss: 9.54e+07 -0.17981214821338654 0.34811949729919434\n",
      "[Step 11659] Loss: 9.53e+07 -0.1797119379043579 0.348117858171463\n",
      "[Step 11660] Loss: 9.55e+07 -0.17970603704452515 0.34810301661491394\n",
      "[Step 11661] Loss: 9.45e+07 -0.17963910102844238 0.3481137454509735\n",
      "[Step 11662] Loss: 9.51e+07 -0.1796139031648636 0.34811702370643616\n",
      "[Step 11663] Loss: 9.64e+07 -0.17977342009544373 0.3480972349643707\n",
      "[Step 11664] Loss: 9.56e+07 -0.1798790693283081 0.34809640049934387\n",
      "[Step 11665] Loss: 9.52e+07 -0.17988787591457367 0.3480733036994934\n",
      "[Step 11666] Loss: 9.52e+07 -0.17986248433589935 0.34807825088500977\n",
      "[Step 11667] Loss: 9.52e+07 -0.17969614267349243 0.3481318950653076\n",
      "[Step 11668] Loss: 9.50e+07 -0.17952224612236023 0.3481871783733368\n",
      "[Step 11669] Loss: 9.51e+07 -0.17936813831329346 0.348223477602005\n",
      "[Step 11670] Loss: 9.47e+07 -0.17925341427326202 0.34825071692466736\n",
      "[Step 11671] Loss: 9.57e+07 -0.1790052056312561 0.34832167625427246\n",
      "[Step 11672] Loss: 9.55e+07 -0.17884784936904907 0.34837695956230164\n",
      "[Step 11673] Loss: 9.54e+07 -0.1786654144525528 0.34841078519821167\n",
      "[Step 11674] Loss: 9.52e+07 -0.17851266264915466 0.3484388291835785\n",
      "[Step 11675] Loss: 9.51e+07 -0.1784575879573822 0.3484503924846649\n",
      "[Step 11676] Loss: 9.56e+07 -0.17839686572551727 0.3484503924846649\n",
      "[Step 11677] Loss: 9.53e+07 -0.17831279337406158 0.34850072860717773\n",
      "[Step 11678] Loss: 9.60e+07 -0.1781337559223175 0.34860220551490784\n",
      "[Step 11679] Loss: 9.58e+07 -0.17802682518959045 0.34861624240875244\n",
      "[Step 11680] Loss: 9.54e+07 -0.17799238860607147 0.34862202405929565\n",
      "[Step 11681] Loss: 9.58e+07 -0.1780771166086197 0.3486475944519043\n",
      "[Step 11682] Loss: 9.55e+07 -0.17827363312244415 0.34860220551490784\n",
      "[Step 11683] Loss: 9.56e+07 -0.17849200963974 0.3485543429851532\n",
      "[Step 11684] Loss: 9.52e+07 -0.17883791029453278 0.3485172390937805\n",
      "[Step 11685] Loss: 9.50e+07 -0.17902357876300812 0.34852051734924316\n",
      "[Step 11686] Loss: 9.64e+07 -0.17917880415916443 0.34847596287727356\n",
      "[Step 11687] Loss: 9.48e+07 -0.17937172949314117 0.348438024520874\n",
      "[Step 11688] Loss: 9.50e+07 -0.1795484870672226 0.3483752906322479\n",
      "[Step 11689] Loss: 9.47e+07 -0.17970134317874908 0.3483571410179138\n",
      "[Step 11690] Loss: 9.56e+07 -0.1798209697008133 0.3483406603336334\n",
      "[Step 11691] Loss: 9.55e+07 -0.1799008548259735 0.3483125865459442\n",
      "[Step 11692] Loss: 9.67e+07 -0.18009641766548157 0.34826555848121643\n",
      "[Step 11693] Loss: 9.52e+07 -0.1802094429731369 0.3482985496520996\n",
      "[Step 11694] Loss: 9.54e+07 -0.1803460270166397 0.3482606112957001\n",
      "[Step 11695] Loss: 9.61e+07 -0.18037903308868408 0.3482705056667328\n",
      "[Step 11696] Loss: 9.54e+07 -0.18033696711063385 0.3482903242111206\n",
      "[Step 11697] Loss: 9.50e+07 -0.18030592799186707 0.34829360246658325\n",
      "[Step 11698] Loss: 9.73e+07 -0.18057306110858917 0.3482581377029419\n",
      "[Step 11699] Loss: 9.62e+07 -0.1807437241077423 0.3482176959514618\n",
      "[Step 11700] Loss: 9.60e+07 -0.18080902099609375 0.34818387031555176\n",
      "[Step 11701] Loss: 9.65e+07 -0.1809471696615219 0.3481648862361908\n",
      "[Step 11702] Loss: 9.54e+07 -0.18115587532520294 0.3481409549713135\n",
      "[Step 11703] Loss: 9.55e+07 -0.18139396607875824 0.348087340593338\n",
      "[Step 11704] Loss: 9.60e+07 -0.1817244589328766 0.3480023443698883\n",
      "[Step 11705] Loss: 9.65e+07 -0.1821838766336441 0.3479090929031372\n",
      "[Step 11706] Loss: 9.52e+07 -0.18258148431777954 0.34783729910850525\n",
      "[Step 11707] Loss: 9.53e+07 -0.18301773071289062 0.34775644540786743\n",
      "[Step 11708] Loss: 9.50e+07 -0.18347880244255066 0.3476516604423523\n",
      "[Step 11709] Loss: 9.70e+07 -0.18413841724395752 0.34751880168914795\n",
      "[Step 11710] Loss: 9.53e+07 -0.18476295471191406 0.3473876118659973\n",
      "[Step 11711] Loss: 9.55e+07 -0.18535789847373962 0.347258061170578\n",
      "[Step 11712] Loss: 9.53e+07 -0.18586106598377228 0.34709715843200684\n",
      "[Step 11713] Loss: 9.61e+07 -0.1864883005619049 0.3469676077365875\n",
      "[Step 11714] Loss: 9.64e+07 -0.18716290593147278 0.34680095314979553\n",
      "[Step 11715] Loss: 9.56e+07 -0.18786956369876862 0.3466309607028961\n",
      "[Step 11716] Loss: 9.59e+07 -0.18854735791683197 0.3464857339859009\n",
      "[Step 11717] Loss: 9.54e+07 -0.18915824592113495 0.34633970260620117\n",
      "[Step 11718] Loss: 9.51e+07 -0.18980512022972107 0.3461911678314209\n",
      "[Step 11719] Loss: 9.53e+07 -0.19036981463432312 0.346100389957428\n",
      "[Step 11720] Loss: 9.51e+07 -0.19082215428352356 0.3459939658641815\n",
      "[Step 11721] Loss: 9.56e+07 -0.1911897361278534 0.3459155559539795\n",
      "[Step 11722] Loss: 9.54e+07 -0.19156514108181 0.3458421230316162\n",
      "[Step 11723] Loss: 9.54e+07 -0.19189444184303284 0.34573817253112793\n",
      "[Step 11724] Loss: 9.50e+07 -0.19219781458377838 0.3456457555294037\n",
      "[Step 11725] Loss: 9.49e+07 -0.1924252212047577 0.34560778737068176\n",
      "[Step 11726] Loss: 9.51e+07 -0.19265812635421753 0.34557396173477173\n",
      "[Step 11727] Loss: 9.56e+07 -0.19297367334365845 0.3455153703689575\n",
      "[Step 11728] Loss: 9.46e+07 -0.19327791035175323 0.3454411029815674\n",
      "[Step 11729] Loss: 9.59e+07 -0.1935010403394699 0.34539490938186646\n",
      "[Step 11730] Loss: 9.54e+07 -0.19364245235919952 0.3453874886035919\n",
      "[Step 11731] Loss: 9.53e+07 -0.19375357031822205 0.3453594148159027\n",
      "[Step 11732] Loss: 9.56e+07 -0.19400730729103088 0.34530743956565857\n",
      "[Step 11733] Loss: 9.55e+07 -0.19422009587287903 0.34524884819984436\n",
      "[Step 11734] Loss: 9.54e+07 -0.19445697963237762 0.3451935648918152\n",
      "[Step 11735] Loss: 9.56e+07 -0.19459544122219086 0.34518861770629883\n",
      "[Step 11736] Loss: 9.56e+07 -0.19461411237716675 0.345213383436203\n",
      "[Step 11737] Loss: 9.50e+07 -0.1945776492357254 0.3452282249927521\n",
      "[Step 11738] Loss: 9.55e+07 -0.19442279636859894 0.34524720907211304\n",
      "[Step 11739] Loss: 9.48e+07 -0.19430497288703918 0.345296710729599\n",
      "[Step 11740] Loss: 9.52e+07 -0.19422857463359833 0.34530332684516907\n",
      "[Step 11741] Loss: 9.56e+07 -0.194027841091156 0.34533631801605225\n",
      "[Step 11742] Loss: 9.59e+07 -0.1937340795993805 0.34541553258895874\n",
      "[Step 11743] Loss: 9.57e+07 -0.19348731637001038 0.345436155796051\n",
      "[Step 11744] Loss: 9.50e+07 -0.19324447214603424 0.3455095887184143\n",
      "[Step 11745] Loss: 9.61e+07 -0.19295862317085266 0.34559789299964905\n",
      "[Step 11746] Loss: 9.51e+07 -0.19279251992702484 0.34563586115837097\n",
      "[Step 11747] Loss: 9.71e+07 -0.1924407184123993 0.34570515155792236\n",
      "[Step 11748] Loss: 9.51e+07 -0.19206155836582184 0.3458074629306793\n",
      "[Step 11749] Loss: 9.55e+07 -0.1918238252401352 0.3458611071109772\n",
      "[Step 11750] Loss: 9.50e+07 -0.19157029688358307 0.3458908200263977\n",
      "[Step 11751] Loss: 9.60e+07 -0.1913730800151825 0.34593042731285095\n",
      "[Step 11752] Loss: 9.60e+07 -0.19135092198848724 0.34594443440437317\n",
      "[Step 11753] Loss: 9.58e+07 -0.19133692979812622 0.34592875838279724\n",
      "[Step 11754] Loss: 9.54e+07 -0.19126692414283752 0.34595268964767456\n",
      "[Step 11755] Loss: 9.47e+07 -0.1912686973810196 0.34597745537757874\n",
      "[Step 11756] Loss: 9.56e+07 -0.1911427527666092 0.3460005521774292\n",
      "[Step 11757] Loss: 9.46e+07 -0.1909804493188858 0.3460434675216675\n",
      "[Step 11758] Loss: 9.53e+07 -0.19071879982948303 0.34610700607299805\n",
      "[Step 11759] Loss: 9.55e+07 -0.19047828018665314 0.3461977541446686\n",
      "[Step 11760] Loss: 9.53e+07 -0.19024772942066193 0.34623903036117554\n",
      "[Step 11761] Loss: 9.50e+07 -0.19004513323307037 0.34628522396087646\n",
      "[Step 11762] Loss: 9.63e+07 -0.18974928557872772 0.34636032581329346\n",
      "[Step 11763] Loss: 9.63e+07 -0.18945354223251343 0.346423864364624\n",
      "[Step 11764] Loss: 9.54e+07 -0.18909916281700134 0.3464816212654114\n",
      "[Step 11765] Loss: 9.55e+07 -0.18869328498840332 0.34657567739486694\n",
      "[Step 11766] Loss: 9.52e+07 -0.18836286664009094 0.3466070294380188\n",
      "[Step 11767] Loss: 9.58e+07 -0.18808609247207642 0.3466763496398926\n",
      "[Step 11768] Loss: 9.53e+07 -0.18784478306770325 0.3467225432395935\n",
      "[Step 11769] Loss: 9.53e+07 -0.1876501441001892 0.34676793217658997\n",
      "[Step 11770] Loss: 9.52e+07 -0.1874610334634781 0.34682321548461914\n",
      "[Step 11771] Loss: 9.47e+07 -0.18730467557907104 0.3468702435493469\n",
      "[Step 11772] Loss: 9.48e+07 -0.18708902597427368 0.3469230532646179\n",
      "[Step 11773] Loss: 9.53e+07 -0.1869538277387619 0.34696266055107117\n",
      "[Step 11774] Loss: 9.48e+07 -0.18688055872917175 0.34699732065200806\n",
      "[Step 11775] Loss: 9.50e+07 -0.1868259757757187 0.34701961278915405\n",
      "[Step 11776] Loss: 9.59e+07 -0.18673014640808105 0.3470616936683655\n",
      "[Step 11777] Loss: 9.42e+07 -0.1866060197353363 0.34713345766067505\n",
      "[Step 11778] Loss: 9.55e+07 -0.18640625476837158 0.34717804193496704\n",
      "[Step 11779] Loss: 9.51e+07 -0.186207115650177 0.347258061170578\n",
      "[Step 11780] Loss: 9.51e+07 -0.18604126572608948 0.3473191261291504\n",
      "[Step 11781] Loss: 9.59e+07 -0.18583381175994873 0.34737110137939453\n",
      "[Step 11782] Loss: 9.61e+07 -0.18578869104385376 0.34740492701530457\n",
      "[Step 11783] Loss: 9.50e+07 -0.1857433319091797 0.3474057614803314\n",
      "[Step 11784] Loss: 9.56e+07 -0.18576593697071075 0.3474082350730896\n",
      "[Step 11785] Loss: 9.55e+07 -0.1858656108379364 0.34738513827323914\n",
      "[Step 11786] Loss: 9.57e+07 -0.18592341244220734 0.34738925099372864\n",
      "[Step 11787] Loss: 9.53e+07 -0.1859985589981079 0.3473678231239319\n",
      "[Step 11788] Loss: 9.54e+07 -0.18613015115261078 0.34733644127845764\n",
      "[Step 11789] Loss: 9.53e+07 -0.18633034825325012 0.3473191261291504\n",
      "[Step 11790] Loss: 9.58e+07 -0.1863897740840912 0.34729933738708496\n",
      "[Step 11791] Loss: 9.58e+07 -0.18640001118183136 0.3473009765148163\n",
      "[Step 11792] Loss: 9.57e+07 -0.1863667219877243 0.34726300835609436\n",
      "[Step 11793] Loss: 9.86e+07 -0.1866554170846939 0.3472151458263397\n",
      "[Step 11794] Loss: 9.57e+07 -0.18698793649673462 0.3471367657184601\n",
      "[Step 11795] Loss: 9.54e+07 -0.1873455047607422 0.34708890318870544\n",
      "[Step 11796] Loss: 9.55e+07 -0.1877821683883667 0.3470245599746704\n",
      "[Step 11797] Loss: 9.48e+07 -0.18814648687839508 0.34694451093673706\n",
      "[Step 11798] Loss: 9.55e+07 -0.18851342797279358 0.34687933325767517\n",
      "[Step 11799] Loss: 9.46e+07 -0.18876700103282928 0.34683310985565186\n",
      "[Step 11800] Loss: 9.54e+07 -0.1890675276517868 0.3467893898487091\n",
      "[Step 11801] Loss: 9.53e+07 -0.1893090009689331 0.3467737138271332\n",
      "[Step 11802] Loss: 9.56e+07 -0.18948496878147125 0.34673410654067993\n",
      "[Step 11803] Loss: 9.54e+07 -0.18962031602859497 0.34671348333358765\n",
      "[Step 11804] Loss: 9.56e+07 -0.18974144756793976 0.34668129682540894\n",
      "[Step 11805] Loss: 9.57e+07 -0.18974746763706207 0.34666892886161804\n",
      "[Step 11806] Loss: 9.56e+07 -0.1898038536310196 0.34665241837501526\n",
      "[Step 11807] Loss: 9.57e+07 -0.1898995190858841 0.34663674235343933\n",
      "[Step 11808] Loss: 9.52e+07 -0.1900469809770584 0.34658804535865784\n",
      "[Step 11809] Loss: 9.49e+07 -0.19023530185222626 0.34654679894447327\n",
      "[Step 11810] Loss: 9.49e+07 -0.1903829723596573 0.34651049971580505\n",
      "[Step 11811] Loss: 9.49e+07 -0.19055400788784027 0.3464997708797455\n",
      "[Step 11812] Loss: 9.57e+07 -0.1907399296760559 0.3464263379573822\n",
      "[Step 11813] Loss: 9.51e+07 -0.19081559777259827 0.3464065194129944\n",
      "[Step 11814] Loss: 9.54e+07 -0.19100280106067657 0.3463743329048157\n",
      "[Step 11815] Loss: 9.49e+07 -0.19117730855941772 0.3463042080402374\n",
      "[Step 11816] Loss: 9.59e+07 -0.1912410706281662 0.34632977843284607\n",
      "[Step 11817] Loss: 9.60e+07 -0.19131876528263092 0.34634464979171753\n",
      "[Step 11818] Loss: 9.52e+07 -0.1913577914237976 0.34632235765457153\n",
      "[Step 11819] Loss: 9.63e+07 -0.1915121078491211 0.3462885320186615\n",
      "[Step 11820] Loss: 9.48e+07 -0.19168294966220856 0.34624728560447693\n",
      "[Step 11821] Loss: 9.56e+07 -0.19177871942520142 0.34623241424560547\n",
      "[Step 11822] Loss: 9.52e+07 -0.19178880751132965 0.34620848298072815\n",
      "[Step 11823] Loss: 9.66e+07 -0.19197367131710052 0.34614741802215576\n",
      "[Step 11824] Loss: 9.59e+07 -0.19220134615898132 0.3461061716079712\n",
      "[Step 11825] Loss: 9.49e+07 -0.19243904948234558 0.3460467755794525\n",
      "[Step 11826] Loss: 9.53e+07 -0.19259367883205414 0.34599974751472473\n",
      "[Step 11827] Loss: 9.58e+07 -0.19263267517089844 0.34600386023521423\n",
      "[Step 11828] Loss: 9.56e+07 -0.19257530570030212 0.3460327386856079\n",
      "[Step 11829] Loss: 9.57e+07 -0.19261306524276733 0.34602779150009155\n",
      "[Step 11830] Loss: 9.59e+07 -0.19270732998847961 0.3459824025630951\n",
      "[Step 11831] Loss: 9.61e+07 -0.19293804466724396 0.34591802954673767\n",
      "[Step 11832] Loss: 9.54e+07 -0.19320079684257507 0.3458545207977295\n",
      "[Step 11833] Loss: 9.54e+07 -0.1934431791305542 0.3458033502101898\n",
      "[Step 11834] Loss: 9.53e+07 -0.19360043108463287 0.34576621651649475\n",
      "[Step 11835] Loss: 9.54e+07 -0.1936742216348648 0.34575217962265015\n",
      "[Step 11836] Loss: 9.57e+07 -0.19371914863586426 0.3457365036010742\n",
      "[Step 11837] Loss: 9.52e+07 -0.19377292692661285 0.3457282483577728\n",
      "[Step 11838] Loss: 9.58e+07 -0.19380660355091095 0.3457100987434387\n",
      "[Step 11839] Loss: 9.57e+07 -0.19387787580490112 0.34570515155792236\n",
      "[Step 11840] Loss: 9.50e+07 -0.1939331591129303 0.3457084596157074\n",
      "[Step 11841] Loss: 9.53e+07 -0.193937286734581 0.3457200229167938\n",
      "[Step 11842] Loss: 9.62e+07 -0.19404928386211395 0.34572166204452515\n",
      "[Step 11843] Loss: 9.51e+07 -0.19417254626750946 0.3456936180591583\n",
      "[Step 11844] Loss: 9.49e+07 -0.194219172000885 0.3456919491291046\n",
      "[Step 11845] Loss: 9.54e+07 -0.194170743227005 0.34570515155792236\n",
      "[Step 11846] Loss: 9.54e+07 -0.19422291219234467 0.34571588039398193\n",
      "[Step 11847] Loss: 9.56e+07 -0.19430884718894958 0.34571588039398193\n",
      "[Step 11848] Loss: 9.52e+07 -0.1943666785955429 0.34568288922309875\n",
      "[Step 11849] Loss: 9.57e+07 -0.19437217712402344 0.34570929408073425\n",
      "[Step 11850] Loss: 9.56e+07 -0.19445204734802246 0.3457249701023102\n",
      "[Step 11851] Loss: 9.59e+07 -0.19457010924816132 0.34569114446640015\n",
      "[Step 11852] Loss: 9.57e+07 -0.1945849061012268 0.3456977307796478\n",
      "[Step 11853] Loss: 9.51e+07 -0.19459658861160278 0.3457059860229492\n",
      "[Step 11854] Loss: 9.51e+07 -0.19470712542533875 0.34570103883743286\n",
      "[Step 11855] Loss: 9.57e+07 -0.1947467178106308 0.3457266092300415\n",
      "[Step 11856] Loss: 9.52e+07 -0.19480010867118835 0.3457332253456116\n",
      "[Step 11857] Loss: 9.62e+07 -0.1948932558298111 0.3457208275794983\n",
      "[Step 11858] Loss: 9.52e+07 -0.19486859440803528 0.3457571566104889\n",
      "[Step 11859] Loss: 9.58e+07 -0.1947128027677536 0.34580087661743164\n",
      "[Step 11860] Loss: 9.56e+07 -0.19458776712417603 0.3458421230316162\n",
      "[Step 11861] Loss: 9.59e+07 -0.19445069134235382 0.3458850383758545\n",
      "[Step 11862] Loss: 9.50e+07 -0.19439873099327087 0.3459295928478241\n",
      "[Step 11863] Loss: 9.56e+07 -0.19437700510025024 0.3459320664405823\n",
      "[Step 11864] Loss: 9.57e+07 -0.19438911974430084 0.3459394872188568\n",
      "[Step 11865] Loss: 9.54e+07 -0.19442163407802582 0.34596261382102966\n",
      "[Step 11866] Loss: 9.50e+07 -0.1944800615310669 0.34594693779945374\n",
      "[Step 11867] Loss: 9.75e+07 -0.1948024332523346 0.34586358070373535\n",
      "[Step 11868] Loss: 9.56e+07 -0.19508063793182373 0.3457711637020111\n",
      "[Step 11869] Loss: 9.55e+07 -0.1953306794166565 0.3457266092300415\n",
      "[Step 11870] Loss: 9.65e+07 -0.19576972723007202 0.34561604261398315\n",
      "[Step 11871] Loss: 9.61e+07 -0.19605973362922668 0.34556323289871216\n",
      "[Step 11872] Loss: 9.52e+07 -0.19634802639484406 0.3455013632774353\n",
      "[Step 11873] Loss: 9.50e+07 -0.19653360545635223 0.34545019268989563\n",
      "[Step 11874] Loss: 9.51e+07 -0.19673387706279755 0.34538334608078003\n",
      "[Step 11875] Loss: 9.45e+07 -0.19690720736980438 0.3453470468521118\n",
      "[Step 11876] Loss: 9.59e+07 -0.1969408243894577 0.3453412652015686\n",
      "[Step 11877] Loss: 9.51e+07 -0.1970508098602295 0.34530001878738403\n",
      "[Step 11878] Loss: 9.61e+07 -0.1971922069787979 0.3452843427658081\n",
      "[Step 11879] Loss: 9.52e+07 -0.1973039209842682 0.3452455699443817\n",
      "[Step 11880] Loss: 9.65e+07 -0.19726049900054932 0.3452422618865967\n",
      "[Step 11881] Loss: 9.59e+07 -0.1971350610256195 0.3452802002429962\n",
      "[Step 11882] Loss: 9.64e+07 -0.1969967633485794 0.3453132212162018\n",
      "[Step 11883] Loss: 9.51e+07 -0.1969277560710907 0.3452826738357544\n",
      "[Step 11884] Loss: 9.57e+07 -0.1970473825931549 0.34525546431541443\n",
      "[Step 11885] Loss: 9.54e+07 -0.197269469499588 0.34517955780029297\n",
      "[Step 11886] Loss: 9.65e+07 -0.19759513437747955 0.34512755274772644\n",
      "[Step 11887] Loss: 9.48e+07 -0.1979205459356308 0.3450656831264496\n",
      "[Step 11888] Loss: 9.62e+07 -0.19835947453975677 0.3449741005897522\n",
      "[Step 11889] Loss: 9.50e+07 -0.19884763658046722 0.3448989987373352\n",
      "[Step 11890] Loss: 9.53e+07 -0.19940359890460968 0.34479090571403503\n",
      "[Step 11891] Loss: 9.56e+07 -0.1998201161623001 0.3447100520133972\n",
      "[Step 11892] Loss: 9.58e+07 -0.20012857019901276 0.3446432054042816\n",
      "[Step 11893] Loss: 9.55e+07 -0.20048649609088898 0.34458214044570923\n",
      "[Step 11894] Loss: 9.56e+07 -0.2007584571838379 0.34452685713768005\n",
      "[Step 11895] Loss: 9.70e+07 -0.2012060135602951 0.3444361090660095\n",
      "[Step 11896] Loss: 9.59e+07 -0.20170828700065613 0.3443205654621124\n",
      "[Step 11897] Loss: 9.55e+07 -0.20225605368614197 0.34423887729644775\n",
      "[Step 11898] Loss: 9.46e+07 -0.2027326226234436 0.34416627883911133\n",
      "[Step 11899] Loss: 9.53e+07 -0.20309454202651978 0.3441043794155121\n",
      "[Step 11900] Loss: 9.52e+07 -0.2035154402256012 0.3440243601799011\n",
      "[Step 11901] Loss: 9.58e+07 -0.20379067957401276 0.3440152704715729\n",
      "[Step 11902] Loss: 9.48e+07 -0.20406317710876465 0.34394845366477966\n",
      "[Step 11903] Loss: 9.53e+07 -0.2043277472257614 0.34388986229896545\n",
      "[Step 11904] Loss: 9.52e+07 -0.2046343982219696 0.3438345789909363\n",
      "[Step 11905] Loss: 9.46e+07 -0.20494131743907928 0.34376856684684753\n",
      "[Step 11906] Loss: 9.51e+07 -0.2052099108695984 0.3437248170375824\n",
      "[Step 11907] Loss: 9.49e+07 -0.2055089771747589 0.34367120265960693\n",
      "[Step 11908] Loss: 9.61e+07 -0.2059277892112732 0.3435911536216736\n",
      "[Step 11909] Loss: 9.45e+07 -0.20628421008586884 0.3435564935207367\n",
      "[Step 11910] Loss: 9.51e+07 -0.2065638154745102 0.34351855516433716\n",
      "[Step 11911] Loss: 9.61e+07 -0.20670750737190247 0.34349462389945984\n",
      "[Step 11912] Loss: 9.52e+07 -0.20677760243415833 0.3434673845767975\n",
      "[Step 11913] Loss: 9.52e+07 -0.20683299005031586 0.34345170855522156\n",
      "[Step 11914] Loss: 9.60e+07 -0.20682254433631897 0.34345418214797974\n",
      "[Step 11915] Loss: 9.55e+07 -0.20673121511936188 0.34346985816955566\n",
      "[Step 11916] Loss: 9.51e+07 -0.20658642053604126 0.34353503584861755\n",
      "[Step 11917] Loss: 9.58e+07 -0.20632360875606537 0.3435787856578827\n",
      "[Step 11918] Loss: 9.53e+07 -0.20617102086544037 0.34360602498054504\n",
      "[Step 11919] Loss: 9.70e+07 -0.20585189759731293 0.3436844050884247\n",
      "[Step 11920] Loss: 9.59e+07 -0.2054261863231659 0.3437627851963043\n",
      "[Step 11921] Loss: 9.51e+07 -0.20507203042507172 0.34383705258369446\n",
      "[Step 11922] Loss: 9.60e+07 -0.20473022758960724 0.3439071774482727\n",
      "[Step 11923] Loss: 9.54e+07 -0.20453031361103058 0.34394845366477966\n",
      "[Step 11924] Loss: 9.61e+07 -0.20446589589118958 0.34394267201423645\n",
      "[Step 11925] Loss: 9.58e+07 -0.20437858998775482 0.3439880609512329\n",
      "[Step 11926] Loss: 9.60e+07 -0.20427000522613525 0.3440020680427551\n",
      "[Step 11927] Loss: 9.59e+07 -0.20424461364746094 0.3439863920211792\n",
      "[Step 11928] Loss: 9.48e+07 -0.20422852039337158 0.3440111577510834\n",
      "[Step 11929] Loss: 9.53e+07 -0.20422327518463135 0.344025194644928\n",
      "[Step 11930] Loss: 9.49e+07 -0.20419278740882874 0.34405240416526794\n",
      "[Step 11931] Loss: 9.60e+07 -0.2042173445224762 0.34406396746635437\n",
      "[Step 11932] Loss: 9.70e+07 -0.20434334874153137 0.3440284729003906\n",
      "[Step 11933] Loss: 9.51e+07 -0.20438364148139954 0.34400948882102966\n",
      "[Step 11934] Loss: 9.56e+07 -0.20447035133838654 0.3439698815345764\n",
      "[Step 11935] Loss: 9.53e+07 -0.20444439351558685 0.34395256638526917\n",
      "[Step 11936] Loss: 9.49e+07 -0.20449182391166687 0.3439236879348755\n",
      "[Step 11937] Loss: 9.66e+07 -0.20475831627845764 0.3438263237476349\n",
      "[Step 11938] Loss: 9.58e+07 -0.20511136949062347 0.3437504172325134\n",
      "[Step 11939] Loss: 9.56e+07 -0.2053358107805252 0.34370338916778564\n",
      "[Step 11940] Loss: 9.62e+07 -0.2054612785577774 0.3436703681945801\n",
      "[Step 11941] Loss: 9.52e+07 -0.20551489293575287 0.3436390161514282\n",
      "[Step 11942] Loss: 9.52e+07 -0.20549552142620087 0.3436398506164551\n",
      "[Step 11943] Loss: 9.62e+07 -0.20539166033267975 0.3436695337295532\n",
      "[Step 11944] Loss: 9.55e+07 -0.2051980346441269 0.34372153878211975\n",
      "[Step 11945] Loss: 9.44e+07 -0.2049729973077774 0.3437974452972412\n",
      "[Step 11946] Loss: 9.51e+07 -0.20478123426437378 0.34383952617645264\n",
      "[Step 11947] Loss: 9.52e+07 -0.20450112223625183 0.3438849151134491\n",
      "[Step 11948] Loss: 9.59e+07 -0.2041328251361847 0.3439558744430542\n",
      "[Step 11949] Loss: 9.49e+07 -0.20373989641666412 0.34404003620147705\n",
      "[Step 11950] Loss: 9.57e+07 -0.20349609851837158 0.34409037232398987\n",
      "[Step 11951] Loss: 9.52e+07 -0.20317180454730988 0.3441654443740845\n",
      "[Step 11952] Loss: 9.54e+07 -0.20278975367546082 0.3442595303058624\n",
      "[Step 11953] Loss: 9.54e+07 -0.20232301950454712 0.34433048963546753\n",
      "[Step 11954] Loss: 9.50e+07 -0.2018570452928543 0.34445425868034363\n",
      "[Step 11955] Loss: 9.52e+07 -0.20130190253257751 0.3445400595664978\n",
      "[Step 11956] Loss: 9.54e+07 -0.20080360770225525 0.3446349501609802\n",
      "[Step 11957] Loss: 9.68e+07 -0.20053139328956604 0.3446943759918213\n",
      "[Step 11958] Loss: 9.63e+07 -0.20007272064685822 0.34482142329216003\n",
      "[Step 11959] Loss: 9.50e+07 -0.19968268275260925 0.3448849618434906\n",
      "[Step 11960] Loss: 9.47e+07 -0.1993139535188675 0.34496253728866577\n",
      "[Step 11961] Loss: 9.53e+07 -0.19910705089569092 0.34500378370285034\n",
      "[Step 11962] Loss: 9.58e+07 -0.199039489030838 0.3450112044811249\n",
      "[Step 11963] Loss: 9.58e+07 -0.1989390105009079 0.3450466990470886\n",
      "[Step 11964] Loss: 9.54e+07 -0.19873058795928955 0.3450607359409332\n",
      "[Step 11965] Loss: 9.58e+07 -0.1984914094209671 0.3451143503189087\n",
      "[Step 11966] Loss: 9.51e+07 -0.19834907352924347 0.34514984488487244\n",
      "[Step 11967] Loss: 9.60e+07 -0.19830885529518127 0.3451671600341797\n",
      "[Step 11968] Loss: 9.54e+07 -0.198286235332489 0.3451564311981201\n",
      "[Step 11969] Loss: 9.61e+07 -0.19840691983699799 0.34516140818595886\n",
      "[Step 11970] Loss: 9.46e+07 -0.19845089316368103 0.3451746106147766\n",
      "[Step 11971] Loss: 9.52e+07 -0.19857196509838104 0.34516552090644836\n",
      "[Step 11972] Loss: 9.52e+07 -0.19864419102668762 0.34516140818595886\n",
      "[Step 11973] Loss: 9.65e+07 -0.19887569546699524 0.34512507915496826\n",
      "[Step 11974] Loss: 9.56e+07 -0.19910211861133575 0.34509456157684326\n",
      "[Step 11975] Loss: 9.59e+07 -0.19930654764175415 0.3450269103050232\n",
      "[Step 11976] Loss: 9.55e+07 -0.19941258430480957 0.34500131011009216\n",
      "[Step 11977] Loss: 9.53e+07 -0.19949191808700562 0.34496089816093445\n",
      "[Step 11978] Loss: 9.52e+07 -0.19951626658439636 0.34497079253196716\n",
      "[Step 11979] Loss: 9.52e+07 -0.19965124130249023 0.3449237644672394\n",
      "[Step 11980] Loss: 9.50e+07 -0.19976001977920532 0.3448874354362488\n",
      "[Step 11981] Loss: 9.50e+07 -0.1998525857925415 0.3448684811592102\n",
      "[Step 11982] Loss: 9.56e+07 -0.20001988112926483 0.34483134746551514\n",
      "[Step 11983] Loss: 9.54e+07 -0.20006747543811798 0.3448057472705841\n",
      "[Step 11984] Loss: 9.53e+07 -0.20018377900123596 0.34476861357688904\n",
      "[Step 11985] Loss: 9.50e+07 -0.20028096437454224 0.34475377202033997\n",
      "[Step 11986] Loss: 9.58e+07 -0.2003992199897766 0.3447331488132477\n",
      "[Step 11987] Loss: 9.50e+07 -0.2005566507577896 0.34468281269073486\n",
      "[Step 11988] Loss: 9.54e+07 -0.20069344341754913 0.34464651346206665\n",
      "[Step 11989] Loss: 9.62e+07 -0.20076337456703186 0.3446151614189148\n",
      "[Step 11990] Loss: 9.50e+07 -0.20078907907009125 0.3446250557899475\n",
      "[Step 11991] Loss: 9.55e+07 -0.2009282410144806 0.34460029006004333\n",
      "[Step 11992] Loss: 9.52e+07 -0.20097912847995758 0.3445788323879242\n",
      "[Step 11993] Loss: 9.56e+07 -0.20107854902744293 0.34456562995910645\n",
      "[Step 11994] Loss: 9.59e+07 -0.20123781263828278 0.34452852606773376\n",
      "[Step 11995] Loss: 9.54e+07 -0.20145854353904724 0.3445260524749756\n",
      "[Step 11996] Loss: 9.73e+07 -0.20193400979042053 0.3444179594516754\n",
      "[Step 11997] Loss: 9.53e+07 -0.20224040746688843 0.34434202313423157\n",
      "[Step 11998] Loss: 9.47e+07 -0.20250774919986725 0.3442908823490143\n",
      "[Step 11999] Loss: 9.45e+07 -0.20275838673114777 0.3442743718624115\n",
      "[Step 12000] Loss: 9.54e+07 -0.20299780368804932 0.34421661496162415\n",
      "[Step 12001] Loss: 9.51e+07 -0.20322969555854797 0.3441935181617737\n",
      "[Step 12002] Loss: 9.53e+07 -0.2034950703382492 0.3441299796104431\n",
      "[Step 12003] Loss: 9.57e+07 -0.20380285382270813 0.344086229801178\n",
      "[Step 12004] Loss: 9.61e+07 -0.20396600663661957 0.344059020280838\n",
      "[Step 12005] Loss: 9.66e+07 -0.20396795868873596 0.3440573513507843\n",
      "[Step 12006] Loss: 9.49e+07 -0.20397913455963135 0.3440573513507843\n",
      "[Step 12007] Loss: 9.57e+07 -0.20390576124191284 0.344111829996109\n",
      "[Step 12008] Loss: 9.52e+07 -0.20389941334724426 0.34412336349487305\n",
      "[Step 12009] Loss: 9.52e+07 -0.20381133258342743 0.34414565563201904\n",
      "[Step 12010] Loss: 9.60e+07 -0.20378583669662476 0.34416380524635315\n",
      "[Step 12011] Loss: 9.61e+07 -0.20370803773403168 0.34418606758117676\n",
      "[Step 12012] Loss: 9.70e+07 -0.20390719175338745 0.3441753685474396\n",
      "[Step 12013] Loss: 9.52e+07 -0.20410017669200897 0.34413328766822815\n",
      "[Step 12014] Loss: 9.62e+07 -0.20426471531391144 0.3440994322299957\n",
      "[Step 12015] Loss: 9.61e+07 -0.20426976680755615 0.34410274028778076\n",
      "[Step 12016] Loss: 9.51e+07 -0.20431144535541534 0.34410935640335083\n",
      "[Step 12017] Loss: 9.61e+07 -0.20444034039974213 0.34411099553108215\n",
      "[Step 12018] Loss: 9.58e+07 -0.20460550487041473 0.34407302737236023\n",
      "[Step 12019] Loss: 9.49e+07 -0.20470121502876282 0.34407302737236023\n",
      "[Step 12020] Loss: 9.54e+07 -0.2048039734363556 0.34405818581581116\n",
      "[Step 12021] Loss: 9.49e+07 -0.20488911867141724 0.3440697491168976\n",
      "[Step 12022] Loss: 9.45e+07 -0.20494404435157776 0.3440326154232025\n",
      "[Step 12023] Loss: 9.49e+07 -0.20489028096199036 0.34404662251472473\n",
      "[Step 12024] Loss: 9.54e+07 -0.20483775436878204 0.3440738618373871\n",
      "[Step 12025] Loss: 9.57e+07 -0.204830601811409 0.3441002666950226\n",
      "[Step 12026] Loss: 9.62e+07 -0.2048436552286148 0.3441035747528076\n",
      "[Step 12027] Loss: 9.51e+07 -0.2047877162694931 0.34416958689689636\n",
      "[Step 12028] Loss: 9.58e+07 -0.2047520875930786 0.344195157289505\n",
      "[Step 12029] Loss: 9.55e+07 -0.20475269854068756 0.34420424699783325\n",
      "[Step 12030] Loss: 9.44e+07 -0.2046876847743988 0.344195157289505\n",
      "[Step 12031] Loss: 9.58e+07 -0.20455163717269897 0.3442091941833496\n",
      "[Step 12032] Loss: 9.46e+07 -0.20443817973136902 0.3442454934120178\n",
      "[Step 12033] Loss: 9.59e+07 -0.20429863035678864 0.3442900478839874\n",
      "[Step 12034] Loss: 9.59e+07 -0.20419329404830933 0.3443123400211334\n",
      "[Step 12035] Loss: 9.56e+07 -0.20414838194847107 0.34434863924980164\n",
      "[Step 12036] Loss: 9.53e+07 -0.20412614941596985 0.344323068857193\n",
      "[Step 12037] Loss: 9.54e+07 -0.20416931807994843 0.34431150555610657\n",
      "[Step 12038] Loss: 9.57e+07 -0.20423805713653564 0.3442826271057129\n",
      "[Step 12039] Loss: 9.54e+07 -0.20433643460273743 0.34425291419029236\n",
      "[Step 12040] Loss: 9.54e+07 -0.20446176826953888 0.3441893756389618\n",
      "[Step 12041] Loss: 9.58e+07 -0.20467175543308258 0.34414976835250854\n",
      "[Step 12042] Loss: 9.53e+07 -0.20488053560256958 0.34410110116004944\n",
      "[Step 12043] Loss: 9.64e+07 -0.2052723914384842 0.3440111577510834\n",
      "[Step 12044] Loss: 9.59e+07 -0.20567955076694489 0.34393441677093506\n",
      "[Step 12045] Loss: 9.55e+07 -0.20608967542648315 0.3438180685043335\n",
      "[Step 12046] Loss: 9.56e+07 -0.2064753770828247 0.3437429964542389\n",
      "[Step 12047] Loss: 9.51e+07 -0.20685166120529175 0.34368687868118286\n",
      "[Step 12048] Loss: 9.55e+07 -0.20725606381893158 0.3436233401298523\n",
      "[Step 12049] Loss: 9.56e+07 -0.20750828087329865 0.3435969352722168\n",
      "[Step 12050] Loss: 9.54e+07 -0.20775406062602997 0.34351029992103577\n",
      "[Step 12051] Loss: 9.55e+07 -0.2078961282968521 0.34350451827049255\n",
      "[Step 12052] Loss: 9.47e+07 -0.2080419510602951 0.3434690237045288\n",
      "[Step 12053] Loss: 9.53e+07 -0.2080620974302292 0.34349626302719116\n",
      "[Step 12054] Loss: 9.56e+07 -0.20815010368824005 0.3434847295284271\n",
      "[Step 12055] Loss: 9.53e+07 -0.20823761820793152 0.3435136079788208\n",
      "[Step 12056] Loss: 9.52e+07 -0.20833374559879303 0.3434797525405884\n",
      "[Step 12057] Loss: 9.46e+07 -0.20842847228050232 0.34347233176231384\n",
      "[Step 12058] Loss: 9.49e+07 -0.20849467813968658 0.3434731662273407\n",
      "[Step 12059] Loss: 9.56e+07 -0.2084352970123291 0.34351855516433716\n",
      "[Step 12060] Loss: 9.56e+07 -0.20835274457931519 0.34353339672088623\n",
      "[Step 12061] Loss: 9.57e+07 -0.20830115675926208 0.34356144070625305\n",
      "[Step 12062] Loss: 9.51e+07 -0.20826482772827148 0.3435787856578827\n",
      "[Step 12063] Loss: 9.53e+07 -0.20822837948799133 0.34358537197113037\n",
      "[Step 12064] Loss: 9.53e+07 -0.20819859206676483 0.34360602498054504\n",
      "[Step 12065] Loss: 9.56e+07 -0.20804324746131897 0.34367862343788147\n",
      "[Step 12066] Loss: 9.53e+07 -0.20792889595031738 0.3436984121799469\n",
      "[Step 12067] Loss: 9.54e+07 -0.2078113704919815 0.34373801946640015\n",
      "[Step 12068] Loss: 9.51e+07 -0.20773343741893768 0.34376856684684753\n",
      "[Step 12069] Loss: 9.56e+07 -0.20767742395401 0.34379827976226807\n",
      "[Step 12070] Loss: 9.51e+07 -0.2077135443687439 0.3437999188899994\n",
      "[Step 12071] Loss: 9.50e+07 -0.20765896141529083 0.34385356307029724\n",
      "[Step 12072] Loss: 9.71e+07 -0.20781786739826202 0.3438601493835449\n",
      "[Step 12073] Loss: 9.61e+07 -0.20782357454299927 0.34386757016181946\n",
      "[Step 12074] Loss: 9.48e+07 -0.20784641802310944 0.34388571977615356\n",
      "[Step 12075] Loss: 9.56e+07 -0.2078714519739151 0.34388819336891174\n",
      "[Step 12076] Loss: 9.45e+07 -0.20786108076572418 0.34387829899787903\n",
      "[Step 12077] Loss: 9.49e+07 -0.20779761672019958 0.34388571977615356\n",
      "[Step 12078] Loss: 9.54e+07 -0.2078474909067154 0.3438766598701477\n",
      "[Step 12079] Loss: 9.56e+07 -0.20794816315174103 0.34383538365364075\n",
      "[Step 12080] Loss: 9.55e+07 -0.20811542868614197 0.3437875509262085\n",
      "[Step 12081] Loss: 9.60e+07 -0.2082521766424179 0.34377267956733704\n",
      "[Step 12082] Loss: 9.64e+07 -0.20854108035564423 0.3437305986881256\n",
      "[Step 12083] Loss: 9.54e+07 -0.20880243182182312 0.34367531538009644\n",
      "[Step 12084] Loss: 9.46e+07 -0.20910866558551788 0.34359610080718994\n",
      "[Step 12085] Loss: 9.51e+07 -0.20946258306503296 0.3435094654560089\n",
      "[Step 12086] Loss: 9.48e+07 -0.20979183912277222 0.3434261381626129\n",
      "[Step 12087] Loss: 9.63e+07 -0.2100646048784256 0.3433733284473419\n",
      "[Step 12088] Loss: 9.57e+07 -0.21030953526496887 0.3433188498020172\n",
      "[Step 12089] Loss: 9.60e+07 -0.2106875330209732 0.3432214856147766\n",
      "[Step 12090] Loss: 9.65e+07 -0.21090739965438843 0.34316620230674744\n",
      "[Step 12091] Loss: 9.47e+07 -0.21113044023513794 0.34312906861305237\n",
      "[Step 12092] Loss: 9.54e+07 -0.21138300001621246 0.3430465757846832\n",
      "[Step 12093] Loss: 9.55e+07 -0.21171273291110992 0.34300529956817627\n",
      "[Step 12094] Loss: 9.58e+07 -0.2119782716035843 0.3429516851902008\n",
      "[Step 12095] Loss: 9.52e+07 -0.21230605244636536 0.3428988754749298\n",
      "[Step 12096] Loss: 9.55e+07 -0.21258573234081268 0.34283533692359924\n",
      "[Step 12097] Loss: 9.56e+07 -0.21286484599113464 0.3427487015724182\n",
      "[Step 12098] Loss: 9.52e+07 -0.2131204605102539 0.34272146224975586\n",
      "[Step 12099] Loss: 9.55e+07 -0.21331149339675903 0.34266287088394165\n",
      "[Step 12100] Loss: 9.49e+07 -0.21348074078559875 0.3426075875759125\n",
      "[Step 12101] Loss: 9.59e+07 -0.2136765867471695 0.3425638675689697\n",
      "[Step 12102] Loss: 9.51e+07 -0.21376927196979523 0.3425729274749756\n",
      "[Step 12103] Loss: 9.54e+07 -0.21380992233753204 0.3425886034965515\n",
      "[Step 12104] Loss: 9.58e+07 -0.21389800310134888 0.342581182718277\n",
      "[Step 12105] Loss: 9.58e+07 -0.21392370760440826 0.3425927460193634\n",
      "[Step 12106] Loss: 9.54e+07 -0.21389135718345642 0.342603474855423\n",
      "[Step 12107] Loss: 9.54e+07 -0.21391546726226807 0.34261253476142883\n",
      "[Step 12108] Loss: 9.58e+07 -0.21394966542720795 0.3426108956336975\n",
      "[Step 12109] Loss: 9.53e+07 -0.2140183448791504 0.34262821078300476\n",
      "[Step 12110] Loss: 9.58e+07 -0.21401193737983704 0.3426760733127594\n",
      "[Step 12111] Loss: 9.54e+07 -0.21409864723682404 0.3426521420478821\n",
      "[Step 12112] Loss: 9.57e+07 -0.21427910029888153 0.34263482689857483\n",
      "[Step 12113] Loss: 9.50e+07 -0.21443571150302887 0.34262821078300476\n",
      "[Step 12114] Loss: 9.53e+07 -0.21454675495624542 0.34262657165527344\n",
      "[Step 12115] Loss: 9.48e+07 -0.21465131640434265 0.3425902724266052\n",
      "[Step 12116] Loss: 9.62e+07 -0.21461477875709534 0.3425729274749756\n",
      "[Step 12117] Loss: 9.58e+07 -0.2145535796880722 0.34261831641197205\n",
      "[Step 12118] Loss: 9.47e+07 -0.21446429193019867 0.342659592628479\n",
      "[Step 12119] Loss: 9.55e+07 -0.2145155817270279 0.34265628457069397\n",
      "[Step 12120] Loss: 9.58e+07 -0.21441924571990967 0.3426579236984253\n",
      "[Step 12121] Loss: 9.61e+07 -0.2144218385219574 0.34266865253448486\n",
      "[Step 12122] Loss: 9.48e+07 -0.21434226632118225 0.34269917011260986\n",
      "[Step 12123] Loss: 9.55e+07 -0.2142607867717743 0.3426966965198517\n",
      "[Step 12124] Loss: 9.51e+07 -0.2142663598060608 0.3427165150642395\n",
      "[Step 12125] Loss: 9.59e+07 -0.2142508178949356 0.34270742535591125\n",
      "[Step 12126] Loss: 9.50e+07 -0.2142588496208191 0.3426843285560608\n",
      "[Step 12127] Loss: 9.57e+07 -0.21423488855361938 0.34271156787872314\n",
      "[Step 12128] Loss: 9.57e+07 -0.21421648561954498 0.3427181541919708\n",
      "[Step 12129] Loss: 9.53e+07 -0.21428704261779785 0.3427066206932068\n",
      "[Step 12130] Loss: 9.56e+07 -0.2144978940486908 0.3426719605922699\n",
      "[Step 12131] Loss: 9.57e+07 -0.21463097631931305 0.3426702916622162\n",
      "[Step 12132] Loss: 9.61e+07 -0.21466577053070068 0.34266701340675354\n",
      "[Step 12133] Loss: 9.65e+07 -0.21451148390769958 0.34269505739212036\n",
      "[Step 12134] Loss: 9.52e+07 -0.2144458293914795 0.34268680214881897\n",
      "[Step 12135] Loss: 9.61e+07 -0.21426060795783997 0.3427453935146332\n",
      "[Step 12136] Loss: 9.54e+07 -0.2140844762325287 0.3428097665309906\n",
      "[Step 12137] Loss: 9.54e+07 -0.21388156712055206 0.34287741780281067\n",
      "[Step 12138] Loss: 9.53e+07 -0.21384429931640625 0.34289225935935974\n",
      "[Step 12139] Loss: 9.54e+07 -0.21393370628356934 0.34289804100990295\n",
      "[Step 12140] Loss: 9.67e+07 -0.2139507383108139 0.342912882566452\n",
      "[Step 12141] Loss: 9.55e+07 -0.21392570436000824 0.3429335355758667\n",
      "[Step 12142] Loss: 9.54e+07 -0.21385525166988373 0.3429376482963562\n",
      "[Step 12143] Loss: 9.55e+07 -0.21374830603599548 0.34297066926956177\n",
      "[Step 12144] Loss: 9.58e+07 -0.21360062062740326 0.34303170442581177\n",
      "[Step 12145] Loss: 9.57e+07 -0.21352490782737732 0.3430515229701996\n",
      "[Step 12146] Loss: 9.48e+07 -0.2134593278169632 0.3430837094783783\n",
      "[Step 12147] Loss: 9.57e+07 -0.21346677839756012 0.34308451414108276\n",
      "[Step 12148] Loss: 9.51e+07 -0.21349689364433289 0.343093603849411\n",
      "[Step 12149] Loss: 9.53e+07 -0.21352440118789673 0.3430696725845337\n",
      "[Step 12150] Loss: 9.55e+07 -0.21361424028873444 0.3430209755897522\n",
      "[Step 12151] Loss: 9.56e+07 -0.21371161937713623 0.34299129247665405\n",
      "[Step 12152] Loss: 9.56e+07 -0.21386227011680603 0.3429360091686249\n",
      "[Step 12153] Loss: 9.54e+07 -0.2139585167169571 0.342912882566452\n",
      "[Step 12154] Loss: 9.55e+07 -0.21412056684494019 0.34289804100990295\n",
      "[Step 12155] Loss: 9.52e+07 -0.21436862647533417 0.34281471371650696\n",
      "[Step 12156] Loss: 9.63e+07 -0.21478182077407837 0.3427371382713318\n",
      "[Step 12157] Loss: 9.59e+07 -0.2151453197002411 0.34264060854911804\n",
      "[Step 12158] Loss: 9.56e+07 -0.21544630825519562 0.3425869643688202\n",
      "[Step 12159] Loss: 9.52e+07 -0.21572817862033844 0.34252920746803284\n",
      "[Step 12160] Loss: 9.55e+07 -0.21597501635551453 0.3424574136734009\n",
      "[Step 12161] Loss: 9.54e+07 -0.21611551940441132 0.34240707755088806\n",
      "[Step 12162] Loss: 9.58e+07 -0.21621550619602203 0.34238314628601074\n",
      "[Step 12163] Loss: 9.73e+07 -0.21656250953674316 0.3423105478286743\n",
      "[Step 12164] Loss: 9.59e+07 -0.21696674823760986 0.3422156572341919\n",
      "[Step 12165] Loss: 9.55e+07 -0.21736501157283783 0.34212735295295715\n",
      "[Step 12166] Loss: 9.64e+07 -0.2179296761751175 0.34199532866477966\n",
      "[Step 12167] Loss: 9.61e+07 -0.21854045987129211 0.3418790102005005\n",
      "[Step 12168] Loss: 9.64e+07 -0.2191685438156128 0.341724693775177\n",
      "[Step 12169] Loss: 9.54e+07 -0.21961629390716553 0.3416232168674469\n",
      "[Step 12170] Loss: 9.64e+07 -0.2199050337076187 0.3415580093860626\n",
      "[Step 12171] Loss: 9.57e+07 -0.22013142704963684 0.34149861335754395\n",
      "[Step 12172] Loss: 9.53e+07 -0.2203560769557953 0.3414367139339447\n",
      "[Step 12173] Loss: 9.53e+07 -0.22066091001033783 0.3413335978984833\n",
      "[Step 12174] Loss: 9.51e+07 -0.2209545373916626 0.34121888875961304\n",
      "[Step 12175] Loss: 9.62e+07 -0.22138021886348724 0.34111741185188293\n",
      "[Step 12176] Loss: 9.48e+07 -0.2217104285955429 0.3410670757293701\n",
      "[Step 12177] Loss: 9.51e+07 -0.22206635773181915 0.3410192131996155\n",
      "[Step 12178] Loss: 9.53e+07 -0.22241634130477905 0.3409358561038971\n",
      "[Step 12179] Loss: 9.60e+07 -0.2228318452835083 0.3408409655094147\n",
      "[Step 12180] Loss: 9.56e+07 -0.2231960892677307 0.3407692015171051\n",
      "[Step 12181] Loss: 9.51e+07 -0.22356167435646057 0.3406842052936554\n",
      "[Step 12182] Loss: 9.54e+07 -0.22392940521240234 0.34059590101242065\n",
      "[Step 12183] Loss: 9.56e+07 -0.22433550655841827 0.3405101001262665\n",
      "[Step 12184] Loss: 9.79e+07 -0.22507165372371674 0.3403393030166626\n",
      "[Step 12185] Loss: 9.54e+07 -0.22576391696929932 0.34020066261291504\n",
      "[Step 12186] Loss: 9.50e+07 -0.2264060527086258 0.34009256958961487\n",
      "[Step 12187] Loss: 9.47e+07 -0.22694355249404907 0.33997952938079834\n",
      "[Step 12188] Loss: 9.48e+07 -0.22750668227672577 0.3398928940296173\n",
      "[Step 12189] Loss: 9.56e+07 -0.2280544489622116 0.33977821469306946\n",
      "[Step 12190] Loss: 9.52e+07 -0.22853493690490723 0.3396453559398651\n",
      "[Step 12191] Loss: 9.60e+07 -0.22901155054569244 0.339571088552475\n",
      "[Step 12192] Loss: 9.55e+07 -0.22945795953273773 0.33950260281562805\n",
      "[Step 12193] Loss: 9.69e+07 -0.22999300062656403 0.33938542008399963\n",
      "[Step 12194] Loss: 9.56e+07 -0.23039014637470245 0.3393235504627228\n",
      "[Step 12195] Loss: 9.50e+07 -0.23079320788383484 0.3392641544342041\n",
      "[Step 12196] Loss: 9.55e+07 -0.23119878768920898 0.33919236063957214\n",
      "[Step 12197] Loss: 9.56e+07 -0.23161785304546356 0.3391288220882416\n",
      "[Step 12198] Loss: 9.48e+07 -0.231998473405838 0.33910074830055237\n",
      "[Step 12199] Loss: 9.48e+07 -0.2323848456144333 0.33902978897094727\n",
      "[Step 12200] Loss: 9.55e+07 -0.23274347186088562 0.3389761745929718\n",
      "[Step 12201] Loss: 9.56e+07 -0.2331191599369049 0.3388672471046448\n",
      "[Step 12202] Loss: 9.56e+07 -0.23346655070781708 0.3388358950614929\n",
      "[Step 12203] Loss: 9.56e+07 -0.23378559947013855 0.3387434780597687\n",
      "[Step 12204] Loss: 9.53e+07 -0.23408348858356476 0.33865848183631897\n",
      "[Step 12205] Loss: 9.50e+07 -0.23433464765548706 0.33858999609947205\n",
      "[Step 12206] Loss: 9.57e+07 -0.2345166951417923 0.33855533599853516\n",
      "[Step 12207] Loss: 9.53e+07 -0.23461338877677917 0.33853718638420105\n",
      "[Step 12208] Loss: 9.54e+07 -0.2347242832183838 0.3384909927845001\n",
      "[Step 12209] Loss: 9.51e+07 -0.2348068803548813 0.3384810984134674\n",
      "[Step 12210] Loss: 9.52e+07 -0.23484259843826294 0.3385116159915924\n",
      "[Step 12211] Loss: 9.54e+07 -0.2348162680864334 0.33851078152656555\n",
      "[Step 12212] Loss: 9.63e+07 -0.23468893766403198 0.33853965997695923\n",
      "[Step 12213] Loss: 9.57e+07 -0.23444274067878723 0.3385702073574066\n",
      "[Step 12214] Loss: 9.55e+07 -0.23434291779994965 0.3386287987232208\n",
      "[Step 12215] Loss: 9.49e+07 -0.23422610759735107 0.3386535346508026\n",
      "[Step 12216] Loss: 9.59e+07 -0.23402710258960724 0.33871376514434814\n",
      "[Step 12217] Loss: 9.46e+07 -0.23392075300216675 0.33875584602355957\n",
      "[Step 12218] Loss: 9.55e+07 -0.23375774919986725 0.33878061175346375\n",
      "[Step 12219] Loss: 9.63e+07 -0.23378656804561615 0.3387698829174042\n",
      "[Step 12220] Loss: 9.52e+07 -0.2338338941335678 0.33877813816070557\n",
      "[Step 12221] Loss: 9.61e+07 -0.23383206129074097 0.33881279826164246\n",
      "[Step 12222] Loss: 9.53e+07 -0.23389935493469238 0.33881279826164246\n",
      "[Step 12223] Loss: 9.51e+07 -0.23394763469696045 0.3387962877750397\n",
      "[Step 12224] Loss: 9.57e+07 -0.23407840728759766 0.33877071738243103\n",
      "[Step 12225] Loss: 9.57e+07 -0.23415161669254303 0.33875009417533875\n",
      "[Step 12226] Loss: 9.53e+07 -0.23421505093574524 0.33875009417533875\n",
      "[Step 12227] Loss: 9.60e+07 -0.2341081202030182 0.3387962877750397\n",
      "[Step 12228] Loss: 9.55e+07 -0.23395174741744995 0.3388788104057312\n",
      "[Step 12229] Loss: 9.55e+07 -0.23386171460151672 0.3388771414756775\n",
      "[Step 12230] Loss: 9.49e+07 -0.23369131982326508 0.3389415144920349\n",
      "[Step 12231] Loss: 9.60e+07 -0.23343990743160248 0.3390066921710968\n",
      "[Step 12232] Loss: 9.51e+07 -0.2332388162612915 0.33909085392951965\n",
      "[Step 12233] Loss: 9.50e+07 -0.2330203503370285 0.33915191888809204\n",
      "[Step 12234] Loss: 9.44e+07 -0.23278625309467316 0.3392113447189331\n",
      "[Step 12235] Loss: 9.56e+07 -0.2324647605419159 0.3392905294895172\n",
      "[Step 12236] Loss: 9.64e+07 -0.2322636842727661 0.3393515944480896\n",
      "[Step 12237] Loss: 9.54e+07 -0.23210546374320984 0.33939698338508606\n",
      "[Step 12238] Loss: 9.52e+07 -0.23186415433883667 0.33949682116508484\n",
      "[Step 12239] Loss: 9.49e+07 -0.23163913190364838 0.3395578861236572\n",
      "[Step 12240] Loss: 9.67e+07 -0.23128493130207062 0.3396230638027191\n",
      "[Step 12241] Loss: 9.50e+07 -0.2308594435453415 0.33972373604774475\n",
      "[Step 12242] Loss: 9.52e+07 -0.23042398691177368 0.3398186266422272\n",
      "[Step 12243] Loss: 9.51e+07 -0.2300255447626114 0.33993828296661377\n",
      "[Step 12244] Loss: 9.50e+07 -0.22964142262935638 0.34002575278282166\n",
      "[Step 12245] Loss: 9.51e+07 -0.2293270230293274 0.3400777280330658\n",
      "[Step 12246] Loss: 9.54e+07 -0.22898726165294647 0.3401651978492737\n",
      "[Step 12247] Loss: 9.57e+07 -0.2287086844444275 0.3402138650417328\n",
      "[Step 12248] Loss: 9.56e+07 -0.22842808067798615 0.34030380845069885\n",
      "[Step 12249] Loss: 9.57e+07 -0.228287011384964 0.340328574180603\n",
      "[Step 12250] Loss: 9.51e+07 -0.2282283455133438 0.3403756022453308\n",
      "[Step 12251] Loss: 9.60e+07 -0.22828912734985352 0.34037312865257263\n",
      "[Step 12252] Loss: 9.55e+07 -0.22846831381320953 0.3403376340866089\n",
      "[Step 12253] Loss: 9.50e+07 -0.2287110537290573 0.3402906060218811\n",
      "[Step 12254] Loss: 9.57e+07 -0.2288491278886795 0.3402625620365143\n",
      "[Step 12255] Loss: 9.49e+07 -0.22903582453727722 0.3402031362056732\n",
      "[Step 12256] Loss: 9.52e+07 -0.2292233556509018 0.3401643633842468\n",
      "[Step 12257] Loss: 9.58e+07 -0.22940942645072937 0.3401544690132141\n",
      "[Step 12258] Loss: 9.48e+07 -0.22962814569473267 0.3401181697845459\n",
      "[Step 12259] Loss: 9.47e+07 -0.22989094257354736 0.340080201625824\n",
      "[Step 12260] Loss: 9.56e+07 -0.2300334870815277 0.34007441997528076\n",
      "[Step 12261] Loss: 9.46e+07 -0.23014973104000092 0.34004223346710205\n",
      "[Step 12262] Loss: 9.52e+07 -0.2302403450012207 0.34001582860946655\n",
      "[Step 12263] Loss: 9.60e+07 -0.23046709597110748 0.3400108814239502\n",
      "[Step 12264] Loss: 9.54e+07 -0.23077188432216644 0.3399679958820343\n",
      "[Step 12265] Loss: 9.57e+07 -0.23104149103164673 0.3399011492729187\n",
      "[Step 12266] Loss: 9.54e+07 -0.2313915640115738 0.3398400843143463\n",
      "[Step 12267] Loss: 9.65e+07 -0.23186998069286346 0.33974024653434753\n",
      "[Step 12268] Loss: 9.48e+07 -0.23229765892028809 0.3396453559398651\n",
      "[Step 12269] Loss: 9.51e+07 -0.23273250460624695 0.33956778049468994\n",
      "[Step 12270] Loss: 9.56e+07 -0.233053058385849 0.33946794271469116\n",
      "[Step 12271] Loss: 9.57e+07 -0.23344342410564423 0.3393714129924774\n",
      "[Step 12272] Loss: 9.45e+07 -0.2338557243347168 0.33930787444114685\n",
      "[Step 12273] Loss: 9.50e+07 -0.23417381942272186 0.3392806351184845\n",
      "[Step 12274] Loss: 9.63e+07 -0.23463605344295502 0.33922454714775085\n",
      "[Step 12275] Loss: 9.56e+07 -0.23499299585819244 0.33917585015296936\n",
      "[Step 12276] Loss: 9.49e+07 -0.23534660041332245 0.3391098380088806\n",
      "[Step 12277] Loss: 9.54e+07 -0.23560620844364166 0.3390751779079437\n",
      "[Step 12278] Loss: 9.51e+07 -0.23586080968379974 0.33901989459991455\n",
      "[Step 12279] Loss: 9.57e+07 -0.23599876463413239 0.33901247382164\n",
      "[Step 12280] Loss: 9.57e+07 -0.23615136742591858 0.33897534012794495\n",
      "[Step 12281] Loss: 9.54e+07 -0.2363128364086151 0.33891016244888306\n",
      "[Step 12282] Loss: 9.49e+07 -0.23639047145843506 0.33892667293548584\n",
      "[Step 12283] Loss: 9.60e+07 -0.2363547533750534 0.3389316201210022\n",
      "[Step 12284] Loss: 9.49e+07 -0.23632077872753143 0.33895471692085266\n",
      "[Step 12285] Loss: 9.50e+07 -0.23626656830310822 0.33897697925567627\n",
      "[Step 12286] Loss: 9.51e+07 -0.23625589907169342 0.338959664106369\n",
      "[Step 12287] Loss: 9.60e+07 -0.23609761893749237 0.33901247382164\n",
      "[Step 12288] Loss: 9.53e+07 -0.2359590232372284 0.3390388786792755\n",
      "[Step 12289] Loss: 9.49e+07 -0.2357528805732727 0.33907270431518555\n",
      "[Step 12290] Loss: 9.44e+07 -0.23556452989578247 0.33910325169563293\n",
      "[Step 12291] Loss: 9.61e+07 -0.23551926016807556 0.33912715315818787\n",
      "[Step 12292] Loss: 9.51e+07 -0.23540686070919037 0.33916348218917847\n",
      "[Step 12293] Loss: 9.55e+07 -0.2353532463312149 0.3391832709312439\n",
      "[Step 12294] Loss: 9.49e+07 -0.2352995127439499 0.33923524618148804\n",
      "[Step 12295] Loss: 9.56e+07 -0.2353505939245224 0.3392038941383362\n",
      "[Step 12296] Loss: 9.51e+07 -0.2354896068572998 0.3391874134540558\n",
      "[Step 12297] Loss: 9.61e+07 -0.23548643290996552 0.3391832709312439\n",
      "[Step 12298] Loss: 9.62e+07 -0.2353927493095398 0.33921298384666443\n",
      "[Step 12299] Loss: 9.43e+07 -0.2353203445672989 0.33921709656715393\n",
      "[Step 12300] Loss: 9.50e+07 -0.23523487150669098 0.33920472860336304\n",
      "[Step 12301] Loss: 9.57e+07 -0.23521387577056885 0.3391989469528198\n",
      "[Step 12302] Loss: 9.55e+07 -0.23524031043052673 0.3391849398612976\n",
      "[Step 12303] Loss: 9.52e+07 -0.2353041023015976 0.3391543924808502\n",
      "[Step 12304] Loss: 9.57e+07 -0.23533540964126587 0.33912965655326843\n",
      "[Step 12305] Loss: 9.53e+07 -0.23553313314914703 0.339065283536911\n",
      "[Step 12306] Loss: 9.50e+07 -0.23576973378658295 0.3390066921710968\n",
      "[Step 12307] Loss: 9.50e+07 -0.23597261309623718 0.33893489837646484\n",
      "[Step 12308] Loss: 9.57e+07 -0.2362189143896103 0.3388400077819824\n",
      "[Step 12309] Loss: 9.50e+07 -0.2364564836025238 0.33877483010292053\n",
      "[Step 12310] Loss: 9.58e+07 -0.2368285357952118 0.33868077397346497\n",
      "[Step 12311] Loss: 9.55e+07 -0.23706752061843872 0.33861228823661804\n",
      "[Step 12312] Loss: 9.60e+07 -0.23711729049682617 0.33860650658607483\n",
      "[Step 12313] Loss: 9.55e+07 -0.23722542822360992 0.3385743200778961\n",
      "[Step 12314] Loss: 9.60e+07 -0.23734904825687408 0.3385017216205597\n",
      "[Step 12315] Loss: 9.53e+07 -0.23755639791488647 0.33845055103302\n",
      "[Step 12316] Loss: 9.47e+07 -0.23775406181812286 0.3383738100528717\n",
      "[Step 12317] Loss: 9.61e+07 -0.23802891373634338 0.3382962644100189\n",
      "[Step 12318] Loss: 9.60e+07 -0.23821121454238892 0.3382566571235657\n",
      "[Step 12319] Loss: 9.50e+07 -0.23831744492053986 0.3382261097431183\n",
      "[Step 12320] Loss: 9.51e+07 -0.2384749799966812 0.3381989002227783\n",
      "[Step 12321] Loss: 9.53e+07 -0.23866364359855652 0.33817824721336365\n",
      "[Step 12322] Loss: 9.52e+07 -0.23888836801052094 0.33814525604248047\n",
      "[Step 12323] Loss: 9.55e+07 -0.23903454840183258 0.3381328880786896\n",
      "[Step 12324] Loss: 9.52e+07 -0.23910747468471527 0.3381592929363251\n",
      "[Step 12325] Loss: 9.51e+07 -0.2391432523727417 0.3381889760494232\n",
      "[Step 12326] Loss: 9.61e+07 -0.2390183061361313 0.3382013738155365\n",
      "[Step 12327] Loss: 9.46e+07 -0.23889027535915375 0.33825913071632385\n",
      "[Step 12328] Loss: 9.57e+07 -0.2386540025472641 0.33831605315208435\n",
      "[Step 12329] Loss: 9.51e+07 -0.2383732795715332 0.33840104937553406\n",
      "[Step 12330] Loss: 9.57e+07 -0.23803654313087463 0.3384992480278015\n",
      "[Step 12331] Loss: 9.49e+07 -0.2377396672964096 0.3385685384273529\n",
      "[Step 12332] Loss: 9.45e+07 -0.23741558194160461 0.3386593163013458\n",
      "[Step 12333] Loss: 9.51e+07 -0.2370009422302246 0.33878061175346375\n",
      "[Step 12334] Loss: 9.67e+07 -0.23686087131500244 0.33881691098213196\n",
      "[Step 12335] Loss: 9.47e+07 -0.2366933673620224 0.33883342146873474\n",
      "[Step 12336] Loss: 9.56e+07 -0.23662246763706207 0.3388499319553375\n",
      "[Step 12337] Loss: 9.56e+07 -0.23654530942440033 0.33889034390449524\n",
      "[Step 12338] Loss: 9.59e+07 -0.23658519983291626 0.3388647735118866\n",
      "[Step 12339] Loss: 9.56e+07 -0.23664742708206177 0.33883094787597656\n",
      "[Step 12340] Loss: 9.53e+07 -0.2367662936449051 0.3388094902038574\n",
      "[Step 12341] Loss: 9.55e+07 -0.236866757273674 0.3387690484523773\n",
      "[Step 12342] Loss: 9.44e+07 -0.23694849014282227 0.33875420689582825\n",
      "[Step 12343] Loss: 9.50e+07 -0.2371305376291275 0.3387327492237091\n",
      "[Step 12344] Loss: 9.43e+07 -0.23726895451545715 0.33868902921676636\n",
      "[Step 12345] Loss: 9.51e+07 -0.2374291867017746 0.3386642634868622\n",
      "[Step 12346] Loss: 9.47e+07 -0.2375800907611847 0.33862796425819397\n",
      "[Step 12347] Loss: 9.58e+07 -0.2377387434244156 0.33861061930656433\n",
      "[Step 12348] Loss: 9.60e+07 -0.23789691925048828 0.33856111764907837\n",
      "[Step 12349] Loss: 9.55e+07 -0.2380586713552475 0.33852893114089966\n",
      "[Step 12350] Loss: 9.47e+07 -0.23816782236099243 0.33850252628326416\n",
      "[Step 12351] Loss: 9.60e+07 -0.23841002583503723 0.3384290933609009\n",
      "[Step 12352] Loss: 9.56e+07 -0.23868753015995026 0.33838289976119995\n",
      "[Step 12353] Loss: 9.46e+07 -0.23891675472259521 0.3383193612098694\n",
      "[Step 12354] Loss: 9.48e+07 -0.23909611999988556 0.33829954266548157\n",
      "[Step 12355] Loss: 9.55e+07 -0.23917031288146973 0.3382987380027771\n",
      "[Step 12356] Loss: 9.50e+07 -0.23920473456382751 0.33829542994499207\n",
      "[Step 12357] Loss: 9.55e+07 -0.23920226097106934 0.3382987380027771\n",
      "[Step 12358] Loss: 9.54e+07 -0.2392703741788864 0.3382904827594757\n",
      "[Step 12359] Loss: 9.57e+07 -0.23936021327972412 0.33828139305114746\n",
      "[Step 12360] Loss: 9.63e+07 -0.23967237770557404 0.3382434546947479\n",
      "[Step 12361] Loss: 9.54e+07 -0.23995472490787506 0.33819064497947693\n",
      "[Step 12362] Loss: 9.53e+07 -0.2401692122220993 0.3381724953651428\n",
      "[Step 12363] Loss: 9.54e+07 -0.24035942554473877 0.3381592929363251\n",
      "[Step 12364] Loss: 9.53e+07 -0.2405112087726593 0.3381468951702118\n",
      "[Step 12365] Loss: 9.49e+07 -0.2406933307647705 0.338096559047699\n",
      "[Step 12366] Loss: 9.52e+07 -0.2408391684293747 0.3380594253540039\n",
      "[Step 12367] Loss: 9.49e+07 -0.24096448719501495 0.3380223214626312\n",
      "[Step 12368] Loss: 9.57e+07 -0.24102988839149475 0.33803054690361023\n",
      "[Step 12369] Loss: 9.54e+07 -0.24115440249443054 0.3380066454410553\n",
      "[Step 12370] Loss: 9.54e+07 -0.24125736951828003 0.3379959166049957\n",
      "[Step 12371] Loss: 9.52e+07 -0.24143105745315552 0.3379703164100647\n",
      "[Step 12372] Loss: 9.54e+07 -0.24157416820526123 0.33792081475257874\n",
      "[Step 12373] Loss: 9.55e+07 -0.2417268604040146 0.3378845155239105\n",
      "[Step 12374] Loss: 9.53e+07 -0.24192437529563904 0.3378663659095764\n",
      "[Step 12375] Loss: 9.61e+07 -0.24208863079547882 0.33784985542297363\n",
      "[Step 12376] Loss: 9.56e+07 -0.24237222969532013 0.33780282735824585\n",
      "[Step 12377] Loss: 9.45e+07 -0.2425844371318817 0.3377392888069153\n",
      "[Step 12378] Loss: 9.55e+07 -0.24285198748111725 0.3376518189907074\n",
      "[Step 12379] Loss: 9.50e+07 -0.2430834174156189 0.3376155197620392\n",
      "[Step 12380] Loss: 9.59e+07 -0.24321721494197845 0.3375660181045532\n",
      "[Step 12381] Loss: 9.53e+07 -0.2433512955904007 0.3375239372253418\n",
      "[Step 12382] Loss: 9.60e+07 -0.24363483488559723 0.33742985129356384\n",
      "[Step 12383] Loss: 9.56e+07 -0.24403391778469086 0.337345689535141\n",
      "[Step 12384] Loss: 9.47e+07 -0.24437597393989563 0.33723101019859314\n",
      "[Step 12385] Loss: 9.60e+07 -0.24476337432861328 0.3371633291244507\n",
      "[Step 12386] Loss: 9.51e+07 -0.24518555402755737 0.3370758891105652\n",
      "[Step 12387] Loss: 9.53e+07 -0.24556416273117065 0.3370090425014496\n",
      "[Step 12388] Loss: 9.50e+07 -0.24591949582099915 0.33695706725120544\n",
      "[Step 12389] Loss: 9.56e+07 -0.24627166986465454 0.3368794918060303\n",
      "[Step 12390] Loss: 9.50e+07 -0.24660491943359375 0.33680111169815063\n",
      "[Step 12391] Loss: 9.51e+07 -0.24684256315231323 0.33674004673957825\n",
      "[Step 12392] Loss: 9.53e+07 -0.2471282184123993 0.3367144763469696\n",
      "[Step 12393] Loss: 9.54e+07 -0.2473590224981308 0.3366756737232208\n",
      "[Step 12394] Loss: 9.53e+07 -0.24752014875411987 0.3366418480873108\n",
      "[Step 12395] Loss: 9.59e+07 -0.24768874049186707 0.3366278409957886\n",
      "[Step 12396] Loss: 9.63e+07 -0.24774311482906342 0.33660638332366943\n",
      "[Step 12397] Loss: 9.45e+07 -0.24775247275829315 0.33658161759376526\n",
      "[Step 12398] Loss: 9.60e+07 -0.24765470623970032 0.33662039041519165\n",
      "[Step 12399] Loss: 9.56e+07 -0.24751438200473785 0.33667320013046265\n",
      "[Step 12400] Loss: 9.63e+07 -0.24729475378990173 0.33674415946006775\n",
      "[Step 12401] Loss: 9.52e+07 -0.24712926149368286 0.33677881956100464\n",
      "[Step 12402] Loss: 9.64e+07 -0.2468019723892212 0.33687537908554077\n",
      "[Step 12403] Loss: 9.56e+07 -0.24652612209320068 0.33690589666366577\n",
      "[Step 12404] Loss: 9.57e+07 -0.2463834434747696 0.3369075357913971\n",
      "[Step 12405] Loss: 9.58e+07 -0.24618984758853912 0.33695870637893677\n",
      "[Step 12406] Loss: 9.53e+07 -0.24586987495422363 0.3370271921157837\n",
      "[Step 12407] Loss: 9.47e+07 -0.24560882151126862 0.33706843852996826\n",
      "[Step 12408] Loss: 9.56e+07 -0.24541713297367096 0.3371204435825348\n",
      "[Step 12409] Loss: 9.56e+07 -0.2451581507921219 0.33718231320381165\n",
      "[Step 12410] Loss: 9.57e+07 -0.24481061100959778 0.33723926544189453\n",
      "[Step 12411] Loss: 9.49e+07 -0.24455252289772034 0.33729371428489685\n",
      "[Step 12412] Loss: 9.60e+07 -0.24443857371807098 0.33733415603637695\n",
      "[Step 12413] Loss: 9.49e+07 -0.24426740407943726 0.3373696208000183\n",
      "[Step 12414] Loss: 9.53e+07 -0.24414542317390442 0.33740344643592834\n",
      "[Step 12415] Loss: 9.52e+07 -0.2440505027770996 0.3374768793582916\n",
      "[Step 12416] Loss: 9.47e+07 -0.2438865602016449 0.3375214636325836\n",
      "[Step 12417] Loss: 9.46e+07 -0.24375160038471222 0.33755776286125183\n",
      "[Step 12418] Loss: 9.46e+07 -0.24369752407073975 0.3376270532608032\n",
      "[Step 12419] Loss: 9.56e+07 -0.24374236166477203 0.3376674950122833\n",
      "[Step 12420] Loss: 9.51e+07 -0.24381490051746368 0.33767905831336975\n",
      "[Step 12421] Loss: 9.52e+07 -0.2439289540052414 0.33770298957824707\n",
      "[Step 12422] Loss: 9.49e+07 -0.2439642995595932 0.3377227783203125\n",
      "[Step 12423] Loss: 9.60e+07 -0.24403786659240723 0.3377310335636139\n",
      "[Step 12424] Loss: 9.58e+07 -0.24406388401985168 0.3377409279346466\n",
      "[Step 12425] Loss: 9.50e+07 -0.24417267739772797 0.33775249123573303\n",
      "[Step 12426] Loss: 9.51e+07 -0.2442578226327896 0.33772194385528564\n",
      "[Step 12427] Loss: 9.57e+07 -0.24430835247039795 0.3377343416213989\n",
      "[Step 12428] Loss: 9.53e+07 -0.24431833624839783 0.3377351462841034\n",
      "[Step 12429] Loss: 9.60e+07 -0.2442544847726822 0.3377739489078522\n",
      "[Step 12430] Loss: 9.49e+07 -0.24422425031661987 0.33775249123573303\n",
      "[Step 12431] Loss: 9.49e+07 -0.24417953193187714 0.3377574384212494\n",
      "[Step 12432] Loss: 9.60e+07 -0.24398165941238403 0.3377995193004608\n",
      "[Step 12433] Loss: 9.48e+07 -0.24379202723503113 0.33782675862312317\n",
      "[Step 12434] Loss: 9.56e+07 -0.24367155134677887 0.3378911018371582\n",
      "[Step 12435] Loss: 9.54e+07 -0.243468776345253 0.3379480540752411\n",
      "[Step 12436] Loss: 9.55e+07 -0.24333219230175018 0.337990939617157\n",
      "[Step 12437] Loss: 9.56e+07 -0.2432357519865036 0.3380330204963684\n",
      "[Step 12438] Loss: 9.51e+07 -0.2431473433971405 0.33806687593460083\n",
      "[Step 12439] Loss: 9.49e+07 -0.24303428828716278 0.33809903264045715\n",
      "[Step 12440] Loss: 9.54e+07 -0.24284425377845764 0.33814194798469543\n",
      "[Step 12441] Loss: 9.58e+07 -0.24251803755760193 0.33819064497947693\n",
      "[Step 12442] Loss: 9.62e+07 -0.24207951128482819 0.33823931217193604\n",
      "[Step 12443] Loss: 9.56e+07 -0.24166962504386902 0.33834409713745117\n",
      "[Step 12444] Loss: 9.54e+07 -0.24126476049423218 0.3384282886981964\n",
      "[Step 12445] Loss: 9.55e+07 -0.24094334244728088 0.33848685026168823\n",
      "[Step 12446] Loss: 9.57e+07 -0.2406691461801529 0.3385116159915924\n",
      "[Step 12447] Loss: 9.58e+07 -0.24024510383605957 0.33859577775001526\n",
      "[Step 12448] Loss: 9.65e+07 -0.2400425225496292 0.3386461138725281\n",
      "[Step 12449] Loss: 9.58e+07 -0.23974083364009857 0.3387005627155304\n",
      "[Step 12450] Loss: 9.52e+07 -0.2394639253616333 0.3387839198112488\n",
      "[Step 12451] Loss: 9.57e+07 -0.2391471564769745 0.3388400077819824\n",
      "[Step 12452] Loss: 9.55e+07 -0.23883329331874847 0.33890438079833984\n",
      "[Step 12453] Loss: 9.55e+07 -0.2385907769203186 0.33894068002700806\n",
      "[Step 12454] Loss: 9.52e+07 -0.2383391112089157 0.3390009105205536\n",
      "[Step 12455] Loss: 9.55e+07 -0.23819829523563385 0.33903971314430237\n",
      "[Step 12456] Loss: 9.52e+07 -0.23807141184806824 0.3390578627586365\n",
      "[Step 12457] Loss: 9.51e+07 -0.2378556877374649 0.33909332752227783\n",
      "[Step 12458] Loss: 9.54e+07 -0.23767417669296265 0.33912965655326843\n",
      "[Step 12459] Loss: 9.53e+07 -0.2375984936952591 0.3391123116016388\n",
      "[Step 12460] Loss: 9.64e+07 -0.23739510774612427 0.33916759490966797\n",
      "[Step 12461] Loss: 9.67e+07 -0.23734989762306213 0.33919399976730347\n",
      "[Step 12462] Loss: 9.55e+07 -0.23735840618610382 0.3392121493816376\n",
      "[Step 12463] Loss: 9.54e+07 -0.23739193379878998 0.3392055630683899\n",
      "[Step 12464] Loss: 9.51e+07 -0.23736132681369781 0.33920061588287354\n",
      "[Step 12465] Loss: 9.53e+07 -0.23728899657726288 0.33920472860336304\n",
      "[Step 12466] Loss: 9.54e+07 -0.23719647526741028 0.3392253518104553\n",
      "[Step 12467] Loss: 9.52e+07 -0.23705396056175232 0.3392377495765686\n",
      "[Step 12468] Loss: 9.62e+07 -0.23678623139858246 0.33928558230400085\n",
      "[Step 12469] Loss: 9.50e+07 -0.2364838868379593 0.3393433392047882\n",
      "[Step 12470] Loss: 9.50e+07 -0.23630540072917938 0.3393672704696655\n",
      "[Step 12471] Loss: 9.57e+07 -0.2360454648733139 0.3394242227077484\n",
      "[Step 12472] Loss: 9.48e+07 -0.23579995334148407 0.3394828140735626\n",
      "[Step 12473] Loss: 9.53e+07 -0.23574508726596832 0.33950260281562805\n",
      "[Step 12474] Loss: 9.57e+07 -0.23577262461185455 0.33952653408050537\n",
      "[Step 12475] Loss: 9.50e+07 -0.23579783737659454 0.3395339548587799\n",
      "[Step 12476] Loss: 9.46e+07 -0.23583878576755524 0.3395281732082367\n",
      "[Step 12477] Loss: 9.49e+07 -0.23600946366786957 0.3395141661167145\n",
      "[Step 12478] Loss: 9.57e+07 -0.23604582250118256 0.33953890204429626\n",
      "[Step 12479] Loss: 9.45e+07 -0.2360636591911316 0.33953148126602173\n",
      "[Step 12480] Loss: 9.51e+07 -0.2361544519662857 0.3395281732082367\n",
      "[Step 12481] Loss: 9.56e+07 -0.23619221150875092 0.33955129981040955\n",
      "[Step 12482] Loss: 9.60e+07 -0.23621544241905212 0.33957770466804504\n",
      "[Step 12483] Loss: 9.70e+07 -0.2364615648984909 0.33952900767326355\n",
      "[Step 12484] Loss: 9.74e+07 -0.23693965375423431 0.3394225537776947\n",
      "[Step 12485] Loss: 9.54e+07 -0.2374410480260849 0.339332640171051\n",
      "[Step 12486] Loss: 9.53e+07 -0.2378840446472168 0.3392624855041504\n",
      "[Step 12487] Loss: 9.51e+07 -0.2382083237171173 0.3391626477241516\n",
      "[Step 12488] Loss: 9.60e+07 -0.23853306472301483 0.33912551403045654\n",
      "[Step 12489] Loss: 9.49e+07 -0.2388346791267395 0.33906280994415283\n",
      "[Step 12490] Loss: 9.54e+07 -0.23910783231258392 0.3390066921710968\n",
      "[Step 12491] Loss: 9.53e+07 -0.23935462534427643 0.3389555513858795\n",
      "[Step 12492] Loss: 9.54e+07 -0.23965299129486084 0.33888375759124756\n",
      "[Step 12493] Loss: 9.51e+07 -0.2398800253868103 0.33885321021080017\n",
      "[Step 12494] Loss: 9.64e+07 -0.24007435142993927 0.3388061821460724\n",
      "[Step 12495] Loss: 9.56e+07 -0.24036163091659546 0.33876824378967285\n",
      "[Step 12496] Loss: 9.56e+07 -0.24066801369190216 0.33871376514434814\n",
      "[Step 12497] Loss: 9.64e+07 -0.24076434969902039 0.33871954679489136\n",
      "[Step 12498] Loss: 9.63e+07 -0.24091601371765137 0.3387451171875\n",
      "[Step 12499] Loss: 9.63e+07 -0.2411855310201645 0.3386906683444977\n",
      "[Step 12500] Loss: 9.53e+07 -0.24134700000286102 0.33866921067237854\n",
      "[Step 12501] Loss: 9.55e+07 -0.24144962430000305 0.3386593163013458\n",
      "[Step 12502] Loss: 9.49e+07 -0.24157153069972992 0.3386271297931671\n",
      "[Step 12503] Loss: 9.51e+07 -0.24179668724536896 0.3385883569717407\n",
      "[Step 12504] Loss: 9.53e+07 -0.24202682077884674 0.3385116159915924\n",
      "[Step 12505] Loss: 9.52e+07 -0.24222545325756073 0.33845385909080505\n",
      "[Step 12506] Loss: 9.53e+07 -0.24235853552818298 0.33842167258262634\n",
      "[Step 12507] Loss: 9.57e+07 -0.2425978183746338 0.33839115500450134\n",
      "[Step 12508] Loss: 9.49e+07 -0.24280475080013275 0.3383556604385376\n",
      "[Step 12509] Loss: 9.54e+07 -0.24297210574150085 0.33834660053253174\n",
      "[Step 12510] Loss: 9.47e+07 -0.24315422773361206 0.3383210003376007\n",
      "[Step 12511] Loss: 9.65e+07 -0.243461012840271 0.33827728033065796\n",
      "[Step 12512] Loss: 9.47e+07 -0.24377129971981049 0.33824262022972107\n",
      "[Step 12513] Loss: 9.56e+07 -0.2441333830356598 0.33817166090011597\n",
      "[Step 12514] Loss: 9.48e+07 -0.2444404810667038 0.3381064832210541\n",
      "[Step 12515] Loss: 9.55e+07 -0.24468106031417847 0.33804458379745483\n",
      "[Step 12516] Loss: 9.51e+07 -0.24496552348136902 0.3379926085472107\n",
      "[Step 12517] Loss: 9.54e+07 -0.2452591210603714 0.3379199802875519\n",
      "[Step 12518] Loss: 9.53e+07 -0.24559247493743896 0.3378845155239105\n",
      "[Step 12519] Loss: 9.53e+07 -0.24595919251441956 0.3378399610519409\n",
      "[Step 12520] Loss: 9.53e+07 -0.24636518955230713 0.33778053522109985\n",
      "[Step 12521] Loss: 9.52e+07 -0.24678795039653778 0.3376864790916443\n",
      "[Step 12522] Loss: 9.55e+07 -0.24720540642738342 0.33760395646095276\n",
      "[Step 12523] Loss: 9.57e+07 -0.24763904511928558 0.3375156819820404\n",
      "[Step 12524] Loss: 9.55e+07 -0.2481391876935959 0.33741170167922974\n",
      "[Step 12525] Loss: 9.56e+07 -0.2486693114042282 0.33729287981987\n",
      "[Step 12526] Loss: 9.72e+07 -0.24945804476737976 0.33711549639701843\n",
      "[Step 12527] Loss: 9.55e+07 -0.2502267062664032 0.33697107434272766\n",
      "[Step 12528] Loss: 9.53e+07 -0.2508487403392792 0.33682090044021606\n",
      "[Step 12529] Loss: 9.50e+07 -0.25145500898361206 0.3366864025592804\n",
      "[Step 12530] Loss: 9.51e+07 -0.2521064877510071 0.3365568518638611\n",
      "[Step 12531] Loss: 9.57e+07 -0.25269970297813416 0.3364207148551941\n",
      "[Step 12532] Loss: 9.50e+07 -0.25326302647590637 0.33630356192588806\n",
      "[Step 12533] Loss: 9.52e+07 -0.25384092330932617 0.3361748158931732\n",
      "[Step 12534] Loss: 9.61e+07 -0.2544989585876465 0.33603784441947937\n",
      "[Step 12535] Loss: 9.53e+07 -0.25511568784713745 0.33587613701820374\n",
      "[Step 12536] Loss: 9.51e+07 -0.255612850189209 0.3357837200164795\n",
      "[Step 12537] Loss: 9.58e+07 -0.2559334635734558 0.3356929421424866\n",
      "[Step 12538] Loss: 9.55e+07 -0.2562543749809265 0.33562612533569336\n",
      "[Step 12539] Loss: 9.55e+07 -0.25663143396377563 0.3355221450328827\n",
      "[Step 12540] Loss: 9.58e+07 -0.2568418085575104 0.33546602725982666\n",
      "[Step 12541] Loss: 9.55e+07 -0.2570120692253113 0.335418164730072\n",
      "[Step 12542] Loss: 9.51e+07 -0.2571743428707123 0.335387647151947\n",
      "[Step 12543] Loss: 9.61e+07 -0.2574003040790558 0.33532246947288513\n",
      "[Step 12544] Loss: 9.51e+07 -0.25763383507728577 0.33523085713386536\n",
      "[Step 12545] Loss: 9.58e+07 -0.257732093334198 0.33518877625465393\n",
      "[Step 12546] Loss: 9.54e+07 -0.2577316462993622 0.3351590931415558\n",
      "[Step 12547] Loss: 9.57e+07 -0.2576828896999359 0.3351673483848572\n",
      "[Step 12548] Loss: 9.53e+07 -0.2577052414417267 0.33516982197761536\n",
      "[Step 12549] Loss: 9.49e+07 -0.2576256990432739 0.3352077603340149\n",
      "[Step 12550] Loss: 9.53e+07 -0.25762948393821716 0.33521270751953125\n",
      "[Step 12551] Loss: 9.56e+07 -0.25768378376960754 0.3351896107196808\n",
      "[Step 12552] Loss: 9.53e+07 -0.2576916813850403 0.33521023392677307\n",
      "[Step 12553] Loss: 9.54e+07 -0.2575953006744385 0.3352605700492859\n",
      "[Step 12554] Loss: 9.53e+07 -0.25752586126327515 0.33525562286376953\n",
      "[Step 12555] Loss: 9.60e+07 -0.25735875964164734 0.3353026509284973\n",
      "[Step 12556] Loss: 9.67e+07 -0.2573866546154022 0.3352688252925873\n",
      "[Step 12557] Loss: 9.49e+07 -0.25740480422973633 0.3352762460708618\n",
      "[Step 12558] Loss: 9.55e+07 -0.2573768198490143 0.33526965975761414\n",
      "[Step 12559] Loss: 9.51e+07 -0.25728508830070496 0.33528202772140503\n",
      "[Step 12560] Loss: 9.60e+07 -0.25709354877471924 0.3353249430656433\n",
      "[Step 12561] Loss: 9.55e+07 -0.25689876079559326 0.3353860080242157\n",
      "[Step 12562] Loss: 9.55e+07 -0.25665152072906494 0.33543962240219116\n",
      "[Step 12563] Loss: 9.54e+07 -0.25641360878944397 0.3354833722114563\n",
      "[Step 12564] Loss: 9.53e+07 -0.25616779923439026 0.3355295658111572\n",
      "[Step 12565] Loss: 9.44e+07 -0.255918949842453 0.3355642259120941\n",
      "[Step 12566] Loss: 9.58e+07 -0.25564783811569214 0.3356228172779083\n",
      "[Step 12567] Loss: 9.51e+07 -0.2553643584251404 0.3356665372848511\n",
      "[Step 12568] Loss: 9.57e+07 -0.2552657723426819 0.33568963408470154\n",
      "[Step 12569] Loss: 9.55e+07 -0.2552284896373749 0.3356863558292389\n",
      "[Step 12570] Loss: 9.52e+07 -0.2551596164703369 0.33570119738578796\n",
      "[Step 12571] Loss: 9.53e+07 -0.2550775706768036 0.3357408046722412\n",
      "[Step 12572] Loss: 9.56e+07 -0.2550085783004761 0.3357474207878113\n",
      "[Step 12573] Loss: 9.49e+07 -0.25491875410079956 0.3357771039009094\n",
      "[Step 12574] Loss: 9.56e+07 -0.2547800540924072 0.33581340312957764\n",
      "[Step 12575] Loss: 9.51e+07 -0.25458580255508423 0.3358612656593323\n",
      "[Step 12576] Loss: 9.48e+07 -0.25446584820747375 0.33587777614593506\n",
      "[Step 12577] Loss: 9.54e+07 -0.2543763518333435 0.33592647314071655\n",
      "[Step 12578] Loss: 9.56e+07 -0.25433453917503357 0.33592480421066284\n",
      "[Step 12579] Loss: 9.58e+07 -0.2543729543685913 0.3359074890613556\n",
      "[Step 12580] Loss: 9.49e+07 -0.2544047236442566 0.33592233061790466\n",
      "[Step 12581] Loss: 9.49e+07 -0.25436049699783325 0.3359074890613556\n",
      "[Step 12582] Loss: 9.57e+07 -0.25426405668258667 0.3359413146972656\n",
      "[Step 12583] Loss: 9.61e+07 -0.254243940114975 0.33596357703208923\n",
      "[Step 12584] Loss: 9.55e+07 -0.2543477714061737 0.3359297513961792\n",
      "[Step 12585] Loss: 9.47e+07 -0.25444602966308594 0.335915744304657\n",
      "[Step 12586] Loss: 9.50e+07 -0.2545824348926544 0.3359239995479584\n",
      "[Step 12587] Loss: 9.56e+07 -0.254800945520401 0.33590996265411377\n",
      "[Step 12588] Loss: 9.55e+07 -0.2548655867576599 0.3358794152736664\n",
      "[Step 12589] Loss: 9.54e+07 -0.2548654079437256 0.3358843922615051\n",
      "[Step 12590] Loss: 9.54e+07 -0.25479763746261597 0.3358893394470215\n",
      "[Step 12591] Loss: 9.51e+07 -0.2547152042388916 0.3359033465385437\n",
      "[Step 12592] Loss: 9.49e+07 -0.2546367049217224 0.33591821789741516\n",
      "[Step 12593] Loss: 9.47e+07 -0.254602313041687 0.3359396755695343\n",
      "[Step 12594] Loss: 9.55e+07 -0.25452175736427307 0.3359561562538147\n",
      "[Step 12595] Loss: 9.55e+07 -0.2544555962085724 0.3359784483909607\n",
      "[Step 12596] Loss: 9.54e+07 -0.25448131561279297 0.33597761392593384\n",
      "[Step 12597] Loss: 9.49e+07 -0.2544572651386261 0.335999071598053\n",
      "[Step 12598] Loss: 9.47e+07 -0.25440680980682373 0.3360254764556885\n",
      "[Step 12599] Loss: 9.52e+07 -0.2543025314807892 0.3360609710216522\n",
      "[Step 12600] Loss: 9.53e+07 -0.2541603446006775 0.33613109588623047\n",
      "[Step 12601] Loss: 9.52e+07 -0.25392454862594604 0.3362078368663788\n",
      "[Step 12602] Loss: 9.54e+07 -0.2536343038082123 0.33627715706825256\n",
      "[Step 12603] Loss: 9.47e+07 -0.25332415103912354 0.33634644746780396\n",
      "[Step 12604] Loss: 9.49e+07 -0.2529807984828949 0.3364413380622864\n",
      "[Step 12605] Loss: 9.55e+07 -0.2526043951511383 0.33653706312179565\n",
      "[Step 12606] Loss: 9.58e+07 -0.25219064950942993 0.3366418480873108\n",
      "[Step 12607] Loss: 9.46e+07 -0.2517947256565094 0.3367384076118469\n",
      "[Step 12608] Loss: 9.58e+07 -0.2515087425708771 0.33679696917533875\n",
      "[Step 12609] Loss: 9.50e+07 -0.25117823481559753 0.33688196539878845\n",
      "[Step 12610] Loss: 9.53e+07 -0.25086501240730286 0.33696117997169495\n",
      "[Step 12611] Loss: 9.51e+07 -0.2505105137825012 0.3370189368724823\n",
      "[Step 12612] Loss: 9.49e+07 -0.25022828578948975 0.337070107460022\n",
      "[Step 12613] Loss: 9.55e+07 -0.2501161992549896 0.3370882570743561\n",
      "[Step 12614] Loss: 9.55e+07 -0.2501164674758911 0.3370940387248993\n",
      "[Step 12615] Loss: 9.54e+07 -0.25011932849884033 0.3370956778526306\n",
      "[Step 12616] Loss: 9.50e+07 -0.2501296401023865 0.3370997905731201\n",
      "[Step 12617] Loss: 9.57e+07 -0.25030142068862915 0.3370437026023865\n",
      "[Step 12618] Loss: 9.54e+07 -0.25057554244995117 0.33696448802948\n",
      "[Step 12619] Loss: 9.53e+07 -0.2507522702217102 0.33691826462745667\n",
      "[Step 12620] Loss: 9.54e+07 -0.2509596347808838 0.33688196539878845\n",
      "[Step 12621] Loss: 9.52e+07 -0.2511028051376343 0.3368176221847534\n",
      "[Step 12622] Loss: 9.60e+07 -0.2513373792171478 0.3367491364479065\n",
      "[Step 12623] Loss: 9.64e+07 -0.2517346441745758 0.33668065071105957\n",
      "[Step 12624] Loss: 9.50e+07 -0.25207895040512085 0.33658573031425476\n",
      "[Step 12625] Loss: 9.60e+07 -0.25249671936035156 0.33649829030036926\n",
      "[Step 12626] Loss: 9.52e+07 -0.2527827322483063 0.3364240229129791\n",
      "[Step 12627] Loss: 9.57e+07 -0.2531594932079315 0.3363010585308075\n",
      "[Step 12628] Loss: 9.50e+07 -0.25351178646087646 0.3361929655075073\n",
      "[Step 12629] Loss: 9.54e+07 -0.253804087638855 0.33614346385002136\n",
      "[Step 12630] Loss: 9.52e+07 -0.25408387184143066 0.3360980749130249\n",
      "[Step 12631] Loss: 9.53e+07 -0.2542288303375244 0.3360758125782013\n",
      "[Step 12632] Loss: 9.58e+07 -0.2544833719730377 0.3360494077205658\n",
      "[Step 12633] Loss: 9.62e+07 -0.25475403666496277 0.33599990606307983\n",
      "[Step 12634] Loss: 9.51e+07 -0.25502684712409973 0.33594295382499695\n",
      "[Step 12635] Loss: 9.64e+07 -0.2551809549331665 0.3359107971191406\n",
      "[Step 12636] Loss: 9.48e+07 -0.2553243041038513 0.33588355779647827\n",
      "[Step 12637] Loss: 9.58e+07 -0.2554433345794678 0.3358794152736664\n",
      "[Step 12638] Loss: 9.51e+07 -0.2556000053882599 0.33588355779647827\n",
      "[Step 12639] Loss: 9.59e+07 -0.25565651059150696 0.33586621284484863\n",
      "[Step 12640] Loss: 9.45e+07 -0.25568917393684387 0.33586540818214417\n",
      "[Step 12641] Loss: 9.56e+07 -0.25572630763053894 0.33583733439445496\n",
      "[Step 12642] Loss: 9.52e+07 -0.25564804673194885 0.3358769416809082\n",
      "[Step 12643] Loss: 9.53e+07 -0.2556028962135315 0.3358950912952423\n",
      "[Step 12644] Loss: 9.51e+07 -0.25554022192955017 0.3359314203262329\n",
      "[Step 12645] Loss: 9.63e+07 -0.25561970472335815 0.335915744304657\n",
      "[Step 12646] Loss: 9.46e+07 -0.2557440996170044 0.3359314203262329\n",
      "[Step 12647] Loss: 9.54e+07 -0.2558961510658264 0.33592647314071655\n",
      "[Step 12648] Loss: 9.41e+07 -0.2560476064682007 0.33590254187583923\n",
      "[Step 12649] Loss: 9.78e+07 -0.25656571984291077 0.3358224928379059\n",
      "[Step 12650] Loss: 9.46e+07 -0.25695300102233887 0.33575400710105896\n",
      "[Step 12651] Loss: 9.58e+07 -0.25725769996643066 0.3357028365135193\n",
      "[Step 12652] Loss: 9.57e+07 -0.2574824392795563 0.33571603894233704\n",
      "[Step 12653] Loss: 9.55e+07 -0.25764116644859314 0.33568716049194336\n",
      "[Step 12654] Loss: 9.49e+07 -0.2578505575656891 0.3356418013572693\n",
      "[Step 12655] Loss: 9.46e+07 -0.2581011950969696 0.3356087803840637\n",
      "[Step 12656] Loss: 9.52e+07 -0.25835341215133667 0.3355568051338196\n",
      "[Step 12657] Loss: 9.47e+07 -0.2585773169994354 0.3355254530906677\n",
      "[Step 12658] Loss: 9.62e+07 -0.2588460445404053 0.3354874849319458\n",
      "[Step 12659] Loss: 9.53e+07 -0.258979469537735 0.3354668617248535\n",
      "[Step 12660] Loss: 9.57e+07 -0.2591104507446289 0.33542314171791077\n",
      "[Step 12661] Loss: 9.52e+07 -0.2591874897480011 0.33543550968170166\n",
      "[Step 12662] Loss: 9.55e+07 -0.25930672883987427 0.33543962240219116\n",
      "[Step 12663] Loss: 9.49e+07 -0.2594546675682068 0.33540743589401245\n",
      "[Step 12664] Loss: 9.56e+07 -0.25960877537727356 0.3353959023952484\n",
      "[Step 12665] Loss: 9.49e+07 -0.25976014137268066 0.3353925943374634\n",
      "[Step 12666] Loss: 9.54e+07 -0.2598962187767029 0.33537691831588745\n",
      "[Step 12667] Loss: 9.60e+07 -0.2598138749599457 0.335406631231308\n",
      "[Step 12668] Loss: 9.56e+07 -0.2598772943019867 0.33542561531066895\n",
      "[Step 12669] Loss: 9.56e+07 -0.2599622309207916 0.33541569113731384\n",
      "[Step 12670] Loss: 9.47e+07 -0.2600739002227783 0.33539673686027527\n",
      "[Step 12671] Loss: 9.47e+07 -0.260172039270401 0.33537691831588745\n",
      "[Step 12672] Loss: 9.49e+07 -0.2602885365486145 0.3353430926799774\n",
      "[Step 12673] Loss: 9.57e+07 -0.2603236138820648 0.33534473180770874\n",
      "[Step 12674] Loss: 9.60e+07 -0.260313481092453 0.3353175222873688\n",
      "[Step 12675] Loss: 9.61e+07 -0.26026177406311035 0.33532989025115967\n",
      "[Step 12676] Loss: 9.53e+07 -0.26024189591407776 0.33536288142204285\n",
      "[Step 12677] Loss: 9.50e+07 -0.26023292541503906 0.3353596031665802\n",
      "[Step 12678] Loss: 9.47e+07 -0.2601955533027649 0.3353356719017029\n",
      "[Step 12679] Loss: 9.50e+07 -0.26014962792396545 0.3353373110294342\n",
      "[Step 12680] Loss: 9.51e+07 -0.2601054608821869 0.3353331983089447\n",
      "[Step 12681] Loss: 9.48e+07 -0.2600167393684387 0.3353249430656433\n",
      "[Step 12682] Loss: 9.55e+07 -0.25990545749664307 0.3353373110294342\n",
      "[Step 12683] Loss: 9.46e+07 -0.25980091094970703 0.33537033200263977\n",
      "[Step 12684] Loss: 9.52e+07 -0.2598004937171936 0.33538928627967834\n",
      "[Step 12685] Loss: 9.55e+07 -0.25993433594703674 0.3353579342365265\n",
      "[Step 12686] Loss: 9.65e+07 -0.26028668880462646 0.33528944849967957\n",
      "[Step 12687] Loss: 9.50e+07 -0.26048851013183594 0.33527377247810364\n",
      "[Step 12688] Loss: 9.51e+07 -0.2607276737689972 0.3352077603340149\n",
      "[Step 12689] Loss: 9.47e+07 -0.26091381907463074 0.3351788818836212\n",
      "[Step 12690] Loss: 9.52e+07 -0.26098525524139404 0.33518797159194946\n",
      "[Step 12691] Loss: 9.47e+07 -0.2610378563404083 0.3352234363555908\n",
      "[Step 12692] Loss: 9.56e+07 -0.2611372768878937 0.33519044518470764\n",
      "[Step 12693] Loss: 9.52e+07 -0.26124265789985657 0.3351937532424927\n",
      "[Step 12694] Loss: 9.55e+07 -0.261280357837677 0.3352160155773163\n",
      "[Step 12695] Loss: 9.52e+07 -0.2613794207572937 0.33520281314849854\n",
      "[Step 12696] Loss: 9.57e+07 -0.26134493947029114 0.3352374732494354\n",
      "[Step 12697] Loss: 9.60e+07 -0.2614890933036804 0.33521848917007446\n",
      "[Step 12698] Loss: 9.63e+07 -0.26148349046707153 0.335248202085495\n",
      "[Step 12699] Loss: 9.47e+07 -0.26145246624946594 0.3352638781070709\n",
      "[Step 12700] Loss: 9.74e+07 -0.26167482137680054 0.33525562286376953\n",
      "[Step 12701] Loss: 9.44e+07 -0.2618315815925598 0.3352811932563782\n",
      "[Step 12702] Loss: 9.67e+07 -0.2617887258529663 0.3353257477283478\n",
      "[Step 12703] Loss: 9.49e+07 -0.2617247998714447 0.3353802263736725\n",
      "[Step 12704] Loss: 9.47e+07 -0.26167088747024536 0.3354189991950989\n",
      "[Step 12705] Loss: 9.59e+07 -0.2617177665233612 0.33539754152297974\n",
      "[Step 12706] Loss: 9.48e+07 -0.26172754168510437 0.3354024887084961\n",
      "[Step 12707] Loss: 9.58e+07 -0.26177316904067993 0.3354049623012543\n",
      "[Step 12708] Loss: 9.51e+07 -0.2618439197540283 0.33540332317352295\n",
      "[Step 12709] Loss: 9.51e+07 -0.2619447410106659 0.3354016840457916\n",
      "[Step 12710] Loss: 9.61e+07 -0.26215171813964844 0.3353620767593384\n",
      "[Step 12711] Loss: 9.66e+07 -0.26220396161079407 0.33536866307258606\n",
      "[Step 12712] Loss: 9.66e+07 -0.2624589800834656 0.33531254529953003\n",
      "[Step 12713] Loss: 9.48e+07 -0.2626097798347473 0.33528533577919006\n",
      "[Step 12714] Loss: 9.47e+07 -0.26278990507125854 0.3352374732494354\n",
      "[Step 12715] Loss: 9.58e+07 -0.26294514536857605 0.33518877625465393\n",
      "[Step 12716] Loss: 9.53e+07 -0.26304951310157776 0.3351706266403198\n",
      "[Step 12717] Loss: 9.58e+07 -0.2632353603839874 0.33516237139701843\n",
      "[Step 12718] Loss: 9.58e+07 -0.26354172825813293 0.3351161777973175\n",
      "[Step 12719] Loss: 9.53e+07 -0.2639313042163849 0.3350328505039215\n",
      "[Step 12720] Loss: 9.43e+07 -0.26427605748176575 0.33497756719589233\n",
      "[Step 12721] Loss: 9.51e+07 -0.26454031467437744 0.3349090814590454\n",
      "[Step 12722] Loss: 9.48e+07 -0.26477062702178955 0.33487769961357117\n",
      "[Step 12723] Loss: 9.50e+07 -0.26497557759284973 0.33484306931495667\n",
      "[Step 12724] Loss: 9.48e+07 -0.2652164399623871 0.33480921387672424\n",
      "[Step 12725] Loss: 9.65e+07 -0.26560431718826294 0.33476465940475464\n",
      "[Step 12726] Loss: 9.50e+07 -0.26600849628448486 0.33472010493278503\n",
      "[Step 12727] Loss: 9.48e+07 -0.2663721442222595 0.33466318249702454\n",
      "[Step 12728] Loss: 9.53e+07 -0.26668277382850647 0.3345872759819031\n",
      "[Step 12729] Loss: 9.54e+07 -0.26686951518058777 0.33454352617263794\n",
      "[Step 12730] Loss: 9.53e+07 -0.2670316994190216 0.3345039188861847\n",
      "[Step 12731] Loss: 9.54e+07 -0.2671634554862976 0.334494024515152\n",
      "[Step 12732] Loss: 9.57e+07 -0.26730048656463623 0.3344676196575165\n",
      "[Step 12733] Loss: 9.63e+07 -0.2673454284667969 0.33448413014411926\n",
      "[Step 12734] Loss: 9.52e+07 -0.2673766016960144 0.33447420597076416\n",
      "[Step 12735] Loss: 9.49e+07 -0.26750507950782776 0.33442553877830505\n",
      "[Step 12736] Loss: 9.62e+07 -0.26751983165740967 0.33442139625549316\n",
      "[Step 12737] Loss: 9.44e+07 -0.2675406038761139 0.33441728353500366\n",
      "[Step 12738] Loss: 9.54e+07 -0.2675483226776123 0.3344065546989441\n",
      "[Step 12739] Loss: 9.53e+07 -0.2676045894622803 0.3343702554702759\n",
      "[Step 12740] Loss: 9.64e+07 -0.26747164130210876 0.3343941867351532\n",
      "[Step 12741] Loss: 9.52e+07 -0.2673184871673584 0.33439335227012634\n",
      "[Step 12742] Loss: 9.57e+07 -0.2672150731086731 0.33440160751342773\n",
      "[Step 12743] Loss: 9.51e+07 -0.26718148589134216 0.3343900442123413\n",
      "[Step 12744] Loss: 9.55e+07 -0.26718002557754517 0.3344123363494873\n",
      "[Step 12745] Loss: 9.51e+07 -0.2672889828681946 0.3343958258628845\n",
      "[Step 12746] Loss: 9.53e+07 -0.26739224791526794 0.33437684178352356\n",
      "[Step 12747] Loss: 9.59e+07 -0.267541766166687 0.3343636393547058\n",
      "[Step 12748] Loss: 9.47e+07 -0.26772361993789673 0.33432403206825256\n",
      "[Step 12749] Loss: 9.48e+07 -0.26787492632865906 0.3343026041984558\n",
      "[Step 12750] Loss: 9.53e+07 -0.2680049538612366 0.33427536487579346\n",
      "[Step 12751] Loss: 9.55e+07 -0.2682301104068756 0.3342134654521942\n",
      "[Step 12752] Loss: 9.48e+07 -0.26845088601112366 0.3342134654521942\n",
      "[Step 12753] Loss: 9.47e+07 -0.26859810948371887 0.3342077136039734\n",
      "[Step 12754] Loss: 9.53e+07 -0.26878196001052856 0.33413922786712646\n",
      "[Step 12755] Loss: 9.56e+07 -0.26909613609313965 0.33409547805786133\n",
      "[Step 12756] Loss: 9.52e+07 -0.26933977007865906 0.3340418338775635\n",
      "[Step 12757] Loss: 9.57e+07 -0.2694978415966034 0.3340435028076172\n",
      "[Step 12758] Loss: 9.59e+07 -0.26957741379737854 0.33401957154273987\n",
      "[Step 12759] Loss: 9.59e+07 -0.26965242624282837 0.33402782678604126\n",
      "[Step 12760] Loss: 9.48e+07 -0.2697300910949707 0.33401378989219666\n",
      "[Step 12761] Loss: 9.49e+07 -0.2697005271911621 0.3339940011501312\n",
      "[Step 12762] Loss: 9.51e+07 -0.2696342468261719 0.3340435028076172\n",
      "[Step 12763] Loss: 9.49e+07 -0.2695865333080292 0.3340641260147095\n",
      "[Step 12764] Loss: 9.60e+07 -0.2693939507007599 0.3340979516506195\n",
      "[Step 12765] Loss: 9.51e+07 -0.26936760544776917 0.33412104845046997\n",
      "[Step 12766] Loss: 9.54e+07 -0.2694065570831299 0.3341202437877655\n",
      "[Step 12767] Loss: 9.55e+07 -0.26937246322631836 0.3341227173805237\n",
      "[Step 12768] Loss: 9.62e+07 -0.26946359872817993 0.33414745330810547\n",
      "[Step 12769] Loss: 9.49e+07 -0.2695764899253845 0.33413177728652954\n",
      "[Step 12770] Loss: 9.64e+07 -0.26959726214408875 0.3341631293296814\n",
      "[Step 12771] Loss: 9.47e+07 -0.26957565546035767 0.3341705799102783\n",
      "[Step 12772] Loss: 9.48e+07 -0.2695280611515045 0.33417385816574097\n",
      "[Step 12773] Loss: 9.48e+07 -0.2695412337779999 0.33419036865234375\n",
      "[Step 12774] Loss: 9.48e+07 -0.2695993185043335 0.334177166223526\n",
      "[Step 12775] Loss: 9.55e+07 -0.26962676644325256 0.33414334058761597\n",
      "[Step 12776] Loss: 9.47e+07 -0.26965728402137756 0.33414581418037415\n",
      "[Step 12777] Loss: 9.48e+07 -0.26967212557792664 0.33414003252983093\n",
      "[Step 12778] Loss: 9.54e+07 -0.2697409391403198 0.3341020941734314\n",
      "[Step 12779] Loss: 9.66e+07 -0.26967060565948486 0.3340756893157959\n",
      "[Step 12780] Loss: 9.54e+07 -0.26960092782974243 0.3340699076652527\n",
      "[Step 12781] Loss: 9.55e+07 -0.2696698307991028 0.33405256271362305\n",
      "[Step 12782] Loss: 9.52e+07 -0.26971593499183655 0.3340170979499817\n",
      "[Step 12783] Loss: 9.48e+07 -0.2697555422782898 0.3340005874633789\n",
      "[Step 12784] Loss: 9.63e+07 -0.26992267370224 0.33398985862731934\n",
      "[Step 12785] Loss: 9.53e+07 -0.27009788155555725 0.33393624424934387\n",
      "[Step 12786] Loss: 9.54e+07 -0.2702656090259552 0.333901584148407\n",
      "[Step 12787] Loss: 9.52e+07 -0.27031612396240234 0.3339098393917084\n",
      "[Step 12788] Loss: 9.56e+07 -0.2704037129878998 0.3339197337627411\n",
      "[Step 12789] Loss: 9.52e+07 -0.27047252655029297 0.33391642570495605\n",
      "[Step 12790] Loss: 9.58e+07 -0.27038827538490295 0.33391889929771423\n",
      "[Step 12791] Loss: 9.55e+07 -0.2701508402824402 0.3339601457118988\n",
      "[Step 12792] Loss: 9.47e+07 -0.26995620131492615 0.3339618146419525\n",
      "[Step 12793] Loss: 9.53e+07 -0.2696935534477234 0.33400967717170715\n",
      "[Step 12794] Loss: 9.50e+07 -0.2694375514984131 0.3340492844581604\n",
      "[Step 12795] Loss: 9.46e+07 -0.26912885904312134 0.3341260254383087\n",
      "[Step 12796] Loss: 9.51e+07 -0.2688525319099426 0.3341606557369232\n",
      "[Step 12797] Loss: 9.50e+07 -0.2686655521392822 0.3341870605945587\n",
      "[Step 12798] Loss: 9.49e+07 -0.2685399353504181 0.33422255516052246\n",
      "[Step 12799] Loss: 9.50e+07 -0.2683512270450592 0.3342646360397339\n",
      "[Step 12800] Loss: 9.55e+07 -0.26803216338157654 0.3343372344970703\n",
      "[Step 12801] Loss: 9.54e+07 -0.2676636576652527 0.3344453275203705\n",
      "[Step 12802] Loss: 9.47e+07 -0.26730403304100037 0.3345121741294861\n",
      "[Step 12803] Loss: 9.51e+07 -0.2670626938343048 0.33458560705184937\n",
      "[Step 12804] Loss: 9.51e+07 -0.26677194237709045 0.33465492725372314\n",
      "[Step 12805] Loss: 9.51e+07 -0.2665634751319885 0.33472999930381775\n",
      "[Step 12806] Loss: 9.51e+07 -0.2663901150226593 0.33478033542633057\n",
      "[Step 12807] Loss: 9.52e+07 -0.26620492339134216 0.3348562717437744\n",
      "[Step 12808] Loss: 9.56e+07 -0.26590657234191895 0.3348892629146576\n",
      "[Step 12809] Loss: 9.54e+07 -0.265789270401001 0.33494290709495544\n",
      "[Step 12810] Loss: 9.61e+07 -0.2655596137046814 0.33499157428741455\n",
      "[Step 12811] Loss: 9.45e+07 -0.26537373661994934 0.33504027128219604\n",
      "[Step 12812] Loss: 9.53e+07 -0.26528453826904297 0.33507245779037476\n",
      "[Step 12813] Loss: 9.47e+07 -0.26528653502464294 0.3350922465324402\n",
      "[Step 12814] Loss: 9.49e+07 -0.26524609327316284 0.33512112498283386\n",
      "[Step 12815] Loss: 9.72e+07 -0.2654389441013336 0.3350757360458374\n",
      "[Step 12816] Loss: 9.52e+07 -0.2655664086341858 0.3350740969181061\n",
      "[Step 12817] Loss: 9.48e+07 -0.26567456126213074 0.3350732624530792\n",
      "[Step 12818] Loss: 9.46e+07 -0.2657860517501831 0.3350476920604706\n",
      "[Step 12819] Loss: 9.62e+07 -0.26578080654144287 0.3350270688533783\n",
      "[Step 12820] Loss: 9.55e+07 -0.2657507658004761 0.3350476920604706\n",
      "[Step 12821] Loss: 9.54e+07 -0.265827476978302 0.33501139283180237\n",
      "[Step 12822] Loss: 9.50e+07 -0.2660042941570282 0.3349981904029846\n",
      "[Step 12823] Loss: 9.49e+07 -0.26617082953453064 0.33494701981544495\n",
      "[Step 12824] Loss: 9.54e+07 -0.26625025272369385 0.3349057734012604\n",
      "[Step 12825] Loss: 9.52e+07 -0.2663695812225342 0.33484140038490295\n",
      "[Step 12826] Loss: 9.52e+07 -0.2664248049259186 0.3348240852355957\n",
      "[Step 12827] Loss: 9.49e+07 -0.2664135992527008 0.3348116874694824\n",
      "[Step 12828] Loss: 9.53e+07 -0.2665259838104248 0.334844708442688\n",
      "[Step 12829] Loss: 9.53e+07 -0.26659679412841797 0.334822416305542\n",
      "[Step 12830] Loss: 9.55e+07 -0.2667240500450134 0.3347588777542114\n",
      "[Step 12831] Loss: 9.56e+07 -0.2669053077697754 0.33469948172569275\n",
      "[Step 12832] Loss: 9.54e+07 -0.26703572273254395 0.3346804976463318\n",
      "[Step 12833] Loss: 9.47e+07 -0.2670833170413971 0.3346656560897827\n",
      "[Step 12834] Loss: 9.53e+07 -0.26705026626586914 0.33468133211135864\n",
      "[Step 12835] Loss: 9.51e+07 -0.267051637172699 0.3346763849258423\n",
      "[Step 12836] Loss: 9.50e+07 -0.2669855058193207 0.33466649055480957\n",
      "[Step 12837] Loss: 9.57e+07 -0.26686760783195496 0.334686279296875\n",
      "[Step 12838] Loss: 9.53e+07 -0.2667432129383087 0.33467307686805725\n",
      "[Step 12839] Loss: 9.54e+07 -0.2666616141796112 0.33469289541244507\n",
      "[Step 12840] Loss: 9.54e+07 -0.26658228039741516 0.33472010493278503\n",
      "[Step 12841] Loss: 9.43e+07 -0.2664806544780731 0.3347267210483551\n",
      "[Step 12842] Loss: 9.53e+07 -0.26630255579948425 0.33477622270584106\n",
      "[Step 12843] Loss: 9.48e+07 -0.266215056180954 0.3347877860069275\n",
      "[Step 12844] Loss: 9.49e+07 -0.2661128044128418 0.334791898727417\n",
      "[Step 12845] Loss: 9.47e+07 -0.26604729890823364 0.3348059356212616\n",
      "[Step 12846] Loss: 9.56e+07 -0.2659860849380493 0.3348116874694824\n",
      "[Step 12847] Loss: 9.53e+07 -0.2659163475036621 0.3348364531993866\n",
      "[Step 12848] Loss: 9.54e+07 -0.2658751606941223 0.3348504900932312\n",
      "[Step 12849] Loss: 9.54e+07 -0.2657667100429535 0.3348810076713562\n",
      "[Step 12850] Loss: 9.53e+07 -0.26566460728645325 0.3348851501941681\n",
      "[Step 12851] Loss: 9.44e+07 -0.26561596989631653 0.3349131941795349\n",
      "[Step 12852] Loss: 9.57e+07 -0.26556289196014404 0.3349255621433258\n",
      "[Step 12853] Loss: 9.55e+07 -0.2656092047691345 0.33493465185165405\n",
      "[Step 12854] Loss: 9.64e+07 -0.26576530933380127 0.33494454622268677\n",
      "[Step 12855] Loss: 9.54e+07 -0.26592323184013367 0.3349239230155945\n",
      "[Step 12856] Loss: 9.54e+07 -0.26600387692451477 0.33492061495780945\n",
      "[Step 12857] Loss: 9.56e+07 -0.2660093307495117 0.3349321782588959\n",
      "[Step 12858] Loss: 9.62e+07 -0.2662767469882965 0.3348834812641144\n",
      "[Step 12859] Loss: 9.51e+07 -0.26650139689445496 0.3348603844642639\n",
      "[Step 12860] Loss: 9.56e+07 -0.26656681299209595 0.33485376834869385\n",
      "[Step 12861] Loss: 9.50e+07 -0.26658469438552856 0.33481666445732117\n",
      "[Step 12862] Loss: 9.56e+07 -0.26678797602653503 0.3347877860069275\n",
      "[Step 12863] Loss: 9.53e+07 -0.26698869466781616 0.3347415626049042\n",
      "[Step 12864] Loss: 9.57e+07 -0.2672853469848633 0.3346656560897827\n",
      "[Step 12865] Loss: 9.54e+07 -0.2675139307975769 0.3346293568611145\n",
      "[Step 12866] Loss: 9.49e+07 -0.2676936984062195 0.3345690965652466\n",
      "[Step 12867] Loss: 9.57e+07 -0.2678025960922241 0.3345542550086975\n",
      "[Step 12868] Loss: 9.50e+07 -0.26786017417907715 0.3345649838447571\n",
      "[Step 12869] Loss: 9.40e+07 -0.26795947551727295 0.3345195949077606\n",
      "[Step 12870] Loss: 9.55e+07 -0.26825833320617676 0.33449649810791016\n",
      "[Step 12871] Loss: 9.50e+07 -0.2685334086418152 0.3344205915927887\n",
      "[Step 12872] Loss: 9.54e+07 -0.26880791783332825 0.33437272906303406\n",
      "[Step 12873] Loss: 9.64e+07 -0.26927608251571655 0.33426710963249207\n",
      "[Step 12874] Loss: 9.59e+07 -0.26981186866760254 0.3341713845729828\n",
      "[Step 12875] Loss: 9.56e+07 -0.2703220546245575 0.33407649397850037\n",
      "[Step 12876] Loss: 9.55e+07 -0.27087998390197754 0.33395519852638245\n",
      "[Step 12877] Loss: 9.49e+07 -0.2713223099708557 0.33388176560401917\n",
      "[Step 12878] Loss: 9.57e+07 -0.2718394994735718 0.3337835669517517\n",
      "[Step 12879] Loss: 9.57e+07 -0.2722870409488678 0.3336639404296875\n",
      "[Step 12880] Loss: 9.51e+07 -0.2727593779563904 0.3335731625556946\n",
      "[Step 12881] Loss: 9.56e+07 -0.2731027603149414 0.33353275060653687\n",
      "[Step 12882] Loss: 9.50e+07 -0.27347180247306824 0.3334675431251526\n",
      "[Step 12883] Loss: 9.54e+07 -0.2738339900970459 0.3333883285522461\n",
      "[Step 12884] Loss: 9.47e+07 -0.274147629737854 0.33332231640815735\n",
      "[Step 12885] Loss: 9.57e+07 -0.27451735734939575 0.33327198028564453\n",
      "[Step 12886] Loss: 9.50e+07 -0.2748751938343048 0.33319443464279175\n",
      "[Step 12887] Loss: 9.61e+07 -0.2754138112068176 0.3330962359905243\n",
      "[Step 12888] Loss: 9.51e+07 -0.2758786082267761 0.33300960063934326\n",
      "[Step 12889] Loss: 9.51e+07 -0.27621373534202576 0.33292874693870544\n",
      "[Step 12890] Loss: 9.57e+07 -0.2765645980834961 0.33284538984298706\n",
      "[Step 12891] Loss: 9.51e+07 -0.276816189289093 0.33281734585762024\n",
      "[Step 12892] Loss: 9.52e+07 -0.27704349160194397 0.33276864886283875\n",
      "[Step 12893] Loss: 9.69e+07 -0.2774391174316406 0.33267953991889954\n",
      "[Step 12894] Loss: 9.45e+07 -0.2777782678604126 0.33261024951934814\n",
      "[Step 12895] Loss: 9.71e+07 -0.2783764898777008 0.3324872851371765\n",
      "[Step 12896] Loss: 9.44e+07 -0.2788969576358795 0.3323882818222046\n",
      "[Step 12897] Loss: 9.53e+07 -0.27950724959373474 0.332271933555603\n",
      "[Step 12898] Loss: 9.44e+07 -0.28005531430244446 0.3321267068386078\n",
      "[Step 12899] Loss: 9.55e+07 -0.2805267572402954 0.3320276737213135\n",
      "[Step 12900] Loss: 9.51e+07 -0.28094786405563354 0.331951767206192\n",
      "[Step 12901] Loss: 9.56e+07 -0.28140804171562195 0.3318510949611664\n",
      "[Step 12902] Loss: 9.52e+07 -0.28176555037498474 0.3318115174770355\n",
      "[Step 12903] Loss: 9.48e+07 -0.2820928990840912 0.33174797892570496\n",
      "[Step 12904] Loss: 9.56e+07 -0.2822502851486206 0.33172816038131714\n",
      "[Step 12905] Loss: 9.51e+07 -0.28248530626296997 0.33167949318885803\n",
      "[Step 12906] Loss: 9.56e+07 -0.2826850116252899 0.33162668347358704\n",
      "[Step 12907] Loss: 9.52e+07 -0.28286227583885193 0.3316192328929901\n",
      "[Step 12908] Loss: 9.52e+07 -0.2830563187599182 0.3316068649291992\n",
      "[Step 12909] Loss: 9.63e+07 -0.28335022926330566 0.33155322074890137\n",
      "[Step 12910] Loss: 9.57e+07 -0.2837045192718506 0.33150291442871094\n",
      "[Step 12911] Loss: 9.55e+07 -0.28394848108291626 0.3314674198627472\n",
      "[Step 12912] Loss: 9.49e+07 -0.2841315269470215 0.33146411180496216\n",
      "[Step 12913] Loss: 9.60e+07 -0.2843596935272217 0.331434428691864\n",
      "[Step 12914] Loss: 9.58e+07 -0.284681499004364 0.3313659429550171\n",
      "[Step 12915] Loss: 9.48e+07 -0.28497859835624695 0.33132797479629517\n",
      "[Step 12916] Loss: 9.51e+07 -0.2852119207382202 0.3312842547893524\n",
      "[Step 12917] Loss: 9.50e+07 -0.285373717546463 0.33129414916038513\n",
      "[Step 12918] Loss: 9.57e+07 -0.2853875756263733 0.3312867283821106\n",
      "[Step 12919] Loss: 9.56e+07 -0.28533247113227844 0.33127763867378235\n",
      "[Step 12920] Loss: 9.46e+07 -0.285262793302536 0.3313172459602356\n",
      "[Step 12921] Loss: 9.48e+07 -0.2851272225379944 0.33137252926826477\n",
      "[Step 12922] Loss: 9.43e+07 -0.2849735915660858 0.33140552043914795\n",
      "[Step 12923] Loss: 9.53e+07 -0.2848268151283264 0.3314286470413208\n",
      "[Step 12924] Loss: 9.56e+07 -0.28474998474121094 0.33144432306289673\n",
      "[Step 12925] Loss: 9.47e+07 -0.28462985157966614 0.3314707279205322\n",
      "[Step 12926] Loss: 9.59e+07 -0.2846508026123047 0.33144843578338623\n",
      "[Step 12927] Loss: 9.56e+07 -0.2847962975502014 0.33143359422683716\n",
      "[Step 12928] Loss: 9.61e+07 -0.28508460521698 0.3313436508178711\n",
      "[Step 12929] Loss: 9.55e+07 -0.2854176163673401 0.3312619626522064\n",
      "[Step 12930] Loss: 9.53e+07 -0.2856987714767456 0.3312075138092041\n",
      "[Step 12931] Loss: 9.53e+07 -0.28601279854774475 0.3311208486557007\n",
      "[Step 12932] Loss: 9.48e+07 -0.28640732169151306 0.3310416638851166\n",
      "[Step 12933] Loss: 9.50e+07 -0.2867976725101471 0.33095583319664\n",
      "[Step 12934] Loss: 9.52e+07 -0.2872236967086792 0.3308749794960022\n",
      "[Step 12935] Loss: 9.46e+07 -0.2876514494419098 0.3307718336582184\n",
      "[Step 12936] Loss: 9.51e+07 -0.287980854511261 0.3306926190853119\n",
      "[Step 12937] Loss: 9.54e+07 -0.2883034944534302 0.3306398093700409\n",
      "[Step 12938] Loss: 9.53e+07 -0.2885076403617859 0.33059030771255493\n",
      "[Step 12939] Loss: 9.41e+07 -0.2886559069156647 0.33057543635368347\n",
      "[Step 12940] Loss: 9.57e+07 -0.2887285351753235 0.3305581212043762\n",
      "[Step 12941] Loss: 9.44e+07 -0.28874531388282776 0.3306092917919159\n",
      "[Step 12942] Loss: 9.42e+07 -0.2887381911277771 0.33059772849082947\n",
      "[Step 12943] Loss: 9.60e+07 -0.28879550099372864 0.3305894732475281\n",
      "[Step 12944] Loss: 9.51e+07 -0.2888975739479065 0.3305540084838867\n",
      "[Step 12945] Loss: 9.64e+07 -0.28919392824172974 0.3305118978023529\n",
      "[Step 12946] Loss: 9.64e+07 -0.28965163230895996 0.3303922712802887\n",
      "[Step 12947] Loss: 9.51e+07 -0.29007649421691895 0.33031222224235535\n",
      "[Step 12948] Loss: 9.52e+07 -0.2905585765838623 0.3302033245563507\n",
      "[Step 12949] Loss: 9.53e+07 -0.2909938395023346 0.3301018178462982\n",
      "[Step 12950] Loss: 9.55e+07 -0.2914159297943115 0.3299863040447235\n",
      "[Step 12951] Loss: 9.54e+07 -0.29181039333343506 0.32988810539245605\n",
      "[Step 12952] Loss: 9.52e+07 -0.2922867238521576 0.3298064172267914\n",
      "[Step 12953] Loss: 9.58e+07 -0.29266586899757385 0.3297123610973358\n",
      "[Step 12954] Loss: 9.54e+07 -0.29302459955215454 0.3296075761318207\n",
      "[Step 12955] Loss: 9.47e+07 -0.2933138310909271 0.3295283615589142\n",
      "[Step 12956] Loss: 9.57e+07 -0.29362937808036804 0.3294491469860077\n",
      "[Step 12957] Loss: 9.49e+07 -0.29385513067245483 0.3294128179550171\n",
      "[Step 12958] Loss: 9.55e+07 -0.29397881031036377 0.32936331629753113\n",
      "[Step 12959] Loss: 9.51e+07 -0.29406091570854187 0.3293212354183197\n",
      "[Step 12960] Loss: 9.56e+07 -0.2940482497215271 0.3293171226978302\n",
      "[Step 12961] Loss: 9.54e+07 -0.29413560032844543 0.3292824625968933\n",
      "[Step 12962] Loss: 9.54e+07 -0.29424723982810974 0.329261839389801\n",
      "[Step 12963] Loss: 9.52e+07 -0.29436883330345154 0.3292543888092041\n",
      "[Step 12964] Loss: 9.54e+07 -0.29434487223625183 0.32925358414649963\n",
      "[Step 12965] Loss: 9.56e+07 -0.29429319500923157 0.3292750418186188\n",
      "[Step 12966] Loss: 9.48e+07 -0.29428550601005554 0.329292356967926\n",
      "[Step 12967] Loss: 9.54e+07 -0.2941654920578003 0.32930639386177063\n",
      "[Step 12968] Loss: 9.51e+07 -0.29395318031311035 0.3293294906616211\n",
      "[Step 12969] Loss: 9.47e+07 -0.2937808930873871 0.3293558955192566\n",
      "[Step 12970] Loss: 9.54e+07 -0.293735146522522 0.32941117882728577\n",
      "[Step 12971] Loss: 9.50e+07 -0.2937565743923187 0.32940128445625305\n",
      "[Step 12972] Loss: 9.50e+07 -0.293796181678772 0.3293938636779785\n",
      "[Step 12973] Loss: 9.52e+07 -0.2938370108604431 0.3293839395046234\n",
      "[Step 12974] Loss: 9.48e+07 -0.2939382791519165 0.329397976398468\n",
      "[Step 12975] Loss: 9.47e+07 -0.29397252202033997 0.3294029235839844\n",
      "[Step 12976] Loss: 9.41e+07 -0.2939543128013611 0.3293897211551666\n",
      "[Step 12977] Loss: 9.56e+07 -0.2939790189266205 0.3293823003768921\n",
      "[Step 12978] Loss: 9.52e+07 -0.2940642833709717 0.32936909794807434\n",
      "[Step 12979] Loss: 9.52e+07 -0.29400837421417236 0.329367458820343\n",
      "[Step 12980] Loss: 9.46e+07 -0.29395925998687744 0.3293781876564026\n",
      "[Step 12981] Loss: 9.54e+07 -0.29398268461227417 0.32935258746147156\n",
      "[Step 12982] Loss: 9.48e+07 -0.29392009973526 0.3293616771697998\n",
      "[Step 12983] Loss: 9.55e+07 -0.2937304973602295 0.3293963372707367\n",
      "[Step 12984] Loss: 9.44e+07 -0.2935081720352173 0.32947224378585815\n",
      "[Step 12985] Loss: 9.50e+07 -0.2933080792427063 0.3295159637928009\n",
      "[Step 12986] Loss: 9.49e+07 -0.2930266559123993 0.3295935392379761\n",
      "[Step 12987] Loss: 9.60e+07 -0.29269105195999146 0.3296636641025543\n",
      "[Step 12988] Loss: 9.49e+07 -0.29238006472587585 0.3297272026538849\n",
      "[Step 12989] Loss: 9.48e+07 -0.2920622229576111 0.3298023045063019\n",
      "[Step 12990] Loss: 9.56e+07 -0.2918921411037445 0.3298451900482178\n",
      "[Step 12991] Loss: 9.57e+07 -0.2917740046977997 0.3298872709274292\n",
      "[Step 12992] Loss: 9.57e+07 -0.29179632663726807 0.3298889398574829\n",
      "[Step 12993] Loss: 9.61e+07 -0.2920444905757904 0.32986006140708923\n",
      "[Step 12994] Loss: 9.59e+07 -0.2924211025238037 0.3297577500343323\n",
      "[Step 12995] Loss: 9.57e+07 -0.2929028272628784 0.32969996333122253\n",
      "[Step 12996] Loss: 9.55e+07 -0.2933812141418457 0.32957208156585693\n",
      "[Step 12997] Loss: 9.56e+07 -0.2938268780708313 0.32952505350112915\n",
      "[Step 12998] Loss: 9.55e+07 -0.29418811202049255 0.3294293284416199\n",
      "[Step 12999] Loss: 9.53e+07 -0.2944989502429962 0.32934847474098206\n",
      "[Step 13000] Loss: 9.51e+07 -0.2948586344718933 0.3292750418186188\n",
      "[Step 13001] Loss: 9.59e+07 -0.2951817214488983 0.32920488715171814\n",
      "[Step 13002] Loss: 9.50e+07 -0.2955469787120819 0.32913392782211304\n",
      "[Step 13003] Loss: 9.51e+07 -0.29579880833625793 0.32907864451408386\n",
      "[Step 13004] Loss: 9.56e+07 -0.2960011959075928 0.3290596604347229\n",
      "[Step 13005] Loss: 9.50e+07 -0.2961921691894531 0.32904234528541565\n",
      "[Step 13006] Loss: 9.54e+07 -0.2962438762187958 0.3290539085865021\n",
      "[Step 13007] Loss: 9.52e+07 -0.2962630093097687 0.3290671110153198\n",
      "[Step 13008] Loss: 9.53e+07 -0.2963690161705017 0.3290580213069916\n",
      "[Step 13009] Loss: 9.53e+07 -0.29646098613739014 0.32903987169265747\n",
      "[Step 13010] Loss: 9.54e+07 -0.2965709865093231 0.3290093243122101\n",
      "[Step 13011] Loss: 9.53e+07 -0.29658347368240356 0.32901015877723694\n",
      "[Step 13012] Loss: 9.45e+07 -0.296601802110672 0.32901182770729065\n",
      "[Step 13013] Loss: 9.60e+07 -0.2966875433921814 0.3290010988712311\n",
      "[Step 13014] Loss: 9.54e+07 -0.2968909442424774 0.3289218842983246\n",
      "[Step 13015] Loss: 9.56e+07 -0.2970142364501953 0.328888863325119\n",
      "[Step 13016] Loss: 9.59e+07 -0.2971496880054474 0.32884347438812256\n",
      "[Step 13017] Loss: 9.49e+07 -0.29728952050209045 0.32882121205329895\n",
      "[Step 13018] Loss: 9.45e+07 -0.297437459230423 0.3288038671016693\n",
      "[Step 13019] Loss: 9.51e+07 -0.2976127862930298 0.3287510573863983\n",
      "[Step 13020] Loss: 9.53e+07 -0.29777732491493225 0.32867762446403503\n",
      "[Step 13021] Loss: 9.47e+07 -0.29785001277923584 0.32864710688591003\n",
      "[Step 13022] Loss: 9.59e+07 -0.2979030907154083 0.32861822843551636\n",
      "[Step 13023] Loss: 9.58e+07 -0.29798170924186707 0.32856541872024536\n",
      "[Step 13024] Loss: 9.64e+07 -0.2982635200023651 0.32846391201019287\n",
      "[Step 13025] Loss: 9.47e+07 -0.29848986864089966 0.32839131355285645\n",
      "[Step 13026] Loss: 9.49e+07 -0.29867130517959595 0.32834675908088684\n",
      "[Step 13027] Loss: 9.53e+07 -0.29881829023361206 0.3283335566520691\n",
      "[Step 13028] Loss: 9.49e+07 -0.2989589273929596 0.3283046782016754\n",
      "[Step 13029] Loss: 9.57e+07 -0.29897233843803406 0.32831868529319763\n",
      "[Step 13030] Loss: 9.48e+07 -0.2990402579307556 0.32827579975128174\n",
      "[Step 13031] Loss: 9.50e+07 -0.2990553677082062 0.32826507091522217\n",
      "[Step 13032] Loss: 9.51e+07 -0.2991151511669159 0.32824525237083435\n",
      "[Step 13033] Loss: 9.51e+07 -0.29910358786582947 0.32825350761413574\n",
      "[Step 13034] Loss: 9.49e+07 -0.2990931570529938 0.3282724916934967\n",
      "[Step 13035] Loss: 9.43e+07 -0.2990577816963196 0.32829973101615906\n",
      "[Step 13036] Loss: 9.55e+07 -0.29906150698661804 0.32829228043556213\n",
      "[Step 13037] Loss: 9.53e+07 -0.29903602600097656 0.32831045985221863\n",
      "[Step 13038] Loss: 9.55e+07 -0.29900920391082764 0.328296422958374\n",
      "[Step 13039] Loss: 9.60e+07 -0.29895827174186707 0.3282988965511322\n",
      "[Step 13040] Loss: 9.46e+07 -0.298859179019928 0.328315407037735\n",
      "[Step 13041] Loss: 9.52e+07 -0.2987217605113983 0.32831788063049316\n",
      "[Step 13042] Loss: 9.64e+07 -0.2984534800052643 0.32834428548812866\n",
      "[Step 13043] Loss: 9.53e+07 -0.298200398683548 0.32840535044670105\n",
      "[Step 13044] Loss: 9.63e+07 -0.29809316992759705 0.32841771841049194\n",
      "[Step 13045] Loss: 9.49e+07 -0.2979748547077179 0.32844412326812744\n",
      "[Step 13046] Loss: 9.57e+07 -0.2977850139141083 0.3284713625907898\n",
      "[Step 13047] Loss: 9.60e+07 -0.29769769310951233 0.328473836183548\n",
      "[Step 13048] Loss: 9.51e+07 -0.2976301610469818 0.32849445939064026\n",
      "[Step 13049] Loss: 9.54e+07 -0.29758384823799133 0.32846885919570923\n",
      "[Step 13050] Loss: 9.52e+07 -0.2975931465625763 0.3284655809402466\n",
      "[Step 13051] Loss: 9.49e+07 -0.29756414890289307 0.3284606337547302\n",
      "[Step 13052] Loss: 9.56e+07 -0.29762330651283264 0.3284367024898529\n",
      "[Step 13053] Loss: 9.51e+07 -0.2977820634841919 0.3283723294734955\n",
      "[Step 13054] Loss: 9.57e+07 -0.29797884821891785 0.3283368647098541\n",
      "[Step 13055] Loss: 9.64e+07 -0.2980281412601471 0.3283054828643799\n",
      "[Step 13056] Loss: 9.46e+07 -0.29813799262046814 0.3282865285873413\n",
      "[Step 13057] Loss: 9.56e+07 -0.2982062101364136 0.32822877168655396\n",
      "[Step 13058] Loss: 9.51e+07 -0.2982988655567169 0.32816439867019653\n",
      "[Step 13059] Loss: 9.54e+07 -0.29828181862831116 0.32815614342689514\n",
      "[Step 13060] Loss: 9.59e+07 -0.29845619201660156 0.3281247913837433\n",
      "[Step 13061] Loss: 9.55e+07 -0.29857519268989563 0.32810497283935547\n",
      "[Step 13062] Loss: 9.46e+07 -0.29870298504829407 0.3280777633190155\n",
      "[Step 13063] Loss: 9.52e+07 -0.29874858260154724 0.3280620872974396\n",
      "[Step 13064] Loss: 9.46e+07 -0.29883450269699097 0.3280414640903473\n",
      "[Step 13065] Loss: 9.60e+07 -0.29881149530410767 0.32804805040359497\n",
      "[Step 13066] Loss: 9.53e+07 -0.29889634251594543 0.3280678689479828\n",
      "[Step 13067] Loss: 9.52e+07 -0.29899969696998596 0.3280662000179291\n",
      "[Step 13068] Loss: 9.42e+07 -0.29906561970710754 0.32805466651916504\n",
      "[Step 13069] Loss: 9.59e+07 -0.29915478825569153 0.32804393768310547\n",
      "[Step 13070] Loss: 9.57e+07 -0.2993517816066742 0.32799360156059265\n",
      "[Step 13071] Loss: 9.47e+07 -0.29958003759384155 0.3279275894165039\n",
      "[Step 13072] Loss: 9.54e+07 -0.29970958828926086 0.32788383960723877\n",
      "[Step 13073] Loss: 9.57e+07 -0.29980677366256714 0.3278244435787201\n",
      "[Step 13074] Loss: 9.49e+07 -0.29993167519569397 0.32779309153556824\n",
      "[Step 13075] Loss: 9.51e+07 -0.2999918460845947 0.3277609050273895\n",
      "[Step 13076] Loss: 9.47e+07 -0.3001194894313812 0.32774606347084045\n",
      "[Step 13077] Loss: 9.50e+07 -0.30018672347068787 0.3277246057987213\n",
      "[Step 13078] Loss: 9.47e+07 -0.3001914620399475 0.32771387696266174\n",
      "[Step 13079] Loss: 9.56e+07 -0.3001173138618469 0.3277254104614258\n",
      "[Step 13080] Loss: 9.50e+07 -0.3000549077987671 0.3277270793914795\n",
      "[Step 13081] Loss: 9.53e+07 -0.30012640357017517 0.32772377133369446\n",
      "[Step 13082] Loss: 9.55e+07 -0.3001861274242401 0.3276808559894562\n",
      "[Step 13083] Loss: 9.47e+07 -0.3001842200756073 0.3277064561843872\n",
      "[Step 13084] Loss: 9.59e+07 -0.3000721037387848 0.3277353346347809\n",
      "[Step 13085] Loss: 9.58e+07 -0.2999681234359741 0.32773450016975403\n",
      "[Step 13086] Loss: 9.53e+07 -0.2998626232147217 0.32774192094802856\n",
      "[Step 13087] Loss: 9.56e+07 -0.29974427819252014 0.32778236269950867\n",
      "[Step 13088] Loss: 9.61e+07 -0.2998383641242981 0.3277815282344818\n",
      "[Step 13089] Loss: 9.47e+07 -0.29994064569473267 0.32774439454078674\n",
      "[Step 13090] Loss: 9.56e+07 -0.29996994137763977 0.32775843143463135\n",
      "[Step 13091] Loss: 9.57e+07 -0.299979567527771 0.3277815282344818\n",
      "[Step 13092] Loss: 9.52e+07 -0.29992005228996277 0.3278137147426605\n",
      "[Step 13093] Loss: 9.50e+07 -0.2999249994754791 0.32778236269950867\n",
      "[Step 13094] Loss: 9.61e+07 -0.2998118996620178 0.32780876755714417\n",
      "[Step 13095] Loss: 9.60e+07 -0.2996806800365448 0.32783764600753784\n",
      "[Step 13096] Loss: 9.53e+07 -0.29963114857673645 0.3278607428073883\n",
      "[Step 13097] Loss: 9.46e+07 -0.2996046245098114 0.32786816358566284\n",
      "[Step 13098] Loss: 9.49e+07 -0.2996906638145447 0.32787230610847473\n",
      "[Step 13099] Loss: 9.54e+07 -0.29969632625579834 0.32784754037857056\n",
      "[Step 13100] Loss: 9.50e+07 -0.2998320758342743 0.32782360911369324\n",
      "[Step 13101] Loss: 9.56e+07 -0.30005982518196106 0.32779473066329956\n",
      "[Step 13102] Loss: 9.62e+07 -0.3001959025859833 0.32779061794281006\n",
      "[Step 13103] Loss: 9.65e+07 -0.3004991412162781 0.327731192111969\n",
      "[Step 13104] Loss: 9.52e+07 -0.3008542060852051 0.3276800513267517\n",
      "[Step 13105] Loss: 9.53e+07 -0.3010804057121277 0.32764124870300293\n",
      "[Step 13106] Loss: 9.51e+07 -0.30125224590301514 0.3276016414165497\n",
      "[Step 13107] Loss: 9.54e+07 -0.30140092968940735 0.32755133509635925\n",
      "[Step 13108] Loss: 9.55e+07 -0.30150124430656433 0.32755133509635925\n",
      "[Step 13109] Loss: 9.58e+07 -0.301559716463089 0.32753482460975647\n",
      "[Step 13110] Loss: 9.71e+07 -0.30145263671875 0.32756534218788147\n",
      "[Step 13111] Loss: 9.54e+07 -0.30135688185691833 0.32757195830345154\n",
      "[Step 13112] Loss: 9.52e+07 -0.30127543210983276 0.32757607102394104\n",
      "[Step 13113] Loss: 9.62e+07 -0.30114927887916565 0.3276173174381256\n",
      "[Step 13114] Loss: 9.51e+07 -0.30097001791000366 0.32762229442596436\n",
      "[Step 13115] Loss: 9.51e+07 -0.3007355034351349 0.32766684889793396\n",
      "[Step 13116] Loss: 9.58e+07 -0.30061426758766174 0.32769572734832764\n",
      "[Step 13117] Loss: 9.55e+07 -0.3004513084888458 0.3277270793914795\n",
      "[Step 13118] Loss: 9.48e+07 -0.30030953884124756 0.3277336657047272\n",
      "[Step 13119] Loss: 9.47e+07 -0.30026310682296753 0.3277435898780823\n",
      "[Step 13120] Loss: 9.57e+07 -0.3002965748310089 0.32773613929748535\n",
      "[Step 13121] Loss: 9.49e+07 -0.3003712594509125 0.32773780822753906\n",
      "[Step 13122] Loss: 9.70e+07 -0.30026209354400635 0.32779309153556824\n",
      "[Step 13123] Loss: 9.57e+07 -0.30022040009498596 0.32783186435699463\n",
      "[Step 13124] Loss: 9.53e+07 -0.3002973794937134 0.32780545949935913\n",
      "[Step 13125] Loss: 9.45e+07 -0.3003639280796051 0.32781124114990234\n",
      "[Step 13126] Loss: 9.47e+07 -0.30049929022789 0.32781949639320374\n",
      "[Step 13127] Loss: 9.53e+07 -0.3005731403827667 0.32781124114990234\n",
      "[Step 13128] Loss: 9.55e+07 -0.3007361888885498 0.32779473066329956\n",
      "[Step 13129] Loss: 9.49e+07 -0.30083316564559937 0.32776254415512085\n",
      "[Step 13130] Loss: 9.57e+07 -0.30083391070365906 0.3277699947357178\n",
      "[Step 13131] Loss: 9.52e+07 -0.3008629381656647 0.3277675211429596\n",
      "[Step 13132] Loss: 9.45e+07 -0.3008762300014496 0.32778236269950867\n",
      "[Step 13133] Loss: 9.71e+07 -0.3011881411075592 0.32771140336990356\n",
      "[Step 13134] Loss: 9.52e+07 -0.30133605003356934 0.3276503384113312\n",
      "[Step 13135] Loss: 9.54e+07 -0.30143114924430847 0.3276354968547821\n",
      "[Step 13136] Loss: 9.56e+07 -0.30152371525764465 0.32761073112487793\n",
      "[Step 13137] Loss: 9.60e+07 -0.30165576934814453 0.3275488317012787\n",
      "[Step 13138] Loss: 9.48e+07 -0.30179616808891296 0.327519953250885\n",
      "[Step 13139] Loss: 9.62e+07 -0.30212461948394775 0.3274531364440918\n",
      "[Step 13140] Loss: 9.58e+07 -0.3024556040763855 0.32736071944236755\n",
      "[Step 13141] Loss: 9.63e+07 -0.30294787883758545 0.3272608816623688\n",
      "[Step 13142] Loss: 9.53e+07 -0.3034724295139313 0.3271007835865021\n",
      "[Step 13143] Loss: 9.49e+07 -0.3039107620716095 0.3270092010498047\n",
      "[Step 13144] Loss: 9.60e+07 -0.30436888337135315 0.3268977999687195\n",
      "[Step 13145] Loss: 9.57e+07 -0.30478355288505554 0.3268285095691681\n",
      "[Step 13146] Loss: 9.57e+07 -0.30513742566108704 0.3267253637313843\n",
      "[Step 13147] Loss: 9.59e+07 -0.30551430583000183 0.32660406827926636\n",
      "[Step 13148] Loss: 9.54e+07 -0.3059154748916626 0.32646873593330383\n",
      "[Step 13149] Loss: 9.59e+07 -0.3061237633228302 0.3263862133026123\n",
      "[Step 13150] Loss: 9.52e+07 -0.3063661754131317 0.32632434368133545\n",
      "[Step 13151] Loss: 9.65e+07 -0.30675819516181946 0.32624924182891846\n",
      "[Step 13152] Loss: 9.52e+07 -0.307115763425827 0.32614612579345703\n",
      "[Step 13153] Loss: 9.58e+07 -0.3075144588947296 0.32604873180389404\n",
      "[Step 13154] Loss: 9.74e+07 -0.30821511149406433 0.3259200155735016\n",
      "[Step 13155] Loss: 9.59e+07 -0.3090045154094696 0.32571539282798767\n",
      "[Step 13156] Loss: 9.49e+07 -0.3097168207168579 0.32556191086769104\n",
      "[Step 13157] Loss: 9.59e+07 -0.31040307879447937 0.32539522647857666\n",
      "[Step 13158] Loss: 9.51e+07 -0.31099000573158264 0.3252689838409424\n",
      "[Step 13159] Loss: 9.53e+07 -0.3115779459476471 0.3251485228538513\n",
      "[Step 13160] Loss: 9.61e+07 -0.3119303286075592 0.3250742554664612\n",
      "[Step 13161] Loss: 9.51e+07 -0.312283456325531 0.32499998807907104\n",
      "[Step 13162] Loss: 9.53e+07 -0.312558114528656 0.3249150216579437\n",
      "[Step 13163] Loss: 9.52e+07 -0.31290146708488464 0.32482919096946716\n",
      "[Step 13164] Loss: 9.59e+07 -0.3130866289138794 0.3247920572757721\n",
      "[Step 13165] Loss: 9.48e+07 -0.3131493330001831 0.32477885484695435\n",
      "[Step 13166] Loss: 9.58e+07 -0.3133011758327484 0.32474997639656067\n",
      "[Step 13167] Loss: 9.51e+07 -0.31351378560066223 0.32469385862350464\n",
      "[Step 13168] Loss: 9.60e+07 -0.31380531191825867 0.3246237337589264\n",
      "[Step 13169] Loss: 9.57e+07 -0.31395217776298523 0.32456761598587036\n",
      "[Step 13170] Loss: 9.56e+07 -0.3139192759990692 0.32456183433532715\n",
      "[Step 13171] Loss: 9.48e+07 -0.31383419036865234 0.32457423210144043\n",
      "[Step 13172] Loss: 9.49e+07 -0.3136916160583496 0.32458990812301636\n",
      "[Step 13173] Loss: 9.51e+07 -0.3135121166706085 0.32464683055877686\n",
      "[Step 13174] Loss: 9.57e+07 -0.3134918808937073 0.32466745376586914\n",
      "[Step 13175] Loss: 9.48e+07 -0.31341809034347534 0.3246922194957733\n",
      "[Step 13176] Loss: 9.48e+07 -0.31334733963012695 0.3247309923171997\n",
      "[Step 13177] Loss: 9.51e+07 -0.313334584236145 0.32469964027404785\n",
      "[Step 13178] Loss: 9.45e+07 -0.3131799101829529 0.3247409164905548\n",
      "[Step 13179] Loss: 9.54e+07 -0.31298327445983887 0.32479289174079895\n",
      "[Step 13180] Loss: 9.54e+07 -0.3127196431159973 0.32486632466316223\n",
      "[Step 13181] Loss: 9.50e+07 -0.3124915361404419 0.32490015029907227\n",
      "[Step 13182] Loss: 9.56e+07 -0.31227031350135803 0.3249537944793701\n",
      "[Step 13183] Loss: 9.58e+07 -0.3121446669101715 0.3249686360359192\n",
      "[Step 13184] Loss: 9.45e+07 -0.3120921850204468 0.3249719440937042\n",
      "[Step 13185] Loss: 9.54e+07 -0.3120097219944 0.32500413060188293\n",
      "[Step 13186] Loss: 9.58e+07 -0.31195318698883057 0.32501155138015747\n",
      "[Step 13187] Loss: 9.48e+07 -0.31196993589401245 0.3250330090522766\n",
      "[Step 13188] Loss: 9.70e+07 -0.3123093247413635 0.324985146522522\n",
      "[Step 13189] Loss: 9.53e+07 -0.3127729296684265 0.32489025592803955\n",
      "[Step 13190] Loss: 9.55e+07 -0.3132651746273041 0.3248143494129181\n",
      "[Step 13191] Loss: 9.61e+07 -0.31391623616218567 0.3246699273586273\n",
      "[Step 13192] Loss: 9.50e+07 -0.3144463002681732 0.32453957200050354\n",
      "[Step 13193] Loss: 9.48e+07 -0.31487178802490234 0.3244710862636566\n",
      "[Step 13194] Loss: 9.76e+07 -0.3155633807182312 0.3243027627468109\n",
      "[Step 13195] Loss: 9.50e+07 -0.31614547967910767 0.3241773247718811\n",
      "[Step 13196] Loss: 9.50e+07 -0.3165767192840576 0.3240939974784851\n",
      "[Step 13197] Loss: 9.48e+07 -0.31705182790756226 0.32396361231803894\n",
      "[Step 13198] Loss: 9.53e+07 -0.31760096549987793 0.32384398579597473\n",
      "[Step 13199] Loss: 9.55e+07 -0.31811094284057617 0.3237350583076477\n",
      "[Step 13200] Loss: 9.40e+07 -0.31856223940849304 0.32361459732055664\n",
      "[Step 13201] Loss: 9.49e+07 -0.31898441910743713 0.32351556420326233\n",
      "[Step 13202] Loss: 9.56e+07 -0.3191823661327362 0.3234495520591736\n",
      "[Step 13203] Loss: 9.51e+07 -0.3194401264190674 0.3233785927295685\n",
      "[Step 13204] Loss: 9.47e+07 -0.3196962773799896 0.32326391339302063\n",
      "[Step 13205] Loss: 9.51e+07 -0.32004258036613464 0.32317396998405457\n",
      "[Step 13206] Loss: 9.55e+07 -0.3203025460243225 0.32312527298927307\n",
      "[Step 13207] Loss: 9.52e+07 -0.3206165134906769 0.3230675160884857\n",
      "[Step 13208] Loss: 9.53e+07 -0.32092320919036865 0.3229462206363678\n",
      "[Step 13209] Loss: 9.67e+07 -0.3214341998100281 0.3227960467338562\n",
      "[Step 13210] Loss: 9.50e+07 -0.32193759083747864 0.3226582705974579\n",
      "[Step 13211] Loss: 9.52e+07 -0.3223212957382202 0.32257160544395447\n",
      "[Step 13212] Loss: 9.52e+07 -0.3227667510509491 0.32248416543006897\n",
      "[Step 13213] Loss: 9.53e+07 -0.3231055438518524 0.3224008083343506\n",
      "[Step 13214] Loss: 9.62e+07 -0.32329973578453064 0.3223719298839569\n",
      "[Step 13215] Loss: 9.53e+07 -0.3233988285064697 0.3223479986190796\n",
      "[Step 13216] Loss: 9.57e+07 -0.32354500889778137 0.3223207890987396\n",
      "[Step 13217] Loss: 9.48e+07 -0.3237292468547821 0.32226797938346863\n",
      "[Step 13218] Loss: 9.56e+07 -0.3238632082939148 0.3222646713256836\n",
      "[Step 13219] Loss: 9.55e+07 -0.32396188378334045 0.3222588896751404\n",
      "[Step 13220] Loss: 9.48e+07 -0.324095219373703 0.32221928238868713\n",
      "[Step 13221] Loss: 9.53e+07 -0.3243280351161957 0.3221202790737152\n",
      "[Step 13222] Loss: 9.52e+07 -0.3245834708213806 0.32205674052238464\n",
      "[Step 13223] Loss: 9.54e+07 -0.32481831312179565 0.32198578119277954\n",
      "[Step 13224] Loss: 9.48e+07 -0.3249489367008209 0.32200226187705994\n",
      "[Step 13225] Loss: 9.60e+07 -0.32507985830307007 0.3219544291496277\n",
      "[Step 13226] Loss: 9.52e+07 -0.3251091241836548 0.32194533944129944\n",
      "[Step 13227] Loss: 9.57e+07 -0.32506346702575684 0.3219701051712036\n",
      "[Step 13228] Loss: 9.50e+07 -0.3248917758464813 0.32203444838523865\n",
      "[Step 13229] Loss: 9.51e+07 -0.32482078671455383 0.32205259799957275\n",
      "[Step 13230] Loss: 9.51e+07 -0.32480692863464355 0.3220765292644501\n",
      "[Step 13231] Loss: 9.56e+07 -0.3249058425426483 0.3220270276069641\n",
      "[Step 13232] Loss: 9.53e+07 -0.32501769065856934 0.3219808340072632\n",
      "[Step 13233] Loss: 9.51e+07 -0.32523325085639954 0.32194286584854126\n",
      "[Step 13234] Loss: 9.55e+07 -0.3255101442337036 0.32188594341278076\n",
      "[Step 13235] Loss: 9.45e+07 -0.32569754123687744 0.32182568311691284\n",
      "[Step 13236] Loss: 9.46e+07 -0.3258385956287384 0.3217860758304596\n",
      "[Step 13237] Loss: 9.49e+07 -0.32595065236091614 0.32174813747406006\n",
      "[Step 13238] Loss: 9.53e+07 -0.32606327533721924 0.3216862380504608\n",
      "[Step 13239] Loss: 9.57e+07 -0.32606014609336853 0.3216680884361267\n",
      "[Step 13240] Loss: 9.54e+07 -0.32608747482299805 0.32165655493736267\n",
      "[Step 13241] Loss: 9.54e+07 -0.32617226243019104 0.3216293156147003\n",
      "[Step 13242] Loss: 9.60e+07 -0.32619884610176086 0.321635901927948\n",
      "[Step 13243] Loss: 9.57e+07 -0.32617825269699097 0.32165902853012085\n",
      "[Step 13244] Loss: 9.46e+07 -0.32617148756980896 0.32165735960006714\n",
      "[Step 13245] Loss: 9.48e+07 -0.3260781466960907 0.32172006368637085\n",
      "[Step 13246] Loss: 9.51e+07 -0.3260270357131958 0.3217275142669678\n",
      "[Step 13247] Loss: 9.57e+07 -0.32613763213157654 0.32166561484336853\n",
      "[Step 13248] Loss: 9.59e+07 -0.32614022493362427 0.3216623067855835\n",
      "[Step 13249] Loss: 9.52e+07 -0.32608547806739807 0.32167550921440125\n",
      "[Step 13250] Loss: 9.55e+07 -0.32603633403778076 0.3216664493083954\n",
      "[Step 13251] Loss: 9.48e+07 -0.32604867219924927 0.32165735960006714\n",
      "[Step 13252] Loss: 9.54e+07 -0.3261570930480957 0.3215996026992798\n",
      "[Step 13253] Loss: 9.48e+07 -0.3262965977191925 0.32154348492622375\n",
      "[Step 13254] Loss: 9.48e+07 -0.3263026177883148 0.3215038776397705\n",
      "[Step 13255] Loss: 9.56e+07 -0.3264952003955841 0.32142964005470276\n",
      "[Step 13256] Loss: 9.58e+07 -0.3265736997127533 0.32140156626701355\n",
      "[Step 13257] Loss: 9.57e+07 -0.3265804350376129 0.32136937975883484\n",
      "[Step 13258] Loss: 9.50e+07 -0.32647401094436646 0.3213759958744049\n",
      "[Step 13259] Loss: 9.78e+07 -0.32675501704216003 0.32130008935928345\n",
      "[Step 13260] Loss: 9.56e+07 -0.32704973220825195 0.321205198764801\n",
      "[Step 13261] Loss: 9.53e+07 -0.327335000038147 0.3211391866207123\n",
      "[Step 13262] Loss: 9.57e+07 -0.3275811970233917 0.32101789116859436\n",
      "[Step 13263] Loss: 9.56e+07 -0.3278605341911316 0.32093289494514465\n",
      "[Step 13264] Loss: 9.52e+07 -0.3281654417514801 0.320820689201355\n",
      "[Step 13265] Loss: 9.62e+07 -0.32821887731552124 0.320798397064209\n",
      "[Step 13266] Loss: 9.50e+07 -0.3282172977924347 0.32074642181396484\n",
      "[Step 13267] Loss: 9.51e+07 -0.32825860381126404 0.3206969201564789\n",
      "[Step 13268] Loss: 9.61e+07 -0.32831084728240967 0.32067298889160156\n",
      "[Step 13269] Loss: 9.53e+07 -0.32836461067199707 0.3206424415111542\n",
      "[Step 13270] Loss: 9.50e+07 -0.3283460736274719 0.3206300735473633\n",
      "[Step 13271] Loss: 9.58e+07 -0.32833540439605713 0.32061687111854553\n",
      "[Step 13272] Loss: 9.41e+07 -0.328307569026947 0.32062676548957825\n",
      "[Step 13273] Loss: 9.50e+07 -0.328249990940094 0.3206300735473633\n",
      "[Step 13274] Loss: 9.54e+07 -0.32814821600914 0.32062265276908875\n",
      "[Step 13275] Loss: 9.49e+07 -0.32803744077682495 0.3206234574317932\n",
      "[Step 13276] Loss: 9.52e+07 -0.32786765694618225 0.3206333816051483\n",
      "[Step 13277] Loss: 9.47e+07 -0.32765212655067444 0.32066142559051514\n",
      "[Step 13278] Loss: 9.58e+07 -0.3273871839046478 0.3207068145275116\n",
      "[Step 13279] Loss: 9.64e+07 -0.32699257135391235 0.32078683376312256\n",
      "[Step 13280] Loss: 9.49e+07 -0.3265881836414337 0.3208668828010559\n",
      "[Step 13281] Loss: 9.53e+07 -0.3261910378932953 0.32094693183898926\n",
      "[Step 13282] Loss: 9.53e+07 -0.3257787823677063 0.32105088233947754\n",
      "[Step 13283] Loss: 9.62e+07 -0.3253162205219269 0.3211531937122345\n",
      "[Step 13284] Loss: 9.49e+07 -0.32474058866500854 0.3212629556655884\n",
      "[Step 13285] Loss: 9.53e+07 -0.3242299556732178 0.3213759958744049\n",
      "[Step 13286] Loss: 9.56e+07 -0.3237864673137665 0.32144200801849365\n",
      "[Step 13287] Loss: 9.45e+07 -0.32335522770881653 0.3215195834636688\n",
      "[Step 13288] Loss: 9.51e+07 -0.3230324983596802 0.3215542137622833\n",
      "[Step 13289] Loss: 9.51e+07 -0.32265138626098633 0.3216177523136139\n",
      "[Step 13290] Loss: 9.59e+07 -0.3223746716976166 0.32162848114967346\n",
      "[Step 13291] Loss: 9.55e+07 -0.322240948677063 0.3216416835784912\n",
      "[Step 13292] Loss: 9.51e+07 -0.3221951127052307 0.3216400444507599\n",
      "[Step 13293] Loss: 9.48e+07 -0.3221963047981262 0.32162022590637207\n",
      "[Step 13294] Loss: 9.52e+07 -0.32210037112236023 0.3216293156147003\n",
      "[Step 13295] Loss: 9.44e+07 -0.321938157081604 0.32165488600730896\n",
      "[Step 13296] Loss: 9.57e+07 -0.32169443368911743 0.32168295979499817\n",
      "[Step 13297] Loss: 9.56e+07 -0.32152673602104187 0.3217126429080963\n",
      "[Step 13298] Loss: 9.54e+07 -0.3213435113430023 0.3217720687389374\n",
      "[Step 13299] Loss: 9.48e+07 -0.32120004296302795 0.32179105281829834\n",
      "[Step 13300] Loss: 9.67e+07 -0.3213288486003876 0.321744829416275\n",
      "[Step 13301] Loss: 9.55e+07 -0.3215133845806122 0.32169944047927856\n",
      "[Step 13302] Loss: 9.54e+07 -0.3217162489891052 0.3216235339641571\n",
      "[Step 13303] Loss: 9.60e+07 -0.3218280076980591 0.32157155871391296\n",
      "[Step 13304] Loss: 9.60e+07 -0.32188117504119873 0.321522057056427\n",
      "[Step 13305] Loss: 9.53e+07 -0.32192716002464294 0.3214700520038605\n",
      "[Step 13306] Loss: 9.50e+07 -0.3220619261264801 0.32141560316085815\n",
      "[Step 13307] Loss: 9.54e+07 -0.32229873538017273 0.32133638858795166\n",
      "[Step 13308] Loss: 9.47e+07 -0.322557270526886 0.3212406635284424\n",
      "[Step 13309] Loss: 9.50e+07 -0.3227778375148773 0.32119032740592957\n",
      "[Step 13310] Loss: 9.50e+07 -0.32294800877571106 0.32113751769065857\n",
      "[Step 13311] Loss: 9.57e+07 -0.3231361508369446 0.32109132409095764\n",
      "[Step 13312] Loss: 9.47e+07 -0.32325831055641174 0.3210368752479553\n",
      "[Step 13313] Loss: 9.50e+07 -0.3232986330986023 0.3209683895111084\n",
      "[Step 13314] Loss: 9.54e+07 -0.32332009077072144 0.3209395110607147\n",
      "[Step 13315] Loss: 9.49e+07 -0.32323628664016724 0.32091227173805237\n",
      "[Step 13316] Loss: 9.51e+07 -0.32313215732574463 0.3209304213523865\n",
      "[Step 13317] Loss: 9.48e+07 -0.3230004906654358 0.32093700766563416\n",
      "[Step 13318] Loss: 9.58e+07 -0.32296112179756165 0.3209320604801178\n",
      "[Step 13319] Loss: 9.51e+07 -0.3228514790534973 0.3209502100944519\n",
      "[Step 13320] Loss: 9.53e+07 -0.32279160618782043 0.32098323106765747\n",
      "[Step 13321] Loss: 9.50e+07 -0.322842001914978 0.32093289494514465\n",
      "[Step 13322] Loss: 9.56e+07 -0.3228846788406372 0.32088422775268555\n",
      "[Step 13323] Loss: 9.54e+07 -0.322948157787323 0.32083553075790405\n",
      "[Step 13324] Loss: 9.52e+07 -0.32294154167175293 0.3208503723144531\n",
      "[Step 13325] Loss: 9.52e+07 -0.32288888096809387 0.32084378600120544\n",
      "[Step 13326] Loss: 9.47e+07 -0.3228614628314972 0.32082974910736084\n",
      "[Step 13327] Loss: 9.53e+07 -0.3228006064891815 0.320820689201355\n",
      "[Step 13328] Loss: 9.52e+07 -0.322710245847702 0.3208058178424835\n",
      "[Step 13329] Loss: 9.47e+07 -0.32265588641166687 0.32079097628593445\n",
      "[Step 13330] Loss: 9.55e+07 -0.32268238067626953 0.3207719922065735\n",
      "[Step 13331] Loss: 9.57e+07 -0.3228953182697296 0.3207134008407593\n",
      "[Step 13332] Loss: 9.56e+07 -0.32304027676582336 0.3206482231616974\n",
      "[Step 13333] Loss: 9.49e+07 -0.32310372591018677 0.3206275999546051\n",
      "[Step 13334] Loss: 9.54e+07 -0.3230818510055542 0.3206374943256378\n",
      "[Step 13335] Loss: 9.53e+07 -0.32311564683914185 0.32063254714012146\n",
      "[Step 13336] Loss: 9.53e+07 -0.323167622089386 0.3206028342247009\n",
      "[Step 13337] Loss: 9.51e+07 -0.3232599198818207 0.3205690085887909\n",
      "[Step 13338] Loss: 9.57e+07 -0.3232067823410034 0.3205830454826355\n",
      "[Step 13339] Loss: 9.54e+07 -0.3231799900531769 0.32058221101760864\n",
      "[Step 13340] Loss: 9.56e+07 -0.32328107953071594 0.32056817412376404\n",
      "[Step 13341] Loss: 9.56e+07 -0.32325029373168945 0.3205508589744568\n",
      "[Step 13342] Loss: 9.59e+07 -0.3232187032699585 0.32052528858184814\n",
      "[Step 13343] Loss: 9.48e+07 -0.3231855630874634 0.3205178678035736\n",
      "[Step 13344] Loss: 9.57e+07 -0.32329052686691284 0.3204774260520935\n",
      "[Step 13345] Loss: 9.50e+07 -0.3234527111053467 0.32044854760169983\n",
      "[Step 13346] Loss: 9.49e+07 -0.3235931992530823 0.3204006850719452\n",
      "[Step 13347] Loss: 9.51e+07 -0.32371601462364197 0.32037922739982605\n",
      "[Step 13348] Loss: 9.56e+07 -0.32384562492370605 0.3203437626361847\n",
      "[Step 13349] Loss: 9.57e+07 -0.324024498462677 0.3202851712703705\n",
      "[Step 13350] Loss: 9.52e+07 -0.32417935132980347 0.32022327184677124\n",
      "[Step 13351] Loss: 9.51e+07 -0.324308842420578 0.32018449902534485\n",
      "[Step 13352] Loss: 9.53e+07 -0.32447752356529236 0.3201795518398285\n",
      "[Step 13353] Loss: 9.56e+07 -0.3246806561946869 0.32013005018234253\n",
      "[Step 13354] Loss: 9.47e+07 -0.3248600959777832 0.32007476687431335\n",
      "[Step 13355] Loss: 9.56e+07 -0.32497313618659973 0.3200318515300751\n",
      "[Step 13356] Loss: 9.56e+07 -0.32507720589637756 0.32003679871559143\n",
      "[Step 13357] Loss: 9.45e+07 -0.325175017118454 0.3200458884239197\n",
      "[Step 13358] Loss: 9.49e+07 -0.32519981265068054 0.32005494832992554\n",
      "[Step 13359] Loss: 9.52e+07 -0.3252670466899872 0.32007887959480286\n",
      "[Step 13360] Loss: 9.53e+07 -0.32526499032974243 0.32007887959480286\n",
      "[Step 13361] Loss: 9.59e+07 -0.32525384426116943 0.320100337266922\n",
      "[Step 13362] Loss: 9.50e+07 -0.32524698972702026 0.3200961947441101\n",
      "[Step 13363] Loss: 9.53e+07 -0.3251863718032837 0.3200978636741638\n",
      "[Step 13364] Loss: 9.45e+07 -0.32511866092681885 0.32007724046707153\n",
      "[Step 13365] Loss: 9.49e+07 -0.32512298226356506 0.32006898522377014\n",
      "[Step 13366] Loss: 9.52e+07 -0.3250580132007599 0.32006320357322693\n",
      "[Step 13367] Loss: 9.52e+07 -0.32490643858909607 0.32011932134628296\n",
      "[Step 13368] Loss: 9.50e+07 -0.32478487491607666 0.3201597332954407\n",
      "[Step 13369] Loss: 9.43e+07 -0.32466745376586914 0.3201795518398285\n",
      "[Step 13370] Loss: 9.52e+07 -0.324552983045578 0.3202034831047058\n",
      "[Step 13371] Loss: 9.56e+07 -0.32432353496551514 0.3202257454395294\n",
      "[Step 13372] Loss: 9.52e+07 -0.3241593837738037 0.3202744424343109\n",
      "[Step 13373] Loss: 9.51e+07 -0.32404112815856934 0.32029011845588684\n",
      "[Step 13374] Loss: 9.45e+07 -0.3238692879676819 0.3203330338001251\n",
      "[Step 13375] Loss: 9.61e+07 -0.32391485571861267 0.32032063603401184\n",
      "[Step 13376] Loss: 9.56e+07 -0.32414019107818604 0.32023730874061584\n",
      "[Step 13377] Loss: 9.53e+07 -0.3243768513202667 0.32018038630485535\n",
      "[Step 13378] Loss: 9.60e+07 -0.32454416155815125 0.32015562057495117\n",
      "[Step 13379] Loss: 9.53e+07 -0.32461097836494446 0.32014158368110657\n",
      "[Step 13380] Loss: 9.46e+07 -0.3246610760688782 0.32011106610298157\n",
      "[Step 13381] Loss: 9.58e+07 -0.3247852027416229 0.32005825638771057\n",
      "[Step 13382] Loss: 9.52e+07 -0.32487714290618896 0.32001450657844543\n",
      "[Step 13383] Loss: 9.51e+07 -0.3249565362930298 0.3199848234653473\n",
      "[Step 13384] Loss: 9.44e+07 -0.325032114982605 0.3199584186077118\n",
      "[Step 13385] Loss: 9.52e+07 -0.32501739263534546 0.319938600063324\n",
      "[Step 13386] Loss: 9.49e+07 -0.324910432100296 0.3199666738510132\n",
      "[Step 13387] Loss: 9.59e+07 -0.3246699273586273 0.3199906051158905\n",
      "[Step 13388] Loss: 9.58e+07 -0.32458820939064026 0.31997326016426086\n",
      "[Step 13389] Loss: 9.60e+07 -0.32460105419158936 0.319941908121109\n",
      "[Step 13390] Loss: 9.57e+07 -0.3246111571788788 0.3199138641357422\n",
      "[Step 13391] Loss: 9.58e+07 -0.3247735798358917 0.31984537839889526\n",
      "[Step 13392] Loss: 9.63e+07 -0.3250059187412262 0.3197735846042633\n",
      "[Step 13393] Loss: 9.55e+07 -0.325278639793396 0.31970342993736267\n",
      "[Step 13394] Loss: 9.48e+07 -0.32546985149383545 0.31961268186569214\n",
      "[Step 13395] Loss: 9.54e+07 -0.32569506764411926 0.31953510642051697\n",
      "[Step 13396] Loss: 9.68e+07 -0.3257168233394623 0.3195136487483978\n",
      "[Step 13397] Loss: 9.48e+07 -0.3258025050163269 0.3194534182548523\n",
      "[Step 13398] Loss: 9.48e+07 -0.3258751332759857 0.3193841278553009\n",
      "[Step 13399] Loss: 9.51e+07 -0.3260171413421631 0.31932222843170166\n",
      "[Step 13400] Loss: 9.65e+07 -0.32638081908226013 0.31921082735061646\n",
      "[Step 13401] Loss: 9.47e+07 -0.3267063796520233 0.3191085159778595\n",
      "[Step 13402] Loss: 9.50e+07 -0.32699689269065857 0.31901857256889343\n",
      "[Step 13403] Loss: 9.52e+07 -0.32722505927085876 0.3189319372177124\n",
      "[Step 13404] Loss: 9.50e+07 -0.3275059461593628 0.3188585042953491\n",
      "[Step 13405] Loss: 9.55e+07 -0.32766222953796387 0.31878340244293213\n",
      "[Step 13406] Loss: 9.52e+07 -0.3277938961982727 0.3187231719493866\n",
      "[Step 13407] Loss: 9.59e+07 -0.3278721570968628 0.3186885118484497\n",
      "[Step 13408] Loss: 9.54e+07 -0.3279300630092621 0.3186637759208679\n",
      "[Step 13409] Loss: 9.53e+07 -0.3280238211154938 0.3186414837837219\n",
      "[Step 13410] Loss: 9.62e+07 -0.32831886410713196 0.31854164600372314\n",
      "[Step 13411] Loss: 9.52e+07 -0.32860255241394043 0.3184731602668762\n",
      "[Step 13412] Loss: 9.57e+07 -0.3287087380886078 0.318433552980423\n",
      "[Step 13413] Loss: 9.56e+07 -0.3287672996520996 0.318403035402298\n",
      "[Step 13414] Loss: 9.60e+07 -0.3288721740245819 0.31837084889411926\n",
      "[Step 13415] Loss: 9.50e+07 -0.32889825105667114 0.3183683753013611\n",
      "[Step 13416] Loss: 9.56e+07 -0.3290829658508301 0.31831225752830505\n",
      "[Step 13417] Loss: 9.51e+07 -0.3291378617286682 0.31828173995018005\n",
      "[Step 13418] Loss: 9.51e+07 -0.32926052808761597 0.31824707984924316\n",
      "[Step 13419] Loss: 9.53e+07 -0.3293500542640686 0.31819427013397217\n",
      "[Step 13420] Loss: 9.50e+07 -0.32932010293006897 0.31819427013397217\n",
      "[Step 13421] Loss: 9.52e+07 -0.3293546438217163 0.3181513547897339\n",
      "[Step 13422] Loss: 9.42e+07 -0.32936346530914307 0.31812000274658203\n",
      "[Step 13423] Loss: 9.53e+07 -0.3294317126274109 0.31808122992515564\n",
      "[Step 13424] Loss: 9.56e+07 -0.3296635150909424 0.31804242730140686\n",
      "[Step 13425] Loss: 9.49e+07 -0.32987624406814575 0.31794920563697815\n",
      "[Step 13426] Loss: 9.52e+07 -0.32999882102012634 0.3178848326206207\n",
      "[Step 13427] Loss: 9.55e+07 -0.3300447165966034 0.317874938249588\n",
      "[Step 13428] Loss: 9.47e+07 -0.33006441593170166 0.3178510069847107\n",
      "[Step 13429] Loss: 9.50e+07 -0.3301587700843811 0.3177841603755951\n",
      "[Step 13430] Loss: 9.45e+07 -0.3302042782306671 0.3177396059036255\n",
      "[Step 13431] Loss: 9.54e+07 -0.33039742708206177 0.31768763065338135\n",
      "[Step 13432] Loss: 9.52e+07 -0.3305317759513855 0.3176538050174713\n",
      "[Step 13433] Loss: 9.53e+07 -0.3307499587535858 0.3175754249095917\n",
      "[Step 13434] Loss: 9.66e+07 -0.33079952001571655 0.31754323840141296\n",
      "[Step 13435] Loss: 9.61e+07 -0.33090677857398987 0.3174920678138733\n",
      "[Step 13436] Loss: 9.62e+07 -0.3311609923839569 0.31745660305023193\n",
      "[Step 13437] Loss: 9.54e+07 -0.33149924874305725 0.31738728284835815\n",
      "[Step 13438] Loss: 9.53e+07 -0.33186960220336914 0.31728002429008484\n",
      "[Step 13439] Loss: 9.52e+07 -0.3323177993297577 0.31712818145751953\n",
      "[Step 13440] Loss: 9.52e+07 -0.33273690938949585 0.3170011043548584\n",
      "[Step 13441] Loss: 9.47e+07 -0.3330930471420288 0.3169012665748596\n",
      "[Step 13442] Loss: 9.51e+07 -0.33342376351356506 0.31679317355155945\n",
      "[Step 13443] Loss: 9.54e+07 -0.3337228298187256 0.3166966438293457\n",
      "[Step 13444] Loss: 9.52e+07 -0.3340173065662384 0.31658607721328735\n",
      "[Step 13445] Loss: 9.58e+07 -0.3341892957687378 0.3165423572063446\n",
      "[Step 13446] Loss: 9.53e+07 -0.33437973260879517 0.31651511788368225\n",
      "[Step 13447] Loss: 9.54e+07 -0.33454176783561707 0.3164515793323517\n",
      "[Step 13448] Loss: 9.57e+07 -0.33467909693717957 0.3163929879665375\n",
      "[Step 13449] Loss: 9.54e+07 -0.33494386076927185 0.31630057096481323\n",
      "[Step 13450] Loss: 9.52e+07 -0.3352549076080322 0.3162098228931427\n",
      "[Step 13451] Loss: 9.51e+07 -0.33538907766342163 0.3161405026912689\n",
      "[Step 13452] Loss: 9.48e+07 -0.3354755640029907 0.3161050081253052\n",
      "[Step 13453] Loss: 9.53e+07 -0.335529088973999 0.31603899598121643\n",
      "[Step 13454] Loss: 9.51e+07 -0.335453599691391 0.3160167336463928\n",
      "[Step 13455] Loss: 9.53e+07 -0.33540770411491394 0.3159845471382141\n",
      "[Step 13456] Loss: 9.51e+07 -0.3353191018104553 0.31597548723220825\n",
      "[Step 13457] Loss: 9.50e+07 -0.3352591097354889 0.31596970558166504\n",
      "[Step 13458] Loss: 9.59e+07 -0.33504974842071533 0.31596639752388\n",
      "[Step 13459] Loss: 9.52e+07 -0.33480164408683777 0.31599611043930054\n",
      "[Step 13460] Loss: 9.53e+07 -0.33458447456359863 0.31600189208984375\n",
      "[Step 13461] Loss: 9.49e+07 -0.33435818552970886 0.3160068392753601\n",
      "[Step 13462] Loss: 9.53e+07 -0.3341818153858185 0.31600022315979004\n",
      "[Step 13463] Loss: 9.65e+07 -0.33417144417762756 0.3159845471382141\n",
      "[Step 13464] Loss: 9.48e+07 -0.3342147767543793 0.31596639752388\n",
      "[Step 13465] Loss: 9.51e+07 -0.33420267701148987 0.31597134470939636\n",
      "[Step 13466] Loss: 9.49e+07 -0.33424463868141174 0.3159507215023041\n",
      "[Step 13467] Loss: 9.45e+07 -0.3343032896518707 0.3159548342227936\n",
      "[Step 13468] Loss: 9.49e+07 -0.33441799879074097 0.3159012198448181\n",
      "[Step 13469] Loss: 9.55e+07 -0.33443543314933777 0.31588470935821533\n",
      "[Step 13470] Loss: 9.56e+07 -0.33430641889572144 0.3158937990665436\n",
      "[Step 13471] Loss: 9.59e+07 -0.33431169390678406 0.3159177005290985\n",
      "[Step 13472] Loss: 9.57e+07 -0.3341803252696991 0.31593090295791626\n",
      "[Step 13473] Loss: 9.45e+07 -0.33404862880706787 0.3159606158733368\n",
      "[Step 13474] Loss: 9.53e+07 -0.3339451253414154 0.31595897674560547\n",
      "[Step 13475] Loss: 9.54e+07 -0.3339042663574219 0.31592267751693726\n",
      "[Step 13476] Loss: 9.60e+07 -0.3340771794319153 0.3158756196498871\n",
      "[Step 13477] Loss: 9.48e+07 -0.3342151939868927 0.31579723954200745\n",
      "[Step 13478] Loss: 9.45e+07 -0.3342854678630829 0.3157493770122528\n",
      "[Step 13479] Loss: 9.44e+07 -0.3343612849712372 0.3157254457473755\n",
      "[Step 13480] Loss: 9.56e+07 -0.3343890905380249 0.3156949281692505\n",
      "[Step 13481] Loss: 9.51e+07 -0.33449697494506836 0.31563717126846313\n",
      "[Step 13482] Loss: 9.45e+07 -0.33466020226478577 0.315585196018219\n",
      "[Step 13483] Loss: 9.58e+07 -0.334762305021286 0.31550925970077515\n",
      "[Step 13484] Loss: 9.51e+07 -0.33478760719299316 0.3154671788215637\n",
      "[Step 13485] Loss: 9.49e+07 -0.3347381055355072 0.31547874212265015\n",
      "[Step 13486] Loss: 9.60e+07 -0.33486777544021606 0.31542840600013733\n",
      "[Step 13487] Loss: 9.55e+07 -0.3349713385105133 0.31538549065589905\n",
      "[Step 13488] Loss: 9.56e+07 -0.3351985514163971 0.31530627608299255\n",
      "[Step 13489] Loss: 9.51e+07 -0.3354083299636841 0.31524357199668884\n",
      "[Step 13490] Loss: 9.59e+07 -0.3356398642063141 0.3151412606239319\n",
      "[Step 13491] Loss: 9.53e+07 -0.3359319865703583 0.3150636851787567\n",
      "[Step 13492] Loss: 9.57e+07 -0.33608075976371765 0.31501007080078125\n",
      "[Step 13493] Loss: 9.50e+07 -0.33624598383903503 0.31492671370506287\n",
      "[Step 13494] Loss: 9.52e+07 -0.33651772141456604 0.31483182311058044\n",
      "[Step 13495] Loss: 9.50e+07 -0.33678728342056274 0.314736932516098\n",
      "[Step 13496] Loss: 9.63e+07 -0.33689644932746887 0.314684122800827\n",
      "[Step 13497] Loss: 9.50e+07 -0.33703354001045227 0.3146074116230011\n",
      "[Step 13498] Loss: 9.57e+07 -0.3372499942779541 0.3145471513271332\n",
      "[Step 13499] Loss: 9.52e+07 -0.3375161290168762 0.31443163752555847\n",
      "[Step 13500] Loss: 9.46e+07 -0.3377113938331604 0.3143293261528015\n",
      "[Step 13501] Loss: 9.53e+07 -0.3377619683742523 0.31429633498191833\n",
      "[Step 13502] Loss: 9.58e+07 -0.3377710282802582 0.31425341963768005\n",
      "[Step 13503] Loss: 9.58e+07 -0.3378278315067291 0.31419482827186584\n",
      "[Step 13504] Loss: 9.56e+07 -0.33785855770111084 0.31416016817092896\n",
      "[Step 13505] Loss: 9.53e+07 -0.33796507120132446 0.31412798166275024\n",
      "[Step 13506] Loss: 9.52e+07 -0.3381348252296448 0.31405290961265564\n",
      "[Step 13507] Loss: 9.47e+07 -0.33841297030448914 0.3139481246471405\n",
      "[Step 13508] Loss: 9.47e+07 -0.338693231344223 0.31384167075157166\n",
      "[Step 13509] Loss: 9.50e+07 -0.3389434218406677 0.3137575089931488\n",
      "[Step 13510] Loss: 9.55e+07 -0.3391536474227905 0.3136749863624573\n",
      "[Step 13511] Loss: 9.53e+07 -0.33923330903053284 0.3136700391769409\n",
      "[Step 13512] Loss: 9.52e+07 -0.3393869698047638 0.31361228227615356\n",
      "[Step 13513] Loss: 9.54e+07 -0.3396308124065399 0.3135066628456116\n",
      "[Step 13514] Loss: 9.51e+07 -0.33988383412361145 0.3134513795375824\n",
      "[Step 13515] Loss: 9.39e+07 -0.3400318920612335 0.31337299942970276\n",
      "[Step 13516] Loss: 9.53e+07 -0.3400540053844452 0.3133416473865509\n",
      "[Step 13517] Loss: 9.56e+07 -0.34020256996154785 0.3133276104927063\n",
      "[Step 13518] Loss: 9.56e+07 -0.3403695523738861 0.31322529911994934\n",
      "[Step 13519] Loss: 9.57e+07 -0.34055402874946594 0.31318238377571106\n",
      "[Step 13520] Loss: 9.45e+07 -0.34072238206863403 0.31310564279556274\n",
      "[Step 13521] Loss: 9.52e+07 -0.3409159481525421 0.31304293870925903\n",
      "[Step 13522] Loss: 9.48e+07 -0.341175377368927 0.3129802346229553\n",
      "[Step 13523] Loss: 9.46e+07 -0.34140264987945557 0.312934011220932\n",
      "[Step 13524] Loss: 9.47e+07 -0.3415733873844147 0.312903493642807\n",
      "[Step 13525] Loss: 9.52e+07 -0.34177589416503906 0.31285151839256287\n",
      "[Step 13526] Loss: 9.57e+07 -0.3420438766479492 0.31277477741241455\n",
      "[Step 13527] Loss: 9.56e+07 -0.34224605560302734 0.31273433566093445\n",
      "[Step 13528] Loss: 9.59e+07 -0.34230270981788635 0.31269142031669617\n",
      "[Step 13529] Loss: 9.58e+07 -0.3422718644142151 0.312688946723938\n",
      "[Step 13530] Loss: 9.46e+07 -0.3422166407108307 0.31267327070236206\n",
      "[Step 13531] Loss: 9.52e+07 -0.34214940667152405 0.31266748905181885\n",
      "[Step 13532] Loss: 9.65e+07 -0.34231507778167725 0.3126336634159088\n",
      "[Step 13533] Loss: 9.47e+07 -0.3424391746520996 0.3125816881656647\n",
      "[Step 13534] Loss: 9.52e+07 -0.3425859212875366 0.3125156760215759\n",
      "[Step 13535] Loss: 9.50e+07 -0.3426297605037689 0.31251320242881775\n",
      "[Step 13536] Loss: 9.55e+07 -0.3428017497062683 0.31245461106300354\n",
      "[Step 13537] Loss: 9.52e+07 -0.34296998381614685 0.3123844861984253\n",
      "[Step 13538] Loss: 9.59e+07 -0.34315919876098633 0.3123176395893097\n",
      "[Step 13539] Loss: 9.50e+07 -0.34332534670829773 0.31226566433906555\n",
      "[Step 13540] Loss: 9.53e+07 -0.3434396982192993 0.31220129132270813\n",
      "[Step 13541] Loss: 9.63e+07 -0.3436117470264435 0.3121468424797058\n",
      "[Step 13542] Loss: 9.47e+07 -0.3438454270362854 0.3120535910129547\n",
      "[Step 13543] Loss: 9.54e+07 -0.34403371810913086 0.31200408935546875\n",
      "[Step 13544] Loss: 9.45e+07 -0.344180703163147 0.3119925260543823\n",
      "[Step 13545] Loss: 9.57e+07 -0.34441596269607544 0.3119314908981323\n",
      "[Step 13546] Loss: 9.59e+07 -0.3444979190826416 0.3119001090526581\n",
      "[Step 13547] Loss: 9.50e+07 -0.34455016255378723 0.3118811547756195\n",
      "[Step 13548] Loss: 9.62e+07 -0.34444281458854675 0.31189435720443726\n",
      "[Step 13549] Loss: 9.53e+07 -0.3442213535308838 0.31193724274635315\n",
      "[Step 13550] Loss: 9.57e+07 -0.34396234154701233 0.3119867742061615\n",
      "[Step 13551] Loss: 9.60e+07 -0.34362322092056274 0.31206679344177246\n",
      "[Step 13552] Loss: 9.49e+07 -0.3433477282524109 0.31213197112083435\n",
      "[Step 13553] Loss: 9.62e+07 -0.3433090150356293 0.3121394217014313\n",
      "[Step 13554] Loss: 9.52e+07 -0.34326115250587463 0.3121451735496521\n",
      "[Step 13555] Loss: 9.52e+07 -0.343203067779541 0.31214189529418945\n",
      "[Step 13556] Loss: 9.44e+07 -0.3430997431278229 0.31214436888694763\n",
      "[Step 13557] Loss: 9.48e+07 -0.3429545760154724 0.31216830015182495\n",
      "[Step 13558] Loss: 9.49e+07 -0.3428339958190918 0.31215590238571167\n",
      "[Step 13559] Loss: 9.52e+07 -0.34265679121017456 0.3121963441371918\n",
      "[Step 13560] Loss: 9.52e+07 -0.34241795539855957 0.31222522258758545\n",
      "[Step 13561] Loss: 9.45e+07 -0.3421531021595001 0.3122805058956146\n",
      "[Step 13562] Loss: 9.55e+07 -0.34201350808143616 0.3123011291027069\n",
      "[Step 13563] Loss: 9.55e+07 -0.3419968783855438 0.31227967143058777\n",
      "[Step 13564] Loss: 9.48e+07 -0.3419662117958069 0.3122524619102478\n",
      "[Step 13565] Loss: 9.50e+07 -0.3419152498245239 0.3122623562812805\n",
      "[Step 13566] Loss: 9.49e+07 -0.3418451249599457 0.31221118569374084\n",
      "[Step 13567] Loss: 9.50e+07 -0.34183862805366516 0.31221863627433777\n",
      "[Step 13568] Loss: 9.52e+07 -0.34181272983551025 0.3122079074382782\n",
      "[Step 13569] Loss: 9.57e+07 -0.341727077960968 0.3122103810310364\n",
      "[Step 13570] Loss: 9.60e+07 -0.34168288111686707 0.312202125787735\n",
      "[Step 13571] Loss: 9.51e+07 -0.34159567952156067 0.3122260570526123\n",
      "[Step 13572] Loss: 9.54e+07 -0.3415106236934662 0.31221118569374084\n",
      "[Step 13573] Loss: 9.62e+07 -0.3415769338607788 0.3121839761734009\n",
      "[Step 13574] Loss: 9.54e+07 -0.34154728055000305 0.3121955096721649\n",
      "[Step 13575] Loss: 9.44e+07 -0.3415313959121704 0.3121773600578308\n",
      "[Step 13576] Loss: 9.45e+07 -0.34152302145957947 0.31215426325798035\n",
      "[Step 13577] Loss: 9.49e+07 -0.3415692448616028 0.3121608793735504\n",
      "[Step 13578] Loss: 9.47e+07 -0.3415277898311615 0.31215015053749084\n",
      "[Step 13579] Loss: 9.51e+07 -0.34141626954078674 0.31214767694473267\n",
      "[Step 13580] Loss: 9.71e+07 -0.3415669798851013 0.31211134791374207\n",
      "[Step 13581] Loss: 9.56e+07 -0.34180977940559387 0.31203049421310425\n",
      "[Step 13582] Loss: 9.63e+07 -0.3421781361103058 0.31191331148147583\n",
      "[Step 13583] Loss: 9.51e+07 -0.34247246384620667 0.3118044137954712\n",
      "[Step 13584] Loss: 9.54e+07 -0.3426409065723419 0.31173592805862427\n",
      "[Step 13585] Loss: 9.67e+07 -0.3429817855358124 0.31160968542099\n",
      "[Step 13586] Loss: 9.54e+07 -0.34324201941490173 0.311504065990448\n",
      "[Step 13587] Loss: 9.63e+07 -0.3436279892921448 0.3113868832588196\n",
      "[Step 13588] Loss: 9.49e+07 -0.343952476978302 0.3112581670284271\n",
      "[Step 13589] Loss: 9.48e+07 -0.34418779611587524 0.31119051575660706\n",
      "[Step 13590] Loss: 9.56e+07 -0.3443707823753357 0.3111245036125183\n",
      "[Step 13591] Loss: 9.51e+07 -0.3445585072040558 0.3110279440879822\n",
      "[Step 13592] Loss: 9.50e+07 -0.34488120675086975 0.3109223246574402\n",
      "[Step 13593] Loss: 9.61e+07 -0.34533432126045227 0.31081423163414\n",
      "[Step 13594] Loss: 9.58e+07 -0.345868855714798 0.3106764554977417\n",
      "[Step 13595] Loss: 9.55e+07 -0.346417099237442 0.3105138838291168\n",
      "[Step 13596] Loss: 9.44e+07 -0.34688830375671387 0.31035465002059937\n",
      "[Step 13597] Loss: 9.54e+07 -0.34735098481178284 0.3101920783519745\n",
      "[Step 13598] Loss: 9.50e+07 -0.34778091311454773 0.3100782334804535\n",
      "[Step 13599] Loss: 9.54e+07 -0.3480846881866455 0.3099849820137024\n",
      "[Step 13600] Loss: 9.49e+07 -0.34832799434661865 0.3099321722984314\n",
      "[Step 13601] Loss: 9.53e+07 -0.34868040680885315 0.30981335043907166\n",
      "[Step 13602] Loss: 9.56e+07 -0.3490745425224304 0.30966565012931824\n",
      "[Step 13603] Loss: 9.51e+07 -0.34948602318763733 0.30952125787734985\n",
      "[Step 13604] Loss: 9.54e+07 -0.3499380648136139 0.3093686103820801\n",
      "[Step 13605] Loss: 9.54e+07 -0.350320041179657 0.30924317240715027\n",
      "[Step 13606] Loss: 9.55e+07 -0.3508279323577881 0.3090740144252777\n",
      "[Step 13607] Loss: 9.53e+07 -0.3512098789215088 0.30894777178764343\n",
      "[Step 13608] Loss: 9.50e+07 -0.3516446053981781 0.3088124692440033\n",
      "[Step 13609] Loss: 9.52e+07 -0.3520801365375519 0.30870354175567627\n",
      "[Step 13610] Loss: 9.54e+07 -0.352448046207428 0.308607816696167\n",
      "[Step 13611] Loss: 9.47e+07 -0.3528173863887787 0.3084692060947418\n",
      "[Step 13612] Loss: 9.58e+07 -0.35328614711761475 0.30829179286956787\n",
      "[Step 13613] Loss: 9.51e+07 -0.35364261269569397 0.3081589639186859\n",
      "[Step 13614] Loss: 9.63e+07 -0.3540811836719513 0.3080434203147888\n",
      "[Step 13615] Loss: 9.55e+07 -0.35450053215026855 0.307879239320755\n",
      "[Step 13616] Loss: 9.49e+07 -0.35489189624786377 0.307770311832428\n",
      "[Step 13617] Loss: 9.55e+07 -0.3553076684474945 0.3076275587081909\n",
      "[Step 13618] Loss: 9.48e+07 -0.3556763231754303 0.3075145184993744\n",
      "[Step 13619] Loss: 9.45e+07 -0.35598719120025635 0.3074130415916443\n",
      "[Step 13620] Loss: 9.47e+07 -0.3562036454677582 0.3073519766330719\n",
      "[Step 13621] Loss: 9.45e+07 -0.35638153553009033 0.30727770924568176\n",
      "[Step 13622] Loss: 9.53e+07 -0.3566328287124634 0.30719849467277527\n",
      "[Step 13623] Loss: 9.56e+07 -0.35680246353149414 0.3071497976779938\n",
      "[Step 13624] Loss: 9.49e+07 -0.35700932145118713 0.3071044385433197\n",
      "[Step 13625] Loss: 9.52e+07 -0.35707393288612366 0.30705490708351135\n",
      "[Step 13626] Loss: 9.44e+07 -0.3570633828639984 0.3070433735847473\n",
      "[Step 13627] Loss: 9.47e+07 -0.3570062816143036 0.30704253911972046\n",
      "[Step 13628] Loss: 9.55e+07 -0.3568302094936371 0.30704832077026367\n",
      "[Step 13629] Loss: 9.55e+07 -0.35672876238822937 0.3070541024208069\n",
      "[Step 13630] Loss: 9.53e+07 -0.3565725088119507 0.3070615231990814\n",
      "[Step 13631] Loss: 9.53e+07 -0.3565318286418915 0.30704089999198914\n",
      "[Step 13632] Loss: 9.49e+07 -0.3564651608467102 0.3069946765899658\n",
      "[Step 13633] Loss: 9.52e+07 -0.3564735949039459 0.30697816610336304\n",
      "[Step 13634] Loss: 9.54e+07 -0.3565712869167328 0.3069344460964203\n",
      "[Step 13635] Loss: 9.51e+07 -0.35665369033813477 0.30687832832336426\n",
      "[Step 13636] Loss: 9.59e+07 -0.3566262423992157 0.30685853958129883\n",
      "[Step 13637] Loss: 9.53e+07 -0.3566032648086548 0.30685439705848694\n",
      "[Step 13638] Loss: 9.51e+07 -0.3564266264438629 0.30687668919563293\n",
      "[Step 13639] Loss: 9.51e+07 -0.3563106656074524 0.3069014549255371\n",
      "[Step 13640] Loss: 9.54e+07 -0.35632848739624023 0.30690887570381165\n",
      "[Step 13641] Loss: 9.56e+07 -0.35631778836250305 0.30693280696868896\n",
      "[Step 13642] Loss: 9.51e+07 -0.3563033640384674 0.30693280696868896\n",
      "[Step 13643] Loss: 9.50e+07 -0.35620570182800293 0.30694517493247986\n",
      "[Step 13644] Loss: 9.47e+07 -0.3561836779117584 0.30692288279533386\n",
      "[Step 13645] Loss: 9.54e+07 -0.3560607433319092 0.30690309405326843\n",
      "[Step 13646] Loss: 9.54e+07 -0.35603222250938416 0.30690640211105347\n",
      "[Step 13647] Loss: 9.55e+07 -0.35594141483306885 0.30690640211105347\n",
      "[Step 13648] Loss: 9.46e+07 -0.3559194803237915 0.30689483880996704\n",
      "[Step 13649] Loss: 9.61e+07 -0.35573887825012207 0.30692702531814575\n",
      "[Step 13650] Loss: 9.75e+07 -0.3558661639690399 0.3068651258945465\n",
      "[Step 13651] Loss: 9.55e+07 -0.356119304895401 0.3067900538444519\n",
      "[Step 13652] Loss: 9.53e+07 -0.3563142418861389 0.3067050576210022\n",
      "[Step 13653] Loss: 9.55e+07 -0.3566015362739563 0.30659037828445435\n",
      "[Step 13654] Loss: 9.62e+07 -0.3567459285259247 0.3065425157546997\n",
      "[Step 13655] Loss: 9.59e+07 -0.35694125294685364 0.306479811668396\n",
      "[Step 13656] Loss: 9.59e+07 -0.35727253556251526 0.3063585162162781\n",
      "[Step 13657] Loss: 9.50e+07 -0.35748490691185 0.3062611222267151\n",
      "[Step 13658] Loss: 9.53e+07 -0.3576914668083191 0.30616873502731323\n",
      "[Step 13659] Loss: 9.58e+07 -0.357888400554657 0.3060886859893799\n",
      "[Step 13660] Loss: 9.43e+07 -0.35802823305130005 0.3060210347175598\n",
      "[Step 13661] Loss: 9.56e+07 -0.35825154185295105 0.305917888879776\n",
      "[Step 13662] Loss: 9.49e+07 -0.3584931194782257 0.305808961391449\n",
      "[Step 13663] Loss: 9.48e+07 -0.35876205563545227 0.30570581555366516\n",
      "[Step 13664] Loss: 9.45e+07 -0.3590257465839386 0.30563074350357056\n",
      "[Step 13665] Loss: 9.45e+07 -0.3593008816242218 0.3055300712585449\n",
      "[Step 13666] Loss: 9.54e+07 -0.35945266485214233 0.3054904639720917\n",
      "[Step 13667] Loss: 9.53e+07 -0.3595070242881775 0.3054368197917938\n",
      "[Step 13668] Loss: 9.61e+07 -0.3594924509525299 0.3054046332836151\n",
      "[Step 13669] Loss: 9.60e+07 -0.35947245359420776 0.3053534924983978\n",
      "[Step 13670] Loss: 9.46e+07 -0.35943660140037537 0.3053402900695801\n",
      "[Step 13671] Loss: 9.55e+07 -0.35934844613075256 0.30532708764076233\n",
      "[Step 13672] Loss: 9.55e+07 -0.3591919243335724 0.30531635880470276\n",
      "[Step 13673] Loss: 9.49e+07 -0.3590550124645233 0.3053278923034668\n",
      "[Step 13674] Loss: 9.53e+07 -0.35886484384536743 0.30535513162612915\n",
      "[Step 13675] Loss: 9.54e+07 -0.35867345333099365 0.3054071068763733\n",
      "[Step 13676] Loss: 9.54e+07 -0.3586329519748688 0.3054029941558838\n",
      "[Step 13677] Loss: 9.51e+07 -0.3585566282272339 0.30540215969085693\n",
      "[Step 13678] Loss: 9.54e+07 -0.358336478471756 0.30542030930519104\n",
      "[Step 13679] Loss: 9.50e+07 -0.3580748438835144 0.3054673671722412\n",
      "[Step 13680] Loss: 9.53e+07 -0.35780099034309387 0.30550530552864075\n",
      "[Step 13681] Loss: 9.49e+07 -0.357453316450119 0.30559441447257996\n",
      "[Step 13682] Loss: 9.47e+07 -0.3571661114692688 0.30561918020248413\n",
      "[Step 13683] Loss: 9.50e+07 -0.3568497598171234 0.30567529797554016\n",
      "[Step 13684] Loss: 9.51e+07 -0.35645562410354614 0.30574706196784973\n",
      "[Step 13685] Loss: 9.50e+07 -0.35602331161499023 0.3058535158634186\n",
      "[Step 13686] Loss: 9.60e+07 -0.35567256808280945 0.3058873414993286\n",
      "[Step 13687] Loss: 9.42e+07 -0.35535600781440735 0.305948406457901\n",
      "[Step 13688] Loss: 9.63e+07 -0.35526129603385925 0.3059154152870178\n",
      "[Step 13689] Loss: 9.46e+07 -0.35524579882621765 0.3058815598487854\n",
      "[Step 13690] Loss: 9.63e+07 -0.3553880453109741 0.30585187673568726\n",
      "[Step 13691] Loss: 9.51e+07 -0.355595201253891 0.3057957589626312\n",
      "[Step 13692] Loss: 9.52e+07 -0.3558359742164612 0.30569756031036377\n",
      "[Step 13693] Loss: 9.53e+07 -0.3561129570007324 0.30559608340263367\n",
      "[Step 13694] Loss: 9.46e+07 -0.35641393065452576 0.30550283193588257\n",
      "[Step 13695] Loss: 9.45e+07 -0.3567005693912506 0.3053848445415497\n",
      "[Step 13696] Loss: 9.53e+07 -0.3570895195007324 0.3052387833595276\n",
      "[Step 13697] Loss: 9.49e+07 -0.35745906829833984 0.30513235926628113\n",
      "[Step 13698] Loss: 9.50e+07 -0.35772818326950073 0.3050382733345032\n",
      "[Step 13699] Loss: 9.43e+07 -0.3579448163509369 0.30497145652770996\n",
      "[Step 13700] Loss: 9.50e+07 -0.35821080207824707 0.30491697788238525\n",
      "[Step 13701] Loss: 9.47e+07 -0.35842785239219666 0.30484601855278015\n",
      "[Step 13702] Loss: 9.55e+07 -0.3587445020675659 0.3047453463077545\n",
      "[Step 13703] Loss: 9.64e+07 -0.35924673080444336 0.3046092092990875\n",
      "[Step 13704] Loss: 9.65e+07 -0.359799861907959 0.3044615089893341\n",
      "[Step 13705] Loss: 9.50e+07 -0.3602662980556488 0.3043484687805176\n",
      "[Step 13706] Loss: 9.51e+07 -0.36070799827575684 0.3042106628417969\n",
      "[Step 13707] Loss: 9.57e+07 -0.36108922958374023 0.304095983505249\n",
      "[Step 13708] Loss: 9.47e+07 -0.3614606559276581 0.30400189757347107\n",
      "[Step 13709] Loss: 9.57e+07 -0.3617514967918396 0.30394744873046875\n",
      "[Step 13710] Loss: 9.50e+07 -0.36192265152931213 0.3039259910583496\n",
      "[Step 13711] Loss: 9.46e+07 -0.3619786202907562 0.30390867590904236\n",
      "[Step 13712] Loss: 9.50e+07 -0.36201271414756775 0.30389299988746643\n",
      "[Step 13713] Loss: 9.52e+07 -0.3621235489845276 0.30386412143707275\n",
      "[Step 13714] Loss: 9.57e+07 -0.36215466260910034 0.3038484454154968\n",
      "[Step 13715] Loss: 9.43e+07 -0.3621794581413269 0.30385419726371765\n",
      "[Step 13716] Loss: 9.47e+07 -0.3622204661369324 0.30385255813598633\n",
      "[Step 13717] Loss: 9.50e+07 -0.36228811740875244 0.3038393557071686\n",
      "[Step 13718] Loss: 9.59e+07 -0.36220255494117737 0.3038773238658905\n",
      "[Step 13719] Loss: 9.50e+07 -0.362128347158432 0.30385586619377136\n",
      "[Step 13720] Loss: 9.49e+07 -0.36209356784820557 0.30386245250701904\n",
      "[Step 13721] Loss: 9.59e+07 -0.36196646094322205 0.30385255813598633\n",
      "[Step 13722] Loss: 9.45e+07 -0.3617807924747467 0.30388227105140686\n",
      "[Step 13723] Loss: 9.51e+07 -0.36169862747192383 0.3038756549358368\n",
      "[Step 13724] Loss: 9.52e+07 -0.3615973889827728 0.30385833978652954\n",
      "[Step 13725] Loss: 9.45e+07 -0.3615322709083557 0.3038104772567749\n",
      "[Step 13726] Loss: 9.51e+07 -0.3614814877510071 0.30380141735076904\n",
      "[Step 13727] Loss: 9.54e+07 -0.3614773750305176 0.30377665162086487\n",
      "[Step 13728] Loss: 9.51e+07 -0.3614625334739685 0.3037700355052948\n",
      "[Step 13729] Loss: 9.50e+07 -0.36140143871307373 0.3037882149219513\n",
      "[Step 13730] Loss: 9.43e+07 -0.3612806797027588 0.3038162589073181\n",
      "[Step 13731] Loss: 9.50e+07 -0.3611375093460083 0.3038773238658905\n",
      "[Step 13732] Loss: 9.50e+07 -0.36090654134750366 0.30388143658638\n",
      "[Step 13733] Loss: 9.53e+07 -0.36080363392829895 0.30390289425849915\n",
      "[Step 13734] Loss: 9.47e+07 -0.36063119769096375 0.3039160966873169\n",
      "[Step 13735] Loss: 9.46e+07 -0.36046525835990906 0.30392929911613464\n",
      "[Step 13736] Loss: 9.52e+07 -0.3603225648403168 0.30394166707992554\n",
      "[Step 13737] Loss: 9.43e+07 -0.36017704010009766 0.3039722144603729\n",
      "[Step 13738] Loss: 9.56e+07 -0.3600458800792694 0.3039722144603729\n",
      "[Step 13739] Loss: 9.65e+07 -0.36007216572761536 0.30395981669425964\n",
      "[Step 13740] Loss: 9.46e+07 -0.36010658740997314 0.30392929911613464\n",
      "[Step 13741] Loss: 9.46e+07 -0.36012545228004456 0.3039317727088928\n",
      "[Step 13742] Loss: 9.51e+07 -0.3601771295070648 0.3039243519306183\n",
      "[Step 13743] Loss: 9.55e+07 -0.3603177070617676 0.30384597182273865\n",
      "[Step 13744] Loss: 9.51e+07 -0.360372394323349 0.3038203716278076\n",
      "[Step 13745] Loss: 9.41e+07 -0.36043041944503784 0.30380716919898987\n",
      "[Step 13746] Loss: 9.53e+07 -0.3606399893760681 0.3036883473396301\n",
      "[Step 13747] Loss: 9.44e+07 -0.3607729971408844 0.3036182224750519\n",
      "[Step 13748] Loss: 9.45e+07 -0.3609158992767334 0.3035546839237213\n",
      "[Step 13749] Loss: 9.45e+07 -0.36102840304374695 0.3035241663455963\n",
      "[Step 13750] Loss: 9.58e+07 -0.36119160056114197 0.30346062779426575\n",
      "[Step 13751] Loss: 9.56e+07 -0.3614022433757782 0.30339545011520386\n",
      "[Step 13752] Loss: 9.46e+07 -0.36160632967948914 0.3032848536968231\n",
      "[Step 13753] Loss: 9.53e+07 -0.3617894649505615 0.303202360868454\n",
      "[Step 13754] Loss: 9.45e+07 -0.36195746064186096 0.30311983823776245\n",
      "[Step 13755] Loss: 9.56e+07 -0.36210840940475464 0.3030274212360382\n",
      "[Step 13756] Loss: 9.45e+07 -0.3622487485408783 0.30293747782707214\n",
      "[Step 13757] Loss: 9.48e+07 -0.36229124665260315 0.30289706587791443\n",
      "[Step 13758] Loss: 9.50e+07 -0.3623359799385071 0.302863210439682\n",
      "[Step 13759] Loss: 9.52e+07 -0.3622598648071289 0.30282196402549744\n",
      "[Step 13760] Loss: 9.54e+07 -0.36222758889198303 0.3027864992618561\n",
      "[Step 13761] Loss: 9.47e+07 -0.3621686100959778 0.30276256799697876\n",
      "[Step 13762] Loss: 9.67e+07 -0.3619639277458191 0.30275678634643555\n",
      "[Step 13763] Loss: 9.44e+07 -0.3617986738681793 0.30275264382362366\n",
      "[Step 13764] Loss: 9.53e+07 -0.3616621494293213 0.3027295470237732\n",
      "[Step 13765] Loss: 9.47e+07 -0.3615809381008148 0.30273038148880005\n",
      "[Step 13766] Loss: 9.52e+07 -0.36149224638938904 0.3027295470237732\n",
      "[Step 13767] Loss: 9.61e+07 -0.3615761399269104 0.3026701509952545\n",
      "[Step 13768] Loss: 9.50e+07 -0.3616733253002167 0.3026074171066284\n",
      "[Step 13769] Loss: 9.48e+07 -0.3616701662540436 0.30257442593574524\n",
      "[Step 13770] Loss: 9.54e+07 -0.3618052303791046 0.30249685049057007\n",
      "[Step 13771] Loss: 9.55e+07 -0.361876904964447 0.302459716796875\n",
      "[Step 13772] Loss: 9.50e+07 -0.3618556261062622 0.3024003207683563\n",
      "[Step 13773] Loss: 9.50e+07 -0.3618980348110199 0.3023598790168762\n",
      "[Step 13774] Loss: 9.52e+07 -0.3621244430541992 0.30228644609451294\n",
      "[Step 13775] Loss: 9.51e+07 -0.3622862994670868 0.30223941802978516\n",
      "[Step 13776] Loss: 9.59e+07 -0.36265894770622253 0.30210986733436584\n",
      "[Step 13777] Loss: 9.55e+07 -0.362922728061676 0.3019885718822479\n",
      "[Step 13778] Loss: 9.51e+07 -0.3631221354007721 0.30194565653800964\n",
      "[Step 13779] Loss: 9.48e+07 -0.3633551597595215 0.3018516004085541\n",
      "[Step 13780] Loss: 9.51e+07 -0.3636307716369629 0.30176249146461487\n",
      "[Step 13781] Loss: 9.50e+07 -0.3639145791530609 0.30168163776397705\n",
      "[Step 13782] Loss: 9.60e+07 -0.36407262086868286 0.3016263544559479\n",
      "[Step 13783] Loss: 9.48e+07 -0.3642880618572235 0.3015768229961395\n",
      "[Step 13784] Loss: 9.52e+07 -0.36456263065338135 0.30148524045944214\n",
      "[Step 13785] Loss: 9.56e+07 -0.36494144797325134 0.3013680875301361\n",
      "[Step 13786] Loss: 9.54e+07 -0.36522361636161804 0.3012690544128418\n",
      "[Step 13787] Loss: 9.46e+07 -0.3654595613479614 0.30119645595550537\n",
      "[Step 13788] Loss: 9.49e+07 -0.3656693398952484 0.30113622546195984\n",
      "[Step 13789] Loss: 9.45e+07 -0.36589524149894714 0.30107516050338745\n",
      "[Step 13790] Loss: 9.48e+07 -0.3660608232021332 0.3010132610797882\n",
      "[Step 13791] Loss: 9.53e+07 -0.366213321685791 0.30097779631614685\n",
      "[Step 13792] Loss: 9.53e+07 -0.3664540946483612 0.3009158968925476\n",
      "[Step 13793] Loss: 9.61e+07 -0.36662107706069946 0.300924152135849\n",
      "[Step 13794] Loss: 9.49e+07 -0.366727739572525 0.3008853793144226\n",
      "[Step 13795] Loss: 9.48e+07 -0.3667779266834259 0.30086639523506165\n",
      "[Step 13796] Loss: 9.45e+07 -0.36688756942749023 0.3008119463920593\n",
      "[Step 13797] Loss: 9.54e+07 -0.3668966591358185 0.30083584785461426\n",
      "[Step 13798] Loss: 9.55e+07 -0.36689263582229614 0.30079707503318787\n",
      "[Step 13799] Loss: 9.60e+07 -0.36700671911239624 0.30079543590545654\n",
      "[Step 13800] Loss: 9.67e+07 -0.36699023842811584 0.30081605911254883\n",
      "[Step 13801] Loss: 9.53e+07 -0.367087721824646 0.3007822334766388\n",
      "[Step 13802] Loss: 9.40e+07 -0.3672182261943817 0.30071374773979187\n",
      "[Step 13803] Loss: 9.53e+07 -0.3673660457134247 0.3006221652030945\n",
      "[Step 13804] Loss: 9.51e+07 -0.3674575090408325 0.3006056547164917\n",
      "[Step 13805] Loss: 9.49e+07 -0.3675330877304077 0.30053797364234924\n",
      "[Step 13806] Loss: 9.49e+07 -0.3676029145717621 0.30048105120658875\n",
      "[Step 13807] Loss: 9.57e+07 -0.3677319884300232 0.30042412877082825\n",
      "[Step 13808] Loss: 9.49e+07 -0.3678279519081116 0.3003861606121063\n",
      "[Step 13809] Loss: 9.50e+07 -0.3679652512073517 0.30029457807540894\n",
      "[Step 13810] Loss: 9.55e+07 -0.3680098056793213 0.3002830147743225\n",
      "[Step 13811] Loss: 9.62e+07 -0.3681829869747162 0.3002203106880188\n",
      "[Step 13812] Loss: 9.49e+07 -0.3683651089668274 0.3001576066017151\n",
      "[Step 13813] Loss: 9.58e+07 -0.36856886744499207 0.3000923991203308\n",
      "[Step 13814] Loss: 9.48e+07 -0.36877986788749695 0.300045371055603\n",
      "[Step 13815] Loss: 9.52e+07 -0.3688803017139435 0.3000296950340271\n",
      "[Step 13816] Loss: 9.50e+07 -0.36888739466667175 0.3000131845474243\n",
      "[Step 13817] Loss: 9.49e+07 -0.3688276708126068 0.29999256134033203\n",
      "[Step 13818] Loss: 9.52e+07 -0.36868172883987427 0.30001071095466614\n",
      "[Step 13819] Loss: 9.52e+07 -0.3685612976551056 0.3000354766845703\n",
      "[Step 13820] Loss: 9.62e+07 -0.36825793981552124 0.30006682872772217\n",
      "[Step 13821] Loss: 9.55e+07 -0.36813947558403015 0.30008170008659363\n",
      "[Step 13822] Loss: 9.50e+07 -0.36805635690689087 0.3000503182411194\n",
      "[Step 13823] Loss: 9.59e+07 -0.3680685758590698 0.30000001192092896\n",
      "[Step 13824] Loss: 9.51e+07 -0.36820387840270996 0.29995542764663696\n",
      "[Step 13825] Loss: 9.51e+07 -0.36834773421287537 0.29990512132644653\n",
      "[Step 13826] Loss: 9.55e+07 -0.3684106469154358 0.29983991384506226\n",
      "[Step 13827] Loss: 9.51e+07 -0.36841312050819397 0.2997879385948181\n",
      "[Step 13828] Loss: 9.49e+07 -0.36839497089385986 0.29977309703826904\n",
      "[Step 13829] Loss: 9.58e+07 -0.36857661604881287 0.29969221353530884\n",
      "[Step 13830] Loss: 9.49e+07 -0.36878976225852966 0.2996542751789093\n",
      "[Step 13831] Loss: 9.53e+07 -0.36907678842544556 0.2995733916759491\n",
      "[Step 13832] Loss: 9.50e+07 -0.3693530261516571 0.29951152205467224\n",
      "[Step 13833] Loss: 9.57e+07 -0.3695808947086334 0.2994818091392517\n",
      "[Step 13834] Loss: 9.56e+07 -0.36969900131225586 0.2994578778743744\n",
      "[Step 13835] Loss: 9.56e+07 -0.36973729729652405 0.29943642020225525\n",
      "[Step 13836] Loss: 9.49e+07 -0.36974433064460754 0.29945623874664307\n",
      "[Step 13837] Loss: 9.53e+07 -0.3697044849395752 0.29945456981658936\n",
      "[Step 13838] Loss: 9.54e+07 -0.3696078062057495 0.2994735538959503\n",
      "[Step 13839] Loss: 9.53e+07 -0.3695613145828247 0.2994620203971863\n",
      "[Step 13840] Loss: 9.51e+07 -0.369608074426651 0.2994331419467926\n",
      "[Step 13841] Loss: 9.59e+07 -0.3698064088821411 0.2993885576725006\n",
      "[Step 13842] Loss: 9.60e+07 -0.3698861598968506 0.2993497848510742\n",
      "[Step 13843] Loss: 9.47e+07 -0.3699086308479309 0.29933327436447144\n",
      "[Step 13844] Loss: 9.63e+07 -0.3700459897518158 0.29930606484413147\n",
      "[Step 13845] Loss: 9.49e+07 -0.37003281712532043 0.2992664575576782\n",
      "[Step 13846] Loss: 9.53e+07 -0.3701162040233612 0.29920125007629395\n",
      "[Step 13847] Loss: 9.49e+07 -0.3702296316623688 0.29914185404777527\n",
      "[Step 13848] Loss: 9.46e+07 -0.37025704979896545 0.29909151792526245\n",
      "[Step 13849] Loss: 9.44e+07 -0.37034308910369873 0.2990271747112274\n",
      "[Step 13850] Loss: 9.50e+07 -0.37034937739372253 0.29899662733078003\n",
      "[Step 13851] Loss: 9.46e+07 -0.37034568190574646 0.29896363615989685\n",
      "[Step 13852] Loss: 9.78e+07 -0.37054723501205444 0.2988249957561493\n",
      "[Step 13853] Loss: 9.55e+07 -0.3708265423774719 0.29872599244117737\n",
      "[Step 13854] Loss: 9.54e+07 -0.371169775724411 0.2986080050468445\n",
      "[Step 13855] Loss: 9.58e+07 -0.37154799699783325 0.29846689105033875\n",
      "[Step 13856] Loss: 9.48e+07 -0.3717745244503021 0.29841160774230957\n",
      "[Step 13857] Loss: 9.61e+07 -0.3718229830265045 0.2983686923980713\n",
      "[Step 13858] Loss: 9.61e+07 -0.3719838261604309 0.2982936203479767\n",
      "[Step 13859] Loss: 9.48e+07 -0.37209463119506836 0.29823172092437744\n",
      "[Step 13860] Loss: 9.77e+07 -0.37250766158103943 0.29808568954467773\n",
      "[Step 13861] Loss: 9.51e+07 -0.3728332817554474 0.2979643940925598\n",
      "[Step 13862] Loss: 9.43e+07 -0.3732038140296936 0.2978249490261078\n",
      "[Step 13863] Loss: 9.59e+07 -0.37359851598739624 0.29771023988723755\n",
      "[Step 13864] Loss: 9.45e+07 -0.3739158511161804 0.29758894443511963\n",
      "[Step 13865] Loss: 9.56e+07 -0.37433162331581116 0.2974272072315216\n",
      "[Step 13866] Loss: 9.52e+07 -0.3748481571674347 0.2972910702228546\n",
      "[Step 13867] Loss: 9.52e+07 -0.37537574768066406 0.29714253544807434\n",
      "[Step 13868] Loss: 9.52e+07 -0.3758472502231598 0.29701876640319824\n",
      "[Step 13869] Loss: 9.54e+07 -0.37625986337661743 0.29690492153167725\n",
      "[Step 13870] Loss: 9.47e+07 -0.37663912773132324 0.29674071073532104\n",
      "[Step 13871] Loss: 9.52e+07 -0.37696072459220886 0.2966458201408386\n",
      "[Step 13872] Loss: 9.48e+07 -0.37733006477355957 0.29653605818748474\n",
      "[Step 13873] Loss: 9.54e+07 -0.3776484727859497 0.2964494228363037\n",
      "[Step 13874] Loss: 9.53e+07 -0.37784621119499207 0.2963925004005432\n",
      "[Step 13875] Loss: 9.44e+07 -0.3780958652496338 0.2963009178638458\n",
      "[Step 13876] Loss: 9.45e+07 -0.3784075379371643 0.29621508717536926\n",
      "[Step 13877] Loss: 9.50e+07 -0.37864869832992554 0.29611194133758545\n",
      "[Step 13878] Loss: 9.50e+07 -0.3788008391857147 0.29603850841522217\n",
      "[Step 13879] Loss: 9.49e+07 -0.3788721561431885 0.29599395394325256\n",
      "[Step 13880] Loss: 9.55e+07 -0.3790854513645172 0.2959139049053192\n",
      "[Step 13881] Loss: 9.53e+07 -0.37919527292251587 0.2958833873271942\n",
      "[Step 13882] Loss: 9.53e+07 -0.3793458342552185 0.29581159353256226\n",
      "[Step 13883] Loss: 9.56e+07 -0.3794683516025543 0.29574230313301086\n",
      "[Step 13884] Loss: 9.56e+07 -0.3795343339443207 0.2956969141960144\n",
      "[Step 13885] Loss: 9.54e+07 -0.37968677282333374 0.2956680357456207\n",
      "[Step 13886] Loss: 9.61e+07 -0.37976089119911194 0.29564493894577026\n",
      "[Step 13887] Loss: 9.66e+07 -0.37996813654899597 0.2955756187438965\n",
      "[Step 13888] Loss: 9.52e+07 -0.38011038303375244 0.2955434322357178\n",
      "[Step 13889] Loss: 9.50e+07 -0.38031134009361267 0.29545265436172485\n",
      "[Step 13890] Loss: 9.54e+07 -0.3804873526096344 0.2953808903694153\n",
      "[Step 13891] Loss: 9.49e+07 -0.3806881308555603 0.2953173518180847\n",
      "[Step 13892] Loss: 9.49e+07 -0.38093268871307373 0.2952166795730591\n",
      "[Step 13893] Loss: 9.51e+07 -0.38113492727279663 0.2951308786869049\n",
      "[Step 13894] Loss: 9.51e+07 -0.38126206398010254 0.29509207606315613\n",
      "[Step 13895] Loss: 9.53e+07 -0.3813423216342926 0.295073926448822\n",
      "[Step 13896] Loss: 9.58e+07 -0.38129037618637085 0.29507970809936523\n",
      "[Step 13897] Loss: 9.53e+07 -0.38125497102737427 0.29508382081985474\n",
      "[Step 13898] Loss: 9.54e+07 -0.38122543692588806 0.2950780689716339\n",
      "[Step 13899] Loss: 9.52e+07 -0.3811738193035126 0.29508301615715027\n",
      "[Step 13900] Loss: 9.52e+07 -0.381131112575531 0.29506319761276245\n",
      "[Step 13901] Loss: 9.49e+07 -0.3811185956001282 0.2950318455696106\n",
      "[Step 13902] Loss: 9.49e+07 -0.38104137778282166 0.2950458824634552\n",
      "[Step 13903] Loss: 9.51e+07 -0.38089466094970703 0.29504916071891785\n",
      "[Step 13904] Loss: 9.48e+07 -0.3808412551879883 0.2950277328491211\n",
      "[Step 13905] Loss: 9.45e+07 -0.380795955657959 0.29501038789749146\n",
      "[Step 13906] Loss: 9.50e+07 -0.3807913661003113 0.29498398303985596\n",
      "[Step 13907] Loss: 9.47e+07 -0.3808284103870392 0.29495593905448914\n",
      "[Step 13908] Loss: 9.55e+07 -0.3807132840156555 0.294964998960495\n",
      "[Step 13909] Loss: 9.44e+07 -0.380645751953125 0.29496005177497864\n",
      "[Step 13910] Loss: 9.55e+07 -0.3806169629096985 0.29494190216064453\n",
      "[Step 13911] Loss: 9.61e+07 -0.38073989748954773 0.29490065574645996\n",
      "[Step 13912] Loss: 9.58e+07 -0.380787193775177 0.29488083720207214\n",
      "[Step 13913] Loss: 9.48e+07 -0.3808887302875519 0.2948412299156189\n",
      "[Step 13914] Loss: 9.59e+07 -0.38100236654281616 0.29480987787246704\n",
      "[Step 13915] Loss: 9.56e+07 -0.3812377154827118 0.2947216033935547\n",
      "[Step 13916] Loss: 9.54e+07 -0.38140299916267395 0.2946869432926178\n",
      "[Step 13917] Loss: 9.49e+07 -0.38168221712112427 0.2946341335773468\n",
      "[Step 13918] Loss: 9.57e+07 -0.3820274770259857 0.29456233978271484\n",
      "[Step 13919] Loss: 9.50e+07 -0.3823554813861847 0.2944641411304474\n",
      "[Step 13920] Loss: 9.46e+07 -0.38267964124679565 0.2943907082080841\n",
      "[Step 13921] Loss: 9.65e+07 -0.38275742530822754 0.29438164830207825\n",
      "[Step 13922] Loss: 9.55e+07 -0.3826138377189636 0.29444271326065063\n",
      "[Step 13923] Loss: 9.44e+07 -0.3824264407157898 0.29450294375419617\n",
      "[Step 13924] Loss: 9.62e+07 -0.3820993900299072 0.294553279876709\n",
      "[Step 13925] Loss: 9.49e+07 -0.381779283285141 0.29462504386901855\n",
      "[Step 13926] Loss: 9.53e+07 -0.38146036863327026 0.294711709022522\n",
      "[Step 13927] Loss: 9.53e+07 -0.38122522830963135 0.2947554290294647\n",
      "[Step 13928] Loss: 9.55e+07 -0.38099849224090576 0.29480576515197754\n",
      "[Step 13929] Loss: 9.57e+07 -0.38090962171554565 0.2948164939880371\n",
      "[Step 13930] Loss: 9.52e+07 -0.380891352891922 0.29483628273010254\n",
      "[Step 13931] Loss: 9.49e+07 -0.3808986246585846 0.29483547806739807\n",
      "[Step 13932] Loss: 9.64e+07 -0.38117995858192444 0.2947620153427124\n",
      "[Step 13933] Loss: 9.49e+07 -0.38152870535850525 0.2946844696998596\n",
      "[Step 13934] Loss: 9.50e+07 -0.3817545175552368 0.29461514949798584\n",
      "[Step 13935] Loss: 9.50e+07 -0.3819104731082916 0.29454171657562256\n",
      "[Step 13936] Loss: 9.55e+07 -0.3821379840373993 0.29447075724601746\n",
      "[Step 13937] Loss: 9.57e+07 -0.3824567198753357 0.2943907082080841\n",
      "[Step 13938] Loss: 9.53e+07 -0.3827182352542877 0.2943131625652313\n",
      "[Step 13939] Loss: 9.49e+07 -0.3830413520336151 0.29423394799232483\n",
      "[Step 13940] Loss: 9.51e+07 -0.38332071900367737 0.2941555380821228\n",
      "[Step 13941] Loss: 9.47e+07 -0.38350850343704224 0.29410192370414734\n",
      "[Step 13942] Loss: 9.68e+07 -0.3834783732891083 0.2940829396247864\n",
      "[Step 13943] Loss: 9.53e+07 -0.38353028893470764 0.29407551884651184\n",
      "[Step 13944] Loss: 9.51e+07 -0.3835432529449463 0.2940581738948822\n",
      "[Step 13945] Loss: 9.40e+07 -0.3835858702659607 0.2940375506877899\n",
      "[Step 13946] Loss: 9.52e+07 -0.3835594952106476 0.294021874666214\n",
      "[Step 13947] Loss: 9.47e+07 -0.38354432582855225 0.2940152883529663\n",
      "[Step 13948] Loss: 9.48e+07 -0.3835635185241699 0.2939773201942444\n",
      "[Step 13949] Loss: 9.51e+07 -0.38360661268234253 0.2939591705799103\n",
      "[Step 13950] Loss: 9.49e+07 -0.38359981775283813 0.2939550578594208\n",
      "[Step 13951] Loss: 9.58e+07 -0.38351887464523315 0.29393771290779114\n",
      "[Step 13952] Loss: 9.53e+07 -0.38348668813705444 0.2939525544643402\n",
      "[Step 13953] Loss: 9.56e+07 -0.38347873091697693 0.2939121425151825\n",
      "[Step 13954] Loss: 9.49e+07 -0.38354822993278503 0.2938733696937561\n",
      "[Step 13955] Loss: 9.51e+07 -0.3836170434951782 0.29378175735473633\n",
      "[Step 13956] Loss: 9.54e+07 -0.3837931156158447 0.29371246695518494\n",
      "[Step 13957] Loss: 9.54e+07 -0.38390833139419556 0.29369595646858215\n",
      "[Step 13958] Loss: 9.51e+07 -0.3839750587940216 0.2936505675315857\n",
      "[Step 13959] Loss: 9.56e+07 -0.38388314843177795 0.29367533326148987\n",
      "[Step 13960] Loss: 9.52e+07 -0.3837377429008484 0.2936910092830658\n",
      "[Step 13961] Loss: 9.75e+07 -0.3838898539543152 0.29366788268089294\n",
      "[Step 13962] Loss: 9.50e+07 -0.38395899534225464 0.29364892840385437\n",
      "[Step 13963] Loss: 9.69e+07 -0.3841903507709503 0.2935952842235565\n",
      "[Step 13964] Loss: 9.43e+07 -0.38435429334640503 0.29354578256607056\n",
      "[Step 13965] Loss: 9.64e+07 -0.3843860626220703 0.29349708557128906\n",
      "[Step 13966] Loss: 9.48e+07 -0.38437619805336 0.29349297285079956\n",
      "[Step 13967] Loss: 9.48e+07 -0.38432469964027405 0.29346489906311035\n",
      "[Step 13968] Loss: 9.53e+07 -0.38426679372787476 0.2934657335281372\n",
      "[Step 13969] Loss: 9.51e+07 -0.38429248332977295 0.29348140954971313\n",
      "[Step 13970] Loss: 9.59e+07 -0.38445863127708435 0.2934475839138031\n",
      "[Step 13971] Loss: 9.72e+07 -0.38438573479652405 0.2934492230415344\n",
      "[Step 13972] Loss: 9.58e+07 -0.3845309317111969 0.2933923006057739\n",
      "[Step 13973] Loss: 9.48e+07 -0.38462501764297485 0.29337000846862793\n",
      "[Step 13974] Loss: 9.51e+07 -0.3848091661930084 0.2933139204978943\n",
      "[Step 13975] Loss: 9.51e+07 -0.38489556312561035 0.29326605796813965\n",
      "[Step 13976] Loss: 9.50e+07 -0.38502469658851624 0.29322975873947144\n",
      "[Step 13977] Loss: 9.57e+07 -0.3852566182613373 0.29317694902420044\n",
      "[Step 13978] Loss: 9.48e+07 -0.3855617642402649 0.2930762767791748\n",
      "[Step 13979] Loss: 9.59e+07 -0.38602402806282043 0.29296404123306274\n",
      "[Step 13980] Loss: 9.52e+07 -0.3864295482635498 0.2928295433521271\n",
      "[Step 13981] Loss: 9.46e+07 -0.38676711916923523 0.2927272319793701\n",
      "[Step 13982] Loss: 9.60e+07 -0.38702157139778137 0.29262575507164\n",
      "[Step 13983] Loss: 9.68e+07 -0.3874652087688446 0.29251599311828613\n",
      "[Step 13984] Loss: 9.51e+07 -0.38777124881744385 0.2924293577671051\n",
      "[Step 13985] Loss: 9.46e+07 -0.3880077302455902 0.2923848032951355\n",
      "[Step 13986] Loss: 9.52e+07 -0.3881879150867462 0.29232126474380493\n",
      "[Step 13987] Loss: 9.50e+07 -0.3883262276649475 0.29228001832962036\n",
      "[Step 13988] Loss: 9.58e+07 -0.38854897022247314 0.2922205924987793\n",
      "[Step 13989] Loss: 9.50e+07 -0.3887951076030731 0.2921496331691742\n",
      "[Step 13990] Loss: 9.52e+07 -0.38891419768333435 0.29208776354789734\n",
      "[Step 13991] Loss: 9.51e+07 -0.3889632225036621 0.2920580506324768\n",
      "[Step 13992] Loss: 9.59e+07 -0.38898250460624695 0.2920341193675995\n",
      "[Step 13993] Loss: 9.50e+07 -0.38906949758529663 0.2919846177101135\n",
      "[Step 13994] Loss: 9.55e+07 -0.3890938460826874 0.29196810722351074\n",
      "[Step 13995] Loss: 9.56e+07 -0.3891856372356415 0.29192933440208435\n",
      "[Step 13996] Loss: 9.51e+07 -0.3893056809902191 0.2918674349784851\n",
      "[Step 13997] Loss: 9.50e+07 -0.3893676698207855 0.29183855652809143\n",
      "[Step 13998] Loss: 9.53e+07 -0.389483243227005 0.29182949662208557\n",
      "[Step 13999] Loss: 9.49e+07 -0.3896356523036957 0.29178163409233093\n",
      "[Step 14000] Loss: 9.63e+07 -0.38966697454452515 0.2917494475841522\n",
      "[Step 14001] Loss: 9.51e+07 -0.38966649770736694 0.2917238771915436\n",
      "[Step 14002] Loss: 9.53e+07 -0.38958317041397095 0.29174038767814636\n",
      "[Step 14003] Loss: 9.49e+07 -0.38949817419052124 0.29174697399139404\n",
      "[Step 14004] Loss: 9.55e+07 -0.3894130289554596 0.2917601764202118\n",
      "[Step 14005] Loss: 9.56e+07 -0.3892660439014435 0.2917981445789337\n",
      "[Step 14006] Loss: 9.52e+07 -0.38913092017173767 0.2918129861354828\n",
      "[Step 14007] Loss: 9.44e+07 -0.38908326625823975 0.2918253540992737\n",
      "[Step 14008] Loss: 9.48e+07 -0.38895145058631897 0.2918286621570587\n",
      "[Step 14009] Loss: 9.52e+07 -0.3889528214931488 0.2917824685573578\n",
      "[Step 14010] Loss: 9.45e+07 -0.38897550106048584 0.29176101088523865\n",
      "[Step 14011] Loss: 9.57e+07 -0.3890429139137268 0.291709840297699\n",
      "[Step 14012] Loss: 9.63e+07 -0.38923516869544983 0.2916628122329712\n",
      "[Step 14013] Loss: 9.55e+07 -0.38945260643959045 0.29162484407424927\n",
      "[Step 14014] Loss: 9.53e+07 -0.3898066282272339 0.2915431559085846\n",
      "[Step 14015] Loss: 9.39e+07 -0.39015811681747437 0.2914623022079468\n",
      "[Step 14016] Loss: 9.52e+07 -0.3905370235443115 0.2913376986980438\n",
      "[Step 14017] Loss: 9.59e+07 -0.39078015089035034 0.29126179218292236\n",
      "[Step 14018] Loss: 9.56e+07 -0.39091452956199646 0.2912485897541046\n",
      "[Step 14019] Loss: 9.52e+07 -0.390877902507782 0.29124775528907776\n",
      "[Step 14020] Loss: 9.42e+07 -0.39077144861221313 0.2912288010120392\n",
      "[Step 14021] Loss: 9.59e+07 -0.39078059792518616 0.2912329137325287\n",
      "[Step 14022] Loss: 9.44e+07 -0.3907214403152466 0.29123952984809875\n",
      "[Step 14023] Loss: 9.51e+07 -0.3906920850276947 0.2912469506263733\n",
      "[Step 14024] Loss: 9.45e+07 -0.39065641164779663 0.29124611616134644\n",
      "[Step 14025] Loss: 9.59e+07 -0.3904670476913452 0.2912675738334656\n",
      "[Step 14026] Loss: 9.46e+07 -0.3902507424354553 0.29129067063331604\n",
      "[Step 14027] Loss: 9.46e+07 -0.39001718163490295 0.291331946849823\n",
      "[Step 14028] Loss: 9.50e+07 -0.38970711827278137 0.29139795899391174\n",
      "[Step 14029] Loss: 9.54e+07 -0.38933685421943665 0.29146724939346313\n",
      "[Step 14030] Loss: 9.73e+07 -0.38930895924568176 0.291445791721344\n",
      "[Step 14031] Loss: 9.55e+07 -0.38919395208358765 0.2914920151233673\n",
      "[Step 14032] Loss: 9.49e+07 -0.3891424238681793 0.2914887070655823\n",
      "[Step 14033] Loss: 9.54e+07 -0.38913437724113464 0.2914474606513977\n",
      "[Step 14034] Loss: 9.50e+07 -0.38911572098731995 0.29145073890686035\n",
      "[Step 14035] Loss: 9.50e+07 -0.38915419578552246 0.2914358973503113\n",
      "[Step 14036] Loss: 9.64e+07 -0.3894106447696686 0.2913806140422821\n",
      "[Step 14037] Loss: 9.49e+07 -0.3896876275539398 0.2912915050983429\n",
      "[Step 14038] Loss: 9.52e+07 -0.38986849784851074 0.2912304401397705\n",
      "[Step 14039] Loss: 9.53e+07 -0.3901294469833374 0.2911570072174072\n",
      "[Step 14040] Loss: 9.56e+07 -0.39037880301475525 0.2910843789577484\n",
      "[Step 14041] Loss: 9.47e+07 -0.3905979096889496 0.2910381853580475\n",
      "[Step 14042] Loss: 9.55e+07 -0.39071643352508545 0.2909994125366211\n",
      "[Step 14043] Loss: 9.43e+07 -0.3907763957977295 0.2910018861293793\n",
      "[Step 14044] Loss: 9.49e+07 -0.39078500866889954 0.29098621010780334\n",
      "[Step 14045] Loss: 9.60e+07 -0.3908875584602356 0.29095566272735596\n",
      "[Step 14046] Loss: 9.48e+07 -0.3910006284713745 0.2908937931060791\n",
      "[Step 14047] Loss: 9.60e+07 -0.3911486864089966 0.2908310890197754\n",
      "[Step 14048] Loss: 9.61e+07 -0.39143604040145874 0.29074689745903015\n",
      "[Step 14049] Loss: 9.42e+07 -0.39173123240470886 0.29066357016563416\n",
      "[Step 14050] Loss: 9.59e+07 -0.39211368560791016 0.2905810475349426\n",
      "[Step 14051] Loss: 9.48e+07 -0.3925842046737671 0.29047542810440063\n",
      "[Step 14052] Loss: 9.44e+07 -0.3929423987865448 0.29037725925445557\n",
      "[Step 14053] Loss: 9.52e+07 -0.3932211995124817 0.29031452536582947\n",
      "[Step 14054] Loss: 9.52e+07 -0.3934696614742279 0.29030463099479675\n",
      "[Step 14055] Loss: 9.43e+07 -0.39369699358940125 0.2902510166168213\n",
      "[Step 14056] Loss: 9.48e+07 -0.39386245608329773 0.290185809135437\n",
      "[Step 14057] Loss: 9.46e+07 -0.3939726948738098 0.29015693068504333\n",
      "[Step 14058] Loss: 9.46e+07 -0.3940748870372772 0.29011979699134827\n",
      "[Step 14059] Loss: 9.51e+07 -0.39407292008399963 0.2900785505771637\n",
      "[Step 14060] Loss: 9.59e+07 -0.3941916525363922 0.2900438904762268\n",
      "[Step 14061] Loss: 9.54e+07 -0.3944450318813324 0.2899993360042572\n",
      "[Step 14062] Loss: 9.54e+07 -0.394831120967865 0.28988713026046753\n",
      "[Step 14063] Loss: 9.60e+07 -0.3950295150279999 0.28982028365135193\n",
      "[Step 14064] Loss: 9.51e+07 -0.3951682150363922 0.2897905707359314\n",
      "[Step 14065] Loss: 9.52e+07 -0.39516252279281616 0.28981202840805054\n",
      "[Step 14066] Loss: 9.45e+07 -0.395178884267807 0.28981533646583557\n",
      "[Step 14067] Loss: 9.53e+07 -0.39513587951660156 0.2898004651069641\n",
      "[Step 14068] Loss: 9.48e+07 -0.3950943052768707 0.2898029685020447\n",
      "[Step 14069] Loss: 9.53e+07 -0.39504745602607727 0.28982439637184143\n",
      "[Step 14070] Loss: 9.49e+07 -0.39507943391799927 0.2898062467575073\n",
      "[Step 14071] Loss: 9.73e+07 -0.3953968584537506 0.28972128033638\n",
      "[Step 14072] Loss: 9.60e+07 -0.3955020606517792 0.289668470621109\n",
      "[Step 14073] Loss: 9.54e+07 -0.3956032991409302 0.289615660905838\n",
      "[Step 14074] Loss: 9.57e+07 -0.3956552743911743 0.2895859479904175\n",
      "[Step 14075] Loss: 9.55e+07 -0.3957023620605469 0.28956612944602966\n",
      "[Step 14076] Loss: 9.51e+07 -0.3956953287124634 0.2895735800266266\n",
      "[Step 14077] Loss: 9.52e+07 -0.3956185579299927 0.28955787420272827\n",
      "[Step 14078] Loss: 9.52e+07 -0.39556747674942017 0.28954797983169556\n",
      "[Step 14079] Loss: 9.54e+07 -0.39546525478363037 0.28957852721214294\n",
      "[Step 14080] Loss: 9.53e+07 -0.39524200558662415 0.2896197736263275\n",
      "[Step 14081] Loss: 9.54e+07 -0.39490190148353577 0.28968578577041626\n",
      "[Step 14082] Loss: 9.45e+07 -0.3946399986743927 0.2897435426712036\n",
      "[Step 14083] Loss: 9.51e+07 -0.39435210824012756 0.28977325558662415\n",
      "[Step 14084] Loss: 9.53e+07 -0.3941185176372528 0.2897905707359314\n",
      "[Step 14085] Loss: 9.51e+07 -0.3938266932964325 0.2898367941379547\n",
      "[Step 14086] Loss: 9.47e+07 -0.3935164511203766 0.28989866375923157\n",
      "[Step 14087] Loss: 9.56e+07 -0.3933178186416626 0.2899283766746521\n",
      "[Step 14088] Loss: 9.47e+07 -0.3931100368499756 0.2899754047393799\n",
      "[Step 14089] Loss: 9.57e+07 -0.39311736822128296 0.2899729311466217\n",
      "[Step 14090] Loss: 9.53e+07 -0.3931921124458313 0.2899267375469208\n",
      "[Step 14091] Loss: 9.52e+07 -0.39321595430374146 0.289913535118103\n",
      "[Step 14092] Loss: 9.49e+07 -0.39335283637046814 0.2898755669593811\n",
      "[Step 14093] Loss: 9.64e+07 -0.3936695456504822 0.2898070812225342\n",
      "[Step 14094] Loss: 9.52e+07 -0.3940291106700897 0.28970807790756226\n",
      "[Step 14095] Loss: 9.55e+07 -0.39437684416770935 0.289623886346817\n",
      "[Step 14096] Loss: 9.44e+07 -0.3946988582611084 0.28952983021736145\n",
      "[Step 14097] Loss: 9.56e+07 -0.3950583040714264 0.28947538137435913\n",
      "[Step 14098] Loss: 9.60e+07 -0.3952529728412628 0.2894374132156372\n",
      "[Step 14099] Loss: 9.68e+07 -0.3956432640552521 0.2893524169921875\n",
      "[Step 14100] Loss: 9.68e+07 -0.39618197083473206 0.2892228960990906\n",
      "[Step 14101] Loss: 9.58e+07 -0.3966514468193054 0.2891576886177063\n",
      "[Step 14102] Loss: 9.54e+07 -0.3971104323863983 0.28905701637268066\n",
      "[Step 14103] Loss: 9.44e+07 -0.39749446511268616 0.2889654338359833\n",
      "[Step 14104] Loss: 9.50e+07 -0.39789915084838867 0.28889694809913635\n",
      "[Step 14105] Loss: 9.48e+07 -0.3983362019062042 0.28877732157707214\n",
      "[Step 14106] Loss: 9.44e+07 -0.3987729251384735 0.2886890172958374\n",
      "[Step 14107] Loss: 9.52e+07 -0.39928120374679565 0.2885594666004181\n",
      "[Step 14108] Loss: 9.51e+07 -0.39985257387161255 0.28844478726387024\n",
      "[Step 14109] Loss: 9.52e+07 -0.40029120445251465 0.28831276297569275\n",
      "[Step 14110] Loss: 9.50e+07 -0.40077531337738037 0.2882079780101776\n",
      "[Step 14111] Loss: 9.51e+07 -0.40113911032676697 0.28811389207839966\n",
      "[Step 14112] Loss: 9.65e+07 -0.4016963541507721 0.2879736125469208\n",
      "[Step 14113] Loss: 9.48e+07 -0.40225809812545776 0.2878473699092865\n",
      "[Step 14114] Loss: 9.66e+07 -0.4030552804470062 0.28766751289367676\n",
      "[Step 14115] Loss: 9.51e+07 -0.4037752151489258 0.28750577569007874\n",
      "[Step 14116] Loss: 9.51e+07 -0.40433570742607117 0.28739026188850403\n",
      "[Step 14117] Loss: 9.52e+07 -0.4048309624195099 0.2872912287712097\n",
      "[Step 14118] Loss: 9.52e+07 -0.4051879048347473 0.28720954060554504\n",
      "[Step 14119] Loss: 9.52e+07 -0.4055005609989166 0.2871682941913605\n",
      "[Step 14120] Loss: 9.51e+07 -0.40576890110969543 0.2870882451534271\n",
      "[Step 14121] Loss: 9.46e+07 -0.4060828983783722 0.28703710436820984\n",
      "[Step 14122] Loss: 9.57e+07 -0.40631839632987976 0.28696367144584656\n",
      "[Step 14123] Loss: 9.50e+07 -0.4066182076931 0.2869240641593933\n",
      "[Step 14124] Loss: 9.49e+07 -0.40689581632614136 0.2868695855140686\n",
      "[Step 14125] Loss: 9.50e+07 -0.40704479813575745 0.2868291735649109\n",
      "[Step 14126] Loss: 9.47e+07 -0.4071376323699951 0.2868027687072754\n",
      "[Step 14127] Loss: 9.54e+07 -0.40715882182121277 0.2868308126926422\n",
      "[Step 14128] Loss: 9.67e+07 -0.40698811411857605 0.2868695855140686\n",
      "[Step 14129] Loss: 9.47e+07 -0.4068388342857361 0.2868712544441223\n",
      "[Step 14130] Loss: 9.52e+07 -0.40673694014549255 0.2868803143501282\n",
      "[Step 14131] Loss: 9.46e+07 -0.4066053330898285 0.28689104318618774\n",
      "[Step 14132] Loss: 9.51e+07 -0.406455934047699 0.2869322896003723\n",
      "[Step 14133] Loss: 9.45e+07 -0.4063533544540405 0.28694137930870056\n",
      "[Step 14134] Loss: 9.48e+07 -0.40631404519081116 0.28693559765815735\n",
      "[Step 14135] Loss: 9.53e+07 -0.4063301980495453 0.28693559765815735\n",
      "[Step 14136] Loss: 9.58e+07 -0.4062400758266449 0.2869422137737274\n",
      "[Step 14137] Loss: 9.54e+07 -0.4061144292354584 0.28698182106018066\n",
      "[Step 14138] Loss: 9.53e+07 -0.40586692094802856 0.2870337963104248\n",
      "[Step 14139] Loss: 9.51e+07 -0.40558668971061707 0.2870866060256958\n",
      "[Step 14140] Loss: 9.58e+07 -0.4053124785423279 0.28713279962539673\n",
      "[Step 14141] Loss: 9.48e+07 -0.40509507060050964 0.2871682941913605\n",
      "[Step 14142] Loss: 9.51e+07 -0.4049973785877228 0.2871814966201782\n",
      "[Step 14143] Loss: 9.49e+07 -0.4049622714519501 0.2871781885623932\n",
      "[Step 14144] Loss: 9.56e+07 -0.4047960638999939 0.2871897518634796\n",
      "[Step 14145] Loss: 9.50e+07 -0.4046349823474884 0.28720375895500183\n",
      "[Step 14146] Loss: 9.51e+07 -0.40441077947616577 0.2872714400291443\n",
      "[Step 14147] Loss: 9.56e+07 -0.40425926446914673 0.2872928977012634\n",
      "[Step 14148] Loss: 9.46e+07 -0.4040849804878235 0.28732505440711975\n",
      "[Step 14149] Loss: 9.56e+07 -0.4039342403411865 0.28736385703086853\n",
      "[Step 14150] Loss: 9.53e+07 -0.40387430787086487 0.28735724091529846\n",
      "[Step 14151] Loss: 9.50e+07 -0.40376919507980347 0.2873621881008148\n",
      "[Step 14152] Loss: 9.56e+07 -0.4035620391368866 0.2874199450016022\n",
      "[Step 14153] Loss: 9.46e+07 -0.4033602178096771 0.2874603867530823\n",
      "[Step 14154] Loss: 9.48e+07 -0.4031084477901459 0.28750908374786377\n",
      "[Step 14155] Loss: 9.55e+07 -0.4027874171733856 0.2875494956970215\n",
      "[Step 14156] Loss: 9.64e+07 -0.40236932039260864 0.28766998648643494\n",
      "[Step 14157] Loss: 9.51e+07 -0.40208446979522705 0.28772032260894775\n",
      "[Step 14158] Loss: 9.57e+07 -0.4017332196235657 0.28776815533638\n",
      "[Step 14159] Loss: 9.53e+07 -0.401324987411499 0.2878498435020447\n",
      "[Step 14160] Loss: 9.52e+07 -0.4009453356266022 0.28793567419052124\n",
      "[Step 14161] Loss: 9.62e+07 -0.4005039632320404 0.2880198359489441\n",
      "[Step 14162] Loss: 9.51e+07 -0.40016070008277893 0.2880809009075165\n",
      "[Step 14163] Loss: 9.63e+07 -0.39985746145248413 0.28815433382987976\n",
      "[Step 14164] Loss: 9.54e+07 -0.39966192841529846 0.2881733179092407\n",
      "[Step 14165] Loss: 9.50e+07 -0.3994907736778259 0.2882145643234253\n",
      "[Step 14166] Loss: 9.56e+07 -0.39920881390571594 0.2882913053035736\n",
      "[Step 14167] Loss: 9.51e+07 -0.39899390935897827 0.2883234918117523\n",
      "[Step 14168] Loss: 9.52e+07 -0.39886343479156494 0.28833091259002686\n",
      "[Step 14169] Loss: 9.52e+07 -0.3986658751964569 0.2883804142475128\n",
      "[Step 14170] Loss: 9.47e+07 -0.3985432982444763 0.28840434551239014\n",
      "[Step 14171] Loss: 9.49e+07 -0.3984735906124115 0.28842416405677795\n",
      "[Step 14172] Loss: 9.53e+07 -0.39832767844200134 0.28845056891441345\n",
      "[Step 14173] Loss: 9.50e+07 -0.398165225982666 0.2884901762008667\n",
      "[Step 14174] Loss: 9.57e+07 -0.39816227555274963 0.2884621024131775\n",
      "[Step 14175] Loss: 9.68e+07 -0.3979265093803406 0.2885231673717499\n",
      "[Step 14176] Loss: 9.45e+07 -0.3977392613887787 0.288575142621994\n",
      "[Step 14177] Loss: 9.56e+07 -0.3975500166416168 0.28859081864356995\n",
      "[Step 14178] Loss: 9.51e+07 -0.3973497450351715 0.2886238396167755\n",
      "[Step 14179] Loss: 9.53e+07 -0.39704957604408264 0.2886931598186493\n",
      "[Step 14180] Loss: 9.54e+07 -0.3968236446380615 0.28876328468322754\n",
      "[Step 14181] Loss: 9.45e+07 -0.39667898416519165 0.28880125284194946\n",
      "[Step 14182] Loss: 9.66e+07 -0.39677658677101135 0.2887665927410126\n",
      "[Step 14183] Loss: 9.39e+07 -0.39681851863861084 0.2887541949748993\n",
      "[Step 14184] Loss: 9.58e+07 -0.3969201147556305 0.288730263710022\n",
      "[Step 14185] Loss: 9.46e+07 -0.3970336318016052 0.288669228553772\n",
      "[Step 14186] Loss: 9.49e+07 -0.39729902148246765 0.28858423233032227\n",
      "[Step 14187] Loss: 9.51e+07 -0.3976143002510071 0.2884819209575653\n",
      "[Step 14188] Loss: 9.54e+07 -0.3978644609451294 0.2884299159049988\n",
      "[Step 14189] Loss: 9.60e+07 -0.39831051230430603 0.2883201837539673\n",
      "[Step 14190] Loss: 9.55e+07 -0.3987833261489868 0.28823766112327576\n",
      "[Step 14191] Loss: 9.50e+07 -0.3992775082588196 0.28815269470214844\n",
      "[Step 14192] Loss: 9.53e+07 -0.39981013536453247 0.28804129362106323\n",
      "[Step 14193] Loss: 9.59e+07 -0.40016353130340576 0.28797033429145813\n",
      "[Step 14194] Loss: 9.54e+07 -0.40054023265838623 0.2878853380680084\n",
      "[Step 14195] Loss: 9.52e+07 -0.4008926749229431 0.287790447473526\n",
      "[Step 14196] Loss: 9.45e+07 -0.4012153148651123 0.28774258494377136\n",
      "[Step 14197] Loss: 9.50e+07 -0.40151047706604004 0.2876831889152527\n",
      "[Step 14198] Loss: 9.50e+07 -0.4017362594604492 0.28762707114219666\n",
      "[Step 14199] Loss: 9.54e+07 -0.4019239544868469 0.2875610589981079\n",
      "[Step 14200] Loss: 9.55e+07 -0.40222787857055664 0.28749173879623413\n",
      "[Step 14201] Loss: 9.57e+07 -0.4024496078491211 0.2874538004398346\n",
      "[Step 14202] Loss: 9.52e+07 -0.40274348855018616 0.2873993217945099\n",
      "[Step 14203] Loss: 9.53e+07 -0.40304306149482727 0.28731516003608704\n",
      "[Step 14204] Loss: 9.49e+07 -0.40320730209350586 0.2872928977012634\n",
      "[Step 14205] Loss: 9.53e+07 -0.4034762382507324 0.287250816822052\n",
      "[Step 14206] Loss: 9.53e+07 -0.4036254286766052 0.28719717264175415\n",
      "[Step 14207] Loss: 9.56e+07 -0.4039466679096222 0.2870907187461853\n",
      "[Step 14208] Loss: 9.48e+07 -0.40422412753105164 0.28702059388160706\n",
      "[Step 14209] Loss: 9.64e+07 -0.40470144152641296 0.2869158089160919\n",
      "[Step 14210] Loss: 9.55e+07 -0.4051152169704437 0.28681761026382446\n",
      "[Step 14211] Loss: 9.52e+07 -0.4054677188396454 0.2867136299610138\n",
      "[Step 14212] Loss: 9.54e+07 -0.4058680236339569 0.2866179347038269\n",
      "[Step 14213] Loss: 9.56e+07 -0.40629395842552185 0.2865180969238281\n",
      "[Step 14214] Loss: 9.50e+07 -0.40659651160240173 0.2864619791507721\n",
      "[Step 14215] Loss: 9.49e+07 -0.4069366753101349 0.2863844037055969\n",
      "[Step 14216] Loss: 9.58e+07 -0.40729761123657227 0.28633078932762146\n",
      "[Step 14217] Loss: 9.50e+07 -0.4076760411262512 0.2862433195114136\n",
      "[Step 14218] Loss: 9.58e+07 -0.40787047147750854 0.2862268090248108\n",
      "[Step 14219] Loss: 9.55e+07 -0.4080013930797577 0.28620287775993347\n",
      "[Step 14220] Loss: 9.62e+07 -0.4083380699157715 0.2861434817314148\n",
      "[Step 14221] Loss: 9.50e+07 -0.4086933732032776 0.2860601246356964\n",
      "[Step 14222] Loss: 9.53e+07 -0.4091579020023346 0.28594955801963806\n",
      "[Step 14223] Loss: 9.54e+07 -0.4097196161746979 0.2858530282974243\n",
      "[Step 14224] Loss: 9.59e+07 -0.4104519486427307 0.2857036888599396\n",
      "[Step 14225] Loss: 9.50e+07 -0.4109797775745392 0.28558072447776794\n",
      "[Step 14226] Loss: 9.49e+07 -0.411394864320755 0.2855064570903778\n",
      "[Step 14227] Loss: 9.53e+07 -0.4117211103439331 0.28543880581855774\n",
      "[Step 14228] Loss: 9.57e+07 -0.4118792414665222 0.2854074537754059\n",
      "[Step 14229] Loss: 9.53e+07 -0.4121081531047821 0.28533896803855896\n",
      "[Step 14230] Loss: 9.53e+07 -0.41232454776763916 0.2852572798728943\n",
      "[Step 14231] Loss: 9.58e+07 -0.4126887619495392 0.2851599156856537\n",
      "[Step 14232] Loss: 9.54e+07 -0.4128887951374054 0.28512609004974365\n",
      "[Step 14233] Loss: 9.47e+07 -0.4129866063594818 0.2851351499557495\n",
      "[Step 14234] Loss: 9.48e+07 -0.4130329489707947 0.2851516604423523\n",
      "[Step 14235] Loss: 9.43e+07 -0.4129941761493683 0.28513020277023315\n",
      "[Step 14236] Loss: 9.55e+07 -0.41292592883110046 0.28514835238456726\n",
      "[Step 14237] Loss: 9.51e+07 -0.4127901494503021 0.28517475724220276\n",
      "[Step 14238] Loss: 9.56e+07 -0.41272443532943726 0.2851673364639282\n",
      "[Step 14239] Loss: 9.52e+07 -0.41272303462028503 0.2851409316062927\n",
      "[Step 14240] Loss: 9.53e+07 -0.41281113028526306 0.28511369228363037\n",
      "[Step 14241] Loss: 9.50e+07 -0.41293081641197205 0.285108745098114\n",
      "[Step 14242] Loss: 9.48e+07 -0.4130557179450989 0.2851013243198395\n",
      "[Step 14243] Loss: 9.53e+07 -0.4131234884262085 0.285078227519989\n",
      "[Step 14244] Loss: 9.52e+07 -0.4132949113845825 0.28503942489624023\n",
      "[Step 14245] Loss: 9.52e+07 -0.41335996985435486 0.2850303649902344\n",
      "[Step 14246] Loss: 9.54e+07 -0.4133043885231018 0.28503942489624023\n",
      "[Step 14247] Loss: 9.52e+07 -0.4133327603340149 0.2850278913974762\n",
      "[Step 14248] Loss: 9.57e+07 -0.413280189037323 0.2850171625614166\n",
      "[Step 14249] Loss: 9.49e+07 -0.413239061832428 0.2850138545036316\n",
      "[Step 14250] Loss: 9.45e+07 -0.413155198097229 0.28502127528190613\n",
      "[Step 14251] Loss: 9.54e+07 -0.4131661057472229 0.28503283858299255\n",
      "[Step 14252] Loss: 9.51e+07 -0.4131416082382202 0.28502458333969116\n",
      "[Step 14253] Loss: 9.47e+07 -0.4130212366580963 0.28504687547683716\n",
      "[Step 14254] Loss: 9.49e+07 -0.41295984387397766 0.2850708067417145\n",
      "[Step 14255] Loss: 9.48e+07 -0.4129349887371063 0.2850807011127472\n",
      "[Step 14256] Loss: 9.46e+07 -0.4130001962184906 0.28507161140441895\n",
      "[Step 14257] Loss: 9.50e+07 -0.41311943531036377 0.285055935382843\n",
      "[Step 14258] Loss: 9.47e+07 -0.41319605708122253 0.2850080728530884\n",
      "[Step 14259] Loss: 9.50e+07 -0.413180947303772 0.285022109746933\n",
      "[Step 14260] Loss: 9.46e+07 -0.4130563735961914 0.2850361466407776\n",
      "[Step 14261] Loss: 9.41e+07 -0.4129083752632141 0.2850724458694458\n",
      "[Step 14262] Loss: 9.60e+07 -0.4126076400279999 0.28514671325683594\n",
      "[Step 14263] Loss: 9.51e+07 -0.4122489392757416 0.2852102518081665\n",
      "[Step 14264] Loss: 9.65e+07 -0.4117470383644104 0.28531914949417114\n",
      "[Step 14265] Loss: 9.43e+07 -0.4113467335700989 0.2854090929031372\n",
      "[Step 14266] Loss: 9.51e+07 -0.4109326899051666 0.28549161553382874\n",
      "[Step 14267] Loss: 9.49e+07 -0.41065889596939087 0.28556421399116516\n",
      "[Step 14268] Loss: 9.53e+07 -0.41036468744277954 0.28566408157348633\n",
      "[Step 14269] Loss: 9.56e+07 -0.41018787026405334 0.2857078015804291\n",
      "[Step 14270] Loss: 9.46e+07 -0.4099854826927185 0.2857515215873718\n",
      "[Step 14271] Loss: 9.53e+07 -0.40990880131721497 0.2857275903224945\n",
      "[Step 14272] Loss: 9.49e+07 -0.4099045693874359 0.28574246168136597\n",
      "[Step 14273] Loss: 9.48e+07 -0.4098730981349945 0.2857556641101837\n",
      "[Step 14274] Loss: 9.51e+07 -0.409802109003067 0.28575399518013\n",
      "[Step 14275] Loss: 9.47e+07 -0.4097982347011566 0.28576144576072693\n",
      "[Step 14276] Loss: 9.52e+07 -0.4097898006439209 0.28578370809555054\n",
      "[Step 14277] Loss: 9.53e+07 -0.40976378321647644 0.2857861816883087\n",
      "[Step 14278] Loss: 9.54e+07 -0.409760981798172 0.2857845425605774\n",
      "[Step 14279] Loss: 9.72e+07 -0.41012194752693176 0.28568387031555176\n",
      "[Step 14280] Loss: 9.48e+07 -0.4104067385196686 0.2856104373931885\n",
      "[Step 14281] Loss: 9.51e+07 -0.41060587763786316 0.2855534851551056\n",
      "[Step 14282] Loss: 9.52e+07 -0.4106813669204712 0.28551387786865234\n",
      "[Step 14283] Loss: 9.52e+07 -0.41089871525764465 0.28546684980392456\n",
      "[Step 14284] Loss: 9.52e+07 -0.41114023327827454 0.28541404008865356\n",
      "[Step 14285] Loss: 9.44e+07 -0.41137242317199707 0.2853488624095917\n",
      "[Step 14286] Loss: 9.56e+07 -0.4116252660751343 0.28532081842422485\n",
      "[Step 14287] Loss: 9.48e+07 -0.4118306338787079 0.2852490246295929\n",
      "[Step 14288] Loss: 9.56e+07 -0.411956787109375 0.2851937413215637\n",
      "[Step 14289] Loss: 9.50e+07 -0.4120013415813446 0.28515496850013733\n",
      "[Step 14290] Loss: 9.55e+07 -0.41194266080856323 0.2851879596710205\n",
      "[Step 14291] Loss: 9.53e+07 -0.41203364729881287 0.28513103723526\n",
      "[Step 14292] Loss: 9.52e+07 -0.4120863974094391 0.28513103723526\n",
      "[Step 14293] Loss: 9.53e+07 -0.41208648681640625 0.2851376235485077\n",
      "[Step 14294] Loss: 9.50e+07 -0.4119690954685211 0.28512609004974365\n",
      "[Step 14295] Loss: 9.55e+07 -0.411888986825943 0.2851194739341736\n",
      "[Step 14296] Loss: 9.43e+07 -0.41179025173187256 0.2851516604423523\n",
      "[Step 14297] Loss: 9.48e+07 -0.41171392798423767 0.2851532995700836\n",
      "[Step 14298] Loss: 9.51e+07 -0.4117177128791809 0.28515082597732544\n",
      "[Step 14299] Loss: 9.48e+07 -0.41172656416893005 0.2851640284061432\n",
      "[Step 14300] Loss: 9.44e+07 -0.411777526140213 0.28511205315589905\n",
      "[Step 14301] Loss: 9.44e+07 -0.4118557274341583 0.2850930690765381\n",
      "[Step 14302] Loss: 9.47e+07 -0.4120267331600189 0.2850361466407776\n",
      "[Step 14303] Loss: 9.49e+07 -0.4122498035430908 0.28494784235954285\n",
      "[Step 14304] Loss: 9.47e+07 -0.41238459944725037 0.284919798374176\n",
      "[Step 14305] Loss: 9.51e+07 -0.4124959707260132 0.28488844633102417\n",
      "[Step 14306] Loss: 9.68e+07 -0.4128974974155426 0.28479108214378357\n",
      "[Step 14307] Loss: 9.54e+07 -0.4131907522678375 0.2847374379634857\n",
      "[Step 14308] Loss: 9.55e+07 -0.4133533239364624 0.28469619154930115\n",
      "[Step 14309] Loss: 9.48e+07 -0.41353169083595276 0.2846541106700897\n",
      "[Step 14310] Loss: 9.57e+07 -0.4137504994869232 0.28461697697639465\n",
      "[Step 14311] Loss: 9.46e+07 -0.41386887431144714 0.2845872640609741\n",
      "[Step 14312] Loss: 9.57e+07 -0.41411030292510986 0.2845204174518585\n",
      "[Step 14313] Loss: 9.53e+07 -0.4144160747528076 0.28444617986679077\n",
      "[Step 14314] Loss: 9.41e+07 -0.41463664174079895 0.28438758850097656\n",
      "[Step 14315] Loss: 9.49e+07 -0.41489267349243164 0.28434550762176514\n",
      "[Step 14316] Loss: 9.47e+07 -0.415099173784256 0.2842976450920105\n",
      "[Step 14317] Loss: 9.48e+07 -0.4151843190193176 0.28429022431373596\n",
      "[Step 14318] Loss: 9.50e+07 -0.4152316153049469 0.284271240234375\n",
      "[Step 14319] Loss: 9.50e+07 -0.4153633415699005 0.28423163294792175\n",
      "[Step 14320] Loss: 9.63e+07 -0.41569918394088745 0.28417056798934937\n",
      "[Step 14321] Loss: 9.57e+07 -0.41596123576164246 0.28412023186683655\n",
      "[Step 14322] Loss: 9.73e+07 -0.4165290892124176 0.28400471806526184\n",
      "[Step 14323] Loss: 9.54e+07 -0.4171426296234131 0.2838174104690552\n",
      "[Step 14324] Loss: 9.61e+07 -0.4176032841205597 0.28373241424560547\n",
      "[Step 14325] Loss: 9.52e+07 -0.4178994297981262 0.2836829125881195\n",
      "[Step 14326] Loss: 9.49e+07 -0.4180433750152588 0.28365567326545715\n",
      "[Step 14327] Loss: 9.46e+07 -0.4181760549545288 0.2836399972438812\n",
      "[Step 14328] Loss: 9.48e+07 -0.41823387145996094 0.2836383581161499\n",
      "[Step 14329] Loss: 9.56e+07 -0.41820257902145386 0.28365814685821533\n",
      "[Step 14330] Loss: 9.52e+07 -0.418205201625824 0.2836482524871826\n",
      "[Step 14331] Loss: 9.47e+07 -0.41818636655807495 0.2836325764656067\n",
      "[Step 14332] Loss: 9.45e+07 -0.4181011915206909 0.28364330530166626\n",
      "[Step 14333] Loss: 9.54e+07 -0.41793495416641235 0.28366145491600037\n",
      "[Step 14334] Loss: 9.54e+07 -0.41773179173469543 0.2837200462818146\n",
      "[Step 14335] Loss: 9.52e+07 -0.4174859821796417 0.2837802767753601\n",
      "[Step 14336] Loss: 9.48e+07 -0.41729024052619934 0.28380337357521057\n",
      "[Step 14337] Loss: 9.53e+07 -0.41719818115234375 0.283792644739151\n",
      "[Step 14338] Loss: 9.51e+07 -0.41729652881622314 0.2837703824043274\n",
      "[Step 14339] Loss: 9.66e+07 -0.4175799787044525 0.2836936414241791\n",
      "[Step 14340] Loss: 9.50e+07 -0.41794776916503906 0.28361111879348755\n",
      "[Step 14341] Loss: 9.51e+07 -0.41832876205444336 0.28351953625679016\n",
      "[Step 14342] Loss: 9.53e+07 -0.41878563165664673 0.28339412808418274\n",
      "[Step 14343] Loss: 9.56e+07 -0.41928964853286743 0.2832711637020111\n",
      "[Step 14344] Loss: 9.53e+07 -0.4198239743709564 0.2831779420375824\n",
      "[Step 14345] Loss: 9.46e+07 -0.4203583300113678 0.2830442488193512\n",
      "[Step 14346] Loss: 9.51e+07 -0.4208992123603821 0.28292378783226013\n",
      "[Step 14347] Loss: 9.44e+07 -0.42144522070884705 0.28281405568122864\n",
      "[Step 14348] Loss: 9.61e+07 -0.4221836030483246 0.28265148401260376\n",
      "[Step 14349] Loss: 9.46e+07 -0.4227989912033081 0.28249967098236084\n",
      "[Step 14350] Loss: 9.53e+07 -0.42339888215065 0.2824072539806366\n",
      "[Step 14351] Loss: 9.57e+07 -0.42385414242744446 0.2823123633861542\n",
      "[Step 14352] Loss: 9.55e+07 -0.42417168617248535 0.2822323143482208\n",
      "[Step 14353] Loss: 9.49e+07 -0.42442741990089417 0.28219518065452576\n",
      "[Step 14354] Loss: 9.46e+07 -0.42464619874954224 0.28215640783309937\n",
      "[Step 14355] Loss: 9.50e+07 -0.42497768998146057 0.2820862829685211\n",
      "[Step 14356] Loss: 9.54e+07 -0.42526400089263916 0.28199881315231323\n",
      "[Step 14357] Loss: 9.48e+07 -0.42551225423812866 0.2819344401359558\n",
      "[Step 14358] Loss: 9.55e+07 -0.42570018768310547 0.28190144896507263\n",
      "[Step 14359] Loss: 9.52e+07 -0.4257470667362213 0.28192371129989624\n",
      "[Step 14360] Loss: 9.53e+07 -0.4258110225200653 0.28192123770713806\n",
      "[Step 14361] Loss: 9.60e+07 -0.42601099610328674 0.2819286584854126\n",
      "[Step 14362] Loss: 9.58e+07 -0.42609718441963196 0.281936913728714\n",
      "[Step 14363] Loss: 9.46e+07 -0.42611056566238403 0.2819525897502899\n",
      "[Step 14364] Loss: 9.58e+07 -0.4262735843658447 0.28191712498664856\n",
      "[Step 14365] Loss: 9.48e+07 -0.4264523386955261 0.2819534242153168\n",
      "[Step 14366] Loss: 9.58e+07 -0.4268121123313904 0.2818956673145294\n",
      "[Step 14367] Loss: 9.57e+07 -0.4271624684333801 0.28186267614364624\n",
      "[Step 14368] Loss: 9.55e+07 -0.4274390935897827 0.28183048963546753\n",
      "[Step 14369] Loss: 9.49e+07 -0.42769572138786316 0.28175538778305054\n",
      "[Step 14370] Loss: 9.45e+07 -0.42786407470703125 0.28174713253974915\n",
      "[Step 14371] Loss: 9.52e+07 -0.42805254459381104 0.28172239661216736\n",
      "[Step 14372] Loss: 9.57e+07 -0.42834246158599854 0.2816481292247772\n",
      "[Step 14373] Loss: 9.51e+07 -0.4286373555660248 0.2815854251384735\n",
      "[Step 14374] Loss: 9.48e+07 -0.4289093017578125 0.281525194644928\n",
      "[Step 14375] Loss: 9.65e+07 -0.4289959669113159 0.2815004289150238\n",
      "[Step 14376] Loss: 9.56e+07 -0.4290914237499237 0.281472384929657\n",
      "[Step 14377] Loss: 9.56e+07 -0.42932644486427307 0.2814377248287201\n",
      "[Step 14378] Loss: 9.53e+07 -0.42965665459632874 0.28138408064842224\n",
      "[Step 14379] Loss: 9.50e+07 -0.430004358291626 0.2813057005405426\n",
      "[Step 14380] Loss: 9.51e+07 -0.43036121129989624 0.2812066674232483\n",
      "[Step 14381] Loss: 9.45e+07 -0.4307243824005127 0.28114643692970276\n",
      "[Step 14382] Loss: 9.46e+07 -0.43103983998298645 0.2810664176940918\n",
      "[Step 14383] Loss: 9.52e+07 -0.4311671555042267 0.2810441255569458\n",
      "[Step 14384] Loss: 9.58e+07 -0.431174635887146 0.28100287914276123\n",
      "[Step 14385] Loss: 9.59e+07 -0.4312746226787567 0.28097400069236755\n",
      "[Step 14386] Loss: 9.46e+07 -0.4312978684902191 0.2809731662273407\n",
      "[Step 14387] Loss: 9.47e+07 -0.43133673071861267 0.2809673845767975\n",
      "[Step 14388] Loss: 9.52e+07 -0.43121960759162903 0.2809616029262543\n",
      "[Step 14389] Loss: 9.73e+07 -0.4314458966255188 0.28092530369758606\n",
      "[Step 14390] Loss: 9.54e+07 -0.4316255450248718 0.28091126680374146\n",
      "[Step 14391] Loss: 9.58e+07 -0.4318508803844452 0.2808774411678314\n",
      "[Step 14392] Loss: 9.52e+07 -0.43211308121681213 0.2807982265949249\n",
      "[Step 14393] Loss: 9.55e+07 -0.4324713945388794 0.2807379961013794\n",
      "[Step 14394] Loss: 9.52e+07 -0.43279585242271423 0.28067365288734436\n",
      "[Step 14395] Loss: 9.48e+07 -0.43307504057884216 0.2805894613265991\n",
      "[Step 14396] Loss: 9.56e+07 -0.43323084712028503 0.2805696725845337\n",
      "[Step 14397] Loss: 9.54e+07 -0.43350422382354736 0.28054162859916687\n",
      "[Step 14398] Loss: 9.50e+07 -0.433731347322464 0.2804739475250244\n",
      "[Step 14399] Loss: 9.50e+07 -0.4338662028312683 0.2804310619831085\n",
      "[Step 14400] Loss: 9.49e+07 -0.4339263141155243 0.28041040897369385\n",
      "[Step 14401] Loss: 9.51e+07 -0.4340234398841858 0.28037741780281067\n",
      "[Step 14402] Loss: 9.46e+07 -0.4341036379337311 0.28035926818847656\n",
      "[Step 14403] Loss: 9.52e+07 -0.43414077162742615 0.2803584337234497\n",
      "[Step 14404] Loss: 9.49e+07 -0.4341515004634857 0.28035101294517517\n",
      "[Step 14405] Loss: 9.45e+07 -0.43413498997688293 0.28036174178123474\n",
      "[Step 14406] Loss: 9.49e+07 -0.4341576099395752 0.28035348653793335\n",
      "[Step 14407] Loss: 9.54e+07 -0.43427494168281555 0.2803179919719696\n",
      "[Step 14408] Loss: 9.44e+07 -0.43434086441993713 0.2802915871143341\n",
      "[Step 14409] Loss: 9.44e+07 -0.43436044454574585 0.28026437759399414\n",
      "[Step 14410] Loss: 9.48e+07 -0.4343807101249695 0.2802041471004486\n",
      "[Step 14411] Loss: 9.59e+07 -0.4345570504665375 0.28014639019966125\n",
      "[Step 14412] Loss: 9.52e+07 -0.4345930814743042 0.28014060854911804\n",
      "[Step 14413] Loss: 9.49e+07 -0.434578537940979 0.28014472126960754\n",
      "[Step 14414] Loss: 9.49e+07 -0.43459340929985046 0.2801356613636017\n",
      "[Step 14415] Loss: 9.55e+07 -0.43459299206733704 0.28010594844818115\n",
      "[Step 14416] Loss: 9.52e+07 -0.43454116582870483 0.2801108956336975\n",
      "[Step 14417] Loss: 9.50e+07 -0.4345382750034332 0.28011584281921387\n",
      "[Step 14418] Loss: 9.58e+07 -0.4344043433666229 0.28014472126960754\n",
      "[Step 14419] Loss: 9.52e+07 -0.4342716336250305 0.28014639019966125\n",
      "[Step 14420] Loss: 9.49e+07 -0.43423545360565186 0.28013646602630615\n",
      "[Step 14421] Loss: 9.50e+07 -0.43426957726478577 0.2801249325275421\n",
      "[Step 14422] Loss: 9.58e+07 -0.43413448333740234 0.2801331877708435\n",
      "[Step 14423] Loss: 9.54e+07 -0.4340139329433441 0.28017526865005493\n",
      "[Step 14424] Loss: 9.50e+07 -0.43391960859298706 0.28018349409103394\n",
      "[Step 14425] Loss: 9.53e+07 -0.4340028464794159 0.2801818549633026\n",
      "[Step 14426] Loss: 9.48e+07 -0.43415209650993347 0.28014639019966125\n",
      "[Step 14427] Loss: 9.53e+07 -0.43418222665786743 0.28014886379241943\n",
      "[Step 14428] Loss: 9.53e+07 -0.4341770112514496 0.2801760733127594\n",
      "[Step 14429] Loss: 9.53e+07 -0.43431052565574646 0.2801455557346344\n",
      "[Step 14430] Loss: 9.54e+07 -0.4344702363014221 0.2801166772842407\n",
      "[Step 14431] Loss: 9.46e+07 -0.4345748722553253 0.28007540106773376\n",
      "[Step 14432] Loss: 9.51e+07 -0.4347602427005768 0.2800481915473938\n",
      "[Step 14433] Loss: 9.54e+07 -0.43499651551246643 0.2799953818321228\n",
      "[Step 14434] Loss: 9.53e+07 -0.43514588475227356 0.2799466848373413\n",
      "[Step 14435] Loss: 9.45e+07 -0.4353192150592804 0.279922753572464\n",
      "[Step 14436] Loss: 9.50e+07 -0.43542391061782837 0.2799103856086731\n",
      "[Step 14437] Loss: 9.49e+07 -0.43543994426727295 0.27990955114364624\n",
      "[Step 14438] Loss: 9.41e+07 -0.43548640608787537 0.2798773944377899\n",
      "[Step 14439] Loss: 9.59e+07 -0.4353589713573456 0.2799120247364044\n",
      "[Step 14440] Loss: 9.54e+07 -0.43531471490859985 0.2799268960952759\n",
      "[Step 14441] Loss: 9.53e+07 -0.43519771099090576 0.27995824813842773\n",
      "[Step 14442] Loss: 9.53e+07 -0.4351036548614502 0.2799714505672455\n",
      "[Step 14443] Loss: 9.52e+07 -0.4350127875804901 0.27997228503227234\n",
      "[Step 14444] Loss: 9.50e+07 -0.43502292037010193 0.279997855424881\n",
      "[Step 14445] Loss: 9.49e+07 -0.43496760725975037 0.27997887134552\n",
      "[Step 14446] Loss: 9.46e+07 -0.4349134862422943 0.2799813449382782\n",
      "[Step 14447] Loss: 9.50e+07 -0.4349144399166107 0.28001269698143005\n",
      "[Step 14448] Loss: 9.53e+07 -0.43491432070732117 0.2799747586250305\n",
      "[Step 14449] Loss: 9.50e+07 -0.43494418263435364 0.27997639775276184\n",
      "[Step 14450] Loss: 9.53e+07 -0.4350390136241913 0.27997228503227234\n",
      "[Step 14451] Loss: 9.53e+07 -0.4352739751338959 0.2799161672592163\n",
      "[Step 14452] Loss: 9.49e+07 -0.4354880154132843 0.27987077832221985\n",
      "[Step 14453] Loss: 9.44e+07 -0.43565312027931213 0.279842734336853\n",
      "[Step 14454] Loss: 9.52e+07 -0.4358486831188202 0.2798188030719757\n",
      "[Step 14455] Loss: 9.62e+07 -0.4361823499202728 0.2797577381134033\n",
      "[Step 14456] Loss: 9.56e+07 -0.4366260766983032 0.2796933650970459\n",
      "[Step 14457] Loss: 9.52e+07 -0.43714436888694763 0.2795572280883789\n",
      "[Step 14458] Loss: 9.50e+07 -0.437666118144989 0.27948132157325745\n",
      "[Step 14459] Loss: 9.50e+07 -0.43815287947654724 0.2793872654438019\n",
      "[Step 14460] Loss: 9.46e+07 -0.4385550320148468 0.27928492426872253\n",
      "[Step 14461] Loss: 9.62e+07 -0.4387837052345276 0.2792024314403534\n",
      "[Step 14462] Loss: 9.50e+07 -0.4389706552028656 0.27916857600212097\n",
      "[Step 14463] Loss: 9.65e+07 -0.4394108057022095 0.2790505886077881\n",
      "[Step 14464] Loss: 9.47e+07 -0.4399154782295227 0.2789326012134552\n",
      "[Step 14465] Loss: 9.47e+07 -0.44040313363075256 0.27882614731788635\n",
      "[Step 14466] Loss: 9.51e+07 -0.4407593011856079 0.27873703837394714\n",
      "[Step 14467] Loss: 9.48e+07 -0.44111719727516174 0.2786710262298584\n",
      "[Step 14468] Loss: 9.54e+07 -0.44145306944847107 0.27861905097961426\n",
      "[Step 14469] Loss: 9.55e+07 -0.4417382478713989 0.27853652834892273\n",
      "[Step 14470] Loss: 9.45e+07 -0.4420599043369293 0.2784383296966553\n",
      "[Step 14471] Loss: 9.47e+07 -0.4423135221004486 0.2783855199813843\n",
      "[Step 14472] Loss: 9.53e+07 -0.4424820840358734 0.2783220112323761\n",
      "[Step 14473] Loss: 9.45e+07 -0.44271528720855713 0.278281569480896\n",
      "[Step 14474] Loss: 9.54e+07 -0.4430326521396637 0.27822133898735046\n",
      "[Step 14475] Loss: 9.53e+07 -0.4432383179664612 0.27816852927207947\n",
      "[Step 14476] Loss: 9.56e+07 -0.4435189664363861 0.2781091034412384\n",
      "[Step 14477] Loss: 9.51e+07 -0.44374144077301025 0.27805960178375244\n",
      "[Step 14478] Loss: 9.46e+07 -0.44396495819091797 0.27803319692611694\n",
      "[Step 14479] Loss: 9.49e+07 -0.44423919916152954 0.27796471118927\n",
      "[Step 14480] Loss: 9.51e+07 -0.44453543424606323 0.2778863310813904\n",
      "[Step 14481] Loss: 9.62e+07 -0.44469520449638367 0.2778376340866089\n",
      "[Step 14482] Loss: 9.55e+07 -0.4447479844093323 0.2778434157371521\n",
      "[Step 14483] Loss: 9.42e+07 -0.44483473896980286 0.2778409421443939\n",
      "[Step 14484] Loss: 9.48e+07 -0.4448939561843872 0.27784425020217896\n",
      "[Step 14485] Loss: 9.49e+07 -0.44501766562461853 0.27784258127212524\n",
      "[Step 14486] Loss: 9.56e+07 -0.44511106610298157 0.2778194844722748\n",
      "[Step 14487] Loss: 9.46e+07 -0.4452214241027832 0.27780216932296753\n",
      "[Step 14488] Loss: 9.50e+07 -0.44530990719795227 0.2778005003929138\n",
      "[Step 14489] Loss: 9.46e+07 -0.44535523653030396 0.2778186798095703\n",
      "[Step 14490] Loss: 9.63e+07 -0.4455568492412567 0.2777666747570038\n",
      "[Step 14491] Loss: 9.55e+07 -0.4457172155380249 0.27772706747055054\n",
      "[Step 14492] Loss: 9.51e+07 -0.44588425755500793 0.2776816785335541\n",
      "[Step 14493] Loss: 9.48e+07 -0.4459478557109833 0.2776734530925751\n",
      "[Step 14494] Loss: 9.46e+07 -0.4459831118583679 0.2777072787284851\n",
      "[Step 14495] Loss: 9.42e+07 -0.4459575414657593 0.27774521708488464\n",
      "[Step 14496] Loss: 9.50e+07 -0.4459659159183502 0.277750164270401\n",
      "[Step 14497] Loss: 9.40e+07 -0.4459189772605896 0.2777559459209442\n",
      "[Step 14498] Loss: 9.53e+07 -0.44594821333885193 0.2777460515499115\n",
      "[Step 14499] Loss: 9.51e+07 -0.4459797739982605 0.277741938829422\n",
      "[Step 14500] Loss: 9.53e+07 -0.44602763652801514 0.2777377963066101\n",
      "[Step 14501] Loss: 9.52e+07 -0.4459763169288635 0.27773863077163696\n",
      "[Step 14502] Loss: 9.49e+07 -0.4459547996520996 0.2777394652366638\n",
      "[Step 14503] Loss: 9.48e+07 -0.4458670914173126 0.27774688601493835\n",
      "[Step 14504] Loss: 9.52e+07 -0.44590967893600464 0.277689129114151\n",
      "[Step 14505] Loss: 9.52e+07 -0.44591015577316284 0.2776990234851837\n",
      "[Step 14506] Loss: 9.47e+07 -0.44592124223709106 0.2776866555213928\n",
      "[Step 14507] Loss: 9.49e+07 -0.4459087550640106 0.2776916027069092\n",
      "[Step 14508] Loss: 9.61e+07 -0.4457544684410095 0.27770233154296875\n",
      "[Step 14509] Loss: 9.45e+07 -0.4455666244029999 0.2777444124221802\n",
      "[Step 14510] Loss: 9.56e+07 -0.44533228874206543 0.27778154611587524\n",
      "[Step 14511] Loss: 9.46e+07 -0.4449935853481293 0.2778417766094208\n",
      "[Step 14512] Loss: 9.45e+07 -0.44465598464012146 0.2779061198234558\n",
      "[Step 14513] Loss: 9.50e+07 -0.444353848695755 0.2780018448829651\n",
      "[Step 14514] Loss: 9.48e+07 -0.4440312683582306 0.2780851721763611\n",
      "[Step 14515] Loss: 9.48e+07 -0.4437711536884308 0.27816274762153625\n",
      "[Step 14516] Loss: 9.50e+07 -0.44349029660224915 0.2782130837440491\n",
      "[Step 14517] Loss: 9.49e+07 -0.44318687915802 0.27826258540153503\n",
      "[Step 14518] Loss: 9.61e+07 -0.4430338740348816 0.27831870317459106\n",
      "[Step 14519] Loss: 9.50e+07 -0.4429035484790802 0.2783409655094147\n",
      "[Step 14520] Loss: 9.55e+07 -0.4427298307418823 0.27842679619789124\n",
      "[Step 14521] Loss: 9.50e+07 -0.4427533447742462 0.27841606736183167\n",
      "[Step 14522] Loss: 9.51e+07 -0.44282522797584534 0.2783946096897125\n",
      "[Step 14523] Loss: 9.51e+07 -0.4430793523788452 0.27832281589508057\n",
      "[Step 14524] Loss: 9.52e+07 -0.4434804320335388 0.2782271206378937\n",
      "[Step 14525] Loss: 9.53e+07 -0.4438464939594269 0.2781701683998108\n",
      "[Step 14526] Loss: 9.57e+07 -0.4440998435020447 0.2780967354774475\n",
      "[Step 14527] Loss: 9.45e+07 -0.4443535804748535 0.2780587673187256\n",
      "[Step 14528] Loss: 9.64e+07 -0.4444526135921478 0.2780761122703552\n",
      "[Step 14529] Loss: 9.44e+07 -0.44455939531326294 0.2780868411064148\n",
      "[Step 14530] Loss: 9.49e+07 -0.4446503221988678 0.27806538343429565\n",
      "[Step 14531] Loss: 9.55e+07 -0.44469961524009705 0.27804309129714966\n",
      "[Step 14532] Loss: 9.61e+07 -0.44501951336860657 0.27798205614089966\n",
      "[Step 14533] Loss: 9.60e+07 -0.4454546272754669 0.27788880467414856\n",
      "[Step 14534] Loss: 9.49e+07 -0.4459008276462555 0.277802973985672\n",
      "[Step 14535] Loss: 9.48e+07 -0.4462902843952179 0.2777666747570038\n",
      "[Step 14536] Loss: 9.57e+07 -0.4466261565685272 0.2777155339717865\n",
      "[Step 14537] Loss: 9.50e+07 -0.44697949290275574 0.2776462137699127\n",
      "[Step 14538] Loss: 9.50e+07 -0.4471782445907593 0.27761155366897583\n",
      "[Step 14539] Loss: 9.52e+07 -0.4474983215332031 0.27753812074661255\n",
      "[Step 14540] Loss: 9.48e+07 -0.44786813855171204 0.2774886190891266\n",
      "[Step 14541] Loss: 9.50e+07 -0.4482237994670868 0.2774498164653778\n",
      "[Step 14542] Loss: 9.58e+07 -0.44831544160842896 0.2774622142314911\n",
      "[Step 14543] Loss: 9.49e+07 -0.448363333940506 0.27746880054473877\n",
      "[Step 14544] Loss: 9.56e+07 -0.448255717754364 0.27748778462409973\n",
      "[Step 14545] Loss: 9.48e+07 -0.44805437326431274 0.2775471806526184\n",
      "[Step 14546] Loss: 9.51e+07 -0.4479210674762726 0.2775430679321289\n",
      "[Step 14547] Loss: 9.48e+07 -0.44773179292678833 0.2775942385196686\n",
      "[Step 14548] Loss: 9.58e+07 -0.4477609395980835 0.2775917649269104\n",
      "[Step 14549] Loss: 9.53e+07 -0.44768548011779785 0.27760329842567444\n",
      "[Step 14550] Loss: 9.65e+07 -0.44782358407974243 0.2775859832763672\n",
      "[Step 14551] Loss: 9.54e+07 -0.4480842351913452 0.2775364816188812\n",
      "[Step 14552] Loss: 9.44e+07 -0.44832322001457214 0.2775224447250366\n",
      "[Step 14553] Loss: 9.49e+07 -0.4486055076122284 0.277477890253067\n",
      "[Step 14554] Loss: 9.47e+07 -0.4488564729690552 0.27744239568710327\n",
      "[Step 14555] Loss: 9.51e+07 -0.44899895787239075 0.2773871123790741\n",
      "[Step 14556] Loss: 9.43e+07 -0.4491173028945923 0.27738216519355774\n",
      "[Step 14557] Loss: 9.48e+07 -0.44921135902404785 0.2773508131504059\n",
      "[Step 14558] Loss: 9.53e+07 -0.44933897256851196 0.27728891372680664\n",
      "[Step 14559] Loss: 9.48e+07 -0.44955646991729736 0.27724766731262207\n",
      "[Step 14560] Loss: 9.46e+07 -0.44975122809410095 0.2772187888622284\n",
      "[Step 14561] Loss: 9.48e+07 -0.4498913884162903 0.2771701216697693\n",
      "[Step 14562] Loss: 9.43e+07 -0.4499167203903198 0.27714452147483826\n",
      "[Step 14563] Loss: 9.43e+07 -0.44991862773895264 0.27715855836868286\n",
      "[Step 14564] Loss: 9.50e+07 -0.4498838186264038 0.27717259526252747\n",
      "[Step 14565] Loss: 9.54e+07 -0.44995275139808655 0.2771552503108978\n",
      "[Step 14566] Loss: 9.49e+07 -0.4500080347061157 0.2771536111831665\n",
      "[Step 14567] Loss: 9.52e+07 -0.4500998258590698 0.27714452147483826\n",
      "[Step 14568] Loss: 9.43e+07 -0.45017895102500916 0.27712225914001465\n",
      "[Step 14569] Loss: 9.46e+07 -0.45026034116744995 0.2770909070968628\n",
      "[Step 14570] Loss: 9.50e+07 -0.45034584403038025 0.27707523107528687\n",
      "[Step 14571] Loss: 9.49e+07 -0.4504367411136627 0.2770702540874481\n",
      "[Step 14572] Loss: 9.63e+07 -0.4506179094314575 0.2770504653453827\n",
      "[Step 14573] Loss: 9.49e+07 -0.4507237374782562 0.27701663970947266\n",
      "[Step 14574] Loss: 9.41e+07 -0.4508366882801056 0.27699023485183716\n",
      "[Step 14575] Loss: 9.44e+07 -0.45091578364372253 0.2769836187362671\n",
      "[Step 14576] Loss: 9.53e+07 -0.4508296251296997 0.2769894003868103\n",
      "[Step 14577] Loss: 9.63e+07 -0.4509958326816559 0.27693575620651245\n",
      "[Step 14578] Loss: 9.49e+07 -0.4511623978614807 0.27691102027893066\n",
      "[Step 14579] Loss: 9.57e+07 -0.45137983560562134 0.27688294649124146\n",
      "[Step 14580] Loss: 9.46e+07 -0.45155763626098633 0.2768796682357788\n",
      "[Step 14581] Loss: 9.49e+07 -0.45165950059890747 0.27683013677597046\n",
      "[Step 14582] Loss: 9.49e+07 -0.45174768567085266 0.2768095135688782\n",
      "[Step 14583] Loss: 9.51e+07 -0.45184624195098877 0.27678394317626953\n",
      "[Step 14584] Loss: 9.59e+07 -0.45176103711128235 0.2767987847328186\n",
      "[Step 14585] Loss: 9.52e+07 -0.451756089925766 0.2768029272556305\n",
      "[Step 14586] Loss: 9.44e+07 -0.4517323076725006 0.27680209279060364\n",
      "[Step 14587] Loss: 9.50e+07 -0.45170679688453674 0.276829332113266\n",
      "[Step 14588] Loss: 9.42e+07 -0.45160260796546936 0.27690359950065613\n",
      "[Step 14589] Loss: 9.49e+07 -0.4514246881008148 0.27694153785705566\n",
      "[Step 14590] Loss: 9.46e+07 -0.4512863755226135 0.27696463465690613\n",
      "[Step 14591] Loss: 9.45e+07 -0.4511861801147461 0.27698609232902527\n",
      "[Step 14592] Loss: 9.50e+07 -0.45110687613487244 0.27699682116508484\n",
      "[Step 14593] Loss: 9.51e+07 -0.45114022493362427 0.27698034048080444\n",
      "[Step 14594] Loss: 9.46e+07 -0.45123594999313354 0.2769778370857239\n",
      "[Step 14595] Loss: 9.42e+07 -0.4513365626335144 0.27697041630744934\n",
      "[Step 14596] Loss: 9.43e+07 -0.451466828584671 0.2769242227077484\n",
      "[Step 14597] Loss: 9.53e+07 -0.45163407921791077 0.2768895626068115\n",
      "[Step 14598] Loss: 9.57e+07 -0.45190152525901794 0.2768474817276001\n",
      "[Step 14599] Loss: 9.64e+07 -0.4523153305053711 0.27677157521247864\n",
      "[Step 14600] Loss: 9.50e+07 -0.4527937173843384 0.2767030894756317\n",
      "[Step 14601] Loss: 9.58e+07 -0.45338279008865356 0.2765941619873047\n",
      "[Step 14602] Loss: 9.53e+07 -0.4538390338420868 0.27652236819267273\n",
      "[Step 14603] Loss: 9.66e+07 -0.4544173777103424 0.27643078565597534\n",
      "[Step 14604] Loss: 9.54e+07 -0.4549294114112854 0.2763260006904602\n",
      "[Step 14605] Loss: 9.71e+07 -0.45569849014282227 0.2761783003807068\n",
      "[Step 14606] Loss: 9.53e+07 -0.45645859837532043 0.27604958415031433\n",
      "[Step 14607] Loss: 9.49e+07 -0.4572022557258606 0.27591672539711\n",
      "[Step 14608] Loss: 9.48e+07 -0.45791399478912354 0.2757739722728729\n",
      "[Step 14609] Loss: 9.49e+07 -0.4584848880767822 0.2756708264350891\n",
      "[Step 14610] Loss: 9.49e+07 -0.4589368999004364 0.2756122350692749\n",
      "[Step 14611] Loss: 9.46e+07 -0.4593439996242523 0.27555447816848755\n",
      "[Step 14612] Loss: 9.46e+07 -0.4596986472606659 0.275513231754303\n",
      "[Step 14613] Loss: 9.52e+07 -0.4599888324737549 0.2754315435886383\n",
      "[Step 14614] Loss: 9.50e+07 -0.46021467447280884 0.27539193630218506\n",
      "[Step 14615] Loss: 9.55e+07 -0.4602962136268616 0.27537378668785095\n",
      "[Step 14616] Loss: 9.56e+07 -0.4604168236255646 0.27536800503730774\n",
      "[Step 14617] Loss: 9.55e+07 -0.4604661762714386 0.275377094745636\n",
      "[Step 14618] Loss: 9.47e+07 -0.46048128604888916 0.2753465473651886\n",
      "[Step 14619] Loss: 9.46e+07 -0.4604281187057495 0.27534160017967224\n",
      "[Step 14620] Loss: 9.44e+07 -0.4604641795158386 0.27531272172927856\n",
      "[Step 14621] Loss: 9.50e+07 -0.4604451060295105 0.27529868483543396\n",
      "[Step 14622] Loss: 9.52e+07 -0.4603365957736969 0.2753201425075531\n",
      "[Step 14623] Loss: 9.52e+07 -0.46021750569343567 0.2753382921218872\n",
      "[Step 14624] Loss: 9.45e+07 -0.4601339101791382 0.2753440737724304\n",
      "[Step 14625] Loss: 9.55e+07 -0.4599544405937195 0.27536800503730774\n",
      "[Step 14626] Loss: 9.51e+07 -0.4598352611064911 0.2753927707672119\n",
      "[Step 14627] Loss: 9.54e+07 -0.4596274793148041 0.2753993570804596\n",
      "[Step 14628] Loss: 9.46e+07 -0.45937302708625793 0.2754513621330261\n",
      "[Step 14629] Loss: 9.61e+07 -0.4593823254108429 0.2754521667957306\n",
      "[Step 14630] Loss: 9.45e+07 -0.459336519241333 0.275441437959671\n",
      "[Step 14631] Loss: 9.50e+07 -0.45934364199638367 0.2754579484462738\n",
      "[Step 14632] Loss: 9.49e+07 -0.45936545729637146 0.27546289563179016\n",
      "[Step 14633] Loss: 9.58e+07 -0.45933806896209717 0.2754785716533661\n",
      "[Step 14634] Loss: 9.50e+07 -0.4593658745288849 0.27546125650405884\n",
      "[Step 14635] Loss: 9.46e+07 -0.459378182888031 0.2754290699958801\n",
      "[Step 14636] Loss: 9.54e+07 -0.45946621894836426 0.2754381597042084\n",
      "[Step 14637] Loss: 9.52e+07 -0.45966842770576477 0.27540677785873413\n",
      "[Step 14638] Loss: 9.57e+07 -0.45973289012908936 0.2754216492176056\n",
      "[Step 14639] Loss: 9.58e+07 -0.459963321685791 0.27535396814346313\n",
      "[Step 14640] Loss: 9.47e+07 -0.46009889245033264 0.27533334493637085\n",
      "[Step 14641] Loss: 9.48e+07 -0.46034184098243713 0.2753077745437622\n",
      "[Step 14642] Loss: 9.56e+07 -0.46074214577674866 0.27524587512016296\n",
      "[Step 14643] Loss: 9.52e+07 -0.4610953629016876 0.2751922607421875\n",
      "[Step 14644] Loss: 9.43e+07 -0.461341917514801 0.27516254782676697\n",
      "[Step 14645] Loss: 9.45e+07 -0.461590439081192 0.27511388063430786\n",
      "[Step 14646] Loss: 9.46e+07 -0.46186578273773193 0.27503135800361633\n",
      "[Step 14647] Loss: 9.57e+07 -0.4622001647949219 0.2749777138233185\n",
      "[Step 14648] Loss: 9.45e+07 -0.4625192880630493 0.2749224305152893\n",
      "[Step 14649] Loss: 9.52e+07 -0.4629369080066681 0.2748539447784424\n",
      "[Step 14650] Loss: 9.61e+07 -0.4632413685321808 0.27478960156440735\n",
      "[Step 14651] Loss: 9.59e+07 -0.46373388171195984 0.2746847867965698\n",
      "[Step 14652] Loss: 9.46e+07 -0.46412211656570435 0.27461549639701843\n",
      "[Step 14653] Loss: 9.52e+07 -0.46459531784057617 0.27454450726509094\n",
      "[Step 14654] Loss: 9.58e+07 -0.46506962180137634 0.27445128560066223\n",
      "[Step 14655] Loss: 9.51e+07 -0.46549761295318604 0.2743687629699707\n",
      "[Step 14656] Loss: 9.49e+07 -0.4659025967121124 0.2742895483970642\n",
      "[Step 14657] Loss: 9.53e+07 -0.46634069085121155 0.27422353625297546\n",
      "[Step 14658] Loss: 9.51e+07 -0.4666896164417267 0.274169921875\n",
      "[Step 14659] Loss: 9.45e+07 -0.4669521152973175 0.2741294801235199\n",
      "[Step 14660] Loss: 9.45e+07 -0.4671250879764557 0.2740972936153412\n",
      "[Step 14661] Loss: 9.47e+07 -0.4672713577747345 0.27408409118652344\n",
      "[Step 14662] Loss: 9.51e+07 -0.46733716130256653 0.2740725576877594\n",
      "[Step 14663] Loss: 9.48e+07 -0.467394083738327 0.27402469515800476\n",
      "[Step 14664] Loss: 9.44e+07 -0.4673852324485779 0.2740486264228821\n",
      "[Step 14665] Loss: 9.53e+07 -0.46741899847984314 0.27405110001564026\n",
      "[Step 14666] Loss: 9.54e+07 -0.4675348699092865 0.27401477098464966\n",
      "[Step 14667] Loss: 9.47e+07 -0.4675891399383545 0.27399829030036926\n",
      "[Step 14668] Loss: 9.44e+07 -0.46754246950149536 0.273989200592041\n",
      "[Step 14669] Loss: 9.48e+07 -0.46749427914619446 0.27398672699928284\n",
      "[Step 14670] Loss: 9.49e+07 -0.4675265848636627 0.2739627957344055\n",
      "[Step 14671] Loss: 9.61e+07 -0.46767887473106384 0.27395784854888916\n",
      "[Step 14672] Loss: 9.47e+07 -0.467733234167099 0.2739529013633728\n",
      "[Step 14673] Loss: 9.53e+07 -0.4676651358604431 0.27397021651268005\n",
      "[Step 14674] Loss: 9.45e+07 -0.4675604999065399 0.273977667093277\n",
      "[Step 14675] Loss: 9.49e+07 -0.4674489200115204 0.27398014068603516\n",
      "[Step 14676] Loss: 9.60e+07 -0.4674592614173889 0.2739933431148529\n",
      "[Step 14677] Loss: 9.47e+07 -0.46750590205192566 0.273989200592041\n",
      "[Step 14678] Loss: 9.43e+07 -0.4675074517726898 0.2739652693271637\n",
      "[Step 14679] Loss: 9.53e+07 -0.46748238801956177 0.27397847175598145\n",
      "[Step 14680] Loss: 9.49e+07 -0.46736809611320496 0.2739933431148529\n",
      "[Step 14681] Loss: 9.48e+07 -0.4673474133014679 0.27400487661361694\n",
      "[Step 14682] Loss: 9.56e+07 -0.4671720862388611 0.27405935525894165\n",
      "[Step 14683] Loss: 9.52e+07 -0.4671337604522705 0.27406594157218933\n",
      "[Step 14684] Loss: 9.54e+07 -0.46717485785484314 0.27404284477233887\n",
      "[Step 14685] Loss: 9.54e+07 -0.46714991331100464 0.2740519046783447\n",
      "[Step 14686] Loss: 9.59e+07 -0.4672882556915283 0.2740477919578552\n",
      "[Step 14687] Loss: 9.45e+07 -0.4674365818500519 0.2740304470062256\n",
      "[Step 14688] Loss: 9.56e+07 -0.4675914943218231 0.2740197479724884\n",
      "[Step 14689] Loss: 9.53e+07 -0.467800110578537 0.27400240302085876\n",
      "[Step 14690] Loss: 9.48e+07 -0.46800488233566284 0.27398014068603516\n",
      "[Step 14691] Loss: 9.53e+07 -0.46832382678985596 0.27394217252731323\n",
      "[Step 14692] Loss: 9.48e+07 -0.46869558095932007 0.2739099860191345\n",
      "[Step 14693] Loss: 9.55e+07 -0.4691638946533203 0.27382251620292664\n",
      "[Step 14694] Loss: 9.65e+07 -0.46980535984039307 0.27372434735298157\n",
      "[Step 14695] Loss: 9.57e+07 -0.47040149569511414 0.2736203670501709\n",
      "[Step 14696] Loss: 9.48e+07 -0.4709319770336151 0.27353209257125854\n",
      "[Step 14697] Loss: 9.59e+07 -0.47156938910484314 0.27342233061790466\n",
      "[Step 14698] Loss: 9.65e+07 -0.4723432660102844 0.27327215671539307\n",
      "[Step 14699] Loss: 9.55e+07 -0.4730578362941742 0.27311041951179504\n",
      "[Step 14700] Loss: 9.65e+07 -0.47400739789009094 0.27293798327445984\n",
      "[Step 14701] Loss: 9.53e+07 -0.4748041331768036 0.2727803885936737\n",
      "[Step 14702] Loss: 9.61e+07 -0.47544267773628235 0.27265825867652893\n",
      "[Step 14703] Loss: 9.62e+07 -0.4759809374809265 0.27255427837371826\n",
      "[Step 14704] Loss: 9.51e+07 -0.47656920552253723 0.27242887020111084\n",
      "[Step 14705] Loss: 9.50e+07 -0.4770568609237671 0.27233314514160156\n",
      "[Step 14706] Loss: 9.48e+07 -0.47743600606918335 0.27223414182662964\n",
      "[Step 14707] Loss: 9.50e+07 -0.47785404324531555 0.27213841676712036\n",
      "[Step 14708] Loss: 9.46e+07 -0.47823283076286316 0.2720690965652466\n",
      "[Step 14709] Loss: 9.52e+07 -0.4786326587200165 0.271997332572937\n",
      "[Step 14710] Loss: 9.45e+07 -0.4789781868457794 0.2719205915927887\n",
      "[Step 14711] Loss: 9.48e+07 -0.47938084602355957 0.271838903427124\n",
      "[Step 14712] Loss: 9.46e+07 -0.47973689436912537 0.271729975938797\n",
      "[Step 14713] Loss: 9.50e+07 -0.48011094331741333 0.2716449797153473\n",
      "[Step 14714] Loss: 9.47e+07 -0.480442076921463 0.27158641815185547\n",
      "[Step 14715] Loss: 9.50e+07 -0.4806390702724457 0.2715558707714081\n",
      "[Step 14716] Loss: 9.58e+07 -0.48082926869392395 0.2715204060077667\n",
      "[Step 14717] Loss: 9.54e+07 -0.4809393286705017 0.2714906930923462\n",
      "[Step 14718] Loss: 9.51e+07 -0.48099517822265625 0.27147501707077026\n",
      "[Step 14719] Loss: 9.50e+07 -0.4810671806335449 0.2714799642562866\n",
      "[Step 14720] Loss: 9.53e+07 -0.4812285304069519 0.27144283056259155\n",
      "[Step 14721] Loss: 9.43e+07 -0.48132941126823425 0.2713891863822937\n",
      "[Step 14722] Loss: 9.42e+07 -0.481375515460968 0.27136939764022827\n",
      "[Step 14723] Loss: 9.44e+07 -0.481471449136734 0.27135783433914185\n",
      "[Step 14724] Loss: 9.45e+07 -0.4816092252731323 0.2713471055030823\n",
      "[Step 14725] Loss: 9.50e+07 -0.4817940592765808 0.27132153511047363\n",
      "[Step 14726] Loss: 9.47e+07 -0.481981486082077 0.2712934911251068\n",
      "[Step 14727] Loss: 9.49e+07 -0.48210224509239197 0.2712778151035309\n",
      "[Step 14728] Loss: 9.48e+07 -0.48211613297462463 0.2712654173374176\n",
      "[Step 14729] Loss: 9.43e+07 -0.48214712738990784 0.2712637782096863\n",
      "[Step 14730] Loss: 9.48e+07 -0.48214805126190186 0.2712555229663849\n",
      "[Step 14731] Loss: 9.53e+07 -0.4821609556674957 0.2712852358818054\n",
      "[Step 14732] Loss: 9.42e+07 -0.482191264629364 0.2712670862674713\n",
      "[Step 14733] Loss: 9.57e+07 -0.4822954535484314 0.2712918221950531\n",
      "[Step 14734] Loss: 9.45e+07 -0.4823000729084015 0.2713157534599304\n",
      "[Step 14735] Loss: 9.64e+07 -0.4821481704711914 0.2713611423969269\n",
      "[Step 14736] Loss: 9.57e+07 -0.48185864090919495 0.2714180648326874\n",
      "[Step 14737] Loss: 9.54e+07 -0.48164597153663635 0.2714799642562866\n",
      "[Step 14738] Loss: 9.47e+07 -0.4814069867134094 0.2715435028076172\n",
      "[Step 14739] Loss: 9.46e+07 -0.4811569154262543 0.27160951495170593\n",
      "[Step 14740] Loss: 9.54e+07 -0.4808655381202698 0.2716788351535797\n",
      "[Step 14741] Loss: 9.43e+07 -0.480682909488678 0.2717118263244629\n",
      "[Step 14742] Loss: 9.46e+07 -0.4804859161376953 0.27176958322525024\n",
      "[Step 14743] Loss: 9.48e+07 -0.4802786111831665 0.271816611289978\n",
      "[Step 14744] Loss: 9.55e+07 -0.4800538420677185 0.27182653546333313\n",
      "[Step 14745] Loss: 9.50e+07 -0.4798855185508728 0.2718653082847595\n",
      "[Step 14746] Loss: 9.42e+07 -0.4797114133834839 0.27188345789909363\n",
      "[Step 14747] Loss: 9.49e+07 -0.479511022567749 0.27191397547721863\n",
      "[Step 14748] Loss: 9.65e+07 -0.4794501066207886 0.27191564440727234\n",
      "[Step 14749] Loss: 9.45e+07 -0.4793354570865631 0.27194368839263916\n",
      "[Step 14750] Loss: 9.48e+07 -0.4791536331176758 0.2719667851924896\n",
      "[Step 14751] Loss: 9.51e+07 -0.4790307879447937 0.2719791829586029\n",
      "[Step 14752] Loss: 9.47e+07 -0.4789499342441559 0.27199649810791016\n",
      "[Step 14753] Loss: 9.56e+07 -0.4790339767932892 0.27197009325027466\n",
      "[Step 14754] Loss: 9.48e+07 -0.4790128469467163 0.2719667851924896\n",
      "[Step 14755] Loss: 9.55e+07 -0.4790216088294983 0.27193132042884827\n",
      "[Step 14756] Loss: 9.59e+07 -0.47893083095550537 0.27193790674209595\n",
      "[Step 14757] Loss: 9.52e+07 -0.478895366191864 0.2719271779060364\n",
      "[Step 14758] Loss: 9.56e+07 -0.4787953197956085 0.2719329595565796\n",
      "[Step 14759] Loss: 9.47e+07 -0.47873151302337646 0.2719494700431824\n",
      "[Step 14760] Loss: 9.51e+07 -0.47856345772743225 0.27198824286460876\n",
      "[Step 14761] Loss: 9.50e+07 -0.47828832268714905 0.2720336318016052\n",
      "[Step 14762] Loss: 9.52e+07 -0.47810932993888855 0.2720608711242676\n",
      "[Step 14763] Loss: 9.51e+07 -0.4780172109603882 0.27207159996032715\n",
      "[Step 14764] Loss: 9.46e+07 -0.4778914749622345 0.2721054255962372\n",
      "[Step 14765] Loss: 9.47e+07 -0.47783195972442627 0.2721268832683563\n",
      "[Step 14766] Loss: 9.46e+07 -0.47775575518608093 0.2721697688102722\n",
      "[Step 14767] Loss: 9.53e+07 -0.4775836169719696 0.2722044289112091\n",
      "[Step 14768] Loss: 9.43e+07 -0.4774559736251831 0.2722225785255432\n",
      "[Step 14769] Loss: 9.45e+07 -0.47730016708374023 0.272261381149292\n",
      "[Step 14770] Loss: 9.51e+07 -0.47712966799736023 0.2722935378551483\n",
      "[Step 14771] Loss: 9.48e+07 -0.47701576352119446 0.27232077717781067\n",
      "[Step 14772] Loss: 9.47e+07 -0.476934015750885 0.27234965562820435\n",
      "[Step 14773] Loss: 9.58e+07 -0.47701507806777954 0.27233150601387024\n",
      "[Step 14774] Loss: 9.49e+07 -0.47699615359306335 0.27232739329338074\n",
      "[Step 14775] Loss: 9.46e+07 -0.4770611822605133 0.27234140038490295\n",
      "[Step 14776] Loss: 9.52e+07 -0.47719624638557434 0.27230262756347656\n",
      "[Step 14777] Loss: 9.53e+07 -0.4772059917449951 0.2723116874694824\n",
      "[Step 14778] Loss: 9.51e+07 -0.47725144028663635 0.2723116874694824\n",
      "[Step 14779] Loss: 9.42e+07 -0.4772548973560333 0.27232739329338074\n",
      "[Step 14780] Loss: 9.53e+07 -0.477209210395813 0.27235791087150574\n",
      "[Step 14781] Loss: 9.51e+07 -0.4770807921886444 0.27236616611480713\n",
      "[Step 14782] Loss: 9.54e+07 -0.47687825560569763 0.2723793685436249\n",
      "[Step 14783] Loss: 9.52e+07 -0.476811021566391 0.27236121892929077\n",
      "[Step 14784] Loss: 9.61e+07 -0.4769870340824127 0.2723116874694824\n",
      "[Step 14785] Loss: 9.55e+07 -0.47701117396354675 0.272322416305542\n",
      "[Step 14786] Loss: 9.53e+07 -0.4769972860813141 0.2723562717437744\n",
      "[Step 14787] Loss: 9.60e+07 -0.47719764709472656 0.27230262756347656\n",
      "[Step 14788] Loss: 9.46e+07 -0.4774308502674103 0.2722778618335724\n",
      "[Step 14789] Loss: 9.53e+07 -0.4776081442832947 0.27222341299057007\n",
      "[Step 14790] Loss: 9.55e+07 -0.4777027368545532 0.2722151577472687\n",
      "[Step 14791] Loss: 9.44e+07 -0.4776930510997772 0.27218711376190186\n",
      "[Step 14792] Loss: 9.48e+07 -0.47772011160850525 0.2721903920173645\n",
      "[Step 14793] Loss: 9.52e+07 -0.4776163399219513 0.27223166823387146\n",
      "[Step 14794] Loss: 9.50e+07 -0.47747603058815 0.27225393056869507\n",
      "[Step 14795] Loss: 9.43e+07 -0.4773532748222351 0.2722712755203247\n",
      "[Step 14796] Loss: 9.50e+07 -0.4772076904773712 0.27230098843574524\n",
      "[Step 14797] Loss: 9.51e+07 -0.47701308131217957 0.27233976125717163\n",
      "[Step 14798] Loss: 9.46e+07 -0.47673454880714417 0.2724049389362335\n",
      "[Step 14799] Loss: 9.56e+07 -0.4763907194137573 0.2724577486515045\n",
      "[Step 14800] Loss: 9.45e+07 -0.4760758578777313 0.27250146865844727\n",
      "[Step 14801] Loss: 9.46e+07 -0.4757726192474365 0.2725476920604706\n",
      "[Step 14802] Loss: 9.49e+07 -0.4754135310649872 0.27258315682411194\n",
      "[Step 14803] Loss: 9.50e+07 -0.4750789999961853 0.2726310193538666\n",
      "[Step 14804] Loss: 9.50e+07 -0.4748440980911255 0.2726442217826843\n",
      "[Step 14805] Loss: 9.51e+07 -0.474693238735199 0.27266404032707214\n",
      "[Step 14806] Loss: 9.53e+07 -0.47440093755722046 0.2727341651916504\n",
      "[Step 14807] Loss: 9.62e+07 -0.47431451082229614 0.2727316915988922\n",
      "[Step 14808] Loss: 9.50e+07 -0.47420379519462585 0.27274325489997864\n",
      "[Step 14809] Loss: 9.53e+07 -0.4740320146083832 0.2727845013141632\n",
      "[Step 14810] Loss: 9.51e+07 -0.47387173771858215 0.2728249430656433\n",
      "[Step 14811] Loss: 9.46e+07 -0.473772257566452 0.27283400297164917\n",
      "[Step 14812] Loss: 9.42e+07 -0.4736478626728058 0.27285298705101013\n",
      "[Step 14813] Loss: 9.51e+07 -0.47357189655303955 0.2728802263736725\n",
      "[Step 14814] Loss: 9.49e+07 -0.47343671321868896 0.2729140520095825\n",
      "[Step 14815] Loss: 9.54e+07 -0.4734170734882355 0.27293384075164795\n",
      "[Step 14816] Loss: 9.48e+07 -0.47341594099998474 0.2729445695877075\n",
      "[Step 14817] Loss: 9.49e+07 -0.4733163118362427 0.27295777201652527\n",
      "[Step 14818] Loss: 9.50e+07 -0.47311022877693176 0.2730221450328827\n",
      "[Step 14819] Loss: 9.48e+07 -0.47284936904907227 0.2730823755264282\n",
      "[Step 14820] Loss: 9.49e+07 -0.4725792407989502 0.2731318771839142\n",
      "[Step 14821] Loss: 9.59e+07 -0.4725503623485565 0.2731228172779083\n",
      "[Step 14822] Loss: 9.57e+07 -0.47270122170448303 0.2730947434902191\n",
      "[Step 14823] Loss: 9.51e+07 -0.47281378507614136 0.27309972047805786\n",
      "[Step 14824] Loss: 9.52e+07 -0.4729205369949341 0.2730749547481537\n",
      "[Step 14825] Loss: 9.52e+07 -0.47289374470710754 0.2730790674686432\n",
      "[Step 14826] Loss: 9.52e+07 -0.4728805422782898 0.273076593875885\n",
      "[Step 14827] Loss: 9.46e+07 -0.47284379601478577 0.2730823755264282\n",
      "[Step 14828] Loss: 9.50e+07 -0.4728662967681885 0.27307742834091187\n",
      "[Step 14829] Loss: 9.48e+07 -0.4729290008544922 0.2730543315410614\n",
      "[Step 14830] Loss: 9.52e+07 -0.47313106060028076 0.2730295658111572\n",
      "[Step 14831] Loss: 9.53e+07 -0.47328463196754456 0.27301719784736633\n",
      "[Step 14832] Loss: 9.44e+07 -0.47334590554237366 0.27300482988357544\n",
      "[Step 14833] Loss: 9.42e+07 -0.4733469486236572 0.27300894260406494\n",
      "[Step 14834] Loss: 9.54e+07 -0.473307341337204 0.27300068736076355\n",
      "[Step 14835] Loss: 9.50e+07 -0.4733109474182129 0.2730114161968231\n",
      "[Step 14836] Loss: 9.53e+07 -0.4733235836029053 0.2730015218257904\n",
      "[Step 14837] Loss: 9.51e+07 -0.4732474982738495 0.27304691076278687\n",
      "[Step 14838] Loss: 9.62e+07 -0.4732685983181 0.27306175231933594\n",
      "[Step 14839] Loss: 9.54e+07 -0.4732723534107208 0.2730972170829773\n",
      "[Step 14840] Loss: 9.56e+07 -0.4733603894710541 0.2730666995048523\n",
      "[Step 14841] Loss: 9.67e+07 -0.4736648201942444 0.2730279266834259\n",
      "[Step 14842] Loss: 9.50e+07 -0.47384315729141235 0.273023784160614\n",
      "[Step 14843] Loss: 9.42e+07 -0.474017471075058 0.27300646901130676\n",
      "[Step 14844] Loss: 9.48e+07 -0.4742422103881836 0.27298417687416077\n",
      "[Step 14845] Loss: 9.62e+07 -0.4744299352169037 0.2729388177394867\n",
      "[Step 14846] Loss: 9.54e+07 -0.47453880310058594 0.2729247808456421\n",
      "[Step 14847] Loss: 9.63e+07 -0.4744980037212372 0.27294623851776123\n",
      "[Step 14848] Loss: 9.59e+07 -0.47456324100494385 0.2729049623012543\n",
      "[Step 14849] Loss: 9.55e+07 -0.47459161281585693 0.2729124128818512\n",
      "[Step 14850] Loss: 9.55e+07 -0.4745120406150818 0.2729165256023407\n",
      "[Step 14851] Loss: 9.44e+07 -0.47446003556251526 0.27290743589401245\n",
      "[Step 14852] Loss: 9.42e+07 -0.47436514496803284 0.27291569113731384\n",
      "[Step 14853] Loss: 9.63e+07 -0.47409459948539734 0.2729652225971222\n",
      "[Step 14854] Loss: 9.50e+07 -0.4739154577255249 0.2730015218257904\n",
      "[Step 14855] Loss: 9.50e+07 -0.4736923575401306 0.2730402946472168\n",
      "[Step 14856] Loss: 9.44e+07 -0.4734615385532379 0.2730889916419983\n",
      "[Step 14857] Loss: 9.54e+07 -0.473255455493927 0.27313682436943054\n",
      "[Step 14858] Loss: 9.51e+07 -0.4731099307537079 0.2731987237930298\n",
      "[Step 14859] Loss: 9.51e+07 -0.4729328155517578 0.2732449173927307\n",
      "[Step 14860] Loss: 9.45e+07 -0.4727042615413666 0.27331340312957764\n",
      "[Step 14861] Loss: 9.51e+07 -0.472535103559494 0.2733488976955414\n",
      "[Step 14862] Loss: 9.58e+07 -0.4723750352859497 0.27335962653160095\n",
      "[Step 14863] Loss: 9.50e+07 -0.47220999002456665 0.27338355779647827\n",
      "[Step 14864] Loss: 9.52e+07 -0.4722152650356293 0.2733645737171173\n",
      "[Step 14865] Loss: 9.50e+07 -0.47221019864082336 0.2733563184738159\n",
      "[Step 14866] Loss: 9.44e+07 -0.4721854627132416 0.2733604609966278\n",
      "[Step 14867] Loss: 9.54e+07 -0.47225451469421387 0.2733563184738159\n",
      "[Step 14868] Loss: 9.59e+07 -0.4724837839603424 0.27332165837287903\n",
      "[Step 14869] Loss: 9.52e+07 -0.47271105647087097 0.2732795774936676\n",
      "[Step 14870] Loss: 9.68e+07 -0.47323471307754517 0.27317726612091064\n",
      "[Step 14871] Loss: 9.51e+07 -0.47362464666366577 0.2730931043624878\n",
      "[Step 14872] Loss: 9.52e+07 -0.4739014208316803 0.273023784160614\n",
      "[Step 14873] Loss: 9.48e+07 -0.474184513092041 0.2729891240596771\n",
      "[Step 14874] Loss: 9.50e+07 -0.47439077496528625 0.27298253774642944\n",
      "[Step 14875] Loss: 9.48e+07 -0.4746355414390564 0.27291321754455566\n",
      "[Step 14876] Loss: 9.49e+07 -0.47484472393989563 0.27286702394485474\n",
      "[Step 14877] Loss: 9.46e+07 -0.47498494386672974 0.27283400297164917\n",
      "[Step 14878] Loss: 9.54e+07 -0.4750279486179352 0.27281832695007324\n",
      "[Step 14879] Loss: 9.46e+07 -0.47508543729782104 0.2728216350078583\n",
      "[Step 14880] Loss: 9.56e+07 -0.47526815533638 0.2727597653865814\n",
      "[Step 14881] Loss: 9.52e+07 -0.47550445795059204 0.27269870042800903\n",
      "[Step 14882] Loss: 9.49e+07 -0.4756525754928589 0.2726648449897766\n",
      "[Step 14883] Loss: 9.51e+07 -0.475742369890213 0.27264589071273804\n",
      "[Step 14884] Loss: 9.56e+07 -0.4759256839752197 0.2726021409034729\n",
      "[Step 14885] Loss: 9.51e+07 -0.4761364161968231 0.2725617289543152\n",
      "[Step 14886] Loss: 9.58e+07 -0.47637003660202026 0.2725229263305664\n",
      "[Step 14887] Loss: 9.56e+07 -0.47664645314216614 0.2724717855453491\n",
      "[Step 14888] Loss: 9.50e+07 -0.4770669639110565 0.27238595485687256\n",
      "[Step 14889] Loss: 9.48e+07 -0.4775053560733795 0.27229106426239014\n",
      "[Step 14890] Loss: 9.55e+07 -0.47802844643592834 0.2721804976463318\n",
      "[Step 14891] Loss: 9.61e+07 -0.47839832305908203 0.27209633588790894\n",
      "[Step 14892] Loss: 9.43e+07 -0.4786272943019867 0.2720418870449066\n",
      "[Step 14893] Loss: 9.55e+07 -0.47886234521865845 0.2719767093658447\n",
      "[Step 14894] Loss: 9.52e+07 -0.47914567589759827 0.27190324664115906\n",
      "[Step 14895] Loss: 9.48e+07 -0.47936734557151794 0.27185705304145813\n",
      "[Step 14896] Loss: 9.51e+07 -0.4795941412448883 0.27183064818382263\n",
      "[Step 14897] Loss: 9.50e+07 -0.47979095578193665 0.27179598808288574\n",
      "[Step 14898] Loss: 9.50e+07 -0.4799937307834625 0.27173906564712524\n",
      "[Step 14899] Loss: 9.52e+07 -0.48025983572006226 0.2716746926307678\n",
      "[Step 14900] Loss: 9.52e+07 -0.48046034574508667 0.27165406942367554\n",
      "[Step 14901] Loss: 9.49e+07 -0.4806867241859436 0.2716177701950073\n",
      "[Step 14902] Loss: 9.57e+07 -0.48086485266685486 0.27159383893013\n",
      "[Step 14903] Loss: 9.51e+07 -0.4809674918651581 0.27156496047973633\n",
      "[Step 14904] Loss: 9.53e+07 -0.48095372319221497 0.2715699076652527\n",
      "[Step 14905] Loss: 9.47e+07 -0.4809316098690033 0.27158889174461365\n",
      "[Step 14906] Loss: 9.45e+07 -0.48085877299308777 0.2715822756290436\n",
      "[Step 14907] Loss: 9.43e+07 -0.4807907044887543 0.27158063650131226\n",
      "[Step 14908] Loss: 9.45e+07 -0.4807174801826477 0.27161362767219543\n",
      "[Step 14909] Loss: 9.49e+07 -0.48070457577705383 0.271624356508255\n",
      "[Step 14910] Loss: 9.47e+07 -0.48077088594436646 0.27162766456604004\n",
      "[Step 14911] Loss: 9.48e+07 -0.48085707426071167 0.27162519097328186\n",
      "[Step 14912] Loss: 9.56e+07 -0.4807746112346649 0.2716268301010132\n",
      "[Step 14913] Loss: 9.49e+07 -0.4807657301425934 0.2716284990310669\n",
      "[Step 14914] Loss: 9.44e+07 -0.48080766201019287 0.27162519097328186\n",
      "[Step 14915] Loss: 9.44e+07 -0.48082906007766724 0.27165985107421875\n",
      "[Step 14916] Loss: 9.47e+07 -0.4808831214904785 0.27168211340904236\n",
      "[Step 14917] Loss: 9.57e+07 -0.4807949364185333 0.27169451117515564\n",
      "[Step 14918] Loss: 9.44e+07 -0.48078081011772156 0.2716977894306183\n",
      "[Step 14919] Loss: 9.53e+07 -0.48085397481918335 0.2717233896255493\n",
      "[Step 14920] Loss: 9.53e+07 -0.48081061244010925 0.27175474166870117\n",
      "[Step 14921] Loss: 9.46e+07 -0.48072654008865356 0.2717992961406708\n",
      "[Step 14922] Loss: 9.55e+07 -0.4808046221733093 0.2718174457550049\n",
      "[Step 14923] Loss: 9.57e+07 -0.48105108737945557 0.2717943489551544\n",
      "[Step 14924] Loss: 9.51e+07 -0.4812116324901581 0.2717770040035248\n",
      "[Step 14925] Loss: 9.46e+07 -0.4814085364341736 0.2717316150665283\n",
      "[Step 14926] Loss: 9.50e+07 -0.48160919547080994 0.27169284224510193\n",
      "[Step 14927] Loss: 9.62e+07 -0.48192623257637024 0.2716284990310669\n",
      "[Step 14928] Loss: 9.46e+07 -0.4822908937931061 0.27159053087234497\n",
      "[Step 14929] Loss: 9.53e+07 -0.4825754165649414 0.27154597640037537\n",
      "[Step 14930] Loss: 9.47e+07 -0.48273298144340515 0.2715336084365845\n",
      "[Step 14931] Loss: 9.49e+07 -0.4827921688556671 0.27151215076446533\n",
      "[Step 14932] Loss: 9.47e+07 -0.48273566365242004 0.2715245187282562\n",
      "[Step 14933] Loss: 9.49e+07 -0.4827263653278351 0.2715170979499817\n",
      "[Step 14934] Loss: 9.58e+07 -0.4829063415527344 0.27150967717170715\n",
      "[Step 14935] Loss: 9.63e+07 -0.48324698209762573 0.2714436650276184\n",
      "[Step 14936] Loss: 9.49e+07 -0.4835387170314789 0.27138590812683105\n",
      "[Step 14937] Loss: 9.44e+07 -0.48384103178977966 0.27132564783096313\n",
      "[Step 14938] Loss: 9.50e+07 -0.4840272068977356 0.2712877094745636\n",
      "[Step 14939] Loss: 9.57e+07 -0.484353244304657 0.2712183892726898\n",
      "[Step 14940] Loss: 9.55e+07 -0.48474544286727905 0.27115485072135925\n",
      "[Step 14941] Loss: 9.56e+07 -0.4852781593799591 0.2710641026496887\n",
      "[Step 14942] Loss: 9.54e+07 -0.48585280776023865 0.2709650695323944\n",
      "[Step 14943] Loss: 9.54e+07 -0.4862169027328491 0.27089494466781616\n",
      "[Step 14944] Loss: 9.47e+07 -0.4865880012512207 0.2708074748516083\n",
      "[Step 14945] Loss: 9.43e+07 -0.48692455887794495 0.2707720100879669\n",
      "[Step 14946] Loss: 9.59e+07 -0.4874669313430786 0.27068617939949036\n",
      "[Step 14947] Loss: 9.55e+07 -0.4878215789794922 0.2706342041492462\n",
      "[Step 14948] Loss: 9.47e+07 -0.48816272616386414 0.2705739736557007\n",
      "[Step 14949] Loss: 9.58e+07 -0.4886263608932495 0.27049145102500916\n",
      "[Step 14950] Loss: 9.47e+07 -0.48910364508628845 0.2704072892665863\n",
      "[Step 14951] Loss: 9.47e+07 -0.48954781889915466 0.27034375071525574\n",
      "[Step 14952] Loss: 9.45e+07 -0.4899197518825531 0.27030330896377563\n",
      "[Step 14953] Loss: 9.47e+07 -0.49020519852638245 0.27023565769195557\n",
      "[Step 14954] Loss: 9.49e+07 -0.49041947722435 0.27017706632614136\n",
      "[Step 14955] Loss: 9.43e+07 -0.490619421005249 0.2701333463191986\n",
      "[Step 14956] Loss: 9.45e+07 -0.4908132255077362 0.2700846493244171\n",
      "[Step 14957] Loss: 9.47e+07 -0.491021066904068 0.2700689733028412\n",
      "[Step 14958] Loss: 9.46e+07 -0.4912084639072418 0.27004092931747437\n",
      "[Step 14959] Loss: 9.53e+07 -0.49121877551078796 0.2700442373752594\n",
      "[Step 14960] Loss: 9.45e+07 -0.49122971296310425 0.27003514766693115\n",
      "[Step 14961] Loss: 9.41e+07 -0.49122631549835205 0.270032674074173\n",
      "[Step 14962] Loss: 9.43e+07 -0.4912467896938324 0.2700277268886566\n",
      "[Step 14963] Loss: 9.40e+07 -0.49127256870269775 0.27002277970314026\n",
      "[Step 14964] Loss: 9.50e+07 -0.49126407504081726 0.2700343132019043\n",
      "[Step 14965] Loss: 9.42e+07 -0.4912099242210388 0.27005907893180847\n",
      "[Step 14966] Loss: 9.50e+07 -0.4912037253379822 0.2700731158256531\n",
      "[Step 14967] Loss: 9.48e+07 -0.4912704527378082 0.27005496621131897\n",
      "[Step 14968] Loss: 9.50e+07 -0.49125322699546814 0.27005329728126526\n",
      "[Step 14969] Loss: 9.46e+07 -0.49122723937034607 0.2700508236885071\n",
      "[Step 14970] Loss: 9.59e+07 -0.49138298630714417 0.2700417637825012\n",
      "[Step 14971] Loss: 9.51e+07 -0.4916055202484131 0.269983172416687\n",
      "[Step 14972] Loss: 9.47e+07 -0.49188321828842163 0.26994356513023376\n",
      "[Step 14973] Loss: 9.48e+07 -0.4921598434448242 0.2699064314365387\n",
      "[Step 14974] Loss: 9.43e+07 -0.49237510561943054 0.2698841392993927\n",
      "[Step 14975] Loss: 9.56e+07 -0.4926871061325073 0.2698494791984558\n",
      "[Step 14976] Loss: 9.56e+07 -0.49302634596824646 0.26979008316993713\n",
      "[Step 14977] Loss: 9.51e+07 -0.4932183623313904 0.2697966694831848\n",
      "[Step 14978] Loss: 9.52e+07 -0.4933924973011017 0.2697603702545166\n",
      "[Step 14979] Loss: 9.52e+07 -0.4934798777103424 0.2697463631629944\n",
      "[Step 14980] Loss: 9.45e+07 -0.4934804439544678 0.2697446942329407\n",
      "[Step 14981] Loss: 9.53e+07 -0.4934128224849701 0.2697339653968811\n",
      "[Step 14982] Loss: 9.53e+07 -0.4932851195335388 0.269738107919693\n",
      "[Step 14983] Loss: 9.53e+07 -0.49329298734664917 0.2697537839412689\n",
      "[Step 14984] Loss: 9.52e+07 -0.4931771457195282 0.26976367831230164\n",
      "[Step 14985] Loss: 9.48e+07 -0.4929816424846649 0.2698131799697876\n",
      "[Step 14986] Loss: 9.53e+07 -0.4927050769329071 0.26987341046333313\n",
      "[Step 14987] Loss: 9.45e+07 -0.4924401044845581 0.269904762506485\n",
      "[Step 14988] Loss: 9.48e+07 -0.4920487701892853 0.2699839770793915\n",
      "[Step 14989] Loss: 9.51e+07 -0.4917645752429962 0.2700648605823517\n",
      "[Step 14990] Loss: 9.54e+07 -0.4914170801639557 0.2701391279697418\n",
      "[Step 14991] Loss: 9.52e+07 -0.49119898676872253 0.2701696455478668\n",
      "[Step 14992] Loss: 9.51e+07 -0.4909646511077881 0.27018284797668457\n",
      "[Step 14993] Loss: 9.54e+07 -0.49072080850601196 0.2702208161354065\n",
      "[Step 14994] Loss: 9.45e+07 -0.4904557764530182 0.27024224400520325\n",
      "[Step 14995] Loss: 9.46e+07 -0.49017858505249023 0.2702793776988983\n",
      "[Step 14996] Loss: 9.47e+07 -0.4900270700454712 0.27028268575668335\n",
      "[Step 14997] Loss: 9.48e+07 -0.489941269159317 0.27027690410614014\n",
      "[Step 14998] Loss: 9.45e+07 -0.48991620540618896 0.2702628970146179\n",
      "[Step 14999] Loss: 9.44e+07 -0.4898676872253418 0.2702793776988983\n",
      "[Step 15000] Loss: 9.49e+07 -0.48981305956840515 0.27028021216392517\n",
      "[Step 15001] Loss: 9.47e+07 -0.489717960357666 0.2702711522579193\n",
      "[Step 15002] Loss: 9.50e+07 -0.48953354358673096 0.270300030708313\n",
      "[Step 15003] Loss: 9.52e+07 -0.48942461609840393 0.2703206539154053\n",
      "[Step 15004] Loss: 9.52e+07 -0.4893658459186554 0.27031072974205017\n",
      "[Step 15005] Loss: 9.51e+07 -0.48928189277648926 0.2703264355659485\n",
      "[Step 15006] Loss: 9.52e+07 -0.4893731474876404 0.27031323313713074\n",
      "[Step 15007] Loss: 9.51e+07 -0.4895062744617462 0.27026453614234924\n",
      "[Step 15008] Loss: 9.51e+07 -0.48953431844711304 0.27029505372047424\n",
      "[Step 15009] Loss: 9.44e+07 -0.48962050676345825 0.2702893018722534\n",
      "[Step 15010] Loss: 9.60e+07 -0.48954251408576965 0.27031072974205017\n",
      "[Step 15011] Loss: 9.59e+07 -0.48933959007263184 0.2703792452812195\n",
      "[Step 15012] Loss: 9.57e+07 -0.48938265442848206 0.2703849971294403\n",
      "[Step 15013] Loss: 9.46e+07 -0.48940715193748474 0.27039986848831177\n",
      "[Step 15014] Loss: 9.51e+07 -0.4895018935203552 0.2704130709171295\n",
      "[Step 15015] Loss: 9.55e+07 -0.4895074963569641 0.2704320251941681\n",
      "[Step 15016] Loss: 9.47e+07 -0.48945850133895874 0.2704600989818573\n",
      "[Step 15017] Loss: 9.54e+07 -0.48954829573631287 0.2704221308231354\n",
      "[Step 15018] Loss: 9.45e+07 -0.4896245300769806 0.2704254388809204\n",
      "[Step 15019] Loss: 9.49e+07 -0.4897322952747345 0.2703932523727417\n",
      "[Step 15020] Loss: 9.45e+07 -0.4899635910987854 0.27037426829338074\n",
      "[Step 15021] Loss: 9.53e+07 -0.49030086398124695 0.2702901065349579\n",
      "[Step 15022] Loss: 9.56e+07 -0.49037158489227295 0.27026206254959106\n",
      "[Step 15023] Loss: 9.46e+07 -0.4903860092163086 0.2702876329421997\n",
      "[Step 15024] Loss: 9.54e+07 -0.4903666377067566 0.27026617527008057\n",
      "[Step 15025] Loss: 9.53e+07 -0.490308552980423 0.2702513337135315\n",
      "[Step 15026] Loss: 9.60e+07 -0.49020060896873474 0.27025049924850464\n",
      "[Step 15027] Loss: 9.46e+07 -0.4901158809661865 0.27028846740722656\n",
      "[Step 15028] Loss: 9.54e+07 -0.489962100982666 0.270308256149292\n",
      "[Step 15029] Loss: 9.43e+07 -0.48971864581108093 0.270352840423584\n",
      "[Step 15030] Loss: 9.47e+07 -0.48950642347335815 0.27038171887397766\n",
      "[Step 15031] Loss: 9.47e+07 -0.48941656947135925 0.27040398120880127\n",
      "[Step 15032] Loss: 9.47e+07 -0.48927977681159973 0.2704114019870758\n",
      "[Step 15033] Loss: 9.48e+07 -0.4892076253890991 0.27042874693870544\n",
      "[Step 15034] Loss: 9.44e+07 -0.4891301095485687 0.27045679092407227\n",
      "[Step 15035] Loss: 9.70e+07 -0.4893690347671509 0.27043616771698\n",
      "[Step 15036] Loss: 9.50e+07 -0.48957130312919617 0.2703907787799835\n",
      "[Step 15037] Loss: 9.47e+07 -0.48973146080970764 0.27038830518722534\n",
      "[Step 15038] Loss: 9.54e+07 -0.4898644685745239 0.27036190032958984\n",
      "[Step 15039] Loss: 9.53e+07 -0.48991549015045166 0.27035942673683167\n",
      "[Step 15040] Loss: 9.52e+07 -0.4899963438510895 0.27035200595855713\n",
      "[Step 15041] Loss: 9.42e+07 -0.49005240201950073 0.2703206539154053\n",
      "[Step 15042] Loss: 9.59e+07 -0.4900343120098114 0.2703206539154053\n",
      "[Step 15043] Loss: 9.52e+07 -0.48996782302856445 0.270308256149292\n",
      "[Step 15044] Loss: 9.47e+07 -0.48981109261512756 0.27034538984298706\n",
      "[Step 15045] Loss: 9.39e+07 -0.48966774344444275 0.2703486979007721\n",
      "[Step 15046] Loss: 9.46e+07 -0.4895717203617096 0.27037426829338074\n",
      "[Step 15047] Loss: 9.55e+07 -0.4896129071712494 0.27035611867904663\n",
      "[Step 15048] Loss: 9.47e+07 -0.4896654784679413 0.27034786343574524\n",
      "[Step 15049] Loss: 9.47e+07 -0.48974674940109253 0.27032724022865295\n",
      "[Step 15050] Loss: 9.54e+07 -0.4898476004600525 0.2702835202217102\n",
      "[Step 15051] Loss: 9.50e+07 -0.4899645149707794 0.27025628089904785\n",
      "[Step 15052] Loss: 9.50e+07 -0.4900461733341217 0.2702208161354065\n",
      "[Step 15053] Loss: 9.62e+07 -0.49025142192840576 0.27017873525619507\n",
      "[Step 15054] Loss: 9.52e+07 -0.4905371069908142 0.2701316773891449\n",
      "[Step 15055] Loss: 9.49e+07 -0.4908432960510254 0.2700607180595398\n",
      "[Step 15056] Loss: 9.49e+07 -0.49112987518310547 0.2700178325176239\n",
      "[Step 15057] Loss: 9.51e+07 -0.49147018790245056 0.269957572221756\n",
      "[Step 15058] Loss: 9.53e+07 -0.49191033840179443 0.26991385221481323\n",
      "[Step 15059] Loss: 9.48e+07 -0.49233201146125793 0.26984867453575134\n",
      "[Step 15060] Loss: 9.51e+07 -0.49269917607307434 0.2698073983192444\n",
      "[Step 15061] Loss: 9.62e+07 -0.4932427406311035 0.2697578966617584\n",
      "[Step 15062] Loss: 9.54e+07 -0.4936683475971222 0.26968446373939514\n",
      "[Step 15063] Loss: 9.51e+07 -0.49393028020858765 0.26964402198791504\n",
      "[Step 15064] Loss: 9.49e+07 -0.49419546127319336 0.2695821523666382\n",
      "[Step 15065] Loss: 9.49e+07 -0.494412899017334 0.26954585313796997\n",
      "[Step 15066] Loss: 9.64e+07 -0.4948062300682068 0.26947489380836487\n",
      "[Step 15067] Loss: 9.58e+07 -0.49536851048469543 0.2693791687488556\n",
      "[Step 15068] Loss: 9.50e+07 -0.4959109127521515 0.2692760229110718\n",
      "[Step 15069] Loss: 9.44e+07 -0.4963831603527069 0.26919928193092346\n",
      "[Step 15070] Loss: 9.50e+07 -0.49690335988998413 0.26911017298698425\n",
      "[Step 15071] Loss: 9.58e+07 -0.4972850978374481 0.2690507471561432\n",
      "[Step 15072] Loss: 9.50e+07 -0.4975976049900055 0.26898640394210815\n",
      "[Step 15073] Loss: 9.41e+07 -0.4978357255458832 0.26895174384117126\n",
      "[Step 15074] Loss: 9.44e+07 -0.4981733560562134 0.268881618976593\n",
      "[Step 15075] Loss: 9.55e+07 -0.4983546733856201 0.268859326839447\n",
      "[Step 15076] Loss: 9.55e+07 -0.498486191034317 0.268837034702301\n",
      "[Step 15077] Loss: 9.51e+07 -0.49857786297798157 0.2688147723674774\n",
      "[Step 15078] Loss: 9.51e+07 -0.498759388923645 0.2687966227531433\n",
      "[Step 15079] Loss: 9.51e+07 -0.4988774061203003 0.2687545418739319\n",
      "[Step 15080] Loss: 9.45e+07 -0.4990515410900116 0.26871657371520996\n",
      "[Step 15081] Loss: 9.53e+07 -0.49936196208000183 0.2686588168144226\n",
      "[Step 15082] Loss: 9.53e+07 -0.4996180534362793 0.26861095428466797\n",
      "[Step 15083] Loss: 9.49e+07 -0.4998181462287903 0.26858454942703247\n",
      "[Step 15084] Loss: 9.49e+07 -0.49998971819877625 0.2685680687427521\n",
      "[Step 15085] Loss: 9.51e+07 -0.5002714395523071 0.2685375213623047\n",
      "[Step 15086] Loss: 9.52e+07 -0.5004391074180603 0.2684962749481201\n",
      "[Step 15087] Loss: 9.47e+07 -0.5005900859832764 0.26847150921821594\n",
      "[Step 15088] Loss: 9.52e+07 -0.5006940364837646 0.2684904932975769\n",
      "[Step 15089] Loss: 9.48e+07 -0.5007860660552979 0.26849380135536194\n",
      "[Step 15090] Loss: 9.53e+07 -0.5009859800338745 0.26846492290496826\n",
      "[Step 15091] Loss: 9.48e+07 -0.5012149214744568 0.2684343755245209\n",
      "[Step 15092] Loss: 9.53e+07 -0.5013368725776672 0.26841869950294495\n",
      "[Step 15093] Loss: 9.54e+07 -0.5014888644218445 0.26839807629585266\n",
      "[Step 15094] Loss: 9.57e+07 -0.5014644265174866 0.26842036843299866\n",
      "[Step 15095] Loss: 9.43e+07 -0.5014969706535339 0.26840054988861084\n",
      "[Step 15096] Loss: 9.55e+07 -0.5016574859619141 0.26837578415870667\n",
      "[Step 15097] Loss: 9.61e+07 -0.501646101474762 0.2683947682380676\n",
      "[Step 15098] Loss: 9.43e+07 -0.5016036033630371 0.26841291785240173\n",
      "[Step 15099] Loss: 9.56e+07 -0.5015122294425964 0.2684401571750641\n",
      "[Step 15100] Loss: 9.49e+07 -0.5015289783477783 0.2684863805770874\n",
      "[Step 15101] Loss: 9.50e+07 -0.5015813708305359 0.2684904932975769\n",
      "[Step 15102] Loss: 9.48e+07 -0.5016740560531616 0.26846078038215637\n",
      "[Step 15103] Loss: 9.57e+07 -0.501956045627594 0.2684137523174286\n",
      "[Step 15104] Loss: 9.43e+07 -0.502178966999054 0.268391489982605\n",
      "[Step 15105] Loss: 9.49e+07 -0.5023777484893799 0.26834526658058167\n",
      "[Step 15106] Loss: 9.49e+07 -0.5025436282157898 0.268319696187973\n",
      "[Step 15107] Loss: 9.49e+07 -0.5027220249176025 0.26827678084373474\n",
      "[Step 15108] Loss: 9.53e+07 -0.5029370784759521 0.2682611048221588\n",
      "[Step 15109] Loss: 9.46e+07 -0.5030934810638428 0.26822397112846375\n",
      "[Step 15110] Loss: 9.48e+07 -0.5033490657806396 0.26821160316467285\n",
      "[Step 15111] Loss: 9.57e+07 -0.5037328004837036 0.26814723014831543\n",
      "[Step 15112] Loss: 9.49e+07 -0.5040369629859924 0.26812660694122314\n",
      "[Step 15113] Loss: 9.52e+07 -0.5042185187339783 0.26811671257019043\n",
      "[Step 15114] Loss: 9.56e+07 -0.5044078826904297 0.2680845260620117\n",
      "[Step 15115] Loss: 9.47e+07 -0.5044983625411987 0.2680927813053131\n",
      "[Step 15116] Loss: 9.67e+07 -0.5049015283584595 0.26803502440452576\n",
      "[Step 15117] Loss: 9.36e+07 -0.5053038597106934 0.26798221468925476\n",
      "[Step 15118] Loss: 9.56e+07 -0.5055974721908569 0.26794424653053284\n",
      "[Step 15119] Loss: 9.61e+07 -0.5059347748756409 0.2678782343864441\n",
      "[Step 15120] Loss: 9.48e+07 -0.5061183571815491 0.2678378224372864\n",
      "[Step 15121] Loss: 9.56e+07 -0.5062328577041626 0.26781389117240906\n",
      "[Step 15122] Loss: 9.46e+07 -0.506354808807373 0.26782462000846863\n",
      "[Step 15123] Loss: 9.54e+07 -0.5065658092498779 0.26780563592910767\n",
      "[Step 15124] Loss: 9.49e+07 -0.5068308711051941 0.2677742838859558\n",
      "[Step 15125] Loss: 9.54e+07 -0.5070065259933472 0.2677379548549652\n",
      "[Step 15126] Loss: 9.48e+07 -0.5072445869445801 0.2677041292190552\n",
      "[Step 15127] Loss: 9.51e+07 -0.5074166655540466 0.26766782999038696\n",
      "[Step 15128] Loss: 9.49e+07 -0.5075083374977112 0.2676669955253601\n",
      "[Step 15129] Loss: 9.43e+07 -0.5075643062591553 0.26764804124832153\n",
      "[Step 15130] Loss: 9.44e+07 -0.5075348019599915 0.2676571011543274\n",
      "[Step 15131] Loss: 9.49e+07 -0.507476270198822 0.26767444610595703\n",
      "[Step 15132] Loss: 9.45e+07 -0.507381021976471 0.2677074372768402\n",
      "[Step 15133] Loss: 9.48e+07 -0.5073448419570923 0.267754465341568\n",
      "[Step 15134] Loss: 9.44e+07 -0.507253110408783 0.267754465341568\n",
      "[Step 15135] Loss: 9.56e+07 -0.5073626637458801 0.2677437365055084\n",
      "[Step 15136] Loss: 9.48e+07 -0.5073503851890564 0.2677255868911743\n",
      "[Step 15137] Loss: 9.45e+07 -0.5073449611663818 0.26771074533462524\n",
      "[Step 15138] Loss: 9.49e+07 -0.5072796940803528 0.2677255868911743\n",
      "[Step 15139] Loss: 9.52e+07 -0.5070772767066956 0.26774540543556213\n",
      "[Step 15140] Loss: 9.54e+07 -0.5068160891532898 0.2677965462207794\n",
      "[Step 15141] Loss: 9.50e+07 -0.5065928101539612 0.2678493559360504\n",
      "[Step 15142] Loss: 9.53e+07 -0.5062698721885681 0.2678774297237396\n",
      "[Step 15143] Loss: 9.49e+07 -0.5060244202613831 0.2679087817668915\n",
      "[Step 15144] Loss: 9.57e+07 -0.5057803392410278 0.2679145336151123\n",
      "[Step 15145] Loss: 9.48e+07 -0.5055053234100342 0.26794755458831787\n",
      "[Step 15146] Loss: 9.49e+07 -0.5052357912063599 0.2679896354675293\n",
      "[Step 15147] Loss: 9.43e+07 -0.5050044655799866 0.26804739236831665\n",
      "[Step 15148] Loss: 9.51e+07 -0.504826545715332 0.26808369159698486\n",
      "[Step 15149] Loss: 9.48e+07 -0.5047599077224731 0.26811009645462036\n",
      "[Step 15150] Loss: 9.48e+07 -0.5046465396881104 0.2681158781051636\n",
      "[Step 15151] Loss: 9.70e+07 -0.504804253578186 0.2680787444114685\n",
      "[Step 15152] Loss: 9.51e+07 -0.5049182176589966 0.2680548131465912\n",
      "[Step 15153] Loss: 9.55e+07 -0.5050248503684998 0.2680259346961975\n",
      "[Step 15154] Loss: 9.47e+07 -0.505193293094635 0.2680094242095947\n",
      "[Step 15155] Loss: 9.48e+07 -0.5053049325942993 0.26798632740974426\n",
      "[Step 15156] Loss: 9.50e+07 -0.505431056022644 0.26797807216644287\n",
      "[Step 15157] Loss: 9.62e+07 -0.5053912401199341 0.26800036430358887\n",
      "[Step 15158] Loss: 9.45e+07 -0.5054714679718018 0.26796406507492065\n",
      "[Step 15159] Loss: 9.46e+07 -0.505523145198822 0.26795002818107605\n",
      "[Step 15160] Loss: 9.51e+07 -0.5056365132331848 0.2679384648799896\n",
      "[Step 15161] Loss: 9.56e+07 -0.5058943629264832 0.2679104208946228\n",
      "[Step 15162] Loss: 9.62e+07 -0.5062887668609619 0.2678543031215668\n",
      "[Step 15163] Loss: 9.43e+07 -0.5066863894462585 0.26779571175575256\n",
      "[Step 15164] Loss: 9.51e+07 -0.5070052146911621 0.267754465341568\n",
      "[Step 15165] Loss: 9.50e+07 -0.5072188973426819 0.26772063970565796\n",
      "[Step 15166] Loss: 9.46e+07 -0.5074560046195984 0.2677198052406311\n",
      "[Step 15167] Loss: 9.42e+07 -0.5076541900634766 0.2676975429058075\n",
      "[Step 15168] Loss: 9.45e+07 -0.5077945590019226 0.2676348388195038\n",
      "[Step 15169] Loss: 9.49e+07 -0.5078572630882263 0.26764142513275146\n",
      "[Step 15170] Loss: 9.51e+07 -0.5079383254051208 0.26760512590408325\n",
      "[Step 15171] Loss: 9.69e+07 -0.5082971453666687 0.2675110399723053\n",
      "[Step 15172] Loss: 9.53e+07 -0.5086510181427002 0.26743680238723755\n",
      "[Step 15173] Loss: 9.45e+07 -0.5090290307998657 0.26733118295669556\n",
      "[Step 15174] Loss: 9.55e+07 -0.5094465017318726 0.26722803711891174\n",
      "[Step 15175] Loss: 9.48e+07 -0.5097437500953674 0.26716285943984985\n",
      "[Step 15176] Loss: 9.55e+07 -0.5099608302116394 0.2671273648738861\n",
      "[Step 15177] Loss: 9.51e+07 -0.5101062059402466 0.2670687735080719\n",
      "[Step 15178] Loss: 9.58e+07 -0.5102220773696899 0.26704567670822144\n",
      "[Step 15179] Loss: 9.56e+07 -0.5102874040603638 0.26703163981437683\n",
      "[Step 15180] Loss: 9.55e+07 -0.5103504061698914 0.2670547664165497\n",
      "[Step 15181] Loss: 9.53e+07 -0.5103276371955872 0.2670539319515228\n",
      "[Step 15182] Loss: 9.49e+07 -0.5103393197059631 0.2670357823371887\n",
      "[Step 15183] Loss: 9.61e+07 -0.5103256702423096 0.2670407295227051\n",
      "[Step 15184] Loss: 9.53e+07 -0.5104321241378784 0.26698628067970276\n",
      "[Step 15185] Loss: 9.48e+07 -0.5105493068695068 0.2669565677642822\n",
      "[Step 15186] Loss: 9.48e+07 -0.5105869174003601 0.2669590413570404\n",
      "[Step 15187] Loss: 9.45e+07 -0.5105733275413513 0.26697224378585815\n",
      "[Step 15188] Loss: 9.58e+07 -0.5107746124267578 0.26695987582206726\n",
      "[Step 15189] Loss: 9.47e+07 -0.5109438300132751 0.2669243812561035\n",
      "[Step 15190] Loss: 9.46e+07 -0.5110405087471008 0.26692354679107666\n",
      "[Step 15191] Loss: 9.51e+07 -0.5111840963363647 0.2668740451335907\n",
      "[Step 15192] Loss: 9.51e+07 -0.5112960338592529 0.2668410539627075\n",
      "[Step 15193] Loss: 9.51e+07 -0.5114699602127075 0.2667973041534424\n",
      "[Step 15194] Loss: 9.54e+07 -0.5115560293197632 0.2667684257030487\n",
      "[Step 15195] Loss: 9.54e+07 -0.5116739869117737 0.2667255103588104\n",
      "[Step 15196] Loss: 9.59e+07 -0.5119385719299316 0.2667115032672882\n",
      "[Step 15197] Loss: 9.49e+07 -0.5120917558670044 0.26667520403862\n",
      "[Step 15198] Loss: 9.42e+07 -0.5122361779212952 0.26664218306541443\n",
      "[Step 15199] Loss: 9.45e+07 -0.5123162865638733 0.2666083574295044\n",
      "[Step 15200] Loss: 9.50e+07 -0.5123045444488525 0.26661908626556396\n",
      "[Step 15201] Loss: 9.45e+07 -0.5123851895332336 0.2665918469429016\n",
      "[Step 15202] Loss: 9.54e+07 -0.5124269723892212 0.26658111810684204\n",
      "[Step 15203] Loss: 9.44e+07 -0.5125104188919067 0.2665712237358093\n",
      "[Step 15204] Loss: 9.53e+07 -0.5125434994697571 0.26652172207832336\n",
      "[Step 15205] Loss: 9.53e+07 -0.5126262903213501 0.26651841402053833\n",
      "[Step 15206] Loss: 9.52e+07 -0.5126050710678101 0.2665316164493561\n",
      "[Step 15207] Loss: 9.49e+07 -0.5124294757843018 0.26652997732162476\n",
      "[Step 15208] Loss: 9.54e+07 -0.5121934413909912 0.2666017413139343\n",
      "[Step 15209] Loss: 9.49e+07 -0.5119218826293945 0.26667270064353943\n",
      "[Step 15210] Loss: 9.46e+07 -0.5117349624633789 0.26671645045280457\n",
      "[Step 15211] Loss: 9.45e+07 -0.511552095413208 0.2667486369609833\n",
      "[Step 15212] Loss: 9.50e+07 -0.5113598704338074 0.26678577065467834\n",
      "[Step 15213] Loss: 9.49e+07 -0.5110666155815125 0.26683032512664795\n",
      "[Step 15214] Loss: 9.52e+07 -0.5107824802398682 0.26687321066856384\n",
      "[Step 15215] Loss: 9.55e+07 -0.5105671882629395 0.2668988108634949\n",
      "[Step 15216] Loss: 9.55e+07 -0.5105783343315125 0.2668938636779785\n",
      "[Step 15217] Loss: 9.49e+07 -0.5104871392250061 0.2669087052345276\n",
      "[Step 15218] Loss: 9.55e+07 -0.5102383494377136 0.26694995164871216\n",
      "[Step 15219] Loss: 9.45e+07 -0.5100492238998413 0.2669895589351654\n",
      "[Step 15220] Loss: 9.47e+07 -0.5099525451660156 0.267000287771225\n",
      "[Step 15221] Loss: 9.48e+07 -0.5098053812980652 0.2670365869998932\n",
      "[Step 15222] Loss: 9.50e+07 -0.5097395777702332 0.2670704424381256\n",
      "[Step 15223] Loss: 9.51e+07 -0.5098005533218384 0.2670687735080719\n",
      "[Step 15224] Loss: 9.46e+07 -0.5099206566810608 0.2670382559299469\n",
      "[Step 15225] Loss: 9.60e+07 -0.5102545022964478 0.26698213815689087\n",
      "[Step 15226] Loss: 9.54e+07 -0.5104739665985107 0.2669648230075836\n",
      "[Step 15227] Loss: 9.48e+07 -0.5107781887054443 0.2669227421283722\n",
      "[Step 15228] Loss: 9.52e+07 -0.5111067295074463 0.26689139008522034\n",
      "[Step 15229] Loss: 9.41e+07 -0.5113806128501892 0.26684680581092834\n",
      "[Step 15230] Loss: 9.48e+07 -0.5117039680480957 0.2667882442474365\n",
      "[Step 15231] Loss: 9.50e+07 -0.5119338035583496 0.266761839389801\n",
      "[Step 15232] Loss: 9.56e+07 -0.5120728611946106 0.26673623919487\n",
      "[Step 15233] Loss: 9.48e+07 -0.512232780456543 0.26671066880226135\n",
      "[Step 15234] Loss: 9.43e+07 -0.5123767852783203 0.26667022705078125\n",
      "[Step 15235] Loss: 9.52e+07 -0.5124260187149048 0.2666570246219635\n",
      "[Step 15236] Loss: 9.58e+07 -0.5123727321624756 0.2666933536529541\n",
      "[Step 15237] Loss: 9.53e+07 -0.5124173760414124 0.26667270064353943\n",
      "[Step 15238] Loss: 9.51e+07 -0.5124598145484924 0.2666586935520172\n",
      "[Step 15239] Loss: 9.60e+07 -0.5123698711395264 0.26668015122413635\n",
      "[Step 15240] Loss: 9.51e+07 -0.5123414397239685 0.2666958272457123\n",
      "[Step 15241] Loss: 9.44e+07 -0.5123218297958374 0.2667032480239868\n",
      "[Step 15242] Loss: 9.44e+07 -0.5123345851898193 0.266705721616745\n",
      "[Step 15243] Loss: 9.48e+07 -0.5123625993728638 0.26668262481689453\n",
      "[Step 15244] Loss: 9.45e+07 -0.5124817490577698 0.26666611433029175\n",
      "[Step 15245] Loss: 9.52e+07 -0.5126258134841919 0.2666570246219635\n",
      "[Step 15246] Loss: 9.48e+07 -0.512762725353241 0.26662734150886536\n",
      "[Step 15247] Loss: 9.51e+07 -0.5127949714660645 0.26659101247787476\n",
      "[Step 15248] Loss: 9.44e+07 -0.512859046459198 0.266577810049057\n",
      "[Step 15249] Loss: 9.50e+07 -0.5129413604736328 0.2665621340274811\n",
      "[Step 15250] Loss: 9.49e+07 -0.5129445195198059 0.2665456533432007\n",
      "[Step 15251] Loss: 9.52e+07 -0.5130758881568909 0.26654234528541565\n",
      "[Step 15252] Loss: 9.51e+07 -0.5132196545600891 0.2664986252784729\n",
      "[Step 15253] Loss: 9.42e+07 -0.5133783221244812 0.266494482755661\n",
      "[Step 15254] Loss: 9.58e+07 -0.5135814547538757 0.2664928436279297\n",
      "[Step 15255] Loss: 9.49e+07 -0.5138290524482727 0.2664565145969391\n",
      "[Step 15256] Loss: 9.45e+07 -0.5140429735183716 0.26639875769615173\n",
      "[Step 15257] Loss: 9.44e+07 -0.5141957998275757 0.2664053738117218\n",
      "[Step 15258] Loss: 9.54e+07 -0.5142276287078857 0.2664276361465454\n",
      "[Step 15259] Loss: 9.47e+07 -0.51430743932724 0.2664235234260559\n",
      "[Step 15260] Loss: 9.50e+07 -0.5144820809364319 0.26639795303344727\n",
      "[Step 15261] Loss: 9.53e+07 -0.5146495699882507 0.2663748264312744\n",
      "[Step 15262] Loss: 9.59e+07 -0.5146476626396179 0.2663385272026062\n",
      "[Step 15263] Loss: 9.60e+07 -0.514578104019165 0.26636412739753723\n",
      "[Step 15264] Loss: 9.53e+07 -0.5144903063774109 0.2664070129394531\n",
      "[Step 15265] Loss: 9.44e+07 -0.5143794417381287 0.26643508672714233\n",
      "[Step 15266] Loss: 9.49e+07 -0.5142530798912048 0.26645323634147644\n",
      "[Step 15267] Loss: 9.47e+07 -0.5141136646270752 0.26646149158477783\n",
      "[Step 15268] Loss: 9.49e+07 -0.5139566659927368 0.2665052115917206\n",
      "[Step 15269] Loss: 9.55e+07 -0.5139209032058716 0.26651594042778015\n",
      "[Step 15270] Loss: 9.44e+07 -0.513911783695221 0.26654481887817383\n",
      "[Step 15271] Loss: 9.47e+07 -0.5140288472175598 0.2665390372276306\n",
      "[Step 15272] Loss: 9.49e+07 -0.5141581296920776 0.26650604605674744\n",
      "[Step 15273] Loss: 9.54e+07 -0.5143837928771973 0.26647549867630005\n",
      "[Step 15274] Loss: 9.53e+07 -0.5145680904388428 0.2664622962474823\n",
      "[Step 15275] Loss: 9.45e+07 -0.5146656632423401 0.2664400339126587\n",
      "[Step 15276] Loss: 9.53e+07 -0.5147402882575989 0.26642268896102905\n",
      "[Step 15277] Loss: 9.47e+07 -0.5149050354957581 0.2663930058479309\n",
      "[Step 15278] Loss: 9.46e+07 -0.5149893164634705 0.26635998487472534\n",
      "[Step 15279] Loss: 9.42e+07 -0.5150585770606995 0.2663302719593048\n",
      "[Step 15280] Loss: 9.57e+07 -0.5150370001792908 0.26633524894714355\n",
      "[Step 15281] Loss: 9.53e+07 -0.5150315165519714 0.2663261592388153\n",
      "[Step 15282] Loss: 9.50e+07 -0.5150106549263 0.2663104832172394\n",
      "[Step 15283] Loss: 9.49e+07 -0.5149238705635071 0.2663145959377289\n",
      "[Step 15284] Loss: 9.53e+07 -0.5148598551750183 0.2663319408893585\n",
      "[Step 15285] Loss: 9.62e+07 -0.5149701833724976 0.26629313826560974\n",
      "[Step 15286] Loss: 9.48e+07 -0.5151452422142029 0.26624447107315063\n",
      "[Step 15287] Loss: 9.46e+07 -0.5152320265769958 0.2662106454372406\n",
      "[Step 15288] Loss: 9.43e+07 -0.5153433084487915 0.26616525650024414\n",
      "[Step 15289] Loss: 9.48e+07 -0.5154120326042175 0.2661520540714264\n",
      "[Step 15290] Loss: 9.48e+07 -0.5154742002487183 0.2661413252353668\n",
      "[Step 15291] Loss: 9.51e+07 -0.5154797434806824 0.2661355435848236\n",
      "[Step 15292] Loss: 9.50e+07 -0.515615701675415 0.2661198675632477\n",
      "[Step 15293] Loss: 9.51e+07 -0.5156161189079285 0.2661008834838867\n",
      "[Step 15294] Loss: 9.55e+07 -0.5155379176139832 0.2660852074623108\n",
      "[Step 15295] Loss: 9.47e+07 -0.5155023336410522 0.26608192920684814\n",
      "[Step 15296] Loss: 9.56e+07 -0.515442967414856 0.266090989112854\n",
      "[Step 15297] Loss: 9.56e+07 -0.5153127908706665 0.2661108076572418\n",
      "[Step 15298] Loss: 9.44e+07 -0.5152561664581299 0.2661281228065491\n",
      "[Step 15299] Loss: 9.39e+07 -0.5151947140693665 0.2661454379558563\n",
      "[Step 15300] Loss: 9.53e+07 -0.5151858925819397 0.26613306999206543\n",
      "[Step 15301] Loss: 9.44e+07 -0.5152669548988342 0.26614049077033997\n",
      "[Step 15302] Loss: 9.53e+07 -0.5153581500053406 0.2661586403846741\n",
      "[Step 15303] Loss: 9.49e+07 -0.5154140591621399 0.2661883533000946\n",
      "[Step 15304] Loss: 9.53e+07 -0.5154122710227966 0.26621145009994507\n",
      "[Step 15305] Loss: 9.52e+07 -0.5155189037322998 0.26622632145881653\n",
      "[Step 15306] Loss: 9.44e+07 -0.5156770348548889 0.2662271559238434\n",
      "[Step 15307] Loss: 9.53e+07 -0.5159674286842346 0.26620569825172424\n",
      "[Step 15308] Loss: 9.63e+07 -0.5164217948913574 0.2661281228065491\n",
      "[Step 15309] Loss: 9.47e+07 -0.5169212818145752 0.2660563290119171\n",
      "[Step 15310] Loss: 9.58e+07 -0.5173464417457581 0.26598620414733887\n",
      "[Step 15311] Loss: 9.51e+07 -0.5177316665649414 0.26592597365379333\n",
      "[Step 15312] Loss: 9.54e+07 -0.5180927515029907 0.2658517062664032\n",
      "[Step 15313] Loss: 9.50e+07 -0.5183712840080261 0.2658071517944336\n",
      "[Step 15314] Loss: 9.53e+07 -0.5186089277267456 0.26574939489364624\n",
      "[Step 15315] Loss: 9.45e+07 -0.5187879800796509 0.2656973898410797\n",
      "[Step 15316] Loss: 9.49e+07 -0.5188654661178589 0.2656850218772888\n",
      "[Step 15317] Loss: 9.51e+07 -0.5189365744590759 0.26569658517837524\n",
      "[Step 15318] Loss: 9.47e+07 -0.5189980268478394 0.26568007469177246\n",
      "[Step 15319] Loss: 9.53e+07 -0.5190752148628235 0.2657031714916229\n",
      "[Step 15320] Loss: 9.54e+07 -0.5193312168121338 0.26564541459083557\n",
      "[Step 15321] Loss: 9.53e+07 -0.5196241140365601 0.2656016945838928\n",
      "[Step 15322] Loss: 9.54e+07 -0.5197807550430298 0.2655843496322632\n",
      "[Step 15323] Loss: 9.47e+07 -0.5198920965194702 0.2655843496322632\n",
      "[Step 15324] Loss: 9.50e+07 -0.5199480056762695 0.2655884921550751\n",
      "[Step 15325] Loss: 9.54e+07 -0.5200067162513733 0.26556867361068726\n",
      "[Step 15326] Loss: 9.49e+07 -0.5202045440673828 0.2655431032180786\n",
      "[Step 15327] Loss: 9.49e+07 -0.5204217433929443 0.26550596952438354\n",
      "[Step 15328] Loss: 9.60e+07 -0.5205203890800476 0.265498548746109\n",
      "[Step 15329] Loss: 9.56e+07 -0.5207469463348389 0.2654399573802948\n",
      "[Step 15330] Loss: 9.48e+07 -0.5209928154945374 0.26536157727241516\n",
      "[Step 15331] Loss: 9.47e+07 -0.5212178230285645 0.2653203010559082\n",
      "[Step 15332] Loss: 9.51e+07 -0.5213393568992615 0.2652609050273895\n",
      "[Step 15333] Loss: 9.47e+07 -0.5213870406150818 0.2652493417263031\n",
      "[Step 15334] Loss: 9.50e+07 -0.521453320980072 0.26521551609039307\n",
      "[Step 15335] Loss: 9.52e+07 -0.5216889381408691 0.2651717960834503\n",
      "[Step 15336] Loss: 9.51e+07 -0.5218973755836487 0.2651371359825134\n",
      "[Step 15337] Loss: 9.56e+07 -0.522017240524292 0.2651313543319702\n",
      "[Step 15338] Loss: 9.48e+07 -0.5220412611961365 0.2651503384113312\n",
      "[Step 15339] Loss: 9.48e+07 -0.5220080614089966 0.26515281200408936\n",
      "[Step 15340] Loss: 9.56e+07 -0.5219566226005554 0.26516517996788025\n",
      "[Step 15341] Loss: 9.55e+07 -0.5220768451690674 0.265125572681427\n",
      "[Step 15342] Loss: 9.48e+07 -0.5221042037010193 0.2651098966598511\n",
      "[Step 15343] Loss: 9.58e+07 -0.5222977995872498 0.265072762966156\n",
      "[Step 15344] Loss: 9.60e+07 -0.5226306319236755 0.265011727809906\n",
      "[Step 15345] Loss: 9.54e+07 -0.5228441953659058 0.2649489939212799\n",
      "[Step 15346] Loss: 9.47e+07 -0.5230138897895813 0.2649225890636444\n",
      "[Step 15347] Loss: 9.48e+07 -0.5232563018798828 0.2648681402206421\n",
      "[Step 15348] Loss: 9.53e+07 -0.5235865116119385 0.2647930383682251\n",
      "[Step 15349] Loss: 9.50e+07 -0.5238875150680542 0.26473942399024963\n",
      "[Step 15350] Loss: 9.58e+07 -0.524066150188446 0.26467835903167725\n",
      "[Step 15351] Loss: 9.52e+07 -0.5242698788642883 0.26465773582458496\n",
      "[Step 15352] Loss: 9.51e+07 -0.5244166254997253 0.26462307572364807\n",
      "[Step 15353] Loss: 9.44e+07 -0.5245401859283447 0.26460739970207214\n",
      "[Step 15354] Loss: 9.46e+07 -0.524626612663269 0.26459088921546936\n",
      "[Step 15355] Loss: 9.49e+07 -0.5246862173080444 0.26456695795059204\n",
      "[Step 15356] Loss: 9.55e+07 -0.5246894359588623 0.26459088921546936\n",
      "[Step 15357] Loss: 9.47e+07 -0.5247569680213928 0.2645999789237976\n",
      "[Step 15358] Loss: 9.52e+07 -0.5246751308441162 0.2645966708660126\n",
      "[Step 15359] Loss: 9.52e+07 -0.5246334075927734 0.2646007835865021\n",
      "[Step 15360] Loss: 9.64e+07 -0.5248185396194458 0.26458263397216797\n",
      "[Step 15361] Loss: 9.45e+07 -0.5250454545021057 0.26450425386428833\n",
      "[Step 15362] Loss: 9.54e+07 -0.5251273512840271 0.2645215690135956\n",
      "[Step 15363] Loss: 9.52e+07 -0.5251877307891846 0.26453807950019836\n",
      "[Step 15364] Loss: 9.52e+07 -0.5253140330314636 0.26451003551483154\n",
      "[Step 15365] Loss: 9.55e+07 -0.525434672832489 0.2644762098789215\n",
      "[Step 15366] Loss: 9.45e+07 -0.5255761742591858 0.2644786834716797\n",
      "[Step 15367] Loss: 9.60e+07 -0.5256557464599609 0.264468789100647\n",
      "[Step 15368] Loss: 9.56e+07 -0.5258402824401855 0.26446712017059326\n",
      "[Step 15369] Loss: 9.53e+07 -0.5260711312294006 0.26442751288414\n",
      "[Step 15370] Loss: 9.49e+07 -0.5263809561729431 0.2643491327762604\n",
      "[Step 15371] Loss: 9.51e+07 -0.5267232656478882 0.264288067817688\n",
      "[Step 15372] Loss: 9.62e+07 -0.5272253751754761 0.2641535699367523\n",
      "[Step 15373] Loss: 9.50e+07 -0.5277504920959473 0.2640562057495117\n",
      "[Step 15374] Loss: 9.51e+07 -0.5282178521156311 0.2639514207839966\n",
      "[Step 15375] Loss: 9.46e+07 -0.5285905599594116 0.26387301087379456\n",
      "[Step 15376] Loss: 9.49e+07 -0.5288777351379395 0.2638070285320282\n",
      "[Step 15377] Loss: 9.56e+07 -0.5290679335594177 0.26375338435173035\n",
      "[Step 15378] Loss: 9.50e+07 -0.5291140079498291 0.26375338435173035\n",
      "[Step 15379] Loss: 9.50e+07 -0.5290824770927429 0.26376327872276306\n",
      "[Step 15380] Loss: 9.48e+07 -0.5290740728378296 0.26375749707221985\n",
      "[Step 15381] Loss: 9.45e+07 -0.5291256904602051 0.2637195587158203\n",
      "[Step 15382] Loss: 9.51e+07 -0.5291598439216614 0.26368820667266846\n",
      "[Step 15383] Loss: 9.47e+07 -0.5291648507118225 0.2636708617210388\n",
      "[Step 15384] Loss: 9.46e+07 -0.5291008949279785 0.2636832296848297\n",
      "[Step 15385] Loss: 9.49e+07 -0.5291222333908081 0.2636832296848297\n",
      "[Step 15386] Loss: 9.50e+07 -0.5290489792823792 0.2636568248271942\n",
      "[Step 15387] Loss: 9.54e+07 -0.5290055274963379 0.26366013288497925\n",
      "[Step 15388] Loss: 9.48e+07 -0.5290683507919312 0.2636584937572479\n",
      "[Step 15389] Loss: 9.67e+07 -0.5293635129928589 0.2635883390903473\n",
      "[Step 15390] Loss: 9.46e+07 -0.5296335220336914 0.26353719830513\n",
      "[Step 15391] Loss: 9.49e+07 -0.5299639701843262 0.26345881819725037\n",
      "[Step 15392] Loss: 9.44e+07 -0.5302467346191406 0.2633993923664093\n",
      "[Step 15393] Loss: 9.45e+07 -0.5304731130599976 0.2633630931377411\n",
      "[Step 15394] Loss: 9.42e+07 -0.5306423306465149 0.26330533623695374\n",
      "[Step 15395] Loss: 9.52e+07 -0.5307109355926514 0.263295441865921\n",
      "[Step 15396] Loss: 9.47e+07 -0.5307300686836243 0.2632838785648346\n",
      "[Step 15397] Loss: 9.57e+07 -0.5307728052139282 0.26329296827316284\n",
      "[Step 15398] Loss: 9.53e+07 -0.5309085249900818 0.26327893137931824\n",
      "[Step 15399] Loss: 9.65e+07 -0.5312486886978149 0.26323601603507996\n",
      "[Step 15400] Loss: 9.46e+07 -0.5315335392951965 0.2631964087486267\n",
      "[Step 15401] Loss: 9.52e+07 -0.5317621231079102 0.2631460726261139\n",
      "[Step 15402] Loss: 9.44e+07 -0.5319767594337463 0.2630685269832611\n",
      "[Step 15403] Loss: 9.53e+07 -0.5320842862129211 0.2630544900894165\n",
      "[Step 15404] Loss: 9.42e+07 -0.5321506857872009 0.2630487084388733\n",
      "[Step 15405] Loss: 9.46e+07 -0.5322679281234741 0.26301899552345276\n",
      "[Step 15406] Loss: 9.53e+07 -0.5324374437332153 0.2629554867744446\n",
      "[Step 15407] Loss: 9.51e+07 -0.5326015949249268 0.2629125714302063\n",
      "[Step 15408] Loss: 9.43e+07 -0.5327878594398499 0.2628820240497589\n",
      "[Step 15409] Loss: 9.52e+07 -0.5330766439437866 0.2628292143344879\n",
      "[Step 15410] Loss: 9.46e+07 -0.5333662033081055 0.262764036655426\n",
      "[Step 15411] Loss: 9.45e+07 -0.5335568189620972 0.2627483606338501\n",
      "[Step 15412] Loss: 9.47e+07 -0.5336943864822388 0.26270627975463867\n",
      "[Step 15413] Loss: 9.43e+07 -0.5338140726089478 0.26269638538360596\n",
      "[Step 15414] Loss: 9.49e+07 -0.5338147282600403 0.2627013325691223\n",
      "[Step 15415] Loss: 9.44e+07 -0.5337794423103333 0.2626939117908478\n",
      "[Step 15416] Loss: 9.48e+07 -0.533776044845581 0.26269471645355225\n",
      "[Step 15417] Loss: 9.53e+07 -0.5339082479476929 0.2626790404319763\n",
      "[Step 15418] Loss: 9.39e+07 -0.534065842628479 0.262677401304245\n",
      "[Step 15419] Loss: 9.43e+07 -0.5342562794685364 0.26267409324645996\n",
      "[Step 15420] Loss: 9.43e+07 -0.5344527363777161 0.26266419887542725\n",
      "[Step 15421] Loss: 9.47e+07 -0.5346434116363525 0.262624591588974\n",
      "[Step 15422] Loss: 9.51e+07 -0.5348619222640991 0.26258912682533264\n",
      "[Step 15423] Loss: 9.51e+07 -0.5350394248962402 0.26255694031715393\n",
      "[Step 15424] Loss: 9.53e+07 -0.5353420376777649 0.26249751448631287\n",
      "[Step 15425] Loss: 9.52e+07 -0.5356748700141907 0.26243069767951965\n",
      "[Step 15426] Loss: 9.54e+07 -0.5360866189002991 0.2623349726200104\n",
      "[Step 15427] Loss: 9.46e+07 -0.5365158915519714 0.26224008202552795\n",
      "[Step 15428] Loss: 9.52e+07 -0.5367783308029175 0.2621600329875946\n",
      "[Step 15429] Loss: 9.51e+07 -0.5371944904327393 0.2620643377304077\n",
      "[Step 15430] Loss: 9.46e+07 -0.5375490188598633 0.2619941830635071\n",
      "[Step 15431] Loss: 9.51e+07 -0.5377683043479919 0.2619388997554779\n",
      "[Step 15432] Loss: 9.48e+07 -0.5380297303199768 0.2618918716907501\n",
      "[Step 15433] Loss: 9.56e+07 -0.5381033420562744 0.26185888051986694\n",
      "[Step 15434] Loss: 9.40e+07 -0.538207471370697 0.26181676983833313\n",
      "[Step 15435] Loss: 9.45e+07 -0.538309633731842 0.26177552342414856\n",
      "[Step 15436] Loss: 9.46e+07 -0.5384021401405334 0.26175326108932495\n",
      "[Step 15437] Loss: 9.43e+07 -0.5385384559631348 0.26169219613075256\n",
      "[Step 15438] Loss: 9.55e+07 -0.5387977957725525 0.2616608440876007\n",
      "[Step 15439] Loss: 9.45e+07 -0.5390254855155945 0.26161956787109375\n",
      "[Step 15440] Loss: 9.54e+07 -0.5392113327980042 0.2615733742713928\n",
      "[Step 15441] Loss: 9.52e+07 -0.5395711660385132 0.26146113872528076\n",
      "[Step 15442] Loss: 9.55e+07 -0.5399368405342102 0.2614058554172516\n",
      "[Step 15443] Loss: 9.46e+07 -0.5402395725250244 0.2613728642463684\n",
      "[Step 15444] Loss: 9.53e+07 -0.5406211018562317 0.2613126337528229\n",
      "[Step 15445] Loss: 9.55e+07 -0.5410890579223633 0.2612449526786804\n",
      "[Step 15446] Loss: 9.50e+07 -0.541549801826477 0.2611542046070099\n",
      "[Step 15447] Loss: 9.54e+07 -0.5418365001678467 0.2610791027545929\n",
      "[Step 15448] Loss: 9.54e+07 -0.5422132015228271 0.2610023617744446\n",
      "[Step 15449] Loss: 9.52e+07 -0.5425951480865479 0.26089346408843994\n",
      "[Step 15450] Loss: 9.54e+07 -0.542975664138794 0.26082003116607666\n",
      "[Step 15451] Loss: 9.45e+07 -0.5433236360549927 0.2607399821281433\n",
      "[Step 15452] Loss: 9.55e+07 -0.5437074899673462 0.2606426179409027\n",
      "[Step 15453] Loss: 9.51e+07 -0.5440542697906494 0.26056671142578125\n",
      "[Step 15454] Loss: 9.44e+07 -0.5444071888923645 0.2604602575302124\n",
      "[Step 15455] Loss: 9.48e+07 -0.5447336435317993 0.2603950798511505\n",
      "[Step 15456] Loss: 9.57e+07 -0.5450237989425659 0.26032739877700806\n",
      "[Step 15457] Loss: 9.44e+07 -0.5452374815940857 0.2602778971195221\n",
      "[Step 15458] Loss: 9.47e+07 -0.5455026626586914 0.26019540429115295\n",
      "[Step 15459] Loss: 9.50e+07 -0.5458505749702454 0.26008400321006775\n",
      "[Step 15460] Loss: 9.46e+07 -0.5462268590927124 0.2599940598011017\n",
      "[Step 15461] Loss: 9.59e+07 -0.5463958978652954 0.25997260212898254\n",
      "[Step 15462] Loss: 9.56e+07 -0.5466742515563965 0.2599082291126251\n",
      "[Step 15463] Loss: 9.46e+07 -0.5469597578048706 0.25982901453971863\n",
      "[Step 15464] Loss: 9.50e+07 -0.5472229719161987 0.25979354977607727\n",
      "[Step 15465] Loss: 9.51e+07 -0.5475053191184998 0.2597366273403168\n",
      "[Step 15466] Loss: 9.48e+07 -0.5477941632270813 0.25965988636016846\n",
      "[Step 15467] Loss: 9.45e+07 -0.5481570959091187 0.25957900285720825\n",
      "[Step 15468] Loss: 9.57e+07 -0.548363208770752 0.2595460116863251\n",
      "[Step 15469] Loss: 9.49e+07 -0.5484694242477417 0.2595369219779968\n",
      "[Step 15470] Loss: 9.62e+07 -0.5487645864486694 0.25949567556381226\n",
      "[Step 15471] Loss: 9.43e+07 -0.5490322113037109 0.25943297147750854\n",
      "[Step 15472] Loss: 9.50e+07 -0.54921954870224 0.2594115138053894\n",
      "[Step 15473] Loss: 9.45e+07 -0.5493022203445435 0.25939005613327026\n",
      "[Step 15474] Loss: 9.51e+07 -0.5493658185005188 0.25938180088996887\n",
      "[Step 15475] Loss: 9.47e+07 -0.549340009689331 0.25938427448272705\n",
      "[Step 15476] Loss: 9.45e+07 -0.5493884682655334 0.2593834698200226\n",
      "[Step 15477] Loss: 9.39e+07 -0.5494480729103088 0.2593553960323334\n",
      "[Step 15478] Loss: 9.46e+07 -0.5494664311408997 0.2593388855457306\n",
      "[Step 15479] Loss: 9.46e+07 -0.5494804382324219 0.2593347728252411\n",
      "[Step 15480] Loss: 9.47e+07 -0.5495360493659973 0.25931495428085327\n",
      "[Step 15481] Loss: 9.47e+07 -0.5496623516082764 0.2592860758304596\n",
      "[Step 15482] Loss: 9.59e+07 -0.5498901605606079 0.25922173261642456\n",
      "[Step 15483] Loss: 9.45e+07 -0.5499606132507324 0.2591928541660309\n",
      "[Step 15484] Loss: 9.49e+07 -0.5500038266181946 0.2591383755207062\n",
      "[Step 15485] Loss: 9.51e+07 -0.5501154661178589 0.2591094970703125\n",
      "[Step 15486] Loss: 9.60e+07 -0.5503503084182739 0.25905999541282654\n",
      "[Step 15487] Loss: 9.42e+07 -0.5504599809646606 0.2590146064758301\n",
      "[Step 15488] Loss: 9.47e+07 -0.5505688190460205 0.258999764919281\n",
      "[Step 15489] Loss: 9.45e+07 -0.5507007241249084 0.2589799761772156\n",
      "[Step 15490] Loss: 9.47e+07 -0.5506922602653503 0.2590055465698242\n",
      "[Step 15491] Loss: 9.51e+07 -0.5507185459136963 0.25898244976997375\n",
      "[Step 15492] Loss: 9.48e+07 -0.5507236123085022 0.2589873969554901\n",
      "[Step 15493] Loss: 9.52e+07 -0.5506709218025208 0.25896263122558594\n",
      "[Step 15494] Loss: 9.49e+07 -0.5506764054298401 0.25895190238952637\n",
      "[Step 15495] Loss: 9.56e+07 -0.550576388835907 0.25896263122558594\n",
      "[Step 15496] Loss: 9.47e+07 -0.5504443049430847 0.2589700520038605\n",
      "[Step 15497] Loss: 9.52e+07 -0.5503156185150146 0.25897830724716187\n",
      "[Step 15498] Loss: 9.51e+07 -0.5501638054847717 0.25897830724716187\n",
      "[Step 15499] Loss: 9.45e+07 -0.5500252842903137 0.2590121328830719\n",
      "[Step 15500] Loss: 9.48e+07 -0.549974799156189 0.2590195834636688\n",
      "[Step 15501] Loss: 9.44e+07 -0.5499466061592102 0.25900140404701233\n",
      "[Step 15502] Loss: 9.53e+07 -0.5498037934303284 0.25901874899864197\n",
      "[Step 15503] Loss: 9.50e+07 -0.5496784448623657 0.2590344250202179\n",
      "[Step 15504] Loss: 9.49e+07 -0.5496758818626404 0.2590509355068207\n",
      "[Step 15505] Loss: 9.51e+07 -0.549630343914032 0.2590666115283966\n",
      "[Step 15506] Loss: 9.46e+07 -0.5495978593826294 0.25906988978385925\n",
      "[Step 15507] Loss: 9.50e+07 -0.549472451210022 0.25906166434288025\n",
      "[Step 15508] Loss: 9.46e+07 -0.5493132472038269 0.25908640027046204\n",
      "[Step 15509] Loss: 9.41e+07 -0.5491246581077576 0.25908640027046204\n",
      "[Step 15510] Loss: 9.58e+07 -0.5490586757659912 0.25907403230667114\n",
      "[Step 15511] Loss: 9.56e+07 -0.549124002456665 0.2590261697769165\n",
      "[Step 15512] Loss: 9.49e+07 -0.5492956638336182 0.2589717209339142\n",
      "[Step 15513] Loss: 9.52e+07 -0.5494383573532104 0.25891560316085815\n",
      "[Step 15514] Loss: 9.59e+07 -0.5495089292526245 0.25890403985977173\n",
      "[Step 15515] Loss: 9.54e+07 -0.5496940016746521 0.258894145488739\n",
      "[Step 15516] Loss: 9.50e+07 -0.5498420596122742 0.25884711742401123\n",
      "[Step 15517] Loss: 9.50e+07 -0.5499027967453003 0.2588438093662262\n",
      "[Step 15518] Loss: 9.48e+07 -0.5499944090843201 0.2588339149951935\n",
      "[Step 15519] Loss: 9.54e+07 -0.5501003265380859 0.25879761576652527\n",
      "[Step 15520] Loss: 9.43e+07 -0.5501363277435303 0.2587811052799225\n",
      "[Step 15521] Loss: 9.50e+07 -0.5501872897148132 0.25879183411598206\n",
      "[Step 15522] Loss: 9.47e+07 -0.5502277612686157 0.2587621212005615\n",
      "[Step 15523] Loss: 9.48e+07 -0.5502699017524719 0.25873076915740967\n",
      "[Step 15524] Loss: 9.58e+07 -0.5502491593360901 0.2587134540081024\n",
      "[Step 15525] Loss: 9.56e+07 -0.5500768423080444 0.2587464451789856\n",
      "[Step 15526] Loss: 9.48e+07 -0.5499126315116882 0.2587703764438629\n",
      "[Step 15527] Loss: 9.54e+07 -0.5497391819953918 0.2588050365447998\n",
      "[Step 15528] Loss: 9.52e+07 -0.5496164560317993 0.25882649421691895\n",
      "[Step 15529] Loss: 9.43e+07 -0.5495404005050659 0.25881659984588623\n",
      "[Step 15530] Loss: 9.58e+07 -0.5494216680526733 0.25880998373031616\n",
      "[Step 15531] Loss: 9.57e+07 -0.5491775274276733 0.25884050130844116\n",
      "[Step 15532] Loss: 9.54e+07 -0.548889696598053 0.2588817775249481\n",
      "[Step 15533] Loss: 9.54e+07 -0.5485462546348572 0.2589304447174072\n",
      "[Step 15534] Loss: 9.69e+07 -0.5485472083091736 0.2589122951030731\n",
      "[Step 15535] Loss: 9.54e+07 -0.5484557747840881 0.2589353919029236\n",
      "[Step 15536] Loss: 9.55e+07 -0.5485209226608276 0.2589527368545532\n",
      "[Step 15537] Loss: 9.49e+07 -0.5484753251075745 0.2589535713195801\n",
      "[Step 15538] Loss: 9.45e+07 -0.5484291315078735 0.25895604491233826\n",
      "[Step 15539] Loss: 9.49e+07 -0.5485031008720398 0.2589263319969177\n",
      "[Step 15540] Loss: 9.46e+07 -0.5486129522323608 0.25889497995376587\n",
      "[Step 15541] Loss: 9.44e+07 -0.5487201809883118 0.2588619589805603\n",
      "[Step 15542] Loss: 9.54e+07 -0.5487562417984009 0.2588372230529785\n",
      "[Step 15543] Loss: 9.48e+07 -0.5488042831420898 0.25882071256637573\n",
      "[Step 15544] Loss: 9.45e+07 -0.5488420128822327 0.2588174045085907\n",
      "[Step 15545] Loss: 9.70e+07 -0.5486432909965515 0.2588578462600708\n",
      "[Step 15546] Loss: 9.55e+07 -0.5482879281044006 0.2589304447174072\n",
      "[Step 15547] Loss: 9.51e+07 -0.5479881763458252 0.2589873969554901\n",
      "[Step 15548] Loss: 9.71e+07 -0.5480658411979675 0.25896430015563965\n",
      "[Step 15549] Loss: 9.54e+07 -0.5482528805732727 0.25892218947410583\n",
      "[Step 15550] Loss: 9.49e+07 -0.5484036803245544 0.25886690616607666\n",
      "[Step 15551] Loss: 9.51e+07 -0.548507034778595 0.2588396966457367\n",
      "[Step 15552] Loss: 9.51e+07 -0.5485612750053406 0.25879842042922974\n",
      "[Step 15553] Loss: 9.53e+07 -0.5486190319061279 0.2587588131427765\n",
      "[Step 15554] Loss: 9.45e+07 -0.5486995577812195 0.25875386595726013\n",
      "[Step 15555] Loss: 9.47e+07 -0.5488013625144958 0.2587439715862274\n",
      "[Step 15556] Loss: 9.51e+07 -0.5488786101341248 0.2587282955646515\n",
      "[Step 15557] Loss: 9.48e+07 -0.5488998889923096 0.25871673226356506\n",
      "[Step 15558] Loss: 9.45e+07 -0.5488426089286804 0.2587282955646515\n",
      "[Step 15559] Loss: 9.46e+07 -0.5487841367721558 0.2587398588657379\n",
      "[Step 15560] Loss: 9.59e+07 -0.5489208102226257 0.258735716342926\n",
      "[Step 15561] Loss: 9.43e+07 -0.5490593314170837 0.25870850682258606\n",
      "[Step 15562] Loss: 9.47e+07 -0.5491112470626831 0.25868210196495056\n",
      "[Step 15563] Loss: 9.61e+07 -0.549374520778656 0.25861361622810364\n",
      "[Step 15564] Loss: 9.50e+07 -0.5497004985809326 0.25852036476135254\n",
      "[Step 15565] Loss: 9.48e+07 -0.5499876141548157 0.2584477365016937\n",
      "[Step 15566] Loss: 9.53e+07 -0.5503986477851868 0.2583875060081482\n",
      "[Step 15567] Loss: 9.45e+07 -0.5507771968841553 0.25831159949302673\n",
      "[Step 15568] Loss: 9.57e+07 -0.5512683391571045 0.2582109272480011\n",
      "[Step 15569] Loss: 9.51e+07 -0.5517265796661377 0.25810614228248596\n",
      "[Step 15570] Loss: 9.57e+07 -0.5521763563156128 0.25799888372421265\n",
      "[Step 15571] Loss: 9.50e+07 -0.5526086688041687 0.2579039931297302\n",
      "[Step 15572] Loss: 9.48e+07 -0.5528941750526428 0.2578676640987396\n",
      "[Step 15573] Loss: 9.41e+07 -0.5532184839248657 0.25780001282691956\n",
      "[Step 15574] Loss: 9.47e+07 -0.5535539388656616 0.2576952278614044\n",
      "[Step 15575] Loss: 9.47e+07 -0.5538683533668518 0.2576391100883484\n",
      "[Step 15576] Loss: 9.49e+07 -0.5540828704833984 0.2576085925102234\n",
      "[Step 15577] Loss: 9.47e+07 -0.5542277693748474 0.2575797140598297\n",
      "[Step 15578] Loss: 9.48e+07 -0.5543050169944763 0.25756072998046875\n",
      "[Step 15579] Loss: 9.56e+07 -0.5544964075088501 0.25752195715904236\n",
      "[Step 15580] Loss: 9.44e+07 -0.5546702146530151 0.25746089220046997\n",
      "[Step 15581] Loss: 9.52e+07 -0.554863452911377 0.25740066170692444\n",
      "[Step 15582] Loss: 9.51e+07 -0.555138885974884 0.25731730461120605\n",
      "[Step 15583] Loss: 9.48e+07 -0.5553339719772339 0.25727853178977966\n",
      "[Step 15584] Loss: 9.58e+07 -0.5553988814353943 0.25723975896835327\n",
      "[Step 15585] Loss: 9.44e+07 -0.5553785562515259 0.2572290301322937\n",
      "[Step 15586] Loss: 9.65e+07 -0.555597186088562 0.2571869492530823\n",
      "[Step 15587] Loss: 9.59e+07 -0.5557143688201904 0.25714072585105896\n",
      "[Step 15588] Loss: 9.49e+07 -0.5558213591575623 0.2571456730365753\n",
      "[Step 15589] Loss: 9.43e+07 -0.55592280626297 0.25711846351623535\n",
      "[Step 15590] Loss: 9.50e+07 -0.5559640526771545 0.2570953369140625\n",
      "[Step 15591] Loss: 9.50e+07 -0.5559897422790527 0.2570854425430298\n",
      "[Step 15592] Loss: 9.50e+07 -0.5561080574989319 0.2570466697216034\n",
      "[Step 15593] Loss: 9.60e+07 -0.5561045408248901 0.25703924894332886\n",
      "[Step 15594] Loss: 9.61e+07 -0.5560323596000671 0.25706565380096436\n",
      "[Step 15595] Loss: 9.49e+07 -0.5559386610984802 0.25708213448524475\n",
      "[Step 15596] Loss: 9.44e+07 -0.5558502078056335 0.2571011185646057\n",
      "[Step 15597] Loss: 9.44e+07 -0.5557408332824707 0.257144033908844\n",
      "[Step 15598] Loss: 9.42e+07 -0.555630087852478 0.25716713070869446\n",
      "[Step 15599] Loss: 9.50e+07 -0.5556344389915466 0.2571679651737213\n",
      "[Step 15600] Loss: 9.46e+07 -0.5556149482727051 0.257174551486969\n",
      "[Step 15601] Loss: 9.52e+07 -0.555621862411499 0.25718775391578674\n",
      "[Step 15602] Loss: 9.51e+07 -0.5556962490081787 0.25717127323150635\n",
      "[Step 15603] Loss: 9.48e+07 -0.5558310151100159 0.2571382522583008\n",
      "[Step 15604] Loss: 9.44e+07 -0.5558844804763794 0.2571192681789398\n",
      "[Step 15605] Loss: 9.39e+07 -0.5558569431304932 0.2571382522583008\n",
      "[Step 15606] Loss: 9.49e+07 -0.555809497833252 0.25713494420051575\n",
      "[Step 15607] Loss: 9.52e+07 -0.555866003036499 0.25715312361717224\n",
      "[Step 15608] Loss: 9.59e+07 -0.5558287501335144 0.25716879963874817\n",
      "[Step 15609] Loss: 9.52e+07 -0.5558526515960693 0.2571357786655426\n",
      "[Step 15610] Loss: 9.49e+07 -0.5559325218200684 0.2571118474006653\n",
      "[Step 15611] Loss: 9.51e+07 -0.5560641288757324 0.2571093738079071\n",
      "[Step 15612] Loss: 9.47e+07 -0.5562341213226318 0.2570623457431793\n",
      "[Step 15613] Loss: 9.44e+07 -0.5563507676124573 0.2570186257362366\n",
      "[Step 15614] Loss: 9.47e+07 -0.5565146803855896 0.2569922208786011\n",
      "[Step 15615] Loss: 9.55e+07 -0.5566971898078918 0.25698477029800415\n",
      "[Step 15616] Loss: 9.55e+07 -0.5569618344306946 0.25693279504776\n",
      "[Step 15617] Loss: 9.51e+07 -0.5572176575660706 0.25686925649642944\n",
      "[Step 15618] Loss: 9.52e+07 -0.5573557615280151 0.2568255364894867\n",
      "[Step 15619] Loss: 9.51e+07 -0.557502269744873 0.25678178668022156\n",
      "[Step 15620] Loss: 9.46e+07 -0.5575929880142212 0.25675538182258606\n",
      "[Step 15621] Loss: 9.49e+07 -0.5575603246688843 0.2567479610443115\n",
      "[Step 15622] Loss: 9.52e+07 -0.5576227903366089 0.2567347586154938\n",
      "[Step 15623] Loss: 9.47e+07 -0.5575338006019592 0.2567364275455475\n",
      "[Step 15624] Loss: 9.45e+07 -0.5574953556060791 0.2567322850227356\n",
      "[Step 15625] Loss: 9.47e+07 -0.5574483275413513 0.25675374269485474\n",
      "[Step 15626] Loss: 9.51e+07 -0.5572821497917175 0.25676941871643066\n",
      "[Step 15627] Loss: 9.49e+07 -0.5572267770767212 0.2567421793937683\n",
      "[Step 15628] Loss: 9.46e+07 -0.5571742653846741 0.2567380666732788\n",
      "[Step 15629] Loss: 9.51e+07 -0.557134211063385 0.25672486424446106\n",
      "[Step 15630] Loss: 9.47e+07 -0.5571829676628113 0.2566992938518524\n",
      "[Step 15631] Loss: 9.51e+07 -0.5573204159736633 0.25666379928588867\n",
      "[Step 15632] Loss: 9.44e+07 -0.5574446320533752 0.25662586092948914\n",
      "[Step 15633] Loss: 9.54e+07 -0.5574496388435364 0.25662335753440857\n",
      "[Step 15634] Loss: 9.42e+07 -0.5575255155563354 0.25658705830574036\n",
      "[Step 15635] Loss: 9.50e+07 -0.5575705170631409 0.256529301404953\n",
      "[Step 15636] Loss: 9.46e+07 -0.5575587153434753 0.2565194070339203\n",
      "[Step 15637] Loss: 9.48e+07 -0.557466983795166 0.2565136253833771\n",
      "[Step 15638] Loss: 9.52e+07 -0.5574467778205872 0.25651609897613525\n",
      "[Step 15639] Loss: 9.61e+07 -0.5573093891143799 0.2564863860607147\n",
      "[Step 15640] Loss: 9.54e+07 -0.5571309328079224 0.25649136304855347\n",
      "[Step 15641] Loss: 9.44e+07 -0.5569654703140259 0.2565012574195862\n",
      "[Step 15642] Loss: 9.64e+07 -0.5570313930511475 0.2564822733402252\n",
      "[Step 15643] Loss: 9.45e+07 -0.5570650696754456 0.2564344108104706\n",
      "[Step 15644] Loss: 9.49e+07 -0.5569953918457031 0.2564484477043152\n",
      "[Step 15645] Loss: 9.48e+07 -0.5569019317626953 0.25644350051879883\n",
      "[Step 15646] Loss: 9.52e+07 -0.5569305419921875 0.2564253509044647\n",
      "[Step 15647] Loss: 9.58e+07 -0.5568828582763672 0.2564038932323456\n",
      "[Step 15648] Loss: 9.50e+07 -0.5568354725837708 0.2564014196395874\n",
      "[Step 15649] Loss: 9.52e+07 -0.5567112565040588 0.2564278244972229\n",
      "[Step 15650] Loss: 9.64e+07 -0.5565670132637024 0.2564418315887451\n",
      "[Step 15651] Loss: 9.49e+07 -0.5564930438995361 0.2564484477043152\n",
      "[Step 15652] Loss: 9.47e+07 -0.5564776062965393 0.2564319372177124\n",
      "[Step 15653] Loss: 9.63e+07 -0.5565977096557617 0.2563816010951996\n",
      "[Step 15654] Loss: 9.44e+07 -0.5567330121994019 0.2563428282737732\n",
      "[Step 15655] Loss: 9.49e+07 -0.5569738745689392 0.2562776505947113\n",
      "[Step 15656] Loss: 9.62e+07 -0.557282030582428 0.25618523359298706\n",
      "[Step 15657] Loss: 9.55e+07 -0.5576909184455872 0.2561118006706238\n",
      "[Step 15658] Loss: 9.51e+07 -0.5580928921699524 0.25604164600372314\n",
      "[Step 15659] Loss: 9.59e+07 -0.5586210489273071 0.25592944025993347\n",
      "[Step 15660] Loss: 9.52e+07 -0.5592535734176636 0.25581640005111694\n",
      "[Step 15661] Loss: 9.44e+07 -0.5598311424255371 0.255695104598999\n",
      "[Step 15662] Loss: 9.48e+07 -0.5604218244552612 0.25555482506752014\n",
      "[Step 15663] Loss: 9.47e+07 -0.5609725713729858 0.2554335296154022\n",
      "[Step 15664] Loss: 9.59e+07 -0.5616400241851807 0.2552957236766815\n",
      "[Step 15665] Loss: 9.50e+07 -0.5623670816421509 0.25511831045150757\n",
      "[Step 15666] Loss: 9.44e+07 -0.5629853010177612 0.2549739181995392\n",
      "[Step 15667] Loss: 9.50e+07 -0.5634922981262207 0.2548410892486572\n",
      "[Step 15668] Loss: 9.43e+07 -0.5639439225196838 0.25473710894584656\n",
      "[Step 15669] Loss: 9.43e+07 -0.5643367767333984 0.2546628415584564\n",
      "[Step 15670] Loss: 9.45e+07 -0.5646916627883911 0.2546042501926422\n",
      "[Step 15671] Loss: 9.49e+07 -0.5649749636650085 0.25453001260757446\n",
      "[Step 15672] Loss: 9.48e+07 -0.5653494000434875 0.25442934036254883\n",
      "[Step 15673] Loss: 9.52e+07 -0.5657693147659302 0.2543369233608246\n",
      "[Step 15674] Loss: 9.56e+07 -0.5661452412605286 0.2542378902435303\n",
      "[Step 15675] Loss: 9.47e+07 -0.5664958357810974 0.2541768550872803\n",
      "[Step 15676] Loss: 9.44e+07 -0.5668085813522339 0.2540968060493469\n",
      "[Step 15677] Loss: 9.45e+07 -0.567099928855896 0.25403985381126404\n",
      "[Step 15678] Loss: 9.46e+07 -0.5673608779907227 0.25395074486732483\n",
      "[Step 15679] Loss: 9.52e+07 -0.5676308274269104 0.25388720631599426\n",
      "[Step 15680] Loss: 9.49e+07 -0.5679759979248047 0.2538096606731415\n",
      "[Step 15681] Loss: 9.41e+07 -0.5681498050689697 0.25377005338668823\n",
      "[Step 15682] Loss: 9.44e+07 -0.5683635473251343 0.25370651483535767\n",
      "[Step 15683] Loss: 9.48e+07 -0.5685046315193176 0.2536751627922058\n",
      "[Step 15684] Loss: 9.53e+07 -0.5686382055282593 0.253624826669693\n",
      "[Step 15685] Loss: 9.50e+07 -0.568892240524292 0.25357696413993835\n",
      "[Step 15686] Loss: 9.50e+07 -0.5690207481384277 0.2535579800605774\n",
      "[Step 15687] Loss: 9.48e+07 -0.5691072940826416 0.25355055928230286\n",
      "[Step 15688] Loss: 9.45e+07 -0.5691266655921936 0.2535431385040283\n",
      "[Step 15689] Loss: 9.53e+07 -0.5691096782684326 0.2535134255886078\n",
      "[Step 15690] Loss: 9.49e+07 -0.569246232509613 0.2534762918949127\n",
      "[Step 15691] Loss: 9.42e+07 -0.5693894624710083 0.25345566868782043\n",
      "[Step 15692] Loss: 9.48e+07 -0.5695638656616211 0.2534300982952118\n",
      "[Step 15693] Loss: 9.43e+07 -0.5696979761123657 0.2533789277076721\n",
      "[Step 15694] Loss: 9.57e+07 -0.5697702169418335 0.2533731460571289\n",
      "[Step 15695] Loss: 9.55e+07 -0.5697206258773804 0.2533979117870331\n",
      "[Step 15696] Loss: 9.45e+07 -0.5696885585784912 0.25341442227363586\n",
      "[Step 15697] Loss: 9.57e+07 -0.5698139071464539 0.2533970773220062\n",
      "[Step 15698] Loss: 9.56e+07 -0.5697665810585022 0.25341111421585083\n",
      "[Step 15699] Loss: 9.48e+07 -0.5696788430213928 0.2534202039241791\n",
      "[Step 15700] Loss: 9.44e+07 -0.5696229338645935 0.2534424662590027\n",
      "[Step 15701] Loss: 9.48e+07 -0.5695931315422058 0.2534482479095459\n",
      "[Step 15702] Loss: 9.53e+07 -0.569683313369751 0.25340864062309265\n",
      "[Step 15703] Loss: 9.49e+07 -0.5697359442710876 0.2534020245075226\n",
      "[Step 15704] Loss: 9.42e+07 -0.5698055624961853 0.25336986780166626\n",
      "[Step 15705] Loss: 9.52e+07 -0.5697970986366272 0.2533285915851593\n",
      "[Step 15706] Loss: 9.61e+07 -0.5696208477020264 0.2533715069293976\n",
      "[Step 15707] Loss: 9.51e+07 -0.5693549513816833 0.2533913254737854\n",
      "[Step 15708] Loss: 9.66e+07 -0.5693132877349854 0.25341853499412537\n",
      "[Step 15709] Loss: 9.49e+07 -0.5692019462585449 0.2534177005290985\n",
      "[Step 15710] Loss: 9.49e+07 -0.5690321922302246 0.2534424662590027\n",
      "[Step 15711] Loss: 9.50e+07 -0.5689148306846619 0.2534399926662445\n",
      "[Step 15712] Loss: 9.51e+07 -0.5688409209251404 0.2534012198448181\n",
      "[Step 15713] Loss: 9.48e+07 -0.5687377452850342 0.2534020245075226\n",
      "[Step 15714] Loss: 9.61e+07 -0.5685299634933472 0.25343915820121765\n",
      "[Step 15715] Loss: 9.56e+07 -0.5681634545326233 0.25349774956703186\n",
      "[Step 15716] Loss: 9.47e+07 -0.5678794980049133 0.25351426005363464\n",
      "[Step 15717] Loss: 9.55e+07 -0.5677050352096558 0.25353488326072693\n",
      "[Step 15718] Loss: 9.53e+07 -0.5674211978912354 0.25360172986984253\n",
      "[Step 15719] Loss: 9.45e+07 -0.5672018527984619 0.25362566113471985\n",
      "[Step 15720] Loss: 9.46e+07 -0.5670092701911926 0.25364381074905396\n",
      "[Step 15721] Loss: 9.55e+07 -0.5667412877082825 0.2537180781364441\n",
      "[Step 15722] Loss: 9.46e+07 -0.5665504932403564 0.25375354290008545\n",
      "[Step 15723] Loss: 9.43e+07 -0.5663998126983643 0.2537708878517151\n",
      "[Step 15724] Loss: 9.45e+07 -0.5662476420402527 0.25379645824432373\n",
      "[Step 15725] Loss: 9.49e+07 -0.5661705732345581 0.25380387902259827\n",
      "[Step 15726] Loss: 9.51e+07 -0.5662261247634888 0.253764271736145\n",
      "[Step 15727] Loss: 9.52e+07 -0.566196084022522 0.2537601590156555\n",
      "[Step 15728] Loss: 9.49e+07 -0.5661141872406006 0.2537626326084137\n",
      "[Step 15729] Loss: 9.43e+07 -0.565989077091217 0.2537584900856018\n",
      "[Step 15730] Loss: 9.49e+07 -0.5659111738204956 0.25375768542289734\n",
      "[Step 15731] Loss: 9.59e+07 -0.5657800436019897 0.253764271736145\n",
      "[Step 15732] Loss: 9.48e+07 -0.5656911730766296 0.25374364852905273\n",
      "[Step 15733] Loss: 9.57e+07 -0.5658490061759949 0.25368010997772217\n",
      "[Step 15734] Loss: 9.41e+07 -0.5659338235855103 0.25364959239959717\n",
      "[Step 15735] Loss: 9.44e+07 -0.5660136342048645 0.2536371946334839\n",
      "[Step 15736] Loss: 9.44e+07 -0.5660187005996704 0.2536347210407257\n",
      "[Step 15737] Loss: 9.43e+07 -0.5660781860351562 0.2536107897758484\n",
      "[Step 15738] Loss: 9.48e+07 -0.5660574436187744 0.2535876929759979\n",
      "[Step 15739] Loss: 9.50e+07 -0.5659629702568054 0.25358685851097107\n",
      "[Step 15740] Loss: 9.67e+07 -0.5660507082939148 0.2535373568534851\n",
      "[Step 15741] Loss: 9.51e+07 -0.5662733912467957 0.2534993886947632\n",
      "[Step 15742] Loss: 9.51e+07 -0.5666476488113403 0.25342267751693726\n",
      "[Step 15743] Loss: 9.56e+07 -0.5668190121650696 0.25336986780166626\n",
      "[Step 15744] Loss: 9.47e+07 -0.5670362710952759 0.25329145789146423\n",
      "[Step 15745] Loss: 9.56e+07 -0.5673348307609558 0.25321143865585327\n",
      "[Step 15746] Loss: 9.51e+07 -0.5676753520965576 0.2531280815601349\n",
      "[Step 15747] Loss: 9.47e+07 -0.5680313110351562 0.2530406415462494\n",
      "[Step 15748] Loss: 9.43e+07 -0.5683627724647522 0.2529771029949188\n",
      "[Step 15749] Loss: 9.51e+07 -0.5686980485916138 0.2528986930847168\n",
      "[Step 15750] Loss: 9.50e+07 -0.5691420435905457 0.25277164578437805\n",
      "[Step 15751] Loss: 9.57e+07 -0.5697826147079468 0.25261980295181274\n",
      "[Step 15752] Loss: 9.52e+07 -0.5703545212745667 0.2524853050708771\n",
      "[Step 15753] Loss: 9.55e+07 -0.5709399580955505 0.2523574233055115\n",
      "[Step 15754] Loss: 9.57e+07 -0.57148277759552 0.25225013494491577\n",
      "[Step 15755] Loss: 9.45e+07 -0.5719620585441589 0.2521478235721588\n",
      "[Step 15756] Loss: 9.59e+07 -0.5722912549972534 0.2520810067653656\n",
      "[Step 15757] Loss: 9.48e+07 -0.5725728273391724 0.25199517607688904\n",
      "[Step 15758] Loss: 9.49e+07 -0.5728884935379028 0.2519192695617676\n",
      "[Step 15759] Loss: 9.51e+07 -0.5730487108230591 0.25188377499580383\n",
      "[Step 15760] Loss: 9.52e+07 -0.5730496048927307 0.2518375813961029\n",
      "[Step 15761] Loss: 9.51e+07 -0.5729992389678955 0.25182437896728516\n",
      "[Step 15762] Loss: 9.49e+07 -0.5728971362113953 0.2518359422683716\n",
      "[Step 15763] Loss: 9.46e+07 -0.5727457404136658 0.2518540918827057\n",
      "[Step 15764] Loss: 9.52e+07 -0.5725505948066711 0.2518598437309265\n",
      "[Step 15765] Loss: 9.52e+07 -0.5724586844444275 0.2518920302391052\n",
      "[Step 15766] Loss: 9.50e+07 -0.5723321437835693 0.2519291639328003\n",
      "[Step 15767] Loss: 9.50e+07 -0.5721109509468079 0.2519679367542267\n",
      "[Step 15768] Loss: 9.55e+07 -0.5717690587043762 0.2520488202571869\n",
      "[Step 15769] Loss: 9.59e+07 -0.5715439915657043 0.2520735561847687\n",
      "[Step 15770] Loss: 9.55e+07 -0.5714299082756042 0.25208181142807007\n",
      "[Step 15771] Loss: 9.52e+07 -0.5713189840316772 0.25210410356521606\n",
      "[Step 15772] Loss: 9.54e+07 -0.5711381435394287 0.25212883949279785\n",
      "[Step 15773] Loss: 9.57e+07 -0.570960283279419 0.2521338164806366\n",
      "[Step 15774] Loss: 9.51e+07 -0.5708636045455933 0.2521296739578247\n",
      "[Step 15775] Loss: 9.53e+07 -0.5707818865776062 0.25214701890945435\n",
      "[Step 15776] Loss: 9.59e+07 -0.5708261132240295 0.25212472677230835\n",
      "[Step 15777] Loss: 9.49e+07 -0.5708501935005188 0.2521032691001892\n",
      "[Step 15778] Loss: 9.52e+07 -0.5708978176116943 0.2520999610424042\n",
      "[Step 15779] Loss: 9.49e+07 -0.571006715297699 0.2520735561847687\n",
      "[Step 15780] Loss: 9.46e+07 -0.5711590647697449 0.2520364224910736\n",
      "[Step 15781] Loss: 9.51e+07 -0.5714048743247986 0.25199517607688904\n",
      "[Step 15782] Loss: 9.51e+07 -0.5717012882232666 0.25194400548934937\n",
      "[Step 15783] Loss: 9.48e+07 -0.5719157457351685 0.2518928647041321\n",
      "[Step 15784] Loss: 9.41e+07 -0.5721394419670105 0.25186482071876526\n",
      "[Step 15785] Loss: 9.44e+07 -0.5724143981933594 0.2517773509025574\n",
      "[Step 15786] Loss: 9.40e+07 -0.5727274417877197 0.2517022490501404\n",
      "[Step 15787] Loss: 9.49e+07 -0.5730196833610535 0.251610666513443\n",
      "[Step 15788] Loss: 9.50e+07 -0.573175847530365 0.2515842616558075\n",
      "[Step 15789] Loss: 9.49e+07 -0.5733584761619568 0.2515537440776825\n",
      "[Step 15790] Loss: 9.47e+07 -0.5735820531845093 0.25152236223220825\n",
      "[Step 15791] Loss: 9.42e+07 -0.5737724304199219 0.25146791338920593\n",
      "[Step 15792] Loss: 9.48e+07 -0.5739100575447083 0.25142088532447815\n",
      "[Step 15793] Loss: 9.49e+07 -0.5740593671798706 0.2513697147369385\n",
      "[Step 15794] Loss: 9.55e+07 -0.574154257774353 0.2512979507446289\n",
      "[Step 15795] Loss: 9.54e+07 -0.5743590593338013 0.2512335777282715\n",
      "[Step 15796] Loss: 9.45e+07 -0.5745718479156494 0.2511642575263977\n",
      "[Step 15797] Loss: 9.44e+07 -0.5748060941696167 0.2511213719844818\n",
      "[Step 15798] Loss: 9.52e+07 -0.574921727180481 0.2510809302330017\n",
      "[Step 15799] Loss: 9.48e+07 -0.574894368648529 0.2510644197463989\n",
      "[Step 15800] Loss: 9.59e+07 -0.5748046636581421 0.25107020139694214\n",
      "[Step 15801] Loss: 9.47e+07 -0.5746358036994934 0.25109824538230896\n",
      "[Step 15802] Loss: 9.42e+07 -0.57448810338974 0.25114694237709045\n",
      "[Step 15803] Loss: 9.52e+07 -0.5742640495300293 0.25119727849960327\n",
      "[Step 15804] Loss: 9.46e+07 -0.5739312171936035 0.2512674033641815\n",
      "[Step 15805] Loss: 9.48e+07 -0.5736216306686401 0.251293808221817\n",
      "[Step 15806] Loss: 9.48e+07 -0.5734807252883911 0.25131115317344666\n",
      "[Step 15807] Loss: 9.60e+07 -0.5732213854789734 0.2513771653175354\n",
      "[Step 15808] Loss: 9.38e+07 -0.5730249285697937 0.2514093220233917\n",
      "[Step 15809] Loss: 9.44e+07 -0.5728487372398376 0.25143325328826904\n",
      "[Step 15810] Loss: 9.47e+07 -0.5727347135543823 0.25142747163772583\n",
      "[Step 15811] Loss: 9.53e+07 -0.5726965665817261 0.2514142692089081\n",
      "[Step 15812] Loss: 9.52e+07 -0.5727089047431946 0.25137385725975037\n",
      "[Step 15813] Loss: 9.53e+07 -0.5726481676101685 0.2513895332813263\n",
      "[Step 15814] Loss: 9.48e+07 -0.5724787712097168 0.2514398694038391\n",
      "[Step 15815] Loss: 9.42e+07 -0.5724278688430786 0.25144892930984497\n",
      "[Step 15816] Loss: 9.55e+07 -0.5723302364349365 0.2514621317386627\n",
      "[Step 15817] Loss: 9.57e+07 -0.5723267793655396 0.25145140290260315\n",
      "[Step 15818] Loss: 9.51e+07 -0.572458028793335 0.2514175772666931\n",
      "[Step 15819] Loss: 9.47e+07 -0.57246994972229 0.25140437483787537\n",
      "[Step 15820] Loss: 9.49e+07 -0.5724712610244751 0.2514324486255646\n",
      "[Step 15821] Loss: 9.47e+07 -0.5723992586135864 0.25143492221832275\n",
      "[Step 15822] Loss: 9.47e+07 -0.5723811388015747 0.25144481658935547\n",
      "[Step 15823] Loss: 9.51e+07 -0.5724194049835205 0.25142747163772583\n",
      "[Step 15824] Loss: 9.50e+07 -0.5724022388458252 0.2514076828956604\n",
      "[Step 15825] Loss: 9.46e+07 -0.5722864866256714 0.25143077969551086\n",
      "[Step 15826] Loss: 9.54e+07 -0.5722089409828186 0.2514629662036896\n",
      "[Step 15827] Loss: 9.56e+07 -0.5720250606536865 0.2515108287334442\n",
      "[Step 15828] Loss: 9.54e+07 -0.5720246434211731 0.2515330910682678\n",
      "[Step 15829] Loss: 9.53e+07 -0.5722034573554993 0.25147533416748047\n",
      "[Step 15830] Loss: 9.52e+07 -0.5723482370376587 0.25142666697502136\n",
      "[Step 15831] Loss: 9.50e+07 -0.5725650787353516 0.2513408362865448\n",
      "[Step 15832] Loss: 9.46e+07 -0.5726815462112427 0.251290500164032\n",
      "[Step 15833] Loss: 9.40e+07 -0.572799026966095 0.2512740194797516\n",
      "[Step 15834] Loss: 9.46e+07 -0.5729054808616638 0.25125667452812195\n",
      "[Step 15835] Loss: 9.46e+07 -0.5729745626449585 0.2512187361717224\n",
      "[Step 15836] Loss: 9.49e+07 -0.5729925632476807 0.2511840760707855\n",
      "[Step 15837] Loss: 9.51e+07 -0.5730249881744385 0.2511560022830963\n",
      "[Step 15838] Loss: 9.48e+07 -0.5730468034744263 0.2511700391769409\n",
      "[Step 15839] Loss: 9.54e+07 -0.5731107592582703 0.2511659264564514\n",
      "[Step 15840] Loss: 9.52e+07 -0.5730623602867126 0.2511700391769409\n",
      "[Step 15841] Loss: 9.51e+07 -0.5728959441184998 0.2511840760707855\n",
      "[Step 15842] Loss: 9.46e+07 -0.5727142691612244 0.2511989176273346\n",
      "[Step 15843] Loss: 9.52e+07 -0.5725654363632202 0.2512533664703369\n",
      "[Step 15844] Loss: 9.48e+07 -0.5724471211433411 0.2512954771518707\n",
      "[Step 15845] Loss: 9.47e+07 -0.572354793548584 0.25132352113723755\n",
      "[Step 15846] Loss: 9.47e+07 -0.572205126285553 0.251343309879303\n",
      "[Step 15847] Loss: 9.47e+07 -0.5720713138580322 0.25137385725975037\n",
      "[Step 15848] Loss: 9.52e+07 -0.5719752311706543 0.25137385725975037\n",
      "[Step 15849] Loss: 9.50e+07 -0.5720165967941284 0.25138211250305176\n",
      "[Step 15850] Loss: 9.60e+07 -0.5719598531723022 0.2514101564884186\n",
      "[Step 15851] Loss: 9.51e+07 -0.5719568729400635 0.2514588534832001\n",
      "[Step 15852] Loss: 9.49e+07 -0.5719558596611023 0.2514365613460541\n",
      "[Step 15853] Loss: 9.49e+07 -0.5719312429428101 0.25144729018211365\n",
      "[Step 15854] Loss: 9.44e+07 -0.5720313787460327 0.2514134645462036\n",
      "[Step 15855] Loss: 9.48e+07 -0.5720224976539612 0.2513788044452667\n",
      "[Step 15856] Loss: 9.49e+07 -0.5721092820167542 0.25136229395866394\n",
      "[Step 15857] Loss: 9.49e+07 -0.5721418261528015 0.2513532340526581\n",
      "[Step 15858] Loss: 9.41e+07 -0.5721480250358582 0.25132763385772705\n",
      "[Step 15859] Loss: 9.46e+07 -0.5721202492713928 0.2513226866722107\n",
      "[Step 15860] Loss: 9.50e+07 -0.5720717310905457 0.25132930278778076\n",
      "[Step 15861] Loss: 9.59e+07 -0.572170615196228 0.2513185739517212\n",
      "[Step 15862] Loss: 9.51e+07 -0.5723305940628052 0.25126907229423523\n",
      "[Step 15863] Loss: 9.41e+07 -0.5724970698356628 0.2512112855911255\n",
      "[Step 15864] Loss: 9.60e+07 -0.5729103088378906 0.2511098086833954\n",
      "[Step 15865] Loss: 9.51e+07 -0.5732764005661011 0.25102895498275757\n",
      "[Step 15866] Loss: 9.45e+07 -0.5735570788383484 0.2509414851665497\n",
      "[Step 15867] Loss: 9.58e+07 -0.5737192034721375 0.2508663833141327\n",
      "[Step 15868] Loss: 9.44e+07 -0.5738929510116577 0.25079378485679626\n",
      "[Step 15869] Loss: 9.48e+07 -0.573958694934845 0.25074756145477295\n",
      "[Step 15870] Loss: 9.46e+07 -0.5740249156951904 0.25070714950561523\n",
      "[Step 15871] Loss: 9.52e+07 -0.574068546295166 0.2506815493106842\n",
      "[Step 15872] Loss: 9.47e+07 -0.5741734504699707 0.25064772367477417\n",
      "[Step 15873] Loss: 9.47e+07 -0.574280858039856 0.2505949139595032\n",
      "[Step 15874] Loss: 9.47e+07 -0.5744071006774902 0.25056523084640503\n",
      "[Step 15875] Loss: 9.41e+07 -0.5745051503181458 0.2505190074443817\n",
      "[Step 15876] Loss: 9.57e+07 -0.5744727849960327 0.25051653385162354\n",
      "[Step 15877] Loss: 9.49e+07 -0.5745064616203308 0.25046372413635254\n",
      "[Step 15878] Loss: 9.46e+07 -0.5745871067047119 0.25044888257980347\n",
      "[Step 15879] Loss: 9.47e+07 -0.5745684504508972 0.2504546344280243\n",
      "[Step 15880] Loss: 9.44e+07 -0.5746052265167236 0.25043073296546936\n",
      "[Step 15881] Loss: 9.51e+07 -0.5746763348579407 0.2503737807273865\n",
      "[Step 15882] Loss: 9.46e+07 -0.5748534798622131 0.25032839179039\n",
      "[Step 15883] Loss: 9.56e+07 -0.574986457824707 0.25029703974723816\n",
      "[Step 15884] Loss: 9.53e+07 -0.5750519037246704 0.25026485323905945\n",
      "[Step 15885] Loss: 9.48e+07 -0.575079619884491 0.25024259090423584\n",
      "[Step 15886] Loss: 9.51e+07 -0.5752137303352356 0.250161737203598\n",
      "[Step 15887] Loss: 9.50e+07 -0.5753564834594727 0.25010645389556885\n",
      "[Step 15888] Loss: 9.47e+07 -0.5754096508026123 0.25009405612945557\n",
      "[Step 15889] Loss: 9.47e+07 -0.5755301713943481 0.25008004903793335\n",
      "[Step 15890] Loss: 9.44e+07 -0.5755739808082581 0.2500321865081787\n",
      "[Step 15891] Loss: 9.41e+07 -0.5755562782287598 0.25002309679985046\n",
      "[Step 15892] Loss: 9.42e+07 -0.5755656957626343 0.24998845160007477\n",
      "[Step 15893] Loss: 9.47e+07 -0.5754917860031128 0.2500082552433014\n",
      "[Step 15894] Loss: 9.51e+07 -0.5753589272499084 0.24996699392795563\n",
      "[Step 15895] Loss: 9.51e+07 -0.5752154588699341 0.24997194111347198\n",
      "[Step 15896] Loss: 9.57e+07 -0.5752115249633789 0.24995379149913788\n",
      "[Step 15897] Loss: 9.71e+07 -0.5755838751792908 0.24983827769756317\n",
      "[Step 15898] Loss: 9.53e+07 -0.5760126709938049 0.24971532821655273\n",
      "[Step 15899] Loss: 9.50e+07 -0.5764988660812378 0.24958330392837524\n",
      "[Step 15900] Loss: 9.41e+07 -0.5768325328826904 0.2494950145483017\n",
      "[Step 15901] Loss: 9.46e+07 -0.5770470499992371 0.24944302439689636\n",
      "[Step 15902] Loss: 9.55e+07 -0.5771098732948303 0.24938197433948517\n",
      "[Step 15903] Loss: 9.51e+07 -0.5770432353019714 0.24936546385288239\n",
      "[Step 15904] Loss: 9.45e+07 -0.5769729018211365 0.24933741986751556\n",
      "[Step 15905] Loss: 9.50e+07 -0.5770381689071655 0.24931925535202026\n",
      "[Step 15906] Loss: 9.44e+07 -0.5770053863525391 0.24932503700256348\n",
      "[Step 15907] Loss: 9.58e+07 -0.5770430564880371 0.24931101500988007\n",
      "[Step 15908] Loss: 9.39e+07 -0.5771448016166687 0.24928048253059387\n",
      "[Step 15909] Loss: 9.48e+07 -0.5772725939750671 0.24921363592147827\n",
      "[Step 15910] Loss: 9.52e+07 -0.5774660110473633 0.24916742742061615\n",
      "[Step 15911] Loss: 9.60e+07 -0.5775497555732727 0.24914267659187317\n",
      "[Step 15912] Loss: 9.46e+07 -0.5776382684707642 0.24909977614879608\n",
      "[Step 15913] Loss: 9.48e+07 -0.5778408646583557 0.24907006323337555\n",
      "[Step 15914] Loss: 9.50e+07 -0.5780880451202393 0.24896033108234406\n",
      "[Step 15915] Loss: 9.60e+07 -0.5784963965415955 0.24886707961559296\n",
      "[Step 15916] Loss: 9.47e+07 -0.578960120677948 0.24875156581401825\n",
      "[Step 15917] Loss: 9.50e+07 -0.5795323848724365 0.24860304594039917\n",
      "[Step 15918] Loss: 9.48e+07 -0.5800641775131226 0.24848338961601257\n",
      "[Step 15919] Loss: 9.52e+07 -0.5805781483650208 0.24836458265781403\n",
      "[Step 15920] Loss: 9.49e+07 -0.5809482932090759 0.2482515275478363\n",
      "[Step 15921] Loss: 9.49e+07 -0.5812282562255859 0.24817891418933868\n",
      "[Step 15922] Loss: 9.47e+07 -0.5815399289131165 0.24810713529586792\n",
      "[Step 15923] Loss: 9.43e+07 -0.5818473696708679 0.24801306426525116\n",
      "[Step 15924] Loss: 9.50e+07 -0.5822266340255737 0.2479289025068283\n",
      "[Step 15925] Loss: 9.45e+07 -0.5826497077941895 0.24783483147621155\n",
      "[Step 15926] Loss: 9.49e+07 -0.5829969048500061 0.2477506697177887\n",
      "[Step 15927] Loss: 9.43e+07 -0.583328902721405 0.24768301844596863\n",
      "[Step 15928] Loss: 9.49e+07 -0.5837088823318481 0.24760957062244415\n",
      "[Step 15929] Loss: 9.47e+07 -0.5841310620307922 0.24750231206417084\n",
      "[Step 15930] Loss: 9.54e+07 -0.5844181180000305 0.247476726770401\n",
      "[Step 15931] Loss: 9.59e+07 -0.5847830772399902 0.24741484224796295\n",
      "[Step 15932] Loss: 9.46e+07 -0.5850771069526672 0.24734222888946533\n",
      "[Step 15933] Loss: 9.49e+07 -0.5853452086448669 0.24728365242481232\n",
      "[Step 15934] Loss: 9.54e+07 -0.5856068730354309 0.24721433222293854\n",
      "[Step 15935] Loss: 9.53e+07 -0.5857685208320618 0.24714750051498413\n",
      "[Step 15936] Loss: 9.46e+07 -0.5859712362289429 0.24708890914916992\n",
      "[Step 15937] Loss: 9.53e+07 -0.5863144993782043 0.2470080554485321\n",
      "[Step 15938] Loss: 9.42e+07 -0.5866744518280029 0.24689336121082306\n",
      "[Step 15939] Loss: 9.69e+07 -0.5872472524642944 0.24676215648651123\n",
      "[Step 15940] Loss: 9.50e+07 -0.5877273082733154 0.24667799472808838\n",
      "[Step 15941] Loss: 9.54e+07 -0.5883303284645081 0.2465517520904541\n",
      "[Step 15942] Loss: 9.53e+07 -0.5889160633087158 0.24640074372291565\n",
      "[Step 15943] Loss: 9.44e+07 -0.5894314646720886 0.24629925191402435\n",
      "[Step 15944] Loss: 9.51e+07 -0.5898504853248596 0.24620601534843445\n",
      "[Step 15945] Loss: 9.48e+07 -0.590218186378479 0.24610286951065063\n",
      "[Step 15946] Loss: 9.47e+07 -0.590634286403656 0.24596920609474182\n",
      "[Step 15947] Loss: 9.50e+07 -0.5909631252288818 0.24584707617759705\n",
      "[Step 15948] Loss: 9.52e+07 -0.5912450551986694 0.2457587867975235\n",
      "[Step 15949] Loss: 9.49e+07 -0.5914890170097351 0.2456878274679184\n",
      "[Step 15950] Loss: 9.43e+07 -0.5916032791137695 0.2456449270248413\n",
      "[Step 15951] Loss: 9.47e+07 -0.5917409658432007 0.24561026692390442\n",
      "[Step 15952] Loss: 9.48e+07 -0.5918705463409424 0.2455863356590271\n",
      "[Step 15953] Loss: 9.46e+07 -0.592005729675293 0.24553270637989044\n",
      "[Step 15954] Loss: 9.47e+07 -0.5921772122383118 0.24547000229358673\n",
      "[Step 15955] Loss: 9.56e+07 -0.5924782752990723 0.2453751116991043\n",
      "[Step 15956] Loss: 9.48e+07 -0.5928299427032471 0.24526123702526093\n",
      "[Step 15957] Loss: 9.49e+07 -0.5932015776634216 0.24518615007400513\n",
      "[Step 15958] Loss: 9.48e+07 -0.5935749411582947 0.24511601030826569\n",
      "[Step 15959] Loss: 9.43e+07 -0.5939450263977051 0.24503763020038605\n",
      "[Step 15960] Loss: 9.51e+07 -0.5941982269287109 0.2449633628129959\n",
      "[Step 15961] Loss: 9.65e+07 -0.5947014689445496 0.2448519617319107\n",
      "[Step 15962] Loss: 9.52e+07 -0.595190167427063 0.2446960210800171\n",
      "[Step 15963] Loss: 9.48e+07 -0.5955936312675476 0.24459369480609894\n",
      "[Step 15964] Loss: 9.50e+07 -0.5960376858711243 0.2444806545972824\n",
      "[Step 15965] Loss: 9.48e+07 -0.5965043306350708 0.2443568855524063\n",
      "[Step 15966] Loss: 9.53e+07 -0.5968784093856812 0.24427932500839233\n",
      "[Step 15967] Loss: 9.54e+07 -0.5973206758499146 0.24415555596351624\n",
      "[Step 15968] Loss: 9.50e+07 -0.5977531671524048 0.24404168128967285\n",
      "[Step 15969] Loss: 9.51e+07 -0.5981388688087463 0.2439269870519638\n",
      "[Step 15970] Loss: 9.46e+07 -0.59852534532547 0.24382632970809937\n",
      "[Step 15971] Loss: 9.54e+07 -0.5987743139266968 0.24380652606487274\n",
      "[Step 15972] Loss: 9.43e+07 -0.5990765690803528 0.24373804032802582\n",
      "[Step 15973] Loss: 9.45e+07 -0.5993642210960388 0.24370667338371277\n",
      "[Step 15974] Loss: 9.47e+07 -0.599587619304657 0.24367037415504456\n",
      "[Step 15975] Loss: 9.49e+07 -0.5997581481933594 0.24363818764686584\n",
      "[Step 15976] Loss: 9.53e+07 -0.5998760461807251 0.2436266392469406\n",
      "[Step 15977] Loss: 9.49e+07 -0.5999298691749573 0.2435903400182724\n",
      "[Step 15978] Loss: 9.53e+07 -0.5998973250389099 0.24362581968307495\n",
      "[Step 15979] Loss: 9.51e+07 -0.5997784733772278 0.24364478886127472\n",
      "[Step 15980] Loss: 9.39e+07 -0.5996177792549133 0.24367614090442657\n",
      "[Step 15981] Loss: 9.50e+07 -0.599348247051239 0.24369843304157257\n",
      "[Step 15982] Loss: 9.55e+07 -0.5989460945129395 0.24378672242164612\n",
      "[Step 15983] Loss: 9.41e+07 -0.5985535383224487 0.24389563500881195\n",
      "[Step 15984] Loss: 9.67e+07 -0.5979602336883545 0.24403178691864014\n",
      "[Step 15985] Loss: 9.51e+07 -0.5974909663200378 0.244144007563591\n",
      "[Step 15986] Loss: 9.49e+07 -0.5970034599304199 0.24426530301570892\n",
      "[Step 15987] Loss: 9.49e+07 -0.596527099609375 0.24435770511627197\n",
      "[Step 15988] Loss: 9.42e+07 -0.5960870981216431 0.24444682896137238\n",
      "[Step 15989] Loss: 9.46e+07 -0.5955736637115479 0.24456565082073212\n",
      "[Step 15990] Loss: 9.47e+07 -0.5952466130256653 0.24462588131427765\n",
      "[Step 15991] Loss: 9.49e+07 -0.5949946045875549 0.24468694627285004\n",
      "[Step 15992] Loss: 9.47e+07 -0.5948377251625061 0.2447017878293991\n",
      "[Step 15993] Loss: 9.45e+07 -0.5947442650794983 0.2447447031736374\n",
      "[Step 15994] Loss: 9.38e+07 -0.594624400138855 0.24478018283843994\n",
      "[Step 15995] Loss: 9.56e+07 -0.5945472717285156 0.24478843808174133\n",
      "[Step 15996] Loss: 9.46e+07 -0.5944798588752747 0.24477523565292358\n",
      "[Step 15997] Loss: 9.50e+07 -0.5943822264671326 0.2447950392961502\n",
      "[Step 15998] Loss: 9.49e+07 -0.5943875908851624 0.2447711080312729\n",
      "[Step 15999] Loss: 9.53e+07 -0.594466507434845 0.24475212395191193\n",
      "[Step 16000] Loss: 9.47e+07 -0.5945331454277039 0.24475790560245514\n",
      "[Step 16001] Loss: 9.44e+07 -0.5945230722427368 0.24475295841693878\n",
      "[Step 16002] Loss: 9.46e+07 -0.5944149494171143 0.24473975598812103\n",
      "[Step 16003] Loss: 9.43e+07 -0.5943222641944885 0.24473892152309418\n",
      "[Step 16004] Loss: 9.49e+07 -0.5942012667655945 0.24476532638072968\n",
      "[Step 16005] Loss: 9.44e+07 -0.5940248966217041 0.24474883079528809\n",
      "[Step 16006] Loss: 9.53e+07 -0.5938001871109009 0.24475377798080444\n",
      "[Step 16007] Loss: 9.53e+07 -0.5935052633285522 0.24483299255371094\n",
      "[Step 16008] Loss: 9.47e+07 -0.5932800769805908 0.2448742538690567\n",
      "[Step 16009] Loss: 9.62e+07 -0.5933356285095215 0.24480824172496796\n",
      "[Step 16010] Loss: 9.51e+07 -0.5933179259300232 0.2447909116744995\n",
      "[Step 16011] Loss: 9.45e+07 -0.5933921337127686 0.2447711080312729\n",
      "[Step 16012] Loss: 9.46e+07 -0.5934140682220459 0.2447463572025299\n",
      "[Step 16013] Loss: 9.49e+07 -0.5935075283050537 0.24465475976467133\n",
      "[Step 16014] Loss: 9.43e+07 -0.593611478805542 0.24462753534317017\n",
      "[Step 16015] Loss: 9.49e+07 -0.5936468243598938 0.2446184605360031\n",
      "[Step 16016] Loss: 9.51e+07 -0.5936440825462341 0.24460525810718536\n",
      "[Step 16017] Loss: 9.49e+07 -0.5936881899833679 0.2445697784423828\n",
      "[Step 16018] Loss: 9.57e+07 -0.5939280986785889 0.24450871348381042\n",
      "[Step 16019] Loss: 9.44e+07 -0.5941587686538696 0.24443939328193665\n",
      "[Step 16020] Loss: 9.45e+07 -0.5943521857261658 0.24439814686775208\n",
      "[Step 16021] Loss: 9.49e+07 -0.5944018363952637 0.24438081681728363\n",
      "[Step 16022] Loss: 9.51e+07 -0.5944855809211731 0.2443288266658783\n",
      "[Step 16023] Loss: 9.43e+07 -0.5945186018943787 0.24430489540100098\n",
      "[Step 16024] Loss: 9.54e+07 -0.5946645736694336 0.24423229694366455\n",
      "[Step 16025] Loss: 9.41e+07 -0.5948175191879272 0.24419516324996948\n",
      "[Step 16026] Loss: 9.52e+07 -0.5948899984359741 0.2441844344139099\n",
      "[Step 16027] Loss: 9.47e+07 -0.5949985384941101 0.24414317309856415\n",
      "[Step 16028] Loss: 9.47e+07 -0.5950843691825867 0.24407881498336792\n",
      "[Step 16029] Loss: 9.56e+07 -0.595100998878479 0.24407139420509338\n",
      "[Step 16030] Loss: 9.54e+07 -0.5951752066612244 0.2440326064825058\n",
      "[Step 16031] Loss: 9.41e+07 -0.5951933264732361 0.2440202236175537\n",
      "[Step 16032] Loss: 9.52e+07 -0.5952211022377014 0.2439921796321869\n",
      "[Step 16033] Loss: 9.60e+07 -0.5954130291938782 0.24391791224479675\n",
      "[Step 16034] Loss: 9.40e+07 -0.5955308675765991 0.24387088418006897\n",
      "[Step 16035] Loss: 9.53e+07 -0.5956833958625793 0.24384447932243347\n",
      "[Step 16036] Loss: 9.45e+07 -0.5957996249198914 0.24380403757095337\n",
      "[Step 16037] Loss: 9.42e+07 -0.595919668674469 0.24378259479999542\n",
      "[Step 16038] Loss: 9.49e+07 -0.5960375070571899 0.24372895061969757\n",
      "[Step 16039] Loss: 9.45e+07 -0.5961800217628479 0.24369265139102936\n",
      "[Step 16040] Loss: 9.70e+07 -0.5965995192527771 0.24357548356056213\n",
      "[Step 16041] Loss: 9.43e+07 -0.5968759655952454 0.24351359903812408\n",
      "[Step 16042] Loss: 9.59e+07 -0.5973082184791565 0.2434038519859314\n",
      "[Step 16043] Loss: 9.44e+07 -0.5978111028671265 0.24327677488327026\n",
      "[Step 16044] Loss: 9.51e+07 -0.5981895327568054 0.24321241676807404\n",
      "[Step 16045] Loss: 9.46e+07 -0.5985154509544373 0.2431175261735916\n",
      "[Step 16046] Loss: 9.45e+07 -0.5988287925720215 0.24302181601524353\n",
      "[Step 16047] Loss: 9.41e+07 -0.5991130471229553 0.24293765425682068\n",
      "[Step 16048] Loss: 9.47e+07 -0.5993714332580566 0.2428741157054901\n",
      "[Step 16049] Loss: 9.32e+07 -0.5996170043945312 0.24278582632541656\n",
      "[Step 16050] Loss: 9.52e+07 -0.5998941659927368 0.24273467063903809\n",
      "[Step 16051] Loss: 9.42e+07 -0.6000866293907166 0.24268846213817596\n",
      "[Step 16052] Loss: 9.51e+07 -0.6002097725868225 0.24261832237243652\n",
      "[Step 16053] Loss: 9.49e+07 -0.6004248261451721 0.24257458746433258\n",
      "[Step 16054] Loss: 9.44e+07 -0.6005761027336121 0.24249455332756042\n",
      "[Step 16055] Loss: 9.53e+07 -0.6005846261978149 0.24245741963386536\n",
      "[Step 16056] Loss: 9.50e+07 -0.6007055640220642 0.2424161583185196\n",
      "[Step 16057] Loss: 9.48e+07 -0.6008663177490234 0.2423691302537918\n",
      "[Step 16058] Loss: 9.54e+07 -0.601102888584137 0.24229486286640167\n",
      "[Step 16059] Loss: 9.50e+07 -0.6013875603675842 0.2422478348016739\n",
      "[Step 16060] Loss: 9.51e+07 -0.6017799973487854 0.24215129017829895\n",
      "[Step 16061] Loss: 9.47e+07 -0.6021987795829773 0.242048978805542\n",
      "[Step 16062] Loss: 9.61e+07 -0.6025317907333374 0.24199451506137848\n",
      "[Step 16063] Loss: 9.46e+07 -0.6028042435646057 0.2419070601463318\n",
      "[Step 16064] Loss: 9.51e+07 -0.602969765663147 0.24186661839485168\n",
      "[Step 16065] Loss: 9.51e+07 -0.6031622290611267 0.24182040989398956\n",
      "[Step 16066] Loss: 9.45e+07 -0.6033855080604553 0.24174119532108307\n",
      "[Step 16067] Loss: 9.45e+07 -0.6036127805709839 0.24169829487800598\n",
      "[Step 16068] Loss: 9.53e+07 -0.60387122631073 0.24160587787628174\n",
      "[Step 16069] Loss: 9.53e+07 -0.60423344373703 0.24149613082408905\n",
      "[Step 16070] Loss: 9.47e+07 -0.6045775413513184 0.24140536785125732\n",
      "[Step 16071] Loss: 9.48e+07 -0.6048420071601868 0.2413426637649536\n",
      "[Step 16072] Loss: 9.52e+07 -0.6050853133201599 0.2412617951631546\n",
      "[Step 16073] Loss: 9.70e+07 -0.6056855916976929 0.24107614159584045\n",
      "[Step 16074] Loss: 9.58e+07 -0.606160044670105 0.2409333884716034\n",
      "[Step 16075] Loss: 9.50e+07 -0.6066223382949829 0.24080219864845276\n",
      "[Step 16076] Loss: 9.50e+07 -0.6071327924728394 0.24067842960357666\n",
      "[Step 16077] Loss: 9.49e+07 -0.6075500845909119 0.24057941138744354\n",
      "[Step 16078] Loss: 9.58e+07 -0.6080012917518616 0.24045151472091675\n",
      "[Step 16079] Loss: 9.47e+07 -0.6083831191062927 0.24034754931926727\n",
      "[Step 16080] Loss: 9.45e+07 -0.6086974143981934 0.24027080833911896\n",
      "[Step 16081] Loss: 9.55e+07 -0.6089336276054382 0.2402089238166809\n",
      "[Step 16082] Loss: 9.41e+07 -0.609171986579895 0.24012723565101624\n",
      "[Step 16083] Loss: 9.56e+07 -0.6095070242881775 0.24003151059150696\n",
      "[Step 16084] Loss: 9.49e+07 -0.6098657250404358 0.23991930484771729\n",
      "[Step 16085] Loss: 9.54e+07 -0.6102219223976135 0.23982110619544983\n",
      "[Step 16086] Loss: 9.59e+07 -0.6104159951210022 0.23975592851638794\n",
      "[Step 16087] Loss: 9.48e+07 -0.6105820536613464 0.23970146477222443\n",
      "[Step 16088] Loss: 9.44e+07 -0.6107778549194336 0.23965772986412048\n",
      "[Step 16089] Loss: 9.50e+07 -0.6110498309135437 0.2395620197057724\n",
      "[Step 16090] Loss: 9.45e+07 -0.6112614870071411 0.23951084911823273\n",
      "[Step 16091] Loss: 9.52e+07 -0.6115367412567139 0.23944072425365448\n",
      "[Step 16092] Loss: 9.40e+07 -0.6117365956306458 0.23938047885894775\n",
      "[Step 16093] Loss: 9.59e+07 -0.6117221713066101 0.23936232924461365\n",
      "[Step 16094] Loss: 9.49e+07 -0.6116299033164978 0.23938626050949097\n",
      "[Step 16095] Loss: 9.56e+07 -0.6116323471069336 0.2393771857023239\n",
      "[Step 16096] Loss: 9.49e+07 -0.6116055846214294 0.23940441012382507\n",
      "[Step 16097] Loss: 9.53e+07 -0.6115193367004395 0.23941513895988464\n",
      "[Step 16098] Loss: 9.49e+07 -0.6114565134048462 0.2394242137670517\n",
      "[Step 16099] Loss: 9.49e+07 -0.611526608467102 0.2393573820590973\n",
      "[Step 16100] Loss: 9.53e+07 -0.611668050289154 0.23932766914367676\n",
      "[Step 16101] Loss: 9.53e+07 -0.6117125153541565 0.2392921894788742\n",
      "[Step 16102] Loss: 9.48e+07 -0.6117420792579651 0.23930209875106812\n",
      "[Step 16103] Loss: 9.46e+07 -0.6116843223571777 0.23931282758712769\n",
      "[Step 16104] Loss: 9.46e+07 -0.6116584539413452 0.239308699965477\n",
      "[Step 16105] Loss: 9.52e+07 -0.6116023659706116 0.23930951952934265\n",
      "[Step 16106] Loss: 9.54e+07 -0.611420750617981 0.23933015763759613\n",
      "[Step 16107] Loss: 9.45e+07 -0.6112808585166931 0.23936232924461365\n",
      "[Step 16108] Loss: 9.55e+07 -0.6111350059509277 0.23939120769500732\n",
      "[Step 16109] Loss: 9.43e+07 -0.6110870242118835 0.23941101133823395\n",
      "[Step 16110] Loss: 9.45e+07 -0.6111096739768982 0.23936976492404938\n",
      "[Step 16111] Loss: 9.50e+07 -0.6112053394317627 0.23931282758712769\n",
      "[Step 16112] Loss: 9.51e+07 -0.6113579869270325 0.23929136991500854\n",
      "[Step 16113] Loss: 9.42e+07 -0.6114158034324646 0.23925010859966278\n",
      "[Step 16114] Loss: 9.51e+07 -0.611488938331604 0.2392129749059677\n",
      "[Step 16115] Loss: 9.44e+07 -0.611553430557251 0.2391948252916336\n",
      "[Step 16116] Loss: 9.53e+07 -0.6114948987960815 0.2391989529132843\n",
      "[Step 16117] Loss: 9.44e+07 -0.6114065051078796 0.2391906976699829\n",
      "[Step 16118] Loss: 9.49e+07 -0.6113185286521912 0.23920555412769318\n",
      "[Step 16119] Loss: 9.45e+07 -0.6112047433853149 0.23922783136367798\n",
      "[Step 16120] Loss: 9.48e+07 -0.610968291759491 0.2392393797636032\n",
      "[Step 16121] Loss: 9.48e+07 -0.610841691493988 0.23926083743572235\n",
      "[Step 16122] Loss: 9.44e+07 -0.6107905507087708 0.23926743865013123\n",
      "[Step 16123] Loss: 9.56e+07 -0.6110110282897949 0.23914861679077148\n",
      "[Step 16124] Loss: 9.49e+07 -0.6111572980880737 0.23912881314754486\n",
      "[Step 16125] Loss: 9.47e+07 -0.6112150549888611 0.2390793114900589\n",
      "[Step 16126] Loss: 9.51e+07 -0.6112313270568848 0.23904959857463837\n",
      "[Step 16127] Loss: 9.52e+07 -0.6113930940628052 0.2390042245388031\n",
      "[Step 16128] Loss: 9.45e+07 -0.6114579439163208 0.2389514148235321\n",
      "[Step 16129] Loss: 9.46e+07 -0.6116028428077698 0.23889365792274475\n",
      "[Step 16130] Loss: 9.46e+07 -0.6117064952850342 0.2388136088848114\n",
      "[Step 16131] Loss: 9.48e+07 -0.611735999584198 0.23877152800559998\n",
      "[Step 16132] Loss: 9.42e+07 -0.6118046045303345 0.23872284591197968\n",
      "[Step 16133] Loss: 9.50e+07 -0.6117950081825256 0.23868820071220398\n",
      "[Step 16134] Loss: 9.52e+07 -0.6118775606155396 0.2386188805103302\n",
      "[Step 16135] Loss: 9.53e+07 -0.6120727062225342 0.23855286836624146\n",
      "[Step 16136] Loss: 9.50e+07 -0.6122564673423767 0.23848851025104523\n",
      "[Step 16137] Loss: 9.44e+07 -0.612402617931366 0.2384299337863922\n",
      "[Step 16138] Loss: 9.60e+07 -0.6128321290016174 0.23829790949821472\n",
      "[Step 16139] Loss: 9.36e+07 -0.6131830811500549 0.23818321526050568\n",
      "[Step 16140] Loss: 9.47e+07 -0.613563597202301 0.23804871737957\n",
      "[Step 16141] Loss: 9.50e+07 -0.6138637661933899 0.2379818707704544\n",
      "[Step 16142] Loss: 9.45e+07 -0.6142029762268066 0.23788203299045563\n",
      "[Step 16143] Loss: 9.47e+07 -0.6144757866859436 0.237809419631958\n",
      "[Step 16144] Loss: 9.49e+07 -0.6147778630256653 0.23769225180149078\n",
      "[Step 16145] Loss: 9.50e+07 -0.6149885058403015 0.23762871325016022\n",
      "[Step 16146] Loss: 9.59e+07 -0.6149975657463074 0.2375965416431427\n",
      "[Step 16147] Loss: 9.52e+07 -0.6151180863380432 0.2375602275133133\n",
      "[Step 16148] Loss: 9.50e+07 -0.6152504682540894 0.23750825226306915\n",
      "[Step 16149] Loss: 9.52e+07 -0.6152627468109131 0.23752392828464508\n",
      "[Step 16150] Loss: 9.51e+07 -0.6153839230537415 0.23749834299087524\n",
      "[Step 16151] Loss: 9.51e+07 -0.6154165267944336 0.23746204376220703\n",
      "[Step 16152] Loss: 9.49e+07 -0.6154117584228516 0.23745957016944885\n",
      "[Step 16153] Loss: 9.41e+07 -0.6154937744140625 0.2374405860900879\n",
      "[Step 16154] Loss: 9.51e+07 -0.6155422329902649 0.23741665482521057\n",
      "[Step 16155] Loss: 9.45e+07 -0.6156811118125916 0.23735971748828888\n",
      "[Step 16156] Loss: 9.61e+07 -0.6160191893577576 0.2372722625732422\n",
      "[Step 16157] Loss: 9.50e+07 -0.6162949800491333 0.23720046877861023\n",
      "[Step 16158] Loss: 9.46e+07 -0.6165885925292969 0.23711714148521423\n",
      "[Step 16159] Loss: 9.45e+07 -0.6168138384819031 0.2370511293411255\n",
      "[Step 16160] Loss: 9.51e+07 -0.6169859766960144 0.23701812326908112\n",
      "[Step 16161] Loss: 9.50e+07 -0.6170581579208374 0.23699913918972015\n",
      "[Step 16162] Loss: 9.50e+07 -0.6171883940696716 0.23695045709609985\n",
      "[Step 16163] Loss: 9.53e+07 -0.6173130869865417 0.23690177500247955\n",
      "[Step 16164] Loss: 9.48e+07 -0.6175021529197693 0.2368704229593277\n",
      "[Step 16165] Loss: 9.52e+07 -0.6176219582557678 0.23680441081523895\n",
      "[Step 16166] Loss: 9.50e+07 -0.6177133321762085 0.2367771714925766\n",
      "[Step 16167] Loss: 9.51e+07 -0.6177931427955627 0.23676562309265137\n",
      "[Step 16168] Loss: 9.49e+07 -0.6179605722427368 0.2366880625486374\n",
      "[Step 16169] Loss: 9.62e+07 -0.6184150576591492 0.23660390079021454\n",
      "[Step 16170] Loss: 9.48e+07 -0.618840217590332 0.2364809513092041\n",
      "[Step 16171] Loss: 9.55e+07 -0.6194006204605103 0.23631839454174042\n",
      "[Step 16172] Loss: 9.46e+07 -0.6198537945747375 0.23622433841228485\n",
      "[Step 16173] Loss: 9.50e+07 -0.6202105283737183 0.23610056936740875\n",
      "[Step 16174] Loss: 9.44e+07 -0.6204414963722229 0.236059308052063\n",
      "[Step 16175] Loss: 9.52e+07 -0.6207587122917175 0.23595286905765533\n",
      "[Step 16176] Loss: 9.50e+07 -0.6211474537849426 0.23584643006324768\n",
      "[Step 16177] Loss: 9.45e+07 -0.6214981079101562 0.235736683011055\n",
      "[Step 16178] Loss: 9.52e+07 -0.6217436194419861 0.23565416038036346\n",
      "[Step 16179] Loss: 9.53e+07 -0.6220760345458984 0.2355683594942093\n",
      "[Step 16180] Loss: 9.52e+07 -0.6224074363708496 0.23549491167068481\n",
      "[Step 16181] Loss: 9.50e+07 -0.6227617263793945 0.23541156947612762\n",
      "[Step 16182] Loss: 9.39e+07 -0.6229813694953918 0.23536288738250732\n",
      "[Step 16183] Loss: 9.39e+07 -0.623150646686554 0.23534804582595825\n",
      "[Step 16184] Loss: 9.57e+07 -0.6231919527053833 0.2352902740240097\n",
      "[Step 16185] Loss: 9.44e+07 -0.6233076453208923 0.23526057600975037\n",
      "[Step 16186] Loss: 9.58e+07 -0.6236020922660828 0.2352052927017212\n",
      "[Step 16187] Loss: 9.58e+07 -0.6238373517990112 0.23514506220817566\n",
      "[Step 16188] Loss: 9.45e+07 -0.6240918040275574 0.23507905006408691\n",
      "[Step 16189] Loss: 9.48e+07 -0.6243488788604736 0.2350608855485916\n",
      "[Step 16190] Loss: 9.44e+07 -0.6245567798614502 0.23500891029834747\n",
      "[Step 16191] Loss: 9.48e+07 -0.6246923804283142 0.23498332500457764\n",
      "[Step 16192] Loss: 9.50e+07 -0.624853789806366 0.23490329086780548\n",
      "[Step 16193] Loss: 9.49e+07 -0.6250332593917847 0.234852135181427\n",
      "[Step 16194] Loss: 9.57e+07 -0.6251102089881897 0.23478034138679504\n",
      "[Step 16195] Loss: 9.52e+07 -0.6253058910369873 0.23473165929317474\n",
      "[Step 16196] Loss: 9.44e+07 -0.625564694404602 0.23464007675647736\n",
      "[Step 16197] Loss: 9.49e+07 -0.6259070038795471 0.23453032970428467\n",
      "[Step 16198] Loss: 9.48e+07 -0.626329779624939 0.23443296551704407\n",
      "[Step 16199] Loss: 9.51e+07 -0.626876711845398 0.2342885583639145\n",
      "[Step 16200] Loss: 9.47e+07 -0.6273865103721619 0.23416396975517273\n",
      "[Step 16201] Loss: 9.52e+07 -0.6278561949729919 0.23408393561840057\n",
      "[Step 16202] Loss: 9.55e+07 -0.628329336643219 0.23395273089408875\n",
      "[Step 16203] Loss: 9.51e+07 -0.628827691078186 0.2338644415140152\n",
      "[Step 16204] Loss: 9.44e+07 -0.6292589902877808 0.23378358781337738\n",
      "[Step 16205] Loss: 9.41e+07 -0.6296785473823547 0.2336837351322174\n",
      "[Step 16206] Loss: 9.59e+07 -0.6299780607223511 0.23363836109638214\n",
      "[Step 16207] Loss: 9.40e+07 -0.6302542090415955 0.23357564210891724\n",
      "[Step 16208] Loss: 9.49e+07 -0.6305233836174011 0.23350881040096283\n",
      "[Step 16209] Loss: 9.44e+07 -0.6308251619338989 0.23342052102088928\n",
      "[Step 16210] Loss: 9.49e+07 -0.6311465501785278 0.2333371788263321\n",
      "[Step 16211] Loss: 9.56e+07 -0.6314381957054138 0.23323816061019897\n",
      "[Step 16212] Loss: 9.49e+07 -0.6316642165184021 0.2331911325454712\n",
      "[Step 16213] Loss: 9.45e+07 -0.6318948268890381 0.2331441044807434\n",
      "[Step 16214] Loss: 9.45e+07 -0.6320016980171204 0.2330995351076126\n",
      "[Step 16215] Loss: 9.51e+07 -0.6320441365242004 0.2330731451511383\n",
      "[Step 16216] Loss: 9.61e+07 -0.6318846940994263 0.2330772578716278\n",
      "[Step 16217] Loss: 9.48e+07 -0.6317716836929321 0.23305003345012665\n",
      "[Step 16218] Loss: 9.45e+07 -0.6315822005271912 0.23306818306446075\n",
      "[Step 16219] Loss: 9.52e+07 -0.6312584280967712 0.23309871554374695\n",
      "[Step 16220] Loss: 9.45e+07 -0.6309898495674133 0.23313337564468384\n",
      "[Step 16221] Loss: 9.53e+07 -0.6309086680412292 0.2331259399652481\n",
      "[Step 16222] Loss: 9.51e+07 -0.6309362649917603 0.23309046030044556\n",
      "[Step 16223] Loss: 9.44e+07 -0.6309167146682739 0.2330467402935028\n",
      "[Step 16224] Loss: 9.47e+07 -0.630995512008667 0.23300713300704956\n",
      "[Step 16225] Loss: 9.44e+07 -0.6309852004051208 0.23299144208431244\n",
      "[Step 16226] Loss: 9.50e+07 -0.6310022473335266 0.23296256363391876\n",
      "[Step 16227] Loss: 9.57e+07 -0.631284236907959 0.23290398716926575\n",
      "[Step 16228] Loss: 9.51e+07 -0.6315710544586182 0.23281322419643402\n",
      "[Step 16229] Loss: 9.45e+07 -0.6318004727363586 0.23273813724517822\n",
      "[Step 16230] Loss: 9.56e+07 -0.6319275498390198 0.23269934952259064\n",
      "[Step 16231] Loss: 9.49e+07 -0.6319980621337891 0.2326655238866806\n",
      "[Step 16232] Loss: 9.56e+07 -0.6321951746940613 0.23257887363433838\n",
      "[Step 16233] Loss: 9.46e+07 -0.6322503685951233 0.23255577683448792\n",
      "[Step 16234] Loss: 9.46e+07 -0.6322143077850342 0.2325334995985031\n",
      "[Step 16235] Loss: 9.57e+07 -0.6322649121284485 0.23250296711921692\n",
      "[Step 16236] Loss: 9.43e+07 -0.6323882937431335 0.23244933784008026\n",
      "[Step 16237] Loss: 9.49e+07 -0.6325790882110596 0.23240065574645996\n",
      "[Step 16238] Loss: 9.54e+07 -0.6329318284988403 0.23229090869426727\n",
      "[Step 16239] Loss: 9.46e+07 -0.6332674622535706 0.23220756649971008\n",
      "[Step 16240] Loss: 9.42e+07 -0.6334713697433472 0.23212671279907227\n",
      "[Step 16241] Loss: 9.53e+07 -0.6337255835533142 0.23205244541168213\n",
      "[Step 16242] Loss: 9.47e+07 -0.6339455842971802 0.23196497559547424\n",
      "[Step 16243] Loss: 9.45e+07 -0.6342262625694275 0.23189814388751984\n",
      "[Step 16244] Loss: 9.41e+07 -0.6343801617622375 0.23183543980121613\n",
      "[Step 16245] Loss: 9.60e+07 -0.6347151398658752 0.23171083629131317\n",
      "[Step 16246] Loss: 9.46e+07 -0.635057806968689 0.2316431701183319\n",
      "[Step 16247] Loss: 9.46e+07 -0.6353157758712769 0.2315804660320282\n",
      "[Step 16248] Loss: 9.58e+07 -0.6356962323188782 0.231491357088089\n",
      "[Step 16249] Loss: 9.44e+07 -0.6360887885093689 0.23138326406478882\n",
      "[Step 16250] Loss: 9.50e+07 -0.6365349888801575 0.23128671944141388\n",
      "[Step 16251] Loss: 9.52e+07 -0.6369156241416931 0.23118191957473755\n",
      "[Step 16252] Loss: 9.50e+07 -0.637199878692627 0.23111343383789062\n",
      "[Step 16253] Loss: 9.64e+07 -0.6377223134040833 0.23101359605789185\n",
      "[Step 16254] Loss: 9.48e+07 -0.6382340788841248 0.2308642417192459\n",
      "[Step 16255] Loss: 9.63e+07 -0.6385236978530884 0.23080483078956604\n",
      "[Step 16256] Loss: 9.51e+07 -0.6388387680053711 0.230718195438385\n",
      "[Step 16257] Loss: 9.47e+07 -0.6391191482543945 0.23063237965106964\n",
      "[Step 16258] Loss: 9.47e+07 -0.6394615769386292 0.23056720197200775\n",
      "[Step 16259] Loss: 9.55e+07 -0.6398411989212036 0.23047395050525665\n",
      "[Step 16260] Loss: 9.53e+07 -0.6399893760681152 0.23043683171272278\n",
      "[Step 16261] Loss: 9.61e+07 -0.6403307318687439 0.23035761713981628\n",
      "[Step 16262] Loss: 9.52e+07 -0.6407172083854675 0.23026107251644135\n",
      "[Step 16263] Loss: 9.46e+07 -0.6410002112388611 0.2301826775074005\n",
      "[Step 16264] Loss: 9.44e+07 -0.6412213444709778 0.23011915385723114\n",
      "[Step 16265] Loss: 9.43e+07 -0.6415466666221619 0.23003581166267395\n",
      "[Step 16266] Loss: 9.45e+07 -0.6419769525527954 0.2299475222826004\n",
      "[Step 16267] Loss: 9.51e+07 -0.6424752473831177 0.22983282804489136\n",
      "[Step 16268] Loss: 9.48e+07 -0.6429895162582397 0.22971978783607483\n",
      "[Step 16269] Loss: 9.51e+07 -0.6434835195541382 0.22962653636932373\n",
      "[Step 16270] Loss: 9.53e+07 -0.6438174247741699 0.22957290709018707\n",
      "[Step 16271] Loss: 9.45e+07 -0.6440423130989075 0.22951515018939972\n",
      "[Step 16272] Loss: 9.53e+07 -0.6443281769752502 0.22944582998752594\n",
      "[Step 16273] Loss: 9.56e+07 -0.6444728970527649 0.2294021099805832\n",
      "[Step 16274] Loss: 9.49e+07 -0.6446487903594971 0.22934846580028534\n",
      "[Step 16275] Loss: 9.43e+07 -0.6447728276252747 0.2293129861354828\n",
      "[Step 16276] Loss: 9.50e+07 -0.6447945237159729 0.2292643040418625\n",
      "[Step 16277] Loss: 9.45e+07 -0.6448007225990295 0.22921809554100037\n",
      "[Step 16278] Loss: 9.46e+07 -0.6447750329971313 0.22919252514839172\n",
      "[Step 16279] Loss: 9.58e+07 -0.6445329189300537 0.2292255312204361\n",
      "[Step 16280] Loss: 9.47e+07 -0.6443238854408264 0.2292519360780716\n",
      "[Step 16281] Loss: 9.60e+07 -0.6439728140830994 0.22929896414279938\n",
      "[Step 16282] Loss: 9.49e+07 -0.6435306072235107 0.22934846580028534\n",
      "[Step 16283] Loss: 9.42e+07 -0.643085241317749 0.22942768037319183\n",
      "[Step 16284] Loss: 9.49e+07 -0.6426368355751038 0.2294953465461731\n",
      "[Step 16285] Loss: 9.51e+07 -0.6420912742614746 0.22958610951900482\n",
      "[Step 16286] Loss: 9.52e+07 -0.6415438652038574 0.22967687249183655\n",
      "[Step 16287] Loss: 9.43e+07 -0.6410703659057617 0.22975939512252808\n",
      "[Step 16288] Loss: 9.37e+07 -0.6406170725822449 0.2298724353313446\n",
      "[Step 16289] Loss: 9.45e+07 -0.6401084065437317 0.2299475222826004\n",
      "[Step 16290] Loss: 9.53e+07 -0.6397053599357605 0.23000197112560272\n",
      "[Step 16291] Loss: 9.45e+07 -0.639270007610321 0.23008449375629425\n",
      "[Step 16292] Loss: 9.40e+07 -0.6388489007949829 0.23015379905700684\n",
      "[Step 16293] Loss: 9.44e+07 -0.6384119987487793 0.2302008420228958\n",
      "[Step 16294] Loss: 9.53e+07 -0.6379222869873047 0.2302577644586563\n",
      "[Step 16295] Loss: 9.53e+07 -0.63749760389328 0.23028334975242615\n",
      "[Step 16296] Loss: 9.43e+07 -0.6370770931243896 0.23032955825328827\n",
      "[Step 16297] Loss: 9.50e+07 -0.6366240978240967 0.2304343432188034\n",
      "[Step 16298] Loss: 9.48e+07 -0.6362892985343933 0.230473130941391\n",
      "[Step 16299] Loss: 9.53e+07 -0.6361123323440552 0.2304706573486328\n",
      "[Step 16300] Loss: 9.49e+07 -0.635933518409729 0.230473130941391\n",
      "[Step 16301] Loss: 9.63e+07 -0.636019766330719 0.23041372001171112\n",
      "[Step 16302] Loss: 9.49e+07 -0.6360484957695007 0.23036256432533264\n",
      "[Step 16303] Loss: 9.56e+07 -0.6361583471298218 0.23030975461006165\n",
      "[Step 16304] Loss: 9.46e+07 -0.6362714767456055 0.23025034368038177\n",
      "[Step 16305] Loss: 9.44e+07 -0.6362564563751221 0.23024044930934906\n",
      "[Step 16306] Loss: 9.47e+07 -0.6362916827201843 0.23021404445171356\n",
      "[Step 16307] Loss: 9.48e+07 -0.6364206075668335 0.23016618192195892\n",
      "[Step 16308] Loss: 9.44e+07 -0.6364879608154297 0.23011666536331177\n",
      "[Step 16309] Loss: 9.48e+07 -0.636498749256134 0.23009604215621948\n",
      "[Step 16310] Loss: 9.45e+07 -0.6365519165992737 0.2300572693347931\n",
      "[Step 16311] Loss: 9.51e+07 -0.636523962020874 0.2300366312265396\n",
      "[Step 16312] Loss: 9.44e+07 -0.6365030407905579 0.23001600801944733\n",
      "[Step 16313] Loss: 9.47e+07 -0.6364535093307495 0.23000527918338776\n",
      "[Step 16314] Loss: 9.45e+07 -0.636503279209137 0.22996319830417633\n",
      "[Step 16315] Loss: 9.50e+07 -0.6364726424217224 0.22994999587535858\n",
      "[Step 16316] Loss: 9.41e+07 -0.6364341974258423 0.2299433946609497\n",
      "[Step 16317] Loss: 9.49e+07 -0.636339008808136 0.22997061908245087\n",
      "[Step 16318] Loss: 9.45e+07 -0.6361753344535828 0.2300044596195221\n",
      "[Step 16319] Loss: 9.45e+07 -0.6360737681388855 0.2299780547618866\n",
      "[Step 16320] Loss: 9.54e+07 -0.6359424591064453 0.22998876869678497\n",
      "[Step 16321] Loss: 9.54e+07 -0.6358556151390076 0.23000362515449524\n",
      "[Step 16322] Loss: 9.51e+07 -0.635648787021637 0.23004406690597534\n",
      "[Step 16323] Loss: 9.50e+07 -0.6354864835739136 0.2300630360841751\n",
      "[Step 16324] Loss: 9.49e+07 -0.6353586316108704 0.23007623851299286\n",
      "[Step 16325] Loss: 9.39e+07 -0.63518226146698 0.2301117181777954\n",
      "[Step 16326] Loss: 9.53e+07 -0.6349275708198547 0.23016700148582458\n",
      "[Step 16327] Loss: 9.50e+07 -0.6345839500427246 0.230256125330925\n",
      "[Step 16328] Loss: 9.51e+07 -0.6341931819915771 0.2303312122821808\n",
      "[Step 16329] Loss: 9.46e+07 -0.6338585615158081 0.23036174476146698\n",
      "[Step 16330] Loss: 9.48e+07 -0.6335063576698303 0.23043186962604523\n",
      "[Step 16331] Loss: 9.42e+07 -0.6331533193588257 0.23049788177013397\n",
      "[Step 16332] Loss: 9.52e+07 -0.6329687237739563 0.23052263259887695\n",
      "[Step 16333] Loss: 9.52e+07 -0.6328765153884888 0.23048138618469238\n",
      "[Step 16334] Loss: 9.52e+07 -0.6329028010368347 0.23044507205486298\n",
      "[Step 16335] Loss: 9.50e+07 -0.632983922958374 0.23041372001171112\n",
      "[Step 16336] Loss: 9.50e+07 -0.6330368518829346 0.23041124641895294\n",
      "[Step 16337] Loss: 9.44e+07 -0.633074164390564 0.2303897887468338\n",
      "[Step 16338] Loss: 9.47e+07 -0.6331080198287964 0.2303592562675476\n",
      "[Step 16339] Loss: 9.54e+07 -0.6331163644790649 0.2303270846605301\n",
      "[Step 16340] Loss: 9.44e+07 -0.6331368684768677 0.2303270846605301\n",
      "[Step 16341] Loss: 9.45e+07 -0.6331450343132019 0.23031140863895416\n",
      "[Step 16342] Loss: 9.44e+07 -0.6331417560577393 0.2303048074245453\n",
      "[Step 16343] Loss: 9.53e+07 -0.6332324147224426 0.2302759289741516\n",
      "[Step 16344] Loss: 9.51e+07 -0.6332021951675415 0.23028995096683502\n",
      "[Step 16345] Loss: 9.52e+07 -0.6331497430801392 0.23028913140296936\n",
      "[Step 16346] Loss: 9.50e+07 -0.633256196975708 0.23027180135250092\n",
      "[Step 16347] Loss: 9.48e+07 -0.6334453821182251 0.23021981120109558\n",
      "[Step 16348] Loss: 9.50e+07 -0.6337169408798218 0.23014143109321594\n",
      "[Step 16349] Loss: 9.47e+07 -0.6339281797409058 0.23008449375629425\n",
      "[Step 16350] Loss: 9.55e+07 -0.6342235803604126 0.23000115156173706\n",
      "[Step 16351] Loss: 9.56e+07 -0.6345152854919434 0.22990378737449646\n",
      "[Step 16352] Loss: 9.51e+07 -0.6348841190338135 0.229775071144104\n",
      "[Step 16353] Loss: 9.44e+07 -0.6351885199546814 0.2296983301639557\n",
      "[Step 16354] Loss: 9.55e+07 -0.635528028011322 0.22960425913333893\n",
      "[Step 16355] Loss: 9.46e+07 -0.6357890367507935 0.22953495383262634\n",
      "[Step 16356] Loss: 9.44e+07 -0.6360334157943726 0.2294549196958542\n",
      "[Step 16357] Loss: 9.42e+07 -0.6362542510032654 0.2293938547372818\n",
      "[Step 16358] Loss: 9.50e+07 -0.6362898349761963 0.22937405109405518\n",
      "[Step 16359] Loss: 9.49e+07 -0.6363070607185364 0.22936414182186127\n",
      "[Step 16360] Loss: 9.55e+07 -0.6363087296485901 0.22932866215705872\n",
      "[Step 16361] Loss: 9.49e+07 -0.6362794041633606 0.22932042181491852\n",
      "[Step 16362] Loss: 9.52e+07 -0.6362195611000061 0.22930803894996643\n",
      "[Step 16363] Loss: 9.57e+07 -0.6363368630409241 0.22928576171398163\n",
      "[Step 16364] Loss: 9.40e+07 -0.6364201903343201 0.2292478084564209\n",
      "[Step 16365] Loss: 9.42e+07 -0.6365545392036438 0.22917848825454712\n",
      "[Step 16366] Loss: 9.45e+07 -0.6366391777992249 0.2291380614042282\n",
      "[Step 16367] Loss: 9.45e+07 -0.6366912722587585 0.22909845411777496\n",
      "[Step 16368] Loss: 9.50e+07 -0.6367713809013367 0.22905637323856354\n",
      "[Step 16369] Loss: 9.48e+07 -0.6368433833122253 0.22901098430156708\n",
      "[Step 16370] Loss: 9.52e+07 -0.6369909048080444 0.22894909977912903\n",
      "[Step 16371] Loss: 9.51e+07 -0.6372743248939514 0.22889216244220734\n",
      "[Step 16372] Loss: 9.48e+07 -0.6375675797462463 0.22882285714149475\n",
      "[Step 16373] Loss: 9.47e+07 -0.6378465890884399 0.22875849902629852\n",
      "[Step 16374] Loss: 9.46e+07 -0.6381070017814636 0.22868341207504272\n",
      "[Step 16375] Loss: 9.50e+07 -0.638322651386261 0.22862482070922852\n",
      "[Step 16376] Loss: 9.51e+07 -0.6387032270431519 0.22852085530757904\n",
      "[Step 16377] Loss: 9.46e+07 -0.6390892863273621 0.22843338549137115\n",
      "[Step 16378] Loss: 9.52e+07 -0.6394544243812561 0.2283046692609787\n",
      "[Step 16379] Loss: 9.50e+07 -0.6398890018463135 0.22821885347366333\n",
      "[Step 16380] Loss: 9.59e+07 -0.6405507326126099 0.22804971039295197\n",
      "[Step 16381] Loss: 9.42e+07 -0.6411784887313843 0.2279028296470642\n",
      "[Step 16382] Loss: 9.46e+07 -0.6416537165641785 0.2278013378381729\n",
      "[Step 16383] Loss: 9.54e+07 -0.642181396484375 0.22767674922943115\n",
      "[Step 16384] Loss: 9.54e+07 -0.6425895690917969 0.22759009897708893\n",
      "[Step 16385] Loss: 9.46e+07 -0.6429903507232666 0.22748036682605743\n",
      "[Step 16386] Loss: 9.48e+07 -0.6432677507400513 0.22737227380275726\n",
      "[Step 16387] Loss: 9.50e+07 -0.6434579491615295 0.2272988259792328\n",
      "[Step 16388] Loss: 9.51e+07 -0.6435695290565491 0.22724106907844543\n",
      "[Step 16389] Loss: 9.41e+07 -0.6436647772789001 0.22719404101371765\n",
      "[Step 16390] Loss: 9.54e+07 -0.6437965035438538 0.2271503061056137\n",
      "[Step 16391] Loss: 9.51e+07 -0.6438820958137512 0.2271222472190857\n",
      "[Step 16392] Loss: 9.47e+07 -0.6439330577850342 0.2270875871181488\n",
      "[Step 16393] Loss: 9.47e+07 -0.6440936923027039 0.22699929773807526\n",
      "[Step 16394] Loss: 9.49e+07 -0.6441079378128052 0.22696217894554138\n",
      "[Step 16395] Loss: 9.51e+07 -0.6442486047744751 0.226901113986969\n",
      "[Step 16396] Loss: 9.63e+07 -0.6442523002624512 0.22689120471477509\n",
      "[Step 16397] Loss: 9.59e+07 -0.6441394686698914 0.22688543796539307\n",
      "[Step 16398] Loss: 9.55e+07 -0.6439228653907776 0.22692421078681946\n",
      "[Step 16399] Loss: 9.49e+07 -0.6438814997673035 0.22693081200122833\n",
      "[Step 16400] Loss: 9.51e+07 -0.64398193359375 0.22689945995807648\n",
      "[Step 16401] Loss: 9.50e+07 -0.6441503167152405 0.22684170305728912\n",
      "[Step 16402] Loss: 9.40e+07 -0.6442968249320984 0.22680869698524475\n",
      "[Step 16403] Loss: 9.55e+07 -0.6443255543708801 0.22679220139980316\n",
      "[Step 16404] Loss: 9.46e+07 -0.6443958878517151 0.22676827013492584\n",
      "[Step 16405] Loss: 9.56e+07 -0.644622266292572 0.22672948241233826\n",
      "[Step 16406] Loss: 9.49e+07 -0.6448214054107666 0.22668161988258362\n",
      "[Step 16407] Loss: 9.46e+07 -0.6449297070503235 0.2266230434179306\n",
      "[Step 16408] Loss: 9.59e+07 -0.6448379755020142 0.22659003734588623\n",
      "[Step 16409] Loss: 9.50e+07 -0.6446794867515564 0.22659169137477875\n",
      "[Step 16410] Loss: 9.51e+07 -0.6445536613464355 0.2265883833169937\n",
      "[Step 16411] Loss: 9.40e+07 -0.6444385051727295 0.22657518088817596\n",
      "[Step 16412] Loss: 9.47e+07 -0.6443419456481934 0.22656197845935822\n",
      "[Step 16413] Loss: 9.49e+07 -0.6441696882247925 0.22657601535320282\n",
      "[Step 16414] Loss: 9.54e+07 -0.644138514995575 0.22654961049556732\n",
      "[Step 16415] Loss: 9.46e+07 -0.6439794898033142 0.22654713690280914\n",
      "[Step 16416] Loss: 9.46e+07 -0.6439012289047241 0.2265298068523407\n",
      "[Step 16417] Loss: 9.50e+07 -0.6439008116722107 0.2265380471944809\n",
      "[Step 16418] Loss: 9.48e+07 -0.6439180374145508 0.22651082277297974\n",
      "[Step 16419] Loss: 9.45e+07 -0.6439747214317322 0.22646132111549377\n",
      "[Step 16420] Loss: 9.56e+07 -0.6439228653907776 0.22643986344337463\n",
      "[Step 16421] Loss: 9.45e+07 -0.6439253091812134 0.2264184057712555\n",
      "[Step 16422] Loss: 9.54e+07 -0.6441321969032288 0.2263755053281784\n",
      "[Step 16423] Loss: 9.52e+07 -0.6445648074150085 0.22623193264007568\n",
      "[Step 16424] Loss: 9.52e+07 -0.6449155807495117 0.22612713277339935\n",
      "[Step 16425] Loss: 9.47e+07 -0.6451855301856995 0.22603224217891693\n",
      "[Step 16426] Loss: 9.55e+07 -0.6453019976615906 0.2260083109140396\n",
      "[Step 16427] Loss: 9.63e+07 -0.6455838680267334 0.2259373515844345\n",
      "[Step 16428] Loss: 9.55e+07 -0.6459541320800781 0.22584080696105957\n",
      "[Step 16429] Loss: 9.51e+07 -0.6463583707809448 0.2257508784532547\n",
      "[Step 16430] Loss: 9.45e+07 -0.6467376351356506 0.2256353497505188\n",
      "[Step 16431] Loss: 9.51e+07 -0.6470521688461304 0.22557593882083893\n",
      "[Step 16432] Loss: 9.47e+07 -0.6473170518875122 0.22550085186958313\n",
      "[Step 16433] Loss: 9.44e+07 -0.6474996209144592 0.22546042501926422\n",
      "[Step 16434] Loss: 9.46e+07 -0.6476739048957825 0.2254001945257187\n",
      "[Step 16435] Loss: 9.56e+07 -0.6477857828140259 0.22535893321037292\n",
      "[Step 16436] Loss: 9.42e+07 -0.6479285955429077 0.2253350019454956\n",
      "[Step 16437] Loss: 9.50e+07 -0.647921621799469 0.22533665597438812\n",
      "[Step 16438] Loss: 9.47e+07 -0.6479907035827637 0.22530199587345123\n",
      "[Step 16439] Loss: 9.51e+07 -0.6479249000549316 0.2252582609653473\n",
      "[Step 16440] Loss: 9.59e+07 -0.647617757320404 0.22533994913101196\n",
      "[Step 16441] Loss: 9.51e+07 -0.647331714630127 0.22539936006069183\n",
      "[Step 16442] Loss: 9.43e+07 -0.6469879150390625 0.22547610104084015\n",
      "[Step 16443] Loss: 9.53e+07 -0.6466763615608215 0.22550828754901886\n",
      "[Step 16444] Loss: 9.50e+07 -0.6462913155555725 0.2255462408065796\n",
      "[Step 16445] Loss: 9.44e+07 -0.6459348201751709 0.2256089448928833\n",
      "[Step 16446] Loss: 9.51e+07 -0.6458246111869812 0.2255866676568985\n",
      "[Step 16447] Loss: 9.44e+07 -0.6457200050354004 0.22563205659389496\n",
      "[Step 16448] Loss: 9.51e+07 -0.6456533670425415 0.2256312221288681\n",
      "[Step 16449] Loss: 9.49e+07 -0.6456829905509949 0.22561554610729218\n",
      "[Step 16450] Loss: 9.47e+07 -0.6457076072692871 0.22559326887130737\n",
      "[Step 16451] Loss: 9.55e+07 -0.6455619931221008 0.22563700377941132\n",
      "[Step 16452] Loss: 9.53e+07 -0.6453028321266174 0.2256617546081543\n",
      "[Step 16453] Loss: 9.43e+07 -0.6451382040977478 0.22565846145153046\n",
      "[Step 16454] Loss: 9.56e+07 -0.6449854373931885 0.22567248344421387\n",
      "[Step 16455] Loss: 9.39e+07 -0.644900918006897 0.2256716638803482\n",
      "[Step 16456] Loss: 9.52e+07 -0.6448670029640198 0.22568239271640778\n",
      "[Step 16457] Loss: 9.47e+07 -0.6449664831161499 0.22565846145153046\n",
      "[Step 16458] Loss: 9.69e+07 -0.6451053619384766 0.22559821605682373\n",
      "[Step 16459] Loss: 9.49e+07 -0.6452102661132812 0.22557346522808075\n",
      "[Step 16460] Loss: 9.49e+07 -0.6453405618667603 0.22553963959217072\n",
      "[Step 16461] Loss: 9.47e+07 -0.6454839110374451 0.22551241517066956\n",
      "[Step 16462] Loss: 9.50e+07 -0.6455128192901611 0.22548352181911469\n",
      "[Step 16463] Loss: 9.52e+07 -0.6455836296081543 0.22544144093990326\n",
      "[Step 16464] Loss: 9.48e+07 -0.6455510258674622 0.2254265993833542\n",
      "[Step 16465] Loss: 9.45e+07 -0.6455709934234619 0.22542081773281097\n",
      "[Step 16466] Loss: 9.39e+07 -0.6455880999565125 0.22539111971855164\n",
      "[Step 16467] Loss: 9.49e+07 -0.6457140445709229 0.2253696620464325\n",
      "[Step 16468] Loss: 9.52e+07 -0.6457979679107666 0.22534078359603882\n",
      "[Step 16469] Loss: 9.46e+07 -0.6459351778030396 0.22530199587345123\n",
      "[Step 16470] Loss: 9.50e+07 -0.6460387706756592 0.22526156902313232\n",
      "[Step 16471] Loss: 9.55e+07 -0.6462483406066895 0.2252277284860611\n",
      "[Step 16472] Loss: 9.48e+07 -0.6464869976043701 0.22514522075653076\n",
      "[Step 16473] Loss: 9.52e+07 -0.6467938423156738 0.22508004307746887\n",
      "[Step 16474] Loss: 9.56e+07 -0.6469587683677673 0.22499999403953552\n",
      "[Step 16475] Loss: 9.43e+07 -0.6471171975135803 0.22493645548820496\n",
      "[Step 16476] Loss: 9.47e+07 -0.6472040414810181 0.2249191403388977\n",
      "[Step 16477] Loss: 9.53e+07 -0.6472622156143188 0.22487127780914307\n",
      "[Step 16478] Loss: 9.46e+07 -0.647343099117279 0.22479288280010223\n",
      "[Step 16479] Loss: 9.51e+07 -0.6473441123962402 0.2247730791568756\n",
      "[Step 16480] Loss: 9.49e+07 -0.6473763585090637 0.22472026944160461\n",
      "[Step 16481] Loss: 9.49e+07 -0.6473085880279541 0.22470955550670624\n",
      "[Step 16482] Loss: 9.50e+07 -0.6471765041351318 0.22469304502010345\n",
      "[Step 16483] Loss: 9.51e+07 -0.6470739245414734 0.22468891739845276\n",
      "[Step 16484] Loss: 9.49e+07 -0.6469758749008179 0.2247326523065567\n",
      "[Step 16485] Loss: 9.52e+07 -0.646977961063385 0.22475987672805786\n",
      "[Step 16486] Loss: 9.55e+07 -0.6469056010246277 0.2247466742992401\n",
      "[Step 16487] Loss: 9.48e+07 -0.6468932628631592 0.22473759949207306\n",
      "[Step 16488] Loss: 9.42e+07 -0.6468849778175354 0.22473183274269104\n",
      "[Step 16489] Loss: 9.50e+07 -0.6467609405517578 0.2247425615787506\n",
      "[Step 16490] Loss: 9.60e+07 -0.6468527913093567 0.2247045934200287\n",
      "[Step 16491] Loss: 9.50e+07 -0.6468397378921509 0.2246781885623932\n",
      "[Step 16492] Loss: 9.46e+07 -0.6468004584312439 0.22468562424182892\n",
      "[Step 16493] Loss: 9.43e+07 -0.6468313932418823 0.22467489540576935\n",
      "[Step 16494] Loss: 9.39e+07 -0.6468327045440674 0.22464023530483246\n",
      "[Step 16495] Loss: 9.50e+07 -0.6468666791915894 0.22463694214820862\n",
      "[Step 16496] Loss: 9.49e+07 -0.6468484997749329 0.22463694214820862\n",
      "[Step 16497] Loss: 9.52e+07 -0.6467444896697998 0.22465014457702637\n",
      "[Step 16498] Loss: 9.57e+07 -0.6468844413757324 0.22460806369781494\n",
      "[Step 16499] Loss: 9.44e+07 -0.6469364166259766 0.22455359995365143\n",
      "[Step 16500] Loss: 9.44e+07 -0.6469764709472656 0.22454452514648438\n",
      "[Step 16501] Loss: 9.53e+07 -0.646831750869751 0.2245907336473465\n",
      "[Step 16502] Loss: 9.51e+07 -0.6466504335403442 0.2246130108833313\n",
      "[Step 16503] Loss: 9.48e+07 -0.6464740633964539 0.22464601695537567\n",
      "[Step 16504] Loss: 9.47e+07 -0.6463321447372437 0.22468067705631256\n",
      "[Step 16505] Loss: 9.38e+07 -0.6462221741676331 0.22469304502010345\n",
      "[Step 16506] Loss: 9.45e+07 -0.6460894346237183 0.2247021198272705\n",
      "[Step 16507] Loss: 9.44e+07 -0.6459694504737854 0.2247367799282074\n",
      "[Step 16508] Loss: 9.52e+07 -0.6459171772003174 0.22476236522197723\n",
      "[Step 16509] Loss: 9.45e+07 -0.6458488702774048 0.224753275513649\n",
      "[Step 16510] Loss: 9.52e+07 -0.6456975340843201 0.22476813197135925\n",
      "[Step 16511] Loss: 9.44e+07 -0.6455919146537781 0.22476236522197723\n",
      "[Step 16512] Loss: 9.49e+07 -0.6455702185630798 0.22476565837860107\n",
      "[Step 16513] Loss: 9.43e+07 -0.6455342769622803 0.22478298842906952\n",
      "[Step 16514] Loss: 9.45e+07 -0.6455986499786377 0.22474007308483124\n",
      "[Step 16515] Loss: 9.49e+07 -0.6456472277641296 0.22470706701278687\n",
      "[Step 16516] Loss: 9.47e+07 -0.6457000970840454 0.22468149662017822\n",
      "[Step 16517] Loss: 9.50e+07 -0.6457741260528564 0.22466003894805908\n",
      "[Step 16518] Loss: 9.45e+07 -0.6459091901779175 0.22464518249034882\n",
      "[Step 16519] Loss: 9.62e+07 -0.6461988687515259 0.22458989918231964\n",
      "[Step 16520] Loss: 9.48e+07 -0.6465831398963928 0.2244793325662613\n",
      "[Step 16521] Loss: 9.45e+07 -0.6470046639442444 0.22437536716461182\n",
      "[Step 16522] Loss: 9.50e+07 -0.6475502252578735 0.22425737977027893\n",
      "[Step 16523] Loss: 9.56e+07 -0.6482466459274292 0.22410637140274048\n",
      "[Step 16524] Loss: 9.46e+07 -0.648855447769165 0.22399993240833282\n",
      "[Step 16525] Loss: 9.47e+07 -0.6493203639984131 0.22388029098510742\n",
      "[Step 16526] Loss: 9.51e+07 -0.6498147249221802 0.2237713634967804\n",
      "[Step 16527] Loss: 9.50e+07 -0.6502649188041687 0.2236698716878891\n",
      "[Step 16528] Loss: 9.47e+07 -0.6507421731948853 0.22356177866458893\n",
      "[Step 16529] Loss: 9.46e+07 -0.6512017250061035 0.2234182059764862\n",
      "[Step 16530] Loss: 9.49e+07 -0.6515134572982788 0.22334229946136475\n",
      "[Step 16531] Loss: 9.45e+07 -0.65172278881073 0.22328370809555054\n",
      "[Step 16532] Loss: 9.39e+07 -0.6519410014152527 0.22321027517318726\n",
      "[Step 16533] Loss: 9.70e+07 -0.6525779366493225 0.2230270951986313\n",
      "[Step 16534] Loss: 9.43e+07 -0.6530484557151794 0.22291900217533112\n",
      "[Step 16535] Loss: 9.48e+07 -0.6533581018447876 0.22283731400966644\n",
      "[Step 16536] Loss: 9.43e+07 -0.6536558270454407 0.22276470065116882\n",
      "[Step 16537] Loss: 9.46e+07 -0.6539188027381897 0.22269292175769806\n",
      "[Step 16538] Loss: 9.55e+07 -0.6543164849281311 0.22260545194149017\n",
      "[Step 16539] Loss: 9.46e+07 -0.6545717716217041 0.22250477969646454\n",
      "[Step 16540] Loss: 9.50e+07 -0.6546453237533569 0.22244620323181152\n",
      "[Step 16541] Loss: 9.46e+07 -0.6547480225563049 0.22239834070205688\n",
      "[Step 16542] Loss: 9.43e+07 -0.6548554301261902 0.22234883904457092\n",
      "[Step 16543] Loss: 9.48e+07 -0.6550384163856506 0.22232159972190857\n",
      "[Step 16544] Loss: 9.52e+07 -0.6552553772926331 0.22227291762828827\n",
      "[Step 16545] Loss: 9.44e+07 -0.6554467678070068 0.22223001718521118\n",
      "[Step 16546] Loss: 9.56e+07 -0.6556488871574402 0.22219370305538177\n",
      "[Step 16547] Loss: 9.45e+07 -0.6558408141136169 0.22218380868434906\n",
      "[Step 16548] Loss: 9.51e+07 -0.655989944934845 0.22216317057609558\n",
      "[Step 16549] Loss: 9.51e+07 -0.6562988758087158 0.22208891808986664\n",
      "[Step 16550] Loss: 9.46e+07 -0.6565801501274109 0.22202207148075104\n",
      "[Step 16551] Loss: 9.44e+07 -0.6569207906723022 0.2219478189945221\n",
      "[Step 16552] Loss: 9.45e+07 -0.657216489315033 0.22188015282154083\n",
      "[Step 16553] Loss: 9.43e+07 -0.6574864387512207 0.22181497514247894\n",
      "[Step 16554] Loss: 9.56e+07 -0.6576177477836609 0.22177289426326752\n",
      "[Step 16555] Loss: 9.53e+07 -0.6577363014221191 0.22176463901996613\n",
      "[Step 16556] Loss: 9.56e+07 -0.657675564289093 0.22179928421974182\n",
      "[Step 16557] Loss: 9.52e+07 -0.6575474143028259 0.22182981669902802\n",
      "[Step 16558] Loss: 9.46e+07 -0.6573700308799744 0.22187933325767517\n",
      "[Step 16559] Loss: 9.55e+07 -0.6571053266525269 0.2219436913728714\n",
      "[Step 16560] Loss: 9.54e+07 -0.656821608543396 0.2219758778810501\n",
      "[Step 16561] Loss: 9.55e+07 -0.6565577983856201 0.22203610837459564\n",
      "[Step 16562] Loss: 9.56e+07 -0.6563152074813843 0.22208644449710846\n",
      "[Step 16563] Loss: 9.51e+07 -0.6560877561569214 0.222146674990654\n",
      "[Step 16564] Loss: 9.49e+07 -0.6558720469474792 0.22218628227710724\n",
      "[Step 16565] Loss: 9.46e+07 -0.6556444764137268 0.22225311398506165\n",
      "[Step 16566] Loss: 9.50e+07 -0.655502200126648 0.22228612005710602\n",
      "[Step 16567] Loss: 9.42e+07 -0.6553491950035095 0.2223290354013443\n",
      "[Step 16568] Loss: 9.55e+07 -0.6552863121032715 0.22232243418693542\n",
      "[Step 16569] Loss: 9.54e+07 -0.6551600098609924 0.2223232537508011\n",
      "[Step 16570] Loss: 9.83e+07 -0.6555837392807007 0.22226715087890625\n",
      "[Step 16571] Loss: 9.45e+07 -0.6559439897537231 0.2221483290195465\n",
      "[Step 16572] Loss: 9.42e+07 -0.6562108993530273 0.2220773696899414\n",
      "[Step 16573] Loss: 9.43e+07 -0.6564385890960693 0.2220270335674286\n",
      "[Step 16574] Loss: 9.39e+07 -0.6566274762153625 0.2219577133655548\n",
      "[Step 16575] Loss: 9.52e+07 -0.6568945050239563 0.2219090312719345\n",
      "[Step 16576] Loss: 9.49e+07 -0.657086968421936 0.22182568907737732\n",
      "[Step 16577] Loss: 9.48e+07 -0.6572966575622559 0.22175803780555725\n",
      "[Step 16578] Loss: 9.43e+07 -0.6574692726135254 0.2217390537261963\n",
      "[Step 16579] Loss: 9.45e+07 -0.6576040387153625 0.22167634963989258\n",
      "[Step 16580] Loss: 9.47e+07 -0.6577125787734985 0.22162766754627228\n",
      "[Step 16581] Loss: 9.46e+07 -0.6577527523040771 0.22159548103809357\n",
      "[Step 16582] Loss: 9.42e+07 -0.6577209234237671 0.22158311307430267\n",
      "[Step 16583] Loss: 9.44e+07 -0.6577717661857605 0.2215501070022583\n",
      "[Step 16584] Loss: 9.40e+07 -0.6578311920166016 0.22151710093021393\n",
      "[Step 16585] Loss: 9.48e+07 -0.6579775214195251 0.22144530713558197\n",
      "[Step 16586] Loss: 9.42e+07 -0.658161997795105 0.22140651941299438\n",
      "[Step 16587] Loss: 9.64e+07 -0.6585907340049744 0.22126954793930054\n",
      "[Step 16588] Loss: 9.50e+07 -0.6591452956199646 0.22111277282238007\n",
      "[Step 16589] Loss: 9.49e+07 -0.6597588062286377 0.22093866765499115\n",
      "[Step 16590] Loss: 9.44e+07 -0.6603322625160217 0.22077034413814545\n",
      "[Step 16591] Loss: 9.48e+07 -0.6607608795166016 0.22063584625720978\n",
      "[Step 16592] Loss: 9.49e+07 -0.6611303687095642 0.22055910527706146\n",
      "[Step 16593] Loss: 9.47e+07 -0.661553680896759 0.22046421468257904\n",
      "[Step 16594] Loss: 9.70e+07 -0.6623055934906006 0.22028599679470062\n",
      "[Step 16595] Loss: 9.47e+07 -0.6630347967147827 0.22010281682014465\n",
      "[Step 16596] Loss: 9.52e+07 -0.6637186408042908 0.2199254035949707\n",
      "[Step 16597] Loss: 9.56e+07 -0.6643118262290955 0.21977770328521729\n",
      "[Step 16598] Loss: 9.46e+07 -0.6648249626159668 0.21965640783309937\n",
      "[Step 16599] Loss: 9.48e+07 -0.6651990413665771 0.21958710253238678\n",
      "[Step 16600] Loss: 9.42e+07 -0.6654611825942993 0.21951943635940552\n",
      "[Step 16601] Loss: 9.49e+07 -0.6657238006591797 0.21945177018642426\n",
      "[Step 16602] Loss: 9.51e+07 -0.6660895943641663 0.21934698522090912\n",
      "[Step 16603] Loss: 9.43e+07 -0.6665071845054626 0.21925704181194305\n",
      "[Step 16604] Loss: 9.48e+07 -0.6668160557746887 0.21916133165359497\n",
      "[Step 16605] Loss: 9.41e+07 -0.6670471429824829 0.21910768747329712\n",
      "[Step 16606] Loss: 9.58e+07 -0.6671074032783508 0.21909697353839874\n",
      "[Step 16607] Loss: 9.50e+07 -0.6671002507209778 0.21906478703022003\n",
      "[Step 16608] Loss: 9.49e+07 -0.6671167612075806 0.21908541023731232\n",
      "[Step 16609] Loss: 9.55e+07 -0.6671252250671387 0.21907633543014526\n",
      "[Step 16610] Loss: 9.49e+07 -0.6671053171157837 0.2190697342157364\n",
      "[Step 16611] Loss: 9.43e+07 -0.6670801043510437 0.21906396746635437\n",
      "[Step 16612] Loss: 9.49e+07 -0.6670613288879395 0.2190755158662796\n",
      "[Step 16613] Loss: 9.47e+07 -0.6670218706130981 0.21907798945903778\n",
      "[Step 16614] Loss: 9.53e+07 -0.667121171951294 0.219083771109581\n",
      "[Step 16615] Loss: 9.49e+07 -0.6672870516777039 0.2190573662519455\n",
      "[Step 16616] Loss: 9.50e+07 -0.6673324108123779 0.21906809508800507\n",
      "[Step 16617] Loss: 9.51e+07 -0.667525053024292 0.21902188658714294\n",
      "[Step 16618] Loss: 9.49e+07 -0.6678297519683838 0.21896660327911377\n",
      "[Step 16619] Loss: 9.44e+07 -0.6681092977523804 0.21890470385551453\n",
      "[Step 16620] Loss: 9.44e+07 -0.6682658195495605 0.21890388429164886\n",
      "[Step 16621] Loss: 9.52e+07 -0.6682541966438293 0.21887171268463135\n",
      "[Step 16622] Loss: 9.47e+07 -0.6683388948440552 0.21883787214756012\n",
      "[Step 16623] Loss: 9.47e+07 -0.6684302091598511 0.21881477534770966\n",
      "[Step 16624] Loss: 9.47e+07 -0.6686099171638489 0.21875371038913727\n",
      "[Step 16625] Loss: 9.51e+07 -0.6688038110733032 0.21867944300174713\n",
      "[Step 16626] Loss: 9.45e+07 -0.6688931584358215 0.21865221858024597\n",
      "[Step 16627] Loss: 9.45e+07 -0.6690205931663513 0.21862168610095978\n",
      "[Step 16628] Loss: 9.40e+07 -0.6691446900367737 0.218574658036232\n",
      "[Step 16629] Loss: 9.51e+07 -0.6692478656768799 0.2185383439064026\n",
      "[Step 16630] Loss: 9.49e+07 -0.669390857219696 0.21848471462726593\n",
      "[Step 16631] Loss: 9.77e+07 -0.6700006723403931 0.21833206713199615\n",
      "[Step 16632] Loss: 9.49e+07 -0.6706352233886719 0.2181893140077591\n",
      "[Step 16633] Loss: 9.60e+07 -0.6710852384567261 0.2180754542350769\n",
      "[Step 16634] Loss: 9.47e+07 -0.6714733839035034 0.21798056364059448\n",
      "[Step 16635] Loss: 9.50e+07 -0.6718167066574097 0.21788649260997772\n",
      "[Step 16636] Loss: 9.62e+07 -0.6723060607910156 0.21772229671478271\n",
      "[Step 16637] Loss: 9.48e+07 -0.6728300452232361 0.21759027242660522\n",
      "[Step 16638] Loss: 9.50e+07 -0.6733976006507874 0.21751518547534943\n",
      "[Step 16639] Loss: 9.48e+07 -0.6739381551742554 0.21739470958709717\n",
      "[Step 16640] Loss: 9.55e+07 -0.6744123101234436 0.2172783613204956\n",
      "[Step 16641] Loss: 9.45e+07 -0.6748785376548767 0.21716119349002838\n",
      "[Step 16642] Loss: 9.52e+07 -0.6753644943237305 0.2170432060956955\n",
      "[Step 16643] Loss: 9.51e+07 -0.6758143901824951 0.21694006025791168\n",
      "[Step 16644] Loss: 9.54e+07 -0.6761568784713745 0.2168608456850052\n",
      "[Step 16645] Loss: 9.44e+07 -0.6765382289886475 0.21681134402751923\n",
      "[Step 16646] Loss: 9.60e+07 -0.6770325899124146 0.21672387421131134\n",
      "[Step 16647] Loss: 9.52e+07 -0.6774715185165405 0.21662567555904388\n",
      "[Step 16648] Loss: 9.56e+07 -0.6780514717102051 0.21650190651416779\n",
      "[Step 16649] Loss: 9.38e+07 -0.6785056591033936 0.21641114354133606\n",
      "[Step 16650] Loss: 9.52e+07 -0.6789250373840332 0.21631790697574615\n",
      "[Step 16651] Loss: 9.47e+07 -0.6792632937431335 0.21623703837394714\n",
      "[Step 16652] Loss: 9.58e+07 -0.6797422170639038 0.21614298224449158\n",
      "[Step 16653] Loss: 9.55e+07 -0.6802884936332703 0.21603158116340637\n",
      "[Step 16654] Loss: 9.51e+07 -0.680674135684967 0.21592596173286438\n",
      "[Step 16655] Loss: 9.60e+07 -0.6808784604072571 0.21585747599601746\n",
      "[Step 16656] Loss: 9.50e+07 -0.6811532974243164 0.21579064428806305\n",
      "[Step 16657] Loss: 9.44e+07 -0.6815217137336731 0.21570482850074768\n",
      "[Step 16658] Loss: 9.46e+07 -0.6818398833274841 0.21558848023414612\n",
      "[Step 16659] Loss: 9.54e+07 -0.6822340488433838 0.2155034989118576\n",
      "[Step 16660] Loss: 9.49e+07 -0.6826493144035339 0.21540530025959015\n",
      "[Step 16661] Loss: 9.42e+07 -0.6830753684043884 0.21532031893730164\n",
      "[Step 16662] Loss: 9.54e+07 -0.6834532618522644 0.21524357795715332\n",
      "[Step 16663] Loss: 9.49e+07 -0.6838057041168213 0.2151585966348648\n",
      "[Step 16664] Loss: 9.48e+07 -0.6840205192565918 0.21509505808353424\n",
      "[Step 16665] Loss: 9.41e+07 -0.6842122077941895 0.2150414139032364\n",
      "[Step 16666] Loss: 9.36e+07 -0.6843560934066772 0.21499685943126678\n",
      "[Step 16667] Loss: 9.45e+07 -0.6845034956932068 0.21493332087993622\n",
      "[Step 16668] Loss: 9.50e+07 -0.6847695112228394 0.21485741436481476\n",
      "[Step 16669] Loss: 9.42e+07 -0.6850007176399231 0.21478314697742462\n",
      "[Step 16670] Loss: 9.51e+07 -0.6851856112480164 0.2147427201271057\n",
      "[Step 16671] Loss: 9.52e+07 -0.6852841973304749 0.2146965116262436\n",
      "[Step 16672] Loss: 9.53e+07 -0.6853436231613159 0.21466515958309174\n",
      "[Step 16673] Loss: 9.48e+07 -0.685293436050415 0.2146701067686081\n",
      "[Step 16674] Loss: 9.40e+07 -0.6852564811706543 0.2146882563829422\n",
      "[Step 16675] Loss: 9.51e+07 -0.6852564215660095 0.21468165516853333\n",
      "[Step 16676] Loss: 9.44e+07 -0.6852834820747375 0.2146981656551361\n",
      "[Step 16677] Loss: 9.56e+07 -0.6852483749389648 0.21471962332725525\n",
      "[Step 16678] Loss: 9.50e+07 -0.6853061318397522 0.21466845273971558\n",
      "[Step 16679] Loss: 9.42e+07 -0.6853753924369812 0.21461647748947144\n",
      "[Step 16680] Loss: 9.44e+07 -0.6853833794593811 0.21461482346057892\n",
      "[Step 16681] Loss: 9.49e+07 -0.6855143308639526 0.214546337723732\n",
      "[Step 16682] Loss: 9.51e+07 -0.6855143308639526 0.2145545929670334\n",
      "[Step 16683] Loss: 9.38e+07 -0.6855636835098267 0.21453973650932312\n",
      "[Step 16684] Loss: 9.51e+07 -0.685692548751831 0.21449023485183716\n",
      "[Step 16685] Loss: 9.49e+07 -0.6858959197998047 0.21444237232208252\n",
      "[Step 16686] Loss: 9.52e+07 -0.6861763596534729 0.21437636017799377\n",
      "[Step 16687] Loss: 9.58e+07 -0.6863526701927185 0.21431612968444824\n",
      "[Step 16688] Loss: 9.46e+07 -0.6864997148513794 0.21429385244846344\n",
      "[Step 16689] Loss: 9.49e+07 -0.6865313053131104 0.21425753831863403\n",
      "[Step 16690] Loss: 9.49e+07 -0.6866583824157715 0.21423938870429993\n",
      "[Step 16691] Loss: 9.51e+07 -0.6869143843650818 0.2141915261745453\n",
      "[Step 16692] Loss: 9.49e+07 -0.6872208118438721 0.21412056684494019\n",
      "[Step 16693] Loss: 9.49e+07 -0.6875247955322266 0.2140471339225769\n",
      "[Step 16694] Loss: 9.44e+07 -0.6878634691238403 0.21397946774959564\n",
      "[Step 16695] Loss: 9.46e+07 -0.6881927847862244 0.21392583847045898\n",
      "[Step 16696] Loss: 9.50e+07 -0.6885294318199158 0.2138565182685852\n",
      "[Step 16697] Loss: 9.42e+07 -0.6887771487236023 0.21382929384708405\n",
      "[Step 16698] Loss: 9.48e+07 -0.6889351010322571 0.21376658976078033\n",
      "[Step 16699] Loss: 9.45e+07 -0.6890597343444824 0.21371294558048248\n",
      "[Step 16700] Loss: 9.46e+07 -0.6892261505126953 0.21367333829402924\n",
      "[Step 16701] Loss: 9.44e+07 -0.6893672943115234 0.21361392736434937\n",
      "[Step 16702] Loss: 9.49e+07 -0.689547061920166 0.2136048525571823\n",
      "[Step 16703] Loss: 9.50e+07 -0.6898996233940125 0.21352069079875946\n",
      "[Step 16704] Loss: 9.50e+07 -0.6903030872344971 0.2134390026330948\n",
      "[Step 16705] Loss: 9.55e+07 -0.6908155083656311 0.2133614420890808\n",
      "[Step 16706] Loss: 9.41e+07 -0.6912850141525269 0.21323932707309723\n",
      "[Step 16707] Loss: 9.51e+07 -0.6916288137435913 0.2131386548280716\n",
      "[Step 16708] Loss: 9.44e+07 -0.6918466091156006 0.21307429671287537\n",
      "[Step 16709] Loss: 9.49e+07 -0.6919893622398376 0.21302808821201324\n",
      "[Step 16710] Loss: 9.47e+07 -0.692186176776886 0.2129843533039093\n",
      "[Step 16711] Loss: 9.51e+07 -0.6923494935035706 0.21290844678878784\n",
      "[Step 16712] Loss: 9.48e+07 -0.6924160122871399 0.21283087134361267\n",
      "[Step 16713] Loss: 9.44e+07 -0.6925267577171326 0.21281024813652039\n",
      "[Step 16714] Loss: 9.50e+07 -0.6925508379936218 0.2127813696861267\n",
      "[Step 16715] Loss: 9.58e+07 -0.6927430033683777 0.21271535754203796\n",
      "[Step 16716] Loss: 9.48e+07 -0.6928345561027527 0.21266420185565948\n",
      "[Step 16717] Loss: 9.44e+07 -0.6928879022598267 0.212613046169281\n",
      "[Step 16718] Loss: 9.53e+07 -0.6928643584251404 0.21261221170425415\n",
      "[Step 16719] Loss: 9.54e+07 -0.693030059337616 0.21256518363952637\n",
      "[Step 16720] Loss: 9.50e+07 -0.693195104598999 0.2124975174665451\n",
      "[Step 16721] Loss: 9.51e+07 -0.6933861374855042 0.21244554221630096\n",
      "[Step 16722] Loss: 9.45e+07 -0.6935275793075562 0.21243150532245636\n",
      "[Step 16723] Loss: 9.50e+07 -0.6938507556915283 0.2123415768146515\n",
      "[Step 16724] Loss: 9.51e+07 -0.6941307187080383 0.21226152777671814\n",
      "[Step 16725] Loss: 9.48e+07 -0.6943641901016235 0.21221037209033966\n",
      "[Step 16726] Loss: 9.43e+07 -0.6946119070053101 0.2121468335390091\n",
      "[Step 16727] Loss: 9.48e+07 -0.6947599649429321 0.21208082139492035\n",
      "[Step 16728] Loss: 9.43e+07 -0.6949237585067749 0.21202966570854187\n",
      "[Step 16729] Loss: 9.54e+07 -0.6949934363365173 0.21200162172317505\n",
      "[Step 16730] Loss: 9.50e+07 -0.6952311396598816 0.21195293962955475\n",
      "[Step 16731] Loss: 9.56e+07 -0.6955451965332031 0.21186628937721252\n",
      "[Step 16732] Loss: 9.45e+07 -0.6958382725715637 0.21181678771972656\n",
      "[Step 16733] Loss: 9.42e+07 -0.6961149573326111 0.21175159513950348\n",
      "[Step 16734] Loss: 9.42e+07 -0.6963147521018982 0.2116921842098236\n",
      "[Step 16735] Loss: 9.51e+07 -0.6965856552124023 0.21161380410194397\n",
      "[Step 16736] Loss: 9.46e+07 -0.6968550682067871 0.21152138710021973\n",
      "[Step 16737] Loss: 9.46e+07 -0.6970521211624146 0.21143722534179688\n",
      "[Step 16738] Loss: 9.62e+07 -0.6973447799682617 0.21135388314723969\n",
      "[Step 16739] Loss: 9.46e+07 -0.6976819038391113 0.211272194981575\n",
      "[Step 16740] Loss: 9.48e+07 -0.698108971118927 0.21118472516536713\n",
      "[Step 16741] Loss: 9.52e+07 -0.6983915567398071 0.21112778782844543\n",
      "[Step 16742] Loss: 9.44e+07 -0.6988038420677185 0.21102052927017212\n",
      "[Step 16743] Loss: 9.46e+07 -0.6991901993751526 0.21092233061790466\n",
      "[Step 16744] Loss: 9.59e+07 -0.699586808681488 0.21080434322357178\n",
      "[Step 16745] Loss: 9.45e+07 -0.6999483108520508 0.2106863409280777\n",
      "[Step 16746] Loss: 9.48e+07 -0.7001696228981018 0.21063023805618286\n",
      "[Step 16747] Loss: 9.45e+07 -0.7003461122512817 0.2105889767408371\n",
      "[Step 16748] Loss: 9.54e+07 -0.7004762291908264 0.21056753396987915\n",
      "[Step 16749] Loss: 9.54e+07 -0.7005698680877686 0.21053864061832428\n",
      "[Step 16750] Loss: 9.41e+07 -0.7006238102912903 0.21051719784736633\n",
      "[Step 16751] Loss: 9.48e+07 -0.7006757855415344 0.21049904823303223\n",
      "[Step 16752] Loss: 9.51e+07 -0.7007507681846619 0.21048995852470398\n",
      "[Step 16753] Loss: 9.48e+07 -0.7007312774658203 0.2104693353176117\n",
      "[Step 16754] Loss: 9.45e+07 -0.7006746530532837 0.21051223576068878\n",
      "[Step 16755] Loss: 9.53e+07 -0.7006396055221558 0.21052956581115723\n",
      "[Step 16756] Loss: 9.45e+07 -0.7005102634429932 0.21053287386894226\n",
      "[Step 16757] Loss: 9.48e+07 -0.7004073858261108 0.2105262726545334\n",
      "[Step 16758] Loss: 9.61e+07 -0.7005060315132141 0.21046851575374603\n",
      "[Step 16759] Loss: 9.52e+07 -0.7005412578582764 0.2104470580816269\n",
      "[Step 16760] Loss: 9.49e+07 -0.7004112005233765 0.21045200526714325\n",
      "[Step 16761] Loss: 9.43e+07 -0.7003011703491211 0.2104445844888687\n",
      "[Step 16762] Loss: 9.38e+07 -0.7001503705978394 0.21049492061138153\n",
      "[Step 16763] Loss: 9.48e+07 -0.7001471519470215 0.21047675609588623\n",
      "[Step 16764] Loss: 9.53e+07 -0.700349748134613 0.21042312681674957\n",
      "[Step 16765] Loss: 9.46e+07 -0.7004807591438293 0.21040332317352295\n",
      "[Step 16766] Loss: 9.46e+07 -0.7005994319915771 0.21036042273044586\n",
      "[Step 16767] Loss: 9.46e+07 -0.7006551623344421 0.21034474670886993\n",
      "[Step 16768] Loss: 9.47e+07 -0.7007091045379639 0.21029357612133026\n",
      "[Step 16769] Loss: 9.43e+07 -0.7007754445075989 0.21027295291423798\n",
      "[Step 16770] Loss: 9.48e+07 -0.7008301615715027 0.21024325489997864\n",
      "[Step 16771] Loss: 9.67e+07 -0.7007038593292236 0.21024654805660248\n",
      "[Step 16772] Loss: 9.42e+07 -0.7006120681762695 0.21023912727832794\n",
      "[Step 16773] Loss: 9.46e+07 -0.7005332112312317 0.2102498561143875\n",
      "[Step 16774] Loss: 9.41e+07 -0.7003998756408691 0.21022014319896698\n",
      "[Step 16775] Loss: 9.46e+07 -0.7002155780792236 0.2102259248495102\n",
      "[Step 16776] Loss: 9.54e+07 -0.7001486420631409 0.2101772427558899\n",
      "[Step 16777] Loss: 9.45e+07 -0.7001281976699829 0.21015000343322754\n",
      "[Step 16778] Loss: 9.49e+07 -0.7001107335090637 0.21014505624771118\n",
      "[Step 16779] Loss: 9.42e+07 -0.7001623511314392 0.2101607322692871\n",
      "[Step 16780] Loss: 9.49e+07 -0.7002555727958679 0.21012359857559204\n",
      "[Step 16781] Loss: 9.48e+07 -0.7004958987236023 0.2100633680820465\n",
      "[Step 16782] Loss: 9.40e+07 -0.7006673216819763 0.21002458035945892\n",
      "[Step 16783] Loss: 9.52e+07 -0.7007728219032288 0.20999322831630707\n",
      "[Step 16784] Loss: 9.46e+07 -0.7008881568908691 0.20995940268039703\n",
      "[Step 16785] Loss: 9.48e+07 -0.7010430097579956 0.20992639660835266\n",
      "[Step 16786] Loss: 9.50e+07 -0.7011626362800598 0.20989173650741577\n",
      "[Step 16787] Loss: 9.48e+07 -0.7011190056800842 0.20990081131458282\n",
      "[Step 16788] Loss: 9.48e+07 -0.7011561989784241 0.20987771451473236\n",
      "[Step 16789] Loss: 9.46e+07 -0.7010895013809204 0.20989668369293213\n",
      "[Step 16790] Loss: 9.42e+07 -0.7010284066200256 0.20991072058677673\n",
      "[Step 16791] Loss: 9.49e+07 -0.7010678648948669 0.20988184213638306\n",
      "[Step 16792] Loss: 9.51e+07 -0.701107919216156 0.2098504900932312\n",
      "[Step 16793] Loss: 9.46e+07 -0.7011156678199768 0.20983068645000458\n",
      "[Step 16794] Loss: 9.43e+07 -0.7011823058128357 0.20983068645000458\n",
      "[Step 16795] Loss: 9.44e+07 -0.7011755108833313 0.2098141759634018\n",
      "[Step 16796] Loss: 9.49e+07 -0.7011076211929321 0.20984883606433868\n",
      "[Step 16797] Loss: 9.46e+07 -0.701148509979248 0.20981088280677795\n",
      "[Step 16798] Loss: 9.57e+07 -0.7010347843170166 0.20978859066963196\n",
      "[Step 16799] Loss: 9.48e+07 -0.7009604573249817 0.2097712755203247\n",
      "[Step 16800] Loss: 9.45e+07 -0.700890839099884 0.20978116989135742\n",
      "[Step 16801] Loss: 9.48e+07 -0.7007924318313599 0.209819957613945\n",
      "[Step 16802] Loss: 9.59e+07 -0.7006131410598755 0.2098323255777359\n",
      "[Step 16803] Loss: 9.58e+07 -0.7003664374351501 0.2098768949508667\n",
      "[Step 16804] Loss: 9.46e+07 -0.7001133561134338 0.20989751815795898\n",
      "[Step 16805] Loss: 9.51e+07 -0.6998353004455566 0.20993712544441223\n",
      "[Step 16806] Loss: 9.64e+07 -0.6997783184051514 0.2099338173866272\n",
      "[Step 16807] Loss: 9.41e+07 -0.6996776461601257 0.20992639660835266\n",
      "[Step 16808] Loss: 9.45e+07 -0.6995648145675659 0.20992392301559448\n",
      "[Step 16809] Loss: 9.48e+07 -0.6995273232460022 0.20991814136505127\n",
      "[Step 16810] Loss: 9.51e+07 -0.6995505690574646 0.20988760888576508\n",
      "[Step 16811] Loss: 9.44e+07 -0.6996184587478638 0.20986369252204895\n",
      "[Step 16812] Loss: 9.43e+07 -0.6997332572937012 0.20982655882835388\n",
      "[Step 16813] Loss: 9.52e+07 -0.6997760534286499 0.2097894251346588\n",
      "[Step 16814] Loss: 9.46e+07 -0.6997656226158142 0.209791898727417\n",
      "[Step 16815] Loss: 9.59e+07 -0.6995819807052612 0.2098158299922943\n",
      "[Step 16816] Loss: 9.55e+07 -0.6995692849159241 0.20979437232017517\n",
      "[Step 16817] Loss: 9.44e+07 -0.699533998966217 0.20977869629859924\n",
      "[Step 16818] Loss: 9.56e+07 -0.6997193098068237 0.20971186459064484\n",
      "[Step 16819] Loss: 9.45e+07 -0.6999192833900452 0.20965658128261566\n",
      "[Step 16820] Loss: 9.45e+07 -0.7000947594642639 0.20959056913852692\n",
      "[Step 16821] Loss: 9.49e+07 -0.7003128528594971 0.20951217412948608\n",
      "[Step 16822] Loss: 9.51e+07 -0.7004466652870178 0.20946761965751648\n",
      "[Step 16823] Loss: 9.44e+07 -0.700526237487793 0.20943708717823029\n",
      "[Step 16824] Loss: 9.47e+07 -0.7006784677505493 0.2093859314918518\n",
      "[Step 16825] Loss: 9.51e+07 -0.7006893157958984 0.20938345789909363\n",
      "[Step 16826] Loss: 9.58e+07 -0.7009029388427734 0.20933806896209717\n",
      "[Step 16827] Loss: 9.49e+07 -0.7010433673858643 0.209282785654068\n",
      "[Step 16828] Loss: 9.53e+07 -0.7011770606040955 0.20924317836761475\n",
      "[Step 16829] Loss: 9.48e+07 -0.7012173533439636 0.20922502875328064\n",
      "[Step 16830] Loss: 9.52e+07 -0.7012937068939209 0.20920440554618835\n",
      "[Step 16831] Loss: 9.38e+07 -0.7014304995536804 0.2091829478740692\n",
      "[Step 16832] Loss: 9.49e+07 -0.701457142829895 0.20917963981628418\n",
      "[Step 16833] Loss: 9.48e+07 -0.7015879154205322 0.20910455286502838\n",
      "[Step 16834] Loss: 9.49e+07 -0.7017536759376526 0.20905670523643494\n",
      "[Step 16835] Loss: 9.41e+07 -0.7019539475440979 0.209012970328331\n",
      "[Step 16836] Loss: 9.48e+07 -0.7021870017051697 0.20895685255527496\n",
      "[Step 16837] Loss: 9.57e+07 -0.7023248672485352 0.20891477167606354\n",
      "[Step 16838] Loss: 9.51e+07 -0.7024205327033997 0.2088768184185028\n",
      "[Step 16839] Loss: 9.51e+07 -0.7024854421615601 0.20885124802589417\n",
      "[Step 16840] Loss: 9.55e+07 -0.7027458548545837 0.20880503952503204\n",
      "[Step 16841] Loss: 9.47e+07 -0.7030277252197266 0.20872582495212555\n",
      "[Step 16842] Loss: 9.49e+07 -0.7033111453056335 0.20864908397197723\n",
      "[Step 16843] Loss: 9.43e+07 -0.7035883069038391 0.2086070030927658\n",
      "[Step 16844] Loss: 9.46e+07 -0.7038477063179016 0.20853273570537567\n",
      "[Step 16845] Loss: 9.46e+07 -0.7040260434150696 0.20847415924072266\n",
      "[Step 16846] Loss: 9.61e+07 -0.7043277621269226 0.2083842158317566\n",
      "[Step 16847] Loss: 9.46e+07 -0.7044731378555298 0.20833882689476013\n",
      "[Step 16848] Loss: 9.47e+07 -0.7046470046043396 0.20826870203018188\n",
      "[Step 16849] Loss: 9.44e+07 -0.7048667669296265 0.20819196105003357\n",
      "[Step 16850] Loss: 9.50e+07 -0.705221951007843 0.20810943841934204\n",
      "[Step 16851] Loss: 9.46e+07 -0.7055178880691528 0.20801125466823578\n",
      "[Step 16852] Loss: 9.44e+07 -0.7057559490203857 0.20794442296028137\n",
      "[Step 16853] Loss: 9.43e+07 -0.705913782119751 0.2079072892665863\n",
      "[Step 16854] Loss: 9.51e+07 -0.7059381604194641 0.20788830518722534\n",
      "[Step 16855] Loss: 9.58e+07 -0.7058705687522888 0.20789821445941925\n",
      "[Step 16856] Loss: 9.46e+07 -0.7057930827140808 0.20786108076572418\n",
      "[Step 16857] Loss: 9.53e+07 -0.705866813659668 0.2078322023153305\n",
      "[Step 16858] Loss: 9.42e+07 -0.7059816122055054 0.20777855813503265\n",
      "[Step 16859] Loss: 9.48e+07 -0.7061306834220886 0.20774143934249878\n",
      "[Step 16860] Loss: 9.43e+07 -0.7062190771102905 0.2077307105064392\n",
      "[Step 16861] Loss: 9.52e+07 -0.7061541676521301 0.2077571153640747\n",
      "[Step 16862] Loss: 9.44e+07 -0.7060681581497192 0.207752987742424\n",
      "[Step 16863] Loss: 9.58e+07 -0.7061560750007629 0.20770759880542755\n",
      "[Step 16864] Loss: 9.46e+07 -0.7063109874725342 0.20763085782527924\n",
      "[Step 16865] Loss: 9.43e+07 -0.7064898610115051 0.20756733417510986\n",
      "[Step 16866] Loss: 9.44e+07 -0.7067133784294128 0.20750874280929565\n",
      "[Step 16867] Loss: 9.48e+07 -0.7069051265716553 0.20745180547237396\n",
      "[Step 16868] Loss: 9.46e+07 -0.707232654094696 0.20738662779331207\n",
      "[Step 16869] Loss: 9.51e+07 -0.7074103355407715 0.2073453664779663\n",
      "[Step 16870] Loss: 9.56e+07 -0.7077882289886475 0.20723645389080048\n",
      "[Step 16871] Loss: 9.42e+07 -0.708101212978363 0.20718693733215332\n",
      "[Step 16872] Loss: 9.43e+07 -0.7083797454833984 0.20711515843868256\n",
      "[Step 16873] Loss: 9.54e+07 -0.7086334824562073 0.20704831182956696\n",
      "[Step 16874] Loss: 9.47e+07 -0.7089052796363831 0.2070004642009735\n",
      "[Step 16875] Loss: 9.60e+07 -0.7093711495399475 0.2068890631198883\n",
      "[Step 16876] Loss: 9.55e+07 -0.7098571062088013 0.20678509771823883\n",
      "[Step 16877] Loss: 9.56e+07 -0.7104499340057373 0.2066539078950882\n",
      "[Step 16878] Loss: 9.38e+07 -0.7109690308570862 0.20651857554912567\n",
      "[Step 16879] Loss: 9.53e+07 -0.7115850448608398 0.20638903975486755\n",
      "[Step 16880] Loss: 9.40e+07 -0.712003231048584 0.20628836750984192\n",
      "[Step 16881] Loss: 9.64e+07 -0.7126850485801697 0.20613324642181396\n",
      "[Step 16882] Loss: 9.48e+07 -0.7133493423461914 0.20601029694080353\n",
      "[Step 16883] Loss: 9.51e+07 -0.7140524387359619 0.20585599541664124\n",
      "[Step 16884] Loss: 9.45e+07 -0.7146733999252319 0.20575203001499176\n",
      "[Step 16885] Loss: 9.41e+07 -0.7152301073074341 0.20562660694122314\n",
      "[Step 16886] Loss: 9.48e+07 -0.7156464457511902 0.2055160403251648\n",
      "[Step 16887] Loss: 9.64e+07 -0.7163445353507996 0.20538319647312164\n",
      "[Step 16888] Loss: 9.46e+07 -0.7169433832168579 0.2052462249994278\n",
      "[Step 16889] Loss: 9.43e+07 -0.7174836993217468 0.2051265686750412\n",
      "[Step 16890] Loss: 9.48e+07 -0.7178143262863159 0.20506221055984497\n",
      "[Step 16891] Loss: 9.54e+07 -0.7182029485702515 0.20498217642307281\n",
      "[Step 16892] Loss: 9.54e+07 -0.7185327410697937 0.2049235850572586\n",
      "[Step 16893] Loss: 9.39e+07 -0.7188491225242615 0.20484602451324463\n",
      "[Step 16894] Loss: 9.47e+07 -0.7191646099090576 0.2047899216413498\n",
      "[Step 16895] Loss: 9.45e+07 -0.7193508148193359 0.20478413999080658\n",
      "[Step 16896] Loss: 9.52e+07 -0.7195615172386169 0.204714834690094\n",
      "[Step 16897] Loss: 9.49e+07 -0.7197851538658142 0.2046578973531723\n",
      "[Step 16898] Loss: 9.46e+07 -0.7199026346206665 0.20461581647396088\n",
      "[Step 16899] Loss: 9.42e+07 -0.7199769616127014 0.20459766685962677\n",
      "[Step 16900] Loss: 9.53e+07 -0.7199119329452515 0.20462654531002045\n",
      "[Step 16901] Loss: 9.54e+07 -0.7197407484054565 0.20461829006671906\n",
      "[Step 16902] Loss: 9.43e+07 -0.7196046710014343 0.20462901890277863\n",
      "[Step 16903] Loss: 9.41e+07 -0.719427764415741 0.20463809370994568\n",
      "[Step 16904] Loss: 9.55e+07 -0.7194564342498779 0.2046174705028534\n",
      "[Step 16905] Loss: 9.48e+07 -0.7193741798400879 0.20461829006671906\n",
      "[Step 16906] Loss: 9.46e+07 -0.7192590236663818 0.20463727414608002\n",
      "[Step 16907] Loss: 9.43e+07 -0.7191216349601746 0.20464716851711273\n",
      "[Step 16908] Loss: 9.51e+07 -0.7189282178878784 0.20466037094593048\n",
      "[Step 16909] Loss: 9.48e+07 -0.7187053561210632 0.20466367900371552\n",
      "[Step 16910] Loss: 9.53e+07 -0.7185825705528259 0.2046760469675064\n",
      "[Step 16911] Loss: 9.45e+07 -0.7184413075447083 0.20468182861804962\n",
      "[Step 16912] Loss: 9.42e+07 -0.7183331847190857 0.2046760469675064\n",
      "[Step 16913] Loss: 9.44e+07 -0.7181984186172485 0.20464469492435455\n",
      "[Step 16914] Loss: 9.44e+07 -0.7180408835411072 0.20465295016765594\n",
      "[Step 16915] Loss: 9.46e+07 -0.71787428855896 0.2046760469675064\n",
      "[Step 16916] Loss: 9.47e+07 -0.7177497744560242 0.20468924939632416\n",
      "[Step 16917] Loss: 9.49e+07 -0.7175226807594299 0.20470905303955078\n",
      "[Step 16918] Loss: 9.47e+07 -0.7173024415969849 0.20472225546836853\n",
      "[Step 16919] Loss: 9.45e+07 -0.7171538472175598 0.20472143590450287\n",
      "[Step 16920] Loss: 9.51e+07 -0.7170567512512207 0.20472803711891174\n",
      "[Step 16921] Loss: 9.51e+07 -0.7170203924179077 0.2047007977962494\n",
      "[Step 16922] Loss: 9.47e+07 -0.7169678807258606 0.20469503104686737\n",
      "[Step 16923] Loss: 9.43e+07 -0.7170179486274719 0.20470575988292694\n",
      "[Step 16924] Loss: 9.47e+07 -0.7172479629516602 0.2046785205602646\n",
      "[Step 16925] Loss: 9.58e+07 -0.7175402045249939 0.20461829006671906\n",
      "[Step 16926] Loss: 9.46e+07 -0.7177770137786865 0.20456135272979736\n",
      "[Step 16927] Loss: 9.55e+07 -0.7179533839225769 0.20451019704341888\n",
      "[Step 16928] Loss: 9.40e+07 -0.7181257009506226 0.20446564257144928\n",
      "[Step 16929] Loss: 9.47e+07 -0.7182042002677917 0.20443429052829742\n",
      "[Step 16930] Loss: 9.45e+07 -0.7182807922363281 0.2044309824705124\n",
      "[Step 16931] Loss: 9.45e+07 -0.7183351516723633 0.2044144868850708\n",
      "[Step 16932] Loss: 9.47e+07 -0.7184295058250427 0.2043823003768921\n",
      "[Step 16933] Loss: 9.47e+07 -0.7184715867042542 0.2043435126543045\n",
      "[Step 16934] Loss: 9.55e+07 -0.718596339225769 0.20433196425437927\n",
      "[Step 16935] Loss: 9.57e+07 -0.7189547419548035 0.2042379081249237\n",
      "[Step 16936] Loss: 9.52e+07 -0.7191511392593384 0.2041875720024109\n",
      "[Step 16937] Loss: 9.47e+07 -0.7193543910980225 0.2041100114583969\n",
      "[Step 16938] Loss: 9.42e+07 -0.7195479273796082 0.20402748882770538\n",
      "[Step 16939] Loss: 9.44e+07 -0.7196487784385681 0.20402006804943085\n",
      "[Step 16940] Loss: 9.44e+07 -0.7196614742279053 0.2040068656206131\n",
      "[Step 16941] Loss: 9.49e+07 -0.7197540998458862 0.20397880673408508\n",
      "[Step 16942] Loss: 9.45e+07 -0.7198728919029236 0.2039623111486435\n",
      "[Step 16943] Loss: 9.49e+07 -0.7199045419692993 0.20393837988376617\n",
      "[Step 16944] Loss: 9.48e+07 -0.7198047637939453 0.2039722055196762\n",
      "[Step 16945] Loss: 9.57e+07 -0.7195479273796082 0.20401263236999512\n",
      "[Step 16946] Loss: 9.56e+07 -0.7195206880569458 0.20398706197738647\n",
      "[Step 16947] Loss: 9.49e+07 -0.719567060470581 0.2039499282836914\n",
      "[Step 16948] Loss: 9.41e+07 -0.7196070551872253 0.20392930507659912\n",
      "[Step 16949] Loss: 9.47e+07 -0.7196019291877747 0.20391279458999634\n",
      "[Step 16950] Loss: 9.57e+07 -0.7197466492652893 0.2038773149251938\n",
      "[Step 16951] Loss: 9.50e+07 -0.7199772000312805 0.2038220316171646\n",
      "[Step 16952] Loss: 9.52e+07 -0.7201361060142517 0.2037733495235443\n",
      "[Step 16953] Loss: 9.39e+07 -0.72027188539505 0.2037452906370163\n",
      "[Step 16954] Loss: 9.51e+07 -0.7202569842338562 0.20375767350196838\n",
      "[Step 16955] Loss: 9.51e+07 -0.7201579213142395 0.20378242433071136\n",
      "[Step 16956] Loss: 9.52e+07 -0.7200040221214294 0.2038220316171646\n",
      "[Step 16957] Loss: 9.54e+07 -0.7198188900947571 0.20382533967494965\n",
      "[Step 16958] Loss: 9.53e+07 -0.7196140885353088 0.20385503768920898\n",
      "[Step 16959] Loss: 9.56e+07 -0.7195520997047424 0.20384348928928375\n",
      "[Step 16960] Loss: 9.49e+07 -0.7193771004676819 0.20385916531085968\n",
      "[Step 16961] Loss: 9.51e+07 -0.7193393707275391 0.20384018123149872\n",
      "[Step 16962] Loss: 9.56e+07 -0.7192737460136414 0.20386329293251038\n",
      "[Step 16963] Loss: 9.48e+07 -0.7192419767379761 0.20386824011802673\n",
      "[Step 16964] Loss: 9.46e+07 -0.7191534638404846 0.20391114056110382\n",
      "[Step 16965] Loss: 9.53e+07 -0.7189647555351257 0.20395983755588531\n",
      "[Step 16966] Loss: 9.46e+07 -0.7188175320625305 0.203994482755661\n",
      "[Step 16967] Loss: 9.47e+07 -0.7186492085456848 0.20402748882770538\n",
      "[Step 16968] Loss: 9.44e+07 -0.7185123562812805 0.2040291428565979\n",
      "[Step 16969] Loss: 9.48e+07 -0.7184968590736389 0.20402172207832336\n",
      "[Step 16970] Loss: 9.60e+07 -0.7183645963668823 0.20403821766376495\n",
      "[Step 16971] Loss: 9.45e+07 -0.718208372592926 0.20402254164218903\n",
      "[Step 16972] Loss: 9.49e+07 -0.7181509733200073 0.20402583479881287\n",
      "[Step 16973] Loss: 9.50e+07 -0.718032956123352 0.20400191843509674\n",
      "[Step 16974] Loss: 9.47e+07 -0.7178875803947449 0.20402419567108154\n",
      "[Step 16975] Loss: 9.46e+07 -0.7177206873893738 0.20405307412147522\n",
      "[Step 16976] Loss: 9.47e+07 -0.7174614667892456 0.20409680902957916\n",
      "[Step 16977] Loss: 9.49e+07 -0.717248260974884 0.20411908626556396\n",
      "[Step 16978] Loss: 9.54e+07 -0.7168796062469482 0.20420324802398682\n",
      "[Step 16979] Loss: 9.46e+07 -0.7165923714637756 0.20424532890319824\n",
      "[Step 16980] Loss: 9.58e+07 -0.716529130935669 0.20425771176815033\n",
      "[Step 16981] Loss: 9.49e+07 -0.7165796160697937 0.20424285531044006\n",
      "[Step 16982] Loss: 9.49e+07 -0.7168046236038208 0.20419912040233612\n",
      "[Step 16983] Loss: 9.43e+07 -0.7170088291168213 0.20415456593036652\n",
      "[Step 16984] Loss: 9.44e+07 -0.7171374559402466 0.20412321388721466\n",
      "[Step 16985] Loss: 9.50e+07 -0.7173694968223572 0.2040613293647766\n",
      "[Step 16986] Loss: 9.42e+07 -0.7175360918045044 0.20403821766376495\n",
      "[Step 16987] Loss: 9.44e+07 -0.7176845073699951 0.2039928287267685\n",
      "[Step 16988] Loss: 9.42e+07 -0.7177981734275818 0.20397385954856873\n",
      "[Step 16989] Loss: 9.52e+07 -0.717841625213623 0.2039482742547989\n",
      "[Step 16990] Loss: 9.46e+07 -0.7179437875747681 0.2038954645395279\n",
      "[Step 16991] Loss: 9.47e+07 -0.7179938554763794 0.20387154817581177\n",
      "[Step 16992] Loss: 9.52e+07 -0.7181669473648071 0.2038245052099228\n",
      "[Step 16993] Loss: 9.47e+07 -0.718258798122406 0.20379315316677094\n",
      "[Step 16994] Loss: 9.57e+07 -0.7185558676719666 0.20370568335056305\n",
      "[Step 16995] Loss: 9.46e+07 -0.7187750339508057 0.20367267727851868\n",
      "[Step 16996] Loss: 9.45e+07 -0.7189878821372986 0.2036132663488388\n",
      "[Step 16997] Loss: 9.51e+07 -0.7193357348442078 0.2035018801689148\n",
      "[Step 16998] Loss: 9.44e+07 -0.7196449637413025 0.20340946316719055\n",
      "[Step 16999] Loss: 9.45e+07 -0.7199249863624573 0.20332282781600952\n",
      "[Step 17000] Loss: 9.50e+07 -0.7200832962989807 0.2032543420791626\n",
      "[Step 17001] Loss: 9.51e+07 -0.7203495502471924 0.20318254828453064\n",
      "[Step 17002] Loss: 9.58e+07 -0.7204905152320862 0.2031181901693344\n",
      "[Step 17003] Loss: 9.50e+07 -0.7206622362136841 0.20306620001792908\n",
      "[Step 17004] Loss: 9.49e+07 -0.720953643321991 0.20300762355327606\n",
      "[Step 17005] Loss: 9.52e+07 -0.7212586998939514 0.20293253660202026\n",
      "[Step 17006] Loss: 9.63e+07 -0.7218397259712219 0.202806293964386\n",
      "[Step 17007] Loss: 9.48e+07 -0.7224829792976379 0.20269820094108582\n",
      "[Step 17008] Loss: 9.51e+07 -0.7231064438819885 0.20255544781684875\n",
      "[Step 17009] Loss: 9.43e+07 -0.7235724925994873 0.20248118042945862\n",
      "[Step 17010] Loss: 9.48e+07 -0.7240481972694397 0.20234420895576477\n",
      "[Step 17011] Loss: 9.60e+07 -0.724363386631012 0.20226582884788513\n",
      "[Step 17012] Loss: 9.48e+07 -0.7247437238693237 0.20217588543891907\n",
      "[Step 17013] Loss: 9.52e+07 -0.7250044345855713 0.20207934081554413\n",
      "[Step 17014] Loss: 9.51e+07 -0.7253328561782837 0.20201003551483154\n",
      "[Step 17015] Loss: 9.48e+07 -0.7257165312767029 0.20190607011318207\n",
      "[Step 17016] Loss: 9.56e+07 -0.7260534763336182 0.20188461244106293\n",
      "[Step 17017] Loss: 9.45e+07 -0.7263540625572205 0.2018144726753235\n",
      "[Step 17018] Loss: 9.46e+07 -0.7265507578849792 0.2017534077167511\n",
      "[Step 17019] Loss: 9.51e+07 -0.7268303632736206 0.2016907036304474\n",
      "[Step 17020] Loss: 9.43e+07 -0.7270427346229553 0.20165027678012848\n",
      "[Step 17021] Loss: 9.40e+07 -0.7272730469703674 0.20160241425037384\n",
      "[Step 17022] Loss: 9.47e+07 -0.7274006009101868 0.20156198740005493\n",
      "[Step 17023] Loss: 9.48e+07 -0.7276284694671631 0.2014959752559662\n",
      "[Step 17024] Loss: 9.54e+07 -0.7279139757156372 0.2014167606830597\n",
      "[Step 17025] Loss: 9.43e+07 -0.7283082008361816 0.2013169229030609\n",
      "[Step 17026] Loss: 9.49e+07 -0.7286450266838074 0.20123440027236938\n",
      "[Step 17027] Loss: 9.50e+07 -0.7290302515029907 0.20113703608512878\n",
      "[Step 17028] Loss: 9.53e+07 -0.7295579314231873 0.20102152228355408\n",
      "[Step 17029] Loss: 9.50e+07 -0.729931652545929 0.2009340524673462\n",
      "[Step 17030] Loss: 9.57e+07 -0.7304482460021973 0.20084823668003082\n",
      "[Step 17031] Loss: 9.52e+07 -0.7310152649879456 0.2007310688495636\n",
      "[Step 17032] Loss: 9.48e+07 -0.7315364480018616 0.20062050223350525\n",
      "[Step 17033] Loss: 9.52e+07 -0.7320207953453064 0.20051488280296326\n",
      "[Step 17034] Loss: 9.47e+07 -0.7325079441070557 0.20043732225894928\n",
      "[Step 17035] Loss: 9.46e+07 -0.7328848242759705 0.20032097399234772\n",
      "[Step 17036] Loss: 9.52e+07 -0.7332288026809692 0.20024506747722626\n",
      "[Step 17037] Loss: 9.50e+07 -0.7336017489433289 0.2001592516899109\n",
      "[Step 17038] Loss: 9.48e+07 -0.7339603900909424 0.2000552862882614\n",
      "[Step 17039] Loss: 9.55e+07 -0.7341669201850891 0.1999884396791458\n",
      "[Step 17040] Loss: 9.39e+07 -0.7343877553939819 0.19993233680725098\n",
      "[Step 17041] Loss: 9.53e+07 -0.7347317337989807 0.19986219704151154\n",
      "[Step 17042] Loss: 9.44e+07 -0.7350122928619385 0.19976896047592163\n",
      "[Step 17043] Loss: 9.53e+07 -0.7352988719940186 0.19969221949577332\n",
      "[Step 17044] Loss: 9.58e+07 -0.7353906631469727 0.19964684545993805\n",
      "[Step 17045] Loss: 9.48e+07 -0.7354084253311157 0.19963198900222778\n",
      "[Step 17046] Loss: 9.64e+07 -0.7356956005096436 0.19959816336631775\n",
      "[Step 17047] Loss: 9.44e+07 -0.7359795570373535 0.19955772161483765\n",
      "[Step 17048] Loss: 9.51e+07 -0.7364067435264587 0.19944633543491364\n",
      "[Step 17049] Loss: 9.54e+07 -0.7367554903030396 0.1993580460548401\n",
      "[Step 17050] Loss: 9.51e+07 -0.7369566559791565 0.19932256639003754\n",
      "[Step 17051] Loss: 9.47e+07 -0.7371200919151306 0.19928130507469177\n",
      "[Step 17052] Loss: 9.44e+07 -0.7371785640716553 0.19925902783870697\n",
      "[Step 17053] Loss: 9.51e+07 -0.7373223900794983 0.1992218941450119\n",
      "[Step 17054] Loss: 9.41e+07 -0.7374434471130371 0.19920127093791962\n",
      "[Step 17055] Loss: 9.46e+07 -0.737585186958313 0.19915422797203064\n",
      "[Step 17056] Loss: 9.51e+07 -0.7376207709312439 0.19913442432880402\n",
      "[Step 17057] Loss: 9.48e+07 -0.737675130367279 0.19911132752895355\n",
      "[Step 17058] Loss: 9.51e+07 -0.7377597689628601 0.19909977912902832\n",
      "[Step 17059] Loss: 9.44e+07 -0.7378933429718018 0.19909152388572693\n",
      "[Step 17060] Loss: 9.49e+07 -0.7379693388938904 0.1990618109703064\n",
      "[Step 17061] Loss: 9.40e+07 -0.7380319237709045 0.19902385771274567\n",
      "[Step 17062] Loss: 9.49e+07 -0.7380644679069519 0.1990131288766861\n",
      "[Step 17063] Loss: 9.41e+07 -0.7380855083465576 0.19898177683353424\n",
      "[Step 17064] Loss: 9.46e+07 -0.7381203174591064 0.19895124435424805\n",
      "[Step 17065] Loss: 9.48e+07 -0.7381551861763 0.19889843463897705\n",
      "[Step 17066] Loss: 9.55e+07 -0.7380642890930176 0.1988934874534607\n",
      "[Step 17067] Loss: 9.44e+07 -0.737932562828064 0.19888028502464294\n",
      "[Step 17068] Loss: 9.48e+07 -0.737816572189331 0.19888935983181\n",
      "[Step 17069] Loss: 9.41e+07 -0.7377289533615112 0.1988753378391266\n",
      "[Step 17070] Loss: 9.44e+07 -0.737700343132019 0.19889183342456818\n",
      "[Step 17071] Loss: 9.36e+07 -0.737673282623291 0.1988992691040039\n",
      "[Step 17072] Loss: 9.44e+07 -0.737626314163208 0.19889843463897705\n",
      "[Step 17073] Loss: 9.44e+07 -0.7376435399055481 0.19886048138141632\n",
      "[Step 17074] Loss: 9.45e+07 -0.7376706004142761 0.1988406777381897\n",
      "[Step 17075] Loss: 9.47e+07 -0.737600564956665 0.19881592690944672\n",
      "[Step 17076] Loss: 9.56e+07 -0.7374774217605591 0.1988324224948883\n",
      "[Step 17077] Loss: 9.51e+07 -0.7372381091117859 0.1988406777381897\n",
      "[Step 17078] Loss: 9.45e+07 -0.7370068430900574 0.19887202978134155\n",
      "[Step 17079] Loss: 9.51e+07 -0.7367193698883057 0.19890999794006348\n",
      "[Step 17080] Loss: 9.44e+07 -0.7364202737808228 0.19895784556865692\n",
      "[Step 17081] Loss: 9.56e+07 -0.7362618446350098 0.19895784556865692\n",
      "[Step 17082] Loss: 9.43e+07 -0.7361981272697449 0.1989562064409256\n",
      "[Step 17083] Loss: 9.42e+07 -0.7361050248146057 0.19895784556865692\n",
      "[Step 17084] Loss: 9.55e+07 -0.7361852526664734 0.19892071187496185\n",
      "[Step 17085] Loss: 9.43e+07 -0.7361975908279419 0.19891823828220367\n",
      "[Step 17086] Loss: 9.48e+07 -0.7362232208251953 0.19889183342456818\n",
      "[Step 17087] Loss: 9.47e+07 -0.7363235354423523 0.19887781143188477\n",
      "[Step 17088] Loss: 9.48e+07 -0.7365846037864685 0.19881758093833923\n",
      "[Step 17089] Loss: 9.44e+07 -0.7369614243507385 0.1987573355436325\n",
      "[Step 17090] Loss: 9.52e+07 -0.7371851205825806 0.19870370626449585\n",
      "[Step 17091] Loss: 9.49e+07 -0.7374241948127747 0.1986542046070099\n",
      "[Step 17092] Loss: 9.63e+07 -0.7379174828529358 0.19853290915489197\n",
      "[Step 17093] Loss: 9.49e+07 -0.7383971214294434 0.1984594613313675\n",
      "[Step 17094] Loss: 9.51e+07 -0.7387279272079468 0.19842563569545746\n",
      "[Step 17095] Loss: 9.48e+07 -0.7390617728233337 0.1983843743801117\n",
      "[Step 17096] Loss: 9.47e+07 -0.7392961382865906 0.19832414388656616\n",
      "[Step 17097] Loss: 9.46e+07 -0.7394621968269348 0.19830021262168884\n",
      "[Step 17098] Loss: 9.52e+07 -0.7396829724311829 0.19823256134986877\n",
      "[Step 17099] Loss: 9.45e+07 -0.7398170232772827 0.1982177048921585\n",
      "[Step 17100] Loss: 9.44e+07 -0.739955723285675 0.19817891716957092\n",
      "[Step 17101] Loss: 9.63e+07 -0.7403796315193176 0.19809062778949738\n",
      "[Step 17102] Loss: 9.54e+07 -0.7408661842346191 0.19801801443099976\n",
      "[Step 17103] Loss: 9.51e+07 -0.7413526773452759 0.19791735708713531\n",
      "[Step 17104] Loss: 9.50e+07 -0.7417797446250916 0.1978364884853363\n",
      "[Step 17105] Loss: 9.53e+07 -0.7420198321342468 0.19779522716999054\n",
      "[Step 17106] Loss: 9.47e+07 -0.7421717047691345 0.19776222109794617\n",
      "[Step 17107] Loss: 9.44e+07 -0.7422934770584106 0.1977085918188095\n",
      "[Step 17108] Loss: 9.54e+07 -0.7425156831741333 0.19767393171787262\n",
      "[Step 17109] Loss: 9.47e+07 -0.7428140044212341 0.19761452078819275\n",
      "[Step 17110] Loss: 9.45e+07 -0.7430700659751892 0.19753943383693695\n",
      "[Step 17111] Loss: 9.43e+07 -0.7432827353477478 0.19745361804962158\n",
      "[Step 17112] Loss: 9.48e+07 -0.7435185313224792 0.19741153717041016\n",
      "[Step 17113] Loss: 9.45e+07 -0.7436777949333191 0.1973397582769394\n",
      "[Step 17114] Loss: 9.47e+07 -0.7438514828681946 0.1972828209400177\n",
      "[Step 17115] Loss: 9.46e+07 -0.7439445853233337 0.19724403321743011\n",
      "[Step 17116] Loss: 9.41e+07 -0.7440674901008606 0.19720855355262756\n",
      "[Step 17117] Loss: 9.42e+07 -0.744100034236908 0.19717803597450256\n",
      "[Step 17118] Loss: 9.44e+07 -0.744078516960144 0.19713512063026428\n",
      "[Step 17119] Loss: 9.40e+07 -0.7441099882125854 0.19712357223033905\n",
      "[Step 17120] Loss: 9.48e+07 -0.7441601157188416 0.1970798373222351\n",
      "[Step 17121] Loss: 9.42e+07 -0.7442052364349365 0.1970963478088379\n",
      "[Step 17122] Loss: 9.44e+07 -0.7442405223846436 0.19708561897277832\n",
      "[Step 17123] Loss: 9.42e+07 -0.7443177700042725 0.1970534324645996\n",
      "[Step 17124] Loss: 9.59e+07 -0.7445660829544067 0.19700145721435547\n",
      "[Step 17125] Loss: 9.47e+07 -0.7447500824928284 0.19693955779075623\n",
      "[Step 17126] Loss: 9.58e+07 -0.7451543211936951 0.19685623049736023\n",
      "[Step 17127] Loss: 9.51e+07 -0.7454752326011658 0.19678030908107758\n",
      "[Step 17128] Loss: 9.47e+07 -0.7456920742988586 0.19673162698745728\n",
      "[Step 17129] Loss: 9.50e+07 -0.7459518313407898 0.19666892290115356\n",
      "[Step 17130] Loss: 9.43e+07 -0.7462168335914612 0.19659796357154846\n",
      "[Step 17131] Loss: 9.47e+07 -0.7463814616203308 0.19653277099132538\n",
      "[Step 17132] Loss: 9.47e+07 -0.7465323805809021 0.19644860923290253\n",
      "[Step 17133] Loss: 9.47e+07 -0.7467103600502014 0.19643209874629974\n",
      "[Step 17134] Loss: 9.41e+07 -0.7468953132629395 0.1963759958744049\n",
      "[Step 17135] Loss: 9.51e+07 -0.7471262812614441 0.19630585610866547\n",
      "[Step 17136] Loss: 9.52e+07 -0.7473306655883789 0.19624562561511993\n",
      "[Step 17137] Loss: 9.46e+07 -0.7476190328598022 0.19614578783512115\n",
      "[Step 17138] Loss: 9.47e+07 -0.7478765249252319 0.1960781216621399\n",
      "[Step 17139] Loss: 9.51e+07 -0.7481673955917358 0.1959947794675827\n",
      "[Step 17140] Loss: 9.39e+07 -0.7484441995620728 0.19594280421733856\n",
      "[Step 17141] Loss: 9.54e+07 -0.7485904693603516 0.1959196925163269\n",
      "[Step 17142] Loss: 9.42e+07 -0.7486652135848999 0.1959362030029297\n",
      "[Step 17143] Loss: 9.56e+07 -0.7486491203308105 0.19592134654521942\n",
      "[Step 17144] Loss: 9.52e+07 -0.748656153678894 0.1959560066461563\n",
      "[Step 17145] Loss: 9.52e+07 -0.7486870884895325 0.19595187902450562\n",
      "[Step 17146] Loss: 9.42e+07 -0.7487033009529114 0.19593124091625214\n",
      "[Step 17147] Loss: 9.49e+07 -0.7488097548484802 0.19589246809482574\n",
      "[Step 17148] Loss: 9.70e+07 -0.7487243413925171 0.19589988887310028\n",
      "[Step 17149] Loss: 9.45e+07 -0.7486187219619751 0.19588668644428253\n",
      "[Step 17150] Loss: 9.53e+07 -0.7483924031257629 0.19592300057411194\n",
      "[Step 17151] Loss: 9.54e+07 -0.7482848167419434 0.19593949615955353\n",
      "[Step 17152] Loss: 9.44e+07 -0.7482282519340515 0.19593454897403717\n",
      "[Step 17153] Loss: 9.51e+07 -0.7482776641845703 0.19591227173805237\n",
      "[Step 17154] Loss: 9.45e+07 -0.7482524514198303 0.1959238201379776\n",
      "[Step 17155] Loss: 9.55e+07 -0.7480967044830322 0.19593124091625214\n",
      "[Step 17156] Loss: 9.61e+07 -0.7481379508972168 0.19589988887310028\n",
      "[Step 17157] Loss: 9.46e+07 -0.7481845021247864 0.19588834047317505\n",
      "[Step 17158] Loss: 9.44e+07 -0.7481975555419922 0.1958586424589157\n",
      "[Step 17159] Loss: 9.49e+07 -0.7482399940490723 0.19581490755081177\n",
      "[Step 17160] Loss: 9.45e+07 -0.748227059841156 0.19578519463539124\n",
      "[Step 17161] Loss: 9.42e+07 -0.7482115030288696 0.19575715065002441\n",
      "[Step 17162] Loss: 9.50e+07 -0.7481822371482849 0.19576209783554077\n",
      "[Step 17163] Loss: 9.44e+07 -0.7481905817985535 0.19573403894901276\n",
      "[Step 17164] Loss: 9.42e+07 -0.7482223510742188 0.19572249054908752\n",
      "[Step 17165] Loss: 9.51e+07 -0.7482936978340149 0.19570434093475342\n",
      "[Step 17166] Loss: 9.57e+07 -0.7485118508338928 0.1956663727760315\n",
      "[Step 17167] Loss: 9.45e+07 -0.7486772537231445 0.19562429189682007\n",
      "[Step 17168] Loss: 9.45e+07 -0.7487693428993225 0.19559046626091003\n",
      "[Step 17169] Loss: 9.45e+07 -0.7488706111907959 0.1955648809671402\n",
      "[Step 17170] Loss: 9.44e+07 -0.7489283084869385 0.1955384761095047\n",
      "[Step 17171] Loss: 9.44e+07 -0.7489888072013855 0.1955021768808365\n",
      "[Step 17172] Loss: 9.49e+07 -0.7490713596343994 0.19549886882305145\n",
      "[Step 17173] Loss: 9.43e+07 -0.7491079568862915 0.19547411799430847\n",
      "[Step 17174] Loss: 9.48e+07 -0.7491062879562378 0.1955079585313797\n",
      "[Step 17175] Loss: 9.44e+07 -0.7490965723991394 0.19548237323760986\n",
      "[Step 17176] Loss: 9.46e+07 -0.7490577101707458 0.19546422362327576\n",
      "[Step 17177] Loss: 9.47e+07 -0.7489238977432251 0.1954732984304428\n",
      "[Step 17178] Loss: 9.43e+07 -0.7487664818763733 0.19550630450248718\n",
      "[Step 17179] Loss: 9.51e+07 -0.7486318945884705 0.19553270936012268\n",
      "[Step 17180] Loss: 9.43e+07 -0.7485433220863342 0.1955244541168213\n",
      "[Step 17181] Loss: 9.48e+07 -0.7483693957328796 0.19555333256721497\n",
      "[Step 17182] Loss: 9.48e+07 -0.7481924295425415 0.19557808339595795\n",
      "[Step 17183] Loss: 9.45e+07 -0.7479894757270813 0.195587158203125\n",
      "[Step 17184] Loss: 9.48e+07 -0.7476733326911926 0.1956358551979065\n",
      "[Step 17185] Loss: 9.41e+07 -0.7473235726356506 0.19571010768413544\n",
      "[Step 17186] Loss: 9.43e+07 -0.746978759765625 0.19573816657066345\n",
      "[Step 17187] Loss: 9.45e+07 -0.746637761592865 0.19580665230751038\n",
      "[Step 17188] Loss: 9.45e+07 -0.7464342713356018 0.19583718478679657\n",
      "[Step 17189] Loss: 9.59e+07 -0.746160089969635 0.1958693563938141\n",
      "[Step 17190] Loss: 9.51e+07 -0.7460507750511169 0.19590814411640167\n",
      "[Step 17191] Loss: 9.48e+07 -0.7460727691650391 0.1959114372730255\n",
      "[Step 17192] Loss: 9.44e+07 -0.7460634708404541 0.1959097981452942\n",
      "[Step 17193] Loss: 9.51e+07 -0.7460507750511169 0.19590649008750916\n",
      "[Step 17194] Loss: 9.45e+07 -0.746004045009613 0.19591721892356873\n",
      "[Step 17195] Loss: 9.46e+07 -0.7458767890930176 0.19594362378120422\n",
      "[Step 17196] Loss: 9.44e+07 -0.7457746863365173 0.19597581028938293\n",
      "[Step 17197] Loss: 9.49e+07 -0.7456335425376892 0.19598901271820068\n",
      "[Step 17198] Loss: 9.58e+07 -0.7454648613929749 0.1960170567035675\n",
      "[Step 17199] Loss: 9.52e+07 -0.7452659010887146 0.19605006277561188\n",
      "[Step 17200] Loss: 9.44e+07 -0.7451563477516174 0.1960616260766983\n",
      "[Step 17201] Loss: 9.44e+07 -0.7451155185699463 0.1960921436548233\n",
      "[Step 17202] Loss: 9.48e+07 -0.7451539039611816 0.1960574984550476\n",
      "[Step 17203] Loss: 9.47e+07 -0.7451202869415283 0.19606904685497284\n",
      "[Step 17204] Loss: 9.52e+07 -0.7451485991477966 0.19608472287654877\n",
      "[Step 17205] Loss: 9.47e+07 -0.7451520562171936 0.1960781216621399\n",
      "[Step 17206] Loss: 9.46e+07 -0.7451474666595459 0.19607894122600555\n",
      "[Step 17207] Loss: 9.56e+07 -0.745134711265564 0.19606409966945648\n",
      "[Step 17208] Loss: 9.51e+07 -0.74509596824646 0.19606409966945648\n",
      "[Step 17209] Loss: 9.58e+07 -0.7452667951583862 0.1960574984550476\n",
      "[Step 17210] Loss: 9.51e+07 -0.7452579736709595 0.19603025913238525\n",
      "[Step 17211] Loss: 9.52e+07 -0.7453666925430298 0.1959989070892334\n",
      "[Step 17212] Loss: 9.42e+07 -0.7454530596733093 0.1959502249956131\n",
      "[Step 17213] Loss: 9.52e+07 -0.745597779750824 0.19590483605861664\n",
      "[Step 17214] Loss: 9.54e+07 -0.7457447052001953 0.19587595760822296\n",
      "[Step 17215] Loss: 9.43e+07 -0.745978593826294 0.19582480192184448\n",
      "[Step 17216] Loss: 9.47e+07 -0.7463752627372742 0.19572743773460388\n",
      "[Step 17217] Loss: 9.63e+07 -0.7470357418060303 0.19556406140327454\n",
      "[Step 17218] Loss: 9.42e+07 -0.7477306723594666 0.1954188346862793\n",
      "[Step 17219] Loss: 9.46e+07 -0.7484275698661804 0.19527113437652588\n",
      "[Step 17220] Loss: 9.47e+07 -0.7491690516471863 0.1951127052307129\n",
      "[Step 17221] Loss: 9.43e+07 -0.7499207854270935 0.19495758414268494\n",
      "[Step 17222] Loss: 9.51e+07 -0.7506812214851379 0.1947999894618988\n",
      "[Step 17223] Loss: 9.48e+07 -0.7513626217842102 0.19465641677379608\n",
      "[Step 17224] Loss: 9.50e+07 -0.7519527077674866 0.19452686607837677\n",
      "[Step 17225] Loss: 9.46e+07 -0.7525549530982971 0.1943824589252472\n",
      "[Step 17226] Loss: 9.42e+07 -0.7529476881027222 0.19431233406066895\n",
      "[Step 17227] Loss: 9.48e+07 -0.7531816959381104 0.19427189230918884\n",
      "[Step 17228] Loss: 9.46e+07 -0.75331711769104 0.19424714148044586\n",
      "[Step 17229] Loss: 9.50e+07 -0.753434419631958 0.19422651827335358\n",
      "[Step 17230] Loss: 9.50e+07 -0.7534807920455933 0.19419680535793304\n",
      "[Step 17231] Loss: 9.48e+07 -0.7534396648406982 0.19419267773628235\n",
      "[Step 17232] Loss: 9.63e+07 -0.7532214522361755 0.19417865574359894\n",
      "[Step 17233] Loss: 9.53e+07 -0.753200352191925 0.19415967166423798\n",
      "[Step 17234] Loss: 9.47e+07 -0.7531195878982544 0.19419680535793304\n",
      "[Step 17235] Loss: 9.49e+07 -0.7531143426895142 0.19420340657234192\n",
      "[Step 17236] Loss: 9.48e+07 -0.7530680298805237 0.19418607652187347\n",
      "[Step 17237] Loss: 9.42e+07 -0.7530190944671631 0.19420258700847626\n",
      "[Step 17238] Loss: 9.52e+07 -0.7529906034469604 0.19420836865901947\n",
      "[Step 17239] Loss: 9.58e+07 -0.7528538107872009 0.19422073662281036\n",
      "[Step 17240] Loss: 9.56e+07 -0.7528188228607178 0.19422899186611176\n",
      "[Step 17241] Loss: 9.50e+07 -0.7528104186058044 0.19424466788768768\n",
      "[Step 17242] Loss: 9.54e+07 -0.7529097199440002 0.19420340657234192\n",
      "[Step 17243] Loss: 9.48e+07 -0.7529647946357727 0.19418030977249146\n",
      "[Step 17244] Loss: 9.45e+07 -0.7531014680862427 0.194134920835495\n",
      "[Step 17245] Loss: 9.53e+07 -0.7531426548957825 0.1941085159778595\n",
      "[Step 17246] Loss: 9.42e+07 -0.7532307505607605 0.19408376514911652\n",
      "[Step 17247] Loss: 9.48e+07 -0.7533234357833862 0.19406643509864807\n",
      "[Step 17248] Loss: 9.50e+07 -0.7534275054931641 0.1940070241689682\n",
      "[Step 17249] Loss: 9.42e+07 -0.7535603046417236 0.19395586848258972\n",
      "[Step 17250] Loss: 9.55e+07 -0.7535327076911926 0.19392533600330353\n",
      "[Step 17251] Loss: 9.49e+07 -0.7533876895904541 0.1939443200826645\n",
      "[Step 17252] Loss: 9.53e+07 -0.7533949017524719 0.19392451643943787\n",
      "[Step 17253] Loss: 9.46e+07 -0.7534417510032654 0.1939096599817276\n",
      "[Step 17254] Loss: 9.46e+07 -0.7534387707710266 0.1939278095960617\n",
      "[Step 17255] Loss: 9.44e+07 -0.7534241676330566 0.19390636682510376\n",
      "[Step 17256] Loss: 9.49e+07 -0.7534250617027283 0.1938915103673935\n",
      "[Step 17257] Loss: 9.49e+07 -0.753577709197998 0.19383788108825684\n",
      "[Step 17258] Loss: 9.46e+07 -0.7537046670913696 0.193812295794487\n",
      "[Step 17259] Loss: 9.51e+07 -0.7537499070167542 0.19380982220172882\n",
      "[Step 17260] Loss: 9.44e+07 -0.7538179755210876 0.19383291900157928\n",
      "[Step 17261] Loss: 9.43e+07 -0.7539575099945068 0.19381560385227203\n",
      "[Step 17262] Loss: 9.61e+07 -0.7542328834533691 0.19374628365039825\n",
      "[Step 17263] Loss: 9.46e+07 -0.7545181512832642 0.19366872310638428\n",
      "[Step 17264] Loss: 9.48e+07 -0.754791796207428 0.19361096620559692\n",
      "[Step 17265] Loss: 9.43e+07 -0.754981279373169 0.19357961416244507\n",
      "[Step 17266] Loss: 9.47e+07 -0.7550933957099915 0.1935548484325409\n",
      "[Step 17267] Loss: 9.40e+07 -0.7551701068878174 0.19353340566158295\n",
      "[Step 17268] Loss: 9.50e+07 -0.7552456259727478 0.1935078203678131\n",
      "[Step 17269] Loss: 9.58e+07 -0.7551800012588501 0.19350534677505493\n",
      "[Step 17270] Loss: 9.46e+07 -0.7550373673439026 0.19354824721813202\n",
      "[Step 17271] Loss: 9.47e+07 -0.7549437880516052 0.19357217848300934\n",
      "[Step 17272] Loss: 9.45e+07 -0.7549585700035095 0.19355981051921844\n",
      "[Step 17273] Loss: 9.47e+07 -0.7549886703491211 0.1935548484325409\n",
      "[Step 17274] Loss: 9.45e+07 -0.7550714612007141 0.1935342252254486\n",
      "[Step 17275] Loss: 9.61e+07 -0.7553125619888306 0.19350039958953857\n",
      "[Step 17276] Loss: 9.37e+07 -0.755587100982666 0.1934393346309662\n",
      "[Step 17277] Loss: 9.47e+07 -0.7558599710464478 0.1934046745300293\n",
      "[Step 17278] Loss: 9.46e+07 -0.7561403512954712 0.19334279000759125\n",
      "[Step 17279] Loss: 9.43e+07 -0.7563295960426331 0.1932767778635025\n",
      "[Step 17280] Loss: 9.48e+07 -0.7565162181854248 0.19325284659862518\n",
      "[Step 17281] Loss: 9.44e+07 -0.7566300630569458 0.19322974979877472\n",
      "[Step 17282] Loss: 9.45e+07 -0.7566699385643005 0.19324129819869995\n",
      "[Step 17283] Loss: 9.47e+07 -0.7567213773727417 0.19322480261325836\n",
      "[Step 17284] Loss: 9.41e+07 -0.756766140460968 0.19323140382766724\n",
      "[Step 17285] Loss: 9.55e+07 -0.756881594657898 0.19318684935569763\n",
      "[Step 17286] Loss: 9.42e+07 -0.7569928169250488 0.19317694008350372\n",
      "[Step 17287] Loss: 9.56e+07 -0.756914496421814 0.19319674372673035\n",
      "[Step 17288] Loss: 9.53e+07 -0.7569524645805359 0.19319839775562286\n",
      "[Step 17289] Loss: 9.50e+07 -0.7569781541824341 0.19319261610507965\n",
      "[Step 17290] Loss: 9.46e+07 -0.7570219039916992 0.193197563290596\n",
      "[Step 17291] Loss: 9.43e+07 -0.7570745348930359 0.19319261610507965\n",
      "[Step 17292] Loss: 9.41e+07 -0.7571980357170105 0.19315795600414276\n",
      "[Step 17293] Loss: 9.52e+07 -0.7571763396263123 0.19317199289798737\n",
      "[Step 17294] Loss: 9.42e+07 -0.7571551203727722 0.19315961003303528\n",
      "[Step 17295] Loss: 9.51e+07 -0.7571877241134644 0.1931488811969757\n",
      "[Step 17296] Loss: 9.49e+07 -0.7573052644729614 0.1931001991033554\n",
      "[Step 17297] Loss: 9.45e+07 -0.7573738098144531 0.1930556446313858\n",
      "[Step 17298] Loss: 9.54e+07 -0.7573052644729614 0.1930416226387024\n",
      "[Step 17299] Loss: 9.48e+07 -0.7572352886199951 0.1930515170097351\n",
      "[Step 17300] Loss: 9.50e+07 -0.7572752833366394 0.19303996860980988\n",
      "[Step 17301] Loss: 9.47e+07 -0.7572968602180481 0.19300201535224915\n",
      "[Step 17302] Loss: 9.45e+07 -0.75732421875 0.19298797845840454\n",
      "[Step 17303] Loss: 9.48e+07 -0.7573755979537964 0.19298303127288818\n",
      "[Step 17304] Loss: 9.47e+07 -0.7573606371879578 0.19298055768013\n",
      "[Step 17305] Loss: 9.44e+07 -0.7573891282081604 0.19295580685138702\n",
      "[Step 17306] Loss: 9.39e+07 -0.7574589252471924 0.19293516874313354\n",
      "[Step 17307] Loss: 9.41e+07 -0.7575240135192871 0.1928732842206955\n",
      "[Step 17308] Loss: 9.46e+07 -0.7575933337211609 0.19284605979919434\n",
      "[Step 17309] Loss: 9.59e+07 -0.757840633392334 0.19280315935611725\n",
      "[Step 17310] Loss: 9.42e+07 -0.7581449747085571 0.1927231103181839\n",
      "[Step 17311] Loss: 9.46e+07 -0.7584847807884216 0.19263812899589539\n",
      "[Step 17312] Loss: 9.41e+07 -0.7587637305259705 0.19255231320858002\n",
      "[Step 17313] Loss: 9.49e+07 -0.7590737342834473 0.19250032305717468\n",
      "[Step 17314] Loss: 9.48e+07 -0.759285032749176 0.19242770969867706\n",
      "[Step 17315] Loss: 9.51e+07 -0.7595332860946655 0.19235511124134064\n",
      "[Step 17316] Loss: 9.47e+07 -0.7597816586494446 0.1923155039548874\n",
      "[Step 17317] Loss: 9.51e+07 -0.759929895401001 0.19228991866111755\n",
      "[Step 17318] Loss: 9.48e+07 -0.759971559047699 0.19225609302520752\n",
      "[Step 17319] Loss: 9.57e+07 -0.7600318193435669 0.1922461837530136\n",
      "[Step 17320] Loss: 9.50e+07 -0.7600854635238647 0.19221895933151245\n",
      "[Step 17321] Loss: 9.49e+07 -0.7602224946022034 0.19221070408821106\n",
      "[Step 17322] Loss: 9.46e+07 -0.7602389454841614 0.1921958476305008\n",
      "[Step 17323] Loss: 9.45e+07 -0.7603421211242676 0.1921694427728653\n",
      "[Step 17324] Loss: 9.52e+07 -0.7605895400047302 0.19211003184318542\n",
      "[Step 17325] Loss: 9.52e+07 -0.7609339952468872 0.19202092289924622\n",
      "[Step 17326] Loss: 9.45e+07 -0.7612216472625732 0.1919763684272766\n",
      "[Step 17327] Loss: 9.53e+07 -0.7614300847053528 0.1919219046831131\n",
      "[Step 17328] Loss: 9.55e+07 -0.761508047580719 0.19188560545444489\n",
      "[Step 17329] Loss: 9.45e+07 -0.7615241408348083 0.1918831318616867\n",
      "[Step 17330] Loss: 9.49e+07 -0.7616252303123474 0.1918327957391739\n",
      "[Step 17331] Loss: 9.45e+07 -0.7617006301879883 0.1918162852525711\n",
      "[Step 17332] Loss: 9.47e+07 -0.761726438999176 0.19178824126720428\n",
      "[Step 17333] Loss: 9.50e+07 -0.7615892291069031 0.1917940080165863\n",
      "[Step 17334] Loss: 9.38e+07 -0.7614193558692932 0.19179731607437134\n",
      "[Step 17335] Loss: 9.51e+07 -0.7611827850341797 0.19181711971759796\n",
      "[Step 17336] Loss: 9.50e+07 -0.7610002756118774 0.19183608889579773\n",
      "[Step 17337] Loss: 9.40e+07 -0.7608468532562256 0.19183939695358276\n",
      "[Step 17338] Loss: 9.43e+07 -0.7606562972068787 0.1918690949678421\n",
      "[Step 17339] Loss: 9.42e+07 -0.7605000734329224 0.1918690949678421\n",
      "[Step 17340] Loss: 9.43e+07 -0.7604741454124451 0.19186992943286896\n",
      "[Step 17341] Loss: 9.45e+07 -0.7603386044502258 0.19186744093894958\n",
      "[Step 17342] Loss: 9.48e+07 -0.7602213025093079 0.19188889861106873\n",
      "[Step 17343] Loss: 9.47e+07 -0.7601080536842346 0.19190704822540283\n",
      "[Step 17344] Loss: 9.46e+07 -0.7599377632141113 0.19191530346870422\n",
      "[Step 17345] Loss: 9.48e+07 -0.7597812414169312 0.19193345308303833\n",
      "[Step 17346] Loss: 9.51e+07 -0.7598623037338257 0.19192934036254883\n",
      "[Step 17347] Loss: 9.43e+07 -0.7599155902862549 0.19191448390483856\n",
      "[Step 17348] Loss: 9.47e+07 -0.7600359320640564 0.19188477098941803\n",
      "[Step 17349] Loss: 9.50e+07 -0.7600318789482117 0.19186662137508392\n",
      "[Step 17350] Loss: 9.47e+07 -0.7600433826446533 0.19186662137508392\n",
      "[Step 17351] Loss: 9.42e+07 -0.7600618004798889 0.1918732225894928\n",
      "[Step 17352] Loss: 9.39e+07 -0.760114312171936 0.19189797341823578\n",
      "[Step 17353] Loss: 9.53e+07 -0.7601949572563171 0.1918913722038269\n",
      "[Step 17354] Loss: 9.41e+07 -0.7601752877235413 0.19189220666885376\n",
      "[Step 17355] Loss: 9.47e+07 -0.760240375995636 0.19188229739665985\n",
      "[Step 17356] Loss: 9.43e+07 -0.7602965831756592 0.19188973307609558\n",
      "[Step 17357] Loss: 9.49e+07 -0.7603067755699158 0.1918831318616867\n",
      "[Step 17358] Loss: 9.47e+07 -0.7603664994239807 0.1918525993824005\n",
      "[Step 17359] Loss: 9.55e+07 -0.7602756023406982 0.19184847176074982\n",
      "[Step 17360] Loss: 9.53e+07 -0.7603573203086853 0.1918344497680664\n",
      "[Step 17361] Loss: 9.54e+07 -0.7606846690177917 0.19177091121673584\n",
      "[Step 17362] Loss: 9.41e+07 -0.7610156536102295 0.19167354702949524\n",
      "[Step 17363] Loss: 9.57e+07 -0.761178195476532 0.1916562169790268\n",
      "[Step 17364] Loss: 9.44e+07 -0.7612869143486023 0.19161413609981537\n",
      "[Step 17365] Loss: 9.44e+07 -0.7613052129745483 0.19159020483493805\n",
      "[Step 17366] Loss: 9.42e+07 -0.7612953782081604 0.19154317677021027\n",
      "[Step 17367] Loss: 9.51e+07 -0.7612739205360413 0.19150438904762268\n",
      "[Step 17368] Loss: 9.50e+07 -0.7613102197647095 0.19147633016109467\n",
      "[Step 17369] Loss: 9.50e+07 -0.7612333297729492 0.1914878785610199\n",
      "[Step 17370] Loss: 9.43e+07 -0.7611506581306458 0.19151099026203156\n",
      "[Step 17371] Loss: 9.43e+07 -0.7610838413238525 0.19151099026203156\n",
      "[Step 17372] Loss: 9.46e+07 -0.7609827518463135 0.1915225386619568\n",
      "[Step 17373] Loss: 9.52e+07 -0.7607780694961548 0.19152913987636566\n",
      "[Step 17374] Loss: 9.43e+07 -0.7606077194213867 0.19153821468353271\n",
      "[Step 17375] Loss: 9.52e+07 -0.7606185674667358 0.19153492152690887\n",
      "[Step 17376] Loss: 9.52e+07 -0.7607646584510803 0.19149118661880493\n",
      "[Step 17377] Loss: 9.49e+07 -0.7609556317329407 0.19142435491085052\n",
      "[Step 17378] Loss: 9.42e+07 -0.7610306143760681 0.19143259525299072\n",
      "[Step 17379] Loss: 9.51e+07 -0.7612077593803406 0.19135668873786926\n",
      "[Step 17380] Loss: 9.44e+07 -0.7612393498420715 0.19130469858646393\n",
      "[Step 17381] Loss: 9.51e+07 -0.7613499760627747 0.1912750005722046\n",
      "[Step 17382] Loss: 9.52e+07 -0.7614966034889221 0.19124199450016022\n",
      "[Step 17383] Loss: 9.47e+07 -0.761550784111023 0.19123126566410065\n",
      "[Step 17384] Loss: 9.41e+07 -0.7616238594055176 0.19120898842811584\n",
      "[Step 17385] Loss: 9.62e+07 -0.7615240216255188 0.19121477007865906\n",
      "[Step 17386] Loss: 9.49e+07 -0.7614057064056396 0.19121558964252472\n",
      "[Step 17387] Loss: 9.46e+07 -0.7613884806632996 0.19118258357048035\n",
      "[Step 17388] Loss: 9.48e+07 -0.7614099383354187 0.1911735087633133\n",
      "[Step 17389] Loss: 9.44e+07 -0.7613934874534607 0.1911735087633133\n",
      "[Step 17390] Loss: 9.42e+07 -0.761414110660553 0.19113968312740326\n",
      "[Step 17391] Loss: 9.39e+07 -0.7614325881004333 0.19113308191299438\n",
      "[Step 17392] Loss: 9.55e+07 -0.7612959742546082 0.1911289542913437\n",
      "[Step 17393] Loss: 9.46e+07 -0.761181116104126 0.19114463031291962\n",
      "[Step 17394] Loss: 9.48e+07 -0.761151909828186 0.1911471039056778\n",
      "[Step 17395] Loss: 9.51e+07 -0.7610112428665161 0.19115617871284485\n",
      "[Step 17396] Loss: 9.55e+07 -0.7610238790512085 0.1911553591489792\n",
      "[Step 17397] Loss: 9.44e+07 -0.7609535455703735 0.191152885556221\n",
      "[Step 17398] Loss: 9.52e+07 -0.7607893347740173 0.19117845594882965\n",
      "[Step 17399] Loss: 9.44e+07 -0.760593593120575 0.19121311604976654\n",
      "[Step 17400] Loss: 9.47e+07 -0.760539174079895 0.19120486080646515\n",
      "[Step 17401] Loss: 9.49e+07 -0.7604179978370667 0.19121971726417542\n",
      "[Step 17402] Loss: 9.47e+07 -0.7603597044944763 0.19123539328575134\n",
      "[Step 17403] Loss: 9.46e+07 -0.7603049874305725 0.19122137129306793\n",
      "[Step 17404] Loss: 9.46e+07 -0.7602450847625732 0.19124117493629456\n",
      "[Step 17405] Loss: 9.52e+07 -0.760063648223877 0.19129809737205505\n",
      "[Step 17406] Loss: 9.53e+07 -0.7601336240768433 0.19129562377929688\n",
      "[Step 17407] Loss: 9.50e+07 -0.7602018713951111 0.19128160178661346\n",
      "[Step 17408] Loss: 9.45e+07 -0.7602936029434204 0.1912725269794464\n",
      "[Step 17409] Loss: 9.49e+07 -0.7604145407676697 0.1912238448858261\n",
      "[Step 17410] Loss: 9.56e+07 -0.7606938481330872 0.19120238721370697\n",
      "[Step 17411] Loss: 9.46e+07 -0.7608871459960938 0.1911875307559967\n",
      "[Step 17412] Loss: 9.48e+07 -0.7611331939697266 0.19111162424087524\n",
      "[Step 17413] Loss: 9.47e+07 -0.7613229751586914 0.19107449054718018\n",
      "[Step 17414] Loss: 9.47e+07 -0.7615164518356323 0.19102910161018372\n",
      "[Step 17415] Loss: 9.45e+07 -0.7615986466407776 0.19098950922489166\n",
      "[Step 17416] Loss: 9.51e+07 -0.7617301940917969 0.1909482479095459\n",
      "[Step 17417] Loss: 9.43e+07 -0.7618874311447144 0.1908954381942749\n",
      "[Step 17418] Loss: 9.67e+07 -0.7618156671524048 0.190885528922081\n",
      "[Step 17419] Loss: 9.44e+07 -0.7617731690406799 0.1908814162015915\n",
      "[Step 17420] Loss: 9.45e+07 -0.7617696523666382 0.19086572527885437\n",
      "[Step 17421] Loss: 9.51e+07 -0.761882483959198 0.19084180891513824\n",
      "[Step 17422] Loss: 9.44e+07 -0.7619919180870056 0.19080136716365814\n",
      "[Step 17423] Loss: 9.42e+07 -0.7620932459831238 0.19078321754932404\n",
      "[Step 17424] Loss: 9.46e+07 -0.7620900869369507 0.1907922923564911\n",
      "[Step 17425] Loss: 9.49e+07 -0.7621809244155884 0.19078569114208221\n",
      "[Step 17426] Loss: 9.44e+07 -0.7621946930885315 0.1907576322555542\n",
      "[Step 17427] Loss: 9.58e+07 -0.7624213695526123 0.19070565700531006\n",
      "[Step 17428] Loss: 9.44e+07 -0.7626286149024963 0.19064871966838837\n",
      "[Step 17429] Loss: 9.41e+07 -0.7627980709075928 0.19060911238193512\n",
      "[Step 17430] Loss: 9.53e+07 -0.7631285190582275 0.19053815305233002\n",
      "[Step 17431] Loss: 9.52e+07 -0.763556182384491 0.19043171405792236\n",
      "[Step 17432] Loss: 9.43e+07 -0.7640393972396851 0.19033022224903107\n",
      "[Step 17433] Loss: 9.51e+07 -0.7643805742263794 0.19026173651218414\n",
      "[Step 17434] Loss: 9.49e+07 -0.7647867798805237 0.19021469354629517\n",
      "[Step 17435] Loss: 9.56e+07 -0.7650601863861084 0.19018086791038513\n",
      "[Step 17436] Loss: 9.47e+07 -0.7654116749763489 0.1901123821735382\n",
      "[Step 17437] Loss: 9.56e+07 -0.7659240961074829 0.1900108903646469\n",
      "[Step 17438] Loss: 9.50e+07 -0.7665042877197266 0.18990857899188995\n",
      "[Step 17439] Loss: 9.52e+07 -0.7670199275016785 0.18980708718299866\n",
      "[Step 17440] Loss: 9.51e+07 -0.7673435211181641 0.18975922465324402\n",
      "[Step 17441] Loss: 9.41e+07 -0.7676752805709839 0.1896866112947464\n",
      "[Step 17442] Loss: 9.49e+07 -0.7679418325424194 0.189672589302063\n",
      "[Step 17443] Loss: 9.43e+07 -0.7681717872619629 0.1896239072084427\n",
      "[Step 17444] Loss: 9.43e+07 -0.7684746980667114 0.18955376744270325\n",
      "[Step 17445] Loss: 9.48e+07 -0.7688384652137756 0.18950261175632477\n",
      "[Step 17446] Loss: 9.44e+07 -0.7690941691398621 0.18946217000484467\n",
      "[Step 17447] Loss: 9.49e+07 -0.7693860530853271 0.18941761553287506\n",
      "[Step 17448] Loss: 9.42e+07 -0.7696737051010132 0.18936645984649658\n",
      "[Step 17449] Loss: 9.48e+07 -0.7699539661407471 0.18930210173130035\n",
      "[Step 17450] Loss: 9.45e+07 -0.7701680064201355 0.18925423920154572\n",
      "[Step 17451] Loss: 9.46e+07 -0.770352303981781 0.18921957910060883\n",
      "[Step 17452] Loss: 9.48e+07 -0.7705671787261963 0.18919235467910767\n",
      "[Step 17453] Loss: 9.52e+07 -0.7707761526107788 0.18915852904319763\n",
      "[Step 17454] Loss: 9.47e+07 -0.7709559202194214 0.1891345977783203\n",
      "[Step 17455] Loss: 9.48e+07 -0.7711968421936035 0.1890842616558075\n",
      "[Step 17456] Loss: 9.45e+07 -0.7713054418563843 0.1890619844198227\n",
      "[Step 17457] Loss: 9.52e+07 -0.7715216279029846 0.1890314519405365\n",
      "[Step 17458] Loss: 9.47e+07 -0.7716990113258362 0.18899184465408325\n",
      "[Step 17459] Loss: 9.42e+07 -0.7717887759208679 0.18897782266139984\n",
      "[Step 17460] Loss: 9.52e+07 -0.7720813155174255 0.18887796998023987\n",
      "[Step 17461] Loss: 9.51e+07 -0.772430956363678 0.18880701065063477\n",
      "[Step 17462] Loss: 9.57e+07 -0.7729451656341553 0.188707172870636\n",
      "[Step 17463] Loss: 9.41e+07 -0.7734514474868774 0.18862879276275635\n",
      "[Step 17464] Loss: 9.53e+07 -0.7738011479377747 0.1885569989681244\n",
      "[Step 17465] Loss: 9.50e+07 -0.7739805579185486 0.1885446161031723\n",
      "[Step 17466] Loss: 9.43e+07 -0.7741374373435974 0.1885322481393814\n",
      "[Step 17467] Loss: 9.38e+07 -0.7742136120796204 0.18850089609622955\n",
      "[Step 17468] Loss: 9.49e+07 -0.774224042892456 0.18849429488182068\n",
      "[Step 17469] Loss: 9.44e+07 -0.7742433547973633 0.18847200274467468\n",
      "[Step 17470] Loss: 9.48e+07 -0.7742976546287537 0.1884596347808838\n",
      "[Step 17471] Loss: 9.45e+07 -0.774455189704895 0.18841837346553802\n",
      "[Step 17472] Loss: 9.51e+07 -0.774746835231781 0.18829955160617828\n",
      "[Step 17473] Loss: 9.55e+07 -0.7751584053039551 0.18820302188396454\n",
      "[Step 17474] Loss: 9.44e+07 -0.7755205631256104 0.18812957406044006\n",
      "[Step 17475] Loss: 9.51e+07 -0.7758336663246155 0.18807759881019592\n",
      "[Step 17476] Loss: 9.50e+07 -0.7761576175689697 0.18801653385162354\n",
      "[Step 17477] Loss: 9.39e+07 -0.7764377593994141 0.18798434734344482\n",
      "[Step 17478] Loss: 9.50e+07 -0.7766241431236267 0.18795959651470184\n",
      "[Step 17479] Loss: 9.41e+07 -0.7767573595046997 0.18792824447155\n",
      "[Step 17480] Loss: 9.52e+07 -0.7770651578903198 0.18789854645729065\n",
      "[Step 17481] Loss: 9.43e+07 -0.7772769927978516 0.1878366470336914\n",
      "[Step 17482] Loss: 9.59e+07 -0.7777425646781921 0.18776486814022064\n",
      "[Step 17483] Loss: 9.49e+07 -0.7783061265945435 0.187658429145813\n",
      "[Step 17484] Loss: 9.51e+07 -0.7789651155471802 0.18754373490810394\n",
      "[Step 17485] Loss: 9.44e+07 -0.7795271277427673 0.18744800984859467\n",
      "[Step 17486] Loss: 9.45e+07 -0.7800942659378052 0.1873580813407898\n",
      "[Step 17487] Loss: 9.48e+07 -0.7805825471878052 0.18726813793182373\n",
      "[Step 17488] Loss: 9.40e+07 -0.7810019254684448 0.18716830015182495\n",
      "[Step 17489] Loss: 9.41e+07 -0.7813653349876404 0.187096506357193\n",
      "[Step 17490] Loss: 9.57e+07 -0.7819880843162537 0.1869422048330307\n",
      "[Step 17491] Loss: 9.44e+07 -0.782472550868988 0.18685638904571533\n",
      "[Step 17492] Loss: 9.47e+07 -0.7828967571258545 0.18674416840076447\n",
      "[Step 17493] Loss: 9.43e+07 -0.7831886410713196 0.18667815625667572\n",
      "[Step 17494] Loss: 9.43e+07 -0.7834361791610718 0.18661463260650635\n",
      "[Step 17495] Loss: 9.51e+07 -0.7837732434272766 0.18655934929847717\n",
      "[Step 17496] Loss: 9.49e+07 -0.7841113805770874 0.1865139603614807\n",
      "[Step 17497] Loss: 9.41e+07 -0.7845227122306824 0.18642567098140717\n",
      "[Step 17498] Loss: 9.43e+07 -0.7849185466766357 0.18635223805904388\n",
      "[Step 17499] Loss: 9.50e+07 -0.7852489948272705 0.18627631664276123\n",
      "[Step 17500] Loss: 9.49e+07 -0.7856014966964722 0.186183899641037\n",
      "[Step 17501] Loss: 9.48e+07 -0.7859399318695068 0.1860865354537964\n",
      "[Step 17502] Loss: 9.46e+07 -0.7862452864646912 0.18604445457458496\n",
      "[Step 17503] Loss: 9.50e+07 -0.7863590121269226 0.18601392209529877\n",
      "[Step 17504] Loss: 9.46e+07 -0.7866570949554443 0.1859602928161621\n",
      "[Step 17505] Loss: 9.47e+07 -0.7869649529457092 0.18592068552970886\n",
      "[Step 17506] Loss: 9.52e+07 -0.7871940732002258 0.18586045503616333\n",
      "[Step 17507] Loss: 9.40e+07 -0.7873779535293579 0.18581093847751617\n",
      "[Step 17508] Loss: 9.49e+07 -0.7874626517295837 0.18579278886318207\n",
      "[Step 17509] Loss: 9.52e+07 -0.7874437570571899 0.1857878416776657\n",
      "[Step 17510] Loss: 9.50e+07 -0.7874864935874939 0.18577876687049866\n",
      "[Step 17511] Loss: 9.47e+07 -0.7874470949172974 0.18578124046325684\n",
      "[Step 17512] Loss: 9.46e+07 -0.7874019145965576 0.18578040599822998\n",
      "[Step 17513] Loss: 9.40e+07 -0.7872925996780396 0.1857960969209671\n",
      "[Step 17514] Loss: 9.42e+07 -0.7872021198272705 0.185808464884758\n",
      "[Step 17515] Loss: 9.44e+07 -0.787232518196106 0.18580764532089233\n",
      "[Step 17516] Loss: 9.43e+07 -0.7872769832611084 0.18580599129199982\n",
      "[Step 17517] Loss: 9.46e+07 -0.787243664264679 0.18582497537136078\n",
      "[Step 17518] Loss: 9.47e+07 -0.7872297763824463 0.18582414090633392\n",
      "[Step 17519] Loss: 9.49e+07 -0.7872048020362854 0.18583405017852783\n",
      "[Step 17520] Loss: 9.49e+07 -0.7871643900871277 0.18583405017852783\n",
      "[Step 17521] Loss: 9.52e+07 -0.787238359451294 0.18581590056419373\n",
      "[Step 17522] Loss: 9.47e+07 -0.7874056100845337 0.18582166731357574\n",
      "[Step 17523] Loss: 9.50e+07 -0.7876805663108826 0.1857820600271225\n",
      "[Step 17524] Loss: 9.47e+07 -0.7879091501235962 0.1856946051120758\n",
      "[Step 17525] Loss: 9.49e+07 -0.7881552577018738 0.18566736578941345\n",
      "[Step 17526] Loss: 9.54e+07 -0.7882532477378845 0.18566736578941345\n",
      "[Step 17527] Loss: 9.44e+07 -0.7883948683738708 0.18565499782562256\n",
      "[Step 17528] Loss: 9.48e+07 -0.7884804606437683 0.1856417953968048\n",
      "[Step 17529] Loss: 9.47e+07 -0.7885305881500244 0.18562611937522888\n",
      "[Step 17530] Loss: 9.49e+07 -0.7885235548019409 0.18562941253185272\n",
      "[Step 17531] Loss: 9.45e+07 -0.7886471748352051 0.18562281131744385\n",
      "[Step 17532] Loss: 9.39e+07 -0.7887070775032043 0.18562281131744385\n",
      "[Step 17533] Loss: 9.41e+07 -0.7887586951255798 0.18564343452453613\n",
      "[Step 17534] Loss: 9.40e+07 -0.7887880206108093 0.18562611937522888\n",
      "[Step 17535] Loss: 9.49e+07 -0.7887899875640869 0.18562611937522888\n",
      "[Step 17536] Loss: 9.48e+07 -0.7888813614845276 0.18559806048870087\n",
      "[Step 17537] Loss: 9.45e+07 -0.7888974547386169 0.1856178641319275\n",
      "[Step 17538] Loss: 9.43e+07 -0.7889204025268555 0.18560878932476044\n",
      "[Step 17539] Loss: 9.45e+07 -0.788923442363739 0.1856360137462616\n",
      "[Step 17540] Loss: 9.36e+07 -0.7888954281806946 0.18561621010303497\n",
      "[Step 17541] Loss: 9.52e+07 -0.7889169454574585 0.18562941253185272\n",
      "[Step 17542] Loss: 9.50e+07 -0.7889782190322876 0.18561868369579315\n",
      "[Step 17543] Loss: 9.37e+07 -0.7890719771385193 0.18559062480926514\n",
      "[Step 17544] Loss: 9.55e+07 -0.7890374064445496 0.18559393286705017\n",
      "[Step 17545] Loss: 9.51e+07 -0.7888463735580444 0.18561702966690063\n",
      "[Step 17546] Loss: 9.42e+07 -0.7885997891426086 0.18564921617507935\n",
      "[Step 17547] Loss: 9.47e+07 -0.788307785987854 0.18567562103271484\n",
      "[Step 17548] Loss: 9.41e+07 -0.7881088256835938 0.18568964302539825\n",
      "[Step 17549] Loss: 9.46e+07 -0.7878786325454712 0.18573997914791107\n",
      "[Step 17550] Loss: 9.49e+07 -0.7877116203308105 0.1857696920633316\n",
      "[Step 17551] Loss: 9.39e+07 -0.7875537276268005 0.18579278886318207\n",
      "[Step 17552] Loss: 9.49e+07 -0.787543535232544 0.18578124046325684\n",
      "[Step 17553] Loss: 9.59e+07 -0.7877885103225708 0.1857333779335022\n",
      "[Step 17554] Loss: 9.46e+07 -0.7880339622497559 0.1856764405965805\n",
      "[Step 17555] Loss: 9.79e+07 -0.7887285947799683 0.18555350601673126\n",
      "[Step 17556] Loss: 9.44e+07 -0.7894073724746704 0.18543384969234467\n",
      "[Step 17557] Loss: 9.48e+07 -0.7900524139404297 0.18532328307628632\n",
      "[Step 17558] Loss: 9.50e+07 -0.7905890941619873 0.18522179126739502\n",
      "[Step 17559] Loss: 9.47e+07 -0.7912018895149231 0.18509967625141144\n",
      "[Step 17560] Loss: 9.44e+07 -0.7917559742927551 0.18497756123542786\n",
      "[Step 17561] Loss: 9.46e+07 -0.7923853397369385 0.1848735809326172\n",
      "[Step 17562] Loss: 9.45e+07 -0.7928835153579712 0.18478941917419434\n",
      "[Step 17563] Loss: 9.46e+07 -0.7932975888252258 0.18472671508789062\n",
      "[Step 17564] Loss: 9.51e+07 -0.7938247919082642 0.18464750051498413\n",
      "[Step 17565] Loss: 9.56e+07 -0.7945237159729004 0.1845245510339737\n",
      "[Step 17566] Loss: 9.45e+07 -0.7951432466506958 0.18441976606845856\n",
      "[Step 17567] Loss: 9.49e+07 -0.795722484588623 0.1843256950378418\n",
      "[Step 17568] Loss: 9.60e+07 -0.7964867949485779 0.1841796487569809\n",
      "[Step 17569] Loss: 9.42e+07 -0.7971859574317932 0.18405504524707794\n",
      "[Step 17570] Loss: 9.54e+07 -0.7976969480514526 0.18393374979496002\n",
      "[Step 17571] Loss: 9.53e+07 -0.7982900142669678 0.183847114443779\n",
      "[Step 17572] Loss: 9.45e+07 -0.7987241744995117 0.18378441035747528\n",
      "[Step 17573] Loss: 9.45e+07 -0.7991918921470642 0.1837051957845688\n",
      "[Step 17574] Loss: 9.42e+07 -0.7996371388435364 0.1836012303829193\n",
      "[Step 17575] Loss: 9.46e+07 -0.8000603318214417 0.18353191018104553\n",
      "[Step 17576] Loss: 9.45e+07 -0.8004462122917175 0.18347497284412384\n",
      "[Step 17577] Loss: 9.51e+07 -0.8007879853248596 0.18339824676513672\n",
      "[Step 17578] Loss: 9.48e+07 -0.8010535836219788 0.18333058059215546\n",
      "[Step 17579] Loss: 9.52e+07 -0.8014123439788818 0.18328849971294403\n",
      "[Step 17580] Loss: 9.53e+07 -0.8017662167549133 0.18321670591831207\n",
      "[Step 17581] Loss: 9.44e+07 -0.8020704388618469 0.18315400183200836\n",
      "[Step 17582] Loss: 9.52e+07 -0.8022375702857971 0.18309789896011353\n",
      "[Step 17583] Loss: 9.44e+07 -0.8023450970649719 0.1830904632806778\n",
      "[Step 17584] Loss: 9.49e+07 -0.8023911714553833 0.1830558031797409\n",
      "[Step 17585] Loss: 9.49e+07 -0.8024240136146545 0.18305332958698273\n",
      "[Step 17586] Loss: 9.46e+07 -0.8024574518203735 0.18302610516548157\n",
      "[Step 17587] Loss: 9.45e+07 -0.8024411201477051 0.18304343521595\n",
      "[Step 17588] Loss: 9.57e+07 -0.8026496171951294 0.18298815190792084\n",
      "[Step 17589] Loss: 9.51e+07 -0.8028166890144348 0.18296504020690918\n",
      "[Step 17590] Loss: 9.40e+07 -0.803000271320343 0.18290399014949799\n",
      "[Step 17591] Loss: 9.45e+07 -0.8031176924705505 0.18285034596920013\n",
      "[Step 17592] Loss: 9.47e+07 -0.8032415509223938 0.18281733989715576\n",
      "[Step 17593] Loss: 9.43e+07 -0.8033465147018433 0.18277856707572937\n",
      "[Step 17594] Loss: 9.51e+07 -0.8034157752990723 0.18276123702526093\n",
      "[Step 17595] Loss: 9.47e+07 -0.8033515214920044 0.1827620565891266\n",
      "[Step 17596] Loss: 9.36e+07 -0.8032856583595276 0.18275876343250275\n",
      "[Step 17597] Loss: 9.44e+07 -0.8033002018928528 0.18273401260375977\n",
      "[Step 17598] Loss: 9.45e+07 -0.8032956719398499 0.1827249377965927\n",
      "[Step 17599] Loss: 9.53e+07 -0.8034540414810181 0.18268944323062897\n",
      "[Step 17600] Loss: 9.47e+07 -0.8035378456115723 0.18266387283802032\n",
      "[Step 17601] Loss: 9.41e+07 -0.8035567998886108 0.18263912200927734\n",
      "[Step 17602] Loss: 9.50e+07 -0.803629457950592 0.18262013792991638\n",
      "[Step 17603] Loss: 9.46e+07 -0.8036308884620667 0.1826316863298416\n",
      "[Step 17604] Loss: 9.45e+07 -0.8036152720451355 0.18263912200927734\n",
      "[Step 17605] Loss: 9.50e+07 -0.8033558130264282 0.18270017206668854\n",
      "[Step 17606] Loss: 9.47e+07 -0.803131103515625 0.18273977935314178\n",
      "[Step 17607] Loss: 9.42e+07 -0.8029884696006775 0.18277113139629364\n",
      "[Step 17608] Loss: 9.45e+07 -0.8028720021247864 0.18278351426124573\n",
      "[Step 17609] Loss: 9.39e+07 -0.8027031421661377 0.18279589712619781\n",
      "[Step 17610] Loss: 9.50e+07 -0.8024722337722778 0.18282806873321533\n",
      "[Step 17611] Loss: 9.50e+07 -0.8023748397827148 0.18283963203430176\n",
      "[Step 17612] Loss: 9.39e+07 -0.8022834658622742 0.1828487068414688\n",
      "[Step 17613] Loss: 9.47e+07 -0.80229651927948 0.18285612761974335\n",
      "[Step 17614] Loss: 9.46e+07 -0.8023173809051514 0.18283385038375854\n",
      "[Step 17615] Loss: 9.45e+07 -0.8021740913391113 0.18286190927028656\n",
      "[Step 17616] Loss: 9.39e+07 -0.8019518256187439 0.18287593126296997\n",
      "[Step 17617] Loss: 9.42e+07 -0.8018563389778137 0.18288418650627136\n",
      "[Step 17618] Loss: 9.50e+07 -0.801707923412323 0.18291635811328888\n",
      "[Step 17619] Loss: 9.38e+07 -0.8015446662902832 0.1829221397638321\n",
      "[Step 17620] Loss: 9.50e+07 -0.8014004826545715 0.18294194340705872\n",
      "[Step 17621] Loss: 9.42e+07 -0.8012405037879944 0.18297411501407623\n",
      "[Step 17622] Loss: 9.42e+07 -0.8010897040367126 0.18299557268619537\n",
      "[Step 17623] Loss: 9.46e+07 -0.8008360862731934 0.1830376535654068\n",
      "[Step 17624] Loss: 9.41e+07 -0.8004990816116333 0.18309293687343597\n",
      "[Step 17625] Loss: 9.46e+07 -0.8001912236213684 0.18312346935272217\n",
      "[Step 17626] Loss: 9.43e+07 -0.7999122142791748 0.18314987421035767\n",
      "[Step 17627] Loss: 9.51e+07 -0.7996970415115356 0.18316225707530975\n",
      "[Step 17628] Loss: 9.50e+07 -0.7995255589485168 0.18315482139587402\n",
      "[Step 17629] Loss: 9.44e+07 -0.7994104027748108 0.18319278955459595\n",
      "[Step 17630] Loss: 9.48e+07 -0.7993260622024536 0.18320681154727936\n",
      "[Step 17631] Loss: 9.49e+07 -0.7992957830429077 0.18318700790405273\n",
      "[Step 17632] Loss: 9.44e+07 -0.7993327379226685 0.1831977367401123\n",
      "[Step 17633] Loss: 9.53e+07 -0.7993621230125427 0.1831754595041275\n",
      "[Step 17634] Loss: 9.51e+07 -0.7994552254676819 0.1831572949886322\n",
      "[Step 17635] Loss: 9.43e+07 -0.799449622631073 0.18314822018146515\n",
      "[Step 17636] Loss: 9.45e+07 -0.7995488047599792 0.18312925100326538\n",
      "[Step 17637] Loss: 9.48e+07 -0.7995556592941284 0.18309541046619415\n",
      "[Step 17638] Loss: 9.47e+07 -0.7994739413261414 0.1831185221672058\n",
      "[Step 17639] Loss: 9.49e+07 -0.7994733452796936 0.18313172459602356\n",
      "[Step 17640] Loss: 9.48e+07 -0.7994539141654968 0.18312594294548035\n",
      "[Step 17641] Loss: 9.41e+07 -0.7993791699409485 0.1830739676952362\n",
      "[Step 17642] Loss: 9.49e+07 -0.7994388937950134 0.18303601443767548\n",
      "[Step 17643] Loss: 9.47e+07 -0.7995899319648743 0.1830071210861206\n",
      "[Step 17644] Loss: 9.53e+07 -0.7996243238449097 0.18297742307186127\n",
      "[Step 17645] Loss: 9.50e+07 -0.7997344136238098 0.18296340107917786\n",
      "[Step 17646] Loss: 9.42e+07 -0.7998599410057068 0.1829196661710739\n",
      "[Step 17647] Loss: 9.46e+07 -0.7999969720840454 0.1828833520412445\n",
      "[Step 17648] Loss: 9.52e+07 -0.8003035187721252 0.1828470528125763\n",
      "[Step 17649] Loss: 9.44e+07 -0.8005355000495911 0.1828000247478485\n",
      "[Step 17650] Loss: 9.47e+07 -0.8008148074150085 0.18276041746139526\n",
      "[Step 17651] Loss: 9.50e+07 -0.8010294437408447 0.18269853293895721\n",
      "[Step 17652] Loss: 9.52e+07 -0.801328182220459 0.18263912200927734\n",
      "[Step 17653] Loss: 9.55e+07 -0.801439106464386 0.18263086676597595\n",
      "[Step 17654] Loss: 9.57e+07 -0.8017405271530151 0.18256650865077972\n",
      "[Step 17655] Loss: 9.61e+07 -0.8018162250518799 0.18253514170646667\n",
      "[Step 17656] Loss: 9.40e+07 -0.8019153475761414 0.18250462412834167\n",
      "[Step 17657] Loss: 9.49e+07 -0.8021243810653687 0.18247243762016296\n",
      "[Step 17658] Loss: 9.41e+07 -0.8023368716239929 0.1824146807193756\n",
      "[Step 17659] Loss: 9.59e+07 -0.8027798533439636 0.18232639133930206\n",
      "[Step 17660] Loss: 9.57e+07 -0.8031101226806641 0.1822628527879715\n",
      "[Step 17661] Loss: 9.59e+07 -0.803617000579834 0.18217290937900543\n",
      "[Step 17662] Loss: 9.56e+07 -0.8041555881500244 0.1820763796567917\n",
      "[Step 17663] Loss: 9.52e+07 -0.804704487323761 0.18196003139019012\n",
      "[Step 17664] Loss: 9.52e+07 -0.8053277134895325 0.18183626234531403\n",
      "[Step 17665] Loss: 9.50e+07 -0.8058446049690247 0.18172651529312134\n",
      "[Step 17666] Loss: 9.42e+07 -0.8062826991081238 0.18163244426250458\n",
      "[Step 17667] Loss: 9.43e+07 -0.8066456317901611 0.18154498934745789\n",
      "[Step 17668] Loss: 9.52e+07 -0.8069292902946472 0.18145669996738434\n",
      "[Step 17669] Loss: 9.37e+07 -0.807168185710907 0.1813824325799942\n",
      "[Step 17670] Loss: 9.40e+07 -0.807301938533783 0.18133953213691711\n",
      "[Step 17671] Loss: 9.42e+07 -0.8073583841323853 0.1812974363565445\n",
      "[Step 17672] Loss: 9.47e+07 -0.8074866533279419 0.1812487542629242\n",
      "[Step 17673] Loss: 9.47e+07 -0.8076226711273193 0.18121905624866486\n",
      "[Step 17674] Loss: 9.47e+07 -0.8077445030212402 0.1812017261981964\n",
      "[Step 17675] Loss: 9.40e+07 -0.8078081607818604 0.18118439614772797\n",
      "[Step 17676] Loss: 9.43e+07 -0.8079149723052979 0.18116706609725952\n",
      "[Step 17677] Loss: 9.44e+07 -0.8080544471740723 0.1811472624540329\n",
      "[Step 17678] Loss: 9.49e+07 -0.8080987334251404 0.1811472624540329\n",
      "[Step 17679] Loss: 9.43e+07 -0.8081173300743103 0.1811530441045761\n",
      "[Step 17680] Loss: 9.53e+07 -0.8082674741744995 0.1811208575963974\n",
      "[Step 17681] Loss: 9.48e+07 -0.8083301782608032 0.18111343681812286\n",
      "[Step 17682] Loss: 9.58e+07 -0.8082014322280884 0.18111838400363922\n",
      "[Step 17683] Loss: 9.39e+07 -0.8080875873565674 0.18112581968307495\n",
      "[Step 17684] Loss: 9.49e+07 -0.8080140948295593 0.18110930919647217\n",
      "[Step 17685] Loss: 9.46e+07 -0.8080076575279236 0.18110518157482147\n",
      "[Step 17686] Loss: 9.49e+07 -0.8080615997314453 0.18108950555324554\n",
      "[Step 17687] Loss: 9.45e+07 -0.8080781698226929 0.18109197914600372\n",
      "[Step 17688] Loss: 9.48e+07 -0.8082555532455444 0.18106146156787872\n",
      "[Step 17689] Loss: 9.51e+07 -0.8086246848106384 0.18101029098033905\n",
      "[Step 17690] Loss: 9.48e+07 -0.8089591264724731 0.18094345927238464\n",
      "[Step 17691] Loss: 9.42e+07 -0.809166431427002 0.18089395761489868\n",
      "[Step 17692] Loss: 9.47e+07 -0.8092721104621887 0.1808815747499466\n",
      "[Step 17693] Loss: 9.37e+07 -0.8093757033348083 0.1808691918849945\n",
      "[Step 17694] Loss: 9.43e+07 -0.8094796538352966 0.180789977312088\n",
      "[Step 17695] Loss: 9.56e+07 -0.8094342947006226 0.1807759553194046\n",
      "[Step 17696] Loss: 9.44e+07 -0.8093396425247192 0.18077926337718964\n",
      "[Step 17697] Loss: 9.48e+07 -0.8091999292373657 0.1807982325553894\n",
      "[Step 17698] Loss: 9.49e+07 -0.8090140223503113 0.18084527552127838\n",
      "[Step 17699] Loss: 9.50e+07 -0.8088797926902771 0.18084856867790222\n",
      "[Step 17700] Loss: 9.48e+07 -0.8087928295135498 0.18086837232112885\n",
      "[Step 17701] Loss: 9.43e+07 -0.8087745308876038 0.1808857023715973\n",
      "[Step 17702] Loss: 9.56e+07 -0.8089424967765808 0.18085764348506927\n",
      "[Step 17703] Loss: 9.43e+07 -0.8090478777885437 0.18084609508514404\n",
      "[Step 17704] Loss: 9.45e+07 -0.8092676997184753 0.18080978095531464\n",
      "[Step 17705] Loss: 9.51e+07 -0.8095125555992126 0.18077100813388824\n",
      "[Step 17706] Loss: 9.40e+07 -0.8097303509712219 0.1807190179824829\n",
      "[Step 17707] Loss: 9.57e+07 -0.810117781162262 0.1806422919034958\n",
      "[Step 17708] Loss: 9.54e+07 -0.8103855848312378 0.18058699369430542\n",
      "[Step 17709] Loss: 9.42e+07 -0.8105900287628174 0.1805284172296524\n",
      "[Step 17710] Loss: 9.46e+07 -0.8108793497085571 0.18049375712871552\n",
      "[Step 17711] Loss: 9.46e+07 -0.8111463785171509 0.18046405911445618\n",
      "[Step 17712] Loss: 9.47e+07 -0.8113743662834167 0.18043681979179382\n",
      "[Step 17713] Loss: 9.49e+07 -0.8116098046302795 0.18038731813430786\n",
      "[Step 17714] Loss: 9.52e+07 -0.8117348551750183 0.18034441769123077\n",
      "[Step 17715] Loss: 9.42e+07 -0.8118236660957336 0.18034689128398895\n",
      "[Step 17716] Loss: 9.47e+07 -0.8119769096374512 0.18032708764076233\n",
      "[Step 17717] Loss: 9.43e+07 -0.8122121095657349 0.18026849627494812\n",
      "[Step 17718] Loss: 9.50e+07 -0.8123692870140076 0.18024539947509766\n",
      "[Step 17719] Loss: 9.44e+07 -0.8125098347663879 0.18022146821022034\n",
      "[Step 17720] Loss: 9.49e+07 -0.8126400113105774 0.18022476136684418\n",
      "[Step 17721] Loss: 9.47e+07 -0.8129278421401978 0.18019011616706848\n",
      "[Step 17722] Loss: 9.45e+07 -0.8131653666496277 0.18011502921581268\n",
      "[Step 17723] Loss: 9.47e+07 -0.8134351372718811 0.18003250658512115\n",
      "[Step 17724] Loss: 9.39e+07 -0.8137441873550415 0.1799664944410324\n",
      "[Step 17725] Loss: 9.69e+07 -0.8144357800483704 0.17981302738189697\n",
      "[Step 17726] Loss: 9.44e+07 -0.815016508102417 0.17971235513687134\n",
      "[Step 17727] Loss: 9.36e+07 -0.8154694437980652 0.17963479459285736\n",
      "[Step 17728] Loss: 9.51e+07 -0.8158528208732605 0.17955970764160156\n",
      "[Step 17729] Loss: 9.49e+07 -0.8161569237709045 0.17950937151908875\n",
      "[Step 17730] Loss: 9.47e+07 -0.8164132237434387 0.17947223782539368\n",
      "[Step 17731] Loss: 9.46e+07 -0.8166210055351257 0.17941448092460632\n",
      "[Step 17732] Loss: 9.49e+07 -0.8167365789413452 0.17939549684524536\n",
      "[Step 17733] Loss: 9.51e+07 -0.8167776465415955 0.17937158048152924\n",
      "[Step 17734] Loss: 9.46e+07 -0.8168109655380249 0.17934764921665192\n",
      "[Step 17735] Loss: 9.54e+07 -0.817068874835968 0.17930720746517181\n",
      "[Step 17736] Loss: 9.44e+07 -0.8173058032989502 0.17925770580768585\n",
      "[Step 17737] Loss: 9.46e+07 -0.8175039291381836 0.17921562492847443\n",
      "[Step 17738] Loss: 9.49e+07 -0.8178039789199829 0.17917436361312866\n",
      "[Step 17739] Loss: 9.43e+07 -0.8180530667304993 0.17911826074123383\n",
      "[Step 17740] Loss: 9.53e+07 -0.8181554079055786 0.17909680306911469\n",
      "[Step 17741] Loss: 9.47e+07 -0.8182778358459473 0.179067924618721\n",
      "[Step 17742] Loss: 9.47e+07 -0.8185180425643921 0.17903657257556915\n",
      "[Step 17743] Loss: 9.47e+07 -0.8188747763633728 0.17897385358810425\n",
      "[Step 17744] Loss: 9.41e+07 -0.8191431760787964 0.17893095314502716\n",
      "[Step 17745] Loss: 9.50e+07 -0.8193051815032959 0.17890620231628418\n",
      "[Step 17746] Loss: 9.48e+07 -0.8194142580032349 0.17885255813598633\n",
      "[Step 17747] Loss: 9.44e+07 -0.8194945454597473 0.17880800366401672\n",
      "[Step 17748] Loss: 9.42e+07 -0.8194835186004639 0.17880140244960785\n",
      "[Step 17749] Loss: 9.44e+07 -0.8194605112075806 0.1788245141506195\n",
      "[Step 17750] Loss: 9.48e+07 -0.8194383382797241 0.17879974842071533\n",
      "[Step 17751] Loss: 9.45e+07 -0.8194748163223267 0.17877830564975739\n",
      "[Step 17752] Loss: 9.44e+07 -0.8195378184318542 0.1787436455488205\n",
      "[Step 17753] Loss: 9.46e+07 -0.819643497467041 0.17871642112731934\n",
      "[Step 17754] Loss: 9.40e+07 -0.8196620941162109 0.17871971428394318\n",
      "[Step 17755] Loss: 9.52e+07 -0.8197414875030518 0.17867185175418854\n",
      "[Step 17756] Loss: 9.49e+07 -0.8197474479675293 0.17868918180465698\n",
      "[Step 17757] Loss: 9.39e+07 -0.8197495341300964 0.17867021262645721\n",
      "[Step 17758] Loss: 9.40e+07 -0.8198111057281494 0.17862069606781006\n",
      "[Step 17759] Loss: 9.46e+07 -0.8197774887084961 0.17862729728221893\n",
      "[Step 17760] Loss: 9.48e+07 -0.8197985887527466 0.17860832810401917\n",
      "[Step 17761] Loss: 9.48e+07 -0.8198074698448181 0.17860667407512665\n",
      "[Step 17762] Loss: 9.44e+07 -0.8197184801101685 0.1786281317472458\n",
      "[Step 17763] Loss: 9.35e+07 -0.8196238875389099 0.17864297330379486\n",
      "[Step 17764] Loss: 9.42e+07 -0.8195264935493469 0.17863473296165466\n",
      "[Step 17765] Loss: 9.41e+07 -0.8195023536682129 0.17865204811096191\n",
      "[Step 17766] Loss: 9.46e+07 -0.8195716738700867 0.17866525053977966\n",
      "[Step 17767] Loss: 9.49e+07 -0.8196835517883301 0.178636372089386\n",
      "[Step 17768] Loss: 9.51e+07 -0.8198727965354919 0.1786099672317505\n",
      "[Step 17769] Loss: 9.45e+07 -0.8200463652610779 0.1785612851381302\n",
      "[Step 17770] Loss: 9.50e+07 -0.820349931716919 0.17851755023002625\n",
      "[Step 17771] Loss: 9.48e+07 -0.820583164691925 0.17846062779426575\n",
      "[Step 17772] Loss: 9.49e+07 -0.8207098841667175 0.1784292608499527\n",
      "[Step 17773] Loss: 9.48e+07 -0.8207523822784424 0.17839790880680084\n",
      "[Step 17774] Loss: 9.42e+07 -0.8208481073379517 0.17837975919246674\n",
      "[Step 17775] Loss: 9.47e+07 -0.8208589553833008 0.1783640831708908\n",
      "[Step 17776] Loss: 9.52e+07 -0.8207511305809021 0.1783682107925415\n",
      "[Step 17777] Loss: 9.51e+07 -0.8207535147666931 0.17833520472049713\n",
      "[Step 17778] Loss: 9.47e+07 -0.8207510113716125 0.17835500836372375\n",
      "[Step 17779] Loss: 9.42e+07 -0.8207497000694275 0.1783541738986969\n",
      "[Step 17780] Loss: 9.45e+07 -0.8207932114601135 0.17835666239261627\n",
      "[Step 17781] Loss: 9.48e+07 -0.8208129405975342 0.17837563157081604\n",
      "[Step 17782] Loss: 9.52e+07 -0.820692777633667 0.1784028559923172\n",
      "[Step 17783] Loss: 9.46e+07 -0.8205687999725342 0.17844164371490479\n",
      "[Step 17784] Loss: 9.46e+07 -0.8205483555793762 0.17845484614372253\n",
      "[Step 17785] Loss: 9.50e+07 -0.8205732107162476 0.17842184007167816\n",
      "[Step 17786] Loss: 9.48e+07 -0.8205834031105042 0.17841605842113495\n",
      "[Step 17787] Loss: 9.48e+07 -0.820589005947113 0.17839708924293518\n",
      "[Step 17788] Loss: 9.61e+07 -0.8208370208740234 0.1783360242843628\n",
      "[Step 17789] Loss: 9.51e+07 -0.8211650848388672 0.17827248573303223\n",
      "[Step 17790] Loss: 9.49e+07 -0.8215464353561401 0.17819327116012573\n",
      "[Step 17791] Loss: 9.66e+07 -0.8221530914306641 0.17807775735855103\n",
      "[Step 17792] Loss: 9.52e+07 -0.8227289319038391 0.17796719074249268\n",
      "[Step 17793] Loss: 9.60e+07 -0.823577344417572 0.177804633975029\n",
      "[Step 17794] Loss: 9.47e+07 -0.824377715587616 0.17766684293746948\n",
      "[Step 17795] Loss: 9.44e+07 -0.825095534324646 0.1775224357843399\n",
      "[Step 17796] Loss: 9.41e+07 -0.8256461024284363 0.17738133668899536\n",
      "[Step 17797] Loss: 9.46e+07 -0.8261094689369202 0.17730708420276642\n",
      "[Step 17798] Loss: 9.45e+07 -0.8264716267585754 0.17723365128040314\n",
      "[Step 17799] Loss: 9.48e+07 -0.8268304467201233 0.1771635115146637\n",
      "[Step 17800] Loss: 9.58e+07 -0.8270034193992615 0.17712143063545227\n",
      "[Step 17801] Loss: 9.52e+07 -0.8271089792251587 0.17711399495601654\n",
      "[Step 17802] Loss: 9.49e+07 -0.8272837400436401 0.1770842969417572\n",
      "[Step 17803] Loss: 9.46e+07 -0.8275230526924133 0.1770479828119278\n",
      "[Step 17804] Loss: 9.48e+07 -0.8276426196098328 0.1769951730966568\n",
      "[Step 17805] Loss: 9.53e+07 -0.8278836607933044 0.17694732546806335\n",
      "[Step 17806] Loss: 9.46e+07 -0.8281565308570862 0.17685820162296295\n",
      "[Step 17807] Loss: 9.41e+07 -0.8283123970031738 0.17681117355823517\n",
      "[Step 17808] Loss: 9.42e+07 -0.8284527659416199 0.17675423622131348\n",
      "[Step 17809] Loss: 9.46e+07 -0.8285539746284485 0.17673856019973755\n",
      "[Step 17810] Loss: 9.44e+07 -0.8285797834396362 0.17672701179981232\n",
      "[Step 17811] Loss: 9.50e+07 -0.8286259770393372 0.1767072081565857\n",
      "[Step 17812] Loss: 9.41e+07 -0.8285771608352661 0.17671215534210205\n",
      "[Step 17813] Loss: 9.37e+07 -0.8285362124443054 0.1766906976699829\n",
      "[Step 17814] Loss: 9.44e+07 -0.8284651041030884 0.17668575048446655\n",
      "[Step 17815] Loss: 9.42e+07 -0.828420877456665 0.17672206461429596\n",
      "[Step 17816] Loss: 9.46e+07 -0.8283352255821228 0.17674598097801208\n",
      "[Step 17817] Loss: 9.39e+07 -0.8282678723335266 0.17672866582870483\n",
      "[Step 17818] Loss: 9.43e+07 -0.8281634449958801 0.17672619223594666\n",
      "[Step 17819] Loss: 9.53e+07 -0.8280080556869507 0.17674434185028076\n",
      "[Step 17820] Loss: 9.42e+07 -0.8279805779457092 0.17675094306468964\n",
      "[Step 17821] Loss: 9.44e+07 -0.828050434589386 0.17671793699264526\n",
      "[Step 17822] Loss: 9.48e+07 -0.828105092048645 0.17669813334941864\n",
      "[Step 17823] Loss: 9.48e+07 -0.8281829357147217 0.17668740451335907\n",
      "[Step 17824] Loss: 9.49e+07 -0.8282074332237244 0.17668409645557404\n",
      "[Step 17825] Loss: 9.53e+07 -0.8282521367073059 0.17667007446289062\n",
      "[Step 17826] Loss: 9.54e+07 -0.8283200263977051 0.17665357887744904\n",
      "[Step 17827] Loss: 9.52e+07 -0.8285828232765198 0.17661809921264648\n",
      "[Step 17828] Loss: 9.42e+07 -0.8288257122039795 0.17656032741069794\n",
      "[Step 17829] Loss: 9.41e+07 -0.8290517926216125 0.17651908099651337\n",
      "[Step 17830] Loss: 9.46e+07 -0.8293091058731079 0.17646048963069916\n",
      "[Step 17831] Loss: 9.48e+07 -0.8294744491577148 0.1764208823442459\n",
      "[Step 17832] Loss: 9.45e+07 -0.8296909928321838 0.17637714743614197\n",
      "[Step 17833] Loss: 9.47e+07 -0.829852819442749 0.17635570466518402\n",
      "[Step 17834] Loss: 9.43e+07 -0.8300513625144958 0.17632021009922028\n",
      "[Step 17835] Loss: 9.47e+07 -0.8301853537559509 0.1763037145137787\n",
      "[Step 17836] Loss: 9.45e+07 -0.8302385807037354 0.17631609737873077\n",
      "[Step 17837] Loss: 9.46e+07 -0.8302347660064697 0.17633754014968872\n",
      "[Step 17838] Loss: 9.52e+07 -0.8301987051963806 0.1763457953929901\n",
      "[Step 17839] Loss: 9.56e+07 -0.830382764339447 0.1763441413640976\n",
      "[Step 17840] Loss: 9.42e+07 -0.8306140303611755 0.1763053685426712\n",
      "[Step 17841] Loss: 9.45e+07 -0.8308073878288269 0.17626245319843292\n",
      "[Step 17842] Loss: 9.52e+07 -0.8309637904167175 0.1762385219335556\n",
      "[Step 17843] Loss: 9.56e+07 -0.8312878608703613 0.1761799454689026\n",
      "[Step 17844] Loss: 9.46e+07 -0.8314737677574158 0.1761312633752823\n",
      "[Step 17845] Loss: 9.43e+07 -0.8316512703895569 0.1760801076889038\n",
      "[Step 17846] Loss: 9.43e+07 -0.8318448662757874 0.17604131996631622\n",
      "[Step 17847] Loss: 9.51e+07 -0.8321298956871033 0.17599594593048096\n",
      "[Step 17848] Loss: 9.45e+07 -0.8323323726654053 0.17594973742961884\n",
      "[Step 17849] Loss: 9.47e+07 -0.8325982689857483 0.17587628960609436\n",
      "[Step 17850] Loss: 9.47e+07 -0.8327767848968506 0.17584741115570068\n",
      "[Step 17851] Loss: 9.48e+07 -0.8329190015792847 0.1758267879486084\n",
      "[Step 17852] Loss: 9.51e+07 -0.8331441879272461 0.17579130828380585\n",
      "[Step 17853] Loss: 9.44e+07 -0.8333300352096558 0.1757417917251587\n",
      "[Step 17854] Loss: 9.46e+07 -0.8336252570152283 0.17568156123161316\n",
      "[Step 17855] Loss: 9.47e+07 -0.8339195847511292 0.17562296986579895\n",
      "[Step 17856] Loss: 9.48e+07 -0.8343222737312317 0.1755223125219345\n",
      "[Step 17857] Loss: 9.45e+07 -0.834721028804779 0.17545382678508759\n",
      "[Step 17858] Loss: 9.45e+07 -0.8350491523742676 0.17538286745548248\n",
      "[Step 17859] Loss: 9.49e+07 -0.835252583026886 0.17531932890415192\n",
      "[Step 17860] Loss: 9.44e+07 -0.8354304432868958 0.1752830147743225\n",
      "[Step 17861] Loss: 9.44e+07 -0.8357280492782593 0.1752368062734604\n",
      "[Step 17862] Loss: 9.43e+07 -0.8358893990516663 0.17517244815826416\n",
      "[Step 17863] Loss: 9.48e+07 -0.8359816074371338 0.1751353144645691\n",
      "[Step 17864] Loss: 9.40e+07 -0.8359955549240112 0.17511963844299316\n",
      "[Step 17865] Loss: 9.45e+07 -0.8360053300857544 0.17510974407196045\n",
      "[Step 17866] Loss: 9.46e+07 -0.8360703587532043 0.17511221766471863\n",
      "[Step 17867] Loss: 9.48e+07 -0.8360429406166077 0.17510561645030975\n",
      "[Step 17868] Loss: 9.47e+07 -0.8360509276390076 0.17510148882865906\n",
      "[Step 17869] Loss: 9.50e+07 -0.8360265493392944 0.17511634528636932\n",
      "[Step 17870] Loss: 9.48e+07 -0.836121678352356 0.17508333921432495\n",
      "[Step 17871] Loss: 9.44e+07 -0.8360785841941833 0.17508333921432495\n",
      "[Step 17872] Loss: 9.51e+07 -0.836143970489502 0.1750742644071579\n",
      "[Step 17873] Loss: 9.42e+07 -0.8361954092979431 0.17505446076393127\n",
      "[Step 17874] Loss: 9.45e+07 -0.8362402319908142 0.175039604306221\n",
      "[Step 17875] Loss: 9.49e+07 -0.8363673686981201 0.17500825226306915\n",
      "[Step 17876] Loss: 9.53e+07 -0.8366079926490784 0.17493316531181335\n",
      "[Step 17877] Loss: 9.52e+07 -0.8366889953613281 0.17490676045417786\n",
      "[Step 17878] Loss: 9.54e+07 -0.8368834257125854 0.17485807836055756\n",
      "[Step 17879] Loss: 9.53e+07 -0.8370227813720703 0.17482423782348633\n",
      "[Step 17880] Loss: 9.45e+07 -0.8372824788093567 0.17478133738040924\n",
      "[Step 17881] Loss: 9.52e+07 -0.8374419808387756 0.17476071417331696\n",
      "[Step 17882] Loss: 9.53e+07 -0.8374969959259033 0.1747681349515915\n",
      "[Step 17883] Loss: 9.52e+07 -0.8376350402832031 0.1747334748506546\n",
      "[Step 17884] Loss: 9.59e+07 -0.837973952293396 0.17467902600765228\n",
      "[Step 17885] Loss: 9.41e+07 -0.8382250070571899 0.1746765375137329\n",
      "[Step 17886] Loss: 9.44e+07 -0.8386229276657104 0.17459484934806824\n",
      "[Step 17887] Loss: 9.41e+07 -0.8389848470687866 0.17454040050506592\n",
      "[Step 17888] Loss: 9.40e+07 -0.8392641544342041 0.1745040863752365\n",
      "[Step 17889] Loss: 9.52e+07 -0.8396056294441223 0.1744677871465683\n",
      "[Step 17890] Loss: 9.43e+07 -0.8400249481201172 0.17439104616641998\n",
      "[Step 17891] Loss: 9.43e+07 -0.8403724431991577 0.1742829531431198\n",
      "[Step 17892] Loss: 9.46e+07 -0.8407320380210876 0.17419631779193878\n",
      "[Step 17893] Loss: 9.51e+07 -0.8409401178359985 0.17412865161895752\n",
      "[Step 17894] Loss: 9.40e+07 -0.8411425352096558 0.17407996952533722\n",
      "[Step 17895] Loss: 9.47e+07 -0.8413199782371521 0.17404696345329285\n",
      "[Step 17896] Loss: 9.48e+07 -0.8413949608802795 0.17401479184627533\n",
      "[Step 17897] Loss: 9.45e+07 -0.841454029083252 0.1739991009235382\n",
      "[Step 17898] Loss: 9.40e+07 -0.8414149284362793 0.17401643097400665\n",
      "[Step 17899] Loss: 9.52e+07 -0.8414757251739502 0.17399002611637115\n",
      "[Step 17900] Loss: 9.45e+07 -0.8414727449417114 0.17401479184627533\n",
      "[Step 17901] Loss: 9.49e+07 -0.841521680355072 0.17399002611637115\n",
      "[Step 17902] Loss: 9.55e+07 -0.8417786359786987 0.17393805086612701\n",
      "[Step 17903] Loss: 9.45e+07 -0.8420278429985046 0.1738712042570114\n",
      "[Step 17904] Loss: 9.40e+07 -0.842305600643158 0.17380931973457336\n",
      "[Step 17905] Loss: 9.51e+07 -0.8424739837646484 0.17376889288425446\n",
      "[Step 17906] Loss: 9.46e+07 -0.8425730466842651 0.17373506724834442\n",
      "[Step 17907] Loss: 9.48e+07 -0.842792809009552 0.17364512383937836\n",
      "[Step 17908] Loss: 9.50e+07 -0.8428901433944702 0.1736220270395279\n",
      "[Step 17909] Loss: 9.42e+07 -0.8431057929992676 0.17358489334583282\n",
      "[Step 17910] Loss: 9.42e+07 -0.8432971239089966 0.17353455722332\n",
      "[Step 17911] Loss: 9.52e+07 -0.8436654806137085 0.17347101867198944\n",
      "[Step 17912] Loss: 9.48e+07 -0.8439396619796753 0.17342399060726166\n",
      "[Step 17913] Loss: 9.47e+07 -0.8442044854164124 0.17336292564868927\n",
      "[Step 17914] Loss: 9.53e+07 -0.8444451093673706 0.17332331836223602\n",
      "[Step 17915] Loss: 9.40e+07 -0.8445931673049927 0.17324575781822205\n",
      "[Step 17916] Loss: 9.44e+07 -0.8447522521018982 0.17320780456066132\n",
      "[Step 17917] Loss: 9.43e+07 -0.8448864221572876 0.1731673628091812\n",
      "[Step 17918] Loss: 9.54e+07 -0.844803512096405 0.17316241562366486\n",
      "[Step 17919] Loss: 9.44e+07 -0.8446898460388184 0.17317479848861694\n",
      "[Step 17920] Loss: 9.47e+07 -0.8446009755134583 0.17320120334625244\n",
      "[Step 17921] Loss: 9.42e+07 -0.8445659279823303 0.17320285737514496\n",
      "[Step 17922] Loss: 9.46e+07 -0.8445252180099487 0.1731756180524826\n",
      "[Step 17923] Loss: 9.57e+07 -0.84470134973526 0.17313353717327118\n",
      "[Step 17924] Loss: 9.57e+07 -0.8446924686431885 0.17313601076602936\n",
      "[Step 17925] Loss: 9.59e+07 -0.8448969125747681 0.17310713231563568\n",
      "[Step 17926] Loss: 9.49e+07 -0.8451895713806152 0.1730741262435913\n",
      "[Step 17927] Loss: 9.49e+07 -0.8452557325363159 0.17303946614265442\n",
      "[Step 17928] Loss: 9.68e+07 -0.8455977439880371 0.17297594249248505\n",
      "[Step 17929] Loss: 9.47e+07 -0.8458738923072815 0.172914057970047\n",
      "[Step 17930] Loss: 9.42e+07 -0.8459942936897278 0.17288021743297577\n",
      "[Step 17931] Loss: 9.46e+07 -0.846227765083313 0.17287032306194305\n",
      "[Step 17932] Loss: 9.55e+07 -0.8463410139083862 0.1728430837392807\n",
      "[Step 17933] Loss: 9.45e+07 -0.8463485836982727 0.17282246053218842\n",
      "[Step 17934] Loss: 9.39e+07 -0.8463749885559082 0.17283236980438232\n",
      "[Step 17935] Loss: 9.56e+07 -0.8466082811355591 0.17279687523841858\n",
      "[Step 17936] Loss: 9.49e+07 -0.8469187617301941 0.17273251712322235\n",
      "[Step 17937] Loss: 9.78e+07 -0.8475784063339233 0.172593891620636\n",
      "[Step 17938] Loss: 9.43e+07 -0.8480648398399353 0.17250891029834747\n",
      "[Step 17939] Loss: 9.42e+07 -0.8484103083610535 0.17244455218315125\n",
      "[Step 17940] Loss: 9.48e+07 -0.8487353920936584 0.1723966896533966\n",
      "[Step 17941] Loss: 9.50e+07 -0.8489621877670288 0.17236781120300293\n",
      "[Step 17942] Loss: 9.38e+07 -0.8492180109024048 0.17229685187339783\n",
      "[Step 17943] Loss: 9.43e+07 -0.8495032787322998 0.17223002016544342\n",
      "[Step 17944] Loss: 9.55e+07 -0.8499165773391724 0.17217224836349487\n",
      "[Step 17945] Loss: 9.48e+07 -0.8502223491668701 0.17210707068443298\n",
      "[Step 17946] Loss: 9.44e+07 -0.850403904914856 0.17207488417625427\n",
      "[Step 17947] Loss: 9.51e+07 -0.8506287932395935 0.1719989776611328\n",
      "[Step 17948] Loss: 9.43e+07 -0.8507460951805115 0.17195937037467957\n",
      "[Step 17949] Loss: 9.50e+07 -0.8507696986198425 0.1719263643026352\n",
      "[Step 17950] Loss: 9.41e+07 -0.8507989048957825 0.1718999594449997\n",
      "[Step 17951] Loss: 9.42e+07 -0.8507878184318542 0.1718776822090149\n",
      "[Step 17952] Loss: 9.53e+07 -0.8508011102676392 0.17186035215854645\n",
      "[Step 17953] Loss: 9.52e+07 -0.8509263396263123 0.1718388944864273\n",
      "[Step 17954] Loss: 9.47e+07 -0.8510611653327942 0.17180754244327545\n",
      "[Step 17955] Loss: 9.44e+07 -0.8512561917304993 0.17174896597862244\n",
      "[Step 17956] Loss: 9.50e+07 -0.8514381647109985 0.1717093586921692\n",
      "[Step 17957] Loss: 9.49e+07 -0.8517046570777893 0.1716524213552475\n",
      "[Step 17958] Loss: 9.42e+07 -0.8518809676170349 0.1716342717409134\n",
      "[Step 17959] Loss: 9.50e+07 -0.8519958257675171 0.17160950601100922\n",
      "[Step 17960] Loss: 9.47e+07 -0.8520443439483643 0.17161116003990173\n",
      "[Step 17961] Loss: 9.56e+07 -0.8522830605506897 0.17158806324005127\n",
      "[Step 17962] Loss: 9.51e+07 -0.85250324010849 0.17154598236083984\n",
      "[Step 17963] Loss: 9.63e+07 -0.852984607219696 0.171467587351799\n",
      "[Step 17964] Loss: 9.50e+07 -0.8534882664680481 0.17135949432849884\n",
      "[Step 17965] Loss: 9.41e+07 -0.8540064096450806 0.17126873135566711\n",
      "[Step 17966] Loss: 9.42e+07 -0.8544758558273315 0.17118126153945923\n",
      "[Step 17967] Loss: 9.51e+07 -0.8549107909202576 0.1711045205593109\n",
      "[Step 17968] Loss: 9.48e+07 -0.855285108089447 0.17103686928749084\n",
      "[Step 17969] Loss: 9.54e+07 -0.8558294177055359 0.17092959582805634\n",
      "[Step 17970] Loss: 9.47e+07 -0.8563651442527771 0.17084212601184845\n",
      "[Step 17971] Loss: 9.53e+07 -0.8567831516265869 0.17074228823184967\n",
      "[Step 17972] Loss: 9.43e+07 -0.8570544719696045 0.17069444060325623\n",
      "[Step 17973] Loss: 9.53e+07 -0.8575383424758911 0.17061026394367218\n",
      "[Step 17974] Loss: 9.41e+07 -0.8579712510108948 0.1705145537853241\n",
      "[Step 17975] Loss: 9.48e+07 -0.8583500981330872 0.1704576164484024\n",
      "[Step 17976] Loss: 9.50e+07 -0.8585994839668274 0.1704072803258896\n",
      "[Step 17977] Loss: 9.49e+07 -0.8587798476219177 0.17036767303943634\n",
      "[Step 17978] Loss: 9.46e+07 -0.8589022755622864 0.17034126818180084\n",
      "[Step 17979] Loss: 9.48e+07 -0.858991265296936 0.17029836773872375\n",
      "[Step 17980] Loss: 9.45e+07 -0.8590874075889587 0.1702628880739212\n",
      "[Step 17981] Loss: 9.47e+07 -0.859288215637207 0.17022822797298431\n",
      "[Step 17982] Loss: 9.50e+07 -0.8594639897346497 0.17017294466495514\n",
      "[Step 17983] Loss: 9.45e+07 -0.8595802187919617 0.1701391190290451\n",
      "[Step 17984] Loss: 9.55e+07 -0.8597380518913269 0.17010940611362457\n",
      "[Step 17985] Loss: 9.48e+07 -0.8599221706390381 0.17010527849197388\n",
      "[Step 17986] Loss: 9.45e+07 -0.86016446352005 0.1700458824634552\n",
      "[Step 17987] Loss: 9.47e+07 -0.8604679107666016 0.16999389231204987\n",
      "[Step 17988] Loss: 9.44e+07 -0.8607334494590759 0.16997161507606506\n",
      "[Step 17989] Loss: 9.43e+07 -0.8610363602638245 0.16991467773914337\n",
      "[Step 17990] Loss: 9.45e+07 -0.8612505793571472 0.16989818215370178\n",
      "[Step 17991] Loss: 9.48e+07 -0.86156165599823 0.1698470115661621\n",
      "[Step 17992] Loss: 9.52e+07 -0.8618099689483643 0.1698107123374939\n",
      "[Step 17993] Loss: 9.58e+07 -0.8620566129684448 0.16977357864379883\n",
      "[Step 17994] Loss: 9.39e+07 -0.8623121976852417 0.16972820460796356\n",
      "[Step 17995] Loss: 9.52e+07 -0.8626458644866943 0.1696828156709671\n",
      "[Step 17996] Loss: 9.45e+07 -0.8629100322723389 0.1696481555700302\n",
      "[Step 17997] Loss: 9.42e+07 -0.86314857006073 0.16958874464035034\n",
      "[Step 17998] Loss: 9.47e+07 -0.8634748458862305 0.16954006254673004\n",
      "[Step 17999] Loss: 9.39e+07 -0.8637514114379883 0.16948725283145905\n",
      "[Step 18000] Loss: 9.48e+07 -0.8639959096908569 0.16944435238838196\n",
      "[Step 18001] Loss: 9.43e+07 -0.8642749190330505 0.16938576102256775\n",
      "[Step 18002] Loss: 9.48e+07 -0.8645488023757935 0.16933955252170563\n",
      "[Step 18003] Loss: 9.49e+07 -0.8649014234542847 0.169289231300354\n",
      "[Step 18004] Loss: 9.49e+07 -0.8650721907615662 0.16924136877059937\n",
      "[Step 18005] Loss: 9.48e+07 -0.8651857376098633 0.1692265123128891\n",
      "[Step 18006] Loss: 9.47e+07 -0.8653174042701721 0.16920176148414612\n",
      "[Step 18007] Loss: 9.45e+07 -0.8654671907424927 0.16916215419769287\n",
      "[Step 18008] Loss: 9.44e+07 -0.8656237721443176 0.16913162171840668\n",
      "[Step 18009] Loss: 9.47e+07 -0.8657175302505493 0.16911925375461578\n",
      "[Step 18010] Loss: 9.56e+07 -0.8656790256500244 0.16913409531116486\n",
      "[Step 18011] Loss: 9.45e+07 -0.8656339645385742 0.1691332757472992\n",
      "[Step 18012] Loss: 9.50e+07 -0.8655142188072205 0.1691349297761917\n",
      "[Step 18013] Loss: 9.46e+07 -0.8653272986412048 0.16917948424816132\n",
      "[Step 18014] Loss: 9.56e+07 -0.8654084205627441 0.16914235055446625\n",
      "[Step 18015] Loss: 9.44e+07 -0.8653508424758911 0.16915225982666016\n",
      "[Step 18016] Loss: 9.39e+07 -0.8653298020362854 0.1691390573978424\n",
      "[Step 18017] Loss: 9.48e+07 -0.8652133345603943 0.1691291481256485\n",
      "[Step 18018] Loss: 9.44e+07 -0.8650537133216858 0.1691514253616333\n",
      "[Step 18019] Loss: 9.45e+07 -0.864888608455658 0.16916050016880035\n",
      "[Step 18020] Loss: 9.46e+07 -0.8647174835205078 0.16919763386249542\n",
      "[Step 18021] Loss: 9.46e+07 -0.8646478056907654 0.16919763386249542\n",
      "[Step 18022] Loss: 9.46e+07 -0.8645594120025635 0.1692124903202057\n",
      "[Step 18023] Loss: 9.55e+07 -0.8643481731414795 0.1692446619272232\n",
      "[Step 18024] Loss: 9.41e+07 -0.8641076683998108 0.16929830610752106\n",
      "[Step 18025] Loss: 9.38e+07 -0.8638617992401123 0.16935275495052338\n",
      "[Step 18026] Loss: 9.36e+07 -0.8636502027511597 0.16937421262264252\n",
      "[Step 18027] Loss: 9.51e+07 -0.8634243607521057 0.16940392553806305\n",
      "[Step 18028] Loss: 9.45e+07 -0.8632017970085144 0.1694336235523224\n",
      "[Step 18029] Loss: 9.45e+07 -0.8630567789077759 0.1694517731666565\n",
      "[Step 18030] Loss: 9.41e+07 -0.862837553024292 0.16947901248931885\n",
      "[Step 18031] Loss: 9.61e+07 -0.8629464507102966 0.1694757044315338\n",
      "[Step 18032] Loss: 9.50e+07 -0.8632182478904724 0.16941794753074646\n",
      "[Step 18033] Loss: 9.48e+07 -0.8636004328727722 0.16934946179389954\n",
      "[Step 18034] Loss: 9.51e+07 -0.8638129830360413 0.16929994523525238\n",
      "[Step 18035] Loss: 9.41e+07 -0.8640586733818054 0.1692628264427185\n",
      "[Step 18036] Loss: 9.51e+07 -0.8643513321876526 0.16923558712005615\n",
      "[Step 18037] Loss: 9.51e+07 -0.8647536039352417 0.16916050016880035\n",
      "[Step 18038] Loss: 9.50e+07 -0.8652427196502686 0.1690862476825714\n",
      "[Step 18039] Loss: 9.46e+07 -0.8656045794487 0.169021874666214\n",
      "[Step 18040] Loss: 9.50e+07 -0.8661136031150818 0.16890141367912292\n",
      "[Step 18041] Loss: 9.46e+07 -0.866607129573822 0.16881312429904938\n",
      "[Step 18042] Loss: 9.44e+07 -0.8670101761817932 0.1687660813331604\n",
      "[Step 18043] Loss: 9.49e+07 -0.8673765659332275 0.16867779195308685\n",
      "[Step 18044] Loss: 9.45e+07 -0.8676475882530212 0.16861096024513245\n",
      "[Step 18045] Loss: 9.50e+07 -0.8679700493812561 0.16854247450828552\n",
      "[Step 18046] Loss: 9.44e+07 -0.8682118058204651 0.16848719120025635\n",
      "[Step 18047] Loss: 9.59e+07 -0.8682671785354614 0.16847729682922363\n",
      "[Step 18048] Loss: 9.51e+07 -0.8683441281318665 0.16844181716442108\n",
      "[Step 18049] Loss: 9.45e+07 -0.868488609790802 0.16841788589954376\n",
      "[Step 18050] Loss: 9.45e+07 -0.8685430884361267 0.1683807522058487\n",
      "[Step 18051] Loss: 9.51e+07 -0.8684966564178467 0.16836507618427277\n",
      "[Step 18052] Loss: 9.42e+07 -0.86845862865448 0.1683378368616104\n",
      "[Step 18053] Loss: 9.47e+07 -0.868288516998291 0.16835929453372955\n",
      "[Step 18054] Loss: 9.50e+07 -0.8681855201721191 0.16835187375545502\n",
      "[Step 18055] Loss: 9.57e+07 -0.8681938648223877 0.1683642417192459\n",
      "[Step 18056] Loss: 9.44e+07 -0.8681234121322632 0.16834032535552979\n",
      "[Step 18057] Loss: 9.50e+07 -0.8681618571281433 0.16831061244010925\n",
      "[Step 18058] Loss: 9.47e+07 -0.8681755065917969 0.1682974100112915\n",
      "[Step 18059] Loss: 9.43e+07 -0.868301510810852 0.16826771199703217\n",
      "[Step 18060] Loss: 9.52e+07 -0.8684809803962708 0.1682347059249878\n",
      "[Step 18061] Loss: 9.50e+07 -0.868781328201294 0.16815301775932312\n",
      "[Step 18062] Loss: 9.51e+07 -0.8692430257797241 0.16807875037193298\n",
      "[Step 18063] Loss: 9.47e+07 -0.8697263598442078 0.16799624264240265\n",
      "[Step 18064] Loss: 9.49e+07 -0.8700295686721802 0.16791290044784546\n",
      "[Step 18065] Loss: 9.50e+07 -0.8702847361564636 0.16786503791809082\n",
      "[Step 18066] Loss: 9.53e+07 -0.8705077171325684 0.16780397295951843\n",
      "[Step 18067] Loss: 9.48e+07 -0.8706018328666687 0.16776025295257568\n",
      "[Step 18068] Loss: 9.41e+07 -0.8707460761070251 0.16771486401557922\n",
      "[Step 18069] Loss: 9.46e+07 -0.8708765506744385 0.1676950603723526\n",
      "[Step 18070] Loss: 9.53e+07 -0.8711222410202026 0.1676645278930664\n",
      "[Step 18071] Loss: 9.48e+07 -0.8713390827178955 0.16762575507164001\n",
      "[Step 18072] Loss: 9.56e+07 -0.8717042803764343 0.16756221652030945\n",
      "[Step 18073] Loss: 9.51e+07 -0.8720656037330627 0.1675003319978714\n",
      "[Step 18074] Loss: 9.51e+07 -0.8722631931304932 0.1674557775259018\n",
      "[Step 18075] Loss: 9.49e+07 -0.8725283145904541 0.16738232970237732\n",
      "[Step 18076] Loss: 9.43e+07 -0.8727250099182129 0.16733117401599884\n",
      "[Step 18077] Loss: 9.53e+07 -0.8729474544525146 0.16729982197284698\n",
      "[Step 18078] Loss: 9.48e+07 -0.8731081485748291 0.16728827357292175\n",
      "[Step 18079] Loss: 9.48e+07 -0.8731512427330017 0.16729240119457245\n",
      "[Step 18080] Loss: 9.39e+07 -0.8732226490974426 0.1672791987657547\n",
      "[Step 18081] Loss: 9.46e+07 -0.8731582760810852 0.16725608706474304\n",
      "[Step 18082] Loss: 9.45e+07 -0.8731055855751038 0.1672527939081192\n",
      "[Step 18083] Loss: 9.42e+07 -0.8730382323265076 0.16725526750087738\n",
      "[Step 18084] Loss: 9.44e+07 -0.8729916214942932 0.16727589070796967\n",
      "[Step 18085] Loss: 9.42e+07 -0.8729503750801086 0.16724948585033417\n",
      "[Step 18086] Loss: 9.44e+07 -0.8728655576705933 0.16723133623600006\n",
      "[Step 18087] Loss: 9.46e+07 -0.8727158904075623 0.16723959147930145\n",
      "[Step 18088] Loss: 9.43e+07 -0.8726160526275635 0.1672692894935608\n",
      "[Step 18089] Loss: 9.40e+07 -0.8725365400314331 0.16728083789348602\n",
      "[Step 18090] Loss: 9.52e+07 -0.8724560737609863 0.16728083789348602\n",
      "[Step 18091] Loss: 9.51e+07 -0.8725578784942627 0.1672486662864685\n",
      "[Step 18092] Loss: 9.44e+07 -0.872711181640625 0.16722308099269867\n",
      "[Step 18093] Loss: 9.41e+07 -0.872825562953949 0.16717274487018585\n",
      "[Step 18094] Loss: 9.44e+07 -0.8729279637336731 0.1671471744775772\n",
      "[Step 18095] Loss: 9.49e+07 -0.8728834986686707 0.16715046763420105\n",
      "[Step 18096] Loss: 9.46e+07 -0.8727931380271912 0.1671331375837326\n",
      "[Step 18097] Loss: 9.46e+07 -0.8727137446403503 0.16715212166309357\n",
      "[Step 18098] Loss: 9.37e+07 -0.8726446628570557 0.16717439889907837\n",
      "[Step 18099] Loss: 9.46e+07 -0.872548520565033 0.16718430817127228\n",
      "[Step 18100] Loss: 9.46e+07 -0.8725260496139526 0.1671554148197174\n",
      "[Step 18101] Loss: 9.48e+07 -0.872592031955719 0.1671149879693985\n",
      "[Step 18102] Loss: 9.54e+07 -0.8729161024093628 0.16703000664710999\n",
      "[Step 18103] Loss: 9.55e+07 -0.8733121752738953 0.16694995760917664\n",
      "[Step 18104] Loss: 9.44e+07 -0.8736394643783569 0.16691118478775024\n",
      "[Step 18105] Loss: 9.54e+07 -0.8738086819648743 0.16684351861476898\n",
      "[Step 18106] Loss: 9.45e+07 -0.8738633394241333 0.16680309176445007\n",
      "[Step 18107] Loss: 9.43e+07 -0.8738966584205627 0.1667824536561966\n",
      "[Step 18108] Loss: 9.42e+07 -0.8738792538642883 0.16678163409233093\n",
      "[Step 18109] Loss: 9.46e+07 -0.8738538026809692 0.16679731011390686\n",
      "[Step 18110] Loss: 9.46e+07 -0.8738340735435486 0.16678988933563232\n",
      "[Step 18111] Loss: 9.58e+07 -0.8740094304084778 0.16675110161304474\n",
      "[Step 18112] Loss: 9.50e+07 -0.8740464448928833 0.16671893000602722\n",
      "[Step 18113] Loss: 9.48e+07 -0.8740028142929077 0.16673624515533447\n",
      "[Step 18114] Loss: 9.52e+07 -0.8738208413124084 0.16673460602760315\n",
      "[Step 18115] Loss: 9.51e+07 -0.8735566139221191 0.16675935685634613\n",
      "[Step 18116] Loss: 9.45e+07 -0.873390793800354 0.1667577028274536\n",
      "[Step 18117] Loss: 9.45e+07 -0.8731675744056702 0.1668129861354828\n",
      "[Step 18118] Loss: 9.46e+07 -0.8729487061500549 0.16681793332099915\n",
      "[Step 18119] Loss: 9.47e+07 -0.8728168606758118 0.16683444380760193\n",
      "[Step 18120] Loss: 9.48e+07 -0.8727458119392395 0.16682453453540802\n",
      "[Step 18121] Loss: 9.37e+07 -0.8726863265037537 0.1667923629283905\n",
      "[Step 18122] Loss: 9.43e+07 -0.8725730776786804 0.1667700856924057\n",
      "[Step 18123] Loss: 9.43e+07 -0.8723863959312439 0.1667700856924057\n",
      "[Step 18124] Loss: 9.45e+07 -0.8722119331359863 0.16676843166351318\n",
      "[Step 18125] Loss: 9.57e+07 -0.8719317317008972 0.16679731011390686\n",
      "[Step 18126] Loss: 9.47e+07 -0.8717038035392761 0.16682206094264984\n",
      "[Step 18127] Loss: 9.53e+07 -0.8716835379600525 0.16680225729942322\n",
      "[Step 18128] Loss: 9.48e+07 -0.8718256950378418 0.16675688326358795\n",
      "[Step 18129] Loss: 9.42e+07 -0.871936023235321 0.16670654714107513\n",
      "[Step 18130] Loss: 9.55e+07 -0.8719030618667603 0.16668592393398285\n",
      "[Step 18131] Loss: 9.43e+07 -0.8718630075454712 0.16667848825454712\n",
      "[Step 18132] Loss: 9.49e+07 -0.8719037771224976 0.16666775941848755\n",
      "[Step 18133] Loss: 9.61e+07 -0.8720948696136475 0.16663064062595367\n",
      "[Step 18134] Loss: 9.45e+07 -0.8723341822624207 0.16656626760959625\n",
      "[Step 18135] Loss: 9.44e+07 -0.8725428581237793 0.16653986275196075\n",
      "[Step 18136] Loss: 9.50e+07 -0.872704029083252 0.16653326153755188\n",
      "[Step 18137] Loss: 9.50e+07 -0.8729236125946045 0.16647963225841522\n",
      "[Step 18138] Loss: 9.53e+07 -0.8731207251548767 0.16641774773597717\n",
      "[Step 18139] Loss: 9.44e+07 -0.8733234405517578 0.16636328399181366\n",
      "[Step 18140] Loss: 9.49e+07 -0.8734610080718994 0.1663500815629959\n",
      "[Step 18141] Loss: 9.45e+07 -0.8735949993133545 0.1663179099559784\n",
      "[Step 18142] Loss: 9.49e+07 -0.8735931515693665 0.16627830266952515\n",
      "[Step 18143] Loss: 9.47e+07 -0.8735450506210327 0.16625931859016418\n",
      "[Step 18144] Loss: 9.47e+07 -0.873482346534729 0.16626179218292236\n",
      "[Step 18145] Loss: 9.46e+07 -0.8735154867172241 0.1662345677614212\n",
      "[Step 18146] Loss: 9.50e+07 -0.8734975457191467 0.16619743406772614\n",
      "[Step 18147] Loss: 9.48e+07 -0.8736261129379272 0.16617102921009064\n",
      "[Step 18148] Loss: 9.43e+07 -0.8736406564712524 0.16614793241024017\n",
      "[Step 18149] Loss: 9.47e+07 -0.8735796213150024 0.16612234711647034\n",
      "[Step 18150] Loss: 9.44e+07 -0.8734577894210815 0.16612482070922852\n",
      "[Step 18151] Loss: 9.43e+07 -0.8732978105545044 0.16612812876701355\n",
      "[Step 18152] Loss: 9.44e+07 -0.8731512427330017 0.16613554954528809\n",
      "[Step 18153] Loss: 9.39e+07 -0.8729971647262573 0.16617268323898315\n",
      "[Step 18154] Loss: 9.45e+07 -0.8729700446128845 0.16615866124629974\n",
      "[Step 18155] Loss: 9.37e+07 -0.8729715943336487 0.16613802313804626\n",
      "[Step 18156] Loss: 9.47e+07 -0.8730115294456482 0.16612069308757782\n",
      "[Step 18157] Loss: 9.46e+07 -0.8731314539909363 0.16607779264450073\n",
      "[Step 18158] Loss: 9.48e+07 -0.8733056783676147 0.1660340577363968\n",
      "[Step 18159] Loss: 9.42e+07 -0.8734835982322693 0.16597382724285126\n",
      "[Step 18160] Loss: 9.46e+07 -0.8737514615058899 0.16592267155647278\n",
      "[Step 18161] Loss: 9.42e+07 -0.8740454912185669 0.1658616065979004\n",
      "[Step 18162] Loss: 9.54e+07 -0.8745138049125671 0.16579146683216095\n",
      "[Step 18163] Loss: 9.48e+07 -0.8750047087669373 0.16568584740161896\n",
      "[Step 18164] Loss: 9.44e+07 -0.8754833340644836 0.1656000316143036\n",
      "[Step 18165] Loss: 9.48e+07 -0.8760676980018616 0.16549111902713776\n",
      "[Step 18166] Loss: 9.45e+07 -0.876589834690094 0.16540777683258057\n",
      "[Step 18167] Loss: 9.41e+07 -0.8770774602890015 0.16530711948871613\n",
      "[Step 18168] Loss: 9.42e+07 -0.877495288848877 0.16521304845809937\n",
      "[Step 18169] Loss: 9.50e+07 -0.8777676224708557 0.1651635468006134\n",
      "[Step 18170] Loss: 9.39e+07 -0.8780309557914734 0.1651148647069931\n",
      "[Step 18171] Loss: 9.48e+07 -0.8781976103782654 0.1650661677122116\n",
      "[Step 18172] Loss: 9.39e+07 -0.8783867955207825 0.1650521457195282\n",
      "[Step 18173] Loss: 9.47e+07 -0.8785819411277771 0.16501501202583313\n",
      "[Step 18174] Loss: 9.43e+07 -0.8786842226982117 0.16498447954654694\n",
      "[Step 18175] Loss: 9.63e+07 -0.8790497779846191 0.1649118810892105\n",
      "[Step 18176] Loss: 9.42e+07 -0.879430890083313 0.16482853889465332\n",
      "[Step 18177] Loss: 9.52e+07 -0.8796449899673462 0.16477325558662415\n",
      "[Step 18178] Loss: 9.54e+07 -0.8796867728233337 0.16474932432174683\n",
      "[Step 18179] Loss: 9.54e+07 -0.8795377016067505 0.1647501438856125\n",
      "[Step 18180] Loss: 9.46e+07 -0.8792777061462402 0.16481450200080872\n",
      "[Step 18181] Loss: 9.47e+07 -0.8789982199668884 0.1648409068584442\n",
      "[Step 18182] Loss: 9.53e+07 -0.878773033618927 0.16486318409442902\n",
      "[Step 18183] Loss: 9.43e+07 -0.8785086870193481 0.16489042341709137\n",
      "[Step 18184] Loss: 9.45e+07 -0.878267765045166 0.16491930186748505\n",
      "[Step 18185] Loss: 9.44e+07 -0.8780235052108765 0.16495972871780396\n",
      "[Step 18186] Loss: 9.48e+07 -0.8777830004692078 0.16498365998268127\n",
      "[Step 18187] Loss: 9.45e+07 -0.8775167465209961 0.16501832008361816\n",
      "[Step 18188] Loss: 9.46e+07 -0.877300500869751 0.16504141688346863\n",
      "[Step 18189] Loss: 9.52e+07 -0.8769735097885132 0.16505545377731323\n",
      "[Step 18190] Loss: 9.34e+07 -0.8767016530036926 0.1650604009628296\n",
      "[Step 18191] Loss: 9.43e+07 -0.8763519525527954 0.16509835422039032\n",
      "[Step 18192] Loss: 9.45e+07 -0.8759353756904602 0.16515116393566132\n",
      "[Step 18193] Loss: 9.42e+07 -0.8756268620491028 0.1651816964149475\n",
      "[Step 18194] Loss: 9.46e+07 -0.8752273917198181 0.1652163565158844\n",
      "[Step 18195] Loss: 9.50e+07 -0.8748446702957153 0.16526751220226288\n",
      "[Step 18196] Loss: 9.51e+07 -0.8746299147605896 0.16527658700942993\n",
      "[Step 18197] Loss: 9.51e+07 -0.8743493556976318 0.1652914434671402\n",
      "[Step 18198] Loss: 9.41e+07 -0.8741164803504944 0.16529886424541473\n",
      "[Step 18199] Loss: 9.46e+07 -0.8738593459129333 0.16531948745250702\n",
      "[Step 18200] Loss: 9.36e+07 -0.8736207485198975 0.16532856225967407\n",
      "[Step 18201] Loss: 9.39e+07 -0.8733898401260376 0.16536074876785278\n",
      "[Step 18202] Loss: 9.43e+07 -0.8731752038002014 0.1653706431388855\n",
      "[Step 18203] Loss: 9.50e+07 -0.872924268245697 0.16537807881832123\n",
      "[Step 18204] Loss: 9.48e+07 -0.8727277517318726 0.16539622843265533\n",
      "[Step 18205] Loss: 9.54e+07 -0.8725630640983582 0.16539375483989716\n",
      "[Step 18206] Loss: 9.52e+07 -0.8724635243415833 0.16539788246154785\n",
      "[Step 18207] Loss: 9.41e+07 -0.872348427772522 0.16540861129760742\n",
      "[Step 18208] Loss: 9.45e+07 -0.8722698092460632 0.16540201008319855\n",
      "[Step 18209] Loss: 9.46e+07 -0.8721742033958435 0.16538797318935394\n",
      "[Step 18210] Loss: 9.42e+07 -0.8720407485961914 0.16539540886878967\n",
      "[Step 18211] Loss: 9.43e+07 -0.8717957735061646 0.1654457300901413\n",
      "[Step 18212] Loss: 9.52e+07 -0.8716288805007935 0.16547873616218567\n",
      "[Step 18213] Loss: 9.54e+07 -0.8716473579406738 0.16547709703445435\n",
      "[Step 18214] Loss: 9.36e+07 -0.8716829419136047 0.16547873616218567\n",
      "[Step 18215] Loss: 9.43e+07 -0.8717615604400635 0.16549690067768097\n",
      "[Step 18216] Loss: 9.49e+07 -0.8718125820159912 0.16549690067768097\n",
      "[Step 18217] Loss: 9.48e+07 -0.8717289566993713 0.16548451781272888\n",
      "[Step 18218] Loss: 9.53e+07 -0.8717087507247925 0.16547709703445435\n",
      "[Step 18219] Loss: 9.50e+07 -0.8717785477638245 0.1654820442199707\n",
      "[Step 18220] Loss: 9.39e+07 -0.8718332052230835 0.16546636819839478\n",
      "[Step 18221] Loss: 9.56e+07 -0.871695339679718 0.16552412509918213\n",
      "[Step 18222] Loss: 9.39e+07 -0.8714941143989563 0.16558848321437836\n",
      "[Step 18223] Loss: 9.46e+07 -0.8712963461875916 0.16563139855861664\n",
      "[Step 18224] Loss: 9.43e+07 -0.8711960911750793 0.1656421273946762\n",
      "[Step 18225] Loss: 9.41e+07 -0.8710873126983643 0.16565780341625214\n",
      "[Step 18226] Loss: 9.38e+07 -0.8710662722587585 0.1656421273946762\n",
      "[Step 18227] Loss: 9.42e+07 -0.871053159236908 0.16564294695854187\n",
      "[Step 18228] Loss: 9.50e+07 -0.8712132573127747 0.1656058132648468\n",
      "[Step 18229] Loss: 9.47e+07 -0.8713414669036865 0.16560499370098114\n",
      "[Step 18230] Loss: 9.35e+07 -0.8714420795440674 0.16558188199996948\n",
      "[Step 18231] Loss: 9.42e+07 -0.8715752363204956 0.1655488759279251\n",
      "[Step 18232] Loss: 9.40e+07 -0.8717399835586548 0.16554145514965057\n",
      "[Step 18233] Loss: 9.48e+07 -0.8719220161437988 0.16548122465610504\n",
      "[Step 18234] Loss: 9.41e+07 -0.8720809817314148 0.16543996334075928\n",
      "[Step 18235] Loss: 9.48e+07 -0.8723651170730591 0.16536569595336914\n",
      "[Step 18236] Loss: 9.52e+07 -0.8727911114692688 0.16528071463108063\n",
      "[Step 18237] Loss: 9.41e+07 -0.8731739521026611 0.16519902646541595\n",
      "[Step 18238] Loss: 9.44e+07 -0.8734673857688904 0.16513796150684357\n",
      "[Step 18239] Loss: 9.45e+07 -0.8737391829490662 0.16506369411945343\n",
      "[Step 18240] Loss: 9.48e+07 -0.8740459084510803 0.16499604284763336\n",
      "[Step 18241] Loss: 9.41e+07 -0.8742973804473877 0.16495643556118011\n",
      "[Step 18242] Loss: 9.43e+07 -0.8745967149734497 0.16490939259529114\n",
      "[Step 18243] Loss: 9.48e+07 -0.8748331069946289 0.16486071050167084\n",
      "[Step 18244] Loss: 9.54e+07 -0.8748688697814941 0.16484008729457855\n",
      "[Step 18245] Loss: 9.41e+07 -0.8748587965965271 0.16482028365135193\n",
      "[Step 18246] Loss: 9.39e+07 -0.8747804760932922 0.16481781005859375\n",
      "[Step 18247] Loss: 9.49e+07 -0.8746645450592041 0.16479800641536713\n",
      "[Step 18248] Loss: 9.47e+07 -0.8746183514595032 0.16480129957199097\n",
      "[Step 18249] Loss: 9.53e+07 -0.8745443224906921 0.16478809714317322\n",
      "[Step 18250] Loss: 9.40e+07 -0.8745185136795044 0.1647699475288391\n",
      "[Step 18251] Loss: 9.42e+07 -0.874544084072113 0.1647476702928543\n",
      "[Step 18252] Loss: 9.46e+07 -0.8745715618133545 0.16470889747142792\n",
      "[Step 18253] Loss: 9.48e+07 -0.8745275139808655 0.1646973341703415\n",
      "[Step 18254] Loss: 9.46e+07 -0.8745302557945251 0.16466103494167328\n",
      "[Step 18255] Loss: 9.51e+07 -0.8744615912437439 0.16465608775615692\n",
      "[Step 18256] Loss: 9.48e+07 -0.8742963671684265 0.164670929312706\n",
      "[Step 18257] Loss: 9.51e+07 -0.8741571307182312 0.1646544337272644\n",
      "[Step 18258] Loss: 9.46e+07 -0.8740485310554504 0.16465112566947937\n",
      "[Step 18259] Loss: 9.44e+07 -0.8740554451942444 0.16468331217765808\n",
      "[Step 18260] Loss: 9.42e+07 -0.8740267157554626 0.16467753052711487\n",
      "[Step 18261] Loss: 9.51e+07 -0.8741062879562378 0.16465772688388824\n",
      "[Step 18262] Loss: 9.40e+07 -0.8741982579231262 0.16460740566253662\n",
      "[Step 18263] Loss: 9.48e+07 -0.8742836713790894 0.16461895406246185\n",
      "[Step 18264] Loss: 9.47e+07 -0.8743906021118164 0.16461895406246185\n",
      "[Step 18265] Loss: 9.53e+07 -0.8745806217193604 0.16458676755428314\n",
      "[Step 18266] Loss: 9.41e+07 -0.8748444318771362 0.16455210745334625\n",
      "[Step 18267] Loss: 9.45e+07 -0.8750777840614319 0.16448858380317688\n",
      "[Step 18268] Loss: 9.44e+07 -0.8752938508987427 0.16444814205169678\n",
      "[Step 18269] Loss: 9.56e+07 -0.8756362795829773 0.16438791155815125\n",
      "[Step 18270] Loss: 9.46e+07 -0.8759996294975281 0.1643276810646057\n",
      "[Step 18271] Loss: 9.47e+07 -0.8763380646705627 0.16428476572036743\n",
      "[Step 18272] Loss: 9.44e+07 -0.8766177892684937 0.16424021124839783\n",
      "[Step 18273] Loss: 9.50e+07 -0.8770582675933838 0.16419070959091187\n",
      "[Step 18274] Loss: 9.46e+07 -0.8773229718208313 0.16417503356933594\n",
      "[Step 18275] Loss: 9.46e+07 -0.8776073455810547 0.16412222385406494\n",
      "[Step 18276] Loss: 9.45e+07 -0.8779198527336121 0.16407765448093414\n",
      "[Step 18277] Loss: 9.54e+07 -0.8783756494522095 0.16401413083076477\n",
      "[Step 18278] Loss: 9.40e+07 -0.8788011074066162 0.1639464646577835\n",
      "[Step 18279] Loss: 9.49e+07 -0.8793483376502991 0.1638713777065277\n",
      "[Step 18280] Loss: 9.45e+07 -0.8797709345817566 0.16381196677684784\n",
      "[Step 18281] Loss: 9.45e+07 -0.8801760673522949 0.16371047496795654\n",
      "[Step 18282] Loss: 9.44e+07 -0.8804677724838257 0.1636708676815033\n",
      "[Step 18283] Loss: 9.48e+07 -0.8806125521659851 0.16363951563835144\n",
      "[Step 18284] Loss: 9.54e+07 -0.8804993033409119 0.16367746889591217\n",
      "[Step 18285] Loss: 9.42e+07 -0.8804795145988464 0.16367581486701965\n",
      "[Step 18286] Loss: 9.39e+07 -0.8805115222930908 0.16364777088165283\n",
      "[Step 18287] Loss: 9.45e+07 -0.8806646466255188 0.16361476480960846\n",
      "[Step 18288] Loss: 9.40e+07 -0.8807781338691711 0.16359496116638184\n",
      "[Step 18289] Loss: 9.46e+07 -0.8808485865592957 0.16356608271598816\n",
      "[Step 18290] Loss: 9.43e+07 -0.8809158205986023 0.1635264754295349\n",
      "[Step 18291] Loss: 9.52e+07 -0.8811203241348267 0.16348356008529663\n",
      "[Step 18292] Loss: 9.44e+07 -0.8812294602394104 0.1634497344493866\n",
      "[Step 18293] Loss: 9.45e+07 -0.8813295364379883 0.1634233295917511\n",
      "[Step 18294] Loss: 9.46e+07 -0.8815144300460815 0.16335897147655487\n",
      "[Step 18295] Loss: 9.40e+07 -0.881730854511261 0.1633177101612091\n",
      "[Step 18296] Loss: 9.43e+07 -0.8818826675415039 0.16328223049640656\n",
      "[Step 18297] Loss: 9.47e+07 -0.8818754553794861 0.16324427723884583\n",
      "[Step 18298] Loss: 9.42e+07 -0.881895124912262 0.16322611272335052\n",
      "[Step 18299] Loss: 9.38e+07 -0.8818778395652771 0.1632286012172699\n",
      "[Step 18300] Loss: 9.46e+07 -0.8817797303199768 0.1632203459739685\n",
      "[Step 18301] Loss: 9.46e+07 -0.8816821575164795 0.1632162183523178\n",
      "[Step 18302] Loss: 9.60e+07 -0.8813872933387756 0.16326242685317993\n",
      "[Step 18303] Loss: 9.43e+07 -0.8811854124069214 0.16325417160987854\n",
      "[Step 18304] Loss: 9.50e+07 -0.8810972571372986 0.1632450968027115\n",
      "[Step 18305] Loss: 9.49e+07 -0.881036102771759 0.1632368415594101\n",
      "[Step 18306] Loss: 9.60e+07 -0.8808408379554749 0.16325995326042175\n",
      "[Step 18307] Loss: 9.36e+07 -0.8807565569877625 0.16326819360256195\n",
      "[Step 18308] Loss: 9.46e+07 -0.8806334137916565 0.16328388452529907\n",
      "[Step 18309] Loss: 9.45e+07 -0.8806105256080627 0.1633160561323166\n",
      "[Step 18310] Loss: 9.39e+07 -0.8805469870567322 0.16331689059734344\n",
      "[Step 18311] Loss: 9.45e+07 -0.8803813457489014 0.16331936419010162\n",
      "[Step 18312] Loss: 9.42e+07 -0.8802400231361389 0.16334080696105957\n",
      "[Step 18313] Loss: 9.42e+07 -0.8801937103271484 0.16335897147655487\n",
      "[Step 18314] Loss: 9.42e+07 -0.8801950812339783 0.1633647382259369\n",
      "[Step 18315] Loss: 9.56e+07 -0.8802329301834106 0.16337959468364716\n",
      "[Step 18316] Loss: 9.53e+07 -0.8801606297492981 0.16341838240623474\n",
      "[Step 18317] Loss: 9.54e+07 -0.8803120255470276 0.16338784992694855\n",
      "[Step 18318] Loss: 9.49e+07 -0.8804125785827637 0.16336886584758759\n",
      "[Step 18319] Loss: 9.45e+07 -0.8805128335952759 0.16333091259002686\n",
      "[Step 18320] Loss: 9.39e+07 -0.8805729746818542 0.1633300930261612\n",
      "[Step 18321] Loss: 9.36e+07 -0.8806793093681335 0.16331523656845093\n",
      "[Step 18322] Loss: 9.40e+07 -0.8806969523429871 0.16330616176128387\n",
      "[Step 18323] Loss: 9.39e+07 -0.8806890845298767 0.16327810287475586\n",
      "[Step 18324] Loss: 9.43e+07 -0.8807299733161926 0.1632426232099533\n",
      "[Step 18325] Loss: 9.50e+07 -0.8807200193405151 0.1632244735956192\n",
      "[Step 18326] Loss: 9.41e+07 -0.8807133436203003 0.16320548951625824\n",
      "[Step 18327] Loss: 9.43e+07 -0.88068026304245 0.16316835582256317\n",
      "[Step 18328] Loss: 9.48e+07 -0.8805407881736755 0.1631716638803482\n",
      "[Step 18329] Loss: 9.42e+07 -0.8804044127464294 0.16320383548736572\n",
      "[Step 18330] Loss: 9.38e+07 -0.8802662491798401 0.1632244735956192\n",
      "[Step 18331] Loss: 9.55e+07 -0.8804005980491638 0.16319888830184937\n",
      "[Step 18332] Loss: 9.45e+07 -0.8805444836616516 0.16315186023712158\n",
      "[Step 18333] Loss: 9.43e+07 -0.8806503415107727 0.163113072514534\n",
      "[Step 18334] Loss: 9.43e+07 -0.8807803988456726 0.16307181119918823\n",
      "[Step 18335] Loss: 9.52e+07 -0.8807207942008972 0.16306520998477936\n",
      "[Step 18336] Loss: 9.51e+07 -0.8808525800704956 0.16307677328586578\n",
      "[Step 18337] Loss: 9.53e+07 -0.8810727000236511 0.16302809119224548\n",
      "[Step 18338] Loss: 9.51e+07 -0.8812060356140137 0.16297362744808197\n",
      "[Step 18339] Loss: 9.46e+07 -0.8814103007316589 0.1629464030265808\n",
      "[Step 18340] Loss: 9.53e+07 -0.8817688822746277 0.1629059612751007\n",
      "[Step 18341] Loss: 9.46e+07 -0.8821287751197815 0.16284573078155518\n",
      "[Step 18342] Loss: 9.43e+07 -0.8824427127838135 0.16278797388076782\n",
      "[Step 18343] Loss: 9.43e+07 -0.8826440572738647 0.16275909543037415\n",
      "[Step 18344] Loss: 9.55e+07 -0.8830418586730957 0.16269224882125854\n",
      "[Step 18345] Loss: 9.46e+07 -0.8833383321762085 0.16264769434928894\n",
      "[Step 18346] Loss: 9.39e+07 -0.8835201263427734 0.16261716187000275\n",
      "[Step 18347] Loss: 9.50e+07 -0.8837267160415649 0.1625775545835495\n",
      "[Step 18348] Loss: 9.42e+07 -0.883933961391449 0.1625412553548813\n",
      "[Step 18349] Loss: 9.44e+07 -0.8840787410736084 0.16255611181259155\n",
      "[Step 18350] Loss: 9.44e+07 -0.8842917680740356 0.16252723336219788\n",
      "[Step 18351] Loss: 9.50e+07 -0.8846530914306641 0.16246698796749115\n",
      "[Step 18352] Loss: 9.39e+07 -0.885036051273346 0.1624051034450531\n",
      "[Step 18353] Loss: 9.44e+07 -0.885303258895874 0.16235889494419098\n",
      "[Step 18354] Loss: 9.41e+07 -0.8854274749755859 0.1623300164937973\n",
      "[Step 18355] Loss: 9.42e+07 -0.885547935962677 0.16231846809387207\n",
      "[Step 18356] Loss: 9.47e+07 -0.8857323527336121 0.1623036116361618\n",
      "[Step 18357] Loss: 9.44e+07 -0.8860005140304565 0.1622450351715088\n",
      "[Step 18358] Loss: 9.43e+07 -0.8863852024078369 0.16217489540576935\n",
      "[Step 18359] Loss: 9.46e+07 -0.8866140842437744 0.16212621331214905\n",
      "[Step 18360] Loss: 9.47e+07 -0.8869710564613342 0.16204452514648438\n",
      "[Step 18361] Loss: 9.35e+07 -0.8873034119606018 0.16198676824569702\n",
      "[Step 18362] Loss: 9.47e+07 -0.8876239657402039 0.16194798052310944\n",
      "[Step 18363] Loss: 9.40e+07 -0.8879388570785522 0.16190095245838165\n",
      "[Step 18364] Loss: 9.44e+07 -0.8881948590278625 0.16184483468532562\n",
      "[Step 18365] Loss: 9.34e+07 -0.8884709477424622 0.16180193424224854\n",
      "[Step 18366] Loss: 9.47e+07 -0.888696551322937 0.16177058219909668\n",
      "[Step 18367] Loss: 9.43e+07 -0.888848066329956 0.16172850131988525\n",
      "[Step 18368] Loss: 9.40e+07 -0.8890326619148254 0.16170044243335724\n",
      "[Step 18369] Loss: 9.48e+07 -0.8891639709472656 0.1616385579109192\n",
      "[Step 18370] Loss: 9.43e+07 -0.8892882466316223 0.1616038978099823\n",
      "[Step 18371] Loss: 9.43e+07 -0.8894599080085754 0.1615651249885559\n",
      "[Step 18372] Loss: 9.47e+07 -0.8895167112350464 0.16153541207313538\n",
      "[Step 18373] Loss: 9.49e+07 -0.889565646648407 0.1615246832370758\n",
      "[Step 18374] Loss: 9.49e+07 -0.889786422252655 0.16149167716503143\n",
      "[Step 18375] Loss: 9.47e+07 -0.8900476098060608 0.16144134104251862\n",
      "[Step 18376] Loss: 9.44e+07 -0.8902358412742615 0.16139762103557587\n",
      "[Step 18377] Loss: 9.45e+07 -0.8903454542160034 0.16136956214904785\n",
      "[Step 18378] Loss: 9.45e+07 -0.8903815746307373 0.16136790812015533\n",
      "[Step 18379] Loss: 9.51e+07 -0.890495240688324 0.1613646149635315\n",
      "[Step 18380] Loss: 9.44e+07 -0.8906459212303162 0.16132500767707825\n",
      "[Step 18381] Loss: 9.54e+07 -0.8909828662872314 0.1612284630537033\n",
      "[Step 18382] Loss: 9.53e+07 -0.8911285400390625 0.16118720173835754\n",
      "[Step 18383] Loss: 9.44e+07 -0.8912366032600403 0.16114017367362976\n",
      "[Step 18384] Loss: 9.42e+07 -0.8914265036582947 0.16109725832939148\n",
      "[Step 18385] Loss: 9.56e+07 -0.8914754986763 0.16108818352222443\n",
      "[Step 18386] Loss: 9.45e+07 -0.8914835453033447 0.16107498109340668\n",
      "[Step 18387] Loss: 9.50e+07 -0.8914340138435364 0.16105270385742188\n",
      "[Step 18388] Loss: 9.42e+07 -0.8914345502853394 0.1610279530286789\n",
      "[Step 18389] Loss: 9.46e+07 -0.8913505673408508 0.16102629899978638\n",
      "[Step 18390] Loss: 9.52e+07 -0.891185462474823 0.1610378623008728\n",
      "[Step 18391] Loss: 9.47e+07 -0.8908763527870178 0.16107086837291718\n",
      "[Step 18392] Loss: 9.56e+07 -0.8907778263092041 0.16106343269348145\n",
      "[Step 18393] Loss: 9.41e+07 -0.8907005190849304 0.16104941070079803\n",
      "[Step 18394] Loss: 9.46e+07 -0.8906763792037964 0.1610518842935562\n",
      "[Step 18395] Loss: 9.48e+07 -0.8906419277191162 0.1610155701637268\n",
      "[Step 18396] Loss: 9.47e+07 -0.8906682133674622 0.1610098034143448\n",
      "[Step 18397] Loss: 9.47e+07 -0.8907074928283691 0.16098999977111816\n",
      "[Step 18398] Loss: 9.47e+07 -0.8906964659690857 0.1609586477279663\n",
      "[Step 18399] Loss: 9.48e+07 -0.890615701675415 0.16095039248466492\n",
      "[Step 18400] Loss: 9.50e+07 -0.8905830979347229 0.16099576652050018\n",
      "[Step 18401] Loss: 9.43e+07 -0.8904551267623901 0.16102053225040436\n",
      "[Step 18402] Loss: 9.46e+07 -0.890485942363739 0.1610015481710434\n",
      "[Step 18403] Loss: 9.39e+07 -0.8904538750648499 0.1610032021999359\n",
      "[Step 18404] Loss: 9.51e+07 -0.8904275894165039 0.16101475059986115\n",
      "[Step 18405] Loss: 9.49e+07 -0.8904743194580078 0.16104362905025482\n",
      "[Step 18406] Loss: 9.41e+07 -0.8905754685401917 0.16100402176380157\n",
      "[Step 18407] Loss: 9.45e+07 -0.890701949596405 0.16098009049892426\n",
      "[Step 18408] Loss: 9.48e+07 -0.8907172083854675 0.1609710156917572\n",
      "[Step 18409] Loss: 9.54e+07 -0.8908545970916748 0.1609446108341217\n",
      "[Step 18410] Loss: 9.50e+07 -0.8910558223724365 0.16091986000537872\n",
      "[Step 18411] Loss: 9.45e+07 -0.8911772966384888 0.1609140783548355\n",
      "[Step 18412] Loss: 9.44e+07 -0.891269326210022 0.16091656684875488\n",
      "[Step 18413] Loss: 9.49e+07 -0.8913028240203857 0.16092564165592194\n",
      "[Step 18414] Loss: 9.45e+07 -0.8914020657539368 0.16091078519821167\n",
      "[Step 18415] Loss: 9.46e+07 -0.8914489150047302 0.16090665757656097\n",
      "[Step 18416] Loss: 9.49e+07 -0.8914202451705933 0.16092151403427124\n",
      "[Step 18417] Loss: 9.62e+07 -0.8912566304206848 0.16095204651355743\n",
      "[Step 18418] Loss: 9.46e+07 -0.8910441398620605 0.16098587214946747\n",
      "[Step 18419] Loss: 9.44e+07 -0.8908240795135498 0.16103950142860413\n",
      "[Step 18420] Loss: 9.43e+07 -0.8906734585762024 0.16106921434402466\n",
      "[Step 18421] Loss: 9.49e+07 -0.8906594514846802 0.1610683798789978\n",
      "[Step 18422] Loss: 9.40e+07 -0.8906891345977783 0.16107416152954102\n",
      "[Step 18423] Loss: 9.45e+07 -0.8906190991401672 0.16107003390789032\n",
      "[Step 18424] Loss: 9.42e+07 -0.8905404210090637 0.16109643876552582\n",
      "[Step 18425] Loss: 9.39e+07 -0.890523374080658 0.1610865443944931\n",
      "[Step 18426] Loss: 9.44e+07 -0.8905107975006104 0.16108158230781555\n",
      "[Step 18427] Loss: 9.44e+07 -0.890525758266449 0.16107003390789032\n",
      "[Step 18428] Loss: 9.39e+07 -0.8904996514320374 0.1610543578863144\n",
      "[Step 18429] Loss: 9.43e+07 -0.8904376029968262 0.16104528307914734\n",
      "[Step 18430] Loss: 9.44e+07 -0.8903893232345581 0.16104775667190552\n",
      "[Step 18431] Loss: 9.45e+07 -0.8903452754020691 0.1610114574432373\n",
      "[Step 18432] Loss: 9.40e+07 -0.8902639746665955 0.1610378623008728\n",
      "[Step 18433] Loss: 9.51e+07 -0.8904237747192383 0.1610114574432373\n",
      "[Step 18434] Loss: 9.43e+07 -0.8906090259552002 0.16096772253513336\n",
      "[Step 18435] Loss: 9.47e+07 -0.8908485770225525 0.16090252995491028\n",
      "[Step 18436] Loss: 9.37e+07 -0.8911164402961731 0.160829097032547\n",
      "[Step 18437] Loss: 9.46e+07 -0.8914531469345093 0.1607622653245926\n",
      "[Step 18438] Loss: 9.44e+07 -0.8918284773826599 0.16070862114429474\n",
      "[Step 18439] Loss: 9.47e+07 -0.8923338651657104 0.16062693297863007\n",
      "[Step 18440] Loss: 9.42e+07 -0.8927239179611206 0.16056422889232635\n",
      "[Step 18441] Loss: 9.49e+07 -0.8932427167892456 0.16048336029052734\n",
      "[Step 18442] Loss: 9.43e+07 -0.8937214016914368 0.1603909432888031\n",
      "[Step 18443] Loss: 9.49e+07 -0.8941133618354797 0.16033565998077393\n",
      "[Step 18444] Loss: 9.48e+07 -0.8945214152336121 0.1602589339017868\n",
      "[Step 18445] Loss: 9.47e+07 -0.894819974899292 0.16019292175769806\n",
      "[Step 18446] Loss: 9.48e+07 -0.8952449560165405 0.1601153463125229\n",
      "[Step 18447] Loss: 9.45e+07 -0.895708441734314 0.16003118455410004\n",
      "[Step 18448] Loss: 9.44e+07 -0.8961148262023926 0.15994702279567719\n",
      "[Step 18449] Loss: 9.54e+07 -0.8963031768798828 0.15993382036685944\n",
      "[Step 18450] Loss: 9.52e+07 -0.896586000919342 0.15986615419387817\n",
      "[Step 18451] Loss: 9.49e+07 -0.8969161510467529 0.15981335937976837\n",
      "[Step 18452] Loss: 9.46e+07 -0.8972228765487671 0.1597481667995453\n",
      "[Step 18453] Loss: 9.46e+07 -0.897571325302124 0.159699484705925\n",
      "[Step 18454] Loss: 9.43e+07 -0.8977997899055481 0.15963512659072876\n",
      "[Step 18455] Loss: 9.52e+07 -0.8979383111000061 0.15960706770420074\n",
      "[Step 18456] Loss: 9.50e+07 -0.8980352282524109 0.15958726406097412\n",
      "[Step 18457] Loss: 9.45e+07 -0.898100733757019 0.15954600274562836\n",
      "[Step 18458] Loss: 9.45e+07 -0.8981117606163025 0.15953363478183746\n",
      "[Step 18459] Loss: 9.47e+07 -0.8980854749679565 0.15951959788799286\n",
      "[Step 18460] Loss: 9.42e+07 -0.8980512022972107 0.15951217710971832\n",
      "[Step 18461] Loss: 9.45e+07 -0.8981478810310364 0.15949155390262604\n",
      "[Step 18462] Loss: 9.46e+07 -0.8981871604919434 0.15946678817272186\n",
      "[Step 18463] Loss: 9.46e+07 -0.8981171250343323 0.15946844220161438\n",
      "[Step 18464] Loss: 9.42e+07 -0.8980305194854736 0.15944616496562958\n",
      "[Step 18465] Loss: 9.43e+07 -0.897969126701355 0.15941233932971954\n",
      "[Step 18466] Loss: 9.54e+07 -0.8978362679481506 0.15942059457302094\n",
      "[Step 18467] Loss: 9.41e+07 -0.8976860046386719 0.1594255417585373\n",
      "[Step 18468] Loss: 9.47e+07 -0.897635281085968 0.15943627059459686\n",
      "[Step 18469] Loss: 9.58e+07 -0.8978530764579773 0.1593809872865677\n",
      "[Step 18470] Loss: 9.51e+07 -0.8981978893280029 0.15930837392807007\n",
      "[Step 18471] Loss: 9.42e+07 -0.8985300064086914 0.15922915935516357\n",
      "[Step 18472] Loss: 9.57e+07 -0.8988673686981201 0.1591878980398178\n",
      "[Step 18473] Loss: 9.43e+07 -0.8992156982421875 0.1591334342956543\n",
      "[Step 18474] Loss: 9.45e+07 -0.8994686007499695 0.1590641289949417\n",
      "[Step 18475] Loss: 9.41e+07 -0.8996967673301697 0.15902617573738098\n",
      "[Step 18476] Loss: 9.45e+07 -0.8999756574630737 0.15897996723651886\n",
      "[Step 18477] Loss: 9.46e+07 -0.9001500606536865 0.1589123010635376\n",
      "[Step 18478] Loss: 9.44e+07 -0.9003013968467712 0.15885619819164276\n",
      "[Step 18479] Loss: 9.43e+07 -0.900479793548584 0.1587984412908554\n",
      "[Step 18480] Loss: 9.52e+07 -0.9005066156387329 0.1587844043970108\n",
      "[Step 18481] Loss: 9.45e+07 -0.9005242586135864 0.15874892473220825\n",
      "[Step 18482] Loss: 9.48e+07 -0.9004579186439514 0.15876130759716034\n",
      "[Step 18483] Loss: 9.50e+07 -0.9005129933357239 0.15874892473220825\n",
      "[Step 18484] Loss: 9.50e+07 -0.9007174372673035 0.15867631137371063\n",
      "[Step 18485] Loss: 9.44e+07 -0.901007354259491 0.15861524641513824\n",
      "[Step 18486] Loss: 9.44e+07 -0.9012566804885864 0.15855172276496887\n",
      "[Step 18487] Loss: 9.52e+07 -0.901422917842865 0.15851624310016632\n",
      "[Step 18488] Loss: 9.44e+07 -0.9015790224075317 0.15847910940647125\n",
      "[Step 18489] Loss: 9.46e+07 -0.9018107652664185 0.15840978920459747\n",
      "[Step 18490] Loss: 9.47e+07 -0.9020941853523254 0.15831902623176575\n",
      "[Step 18491] Loss: 9.37e+07 -0.9023107886314392 0.15827777981758118\n",
      "[Step 18492] Loss: 9.51e+07 -0.9024772644042969 0.15825632214546204\n",
      "[Step 18493] Loss: 9.51e+07 -0.9024603366851807 0.15825879573822021\n",
      "[Step 18494] Loss: 9.50e+07 -0.9025989770889282 0.15818865597248077\n",
      "[Step 18495] Loss: 9.55e+07 -0.9029874205589294 0.1581292450428009\n",
      "[Step 18496] Loss: 9.46e+07 -0.9033775925636292 0.15806983411312103\n",
      "[Step 18497] Loss: 9.51e+07 -0.903589129447937 0.1579996943473816\n",
      "[Step 18498] Loss: 9.44e+07 -0.9037711024284363 0.1579914540052414\n",
      "[Step 18499] Loss: 9.39e+07 -0.9039984941482544 0.15794937312602997\n",
      "[Step 18500] Loss: 9.52e+07 -0.9041551947593689 0.15787839889526367\n",
      "[Step 18501] Loss: 9.50e+07 -0.9044530391693115 0.15782064199447632\n",
      "[Step 18502] Loss: 9.46e+07 -0.9048340320587158 0.15775299072265625\n",
      "[Step 18503] Loss: 9.37e+07 -0.905092716217041 0.15770100057125092\n",
      "[Step 18504] Loss: 9.42e+07 -0.9052751064300537 0.1576547920703888\n",
      "[Step 18505] Loss: 9.54e+07 -0.905712902545929 0.157579705119133\n",
      "[Step 18506] Loss: 9.43e+07 -0.9060686826705933 0.1574839949607849\n",
      "[Step 18507] Loss: 9.52e+07 -0.9062947630882263 0.1574419140815735\n",
      "[Step 18508] Loss: 9.50e+07 -0.9065955281257629 0.15738414227962494\n",
      "[Step 18509] Loss: 9.53e+07 -0.9067845940589905 0.15733711421489716\n",
      "[Step 18510] Loss: 9.47e+07 -0.907019853591919 0.1573115438222885\n",
      "[Step 18511] Loss: 9.51e+07 -0.9073681831359863 0.15726450085639954\n",
      "[Step 18512] Loss: 9.45e+07 -0.9077478051185608 0.15721829235553741\n",
      "[Step 18513] Loss: 9.47e+07 -0.9079895615577698 0.15715475380420685\n",
      "[Step 18514] Loss: 9.45e+07 -0.9081994891166687 0.1571027785539627\n",
      "[Step 18515] Loss: 9.42e+07 -0.9083305597305298 0.15704667568206787\n",
      "[Step 18516] Loss: 9.43e+07 -0.9084146618843079 0.15700623393058777\n",
      "[Step 18517] Loss: 9.42e+07 -0.9084799289703369 0.1570012867450714\n",
      "[Step 18518] Loss: 9.43e+07 -0.9085438847541809 0.15699386596679688\n",
      "[Step 18519] Loss: 9.46e+07 -0.9084979891777039 0.15698643028736115\n",
      "[Step 18520] Loss: 9.43e+07 -0.9084028601646423 0.15699221193790436\n",
      "[Step 18521] Loss: 9.43e+07 -0.9082934260368347 0.15698230266571045\n",
      "[Step 18522] Loss: 9.42e+07 -0.9081612229347229 0.15702687203884125\n",
      "[Step 18523] Loss: 9.44e+07 -0.9080716967582703 0.15701861679553986\n",
      "[Step 18524] Loss: 9.49e+07 -0.9079423546791077 0.1570318192243576\n",
      "[Step 18525] Loss: 9.48e+07 -0.9077391624450684 0.15703924000263214\n",
      "[Step 18526] Loss: 9.41e+07 -0.9075304865837097 0.15704502165317535\n",
      "[Step 18527] Loss: 9.41e+07 -0.9073715806007385 0.15705491602420807\n",
      "[Step 18528] Loss: 9.43e+07 -0.9072999954223633 0.15706811845302582\n",
      "[Step 18529] Loss: 9.46e+07 -0.9070916175842285 0.1570747196674347\n",
      "[Step 18530] Loss: 9.51e+07 -0.9069981575012207 0.15708544850349426\n",
      "[Step 18531] Loss: 9.50e+07 -0.9068921804428101 0.15710359811782837\n",
      "[Step 18532] Loss: 9.42e+07 -0.9068226218223572 0.1570887565612793\n",
      "[Step 18533] Loss: 9.49e+07 -0.9067795276641846 0.15709947049617767\n",
      "[Step 18534] Loss: 9.41e+07 -0.9067273139953613 0.15708132088184357\n",
      "[Step 18535] Loss: 9.44e+07 -0.9067418575286865 0.157070592045784\n",
      "[Step 18536] Loss: 9.45e+07 -0.9068041443824768 0.1570582240819931\n",
      "[Step 18537] Loss: 9.40e+07 -0.9068540930747986 0.15705491602420807\n",
      "[Step 18538] Loss: 9.46e+07 -0.906812310218811 0.1570483148097992\n",
      "[Step 18539] Loss: 9.54e+07 -0.9067565202713013 0.15704749524593353\n",
      "[Step 18540] Loss: 9.49e+07 -0.9067039489746094 0.15703758597373962\n",
      "[Step 18541] Loss: 9.42e+07 -0.9066905379295349 0.15703347325325012\n",
      "[Step 18542] Loss: 9.43e+07 -0.9067091941833496 0.15704254806041718\n",
      "[Step 18543] Loss: 9.45e+07 -0.9067710638046265 0.1570095419883728\n",
      "[Step 18544] Loss: 9.53e+07 -0.9067142605781555 0.15701201558113098\n",
      "[Step 18545] Loss: 9.42e+07 -0.9065849781036377 0.15701530873775482\n",
      "[Step 18546] Loss: 9.54e+07 -0.9063577651977539 0.15703511238098145\n",
      "[Step 18547] Loss: 9.48e+07 -0.9062541127204895 0.1570235639810562\n",
      "[Step 18548] Loss: 9.61e+07 -0.9064618349075317 0.15698066353797913\n",
      "[Step 18549] Loss: 9.46e+07 -0.9067943692207336 0.15687833726406097\n",
      "[Step 18550] Loss: 9.43e+07 -0.9070097208023071 0.1568313091993332\n",
      "[Step 18551] Loss: 9.47e+07 -0.9073489904403687 0.15675291419029236\n",
      "[Step 18552] Loss: 9.48e+07 -0.9075282216072083 0.15670259296894073\n",
      "[Step 18553] Loss: 9.47e+07 -0.9077388644218445 0.15664978325366974\n",
      "[Step 18554] Loss: 9.62e+07 -0.9078402519226074 0.15663161873817444\n",
      "[Step 18555] Loss: 9.45e+07 -0.9080020785331726 0.15656891465187073\n",
      "[Step 18556] Loss: 9.46e+07 -0.9081452488899231 0.15654169023036957\n",
      "[Step 18557] Loss: 9.43e+07 -0.9083442091941833 0.15646742284297943\n",
      "[Step 18558] Loss: 9.49e+07 -0.9085257053375244 0.1564170867204666\n",
      "[Step 18559] Loss: 9.46e+07 -0.908778190612793 0.1563750058412552\n",
      "[Step 18560] Loss: 9.43e+07 -0.9090054035186768 0.1563221961259842\n",
      "[Step 18561] Loss: 9.47e+07 -0.909088671207428 0.1562710404396057\n",
      "[Step 18562] Loss: 9.56e+07 -0.9091517925262451 0.15625452995300293\n",
      "[Step 18563] Loss: 9.38e+07 -0.9092242121696472 0.1562347263097763\n",
      "[Step 18564] Loss: 9.44e+07 -0.9092959761619568 0.15622317790985107\n",
      "[Step 18565] Loss: 9.50e+07 -0.9092879295349121 0.1562025547027588\n",
      "[Step 18566] Loss: 9.50e+07 -0.9092301726341248 0.15623638033866882\n",
      "[Step 18567] Loss: 9.47e+07 -0.9091325998306274 0.1562776416540146\n",
      "[Step 18568] Loss: 9.41e+07 -0.9090765118598938 0.1562487632036209\n",
      "[Step 18569] Loss: 9.65e+07 -0.9092831015586853 0.15620584785938263\n",
      "[Step 18570] Loss: 9.50e+07 -0.9094452261924744 0.156180277466774\n",
      "[Step 18571] Loss: 9.60e+07 -0.9097379446029663 0.1561249941587448\n",
      "[Step 18572] Loss: 9.60e+07 -0.9102533459663391 0.1560399979352951\n",
      "[Step 18573] Loss: 9.40e+07 -0.9107259511947632 0.15595170855522156\n",
      "[Step 18574] Loss: 9.45e+07 -0.9110528826713562 0.15589313209056854\n",
      "[Step 18575] Loss: 9.39e+07 -0.9113895893096924 0.15585269033908844\n",
      "[Step 18576] Loss: 9.36e+07 -0.9116635918617249 0.15580813586711884\n",
      "[Step 18577] Loss: 9.61e+07 -0.9121789932250977 0.15571902692317963\n",
      "[Step 18578] Loss: 9.55e+07 -0.9129236936569214 0.1555671989917755\n",
      "[Step 18579] Loss: 9.40e+07 -0.913591206073761 0.15545745193958282\n",
      "[Step 18580] Loss: 9.62e+07 -0.9144927859306335 0.15531058609485626\n",
      "[Step 18581] Loss: 9.52e+07 -0.9152635931968689 0.15517525374889374\n",
      "[Step 18582] Loss: 9.46e+07 -0.9160831570625305 0.15505479276180267\n",
      "[Step 18583] Loss: 9.45e+07 -0.9167554378509521 0.15494009852409363\n",
      "[Step 18584] Loss: 9.43e+07 -0.9172987937927246 0.15483364462852478\n",
      "[Step 18585] Loss: 9.44e+07 -0.9178575277328491 0.15473133325576782\n",
      "[Step 18586] Loss: 9.41e+07 -0.9182854294776917 0.15467604994773865\n",
      "[Step 18587] Loss: 9.45e+07 -0.9185988903045654 0.15463809669017792\n",
      "[Step 18588] Loss: 9.49e+07 -0.9190018773078918 0.15457703173160553\n",
      "[Step 18589] Loss: 9.49e+07 -0.9194769263267517 0.1544862687587738\n",
      "[Step 18590] Loss: 9.43e+07 -0.9200193881988525 0.15440870821475983\n",
      "[Step 18591] Loss: 9.53e+07 -0.9204373955726624 0.15434351563453674\n",
      "[Step 18592] Loss: 9.46e+07 -0.9206993579864502 0.1543138176202774\n",
      "[Step 18593] Loss: 9.51e+07 -0.9210147857666016 0.1542832851409912\n",
      "[Step 18594] Loss: 9.54e+07 -0.9214669466018677 0.1541982889175415\n",
      "[Step 18595] Loss: 9.49e+07 -0.9219608306884766 0.1541454941034317\n",
      "[Step 18596] Loss: 9.46e+07 -0.9224758148193359 0.1540786474943161\n",
      "[Step 18597] Loss: 9.39e+07 -0.922917366027832 0.15402089059352875\n",
      "[Step 18598] Loss: 9.50e+07 -0.9232106804847717 0.1539730280637741\n",
      "[Step 18599] Loss: 9.51e+07 -0.9235137104988098 0.153926819562912\n",
      "[Step 18600] Loss: 9.46e+07 -0.9237304925918579 0.1538921743631363\n",
      "[Step 18601] Loss: 9.47e+07 -0.9239246249198914 0.1538517326116562\n",
      "[Step 18602] Loss: 9.44e+07 -0.92408686876297 0.15381872653961182\n",
      "[Step 18603] Loss: 9.49e+07 -0.9242413640022278 0.15380141139030457\n",
      "[Step 18604] Loss: 9.53e+07 -0.9244968891143799 0.1537502408027649\n",
      "[Step 18605] Loss: 9.46e+07 -0.9247292280197144 0.15369001030921936\n",
      "[Step 18606] Loss: 9.51e+07 -0.9249686598777771 0.1536182314157486\n",
      "[Step 18607] Loss: 9.47e+07 -0.9251821637153625 0.15355882048606873\n",
      "[Step 18608] Loss: 9.51e+07 -0.9255590438842773 0.15347382426261902\n",
      "[Step 18609] Loss: 9.46e+07 -0.9259046316146851 0.15339460968971252\n",
      "[Step 18610] Loss: 9.35e+07 -0.9262601733207703 0.153309628367424\n",
      "[Step 18611] Loss: 9.40e+07 -0.9265380501747131 0.15325598418712616\n",
      "[Step 18612] Loss: 9.42e+07 -0.9268210530281067 0.15320730209350586\n",
      "[Step 18613] Loss: 9.40e+07 -0.9269928932189941 0.1531536728143692\n",
      "[Step 18614] Loss: 9.43e+07 -0.9272201061248779 0.15313304960727692\n",
      "[Step 18615] Loss: 9.59e+07 -0.9272664189338684 0.15310664474964142\n",
      "[Step 18616] Loss: 9.43e+07 -0.9273009896278381 0.15306703746318817\n",
      "[Step 18617] Loss: 9.45e+07 -0.9271880388259888 0.15305547416210175\n",
      "[Step 18618] Loss: 9.37e+07 -0.9271345138549805 0.15305712819099426\n",
      "[Step 18619] Loss: 9.48e+07 -0.9271309971809387 0.15301835536956787\n",
      "[Step 18620] Loss: 9.44e+07 -0.9271883368492126 0.15300019085407257\n",
      "[Step 18621] Loss: 9.48e+07 -0.9272279739379883 0.15294574201107025\n",
      "[Step 18622] Loss: 9.42e+07 -0.9273126721382141 0.1529226303100586\n",
      "[Step 18623] Loss: 9.40e+07 -0.9273838996887207 0.15292015671730042\n",
      "[Step 18624] Loss: 9.43e+07 -0.9274289608001709 0.15291108191013336\n",
      "[Step 18625] Loss: 9.45e+07 -0.9275965094566345 0.15288302302360535\n",
      "[Step 18626] Loss: 9.53e+07 -0.9277755618095398 0.1528656929731369\n",
      "[Step 18627] Loss: 9.49e+07 -0.9281089305877686 0.15281371772289276\n",
      "[Step 18628] Loss: 9.57e+07 -0.9284638166427612 0.15278978645801544\n",
      "[Step 18629] Loss: 9.49e+07 -0.9287881851196289 0.15273532271385193\n",
      "[Step 18630] Loss: 9.45e+07 -0.9291056394577026 0.1526767462491989\n",
      "[Step 18631] Loss: 9.47e+07 -0.9293828010559082 0.1526404321193695\n",
      "[Step 18632] Loss: 9.48e+07 -0.9297584295272827 0.15258432924747467\n",
      "[Step 18633] Loss: 9.46e+07 -0.9301308989524841 0.15248943865299225\n",
      "[Step 18634] Loss: 9.42e+07 -0.9303892850875854 0.15243828296661377\n",
      "[Step 18635] Loss: 9.38e+07 -0.9306139945983887 0.15238134562969208\n",
      "[Step 18636] Loss: 9.49e+07 -0.9309023022651672 0.15231451392173767\n",
      "[Step 18637] Loss: 9.49e+07 -0.9313215613365173 0.15224850177764893\n",
      "[Step 18638] Loss: 9.37e+07 -0.9317529201507568 0.15218496322631836\n",
      "[Step 18639] Loss: 9.40e+07 -0.9320713877677917 0.15212802588939667\n",
      "[Step 18640] Loss: 9.48e+07 -0.9322662353515625 0.15208181738853455\n",
      "[Step 18641] Loss: 9.46e+07 -0.9323930144309998 0.15204139053821564\n",
      "[Step 18642] Loss: 9.44e+07 -0.9324763417243958 0.152021586894989\n",
      "[Step 18643] Loss: 9.53e+07 -0.9326847195625305 0.1519795060157776\n",
      "[Step 18644] Loss: 9.39e+07 -0.9329361319541931 0.1519002914428711\n",
      "[Step 18645] Loss: 9.48e+07 -0.9330886006355286 0.15184417366981506\n",
      "[Step 18646] Loss: 9.39e+07 -0.9331985712051392 0.15179136395454407\n",
      "[Step 18647] Loss: 9.47e+07 -0.9333731532096863 0.1517195850610733\n",
      "[Step 18648] Loss: 9.46e+07 -0.9335286021232605 0.15167750418186188\n",
      "[Step 18649] Loss: 9.56e+07 -0.9335020780563354 0.15169070661067963\n",
      "[Step 18650] Loss: 9.52e+07 -0.9336294531822205 0.15166595578193665\n",
      "[Step 18651] Loss: 9.60e+07 -0.9339179396629333 0.15160323679447174\n",
      "[Step 18652] Loss: 9.56e+07 -0.9343817830085754 0.15152567625045776\n",
      "[Step 18653] Loss: 9.51e+07 -0.9348778128623962 0.15145719051361084\n",
      "[Step 18654] Loss: 9.45e+07 -0.9352556467056274 0.151401087641716\n",
      "[Step 18655] Loss: 9.46e+07 -0.9356900453567505 0.15133342146873474\n",
      "[Step 18656] Loss: 9.46e+07 -0.9360585808753967 0.1512731909751892\n",
      "[Step 18657] Loss: 9.45e+07 -0.9364450573921204 0.15120965242385864\n",
      "[Step 18658] Loss: 9.42e+07 -0.9368466138839722 0.1511213630437851\n",
      "[Step 18659] Loss: 9.43e+07 -0.9372566938400269 0.15103554725646973\n",
      "[Step 18660] Loss: 9.44e+07 -0.9376503825187683 0.15095798671245575\n",
      "[Step 18661] Loss: 9.48e+07 -0.9379915595054626 0.15089114010334015\n",
      "[Step 18662] Loss: 9.46e+07 -0.9381700158119202 0.15084411203861237\n",
      "[Step 18663] Loss: 9.51e+07 -0.9383524656295776 0.150786355137825\n",
      "[Step 18664] Loss: 9.53e+07 -0.9385142922401428 0.15072529017925262\n",
      "[Step 18665] Loss: 9.46e+07 -0.9386886954307556 0.1507013589143753\n",
      "[Step 18666] Loss: 9.46e+07 -0.9388518929481506 0.1506568044424057\n",
      "[Step 18667] Loss: 9.46e+07 -0.938973605632782 0.15061719715595245\n",
      "[Step 18668] Loss: 9.46e+07 -0.9391013979911804 0.1506081223487854\n",
      "[Step 18669] Loss: 9.47e+07 -0.939056396484375 0.15061472356319427\n",
      "[Step 18670] Loss: 9.34e+07 -0.9390257596969604 0.1506081223487854\n",
      "[Step 18671] Loss: 9.42e+07 -0.9388845562934875 0.15062545239925385\n",
      "[Step 18672] Loss: 9.41e+07 -0.9387921690940857 0.1506485491991043\n",
      "[Step 18673] Loss: 9.52e+07 -0.9388204216957092 0.1506427824497223\n",
      "[Step 18674] Loss: 9.43e+07 -0.938913881778717 0.1506485491991043\n",
      "[Step 18675] Loss: 9.44e+07 -0.9389510750770569 0.15064525604248047\n",
      "[Step 18676] Loss: 9.56e+07 -0.9388651847839355 0.15064772963523865\n",
      "[Step 18677] Loss: 9.47e+07 -0.9387542009353638 0.15066753327846527\n",
      "[Step 18678] Loss: 9.45e+07 -0.9385576248168945 0.150705486536026\n",
      "[Step 18679] Loss: 9.52e+07 -0.9382633566856384 0.15075169503688812\n",
      "[Step 18680] Loss: 9.44e+07 -0.937906801700592 0.1508152335882187\n",
      "[Step 18681] Loss: 9.46e+07 -0.9376330375671387 0.150863915681839\n",
      "[Step 18682] Loss: 9.50e+07 -0.9373974800109863 0.15087464451789856\n",
      "[Step 18683] Loss: 9.45e+07 -0.9372222423553467 0.15092498064041138\n",
      "[Step 18684] Loss: 9.43e+07 -0.9370735883712769 0.15093158185482025\n",
      "[Step 18685] Loss: 9.48e+07 -0.9368538856506348 0.15093982219696045\n",
      "[Step 18686] Loss: 9.42e+07 -0.9366026520729065 0.1509406566619873\n",
      "[Step 18687] Loss: 9.52e+07 -0.9362331032752991 0.15100254118442535\n",
      "[Step 18688] Loss: 9.46e+07 -0.9358730316162109 0.1510421484708786\n",
      "[Step 18689] Loss: 9.43e+07 -0.9355423450469971 0.15105700492858887\n",
      "[Step 18690] Loss: 9.60e+07 -0.9350612759590149 0.1511048525571823\n",
      "[Step 18691] Loss: 9.40e+07 -0.9346325397491455 0.15114282071590424\n",
      "[Step 18692] Loss: 9.45e+07 -0.9341573715209961 0.1511981040239334\n",
      "[Step 18693] Loss: 9.43e+07 -0.9338089227676392 0.15123358368873596\n",
      "[Step 18694] Loss: 9.43e+07 -0.9335300326347351 0.15127401053905487\n",
      "[Step 18695] Loss: 9.43e+07 -0.9333405494689941 0.1512979418039322\n",
      "[Step 18696] Loss: 9.48e+07 -0.9331727623939514 0.15132682025432587\n",
      "[Step 18697] Loss: 9.48e+07 -0.9330065250396729 0.15132847428321838\n",
      "[Step 18698] Loss: 9.49e+07 -0.9326724410057068 0.15135487914085388\n",
      "[Step 18699] Loss: 9.47e+07 -0.9323292970657349 0.15139035880565643\n",
      "[Step 18700] Loss: 9.39e+07 -0.9319943785667419 0.1514274924993515\n",
      "[Step 18701] Loss: 9.45e+07 -0.9316099286079407 0.15146873891353607\n",
      "[Step 18702] Loss: 9.44e+07 -0.9312430024147034 0.15153475105762482\n",
      "[Step 18703] Loss: 9.47e+07 -0.9309468269348145 0.15156033635139465\n",
      "[Step 18704] Loss: 9.38e+07 -0.9307155013084412 0.1515859067440033\n",
      "[Step 18705] Loss: 9.41e+07 -0.9304819703102112 0.15160076320171356\n",
      "[Step 18706] Loss: 9.44e+07 -0.930292010307312 0.1516123116016388\n",
      "[Step 18707] Loss: 9.47e+07 -0.9301318526268005 0.1516040712594986\n",
      "[Step 18708] Loss: 9.47e+07 -0.9298795461654663 0.15163955092430115\n",
      "[Step 18709] Loss: 9.46e+07 -0.9296390414237976 0.15165191888809204\n",
      "[Step 18710] Loss: 9.44e+07 -0.9294771552085876 0.15163955092430115\n",
      "[Step 18711] Loss: 9.49e+07 -0.9292249083518982 0.15168245136737823\n",
      "[Step 18712] Loss: 9.48e+07 -0.9290946125984192 0.1516651213169098\n",
      "[Step 18713] Loss: 9.37e+07 -0.9289591908454895 0.15165935456752777\n",
      "[Step 18714] Loss: 9.52e+07 -0.9286574125289917 0.15168410539627075\n",
      "[Step 18715] Loss: 9.45e+07 -0.9285429120063782 0.15168079733848572\n",
      "[Step 18716] Loss: 9.44e+07 -0.9284255504608154 0.15165770053863525\n",
      "[Step 18717] Loss: 9.49e+07 -0.928404688835144 0.15162716805934906\n",
      "[Step 18718] Loss: 9.47e+07 -0.9283106327056885 0.151642844080925\n",
      "[Step 18719] Loss: 9.48e+07 -0.9281651377677917 0.15165439248085022\n",
      "[Step 18720] Loss: 9.41e+07 -0.9280028939247131 0.1516667753458023\n",
      "[Step 18721] Loss: 9.43e+07 -0.9278823733329773 0.15165770053863525\n",
      "[Step 18722] Loss: 9.51e+07 -0.9280290603637695 0.15162798762321472\n",
      "[Step 18723] Loss: 9.44e+07 -0.9281173348426819 0.15162304043769836\n",
      "[Step 18724] Loss: 9.46e+07 -0.928176999092102 0.15160241723060608\n",
      "[Step 18725] Loss: 9.50e+07 -0.9283838868141174 0.15154960751533508\n",
      "[Step 18726] Loss: 9.39e+07 -0.9286093711853027 0.1514926701784134\n",
      "[Step 18727] Loss: 9.41e+07 -0.928809642791748 0.15143409371376038\n",
      "[Step 18728] Loss: 9.46e+07 -0.9288293719291687 0.15144069492816925\n",
      "[Step 18729] Loss: 9.45e+07 -0.9289107322692871 0.15141098201274872\n",
      "[Step 18730] Loss: 9.38e+07 -0.9289819002151489 0.15136972069740295\n",
      "[Step 18731] Loss: 9.41e+07 -0.9291010499000549 0.15132516622543335\n",
      "[Step 18732] Loss: 9.52e+07 -0.9292246699333191 0.1512773036956787\n",
      "[Step 18733] Loss: 9.48e+07 -0.929506242275238 0.15121541917324066\n",
      "[Step 18734] Loss: 9.42e+07 -0.929709255695343 0.15115436911582947\n",
      "[Step 18735] Loss: 9.50e+07 -0.9300110340118408 0.15110403299331665\n",
      "[Step 18736] Loss: 9.40e+07 -0.9303553104400635 0.15105204284191132\n",
      "[Step 18737] Loss: 9.40e+07 -0.9306677579879761 0.1509876847267151\n",
      "[Step 18738] Loss: 9.46e+07 -0.930901288986206 0.1509365290403366\n",
      "[Step 18739] Loss: 9.46e+07 -0.9311622977256775 0.15088124573230743\n",
      "[Step 18740] Loss: 9.48e+07 -0.9315808415412903 0.15080450475215912\n",
      "[Step 18741] Loss: 9.45e+07 -0.9319581389427185 0.1507541686296463\n",
      "[Step 18742] Loss: 9.48e+07 -0.9322889447212219 0.15070053935050964\n",
      "[Step 18743] Loss: 9.46e+07 -0.93264240026474 0.15063947439193726\n",
      "[Step 18744] Loss: 9.47e+07 -0.9331011772155762 0.15054954588413239\n",
      "[Step 18745] Loss: 9.44e+07 -0.9333622455596924 0.15047527849674225\n",
      "[Step 18746] Loss: 9.46e+07 -0.9336353540420532 0.15041916072368622\n",
      "[Step 18747] Loss: 9.45e+07 -0.9341000914573669 0.15035316348075867\n",
      "[Step 18748] Loss: 9.44e+07 -0.934492290019989 0.150277242064476\n",
      "[Step 18749] Loss: 9.49e+07 -0.9347811937332153 0.15019308030605316\n",
      "[Step 18750] Loss: 9.41e+07 -0.9350290894508362 0.1501113921403885\n",
      "[Step 18751] Loss: 9.43e+07 -0.9352903962135315 0.15007343888282776\n",
      "[Step 18752] Loss: 9.43e+07 -0.935540497303009 0.1500503271818161\n",
      "[Step 18753] Loss: 9.46e+07 -0.9358535408973694 0.1499628722667694\n",
      "[Step 18754] Loss: 9.38e+07 -0.9361187219619751 0.14989107847213745\n",
      "[Step 18755] Loss: 9.49e+07 -0.9362872242927551 0.14985725283622742\n",
      "[Step 18756] Loss: 9.51e+07 -0.9365964531898499 0.14978629350662231\n",
      "[Step 18757] Loss: 9.35e+07 -0.9368637204170227 0.14971531927585602\n",
      "[Step 18758] Loss: 9.55e+07 -0.9372770190238953 0.149628683924675\n",
      "[Step 18759] Loss: 9.44e+07 -0.9377480745315552 0.14953626692295074\n",
      "[Step 18760] Loss: 9.47e+07 -0.9382867813110352 0.14945128560066223\n",
      "[Step 18761] Loss: 9.48e+07 -0.9386541247367859 0.14939764142036438\n",
      "[Step 18762] Loss: 9.49e+07 -0.939113974571228 0.14930440485477448\n",
      "[Step 18763] Loss: 9.53e+07 -0.9393715858459473 0.14925406873226166\n",
      "[Step 18764] Loss: 9.44e+07 -0.9395979046821594 0.14920951426029205\n",
      "[Step 18765] Loss: 9.51e+07 -0.9396286606788635 0.1492062211036682\n",
      "[Step 18766] Loss: 9.45e+07 -0.9395471811294556 0.14919714629650116\n",
      "[Step 18767] Loss: 9.43e+07 -0.9394264817237854 0.14919054508209229\n",
      "[Step 18768] Loss: 9.41e+07 -0.9391889572143555 0.14921611547470093\n",
      "[Step 18769] Loss: 9.46e+07 -0.9389206767082214 0.1492408663034439\n",
      "[Step 18770] Loss: 9.41e+07 -0.9386837482452393 0.14927305281162262\n",
      "[Step 18771] Loss: 9.47e+07 -0.9386036992073059 0.14929038286209106\n",
      "[Step 18772] Loss: 9.41e+07 -0.9386333227157593 0.14929120242595673\n",
      "[Step 18773] Loss: 9.50e+07 -0.9388444423675537 0.14924004673957825\n",
      "[Step 18774] Loss: 9.48e+07 -0.9389300346374512 0.1492185890674591\n",
      "[Step 18775] Loss: 9.54e+07 -0.9392043352127075 0.14918558299541473\n",
      "[Step 18776] Loss: 9.42e+07 -0.9395150542259216 0.14915010333061218\n",
      "[Step 18777] Loss: 9.40e+07 -0.9397947788238525 0.14907585084438324\n",
      "[Step 18778] Loss: 9.51e+07 -0.9399949908256531 0.14902880787849426\n",
      "[Step 18779] Loss: 9.49e+07 -0.940366804599762 0.14898012578487396\n",
      "[Step 18780] Loss: 9.42e+07 -0.9407142996788025 0.14891576766967773\n",
      "[Step 18781] Loss: 9.46e+07 -0.9411000609397888 0.1488472819328308\n",
      "[Step 18782] Loss: 9.48e+07 -0.9413251280784607 0.14881345629692078\n",
      "[Step 18783] Loss: 9.54e+07 -0.9414833188056946 0.14879117906093597\n",
      "[Step 18784] Loss: 9.51e+07 -0.9417300820350647 0.14875899255275726\n",
      "[Step 18785] Loss: 9.50e+07 -0.9418528079986572 0.14876312017440796\n",
      "[Step 18786] Loss: 9.38e+07 -0.9419316053390503 0.14873753488063812\n",
      "[Step 18787] Loss: 9.43e+07 -0.9420235753059387 0.1487301141023636\n",
      "[Step 18788] Loss: 9.51e+07 -0.9420013427734375 0.14873671531677246\n",
      "[Step 18789] Loss: 9.45e+07 -0.9419326186180115 0.1487482637166977\n",
      "[Step 18790] Loss: 9.38e+07 -0.9418942332267761 0.14873836934566498\n",
      "[Step 18791] Loss: 9.43e+07 -0.9418467879295349 0.14874249696731567\n",
      "[Step 18792] Loss: 9.42e+07 -0.941686749458313 0.1487523913383484\n",
      "[Step 18793] Loss: 9.57e+07 -0.9417798519134521 0.1487301141023636\n",
      "[Step 18794] Loss: 9.45e+07 -0.9419260025024414 0.1486871987581253\n",
      "[Step 18795] Loss: 9.39e+07 -0.9420740604400635 0.14863274991512299\n",
      "[Step 18796] Loss: 9.40e+07 -0.9422065615653992 0.14860303699970245\n",
      "[Step 18797] Loss: 9.46e+07 -0.9423079490661621 0.14856261014938354\n",
      "[Step 18798] Loss: 9.46e+07 -0.9423322081565857 0.14854611456394196\n",
      "[Step 18799] Loss: 9.44e+07 -0.9422042965888977 0.1485411524772644\n",
      "[Step 18800] Loss: 9.50e+07 -0.9421857595443726 0.14855848252773285\n",
      "[Step 18801] Loss: 9.44e+07 -0.94222092628479 0.1485147476196289\n",
      "[Step 18802] Loss: 9.48e+07 -0.9423292875289917 0.1485007256269455\n",
      "[Step 18803] Loss: 9.41e+07 -0.942356526851654 0.14849494397640228\n",
      "[Step 18804] Loss: 9.48e+07 -0.9423343539237976 0.14849577844142914\n",
      "[Step 18805] Loss: 9.48e+07 -0.9421867728233337 0.14851970970630646\n",
      "[Step 18806] Loss: 9.44e+07 -0.9420254826545715 0.14852052927017212\n",
      "[Step 18807] Loss: 9.41e+07 -0.9419156908988953 0.148527130484581\n",
      "[Step 18808] Loss: 9.39e+07 -0.9419031143188477 0.14852631092071533\n",
      "[Step 18809] Loss: 9.44e+07 -0.9418414235115051 0.14853867888450623\n",
      "[Step 18810] Loss: 9.51e+07 -0.9418498873710632 0.14851805567741394\n",
      "[Step 18811] Loss: 9.48e+07 -0.9418659806251526 0.14851227402687073\n",
      "[Step 18812] Loss: 9.53e+07 -0.9418215155601501 0.14851558208465576\n",
      "[Step 18813] Loss: 9.44e+07 -0.9417430758476257 0.14853785932064056\n",
      "[Step 18814] Loss: 9.50e+07 -0.941796600818634 0.14853538572788239\n",
      "[Step 18815] Loss: 9.45e+07 -0.9417247176170349 0.14855435490608215\n",
      "[Step 18816] Loss: 9.44e+07 -0.9416875839233398 0.1485510617494583\n",
      "[Step 18817] Loss: 9.41e+07 -0.9416842460632324 0.14856261014938354\n",
      "[Step 18818] Loss: 9.43e+07 -0.941741406917572 0.14853951334953308\n",
      "[Step 18819] Loss: 9.44e+07 -0.9418008327484131 0.14852631092071533\n",
      "[Step 18820] Loss: 9.52e+07 -0.9420071244239807 0.14849412441253662\n",
      "[Step 18821] Loss: 9.48e+07 -0.9423022866249084 0.14845451712608337\n",
      "[Step 18822] Loss: 9.54e+07 -0.9427341222763062 0.1483852118253708\n",
      "[Step 18823] Loss: 9.49e+07 -0.943091630935669 0.148310124874115\n",
      "[Step 18824] Loss: 9.42e+07 -0.9434192180633545 0.14823667705059052\n",
      "[Step 18825] Loss: 9.48e+07 -0.9436317086219788 0.14820203185081482\n",
      "[Step 18826] Loss: 9.50e+07 -0.94398033618927 0.1481376588344574\n",
      "[Step 18827] Loss: 9.38e+07 -0.9442467093467712 0.14806504547595978\n",
      "[Step 18828] Loss: 9.45e+07 -0.9444148540496826 0.1480485498905182\n",
      "[Step 18829] Loss: 9.40e+07 -0.9446064829826355 0.14800234138965607\n",
      "[Step 18830] Loss: 9.50e+07 -0.9449557065963745 0.1479569524526596\n",
      "[Step 18831] Loss: 9.50e+07 -0.9452447295188904 0.14789919555187225\n",
      "[Step 18832] Loss: 9.45e+07 -0.9453245401382446 0.14788846671581268\n",
      "[Step 18833] Loss: 9.49e+07 -0.9452886581420898 0.14789342880249023\n",
      "[Step 18834] Loss: 9.51e+07 -0.9453812837600708 0.1478373110294342\n",
      "[Step 18835] Loss: 9.41e+07 -0.9454641938209534 0.14778202772140503\n",
      "[Step 18836] Loss: 9.40e+07 -0.9456080198287964 0.14774242043495178\n",
      "[Step 18837] Loss: 9.46e+07 -0.9457026720046997 0.14771932363510132\n",
      "[Step 18838] Loss: 9.46e+07 -0.9457878470420837 0.14772674441337585\n",
      "[Step 18839] Loss: 9.43e+07 -0.9458733797073364 0.14771932363510132\n",
      "[Step 18840] Loss: 9.48e+07 -0.94601970911026 0.147695392370224\n",
      "[Step 18841] Loss: 9.47e+07 -0.9461104869842529 0.14767064154148102\n",
      "[Step 18842] Loss: 9.48e+07 -0.9461536407470703 0.1476648598909378\n",
      "[Step 18843] Loss: 9.47e+07 -0.9462255835533142 0.1476648598909378\n",
      "[Step 18844] Loss: 9.60e+07 -0.9465084075927734 0.1476285606622696\n",
      "[Step 18845] Loss: 9.51e+07 -0.9468972682952881 0.14758647978305817\n",
      "[Step 18846] Loss: 9.40e+07 -0.9472190737724304 0.1475353091955185\n",
      "[Step 18847] Loss: 9.47e+07 -0.9475006461143494 0.14752210676670074\n",
      "[Step 18848] Loss: 9.49e+07 -0.9478356838226318 0.14747755229473114\n",
      "[Step 18849] Loss: 9.52e+07 -0.9481751918792725 0.1474156677722931\n",
      "[Step 18850] Loss: 9.45e+07 -0.9484198689460754 0.14734718203544617\n",
      "[Step 18851] Loss: 9.43e+07 -0.9485609531402588 0.14731664955615997\n",
      "[Step 18852] Loss: 9.50e+07 -0.9485732316970825 0.1473281979560852\n",
      "[Step 18853] Loss: 9.46e+07 -0.9485751986503601 0.14731252193450928\n",
      "[Step 18854] Loss: 9.47e+07 -0.9485803246498108 0.147319957613945\n",
      "[Step 18855] Loss: 9.45e+07 -0.9486187100410461 0.14730015397071838\n",
      "[Step 18856] Loss: 9.46e+07 -0.948617696762085 0.14728529751300812\n",
      "[Step 18857] Loss: 9.49e+07 -0.9485127925872803 0.14730922877788544\n",
      "[Step 18858] Loss: 9.41e+07 -0.9483545422554016 0.14732903242111206\n",
      "[Step 18859] Loss: 9.47e+07 -0.948197066783905 0.14736203849315643\n",
      "[Step 18860] Loss: 9.41e+07 -0.9480929970741272 0.14737771451473236\n",
      "[Step 18861] Loss: 9.49e+07 -0.9479135274887085 0.1474032998085022\n",
      "[Step 18862] Loss: 9.49e+07 -0.9477185010910034 0.1474338173866272\n",
      "[Step 18863] Loss: 9.51e+07 -0.9477498531341553 0.14741814136505127\n",
      "[Step 18864] Loss: 9.43e+07 -0.9478108882904053 0.147425577044487\n",
      "[Step 18865] Loss: 9.50e+07 -0.9478952884674072 0.14742226898670197\n",
      "[Step 18866] Loss: 9.39e+07 -0.948003888130188 0.14740824699401855\n",
      "[Step 18867] Loss: 9.50e+07 -0.9482189416885376 0.14733316004276276\n",
      "[Step 18868] Loss: 9.45e+07 -0.9483770728111267 0.14727044105529785\n",
      "[Step 18869] Loss: 9.43e+07 -0.9485609531402588 0.14723414182662964\n",
      "[Step 18870] Loss: 9.45e+07 -0.9487532377243042 0.1471961885690689\n",
      "[Step 18871] Loss: 9.52e+07 -0.9490164518356323 0.147133469581604\n",
      "[Step 18872] Loss: 9.42e+07 -0.9493258595466614 0.1470542550086975\n",
      "[Step 18873] Loss: 9.48e+07 -0.9495341777801514 0.14701712131500244\n",
      "[Step 18874] Loss: 9.43e+07 -0.949828565120697 0.14696761965751648\n",
      "[Step 18875] Loss: 9.45e+07 -0.9500486850738525 0.1469123363494873\n",
      "[Step 18876] Loss: 9.47e+07 -0.9503178596496582 0.14684467017650604\n",
      "[Step 18877] Loss: 9.58e+07 -0.9508230686187744 0.1467646360397339\n",
      "[Step 18878] Loss: 9.42e+07 -0.9513282775878906 0.14667634665966034\n",
      "[Step 18879] Loss: 9.42e+07 -0.9517653584480286 0.1466020792722702\n",
      "[Step 18880] Loss: 9.48e+07 -0.9522372484207153 0.1464948207139969\n",
      "[Step 18881] Loss: 9.65e+07 -0.9529620409011841 0.14638012647628784\n",
      "[Step 18882] Loss: 9.48e+07 -0.9537231922149658 0.14623984694480896\n",
      "[Step 18883] Loss: 9.50e+07 -0.9543063640594482 0.14612846076488495\n",
      "[Step 18884] Loss: 9.47e+07 -0.9547388553619385 0.14607729017734528\n",
      "[Step 18885] Loss: 9.45e+07 -0.9551693797111511 0.14600469172000885\n",
      "[Step 18886] Loss: 9.39e+07 -0.9555569887161255 0.14593537151813507\n",
      "[Step 18887] Loss: 9.59e+07 -0.9558113217353821 0.14589247107505798\n",
      "[Step 18888] Loss: 9.43e+07 -0.9560866951942444 0.14584048092365265\n",
      "[Step 18889] Loss: 9.43e+07 -0.9564748406410217 0.14576292037963867\n",
      "[Step 18890] Loss: 9.46e+07 -0.9569470286369324 0.14567215740680695\n",
      "[Step 18891] Loss: 9.52e+07 -0.9575294852256775 0.145575612783432\n",
      "[Step 18892] Loss: 9.46e+07 -0.9580439329147339 0.14549805223941803\n",
      "[Step 18893] Loss: 9.46e+07 -0.9585820436477661 0.1454155445098877\n",
      "[Step 18894] Loss: 9.43e+07 -0.959151566028595 0.14533136785030365\n",
      "[Step 18895] Loss: 9.56e+07 -0.9595658183097839 0.1452554613351822\n",
      "[Step 18896] Loss: 9.82e+07 -0.9604558944702148 0.1451094150543213\n",
      "[Step 18897] Loss: 9.46e+07 -0.9611730575561523 0.1449938863515854\n",
      "[Step 18898] Loss: 9.51e+07 -0.9617944955825806 0.14488662779331207\n",
      "[Step 18899] Loss: 9.42e+07 -0.9622350931167603 0.1448189616203308\n",
      "[Step 18900] Loss: 9.44e+07 -0.9627069234848022 0.14474965631961823\n",
      "[Step 18901] Loss: 9.43e+07 -0.9631665945053101 0.14467869699001312\n",
      "[Step 18902] Loss: 9.49e+07 -0.9636322855949402 0.14461763203144073\n",
      "[Step 18903] Loss: 9.45e+07 -0.9640300273895264 0.14456894993782043\n",
      "[Step 18904] Loss: 9.44e+07 -0.9643232226371765 0.1445128321647644\n",
      "[Step 18905] Loss: 9.41e+07 -0.9645704627037048 0.1444501280784607\n",
      "[Step 18906] Loss: 9.49e+07 -0.9646808505058289 0.1444278508424759\n",
      "[Step 18907] Loss: 9.62e+07 -0.9649415612220764 0.1443626582622528\n",
      "[Step 18908] Loss: 9.41e+07 -0.9652166366577148 0.14432552456855774\n",
      "[Step 18909] Loss: 9.49e+07 -0.9654245972633362 0.14426860213279724\n",
      "[Step 18910] Loss: 9.37e+07 -0.965519368648529 0.14427602291107178\n",
      "[Step 18911] Loss: 9.47e+07 -0.9656144976615906 0.14425703883171082\n",
      "[Step 18912] Loss: 9.54e+07 -0.9658514857292175 0.14420919120311737\n",
      "[Step 18913] Loss: 9.42e+07 -0.9660897254943848 0.14417287707328796\n",
      "[Step 18914] Loss: 9.42e+07 -0.966267466545105 0.14414234459400177\n",
      "[Step 18915] Loss: 9.55e+07 -0.9665888547897339 0.14411182701587677\n",
      "[Step 18916] Loss: 9.45e+07 -0.966841459274292 0.14408211410045624\n",
      "[Step 18917] Loss: 9.47e+07 -0.967025637626648 0.14405570924282074\n",
      "[Step 18918] Loss: 9.46e+07 -0.9671896696090698 0.14402930438518524\n",
      "[Step 18919] Loss: 9.49e+07 -0.967336118221283 0.14399465918540955\n",
      "[Step 18920] Loss: 9.62e+07 -0.9672077894210815 0.14400124549865723\n",
      "[Step 18921] Loss: 9.39e+07 -0.9671294093132019 0.14403177797794342\n",
      "[Step 18922] Loss: 9.50e+07 -0.9669458270072937 0.14404085278511047\n",
      "[Step 18923] Loss: 9.44e+07 -0.9667238593101501 0.14407551288604736\n",
      "[Step 18924] Loss: 9.47e+07 -0.966581404209137 0.14407303929328918\n",
      "[Step 18925] Loss: 9.45e+07 -0.9664005041122437 0.14410439133644104\n",
      "[Step 18926] Loss: 9.45e+07 -0.9662206172943115 0.14412584900856018\n",
      "[Step 18927] Loss: 9.49e+07 -0.9661382436752319 0.14412419497966766\n",
      "[Step 18928] Loss: 9.54e+07 -0.9662496447563171 0.14408954977989197\n",
      "[Step 18929] Loss: 9.45e+07 -0.966463565826416 0.1440647840499878\n",
      "[Step 18930] Loss: 9.44e+07 -0.966718316078186 0.14401857554912567\n",
      "[Step 18931] Loss: 9.46e+07 -0.9669049978256226 0.14398227632045746\n",
      "[Step 18932] Loss: 9.45e+07 -0.9670118689537048 0.14395999908447266\n",
      "[Step 18933] Loss: 9.49e+07 -0.967232346534729 0.1439327597618103\n",
      "[Step 18934] Loss: 9.45e+07 -0.9674491882324219 0.14391955733299255\n",
      "[Step 18935] Loss: 9.42e+07 -0.9676831960678101 0.14387747645378113\n",
      "[Step 18936] Loss: 9.44e+07 -0.9679844975471497 0.14380322396755219\n",
      "[Step 18937] Loss: 9.46e+07 -0.9681968688964844 0.14373555779457092\n",
      "[Step 18938] Loss: 9.55e+07 -0.9683179259300232 0.1436753273010254\n",
      "[Step 18939] Loss: 9.43e+07 -0.9684779047966003 0.14362333714962006\n",
      "[Step 18940] Loss: 9.45e+07 -0.9686236381530762 0.1435796022415161\n",
      "[Step 18941] Loss: 9.42e+07 -0.9689077734947205 0.1435168981552124\n",
      "[Step 18942] Loss: 9.57e+07 -0.9690319895744324 0.14349956810474396\n",
      "[Step 18943] Loss: 9.39e+07 -0.9691630601882935 0.14346490800380707\n",
      "[Step 18944] Loss: 9.45e+07 -0.9692967534065247 0.1434335559606552\n",
      "[Step 18945] Loss: 9.50e+07 -0.9695369601249695 0.1433650702238083\n",
      "[Step 18946] Loss: 9.49e+07 -0.9698631167411804 0.14330731332302094\n",
      "[Step 18947] Loss: 9.42e+07 -0.9700579643249512 0.14325863122940063\n",
      "[Step 18948] Loss: 9.44e+07 -0.970298171043396 0.14318767189979553\n",
      "[Step 18949] Loss: 9.47e+07 -0.9704464673995972 0.14312991499900818\n",
      "[Step 18950] Loss: 9.54e+07 -0.9706587195396423 0.1431134045124054\n",
      "[Step 18951] Loss: 9.42e+07 -0.9707504510879517 0.14308370649814606\n",
      "[Step 18952] Loss: 9.46e+07 -0.97081059217453 0.1430911272764206\n",
      "[Step 18953] Loss: 9.42e+07 -0.9708771705627441 0.14305730164051056\n",
      "[Step 18954] Loss: 9.42e+07 -0.9709770083427429 0.14302924275398254\n",
      "[Step 18955] Loss: 9.42e+07 -0.9710294604301453 0.14300696551799774\n",
      "[Step 18956] Loss: 9.37e+07 -0.9709824919700623 0.14299292862415314\n",
      "[Step 18957] Loss: 9.44e+07 -0.9710049629211426 0.14298716187477112\n",
      "[Step 18958] Loss: 9.44e+07 -0.9710375666618347 0.1429714858531952\n",
      "[Step 18959] Loss: 9.48e+07 -0.9711071252822876 0.14295002818107605\n",
      "[Step 18960] Loss: 9.41e+07 -0.9711111187934875 0.14293929934501648\n",
      "[Step 18961] Loss: 9.52e+07 -0.9712945818901062 0.14290300011634827\n",
      "[Step 18962] Loss: 9.51e+07 -0.9715901017189026 0.1428518444299698\n",
      "[Step 18963] Loss: 9.51e+07 -0.9717621803283691 0.14282047748565674\n",
      "[Step 18964] Loss: 9.49e+07 -0.9720478653907776 0.14275199174880981\n",
      "[Step 18965] Loss: 9.49e+07 -0.9722819924354553 0.14269918203353882\n",
      "[Step 18966] Loss: 9.48e+07 -0.9725987315177917 0.14266617596149445\n",
      "[Step 18967] Loss: 9.41e+07 -0.9728732109069824 0.14263400435447693\n",
      "[Step 18968] Loss: 9.48e+07 -0.9732587337493896 0.1425572633743286\n",
      "[Step 18969] Loss: 9.47e+07 -0.9736003279685974 0.14250527322292328\n",
      "[Step 18970] Loss: 9.50e+07 -0.9739217162132263 0.14243102073669434\n",
      "[Step 18971] Loss: 9.55e+07 -0.9740428328514099 0.14237821102142334\n",
      "[Step 18972] Loss: 9.45e+07 -0.9740538597106934 0.14236830174922943\n",
      "[Step 18973] Loss: 9.48e+07 -0.9741635918617249 0.14235593378543854\n",
      "[Step 18974] Loss: 9.45e+07 -0.9742797613143921 0.14230312407016754\n",
      "[Step 18975] Loss: 9.46e+07 -0.9744352698326111 0.1422651708126068\n",
      "[Step 18976] Loss: 9.46e+07 -0.9744852185249329 0.1422329843044281\n",
      "[Step 18977] Loss: 9.41e+07 -0.9746009111404419 0.14219172298908234\n",
      "[Step 18978] Loss: 9.46e+07 -0.9747703671455383 0.14216697216033936\n",
      "[Step 18979] Loss: 9.48e+07 -0.974885106086731 0.14214056730270386\n",
      "[Step 18980] Loss: 9.57e+07 -0.9751322269439697 0.14210179448127747\n",
      "[Step 18981] Loss: 9.46e+07 -0.9752577543258667 0.14208446443080902\n",
      "[Step 18982] Loss: 9.42e+07 -0.9753609895706177 0.14205309748649597\n",
      "[Step 18983] Loss: 9.47e+07 -0.9754189252853394 0.14206713438034058\n",
      "[Step 18984] Loss: 9.49e+07 -0.9755016565322876 0.14201679825782776\n",
      "[Step 18985] Loss: 9.52e+07 -0.975856602191925 0.14193923771381378\n",
      "[Step 18986] Loss: 9.49e+07 -0.9762943983078003 0.14188890159130096\n",
      "[Step 18987] Loss: 9.45e+07 -0.9765852093696594 0.1418558955192566\n",
      "[Step 18988] Loss: 9.45e+07 -0.9768330454826355 0.141786590218544\n",
      "[Step 18989] Loss: 9.43e+07 -0.977149486541748 0.14174532890319824\n",
      "[Step 18990] Loss: 9.47e+07 -0.9775793552398682 0.1416875720024109\n",
      "[Step 18991] Loss: 9.47e+07 -0.9780098795890808 0.1416141241788864\n",
      "[Step 18992] Loss: 9.65e+07 -0.9781800508499146 0.14157947897911072\n",
      "[Step 18993] Loss: 9.42e+07 -0.9783719182014465 0.14157287776470184\n",
      "[Step 18994] Loss: 9.44e+07 -0.9785320162773132 0.14154399931430817\n",
      "[Step 18995] Loss: 9.46e+07 -0.9787198901176453 0.14153574407100677\n",
      "[Step 18996] Loss: 9.41e+07 -0.9789406657218933 0.14149944484233856\n",
      "[Step 18997] Loss: 9.51e+07 -0.979320228099823 0.14145570993423462\n",
      "[Step 18998] Loss: 9.39e+07 -0.9796257019042969 0.14140042662620544\n",
      "[Step 18999] Loss: 9.45e+07 -0.9799301624298096 0.14131708443164825\n",
      "[Step 19000] Loss: 9.43e+07 -0.9802424907684326 0.14124447107315063\n",
      "[Step 19001] Loss: 9.49e+07 -0.9804702401161194 0.14120568335056305\n",
      "[Step 19002] Loss: 9.46e+07 -0.9806150197982788 0.1411660760641098\n",
      "[Step 19003] Loss: 9.55e+07 -0.9806196093559265 0.14115123450756073\n",
      "[Step 19004] Loss: 9.43e+07 -0.9805847406387329 0.14113472402095795\n",
      "[Step 19005] Loss: 9.41e+07 -0.9804834127426147 0.1411314308643341\n",
      "[Step 19006] Loss: 9.43e+07 -0.9804884791374207 0.14111244678497314\n",
      "[Step 19007] Loss: 9.46e+07 -0.9805484414100647 0.14107449352741241\n",
      "[Step 19008] Loss: 9.43e+07 -0.980529248714447 0.14107531309127808\n",
      "[Step 19009] Loss: 9.52e+07 -0.9804126024246216 0.14106129109859467\n",
      "[Step 19010] Loss: 9.48e+07 -0.9804201126098633 0.14104561507701874\n",
      "[Step 19011] Loss: 9.45e+07 -0.9803915619850159 0.14101755619049072\n",
      "[Step 19012] Loss: 9.51e+07 -0.9802460074424744 0.14102746546268463\n",
      "[Step 19013] Loss: 9.41e+07 -0.9801700711250305 0.14100435376167297\n",
      "[Step 19014] Loss: 9.48e+07 -0.9799708127975464 0.14101095497608185\n",
      "[Step 19015] Loss: 9.48e+07 -0.979781985282898 0.14100848138332367\n",
      "[Step 19016] Loss: 9.55e+07 -0.9794442653656006 0.14104314148426056\n",
      "[Step 19017] Loss: 9.45e+07 -0.9791337251663208 0.14107778668403625\n",
      "[Step 19018] Loss: 9.40e+07 -0.9788235425949097 0.141090989112854\n",
      "[Step 19019] Loss: 9.47e+07 -0.9784936308860779 0.14113472402095795\n",
      "[Step 19020] Loss: 9.47e+07 -0.9781187176704407 0.1411842405796051\n",
      "[Step 19021] Loss: 9.48e+07 -0.9778260588645935 0.1412106454372406\n",
      "[Step 19022] Loss: 9.43e+07 -0.977644145488739 0.14124365150928497\n",
      "[Step 19023] Loss: 9.50e+07 -0.9775246977806091 0.14127252995967865\n",
      "[Step 19024] Loss: 9.43e+07 -0.977464497089386 0.14127087593078613\n",
      "[Step 19025] Loss: 9.54e+07 -0.9772866368293762 0.141277477145195\n",
      "[Step 19026] Loss: 9.45e+07 -0.9772167205810547 0.14129067957401276\n",
      "[Step 19027] Loss: 9.48e+07 -0.9772379398345947 0.1412981003522873\n",
      "[Step 19028] Loss: 9.48e+07 -0.9773916602134705 0.14126427471637726\n",
      "[Step 19029] Loss: 9.50e+07 -0.9774728417396545 0.14125685393810272\n",
      "[Step 19030] Loss: 9.46e+07 -0.9775258302688599 0.14123786985874176\n",
      "[Step 19031] Loss: 9.42e+07 -0.9775234460830688 0.14123044908046722\n",
      "[Step 19032] Loss: 9.49e+07 -0.9774337410926819 0.1412535458803177\n",
      "[Step 19033] Loss: 9.41e+07 -0.9773011803627014 0.1412634551525116\n",
      "[Step 19034] Loss: 9.48e+07 -0.9770570397377014 0.14127252995967865\n",
      "[Step 19035] Loss: 9.44e+07 -0.9768592119216919 0.1413038820028305\n",
      "[Step 19036] Loss: 9.45e+07 -0.9767720699310303 0.14129893481731415\n",
      "[Step 19037] Loss: 9.43e+07 -0.9767597913742065 0.1412939727306366\n",
      "[Step 19038] Loss: 9.44e+07 -0.9767946600914001 0.1412857323884964\n",
      "[Step 19039] Loss: 9.53e+07 -0.976952075958252 0.14125189185142517\n",
      "[Step 19040] Loss: 9.42e+07 -0.9770638942718506 0.14121806621551514\n",
      "[Step 19041] Loss: 9.41e+07 -0.9772010445594788 0.14119331538677216\n",
      "[Step 19042] Loss: 9.53e+07 -0.9774211645126343 0.14114463329315186\n",
      "[Step 19043] Loss: 9.46e+07 -0.9775686264038086 0.14109595119953156\n",
      "[Step 19044] Loss: 9.44e+07 -0.9776712656021118 0.14104148745536804\n",
      "[Step 19045] Loss: 9.53e+07 -0.9776579737663269 0.141038179397583\n",
      "[Step 19046] Loss: 9.37e+07 -0.9775862693786621 0.14104726910591125\n",
      "[Step 19047] Loss: 9.39e+07 -0.9774793386459351 0.1410786211490631\n",
      "[Step 19048] Loss: 9.38e+07 -0.977375328540802 0.14109347760677338\n",
      "[Step 19049] Loss: 9.44e+07 -0.9773359298706055 0.14109677076339722\n",
      "[Step 19050] Loss: 9.41e+07 -0.9772546887397766 0.14111244678497314\n",
      "[Step 19051] Loss: 9.45e+07 -0.9772705435752869 0.1411091536283493\n",
      "[Step 19052] Loss: 9.47e+07 -0.9773378372192383 0.1410769671201706\n",
      "[Step 19053] Loss: 9.48e+07 -0.9773281216621399 0.1410786211490631\n",
      "[Step 19054] Loss: 9.48e+07 -0.9771767854690552 0.14111079275608063\n",
      "[Step 19055] Loss: 9.44e+07 -0.9771503210067749 0.14111492037773132\n",
      "[Step 19056] Loss: 9.43e+07 -0.9771407842636108 0.14111079275608063\n",
      "[Step 19057] Loss: 9.48e+07 -0.9772598147392273 0.1410951167345047\n",
      "[Step 19058] Loss: 9.48e+07 -0.977287769317627 0.14108604192733765\n",
      "[Step 19059] Loss: 9.42e+07 -0.9773702025413513 0.14107614755630493\n",
      "[Step 19060] Loss: 9.47e+07 -0.9774736762046814 0.14104314148426056\n",
      "[Step 19061] Loss: 9.45e+07 -0.9775710105895996 0.1410200297832489\n",
      "[Step 19062] Loss: 9.41e+07 -0.977626383304596 0.14098867774009705\n",
      "[Step 19063] Loss: 9.55e+07 -0.9775286316871643 0.14100435376167297\n",
      "[Step 19064] Loss: 9.40e+07 -0.9773761630058289 0.14101260900497437\n",
      "[Step 19065] Loss: 9.60e+07 -0.9773281216621399 0.1410282850265503\n",
      "[Step 19066] Loss: 9.60e+07 -0.9770834445953369 0.14103901386260986\n",
      "[Step 19067] Loss: 9.53e+07 -0.9767484664916992 0.14106211066246033\n",
      "[Step 19068] Loss: 9.43e+07 -0.9764453172683716 0.14108769595623016\n",
      "[Step 19069] Loss: 9.51e+07 -0.9760801196098328 0.14111822843551636\n",
      "[Step 19070] Loss: 9.42e+07 -0.9756864309310913 0.1411883682012558\n",
      "[Step 19071] Loss: 9.50e+07 -0.9752021431922913 0.1412469446659088\n",
      "[Step 19072] Loss: 9.40e+07 -0.974779486656189 0.14127829670906067\n",
      "[Step 19073] Loss: 9.42e+07 -0.974409818649292 0.14131461083889008\n",
      "[Step 19074] Loss: 9.46e+07 -0.9741905331611633 0.14134925603866577\n",
      "[Step 19075] Loss: 9.40e+07 -0.9739372134208679 0.14135998487472534\n",
      "[Step 19076] Loss: 9.38e+07 -0.9736558198928833 0.14140290021896362\n",
      "[Step 19077] Loss: 9.51e+07 -0.973345160484314 0.14146560430526733\n",
      "[Step 19078] Loss: 9.47e+07 -0.9731995463371277 0.1414862424135208\n",
      "[Step 19079] Loss: 9.50e+07 -0.9730233550071716 0.1415109932422638\n",
      "[Step 19080] Loss: 9.51e+07 -0.9730134606361389 0.1415208876132965\n",
      "[Step 19081] Loss: 9.46e+07 -0.973013699054718 0.14150439202785492\n",
      "[Step 19082] Loss: 9.47e+07 -0.973064661026001 0.14145983755588531\n",
      "[Step 19083] Loss: 9.60e+07 -0.9729167222976685 0.14146313071250916\n",
      "[Step 19084] Loss: 9.48e+07 -0.9726729989051819 0.14150108397006989\n",
      "[Step 19085] Loss: 9.47e+07 -0.9725282788276672 0.1415373980998993\n",
      "[Step 19086] Loss: 9.43e+07 -0.9723743796348572 0.14154976606369019\n",
      "[Step 19087] Loss: 9.41e+07 -0.9722684025764465 0.14156709611415863\n",
      "[Step 19088] Loss: 9.44e+07 -0.9721752405166626 0.14156875014305115\n",
      "[Step 19089] Loss: 9.43e+07 -0.9721865057945251 0.14156875014305115\n",
      "[Step 19090] Loss: 9.39e+07 -0.9722006916999817 0.1415638029575348\n",
      "[Step 19091] Loss: 9.46e+07 -0.97230064868927 0.14153821766376495\n",
      "[Step 19092] Loss: 9.49e+07 -0.9723028540611267 0.14154069125652313\n",
      "[Step 19093] Loss: 9.49e+07 -0.9722175002098083 0.14157700538635254\n",
      "[Step 19094] Loss: 9.51e+07 -0.9722653031349182 0.141547292470932\n",
      "[Step 19095] Loss: 9.47e+07 -0.9723277688026428 0.14154234528541565\n",
      "[Step 19096] Loss: 9.51e+07 -0.9723325371742249 0.14152666926383972\n",
      "[Step 19097] Loss: 9.45e+07 -0.9723304510116577 0.14152748882770538\n",
      "[Step 19098] Loss: 9.44e+07 -0.9723227024078369 0.141488716006279\n",
      "[Step 19099] Loss: 9.38e+07 -0.9723554253578186 0.14149200916290283\n",
      "[Step 19100] Loss: 9.42e+07 -0.9723368883132935 0.14148706197738647\n",
      "[Step 19101] Loss: 9.43e+07 -0.9724360704421997 0.1414705514907837\n",
      "[Step 19102] Loss: 9.47e+07 -0.9726242423057556 0.14144745469093323\n",
      "[Step 19103] Loss: 9.41e+07 -0.9727733731269836 0.14140866696834564\n",
      "[Step 19104] Loss: 9.38e+07 -0.972902774810791 0.1413748413324356\n",
      "[Step 19105] Loss: 9.47e+07 -0.9731737375259399 0.14132781326770782\n",
      "[Step 19106] Loss: 9.48e+07 -0.9734089374542236 0.14126262068748474\n",
      "[Step 19107] Loss: 9.47e+07 -0.9736883044242859 0.141196608543396\n",
      "[Step 19108] Loss: 9.37e+07 -0.9739250540733337 0.1411619633436203\n",
      "[Step 19109] Loss: 9.46e+07 -0.9741589426994324 0.14112070202827454\n",
      "[Step 19110] Loss: 9.49e+07 -0.9744471311569214 0.14106129109859467\n",
      "[Step 19111] Loss: 9.40e+07 -0.9747629761695862 0.14099940657615662\n",
      "[Step 19112] Loss: 9.46e+07 -0.9750375151634216 0.14092019200325012\n",
      "[Step 19113] Loss: 9.47e+07 -0.9752737283706665 0.1409003883600235\n",
      "[Step 19114] Loss: 9.56e+07 -0.9756035804748535 0.14084923267364502\n",
      "[Step 19115] Loss: 9.53e+07 -0.9756981730461121 0.14080137014389038\n",
      "[Step 19116] Loss: 9.42e+07 -0.9757238626480103 0.14078404009342194\n",
      "[Step 19117] Loss: 9.50e+07 -0.9758449196815491 0.14072628319263458\n",
      "[Step 19118] Loss: 9.51e+07 -0.9762005805969238 0.14068007469177246\n",
      "[Step 19119] Loss: 9.50e+07 -0.9766332507133484 0.14058683812618256\n",
      "[Step 19120] Loss: 9.46e+07 -0.9769731760025024 0.14051751792430878\n",
      "[Step 19121] Loss: 9.44e+07 -0.9773640036582947 0.1404275894165039\n",
      "[Step 19122] Loss: 9.45e+07 -0.9777917265892029 0.14031371474266052\n",
      "[Step 19123] Loss: 9.42e+07 -0.9782075881958008 0.1402551382780075\n",
      "[Step 19124] Loss: 9.52e+07 -0.978537380695343 0.14016024768352509\n",
      "[Step 19125] Loss: 9.50e+07 -0.9787970781326294 0.14012475311756134\n",
      "[Step 19126] Loss: 9.46e+07 -0.9790887236595154 0.14006370306015015\n",
      "[Step 19127] Loss: 9.45e+07 -0.9792238473892212 0.1400463730096817\n",
      "[Step 19128] Loss: 9.46e+07 -0.9793513417243958 0.14002326130867004\n",
      "[Step 19129] Loss: 9.47e+07 -0.9794491529464722 0.13997870683670044\n",
      "[Step 19130] Loss: 9.48e+07 -0.9795715808868408 0.13998201489448547\n",
      "[Step 19131] Loss: 9.46e+07 -0.9796232581138611 0.13997045159339905\n",
      "[Step 19132] Loss: 9.46e+07 -0.9795923829078674 0.13997705280780792\n",
      "[Step 19133] Loss: 9.39e+07 -0.979568362236023 0.13998696208000183\n",
      "[Step 19134] Loss: 9.45e+07 -0.9794976115226746 0.14000676572322845\n",
      "[Step 19135] Loss: 9.50e+07 -0.979587972164154 0.1399795413017273\n",
      "[Step 19136] Loss: 9.46e+07 -0.9796572923660278 0.1399795413017273\n",
      "[Step 19137] Loss: 9.51e+07 -0.9796595573425293 0.13995642960071564\n",
      "[Step 19138] Loss: 9.51e+07 -0.979630172252655 0.13995395600795746\n",
      "[Step 19139] Loss: 9.41e+07 -0.9796655178070068 0.13994817435741425\n",
      "[Step 19140] Loss: 9.48e+07 -0.9796389937400818 0.13992920517921448\n",
      "[Step 19141] Loss: 9.43e+07 -0.9796098470687866 0.13993580639362335\n",
      "[Step 19142] Loss: 9.45e+07 -0.9795949459075928 0.13994240760803223\n",
      "[Step 19143] Loss: 9.59e+07 -0.9793789982795715 0.1399836540222168\n",
      "[Step 19144] Loss: 9.55e+07 -0.9790278673171997 0.14000016450881958\n",
      "[Step 19145] Loss: 9.44e+07 -0.9785858392715454 0.14005297422409058\n",
      "[Step 19146] Loss: 9.44e+07 -0.9782202839851379 0.14007194340229034\n",
      "[Step 19147] Loss: 9.51e+07 -0.9777759313583374 0.140095055103302\n",
      "[Step 19148] Loss: 9.46e+07 -0.977454662322998 0.1401272416114807\n",
      "[Step 19149] Loss: 9.57e+07 -0.977347195148468 0.14010825753211975\n",
      "[Step 19150] Loss: 9.48e+07 -0.9772903919219971 0.1400810331106186\n",
      "[Step 19151] Loss: 9.45e+07 -0.9772611856460571 0.1400645226240158\n",
      "[Step 19152] Loss: 9.72e+07 -0.9769722819328308 0.14009258151054382\n",
      "[Step 19153] Loss: 9.42e+07 -0.9767289757728577 0.14010000228881836\n",
      "[Step 19154] Loss: 9.48e+07 -0.9765453934669495 0.14010247588157654\n",
      "[Step 19155] Loss: 9.50e+07 -0.9762796759605408 0.14011980593204498\n",
      "[Step 19156] Loss: 9.39e+07 -0.9760159254074097 0.1401396095752716\n",
      "[Step 19157] Loss: 9.46e+07 -0.9758352637290955 0.1401396095752716\n",
      "[Step 19158] Loss: 9.50e+07 -0.9755405783653259 0.1401701420545578\n",
      "[Step 19159] Loss: 9.46e+07 -0.975223183631897 0.140206441283226\n",
      "[Step 19160] Loss: 9.37e+07 -0.9749274849891663 0.14023202657699585\n",
      "[Step 19161] Loss: 9.43e+07 -0.974590003490448 0.14026585221290588\n",
      "[Step 19162] Loss: 9.42e+07 -0.9743390679359436 0.14026503264904022\n",
      "[Step 19163] Loss: 9.37e+07 -0.9741049408912659 0.1402757614850998\n",
      "[Step 19164] Loss: 9.52e+07 -0.9740089178085327 0.14029721915721893\n",
      "[Step 19165] Loss: 9.42e+07 -0.9738978147506714 0.14029309153556824\n",
      "[Step 19166] Loss: 9.53e+07 -0.973875105381012 0.14027081429958344\n",
      "[Step 19167] Loss: 9.39e+07 -0.973806619644165 0.1402312070131302\n",
      "[Step 19168] Loss: 9.39e+07 -0.9736957550048828 0.14022955298423767\n",
      "[Step 19169] Loss: 9.51e+07 -0.9737430214881897 0.14017921686172485\n",
      "[Step 19170] Loss: 9.47e+07 -0.9738361239433289 0.140175923705101\n",
      "[Step 19171] Loss: 9.48e+07 -0.9738509654998779 0.14011980593204498\n",
      "[Step 19172] Loss: 9.47e+07 -0.9739256501197815 0.14009340107440948\n",
      "[Step 19173] Loss: 9.38e+07 -0.974016547203064 0.14008432626724243\n",
      "[Step 19174] Loss: 9.49e+07 -0.9743253588676453 0.14001914858818054\n",
      "[Step 19175] Loss: 9.46e+07 -0.9745393395423889 0.13996881246566772\n",
      "[Step 19176] Loss: 9.37e+07 -0.9747568964958191 0.1399143487215042\n",
      "[Step 19177] Loss: 9.45e+07 -0.974831223487854 0.1398598849773407\n",
      "[Step 19178] Loss: 9.46e+07 -0.9748368263244629 0.1398194581270218\n",
      "[Step 19179] Loss: 9.58e+07 -0.9746435284614563 0.13988134264945984\n",
      "[Step 19180] Loss: 9.40e+07 -0.9745160341262817 0.1398920714855194\n",
      "[Step 19181] Loss: 9.50e+07 -0.9743639230728149 0.13990280032157898\n",
      "[Step 19182] Loss: 9.40e+07 -0.9742461442947388 0.1399184763431549\n",
      "[Step 19183] Loss: 9.47e+07 -0.9742230176925659 0.13992837071418762\n",
      "[Step 19184] Loss: 9.43e+07 -0.9742893576622009 0.1399226039648056\n",
      "[Step 19185] Loss: 9.45e+07 -0.974352240562439 0.13987308740615845\n",
      "[Step 19186] Loss: 9.58e+07 -0.9747132658958435 0.13979139924049377\n",
      "[Step 19187] Loss: 9.48e+07 -0.9751383066177368 0.1397014707326889\n",
      "[Step 19188] Loss: 9.47e+07 -0.9753861427307129 0.1396692842245102\n",
      "[Step 19189] Loss: 9.49e+07 -0.9756348133087158 0.1396486610174179\n",
      "[Step 19190] Loss: 9.47e+07 -0.9759951233863831 0.13959088921546936\n",
      "[Step 19191] Loss: 9.42e+07 -0.9764173626899719 0.1395149827003479\n",
      "[Step 19192] Loss: 9.44e+07 -0.9767619967460632 0.13942916691303253\n",
      "[Step 19193] Loss: 9.40e+07 -0.9770599603652954 0.13936646282672882\n",
      "[Step 19194] Loss: 9.39e+07 -0.9773473143577576 0.13932932913303375\n",
      "[Step 19195] Loss: 9.49e+07 -0.9774611592292786 0.13928641378879547\n",
      "[Step 19196] Loss: 9.47e+07 -0.9774066209793091 0.13931365311145782\n",
      "[Step 19197] Loss: 9.45e+07 -0.9773069620132446 0.1393326222896576\n",
      "[Step 19198] Loss: 9.45e+07 -0.9773580431938171 0.1393062174320221\n",
      "[Step 19199] Loss: 9.42e+07 -0.9772922992706299 0.13929632306098938\n",
      "[Step 19200] Loss: 9.45e+07 -0.9772428274154663 0.13931530714035034\n",
      "[Step 19201] Loss: 9.55e+07 -0.9770506620407104 0.13932272791862488\n",
      "[Step 19202] Loss: 9.45e+07 -0.9768068194389343 0.1393425315618515\n",
      "[Step 19203] Loss: 9.51e+07 -0.9764909148216248 0.13937635719776154\n",
      "[Step 19204] Loss: 9.47e+07 -0.9762059450149536 0.13941267132759094\n",
      "[Step 19205] Loss: 9.47e+07 -0.975878119468689 0.13944649696350098\n",
      "[Step 19206] Loss: 9.37e+07 -0.9755445718765259 0.13948939740657806\n",
      "[Step 19207] Loss: 9.47e+07 -0.9752025604248047 0.13951003551483154\n",
      "[Step 19208] Loss: 9.60e+07 -0.9747788310050964 0.1395554095506668\n",
      "[Step 19209] Loss: 9.44e+07 -0.97449791431427 0.13958099484443665\n",
      "[Step 19210] Loss: 9.45e+07 -0.97420734167099 0.13961318135261536\n",
      "[Step 19211] Loss: 9.40e+07 -0.9739136695861816 0.13966020941734314\n",
      "[Step 19212] Loss: 9.46e+07 -0.9736265540122986 0.13970723748207092\n",
      "[Step 19213] Loss: 9.49e+07 -0.9735096096992493 0.13969816267490387\n",
      "[Step 19214] Loss: 9.43e+07 -0.9734415411949158 0.139719620347023\n",
      "[Step 19215] Loss: 9.55e+07 -0.9733095169067383 0.1397237479686737\n",
      "[Step 19216] Loss: 9.53e+07 -0.973354697227478 0.1397014707326889\n",
      "[Step 19217] Loss: 9.38e+07 -0.9734017252922058 0.13967423141002655\n",
      "[Step 19218] Loss: 9.51e+07 -0.973393440246582 0.13966681063175201\n",
      "[Step 19219] Loss: 9.48e+07 -0.9734081029891968 0.13964122533798218\n",
      "[Step 19220] Loss: 9.43e+07 -0.9734476804733276 0.13963709771633148\n",
      "[Step 19221] Loss: 9.41e+07 -0.9735541343688965 0.13961894810199738\n",
      "[Step 19222] Loss: 9.57e+07 -0.9739465713500977 0.1395471692085266\n",
      "[Step 19223] Loss: 9.45e+07 -0.9744636416435242 0.13945722579956055\n",
      "[Step 19224] Loss: 9.41e+07 -0.9749444723129272 0.1393829584121704\n",
      "[Step 19225] Loss: 9.46e+07 -0.9754818677902222 0.13929137587547302\n",
      "[Step 19226] Loss: 9.48e+07 -0.9759672284126282 0.13921132683753967\n",
      "[Step 19227] Loss: 9.48e+07 -0.9764025211334229 0.13915935158729553\n",
      "[Step 19228] Loss: 9.42e+07 -0.9769217371940613 0.13907106220722198\n",
      "[Step 19229] Loss: 9.50e+07 -0.9773111939430237 0.13901494443416595\n",
      "[Step 19230] Loss: 9.47e+07 -0.9776049256324768 0.1389571875333786\n",
      "[Step 19231] Loss: 9.45e+07 -0.9779471755027771 0.13890603184700012\n",
      "[Step 19232] Loss: 9.46e+07 -0.9781864881515503 0.13889117538928986\n",
      "[Step 19233] Loss: 9.39e+07 -0.9784207940101624 0.1388334184885025\n",
      "[Step 19234] Loss: 9.44e+07 -0.9786040782928467 0.1388251632452011\n",
      "[Step 19235] Loss: 9.46e+07 -0.9788120985031128 0.1387888640165329\n",
      "[Step 19236] Loss: 9.44e+07 -0.9789944887161255 0.13876163959503174\n",
      "[Step 19237] Loss: 9.48e+07 -0.9791020750999451 0.13872532546520233\n",
      "[Step 19238] Loss: 9.51e+07 -0.9791698455810547 0.13870882987976074\n",
      "[Step 19239] Loss: 9.47e+07 -0.9792603850364685 0.13868077099323273\n",
      "[Step 19240] Loss: 9.53e+07 -0.9794971942901611 0.13863208889961243\n",
      "[Step 19241] Loss: 9.53e+07 -0.9795957803726196 0.13861805200576782\n",
      "[Step 19242] Loss: 9.39e+07 -0.9797098636627197 0.13858506083488464\n",
      "[Step 19243] Loss: 9.49e+07 -0.9798280000686646 0.1385776251554489\n",
      "[Step 19244] Loss: 9.42e+07 -0.9799227714538574 0.13855287432670593\n",
      "[Step 19245] Loss: 9.51e+07 -0.9800921082496643 0.13850995898246765\n",
      "[Step 19246] Loss: 9.44e+07 -0.9802944660186768 0.1384439617395401\n",
      "[Step 19247] Loss: 9.38e+07 -0.9804360866546631 0.13842003047466278\n",
      "[Step 19248] Loss: 9.43e+07 -0.9805395603179932 0.1384093016386032\n",
      "[Step 19249] Loss: 9.43e+07 -0.9805251955986023 0.13837134838104248\n",
      "[Step 19250] Loss: 9.44e+07 -0.9804788827896118 0.13838455080986023\n",
      "[Step 19251] Loss: 9.42e+07 -0.9804524183273315 0.13835814595222473\n",
      "[Step 19252] Loss: 9.44e+07 -0.9803766012191772 0.13835978507995605\n",
      "[Step 19253] Loss: 9.44e+07 -0.9803082942962646 0.13836143910884857\n",
      "[Step 19254] Loss: 9.46e+07 -0.980276346206665 0.13833750784397125\n",
      "[Step 19255] Loss: 9.44e+07 -0.9801837205886841 0.13833090662956238\n",
      "[Step 19256] Loss: 9.43e+07 -0.9801710247993469 0.138297900557518\n",
      "[Step 19257] Loss: 9.39e+07 -0.980154812335968 0.13829542696475983\n",
      "[Step 19258] Loss: 9.44e+07 -0.9803619384765625 0.1382269412279129\n",
      "[Step 19259] Loss: 9.47e+07 -0.9805904030799866 0.13817743957042694\n",
      "[Step 19260] Loss: 9.46e+07 -0.9808745384216309 0.13812297582626343\n",
      "[Step 19261] Loss: 9.48e+07 -0.9811385869979858 0.13806356489658356\n",
      "[Step 19262] Loss: 9.64e+07 -0.9817115664482117 0.13795465230941772\n",
      "[Step 19263] Loss: 9.44e+07 -0.9823214411735535 0.13785892724990845\n",
      "[Step 19264] Loss: 9.45e+07 -0.9828417897224426 0.13778962194919586\n",
      "[Step 19265] Loss: 9.48e+07 -0.9833415150642395 0.13769885897636414\n",
      "[Step 19266] Loss: 9.53e+07 -0.9839531183242798 0.13761717081069946\n",
      "[Step 19267] Loss: 9.47e+07 -0.9844354391098022 0.13752475380897522\n",
      "[Step 19268] Loss: 9.51e+07 -0.9850765466690063 0.13741831481456757\n",
      "[Step 19269] Loss: 9.44e+07 -0.9857886433601379 0.13732506334781647\n",
      "[Step 19270] Loss: 9.47e+07 -0.9864242076873779 0.13721615076065063\n",
      "[Step 19271] Loss: 9.42e+07 -0.9870133399963379 0.13711218535900116\n",
      "[Step 19272] Loss: 9.40e+07 -0.9875614643096924 0.1370181143283844\n",
      "[Step 19273] Loss: 9.60e+07 -0.9882262945175171 0.13691085577011108\n",
      "[Step 19274] Loss: 9.44e+07 -0.9889606833457947 0.13681265711784363\n",
      "[Step 19275] Loss: 9.48e+07 -0.9896981716156006 0.13669466972351074\n",
      "[Step 19276] Loss: 9.42e+07 -0.9903482794761658 0.13660472631454468\n",
      "[Step 19277] Loss: 9.37e+07 -0.9909787774085999 0.13650405406951904\n",
      "[Step 19278] Loss: 9.51e+07 -0.991734504699707 0.13638193905353546\n",
      "[Step 19279] Loss: 9.46e+07 -0.9923929572105408 0.13627219200134277\n",
      "[Step 19280] Loss: 9.45e+07 -0.9930190443992615 0.13616244494915009\n",
      "[Step 19281] Loss: 9.44e+07 -0.9935705065727234 0.13606591522693634\n",
      "[Step 19282] Loss: 9.52e+07 -0.9940009117126465 0.13598009943962097\n",
      "[Step 19283] Loss: 9.46e+07 -0.9943766593933105 0.13591326773166656\n",
      "[Step 19284] Loss: 9.45e+07 -0.9946549534797668 0.13585714995861053\n",
      "[Step 19285] Loss: 9.41e+07 -0.99478679895401 0.1358109414577484\n",
      "[Step 19286] Loss: 9.48e+07 -0.9950217604637146 0.13577628135681152\n",
      "[Step 19287] Loss: 9.43e+07 -0.9952164888381958 0.13573256134986877\n",
      "[Step 19288] Loss: 9.47e+07 -0.9953631162643433 0.13570202887058258\n",
      "[Step 19289] Loss: 9.47e+07 -0.9954183101654053 0.13568304479122162\n",
      "[Step 19290] Loss: 9.51e+07 -0.9955386519432068 0.1356549859046936\n",
      "[Step 19291] Loss: 9.49e+07 -0.9956925511360168 0.13560466468334198\n",
      "[Step 19292] Loss: 9.49e+07 -0.995995819568634 0.13553617894649506\n",
      "[Step 19293] Loss: 9.39e+07 -0.9962514042854309 0.1354643851518631\n",
      "[Step 19294] Loss: 9.51e+07 -0.9963800311088562 0.13543303310871124\n",
      "[Step 19295] Loss: 9.43e+07 -0.9965975284576416 0.13541239500045776\n",
      "[Step 19296] Loss: 9.51e+07 -0.9965981841087341 0.1354157030582428\n",
      "[Step 19297] Loss: 9.50e+07 -0.9967465996742249 0.13539095222949982\n",
      "[Step 19298] Loss: 9.55e+07 -0.9970678687095642 0.13531503081321716\n",
      "[Step 19299] Loss: 9.44e+07 -0.9972563982009888 0.13527873158454895\n",
      "[Step 19300] Loss: 9.44e+07 -0.9974384307861328 0.13523581624031067\n",
      "[Step 19301] Loss: 9.46e+07 -0.9977383017539978 0.1351722925901413\n",
      "[Step 19302] Loss: 9.45e+07 -0.9979882836341858 0.1351277232170105\n",
      "[Step 19303] Loss: 9.46e+07 -0.99838787317276 0.13503779470920563\n",
      "[Step 19304] Loss: 9.44e+07 -0.9988176822662354 0.1349329948425293\n",
      "[Step 19305] Loss: 9.52e+07 -0.99918133020401 0.13485461473464966\n",
      "[Step 19306] Loss: 9.39e+07 -0.9993667006492615 0.1348133534193039\n",
      "[Step 19307] Loss: 9.47e+07 -0.9996616840362549 0.1347646713256836\n",
      "[Step 19308] Loss: 9.42e+07 -1.0000429153442383 0.134720116853714\n",
      "[Step 19309] Loss: 9.53e+07 -1.0003149509429932 0.13466565310955048\n",
      "[Step 19310] Loss: 9.44e+07 -1.0005656480789185 0.13461366295814514\n",
      "[Step 19311] Loss: 9.47e+07 -1.0008028745651245 0.1345781832933426\n",
      "[Step 19312] Loss: 9.47e+07 -1.000942349433899 0.13453693687915802\n",
      "[Step 19313] Loss: 9.42e+07 -1.0010663270950317 0.13448825478553772\n",
      "[Step 19314] Loss: 9.48e+07 -1.0012086629867554 0.1344684511423111\n",
      "[Step 19315] Loss: 9.37e+07 -1.0012624263763428 0.13447092473506927\n",
      "[Step 19316] Loss: 9.49e+07 -1.001266360282898 0.13444451987743378\n",
      "[Step 19317] Loss: 9.45e+07 -1.0012545585632324 0.13443131744861603\n",
      "[Step 19318] Loss: 9.48e+07 -1.0013104677200317 0.13443048298358917\n",
      "[Step 19319] Loss: 9.51e+07 -1.0012248754501343 0.1344238817691803\n",
      "[Step 19320] Loss: 9.53e+07 -1.001060128211975 0.13445524871349335\n",
      "[Step 19321] Loss: 9.50e+07 -1.0009804964065552 0.13448742032051086\n",
      "[Step 19322] Loss: 9.45e+07 -1.000933289527893 0.1344684511423111\n",
      "[Step 19323] Loss: 9.47e+07 -1.000982642173767 0.1344502866268158\n",
      "[Step 19324] Loss: 9.46e+07 -1.0009604692459106 0.13444864749908447\n",
      "[Step 19325] Loss: 9.47e+07 -1.001067876815796 0.13441728055477142\n",
      "[Step 19326] Loss: 9.51e+07 -1.0013517141342163 0.13435788452625275\n",
      "[Step 19327] Loss: 9.43e+07 -1.0016154050827026 0.13431578874588013\n",
      "[Step 19328] Loss: 9.50e+07 -1.0018514394760132 0.13427041471004486\n",
      "[Step 19329] Loss: 9.42e+07 -1.0020517110824585 0.13423162698745728\n",
      "[Step 19330] Loss: 9.48e+07 -1.0021265745162964 0.13421595096588135\n",
      "[Step 19331] Loss: 9.49e+07 -1.0022883415222168 0.13417881727218628\n",
      "[Step 19332] Loss: 9.48e+07 -1.002498745918274 0.13411033153533936\n",
      "[Step 19333] Loss: 9.44e+07 -1.0027154684066772 0.13405752182006836\n",
      "[Step 19334] Loss: 9.42e+07 -1.0029603242874146 0.13400636613368988\n",
      "[Step 19335] Loss: 9.50e+07 -1.0031263828277588 0.1339816153049469\n",
      "[Step 19336] Loss: 9.40e+07 -1.0033143758773804 0.13396675884723663\n",
      "[Step 19337] Loss: 9.50e+07 -1.0033154487609863 0.13395026326179504\n",
      "[Step 19338] Loss: 9.39e+07 -1.0033409595489502 0.13394613564014435\n",
      "[Step 19339] Loss: 9.53e+07 -1.003472924232483 0.13389579951763153\n",
      "[Step 19340] Loss: 9.46e+07 -1.0036553144454956 0.13387930393218994\n",
      "[Step 19341] Loss: 9.46e+07 -1.0038789510726929 0.133835569024086\n",
      "[Step 19342] Loss: 9.45e+07 -1.0040783882141113 0.13381823897361755\n",
      "[Step 19343] Loss: 9.53e+07 -1.0044955015182495 0.13374480605125427\n",
      "[Step 19344] Loss: 9.53e+07 -1.0050359964370728 0.13367466628551483\n",
      "[Step 19345] Loss: 9.45e+07 -1.0054861307144165 0.1336061805486679\n",
      "[Step 19346] Loss: 9.52e+07 -1.0060278177261353 0.1335294395685196\n",
      "[Step 19347] Loss: 9.40e+07 -1.006500005722046 0.1334419697523117\n",
      "[Step 19348] Loss: 9.42e+07 -1.0069063901901245 0.13339164853096008\n",
      "[Step 19349] Loss: 9.39e+07 -1.0072989463806152 0.13331159949302673\n",
      "[Step 19350] Loss: 9.46e+07 -1.00758695602417 0.13327695429325104\n",
      "[Step 19351] Loss: 9.49e+07 -1.007983684539795 0.1332167088985443\n",
      "[Step 19352] Loss: 9.43e+07 -1.0084350109100342 0.13314327597618103\n",
      "[Step 19353] Loss: 9.46e+07 -1.0088038444519043 0.1330690085887909\n",
      "[Step 19354] Loss: 9.43e+07 -1.0092600584030151 0.1329815536737442\n",
      "[Step 19355] Loss: 9.50e+07 -1.0098068714141846 0.13287262618541718\n",
      "[Step 19356] Loss: 9.49e+07 -1.0103373527526855 0.13277196884155273\n",
      "[Step 19357] Loss: 9.48e+07 -1.0109490156173706 0.1326853185892105\n",
      "[Step 19358] Loss: 9.45e+07 -1.0115092992782593 0.13259291648864746\n",
      "[Step 19359] Loss: 9.42e+07 -1.0119211673736572 0.1325351446866989\n",
      "[Step 19360] Loss: 9.56e+07 -1.0125001668930054 0.13242210447788239\n",
      "[Step 19361] Loss: 9.42e+07 -1.0129590034484863 0.13235196471214294\n",
      "[Step 19362] Loss: 9.51e+07 -1.0134966373443604 0.1322471797466278\n",
      "[Step 19363] Loss: 9.45e+07 -1.0139570236206055 0.13216136395931244\n",
      "[Step 19364] Loss: 9.45e+07 -1.0143071413040161 0.1320730745792389\n",
      "[Step 19365] Loss: 9.41e+07 -1.014586329460144 0.13202108442783356\n",
      "[Step 19366] Loss: 9.46e+07 -1.0147961378097534 0.13196663558483124\n",
      "[Step 19367] Loss: 9.42e+07 -1.015079379081726 0.13193939626216888\n",
      "[Step 19368] Loss: 9.42e+07 -1.0153039693832397 0.13188742101192474\n",
      "[Step 19369] Loss: 9.53e+07 -1.0155466794967651 0.13183461129665375\n",
      "[Step 19370] Loss: 9.49e+07 -1.015905737876892 0.13177107274532318\n",
      "[Step 19371] Loss: 9.44e+07 -1.0162509679794312 0.13171248137950897\n",
      "[Step 19372] Loss: 9.43e+07 -1.0166034698486328 0.13162997364997864\n",
      "[Step 19373] Loss: 9.55e+07 -1.01681649684906 0.13158129155635834\n",
      "[Step 19374] Loss: 9.46e+07 -1.0170328617095947 0.13154499232769012\n",
      "[Step 19375] Loss: 9.47e+07 -1.0173711776733398 0.13145092129707336\n",
      "[Step 19376] Loss: 9.46e+07 -1.0176552534103394 0.13138985633850098\n",
      "[Step 19377] Loss: 9.47e+07 -1.0178682804107666 0.13135190308094025\n",
      "[Step 19378] Loss: 9.46e+07 -1.0181105136871338 0.1313065141439438\n",
      "[Step 19379] Loss: 9.49e+07 -1.0183312892913818 0.13126195967197418\n",
      "[Step 19380] Loss: 9.39e+07 -1.0185447931289673 0.13120998442173004\n",
      "[Step 19381] Loss: 9.41e+07 -1.0187360048294067 0.13116872310638428\n",
      "[Step 19382] Loss: 9.38e+07 -1.0188651084899902 0.1311579942703247\n",
      "[Step 19383] Loss: 9.49e+07 -1.0188789367675781 0.13115470111370087\n",
      "[Step 19384] Loss: 9.49e+07 -1.0190240144729614 0.13109032809734344\n",
      "[Step 19385] Loss: 9.39e+07 -1.019188642501831 0.13106310367584229\n",
      "[Step 19386] Loss: 9.38e+07 -1.0192948579788208 0.1310507208108902\n",
      "[Step 19387] Loss: 9.54e+07 -1.0196444988250732 0.13097316026687622\n",
      "[Step 19388] Loss: 9.44e+07 -1.0200368165969849 0.13086754083633423\n",
      "[Step 19389] Loss: 9.41e+07 -1.0203503370285034 0.13081969320774078\n",
      "[Step 19390] Loss: 9.45e+07 -1.0205358266830444 0.13077183067798615\n",
      "[Step 19391] Loss: 9.44e+07 -1.0206758975982666 0.1307421326637268\n",
      "[Step 19392] Loss: 9.35e+07 -1.0207964181900024 0.13071076571941376\n",
      "[Step 19393] Loss: 9.52e+07 -1.0207188129425049 0.13068848848342896\n",
      "[Step 19394] Loss: 9.39e+07 -1.0205413103103638 0.13069839775562286\n",
      "[Step 19395] Loss: 9.43e+07 -1.0204229354858398 0.13069427013397217\n",
      "[Step 19396] Loss: 9.54e+07 -1.0202325582504272 0.13070499897003174\n",
      "[Step 19397] Loss: 9.45e+07 -1.0201126337051392 0.13072893023490906\n",
      "[Step 19398] Loss: 9.46e+07 -1.0200587511062622 0.13070829212665558\n",
      "[Step 19399] Loss: 9.41e+07 -1.0199707746505737 0.13074129819869995\n",
      "[Step 19400] Loss: 9.44e+07 -1.0198463201522827 0.1307627558708191\n",
      "[Step 19401] Loss: 9.47e+07 -1.0197787284851074 0.13075202703475952\n",
      "[Step 19402] Loss: 9.53e+07 -1.0195791721343994 0.13077925145626068\n",
      "[Step 19403] Loss: 9.47e+07 -1.019478440284729 0.1307726502418518\n",
      "[Step 19404] Loss: 9.49e+07 -1.0195188522338867 0.13074707984924316\n",
      "[Step 19405] Loss: 9.49e+07 -1.0194993019104004 0.13072893023490906\n",
      "[Step 19406] Loss: 9.49e+07 -1.0196645259857178 0.13069096207618713\n",
      "[Step 19407] Loss: 9.55e+07 -1.0200109481811523 0.1306167095899582\n",
      "[Step 19408] Loss: 9.44e+07 -1.020373821258545 0.13055317103862762\n",
      "[Step 19409] Loss: 9.47e+07 -1.020693063735962 0.1305069625377655\n",
      "[Step 19410] Loss: 9.41e+07 -1.020928144454956 0.13046488165855408\n",
      "[Step 19411] Loss: 9.44e+07 -1.0210931301116943 0.1304302215576172\n",
      "[Step 19412] Loss: 9.63e+07 -1.0215630531311035 0.13033203780651093\n",
      "[Step 19413] Loss: 9.40e+07 -1.0220215320587158 0.13025447726249695\n",
      "[Step 19414] Loss: 9.45e+07 -1.0223684310913086 0.13019341230392456\n",
      "[Step 19415] Loss: 9.52e+07 -1.0225903987884521 0.13014885783195496\n",
      "[Step 19416] Loss: 9.50e+07 -1.0228796005249023 0.13010181486606598\n",
      "[Step 19417] Loss: 9.49e+07 -1.0231561660766602 0.13004983961582184\n",
      "[Step 19418] Loss: 9.43e+07 -1.0232809782028198 0.1300201267004013\n",
      "[Step 19419] Loss: 9.49e+07 -1.0232887268066406 0.13000857830047607\n",
      "[Step 19420] Loss: 9.55e+07 -1.0231868028640747 0.13002590835094452\n",
      "[Step 19421] Loss: 9.43e+07 -1.023005485534668 0.13005149364471436\n",
      "[Step 19422] Loss: 9.35e+07 -1.0227878093719482 0.13007459044456482\n",
      "[Step 19423] Loss: 9.48e+07 -1.022620677947998 0.1300952136516571\n",
      "[Step 19424] Loss: 9.49e+07 -1.022529125213623 0.13013482093811035\n",
      "[Step 19425] Loss: 9.51e+07 -1.0226044654846191 0.13011914491653442\n",
      "[Step 19426] Loss: 9.44e+07 -1.022807240486145 0.13008944690227509\n",
      "[Step 19427] Loss: 9.45e+07 -1.0229662656784058 0.1300564408302307\n",
      "[Step 19428] Loss: 9.44e+07 -1.0229815244674683 0.13004900515079498\n",
      "[Step 19429] Loss: 9.55e+07 -1.0230705738067627 0.13005560636520386\n",
      "[Step 19430] Loss: 9.41e+07 -1.0230958461761475 0.1300159990787506\n",
      "[Step 19431] Loss: 9.53e+07 -1.0230501890182495 0.130024254322052\n",
      "[Step 19432] Loss: 9.39e+07 -1.0231070518493652 0.13000281155109406\n",
      "[Step 19433] Loss: 9.42e+07 -1.0231354236602783 0.13000445067882538\n",
      "[Step 19434] Loss: 9.45e+07 -1.0230883359909058 0.12999124825000763\n",
      "[Step 19435] Loss: 9.46e+07 -1.023027777671814 0.1299937218427658\n",
      "[Step 19436] Loss: 9.46e+07 -1.0230156183242798 0.1299532949924469\n",
      "[Step 19437] Loss: 9.38e+07 -1.0229010581970215 0.1299590766429901\n",
      "[Step 19438] Loss: 9.45e+07 -1.0228471755981445 0.12994256615638733\n",
      "[Step 19439] Loss: 9.45e+07 -1.0229321718215942 0.1299211084842682\n",
      "[Step 19440] Loss: 9.53e+07 -1.0228753089904785 0.12992359697818756\n",
      "[Step 19441] Loss: 9.39e+07 -1.0228016376495361 0.12991781532764435\n",
      "[Step 19442] Loss: 9.42e+07 -1.022740364074707 0.12991946935653687\n",
      "[Step 19443] Loss: 9.43e+07 -1.0227988958358765 0.12987902760505676\n",
      "[Step 19444] Loss: 9.58e+07 -1.0230050086975098 0.12983447313308716\n",
      "[Step 19445] Loss: 9.42e+07 -1.0230863094329834 0.12982045114040375\n",
      "[Step 19446] Loss: 9.43e+07 -1.0231684446334839 0.12979817390441895\n",
      "[Step 19447] Loss: 9.45e+07 -1.0233709812164307 0.12975691258907318\n",
      "[Step 19448] Loss: 9.44e+07 -1.023528814315796 0.12971730530261993\n",
      "[Step 19449] Loss: 9.39e+07 -1.0236115455627441 0.12971152365207672\n",
      "[Step 19450] Loss: 9.39e+07 -1.023710012435913 0.12968429923057556\n",
      "[Step 19451] Loss: 9.46e+07 -1.023764967918396 0.12966780364513397\n",
      "[Step 19452] Loss: 9.45e+07 -1.0238192081451416 0.12963809072971344\n",
      "[Step 19453] Loss: 9.42e+07 -1.023828387260437 0.1296166330575943\n",
      "[Step 19454] Loss: 9.45e+07 -1.023880124092102 0.12961168587207794\n",
      "[Step 19455] Loss: 9.43e+07 -1.0238813161849976 0.1295819878578186\n",
      "[Step 19456] Loss: 9.41e+07 -1.0239208936691284 0.12956631183624268\n",
      "[Step 19457] Loss: 9.44e+07 -1.0239038467407227 0.12956465780735016\n",
      "[Step 19458] Loss: 9.41e+07 -1.0238921642303467 0.1295316517353058\n",
      "[Step 19459] Loss: 9.54e+07 -1.0240484476089478 0.12948626279830933\n",
      "[Step 19460] Loss: 9.43e+07 -1.0242363214492798 0.129431813955307\n",
      "[Step 19461] Loss: 9.39e+07 -1.0245314836502075 0.12936662137508392\n",
      "[Step 19462] Loss: 9.49e+07 -1.0248435735702515 0.12929895520210266\n",
      "[Step 19463] Loss: 9.55e+07 -1.0249626636505127 0.12927338480949402\n",
      "[Step 19464] Loss: 9.43e+07 -1.0250362157821655 0.1292717307806015\n",
      "[Step 19465] Loss: 9.49e+07 -1.0252443552017212 0.12922470271587372\n",
      "[Step 19466] Loss: 9.47e+07 -1.0254595279693604 0.12920571863651276\n",
      "[Step 19467] Loss: 9.40e+07 -1.0255613327026367 0.1291908621788025\n",
      "[Step 19468] Loss: 9.45e+07 -1.0255720615386963 0.1291801482439041\n",
      "[Step 19469] Loss: 9.51e+07 -1.025644302368164 0.12914961576461792\n",
      "[Step 19470] Loss: 9.49e+07 -1.0256373882293701 0.1291380673646927\n",
      "[Step 19471] Loss: 9.51e+07 -1.025707721710205 0.1291479617357254\n",
      "[Step 19472] Loss: 9.56e+07 -1.0257147550582886 0.12915126979351044\n",
      "[Step 19473] Loss: 9.59e+07 -1.0259701013565063 0.1291199028491974\n",
      "[Step 19474] Loss: 9.43e+07 -1.026236891746521 0.12907534837722778\n",
      "[Step 19475] Loss: 9.56e+07 -1.026817798614502 0.12897880375385284\n",
      "[Step 19476] Loss: 9.47e+07 -1.027422308921814 0.1288781464099884\n",
      "[Step 19477] Loss: 9.43e+07 -1.027991771697998 0.12879562377929688\n",
      "[Step 19478] Loss: 9.56e+07 -1.0283383131027222 0.12874364852905273\n",
      "[Step 19479] Loss: 9.54e+07 -1.028727412223816 0.1287040412425995\n",
      "[Step 19480] Loss: 9.43e+07 -1.0291504859924316 0.12860584259033203\n",
      "[Step 19481] Loss: 9.55e+07 -1.0297335386276245 0.12851013243198395\n",
      "[Step 19482] Loss: 9.44e+07 -1.030252456665039 0.1284276247024536\n",
      "[Step 19483] Loss: 9.52e+07 -1.0309354066848755 0.12830880284309387\n",
      "[Step 19484] Loss: 9.51e+07 -1.0316251516342163 0.12821391224861145\n",
      "[Step 19485] Loss: 9.43e+07 -1.0322340726852417 0.12810003757476807\n",
      "[Step 19486] Loss: 9.39e+07 -1.0328247547149658 0.12800762057304382\n",
      "[Step 19487] Loss: 9.33e+07 -1.0333307981491089 0.12792180478572845\n",
      "[Step 19488] Loss: 9.47e+07 -1.0336717367172241 0.12784506380558014\n",
      "[Step 19489] Loss: 9.57e+07 -1.0342316627502441 0.12772955000400543\n",
      "[Step 19490] Loss: 9.44e+07 -1.0348026752471924 0.1276511698961258\n",
      "[Step 19491] Loss: 9.46e+07 -1.0352648496627808 0.12756699323654175\n",
      "[Step 19492] Loss: 9.71e+07 -1.0354751348495483 0.12751419842243195\n",
      "[Step 19493] Loss: 9.43e+07 -1.0356186628341675 0.12746798992156982\n",
      "[Step 19494] Loss: 9.42e+07 -1.0357444286346436 0.12743085622787476\n",
      "[Step 19495] Loss: 9.49e+07 -1.0357952117919922 0.12739206850528717\n",
      "[Step 19496] Loss: 9.52e+07 -1.0360580682754517 0.1273384392261505\n",
      "[Step 19497] Loss: 9.46e+07 -1.036285161972046 0.1272881031036377\n",
      "[Step 19498] Loss: 9.53e+07 -1.0365294218063354 0.1272229105234146\n",
      "[Step 19499] Loss: 9.36e+07 -1.0367282629013062 0.1271701157093048\n",
      "[Step 19500] Loss: 9.47e+07 -1.0369094610214233 0.12713462114334106\n",
      "[Step 19501] Loss: 9.42e+07 -1.0370569229125977 0.12708677351474762\n",
      "[Step 19502] Loss: 9.60e+07 -1.0370358228683472 0.12707273662090302\n",
      "[Step 19503] Loss: 9.46e+07 -1.036919116973877 0.1270851194858551\n",
      "[Step 19504] Loss: 9.45e+07 -1.0368949174880981 0.1270793378353119\n",
      "[Step 19505] Loss: 9.34e+07 -1.0368036031723022 0.12708264589309692\n",
      "[Step 19506] Loss: 9.45e+07 -1.0366394519805908 0.1270851194858551\n",
      "[Step 19507] Loss: 9.45e+07 -1.036479115486145 0.12706449627876282\n",
      "[Step 19508] Loss: 9.65e+07 -1.0361229181289673 0.12709666788578033\n",
      "[Step 19509] Loss: 9.56e+07 -1.03602933883667 0.1270570605993271\n",
      "[Step 19510] Loss: 9.37e+07 -1.0358957052230835 0.12705542147159576\n",
      "[Step 19511] Loss: 9.39e+07 -1.0358119010925293 0.1270446926355362\n",
      "[Step 19512] Loss: 9.44e+07 -1.0356650352478027 0.127066969871521\n",
      "[Step 19513] Loss: 9.43e+07 -1.035591959953308 0.12706366181373596\n",
      "[Step 19514] Loss: 9.40e+07 -1.0356178283691406 0.12703809142112732\n",
      "[Step 19515] Loss: 9.49e+07 -1.0355756282806396 0.1270224153995514\n",
      "[Step 19516] Loss: 9.46e+07 -1.0355299711227417 0.12702158093452454\n",
      "[Step 19517] Loss: 9.47e+07 -1.0355157852172852 0.12702076137065887\n",
      "[Step 19518] Loss: 9.44e+07 -1.0356451272964478 0.1269836276769638\n",
      "[Step 19519] Loss: 9.40e+07 -1.0357807874679565 0.12695640325546265\n",
      "[Step 19520] Loss: 9.52e+07 -1.0358561277389526 0.1269209235906601\n",
      "[Step 19521] Loss: 9.56e+07 -1.0362114906311035 0.12683840095996857\n",
      "[Step 19522] Loss: 9.44e+07 -1.036478877067566 0.12677238881587982\n",
      "[Step 19523] Loss: 9.39e+07 -1.036671757698059 0.1267344355583191\n",
      "[Step 19524] Loss: 9.50e+07 -1.0368880033493042 0.12668906152248383\n",
      "[Step 19525] Loss: 9.43e+07 -1.0370564460754395 0.126663476228714\n",
      "[Step 19526] Loss: 9.39e+07 -1.0371685028076172 0.12663625180721283\n",
      "[Step 19527] Loss: 9.48e+07 -1.0373470783233643 0.12660571932792664\n",
      "[Step 19528] Loss: 9.45e+07 -1.0375181436538696 0.12651824951171875\n",
      "[Step 19529] Loss: 9.51e+07 -1.0378957986831665 0.12643161416053772\n",
      "[Step 19530] Loss: 9.47e+07 -1.0383106470108032 0.12634167075157166\n",
      "[Step 19531] Loss: 9.42e+07 -1.0388383865356445 0.12623770534992218\n",
      "[Step 19532] Loss: 9.57e+07 -1.0395097732543945 0.12613043189048767\n",
      "[Step 19533] Loss: 9.37e+07 -1.0401227474212646 0.12601904571056366\n",
      "[Step 19534] Loss: 9.41e+07 -1.0406476259231567 0.12593404948711395\n",
      "[Step 19535] Loss: 9.48e+07 -1.0410363674163818 0.1258721649646759\n",
      "[Step 19536] Loss: 9.48e+07 -1.0415419340133667 0.1258094608783722\n",
      "[Step 19537] Loss: 9.45e+07 -1.0419944524765015 0.1257343739271164\n",
      "[Step 19538] Loss: 9.46e+07 -1.0425339937210083 0.12564855813980103\n",
      "[Step 19539] Loss: 9.44e+07 -1.0430210828781128 0.1255313903093338\n",
      "[Step 19540] Loss: 9.46e+07 -1.0434987545013428 0.1254463940858841\n",
      "[Step 19541] Loss: 9.46e+07 -1.0438774824142456 0.12539689242839813\n",
      "[Step 19542] Loss: 9.36e+07 -1.0442031621932983 0.12533582746982574\n",
      "[Step 19543] Loss: 9.34e+07 -1.0444778203964233 0.1252797245979309\n",
      "[Step 19544] Loss: 9.48e+07 -1.0447160005569458 0.1252335160970688\n",
      "[Step 19545] Loss: 9.48e+07 -1.0448503494262695 0.1251864731311798\n",
      "[Step 19546] Loss: 9.43e+07 -1.0450280904769897 0.12515677511692047\n",
      "[Step 19547] Loss: 9.60e+07 -1.045579195022583 0.12505857646465302\n",
      "[Step 19548] Loss: 9.43e+07 -1.046140193939209 0.1249207854270935\n",
      "[Step 19549] Loss: 9.47e+07 -1.0467501878738403 0.12482506781816483\n",
      "[Step 19550] Loss: 9.41e+07 -1.0472865104675293 0.12472770363092422\n",
      "[Step 19551] Loss: 9.38e+07 -1.0477380752563477 0.12463611364364624\n",
      "[Step 19552] Loss: 9.44e+07 -1.0482076406478882 0.12452059239149094\n",
      "[Step 19553] Loss: 9.53e+07 -1.048555850982666 0.12445210665464401\n",
      "[Step 19554] Loss: 9.42e+07 -1.0488487482070923 0.1243852749466896\n",
      "[Step 19555] Loss: 9.54e+07 -1.0492743253707886 0.12429285794496536\n",
      "[Step 19556] Loss: 9.45e+07 -1.0497348308563232 0.1241946667432785\n",
      "[Step 19557] Loss: 9.50e+07 -1.050177812576294 0.1240973025560379\n",
      "[Step 19558] Loss: 9.45e+07 -1.0504777431488037 0.12404531240463257\n",
      "[Step 19559] Loss: 9.45e+07 -1.0506656169891357 0.12401065975427628\n",
      "[Step 19560] Loss: 9.47e+07 -1.05083167552948 0.12398095428943634\n",
      "[Step 19561] Loss: 9.55e+07 -1.0507826805114746 0.12396940588951111\n",
      "[Step 19562] Loss: 9.45e+07 -1.050770878791809 0.1239512488245964\n",
      "[Step 19563] Loss: 9.44e+07 -1.0506395101547241 0.12395702302455902\n",
      "[Step 19564] Loss: 9.43e+07 -1.0505691766738892 0.12394464761018753\n",
      "[Step 19565] Loss: 9.46e+07 -1.0505447387695312 0.12390421330928802\n",
      "[Step 19566] Loss: 9.41e+07 -1.050502896308899 0.12389596551656723\n",
      "[Step 19567] Loss: 9.46e+07 -1.0504417419433594 0.12388936430215836\n",
      "[Step 19568] Loss: 9.50e+07 -1.0505534410476685 0.12386048585176468\n",
      "[Step 19569] Loss: 9.45e+07 -1.0505971908569336 0.12384811043739319\n",
      "[Step 19570] Loss: 9.43e+07 -1.0506242513656616 0.123817577958107\n",
      "[Step 19571] Loss: 9.46e+07 -1.0506618022918701 0.12379364669322968\n",
      "[Step 19572] Loss: 9.40e+07 -1.0506502389907837 0.12378622591495514\n",
      "[Step 19573] Loss: 9.39e+07 -1.0505554676055908 0.12381097674369812\n",
      "[Step 19574] Loss: 9.35e+07 -1.0503884553909302 0.12381592392921448\n",
      "[Step 19575] Loss: 9.38e+07 -1.050207257270813 0.12386873364448547\n",
      "[Step 19576] Loss: 9.47e+07 -1.0499382019042969 0.12389596551656723\n",
      "[Step 19577] Loss: 9.45e+07 -1.049628734588623 0.1239289715886116\n",
      "[Step 19578] Loss: 9.47e+07 -1.0493080615997314 0.12397682666778564\n",
      "[Step 19579] Loss: 9.44e+07 -1.0490552186965942 0.12402056157588959\n",
      "[Step 19580] Loss: 9.38e+07 -1.0487998723983765 0.12405109405517578\n",
      "[Step 19581] Loss: 9.43e+07 -1.0485507249832153 0.12407749891281128\n",
      "[Step 19582] Loss: 9.39e+07 -1.048251986503601 0.12411709874868393\n",
      "[Step 19583] Loss: 9.39e+07 -1.0478779077529907 0.12415093183517456\n",
      "[Step 19584] Loss: 9.40e+07 -1.0476168394088745 0.12416000664234161\n",
      "[Step 19585] Loss: 9.43e+07 -1.047394871711731 0.1241987943649292\n",
      "[Step 19586] Loss: 9.48e+07 -1.0471285581588745 0.12421859055757523\n",
      "[Step 19587] Loss: 9.47e+07 -1.0470432043075562 0.12419383972883224\n",
      "[Step 19588] Loss: 9.42e+07 -1.0470242500305176 0.12419549375772476\n",
      "[Step 19589] Loss: 9.43e+07 -1.046979308128357 0.12418393790721893\n",
      "[Step 19590] Loss: 9.40e+07 -1.0469831228256226 0.12414515763521194\n",
      "[Step 19591] Loss: 9.35e+07 -1.047002911567688 0.12413030117750168\n",
      "[Step 19592] Loss: 9.42e+07 -1.0470342636108398 0.12409482151269913\n",
      "[Step 19593] Loss: 9.46e+07 -1.0470757484436035 0.12408740073442459\n",
      "[Step 19594] Loss: 9.43e+07 -1.0471442937850952 0.12407749891281128\n",
      "[Step 19595] Loss: 9.40e+07 -1.047136664390564 0.1240444928407669\n",
      "[Step 19596] Loss: 9.45e+07 -1.0471441745758057 0.12404779344797134\n",
      "[Step 19597] Loss: 9.44e+07 -1.0470973253250122 0.12403293699026108\n",
      "[Step 19598] Loss: 9.54e+07 -1.0468792915344238 0.12406181544065475\n",
      "[Step 19599] Loss: 9.50e+07 -1.046650767326355 0.1240832731127739\n",
      "[Step 19600] Loss: 9.43e+07 -1.0464743375778198 0.12411132454872131\n",
      "[Step 19601] Loss: 9.47e+07 -1.0462241172790527 0.12413772940635681\n",
      "[Step 19602] Loss: 9.55e+07 -1.0461820363998413 0.12411709874868393\n",
      "[Step 19603] Loss: 9.35e+07 -1.0461574792861938 0.12410885095596313\n",
      "[Step 19604] Loss: 9.57e+07 -1.045997142791748 0.12412288039922714\n",
      "[Step 19605] Loss: 9.37e+07 -1.0458118915557861 0.12415505945682526\n",
      "[Step 19606] Loss: 9.43e+07 -1.045660138130188 0.12417073547840118\n",
      "[Step 19607] Loss: 9.49e+07 -1.0456653833389282 0.12419219315052032\n",
      "[Step 19608] Loss: 9.48e+07 -1.0458334684371948 0.12414763122797012\n",
      "[Step 19609] Loss: 9.48e+07 -1.0458617210388184 0.12411875277757645\n",
      "[Step 19610] Loss: 9.50e+07 -1.046026349067688 0.12410307675600052\n",
      "[Step 19611] Loss: 9.49e+07 -1.04611337184906 0.1240832731127739\n",
      "[Step 19612] Loss: 9.46e+07 -1.0461997985839844 0.12405109405517578\n",
      "[Step 19613] Loss: 9.45e+07 -1.0463066101074219 0.12401148676872253\n",
      "[Step 19614] Loss: 9.39e+07 -1.0464694499969482 0.12399828433990479\n",
      "[Step 19615] Loss: 9.61e+07 -1.0469366312026978 0.12392567098140717\n",
      "[Step 19616] Loss: 9.46e+07 -1.047295331954956 0.12387698888778687\n",
      "[Step 19617] Loss: 9.42e+07 -1.0476256608963013 0.12384150922298431\n",
      "[Step 19618] Loss: 9.47e+07 -1.0479576587677002 0.12379530072212219\n",
      "[Step 19619] Loss: 9.45e+07 -1.0483274459838867 0.12372516095638275\n",
      "[Step 19620] Loss: 9.42e+07 -1.048741102218628 0.12363274395465851\n",
      "[Step 19621] Loss: 9.44e+07 -1.0491036176681519 0.12357994168996811\n",
      "[Step 19622] Loss: 9.48e+07 -1.0495009422302246 0.12352465093135834\n",
      "[Step 19623] Loss: 9.48e+07 -1.049849510192871 0.12345946580171585\n",
      "[Step 19624] Loss: 9.44e+07 -1.0502393245697021 0.1234058365225792\n",
      "[Step 19625] Loss: 9.40e+07 -1.050601840019226 0.12334642559289932\n",
      "[Step 19626] Loss: 9.64e+07 -1.0507415533065796 0.12333239614963531\n",
      "[Step 19627] Loss: 9.44e+07 -1.0508736371994019 0.12331754714250565\n",
      "[Step 19628] Loss: 9.41e+07 -1.0509663820266724 0.12325400859117508\n",
      "[Step 19629] Loss: 9.38e+07 -1.0509730577468872 0.12324576079845428\n",
      "[Step 19630] Loss: 9.45e+07 -1.051003336906433 0.12320862710475922\n",
      "[Step 19631] Loss: 9.47e+07 -1.051029086112976 0.1231846958398819\n",
      "[Step 19632] Loss: 9.41e+07 -1.0510659217834473 0.12315581738948822\n",
      "[Step 19633] Loss: 9.47e+07 -1.0511400699615479 0.12313766777515411\n",
      "[Step 19634] Loss: 9.62e+07 -1.0514881610870361 0.12307577580213547\n",
      "[Step 19635] Loss: 9.50e+07 -1.052025318145752 0.12295778840780258\n",
      "[Step 19636] Loss: 9.50e+07 -1.0526024103164673 0.1228439137339592\n",
      "[Step 19637] Loss: 9.47e+07 -1.0532798767089844 0.12272921949625015\n",
      "[Step 19638] Loss: 9.49e+07 -1.053954005241394 0.12261617928743362\n",
      "[Step 19639] Loss: 9.39e+07 -1.0545978546142578 0.1225072592496872\n",
      "[Step 19640] Loss: 9.44e+07 -1.0551302433013916 0.12241896986961365\n",
      "[Step 19641] Loss: 9.47e+07 -1.055433988571167 0.12232077866792679\n",
      "[Step 19642] Loss: 9.43e+07 -1.0557653903961182 0.12223661690950394\n",
      "[Step 19643] Loss: 9.44e+07 -1.0561280250549316 0.12216977775096893\n",
      "[Step 19644] Loss: 9.48e+07 -1.0563974380493164 0.12211532145738602\n",
      "[Step 19645] Loss: 9.42e+07 -1.056668996810913 0.12207901477813721\n",
      "[Step 19646] Loss: 9.34e+07 -1.0568718910217285 0.12203280627727509\n",
      "[Step 19647] Loss: 9.44e+07 -1.057084560394287 0.12196679413318634\n",
      "[Step 19648] Loss: 9.42e+07 -1.0572501420974731 0.12191728502511978\n",
      "[Step 19649] Loss: 9.42e+07 -1.0574501752853394 0.12188015878200531\n",
      "[Step 19650] Loss: 9.46e+07 -1.0576645135879517 0.12182487547397614\n",
      "[Step 19651] Loss: 9.46e+07 -1.0579378604888916 0.12180011719465256\n",
      "[Step 19652] Loss: 9.40e+07 -1.0582009553909302 0.12175803631544113\n",
      "[Step 19653] Loss: 9.46e+07 -1.058428406715393 0.121697798371315\n",
      "[Step 19654] Loss: 9.38e+07 -1.0586363077163696 0.12165901809930801\n",
      "[Step 19655] Loss: 9.44e+07 -1.0588139295578003 0.12162023782730103\n",
      "[Step 19656] Loss: 9.43e+07 -1.0589537620544434 0.12157898396253586\n",
      "[Step 19657] Loss: 9.47e+07 -1.0590449571609497 0.12156165391206741\n",
      "[Step 19658] Loss: 9.40e+07 -1.0591521263122559 0.12150224298238754\n",
      "[Step 19659] Loss: 9.53e+07 -1.059316635131836 0.12145190685987473\n",
      "[Step 19660] Loss: 9.50e+07 -1.0593605041503906 0.12141642719507217\n",
      "[Step 19661] Loss: 9.52e+07 -1.0593887567520142 0.12139827758073807\n",
      "[Step 19662] Loss: 9.40e+07 -1.059386968612671 0.12136279791593552\n",
      "[Step 19663] Loss: 9.50e+07 -1.0592586994171143 0.12136279791593552\n",
      "[Step 19664] Loss: 9.43e+07 -1.0591270923614502 0.1213570162653923\n",
      "[Step 19665] Loss: 9.53e+07 -1.0589946508407593 0.12134959548711777\n",
      "[Step 19666] Loss: 9.45e+07 -1.058828353881836 0.12134051322937012\n",
      "[Step 19667] Loss: 9.48e+07 -1.0586609840393066 0.12134546786546707\n",
      "[Step 19668] Loss: 9.44e+07 -1.0584166049957275 0.12136691808700562\n",
      "[Step 19669] Loss: 9.44e+07 -1.0580896139144897 0.12137847393751144\n",
      "[Step 19670] Loss: 9.53e+07 -1.0579617023468018 0.12139662355184555\n",
      "[Step 19671] Loss: 9.48e+07 -1.0578111410140991 0.12139002233743668\n",
      "[Step 19672] Loss: 9.50e+07 -1.0577839612960815 0.12135949730873108\n",
      "[Step 19673] Loss: 9.46e+07 -1.057823657989502 0.12132896482944489\n",
      "[Step 19674] Loss: 9.47e+07 -1.0579206943511963 0.12131410837173462\n",
      "[Step 19675] Loss: 9.43e+07 -1.0580817461013794 0.12131493538618088\n",
      "[Step 19676] Loss: 9.43e+07 -1.0582118034362793 0.1212778091430664\n",
      "[Step 19677] Loss: 9.50e+07 -1.0584100484848022 0.12125140428543091\n",
      "[Step 19678] Loss: 9.47e+07 -1.0586376190185547 0.12119529396295547\n",
      "[Step 19679] Loss: 9.44e+07 -1.0588328838348389 0.12119446694850922\n",
      "[Step 19680] Loss: 9.47e+07 -1.0590276718139648 0.12116888910531998\n",
      "[Step 19681] Loss: 9.61e+07 -1.0594655275344849 0.12110123038291931\n",
      "[Step 19682] Loss: 9.46e+07 -1.0599277019500732 0.12100055813789368\n",
      "[Step 19683] Loss: 9.43e+07 -1.060238242149353 0.12093372642993927\n",
      "[Step 19684] Loss: 9.41e+07 -1.0605075359344482 0.12090402096509933\n",
      "[Step 19685] Loss: 9.46e+07 -1.0607049465179443 0.12084873765707016\n",
      "[Step 19686] Loss: 9.43e+07 -1.0608937740325928 0.1207728236913681\n",
      "[Step 19687] Loss: 9.50e+07 -1.0609012842178345 0.12077859789133072\n",
      "[Step 19688] Loss: 9.54e+07 -1.0610560178756714 0.12074889242649078\n",
      "[Step 19689] Loss: 9.46e+07 -1.0612236261367798 0.12071093916893005\n",
      "[Step 19690] Loss: 9.43e+07 -1.061321496963501 0.1206795796751976\n",
      "[Step 19691] Loss: 9.59e+07 -1.06123685836792 0.12066390365362167\n",
      "[Step 19692] Loss: 9.39e+07 -1.0610734224319458 0.12063997238874435\n",
      "[Step 19693] Loss: 9.45e+07 -1.0610450506210327 0.1206267699599266\n",
      "[Step 19694] Loss: 9.42e+07 -1.0609222650527954 0.12064492702484131\n",
      "[Step 19695] Loss: 9.49e+07 -1.0609333515167236 0.12063419818878174\n",
      "[Step 19696] Loss: 9.37e+07 -1.0610040426254272 0.12063255161046982\n",
      "[Step 19697] Loss: 9.39e+07 -1.0610164403915405 0.12062016874551773\n",
      "[Step 19698] Loss: 9.52e+07 -1.0612149238586426 0.12056323885917664\n",
      "[Step 19699] Loss: 9.40e+07 -1.061298131942749 0.12053187936544418\n",
      "[Step 19700] Loss: 9.53e+07 -1.0615246295928955 0.12049145251512527\n",
      "[Step 19701] Loss: 9.44e+07 -1.0617748498916626 0.12044358998537064\n",
      "[Step 19702] Loss: 9.43e+07 -1.0620137453079224 0.12038913369178772\n",
      "[Step 19703] Loss: 9.45e+07 -1.0622986555099487 0.12030497193336487\n",
      "[Step 19704] Loss: 9.42e+07 -1.0626652240753174 0.12026206403970718\n",
      "[Step 19705] Loss: 9.44e+07 -1.0629475116729736 0.1202191561460495\n",
      "[Step 19706] Loss: 9.42e+07 -1.0631749629974365 0.12019439786672592\n",
      "[Step 19707] Loss: 9.38e+07 -1.0634416341781616 0.1201481968164444\n",
      "[Step 19708] Loss: 9.39e+07 -1.0636301040649414 0.12011023610830307\n",
      "[Step 19709] Loss: 9.42e+07 -1.0637538433074951 0.1200772300362587\n",
      "[Step 19710] Loss: 9.43e+07 -1.0638599395751953 0.12003680318593979\n",
      "[Step 19711] Loss: 9.56e+07 -1.064168930053711 0.11996996402740479\n",
      "[Step 19712] Loss: 9.39e+07 -1.0644361972808838 0.11993035674095154\n",
      "[Step 19713] Loss: 9.44e+07 -1.0647070407867432 0.11988580226898193\n",
      "[Step 19714] Loss: 9.44e+07 -1.0650261640548706 0.11981896311044693\n",
      "[Step 19715] Loss: 9.45e+07 -1.0653061866760254 0.11977852880954742\n",
      "[Step 19716] Loss: 9.44e+07 -1.065515398979187 0.11974140256643295\n",
      "[Step 19717] Loss: 9.40e+07 -1.0656986236572266 0.11969849467277527\n",
      "[Step 19718] Loss: 9.52e+07 -1.0657200813293457 0.11968281865119934\n",
      "[Step 19719] Loss: 9.40e+07 -1.0657579898834229 0.11965888738632202\n",
      "[Step 19720] Loss: 9.44e+07 -1.0657951831817627 0.11966383457183838\n",
      "[Step 19721] Loss: 9.44e+07 -1.0657362937927246 0.11966218799352646\n",
      "[Step 19722] Loss: 9.45e+07 -1.0656002759933472 0.11967703700065613\n",
      "[Step 19723] Loss: 9.41e+07 -1.0654741525650024 0.11970096826553345\n",
      "[Step 19724] Loss: 9.43e+07 -1.065293312072754 0.11973480135202408\n",
      "[Step 19725] Loss: 9.44e+07 -1.0652395486831665 0.11972407251596451\n",
      "[Step 19726] Loss: 9.43e+07 -1.0652936697006226 0.1197017952799797\n",
      "[Step 19727] Loss: 9.44e+07 -1.0652806758880615 0.11970096826553345\n",
      "[Step 19728] Loss: 9.45e+07 -1.065246820449829 0.11968446522951126\n",
      "[Step 19729] Loss: 9.37e+07 -1.065185546875 0.11967126280069351\n",
      "[Step 19730] Loss: 9.43e+07 -1.065173625946045 0.1196531131863594\n",
      "[Step 19731] Loss: 9.55e+07 -1.0653502941131592 0.11963330954313278\n",
      "[Step 19732] Loss: 9.44e+07 -1.065501093864441 0.11960030347108841\n",
      "[Step 19733] Loss: 9.46e+07 -1.0656853914260864 0.11955409497022629\n",
      "[Step 19734] Loss: 9.46e+07 -1.0659022331237793 0.1194971576333046\n",
      "[Step 19735] Loss: 9.45e+07 -1.0661916732788086 0.11946085095405579\n",
      "[Step 19736] Loss: 9.40e+07 -1.0664114952087402 0.11943279951810837\n",
      "[Step 19737] Loss: 9.44e+07 -1.0665231943130493 0.11940722167491913\n",
      "[Step 19738] Loss: 9.43e+07 -1.0665663480758667 0.11938906461000443\n",
      "[Step 19739] Loss: 9.37e+07 -1.066665530204773 0.11936844140291214\n",
      "[Step 19740] Loss: 9.42e+07 -1.0667924880981445 0.1193651407957077\n",
      "[Step 19741] Loss: 9.46e+07 -1.0669299364089966 0.11934368312358856\n",
      "[Step 19742] Loss: 9.45e+07 -1.0671108961105347 0.11929335445165634\n",
      "[Step 19743] Loss: 9.41e+07 -1.0672798156738281 0.11927519738674164\n",
      "[Step 19744] Loss: 9.47e+07 -1.0674136877059937 0.11924879252910614\n",
      "[Step 19745] Loss: 9.44e+07 -1.067522644996643 0.11925292015075684\n",
      "[Step 19746] Loss: 9.47e+07 -1.0676600933074951 0.11920011043548584\n",
      "[Step 19747] Loss: 9.57e+07 -1.0676791667938232 0.11917700618505478\n",
      "[Step 19748] Loss: 9.45e+07 -1.0676758289337158 0.11916215717792511\n",
      "[Step 19749] Loss: 9.45e+07 -1.0676833391189575 0.11914317309856415\n",
      "[Step 19750] Loss: 9.68e+07 -1.0679521560668945 0.1190953180193901\n",
      "[Step 19751] Loss: 9.44e+07 -1.068286418914795 0.11903590708971024\n",
      "[Step 19752] Loss: 9.48e+07 -1.0687439441680908 0.11895257234573364\n",
      "[Step 19753] Loss: 9.46e+07 -1.0691618919372559 0.11887253075838089\n",
      "[Step 19754] Loss: 9.51e+07 -1.0695775747299194 0.11879414319992065\n",
      "[Step 19755] Loss: 9.51e+07 -1.0699928998947144 0.1187182292342186\n",
      "[Step 19756] Loss: 9.46e+07 -1.0704363584518433 0.11865387111902237\n",
      "[Step 19757] Loss: 9.47e+07 -1.070887565612793 0.11857631057500839\n",
      "[Step 19758] Loss: 9.42e+07 -1.0712441205978394 0.11851029843091965\n",
      "[Step 19759] Loss: 9.45e+07 -1.0715287923812866 0.1184748187661171\n",
      "[Step 19760] Loss: 9.45e+07 -1.0717166662216187 0.1184220090508461\n",
      "[Step 19761] Loss: 9.44e+07 -1.071855902671814 0.11835847049951553\n",
      "[Step 19762] Loss: 9.48e+07 -1.0718774795532227 0.11833866685628891\n",
      "[Step 19763] Loss: 9.43e+07 -1.0718382596969604 0.11831721663475037\n",
      "[Step 19764] Loss: 9.50e+07 -1.0717108249664307 0.11831638962030411\n",
      "[Step 19765] Loss: 9.57e+07 -1.0714497566223145 0.11836259812116623\n",
      "[Step 19766] Loss: 9.45e+07 -1.0712339878082275 0.11835682392120361\n",
      "[Step 19767] Loss: 9.44e+07 -1.0711607933044434 0.11835352331399918\n",
      "[Step 19768] Loss: 9.43e+07 -1.0710811614990234 0.11835434287786484\n",
      "[Step 19769] Loss: 9.42e+07 -1.0709861516952515 0.1183510422706604\n",
      "[Step 19770] Loss: 9.40e+07 -1.0709260702133179 0.11835269629955292\n",
      "[Step 19771] Loss: 9.50e+07 -1.0707204341888428 0.11834609508514404\n",
      "[Step 19772] Loss: 9.49e+07 -1.0706472396850586 0.1183287650346756\n",
      "[Step 19773] Loss: 9.56e+07 -1.0708469152450562 0.11828503757715225\n",
      "[Step 19774] Loss: 9.39e+07 -1.0709244012832642 0.11825285106897354\n",
      "[Step 19775] Loss: 9.57e+07 -1.0711363554000854 0.11819014698266983\n",
      "[Step 19776] Loss: 9.42e+07 -1.0712878704071045 0.11818766593933105\n",
      "[Step 19777] Loss: 9.45e+07 -1.0714117288589478 0.1181299090385437\n",
      "[Step 19778] Loss: 9.38e+07 -1.0714962482452393 0.11808370053768158\n",
      "[Step 19779] Loss: 9.44e+07 -1.0716904401779175 0.11799788475036621\n",
      "[Step 19780] Loss: 9.43e+07 -1.07181978225708 0.11795580387115479\n",
      "[Step 19781] Loss: 9.47e+07 -1.0719387531280518 0.1179393008351326\n",
      "[Step 19782] Loss: 9.50e+07 -1.0719282627105713 0.11792445182800293\n",
      "[Step 19783] Loss: 9.44e+07 -1.0718785524368286 0.11792362481355667\n",
      "[Step 19784] Loss: 9.44e+07 -1.0717889070510864 0.11792032420635223\n",
      "[Step 19785] Loss: 9.44e+07 -1.0718297958374023 0.11789639294147491\n",
      "[Step 19786] Loss: 9.49e+07 -1.0717628002166748 0.117855966091156\n",
      "[Step 19787] Loss: 9.40e+07 -1.0716849565505981 0.11785183846950531\n",
      "[Step 19788] Loss: 9.50e+07 -1.0715583562850952 0.1178683415055275\n",
      "[Step 19789] Loss: 9.60e+07 -1.0717546939849854 0.1178196594119072\n",
      "[Step 19790] Loss: 9.45e+07 -1.0719990730285645 0.117789126932621\n",
      "[Step 19791] Loss: 9.45e+07 -1.072324275970459 0.11774539202451706\n",
      "[Step 19792] Loss: 9.56e+07 -1.0725542306900024 0.11772311478853226\n",
      "[Step 19793] Loss: 9.45e+07 -1.0727970600128174 0.1176736056804657\n",
      "[Step 19794] Loss: 9.58e+07 -1.073167324066162 0.1175902709364891\n",
      "[Step 19795] Loss: 9.46e+07 -1.0734906196594238 0.1175457090139389\n",
      "[Step 19796] Loss: 9.45e+07 -1.0738554000854492 0.11746320128440857\n",
      "[Step 19797] Loss: 9.47e+07 -1.074130654335022 0.11741369217634201\n",
      "[Step 19798] Loss: 9.45e+07 -1.0743882656097412 0.11737161129713058\n",
      "[Step 19799] Loss: 9.45e+07 -1.074544906616211 0.11731301993131638\n",
      "[Step 19800] Loss: 9.39e+07 -1.074694037437439 0.11725691705942154\n",
      "[Step 19801] Loss: 9.45e+07 -1.0748555660247803 0.11720575392246246\n",
      "[Step 19802] Loss: 9.50e+07 -1.0751748085021973 0.1171298399567604\n",
      "[Step 19803] Loss: 9.38e+07 -1.0754228830337524 0.11707951128482819\n",
      "[Step 19804] Loss: 9.47e+07 -1.0757086277008057 0.117010198533535\n",
      "[Step 19805] Loss: 9.47e+07 -1.0759817361831665 0.11693675816059113\n",
      "[Step 19806] Loss: 9.49e+07 -1.076120376586914 0.11689715087413788\n",
      "[Step 19807] Loss: 9.46e+07 -1.0762985944747925 0.11683279275894165\n",
      "[Step 19808] Loss: 9.43e+07 -1.0765657424926758 0.1167667806148529\n",
      "[Step 19809] Loss: 9.41e+07 -1.0767309665679932 0.11671892553567886\n",
      "[Step 19810] Loss: 9.35e+07 -1.0768932104110718 0.11667189002037048\n",
      "[Step 19811] Loss: 9.40e+07 -1.0770213603973389 0.1166430115699768\n",
      "[Step 19812] Loss: 9.41e+07 -1.0771870613098145 0.11659267544746399\n",
      "[Step 19813] Loss: 9.45e+07 -1.077283501625061 0.11656875163316727\n",
      "[Step 19814] Loss: 9.47e+07 -1.077399492263794 0.11651098728179932\n",
      "[Step 19815] Loss: 9.44e+07 -1.0775803327560425 0.1164524033665657\n",
      "[Step 19816] Loss: 9.48e+07 -1.0777462720870972 0.11642682552337646\n",
      "[Step 19817] Loss: 9.42e+07 -1.0778440237045288 0.11639381945133209\n",
      "[Step 19818] Loss: 9.52e+07 -1.0780068635940552 0.11635256558656693\n",
      "[Step 19819] Loss: 9.53e+07 -1.078396201133728 0.11625602096319199\n",
      "[Step 19820] Loss: 9.41e+07 -1.0786230564117432 0.1162131130695343\n",
      "[Step 19821] Loss: 9.49e+07 -1.0787237882614136 0.11618753522634506\n",
      "[Step 19822] Loss: 9.49e+07 -1.0787581205368042 0.1161726862192154\n",
      "[Step 19823] Loss: 9.58e+07 -1.079121708869934 0.1161017194390297\n",
      "[Step 19824] Loss: 9.48e+07 -1.0795831680297852 0.11602910608053207\n",
      "[Step 19825] Loss: 9.40e+07 -1.0800185203552246 0.11598125100135803\n",
      "[Step 19826] Loss: 9.44e+07 -1.0803741216659546 0.11593256890773773\n",
      "[Step 19827] Loss: 9.42e+07 -1.0807387828826904 0.11590533703565598\n",
      "[Step 19828] Loss: 9.52e+07 -1.081010103225708 0.11587151139974594\n",
      "[Step 19829] Loss: 9.50e+07 -1.0812575817108154 0.11584675312042236\n",
      "[Step 19830] Loss: 9.40e+07 -1.0814552307128906 0.11581870168447495\n",
      "[Step 19831] Loss: 9.54e+07 -1.0815373659133911 0.11582117527723312\n",
      "[Step 19832] Loss: 9.41e+07 -1.0816009044647217 0.1158013716340065\n",
      "[Step 19833] Loss: 9.38e+07 -1.0816487073898315 0.11583355069160461\n",
      "[Step 19834] Loss: 9.55e+07 -1.0819085836410522 0.1157832220196724\n",
      "[Step 19835] Loss: 9.45e+07 -1.082051396369934 0.11577001959085464\n",
      "[Step 19836] Loss: 9.43e+07 -1.0821406841278076 0.11575433611869812\n",
      "[Step 19837] Loss: 9.41e+07 -1.0822452306747437 0.11572381108999252\n",
      "[Step 19838] Loss: 9.46e+07 -1.0824602842330933 0.11568503081798553\n",
      "[Step 19839] Loss: 9.45e+07 -1.0827003717422485 0.11563139408826828\n",
      "[Step 19840] Loss: 9.43e+07 -1.0829578638076782 0.11560086160898209\n",
      "[Step 19841] Loss: 9.50e+07 -1.0830214023590088 0.11558105796575546\n",
      "[Step 19842] Loss: 9.45e+07 -1.0830023288726807 0.1155662089586258\n",
      "[Step 19843] Loss: 9.43e+07 -1.0828557014465332 0.11559261381626129\n",
      "[Step 19844] Loss: 9.42e+07 -1.0826966762542725 0.1156066432595253\n",
      "[Step 19845] Loss: 9.46e+07 -1.082383155822754 0.11562561988830566\n",
      "[Step 19846] Loss: 9.43e+07 -1.0820130109786987 0.11569657921791077\n",
      "[Step 19847] Loss: 9.54e+07 -1.0815520286560059 0.11578982323408127\n",
      "[Step 19848] Loss: 9.51e+07 -1.0811865329742432 0.11583355069160461\n",
      "[Step 19849] Loss: 9.43e+07 -1.0807485580444336 0.11587893217802048\n",
      "[Step 19850] Loss: 9.49e+07 -1.0803016424179077 0.1159251406788826\n",
      "[Step 19851] Loss: 9.41e+07 -1.0799283981323242 0.11596722155809402\n",
      "[Step 19852] Loss: 9.52e+07 -1.0795549154281616 0.11599280685186386\n",
      "[Step 19853] Loss: 9.59e+07 -1.0791202783584595 0.11605881154537201\n",
      "[Step 19854] Loss: 9.46e+07 -1.0786771774291992 0.11609017103910446\n",
      "[Step 19855] Loss: 9.37e+07 -1.0782874822616577 0.11611904948949814\n",
      "[Step 19856] Loss: 9.70e+07 -1.0783551931381226 0.11608274281024933\n",
      "[Step 19857] Loss: 9.45e+07 -1.0783450603485107 0.11606129258871078\n",
      "[Step 19858] Loss: 9.45e+07 -1.078357458114624 0.11603323370218277\n",
      "[Step 19859] Loss: 9.48e+07 -1.0784415006637573 0.11600105464458466\n",
      "[Step 19860] Loss: 9.47e+07 -1.0784729719161987 0.11597877740859985\n",
      "[Step 19861] Loss: 9.44e+07 -1.0783997774124146 0.11598290503025055\n",
      "[Step 19862] Loss: 9.54e+07 -1.0782607793807983 0.11601673066616058\n",
      "[Step 19863] Loss: 9.40e+07 -1.0780909061431885 0.11601673066616058\n",
      "[Step 19864] Loss: 9.55e+07 -1.0778083801269531 0.11603653430938721\n",
      "[Step 19865] Loss: 9.38e+07 -1.0775890350341797 0.11602333188056946\n",
      "[Step 19866] Loss: 9.40e+07 -1.0773881673812866 0.11600930988788605\n",
      "[Step 19867] Loss: 9.51e+07 -1.0772786140441895 0.11602333188056946\n",
      "[Step 19868] Loss: 9.41e+07 -1.0771065950393677 0.11603406071662903\n",
      "[Step 19869] Loss: 9.46e+07 -1.077012300491333 0.11602745950222015\n",
      "[Step 19870] Loss: 9.45e+07 -1.076955795288086 0.11600930988788605\n",
      "[Step 19871] Loss: 9.43e+07 -1.076922059059143 0.11600848287343979\n",
      "[Step 19872] Loss: 9.37e+07 -1.076859951019287 0.11599528044462204\n",
      "[Step 19873] Loss: 9.59e+07 -1.0770642757415771 0.11598290503025055\n",
      "[Step 19874] Loss: 9.44e+07 -1.0772243738174438 0.11598125100135803\n",
      "[Step 19875] Loss: 9.41e+07 -1.0773030519485474 0.1159655749797821\n",
      "[Step 19876] Loss: 9.44e+07 -1.0774005651474 0.11593421548604965\n",
      "[Step 19877] Loss: 9.44e+07 -1.0774739980697632 0.11591193825006485\n",
      "[Step 19878] Loss: 9.39e+07 -1.0774905681610107 0.11591276526451111\n",
      "[Step 19879] Loss: 9.42e+07 -1.077567458152771 0.11591523885726929\n",
      "[Step 19880] Loss: 9.42e+07 -1.0775337219238281 0.11591111868619919\n",
      "[Step 19881] Loss: 9.50e+07 -1.0773546695709229 0.11593834310770035\n",
      "[Step 19882] Loss: 9.43e+07 -1.077187418937683 0.1159474179148674\n",
      "[Step 19883] Loss: 9.37e+07 -1.0769996643066406 0.11599528044462204\n",
      "[Step 19884] Loss: 9.50e+07 -1.0769739151000977 0.11602580547332764\n",
      "[Step 19885] Loss: 9.51e+07 -1.0770595073699951 0.1160183846950531\n",
      "[Step 19886] Loss: 9.49e+07 -1.0773138999938965 0.1159878522157669\n",
      "[Step 19887] Loss: 9.40e+07 -1.0774511098861694 0.11599445343017578\n",
      "[Step 19888] Loss: 9.42e+07 -1.077498197555542 0.11598537862300873\n",
      "[Step 19889] Loss: 9.48e+07 -1.0775469541549683 0.1159779503941536\n",
      "[Step 19890] Loss: 9.49e+07 -1.0777583122253418 0.1159432977437973\n",
      "[Step 19891] Loss: 9.44e+07 -1.0779682397842407 0.11589131504297256\n",
      "[Step 19892] Loss: 9.46e+07 -1.0780977010726929 0.11586160957813263\n",
      "[Step 19893] Loss: 9.51e+07 -1.0781925916671753 0.11584758013486862\n",
      "[Step 19894] Loss: 9.41e+07 -1.0782493352890015 0.1158319041132927\n",
      "[Step 19895] Loss: 9.53e+07 -1.0784664154052734 0.11579229682683945\n",
      "[Step 19896] Loss: 9.45e+07 -1.0786412954330444 0.115760937333107\n",
      "[Step 19897] Loss: 9.49e+07 -1.078722357749939 0.11575929075479507\n",
      "[Step 19898] Loss: 9.49e+07 -1.0789602994918823 0.11572133004665375\n",
      "[Step 19899] Loss: 9.36e+07 -1.079189658164978 0.11567924916744232\n",
      "[Step 19900] Loss: 9.38e+07 -1.0794250965118408 0.11564294248819351\n",
      "[Step 19901] Loss: 9.46e+07 -1.0796751976013184 0.11560498923063278\n",
      "[Step 19902] Loss: 9.41e+07 -1.0799202919006348 0.11556703597307205\n",
      "[Step 19903] Loss: 9.40e+07 -1.0801968574523926 0.11553815007209778\n",
      "[Step 19904] Loss: 9.43e+07 -1.0804481506347656 0.11551009863615036\n",
      "[Step 19905] Loss: 9.47e+07 -1.0808380842208862 0.11547131836414337\n",
      "[Step 19906] Loss: 9.39e+07 -1.0811635255813599 0.11540200561285019\n",
      "[Step 19907] Loss: 9.56e+07 -1.0817681550979614 0.11530134081840515\n",
      "[Step 19908] Loss: 9.40e+07 -1.0822913646697998 0.11521635204553604\n",
      "[Step 19909] Loss: 9.37e+07 -1.0828300714492798 0.11513136327266693\n",
      "[Step 19910] Loss: 9.49e+07 -1.08349609375 0.11501501500606537\n",
      "[Step 19911] Loss: 9.48e+07 -1.0840991735458374 0.11491765081882477\n",
      "[Step 19912] Loss: 9.40e+07 -1.0846712589263916 0.11485741287469864\n",
      "[Step 19913] Loss: 9.55e+07 -1.0853607654571533 0.11477655172348022\n",
      "[Step 19914] Loss: 9.42e+07 -1.0859546661376953 0.11468660831451416\n",
      "[Step 19915] Loss: 9.42e+07 -1.0864613056182861 0.11460410058498383\n",
      "[Step 19916] Loss: 9.61e+07 -1.087187647819519 0.11452653259038925\n",
      "[Step 19917] Loss: 9.44e+07 -1.0877254009246826 0.1144729033112526\n",
      "[Step 19918] Loss: 9.48e+07 -1.0883138179779053 0.11438791453838348\n",
      "[Step 19919] Loss: 9.49e+07 -1.0887972116470337 0.11434005200862885\n",
      "[Step 19920] Loss: 9.43e+07 -1.0891785621643066 0.11423525959253311\n",
      "[Step 19921] Loss: 9.41e+07 -1.0894776582717896 0.11416594684123993\n",
      "[Step 19922] Loss: 9.57e+07 -1.0895414352416992 0.11412551999092102\n",
      "[Step 19923] Loss: 9.65e+07 -1.0899951457977295 0.11404795944690704\n",
      "[Step 19924] Loss: 9.44e+07 -1.0904020071029663 0.1139637902379036\n",
      "[Step 19925] Loss: 9.46e+07 -1.0907846689224243 0.11390437930822372\n",
      "[Step 19926] Loss: 9.42e+07 -1.0911343097686768 0.1138400211930275\n",
      "[Step 19927] Loss: 9.56e+07 -1.0917061567306519 0.11375420540571213\n",
      "[Step 19928] Loss: 9.49e+07 -1.0920771360397339 0.11369479447603226\n",
      "[Step 19929] Loss: 9.42e+07 -1.0924019813537598 0.1136370375752449\n",
      "[Step 19930] Loss: 9.41e+07 -1.0927282571792603 0.11359082907438278\n",
      "[Step 19931] Loss: 9.51e+07 -1.093108892440796 0.1135256439447403\n",
      "[Step 19932] Loss: 9.39e+07 -1.0934568643569946 0.11348356306552887\n",
      "[Step 19933] Loss: 9.50e+07 -1.093652367591858 0.11343982815742493\n",
      "[Step 19934] Loss: 9.46e+07 -1.0938891172409058 0.11340682208538055\n",
      "[Step 19935] Loss: 9.54e+07 -1.0943071842193604 0.11337711662054062\n",
      "[Step 19936] Loss: 9.40e+07 -1.0946528911590576 0.11330781131982803\n",
      "[Step 19937] Loss: 9.51e+07 -1.0949287414550781 0.11326407641172409\n",
      "[Step 19938] Loss: 9.55e+07 -1.0953658819198608 0.11319063603878021\n",
      "[Step 19939] Loss: 9.50e+07 -1.0958493947982788 0.1131238043308258\n",
      "[Step 19940] Loss: 9.45e+07 -1.0963016748428345 0.11305119097232819\n",
      "[Step 19941] Loss: 9.45e+07 -1.0966967344284058 0.11299920827150345\n",
      "[Step 19942] Loss: 9.55e+07 -1.0971794128417969 0.11290266364812851\n",
      "[Step 19943] Loss: 9.41e+07 -1.0977026224136353 0.11281684786081314\n",
      "[Step 19944] Loss: 9.39e+07 -1.098172664642334 0.11274506151676178\n",
      "[Step 19945] Loss: 9.43e+07 -1.098564863204956 0.11268895864486694\n",
      "[Step 19946] Loss: 9.43e+07 -1.098835825920105 0.11264852434396744\n",
      "[Step 19947] Loss: 9.46e+07 -1.0991584062576294 0.11258663982152939\n",
      "[Step 19948] Loss: 9.45e+07 -1.099388599395752 0.1125561073422432\n",
      "[Step 19949] Loss: 9.50e+07 -1.0996994972229004 0.11249835044145584\n",
      "[Step 19950] Loss: 9.39e+07 -1.0999960899353027 0.11243811249732971\n",
      "[Step 19951] Loss: 9.41e+07 -1.1002691984176636 0.11237622797489166\n",
      "[Step 19952] Loss: 9.44e+07 -1.1004496812820435 0.11233992129564285\n",
      "[Step 19953] Loss: 9.45e+07 -1.1006934642791748 0.1122821643948555\n",
      "[Step 19954] Loss: 9.48e+07 -1.1009602546691895 0.11223512887954712\n",
      "[Step 19955] Loss: 9.38e+07 -1.101211667060852 0.112188920378685\n",
      "[Step 19956] Loss: 9.43e+07 -1.1014299392700195 0.11216004192829132\n",
      "[Step 19957] Loss: 9.40e+07 -1.1015211343765259 0.11215261369943619\n",
      "[Step 19958] Loss: 9.42e+07 -1.101689100265503 0.11210393160581589\n",
      "[Step 19959] Loss: 9.40e+07 -1.1017247438430786 0.11209733039140701\n",
      "[Step 19960] Loss: 9.44e+07 -1.1019477844238281 0.11207835376262665\n",
      "[Step 19961] Loss: 9.49e+07 -1.102168083190918 0.11201481521129608\n",
      "[Step 19962] Loss: 9.45e+07 -1.102333903312683 0.11197438836097717\n",
      "[Step 19963] Loss: 9.42e+07 -1.1024473905563354 0.11193065345287323\n",
      "[Step 19964] Loss: 9.36e+07 -1.1025596857070923 0.1119009479880333\n",
      "[Step 19965] Loss: 9.46e+07 -1.1025583744049072 0.11189104616641998\n",
      "[Step 19966] Loss: 9.59e+07 -1.1028270721435547 0.11184566468000412\n",
      "[Step 19967] Loss: 9.41e+07 -1.1030758619308472 0.11178790777921677\n",
      "[Step 19968] Loss: 9.40e+07 -1.1033037900924683 0.11176232993602753\n",
      "[Step 19969] Loss: 9.47e+07 -1.1036431789398193 0.11170456558465958\n",
      "[Step 19970] Loss: 9.45e+07 -1.1038240194320679 0.11166661232709885\n",
      "[Step 19971] Loss: 9.51e+07 -1.103891134262085 0.11166165769100189\n",
      "[Step 19972] Loss: 9.60e+07 -1.1039159297943115 0.11165505647659302\n",
      "[Step 19973] Loss: 9.42e+07 -1.1038448810577393 0.11164680868387222\n",
      "[Step 19974] Loss: 9.47e+07 -1.1036258935928345 0.11166825890541077\n",
      "[Step 19975] Loss: 9.43e+07 -1.1035395860671997 0.11165258288383484\n",
      "[Step 19976] Loss: 9.53e+07 -1.1036869287490845 0.11162617802619934\n",
      "[Step 19977] Loss: 9.46e+07 -1.103933572769165 0.11160554736852646\n",
      "[Step 19978] Loss: 9.44e+07 -1.1042534112930298 0.11156759411096573\n",
      "[Step 19979] Loss: 9.41e+07 -1.1045271158218384 0.11150570958852768\n",
      "[Step 19980] Loss: 9.37e+07 -1.1047266721725464 0.11147435009479523\n",
      "[Step 19981] Loss: 9.47e+07 -1.104899287223816 0.1114545539021492\n",
      "[Step 19982] Loss: 9.44e+07 -1.104933738708496 0.11142566800117493\n",
      "[Step 19983] Loss: 9.42e+07 -1.1049083471298218 0.11140256375074387\n",
      "[Step 19984] Loss: 9.56e+07 -1.1047686338424683 0.11140834540128708\n",
      "[Step 19985] Loss: 9.53e+07 -1.1045563220977783 0.11142484843730927\n",
      "[Step 19986] Loss: 9.45e+07 -1.1041934490203857 0.11147187650203705\n",
      "[Step 19987] Loss: 9.43e+07 -1.103847861289978 0.11149498075246811\n",
      "[Step 19988] Loss: 9.44e+07 -1.1035776138305664 0.11151725798845291\n",
      "[Step 19989] Loss: 9.43e+07 -1.103367805480957 0.1115337610244751\n",
      "[Step 19990] Loss: 9.53e+07 -1.1032061576843262 0.11153211444616318\n",
      "[Step 19991] Loss: 9.38e+07 -1.1030393838882446 0.1115337610244751\n",
      "[Step 19992] Loss: 9.40e+07 -1.1029146909713745 0.1115519180893898\n",
      "[Step 19993] Loss: 9.41e+07 -1.1027976274490356 0.11156429350376129\n",
      "[Step 19994] Loss: 9.42e+07 -1.1026250123977661 0.11156842112541199\n",
      "[Step 19995] Loss: 9.45e+07 -1.102421522140503 0.11159894615411758\n",
      "[Step 19996] Loss: 9.45e+07 -1.1022685766220093 0.11161214858293533\n",
      "[Step 19997] Loss: 9.43e+07 -1.1021742820739746 0.11162617802619934\n",
      "[Step 19998] Loss: 9.39e+07 -1.1019885540008545 0.11162453144788742\n",
      "[Step 19999] Loss: 9.40e+07 -1.101875901222229 0.11165918409824371\n",
      "[Step 20000] Loss: 9.37e+07 -1.1017276048660278 0.11166413873434067\n",
      "[Step 20001] Loss: 9.45e+07 -1.1015523672103882 0.11168971657752991\n",
      "[Step 20002] Loss: 9.40e+07 -1.1013516187667847 0.11170291900634766\n",
      "[Step 20003] Loss: 9.39e+07 -1.1011316776275635 0.1117284968495369\n",
      "[Step 20004] Loss: 9.54e+07 -1.101095199584961 0.11173014342784882\n",
      "[Step 20005] Loss: 9.45e+07 -1.1010040044784546 0.11171364039182663\n",
      "[Step 20006] Loss: 9.53e+07 -1.1011096239089966 0.11168311536312103\n",
      "[Step 20007] Loss: 9.39e+07 -1.1011226177215576 0.11168558895587921\n",
      "[Step 20008] Loss: 9.47e+07 -1.1011489629745483 0.11167073994874954\n",
      "[Step 20009] Loss: 9.45e+07 -1.101264476776123 0.1116410344839096\n",
      "[Step 20010] Loss: 9.39e+07 -1.101296305656433 0.11165010929107666\n",
      "[Step 20011] Loss: 9.53e+07 -1.1011801958084106 0.11170456558465958\n",
      "[Step 20012] Loss: 9.46e+07 -1.1010053157806396 0.11174499988555908\n",
      "[Step 20013] Loss: 9.54e+07 -1.1010305881500244 0.11177800595760345\n",
      "[Step 20014] Loss: 9.61e+07 -1.1009516716003418 0.11177470535039902\n",
      "[Step 20015] Loss: 9.44e+07 -1.1009941101074219 0.11175572872161865\n",
      "[Step 20016] Loss: 9.46e+07 -1.1009644269943237 0.11175160109996796\n",
      "[Step 20017] Loss: 9.47e+07 -1.1008927822113037 0.11175654828548431\n",
      "[Step 20018] Loss: 9.42e+07 -1.1009613275527954 0.11176397651433945\n",
      "[Step 20019] Loss: 9.44e+07 -1.1009509563446045 0.11178295314311981\n",
      "[Step 20020] Loss: 9.47e+07 -1.1010513305664062 0.11174912750720978\n",
      "[Step 20021] Loss: 9.47e+07 -1.1012892723083496 0.11171364039182663\n",
      "[Step 20022] Loss: 9.43e+07 -1.1015232801437378 0.1116715595126152\n",
      "[Step 20023] Loss: 9.41e+07 -1.10172700881958 0.11165258288383484\n",
      "[Step 20024] Loss: 9.41e+07 -1.101954698562622 0.11161297559738159\n",
      "[Step 20025] Loss: 9.46e+07 -1.1020158529281616 0.11159152537584305\n",
      "[Step 20026] Loss: 9.35e+07 -1.1020901203155518 0.11155934631824493\n",
      "[Step 20027] Loss: 9.59e+07 -1.1020197868347168 0.1115601658821106\n",
      "[Step 20028] Loss: 9.42e+07 -1.101854681968689 0.1115865707397461\n",
      "[Step 20029] Loss: 9.48e+07 -1.101798176765442 0.11158409714698792\n",
      "[Step 20030] Loss: 9.47e+07 -1.1017323732376099 0.11159234493970871\n",
      "[Step 20031] Loss: 9.44e+07 -1.1016587018966675 0.11156594753265381\n",
      "[Step 20032] Loss: 9.39e+07 -1.1016216278076172 0.11155769228935242\n",
      "[Step 20033] Loss: 9.52e+07 -1.1015191078186035 0.11155439168214798\n",
      "[Step 20034] Loss: 9.48e+07 -1.1013716459274292 0.11153871566057205\n",
      "[Step 20035] Loss: 9.42e+07 -1.1012606620788574 0.11156181991100311\n",
      "[Step 20036] Loss: 9.63e+07 -1.1009560823440552 0.11158987134695053\n",
      "[Step 20037] Loss: 9.42e+07 -1.1005935668945312 0.11163607984781265\n",
      "[Step 20038] Loss: 9.43e+07 -1.1002999544143677 0.1116492822766304\n",
      "[Step 20039] Loss: 9.43e+07 -1.100117564201355 0.11166991293430328\n",
      "[Step 20040] Loss: 9.49e+07 -1.1001468896865845 0.11164680868387222\n",
      "[Step 20041] Loss: 9.44e+07 -1.1001561880111694 0.11165423691272736\n",
      "[Step 20042] Loss: 9.48e+07 -1.1000739336013794 0.11166495829820633\n",
      "[Step 20043] Loss: 9.43e+07 -1.0999584197998047 0.11166578531265259\n",
      "[Step 20044] Loss: 9.42e+07 -1.0997768640518188 0.11167898774147034\n",
      "[Step 20045] Loss: 9.32e+07 -1.0995908975601196 0.11169136315584183\n",
      "[Step 20046] Loss: 9.43e+07 -1.0994069576263428 0.11171529442071915\n",
      "[Step 20047] Loss: 9.38e+07 -1.0992246866226196 0.1117161214351654\n",
      "[Step 20048] Loss: 9.42e+07 -1.0990926027297974 0.11173839867115021\n",
      "[Step 20049] Loss: 9.39e+07 -1.098915934562683 0.11178047955036163\n",
      "[Step 20050] Loss: 9.43e+07 -1.0987333059310913 0.11181678622961044\n",
      "[Step 20051] Loss: 9.41e+07 -1.0984879732131958 0.11182916164398193\n",
      "[Step 20052] Loss: 9.37e+07 -1.0981838703155518 0.11184236407279968\n",
      "[Step 20053] Loss: 9.43e+07 -1.0978809595108032 0.11188361793756485\n",
      "[Step 20054] Loss: 9.45e+07 -1.0975605249404907 0.11188691854476929\n",
      "[Step 20055] Loss: 9.36e+07 -1.0972625017166138 0.11191332340240479\n",
      "[Step 20056] Loss: 9.45e+07 -1.0970288515090942 0.11193230748176575\n",
      "[Step 20057] Loss: 9.41e+07 -1.096845269203186 0.11195211112499237\n",
      "[Step 20058] Loss: 9.46e+07 -1.0966771841049194 0.11195623129606247\n",
      "[Step 20059] Loss: 9.47e+07 -1.0965996980667114 0.11196035891771317\n",
      "[Step 20060] Loss: 9.45e+07 -1.0964778661727905 0.11196613311767578\n",
      "[Step 20061] Loss: 9.47e+07 -1.096398949623108 0.11198263615369797\n",
      "[Step 20062] Loss: 9.38e+07 -1.0963588953018188 0.1119859367609024\n",
      "[Step 20063] Loss: 9.64e+07 -1.0967260599136353 0.11193395406007767\n",
      "[Step 20064] Loss: 9.41e+07 -1.097090721130371 0.11188032478094101\n",
      "[Step 20065] Loss: 9.40e+07 -1.0974586009979248 0.11183823645114899\n",
      "[Step 20066] Loss: 9.46e+07 -1.097756266593933 0.11178790777921677\n",
      "[Step 20067] Loss: 9.47e+07 -1.0981292724609375 0.11171446740627289\n",
      "[Step 20068] Loss: 9.63e+07 -1.09883713722229 0.11162123084068298\n",
      "[Step 20069] Loss: 9.48e+07 -1.0996592044830322 0.11148755252361298\n",
      "[Step 20070] Loss: 9.41e+07 -1.1004265546798706 0.11140256375074387\n",
      "[Step 20071] Loss: 9.46e+07 -1.1011252403259277 0.11129942536354065\n",
      "[Step 20072] Loss: 9.44e+07 -1.101841688156128 0.1112070083618164\n",
      "[Step 20073] Loss: 9.41e+07 -1.102556824684143 0.11109066754579544\n",
      "[Step 20074] Loss: 9.42e+07 -1.1032729148864746 0.11098092049360275\n",
      "[Step 20075] Loss: 9.45e+07 -1.1039656400680542 0.11085879802703857\n",
      "[Step 20076] Loss: 9.52e+07 -1.1044577360153198 0.11077463626861572\n",
      "[Step 20077] Loss: 9.48e+07 -1.1048381328582764 0.11070532351732254\n",
      "[Step 20078] Loss: 9.52e+07 -1.105255126953125 0.11064673960208893\n",
      "[Step 20079] Loss: 9.44e+07 -1.105618953704834 0.11057578027248383\n",
      "[Step 20080] Loss: 9.48e+07 -1.106046199798584 0.11050894111394882\n",
      "[Step 20081] Loss: 9.42e+07 -1.1064872741699219 0.11046191304922104\n",
      "[Step 20082] Loss: 9.47e+07 -1.1067980527877808 0.11040744930505753\n",
      "[Step 20083] Loss: 9.47e+07 -1.1070542335510254 0.11034886538982391\n",
      "[Step 20084] Loss: 9.40e+07 -1.1073905229568481 0.11028037965297699\n",
      "[Step 20085] Loss: 9.43e+07 -1.1077224016189575 0.11022509634494781\n",
      "[Step 20086] Loss: 9.47e+07 -1.1079519987106323 0.11017724126577377\n",
      "[Step 20087] Loss: 9.48e+07 -1.1082630157470703 0.11014588177204132\n",
      "[Step 20088] Loss: 9.45e+07 -1.1085587739944458 0.11009225249290466\n",
      "[Step 20089] Loss: 9.42e+07 -1.1088624000549316 0.11005346477031708\n",
      "[Step 20090] Loss: 9.61e+07 -1.1093937158584595 0.10995940119028091\n",
      "[Step 20091] Loss: 9.40e+07 -1.1099311113357544 0.10987358540296555\n",
      "[Step 20092] Loss: 9.42e+07 -1.1104971170425415 0.10977457463741302\n",
      "[Step 20093] Loss: 9.44e+07 -1.110950231552124 0.1097060889005661\n",
      "[Step 20094] Loss: 9.43e+07 -1.1114163398742676 0.10963842272758484\n",
      "[Step 20095] Loss: 9.41e+07 -1.1117899417877197 0.10958313941955566\n",
      "[Step 20096] Loss: 9.42e+07 -1.1121773719787598 0.10953032970428467\n",
      "[Step 20097] Loss: 9.51e+07 -1.1124275922775269 0.1095113530755043\n",
      "[Step 20098] Loss: 9.41e+07 -1.1124948263168335 0.10948412120342255\n",
      "[Step 20099] Loss: 9.45e+07 -1.1126667261123657 0.10945441573858261\n",
      "[Step 20100] Loss: 9.48e+07 -1.1126691102981567 0.10943709313869476\n",
      "[Step 20101] Loss: 9.52e+07 -1.1128584146499634 0.10940243303775787\n",
      "[Step 20102] Loss: 9.50e+07 -1.1131609678268433 0.109343022108078\n",
      "[Step 20103] Loss: 9.57e+07 -1.1136314868927002 0.1092761904001236\n",
      "[Step 20104] Loss: 9.39e+07 -1.11412513256073 0.10920192301273346\n",
      "[Step 20105] Loss: 9.46e+07 -1.1145923137664795 0.10908805578947067\n",
      "[Step 20106] Loss: 9.48e+07 -1.115059733390808 0.10899976640939713\n",
      "[Step 20107] Loss: 9.42e+07 -1.115368127822876 0.10894200950860977\n",
      "[Step 20108] Loss: 9.44e+07 -1.1155709028244019 0.10891973227262497\n",
      "[Step 20109] Loss: 9.44e+07 -1.115800380706787 0.10888507217168808\n",
      "[Step 20110] Loss: 9.41e+07 -1.1159271001815796 0.10887269675731659\n",
      "[Step 20111] Loss: 9.43e+07 -1.1159940958023071 0.10885041952133179\n",
      "[Step 20112] Loss: 9.42e+07 -1.116084337234497 0.10883556306362152\n",
      "[Step 20113] Loss: 9.42e+07 -1.116265058517456 0.10880421102046967\n",
      "[Step 20114] Loss: 9.42e+07 -1.116400122642517 0.10875800251960754\n",
      "[Step 20115] Loss: 9.43e+07 -1.116628885269165 0.10871509462594986\n",
      "[Step 20116] Loss: 9.38e+07 -1.1167888641357422 0.10869446396827698\n",
      "[Step 20117] Loss: 9.40e+07 -1.1168936491012573 0.10864990949630737\n",
      "[Step 20118] Loss: 9.41e+07 -1.1171343326568604 0.10858389735221863\n",
      "[Step 20119] Loss: 9.47e+07 -1.117546558380127 0.1085195392370224\n",
      "[Step 20120] Loss: 9.55e+07 -1.1180665493011475 0.10845105350017548\n",
      "[Step 20121] Loss: 9.39e+07 -1.1184788942337036 0.10838256776332855\n",
      "[Step 20122] Loss: 9.46e+07 -1.1188585758209229 0.1083206832408905\n",
      "[Step 20123] Loss: 9.41e+07 -1.1192164421081543 0.10826291888952255\n",
      "[Step 20124] Loss: 9.40e+07 -1.119585394859314 0.10819113254547119\n",
      "[Step 20125] Loss: 9.46e+07 -1.1200082302093506 0.10815729945898056\n",
      "[Step 20126] Loss: 9.44e+07 -1.1204017400741577 0.10809541493654251\n",
      "[Step 20127] Loss: 9.40e+07 -1.1207382678985596 0.10804178565740585\n",
      "[Step 20128] Loss: 9.38e+07 -1.1209702491760254 0.10800877958536148\n",
      "[Step 20129] Loss: 9.42e+07 -1.121191143989563 0.10797660052776337\n",
      "[Step 20130] Loss: 9.43e+07 -1.121489405632019 0.10793039202690125\n",
      "[Step 20131] Loss: 9.46e+07 -1.121700644493103 0.10789655894041061\n",
      "[Step 20132] Loss: 9.42e+07 -1.1217893362045288 0.10789243131875992\n",
      "[Step 20133] Loss: 9.43e+07 -1.121820330619812 0.10787428170442581\n",
      "[Step 20134] Loss: 9.43e+07 -1.121899962425232 0.10784704983234406\n",
      "[Step 20135] Loss: 9.43e+07 -1.1220113039016724 0.10782559961080551\n",
      "[Step 20136] Loss: 9.41e+07 -1.1220639944076538 0.10781652480363846\n",
      "[Step 20137] Loss: 9.49e+07 -1.1222028732299805 0.10777773708105087\n",
      "[Step 20138] Loss: 9.43e+07 -1.122223973274231 0.10776948928833008\n",
      "[Step 20139] Loss: 9.50e+07 -1.1221505403518677 0.10775958746671677\n",
      "[Step 20140] Loss: 9.45e+07 -1.122084140777588 0.10776041448116302\n",
      "[Step 20141] Loss: 9.43e+07 -1.1219127178192139 0.10776371508836746\n",
      "[Step 20142] Loss: 9.40e+07 -1.1217020750045776 0.10778021812438965\n",
      "[Step 20143] Loss: 9.44e+07 -1.1214768886566162 0.10779836773872375\n",
      "[Step 20144] Loss: 9.44e+07 -1.121172547340393 0.10784704983234406\n",
      "[Step 20145] Loss: 9.39e+07 -1.1208934783935547 0.10788501054048538\n",
      "[Step 20146] Loss: 9.48e+07 -1.120559573173523 0.10793451964855194\n",
      "[Step 20147] Loss: 9.41e+07 -1.1202157735824585 0.10797742009162903\n",
      "[Step 20148] Loss: 9.49e+07 -1.1200873851776123 0.10799144953489304\n",
      "[Step 20149] Loss: 9.39e+07 -1.1199405193328857 0.10802362859249115\n",
      "[Step 20150] Loss: 9.43e+07 -1.1198570728302002 0.10803601145744324\n",
      "[Step 20151] Loss: 9.49e+07 -1.1198371648788452 0.10804673284292221\n",
      "[Step 20152] Loss: 9.41e+07 -1.119925856590271 0.10801290720701218\n",
      "[Step 20153] Loss: 9.48e+07 -1.1198915243148804 0.10801785439252853\n",
      "[Step 20154] Loss: 9.46e+07 -1.1198248863220215 0.10801702737808228\n",
      "[Step 20155] Loss: 9.44e+07 -1.1198019981384277 0.10803105682134628\n",
      "[Step 20156] Loss: 9.40e+07 -1.1198177337646484 0.10801290720701218\n",
      "[Step 20157] Loss: 9.47e+07 -1.1199777126312256 0.10797247290611267\n",
      "[Step 20158] Loss: 9.38e+07 -1.1199791431427002 0.10798320174217224\n",
      "[Step 20159] Loss: 9.54e+07 -1.1201515197753906 0.10797247290611267\n",
      "[Step 20160] Loss: 9.41e+07 -1.1202837228775024 0.1079799011349678\n",
      "[Step 20161] Loss: 9.38e+07 -1.1204246282577515 0.10796834528446198\n",
      "[Step 20162] Loss: 9.47e+07 -1.1206568479537964 0.10791471600532532\n",
      "[Step 20163] Loss: 9.42e+07 -1.1209317445755005 0.1078602522611618\n",
      "[Step 20164] Loss: 9.49e+07 -1.1210840940475464 0.10784952342510223\n",
      "[Step 20165] Loss: 9.44e+07 -1.1211796998977661 0.10784292221069336\n",
      "[Step 20166] Loss: 9.44e+07 -1.1212369203567505 0.10780332237482071\n",
      "[Step 20167] Loss: 9.45e+07 -1.1212280988693237 0.107785165309906\n",
      "[Step 20168] Loss: 9.38e+07 -1.1212159395217896 0.10778763890266418\n",
      "[Step 20169] Loss: 9.44e+07 -1.1211905479431152 0.10775215923786163\n",
      "[Step 20170] Loss: 9.48e+07 -1.1213171482086182 0.10773731023073196\n",
      "[Step 20171] Loss: 9.41e+07 -1.1214150190353394 0.10771090537309647\n",
      "[Step 20172] Loss: 9.41e+07 -1.1213845014572144 0.10770595073699951\n",
      "[Step 20173] Loss: 9.49e+07 -1.1213151216506958 0.10772410780191422\n",
      "[Step 20174] Loss: 9.41e+07 -1.1212434768676758 0.10772328078746796\n",
      "[Step 20175] Loss: 9.43e+07 -1.121201515197754 0.10769522935152054\n",
      "[Step 20176] Loss: 9.46e+07 -1.1212188005447388 0.10768532752990723\n",
      "[Step 20177] Loss: 9.48e+07 -1.121362328529358 0.10768697410821915\n",
      "[Step 20178] Loss: 9.39e+07 -1.1214354038238525 0.10766717046499252\n",
      "[Step 20179] Loss: 9.51e+07 -1.1216093301773071 0.10761518776416779\n",
      "[Step 20180] Loss: 9.40e+07 -1.1218374967575073 0.10758878290653229\n",
      "[Step 20181] Loss: 9.40e+07 -1.1221410036087036 0.10756733268499374\n",
      "[Step 20182] Loss: 9.34e+07 -1.1223713159561157 0.1074971929192543\n",
      "[Step 20183] Loss: 9.36e+07 -1.1225537061691284 0.10748646408319473\n",
      "[Step 20184] Loss: 9.56e+07 -1.1229965686798096 0.10741385817527771\n",
      "[Step 20185] Loss: 9.44e+07 -1.1235238313674927 0.10736186802387238\n",
      "[Step 20186] Loss: 9.40e+07 -1.1238304376602173 0.1073107123374939\n",
      "[Step 20187] Loss: 9.48e+07 -1.1241366863250732 0.10727357864379883\n",
      "[Step 20188] Loss: 9.41e+07 -1.1243529319763184 0.10722902417182922\n",
      "[Step 20189] Loss: 9.44e+07 -1.1246227025985718 0.10717951506376266\n",
      "[Step 20190] Loss: 9.43e+07 -1.1249163150787354 0.10715971142053604\n",
      "[Step 20191] Loss: 9.43e+07 -1.1251403093338013 0.10711763054132462\n",
      "[Step 20192] Loss: 9.50e+07 -1.1255789995193481 0.10707885026931763\n",
      "[Step 20193] Loss: 9.42e+07 -1.125994086265564 0.10699056088924408\n",
      "[Step 20194] Loss: 9.47e+07 -1.126301884651184 0.10694599896669388\n",
      "[Step 20195] Loss: 9.41e+07 -1.1266632080078125 0.10689236968755722\n",
      "[Step 20196] Loss: 9.45e+07 -1.1269601583480835 0.10683460533618927\n",
      "[Step 20197] Loss: 9.47e+07 -1.127255916595459 0.10679170489311218\n",
      "[Step 20198] Loss: 9.47e+07 -1.1276354789733887 0.1067529171705246\n",
      "[Step 20199] Loss: 9.42e+07 -1.1279634237289429 0.10669928789138794\n",
      "[Step 20200] Loss: 9.47e+07 -1.128389596939087 0.1066431775689125\n",
      "[Step 20201] Loss: 9.38e+07 -1.128751277923584 0.10656479001045227\n",
      "[Step 20202] Loss: 9.35e+07 -1.129088044166565 0.10652270913124084\n",
      "[Step 20203] Loss: 9.53e+07 -1.1292004585266113 0.10649795085191727\n",
      "[Step 20204] Loss: 9.45e+07 -1.1292914152145386 0.10647237300872803\n",
      "[Step 20205] Loss: 9.41e+07 -1.1293636560440063 0.10647402703762054\n",
      "[Step 20206] Loss: 9.40e+07 -1.129415512084961 0.10644762217998505\n",
      "[Step 20207] Loss: 9.39e+07 -1.1295301914215088 0.10640058666467667\n",
      "[Step 20208] Loss: 9.52e+07 -1.1297146081924438 0.10636923462152481\n",
      "[Step 20209] Loss: 9.42e+07 -1.1298654079437256 0.1063370481133461\n",
      "[Step 20210] Loss: 9.43e+07 -1.1300708055496216 0.10628589242696762\n",
      "[Step 20211] Loss: 9.41e+07 -1.130165934562683 0.1062619611620903\n",
      "[Step 20212] Loss: 9.43e+07 -1.130184292793274 0.10624545812606812\n",
      "[Step 20213] Loss: 9.37e+07 -1.1301519870758057 0.10621327906847\n",
      "[Step 20214] Loss: 9.42e+07 -1.1301889419555664 0.10620997846126556\n",
      "[Step 20215] Loss: 9.42e+07 -1.130211591720581 0.1061910018324852\n",
      "[Step 20216] Loss: 9.49e+07 -1.130220890045166 0.10620255023241043\n",
      "[Step 20217] Loss: 9.41e+07 -1.130172848701477 0.10619347542524338\n",
      "[Step 20218] Loss: 9.44e+07 -1.1302614212036133 0.1061868742108345\n",
      "[Step 20219] Loss: 9.47e+07 -1.1303014755249023 0.10617697238922119\n",
      "[Step 20220] Loss: 9.57e+07 -1.1301673650741577 0.10616542398929596\n",
      "[Step 20221] Loss: 9.46e+07 -1.1300461292266846 0.10616625100374222\n",
      "[Step 20222] Loss: 9.54e+07 -1.1298372745513916 0.10618027299642563\n",
      "[Step 20223] Loss: 9.50e+07 -1.1295617818832397 0.10620997846126556\n",
      "[Step 20224] Loss: 9.44e+07 -1.1292316913604736 0.10623390972614288\n",
      "[Step 20225] Loss: 9.49e+07 -1.1288479566574097 0.10627104341983795\n",
      "[Step 20226] Loss: 9.56e+07 -1.128781795501709 0.10627186298370361\n",
      "[Step 20227] Loss: 9.46e+07 -1.128680944442749 0.10625701397657394\n",
      "[Step 20228] Loss: 9.49e+07 -1.128583550453186 0.10624958574771881\n",
      "[Step 20229] Loss: 9.45e+07 -1.1284505128860474 0.10626774281263351\n",
      "[Step 20230] Loss: 9.49e+07 -1.1283982992172241 0.10626856237649918\n",
      "[Step 20231] Loss: 9.40e+07 -1.1283208131790161 0.106280118227005\n",
      "[Step 20232] Loss: 9.69e+07 -1.1280550956726074 0.1063065230846405\n",
      "[Step 20233] Loss: 9.41e+07 -1.1277515888214111 0.10634530335664749\n",
      "[Step 20234] Loss: 9.32e+07 -1.1274657249450684 0.10635603219270706\n",
      "[Step 20235] Loss: 9.46e+07 -1.1272226572036743 0.10639975965023041\n",
      "[Step 20236] Loss: 9.40e+07 -1.1269350051879883 0.1064525693655014\n",
      "[Step 20237] Loss: 9.39e+07 -1.126625895500183 0.10647237300872803\n",
      "[Step 20238] Loss: 9.41e+07 -1.1263121366500854 0.10648640245199203\n",
      "[Step 20239] Loss: 9.50e+07 -1.1263478994369507 0.10647154599428177\n",
      "[Step 20240] Loss: 9.46e+07 -1.1263903379440308 0.10647980123758316\n",
      "[Step 20241] Loss: 9.47e+07 -1.1264244318008423 0.10649630427360535\n",
      "[Step 20242] Loss: 9.43e+07 -1.1265076398849487 0.10647320002317429\n",
      "[Step 20243] Loss: 9.42e+07 -1.126599669456482 0.10645752400159836\n",
      "[Step 20244] Loss: 9.50e+07 -1.1267155408859253 0.10645174235105515\n",
      "[Step 20245] Loss: 9.47e+07 -1.1268805265426636 0.10641296207904816\n",
      "[Step 20246] Loss: 9.39e+07 -1.1269901990890503 0.10640306025743484\n",
      "[Step 20247] Loss: 9.47e+07 -1.1270244121551514 0.10640471428632736\n",
      "[Step 20248] Loss: 9.62e+07 -1.1273738145828247 0.10637170821428299\n",
      "[Step 20249] Loss: 9.46e+07 -1.1277767419815063 0.10630486905574799\n",
      "[Step 20250] Loss: 9.40e+07 -1.1281644105911255 0.1062355563044548\n",
      "[Step 20251] Loss: 9.41e+07 -1.1285263299942017 0.10617862641811371\n",
      "[Step 20252] Loss: 9.50e+07 -1.1288352012634277 0.10612334311008453\n",
      "[Step 20253] Loss: 9.49e+07 -1.1290948390960693 0.10608868300914764\n",
      "[Step 20254] Loss: 9.49e+07 -1.1295228004455566 0.1060367003083229\n",
      "[Step 20255] Loss: 9.47e+07 -1.1299935579299927 0.10595996677875519\n",
      "[Step 20256] Loss: 9.43e+07 -1.1304562091827393 0.10590715706348419\n",
      "[Step 20257] Loss: 9.46e+07 -1.1308555603027344 0.10583867132663727\n",
      "[Step 20258] Loss: 9.37e+07 -1.1312811374664307 0.10576688498258591\n",
      "[Step 20259] Loss: 9.50e+07 -1.1315480470657349 0.10571819543838501\n",
      "[Step 20260] Loss: 9.41e+07 -1.1318342685699463 0.10566539317369461\n",
      "[Step 20261] Loss: 9.46e+07 -1.1321732997894287 0.1056109294295311\n",
      "[Step 20262] Loss: 9.42e+07 -1.132543921470642 0.10556060075759888\n",
      "[Step 20263] Loss: 9.48e+07 -1.1330209970474243 0.105487160384655\n",
      "[Step 20264] Loss: 9.42e+07 -1.1334428787231445 0.10544012486934662\n",
      "[Step 20265] Loss: 9.45e+07 -1.1337864398956299 0.10536999255418777\n",
      "[Step 20266] Loss: 9.50e+07 -1.1339906454086304 0.10534688830375671\n",
      "[Step 20267] Loss: 9.42e+07 -1.1341567039489746 0.1053369864821434\n",
      "[Step 20268] Loss: 9.42e+07 -1.1342638731002808 0.10532955825328827\n",
      "[Step 20269] Loss: 9.38e+07 -1.1342843770980835 0.10531140863895416\n",
      "[Step 20270] Loss: 9.48e+07 -1.1343574523925781 0.10531965643167496\n",
      "[Step 20271] Loss: 9.38e+07 -1.1344529390335083 0.10528665035963058\n",
      "[Step 20272] Loss: 9.37e+07 -1.134629726409912 0.10527592152357101\n",
      "[Step 20273] Loss: 9.47e+07 -1.1348209381103516 0.10524704307317734\n",
      "[Step 20274] Loss: 9.43e+07 -1.1349503993988037 0.10524952411651611\n",
      "[Step 20275] Loss: 9.44e+07 -1.1350886821746826 0.10526107251644135\n",
      "[Step 20276] Loss: 9.44e+07 -1.1353083848953247 0.1052214652299881\n",
      "[Step 20277] Loss: 9.42e+07 -1.1354458332061768 0.10520743578672409\n",
      "[Step 20278] Loss: 9.54e+07 -1.135408639907837 0.10521156340837479\n",
      "[Step 20279] Loss: 9.39e+07 -1.1352815628051758 0.10522641986608505\n",
      "[Step 20280] Loss: 9.45e+07 -1.1351981163024902 0.10523796826601028\n",
      "[Step 20281] Loss: 9.47e+07 -1.1350750923156738 0.10521899163722992\n",
      "[Step 20282] Loss: 9.42e+07 -1.1349865198135376 0.10524292290210724\n",
      "[Step 20283] Loss: 9.39e+07 -1.1349025964736938 0.10525529831647873\n",
      "[Step 20284] Loss: 9.43e+07 -1.134872555732727 0.1052618995308876\n",
      "[Step 20285] Loss: 9.59e+07 -1.134690761566162 0.10527840256690979\n",
      "[Step 20286] Loss: 9.43e+07 -1.1344892978668213 0.10527840256690979\n",
      "[Step 20287] Loss: 9.45e+07 -1.1343425512313843 0.10531800985336304\n",
      "[Step 20288] Loss: 9.48e+07 -1.1341326236724854 0.10534606128931046\n",
      "[Step 20289] Loss: 9.41e+07 -1.1339598894119263 0.10535679012537003\n",
      "[Step 20290] Loss: 9.48e+07 -1.1337134838104248 0.10539557039737701\n",
      "[Step 20291] Loss: 9.50e+07 -1.133447289466858 0.10543765127658844\n",
      "[Step 20292] Loss: 9.49e+07 -1.1332472562789917 0.10545085370540619\n",
      "[Step 20293] Loss: 9.41e+07 -1.1330976486206055 0.10546158254146576\n",
      "[Step 20294] Loss: 9.50e+07 -1.1330442428588867 0.10549210757017136\n",
      "[Step 20295] Loss: 9.43e+07 -1.1330163478851318 0.10550613701343536\n",
      "[Step 20296] Loss: 9.52e+07 -1.133113980293274 0.10549293458461761\n",
      "[Step 20297] Loss: 9.45e+07 -1.13319730758667 0.10546405613422394\n",
      "[Step 20298] Loss: 9.40e+07 -1.1332650184631348 0.10544342547655106\n",
      "[Step 20299] Loss: 9.42e+07 -1.1333163976669312 0.10543105006217957\n",
      "[Step 20300] Loss: 9.46e+07 -1.1333309412002563 0.10539887100458145\n",
      "[Step 20301] Loss: 9.56e+07 -1.13323974609375 0.10540299862623215\n",
      "[Step 20302] Loss: 9.49e+07 -1.1333537101745605 0.10537411272525787\n",
      "[Step 20303] Loss: 9.42e+07 -1.1334223747253418 0.10534193366765976\n",
      "[Step 20304] Loss: 9.47e+07 -1.1334547996520996 0.1053188294172287\n",
      "[Step 20305] Loss: 9.53e+07 -1.1337801218032837 0.10526437312364578\n",
      "[Step 20306] Loss: 9.38e+07 -1.1340581178665161 0.10521899163722992\n",
      "[Step 20307] Loss: 9.52e+07 -1.1342017650604248 0.1051868125796318\n",
      "[Step 20308] Loss: 9.47e+07 -1.134484052658081 0.105097696185112\n",
      "[Step 20309] Loss: 9.54e+07 -1.134831428527832 0.10505808889865875\n",
      "[Step 20310] Loss: 9.53e+07 -1.1352585554122925 0.10498960316181183\n",
      "[Step 20311] Loss: 9.58e+07 -1.1359888315200806 0.10489223897457123\n",
      "[Step 20312] Loss: 9.43e+07 -1.1366448402404785 0.10481549799442291\n",
      "[Step 20313] Loss: 9.42e+07 -1.1373063325881958 0.1047305092215538\n",
      "[Step 20314] Loss: 9.51e+07 -1.137775182723999 0.10464882105588913\n",
      "[Step 20315] Loss: 9.40e+07 -1.1381317377090454 0.10460508614778519\n",
      "[Step 20316] Loss: 9.46e+07 -1.138426423072815 0.10455062985420227\n",
      "[Step 20317] Loss: 9.46e+07 -1.1387137174606323 0.10451515018939972\n",
      "[Step 20318] Loss: 9.46e+07 -1.1388919353485107 0.10450689494609833\n",
      "[Step 20319] Loss: 9.46e+07 -1.1390259265899658 0.10449451953172684\n",
      "[Step 20320] Loss: 9.46e+07 -1.139121174812317 0.10446564108133316\n",
      "[Step 20321] Loss: 9.39e+07 -1.1392323970794678 0.10443180799484253\n",
      "[Step 20322] Loss: 9.46e+07 -1.1394294500350952 0.10439632833003998\n",
      "[Step 20323] Loss: 9.41e+07 -1.139573335647583 0.10437239706516266\n",
      "[Step 20324] Loss: 9.47e+07 -1.1397984027862549 0.1043451726436615\n",
      "[Step 20325] Loss: 9.55e+07 -1.1401667594909668 0.1042964905500412\n",
      "[Step 20326] Loss: 9.45e+07 -1.1404982805252075 0.10424285382032394\n",
      "[Step 20327] Loss: 9.47e+07 -1.1410142183303833 0.10418179631233215\n",
      "[Step 20328] Loss: 9.48e+07 -1.141636610031128 0.10410422831773758\n",
      "[Step 20329] Loss: 9.39e+07 -1.1421904563903809 0.10404399782419205\n",
      "[Step 20330] Loss: 9.48e+07 -1.142810583114624 0.10395900905132294\n",
      "[Step 20331] Loss: 9.36e+07 -1.1434253454208374 0.10390207171440125\n",
      "[Step 20332] Loss: 9.46e+07 -1.1439013481140137 0.10382615774869919\n",
      "[Step 20333] Loss: 9.46e+07 -1.1445354223251343 0.10375189781188965\n",
      "[Step 20334] Loss: 9.44e+07 -1.1451143026351929 0.10367763787508011\n",
      "[Step 20335] Loss: 9.46e+07 -1.1455556154251099 0.10360997170209885\n",
      "[Step 20336] Loss: 9.43e+07 -1.1460046768188477 0.10355551540851593\n",
      "[Step 20337] Loss: 9.36e+07 -1.146497130393982 0.10347547382116318\n",
      "[Step 20338] Loss: 9.36e+07 -1.1469252109527588 0.10342761874198914\n",
      "[Step 20339] Loss: 9.38e+07 -1.1473366022109985 0.10337646305561066\n",
      "[Step 20340] Loss: 9.49e+07 -1.1476666927337646 0.10331952571868896\n",
      "[Step 20341] Loss: 9.51e+07 -1.1481159925460815 0.10325846821069717\n",
      "[Step 20342] Loss: 9.59e+07 -1.1483904123306274 0.10321968048810959\n",
      "[Step 20343] Loss: 9.52e+07 -1.1487846374511719 0.10316192358732224\n",
      "[Step 20344] Loss: 9.48e+07 -1.1490408182144165 0.10312891751527786\n",
      "[Step 20345] Loss: 9.52e+07 -1.1494463682174683 0.10307198762893677\n",
      "[Step 20346] Loss: 9.43e+07 -1.149794578552246 0.10303402692079544\n",
      "[Step 20347] Loss: 9.35e+07 -1.1500792503356934 0.10297049582004547\n",
      "[Step 20348] Loss: 9.46e+07 -1.150328516960144 0.10293253511190414\n",
      "[Step 20349] Loss: 9.41e+07 -1.1505250930786133 0.10289128124713898\n",
      "[Step 20350] Loss: 9.52e+07 -1.1506181955337524 0.10287395119667053\n",
      "[Step 20351] Loss: 9.50e+07 -1.1507935523986816 0.10282526910305023\n",
      "[Step 20352] Loss: 9.46e+07 -1.1508854627609253 0.10279886424541473\n",
      "[Step 20353] Loss: 9.50e+07 -1.1508886814117432 0.10278400778770447\n",
      "[Step 20354] Loss: 9.45e+07 -1.1508591175079346 0.10277988761663437\n",
      "[Step 20355] Loss: 9.47e+07 -1.1508944034576416 0.10276998579502106\n",
      "[Step 20356] Loss: 9.45e+07 -1.1509095430374146 0.10275512933731079\n",
      "[Step 20357] Loss: 9.45e+07 -1.150963306427002 0.10272790491580963\n",
      "[Step 20358] Loss: 9.44e+07 -1.1510716676712036 0.10271717607975006\n",
      "[Step 20359] Loss: 9.43e+07 -1.15118408203125 0.10271057486534119\n",
      "[Step 20360] Loss: 9.53e+07 -1.1511311531066895 0.10272790491580963\n",
      "[Step 20361] Loss: 9.44e+07 -1.1510001420974731 0.10273945331573486\n",
      "[Step 20362] Loss: 9.43e+07 -1.150818943977356 0.10276421159505844\n",
      "[Step 20363] Loss: 9.45e+07 -1.150586485862732 0.10281206667423248\n",
      "[Step 20364] Loss: 9.41e+07 -1.1504158973693848 0.10282279551029205\n",
      "[Step 20365] Loss: 9.55e+07 -1.1504167318344116 0.10282444208860397\n",
      "[Step 20366] Loss: 9.42e+07 -1.1504489183425903 0.10283517092466354\n",
      "[Step 20367] Loss: 9.54e+07 -1.1503121852874756 0.10286900401115417\n",
      "[Step 20368] Loss: 9.44e+07 -1.1502561569213867 0.10285414755344391\n",
      "[Step 20369] Loss: 9.42e+07 -1.1502317190170288 0.10286982357501984\n",
      "[Step 20370] Loss: 9.42e+07 -1.1502496004104614 0.10284341871738434\n",
      "[Step 20371] Loss: 9.45e+07 -1.1503558158874512 0.10280381143093109\n",
      "[Step 20372] Loss: 9.47e+07 -1.150330901145935 0.10280876606702805\n",
      "[Step 20373] Loss: 9.47e+07 -1.1504082679748535 0.10277988761663437\n",
      "[Step 20374] Loss: 9.43e+07 -1.1504300832748413 0.10275100916624069\n",
      "[Step 20375] Loss: 9.42e+07 -1.1504936218261719 0.10275018215179443\n",
      "[Step 20376] Loss: 9.44e+07 -1.1505879163742065 0.10271800309419632\n",
      "[Step 20377] Loss: 9.44e+07 -1.1507580280303955 0.10268829762935638\n",
      "[Step 20378] Loss: 9.40e+07 -1.1509281396865845 0.10267014056444168\n",
      "[Step 20379] Loss: 9.47e+07 -1.1510504484176636 0.10264621675014496\n",
      "[Step 20380] Loss: 9.48e+07 -1.1510614156723022 0.10263713449239731\n",
      "[Step 20381] Loss: 9.39e+07 -1.1509768962860107 0.10266106575727463\n",
      "[Step 20382] Loss: 9.50e+07 -1.1510134935379028 0.10265859216451645\n",
      "[Step 20383] Loss: 9.41e+07 -1.1510182619094849 0.10265611857175827\n",
      "[Step 20384] Loss: 9.59e+07 -1.150874376296997 0.10268169641494751\n",
      "[Step 20385] Loss: 9.45e+07 -1.1508338451385498 0.10267509520053864\n",
      "[Step 20386] Loss: 9.37e+07 -1.1507246494293213 0.10268747061491013\n",
      "[Step 20387] Loss: 9.53e+07 -1.1504603624343872 0.10272790491580963\n",
      "[Step 20388] Loss: 9.41e+07 -1.150091528892517 0.1027650311589241\n",
      "[Step 20389] Loss: 9.42e+07 -1.1498013734817505 0.10281536728143692\n",
      "[Step 20390] Loss: 9.42e+07 -1.1495122909545898 0.10285744816064835\n",
      "[Step 20391] Loss: 9.50e+07 -1.1491883993148804 0.1029110848903656\n",
      "[Step 20392] Loss: 9.42e+07 -1.1487971544265747 0.10297544300556183\n",
      "[Step 20393] Loss: 9.46e+07 -1.1483933925628662 0.10302577912807465\n",
      "[Step 20394] Loss: 9.41e+07 -1.14798104763031 0.10307363420724869\n",
      "[Step 20395] Loss: 9.43e+07 -1.1476751565933228 0.10312148928642273\n",
      "[Step 20396] Loss: 9.46e+07 -1.1474056243896484 0.10315779596567154\n",
      "[Step 20397] Loss: 9.44e+07 -1.147186040878296 0.10316439718008041\n",
      "[Step 20398] Loss: 9.37e+07 -1.1469883918762207 0.10316522419452667\n",
      "[Step 20399] Loss: 9.64e+07 -1.1472091674804688 0.10313717275857925\n",
      "[Step 20400] Loss: 9.41e+07 -1.147297739982605 0.10311076790094376\n",
      "[Step 20401] Loss: 9.43e+07 -1.1473252773284912 0.10311488807201385\n",
      "[Step 20402] Loss: 9.34e+07 -1.1473190784454346 0.10308848321437836\n",
      "[Step 20403] Loss: 9.37e+07 -1.1473395824432373 0.10309673845767975\n",
      "[Step 20404] Loss: 9.57e+07 -1.1475251913070679 0.10307446122169495\n",
      "[Step 20405] Loss: 9.47e+07 -1.1476503610610962 0.10306043177843094\n",
      "[Step 20406] Loss: 9.41e+07 -1.1477848291397095 0.1030431017279625\n",
      "[Step 20407] Loss: 9.49e+07 -1.1478919982910156 0.10301917791366577\n",
      "[Step 20408] Loss: 9.43e+07 -1.1479343175888062 0.10301009565591812\n",
      "[Step 20409] Loss: 9.40e+07 -1.148055911064148 0.10298451781272888\n",
      "[Step 20410] Loss: 9.45e+07 -1.1480896472930908 0.10296966880559921\n",
      "[Step 20411] Loss: 9.40e+07 -1.148075819015503 0.10295399278402328\n",
      "[Step 20412] Loss: 9.44e+07 -1.1481287479400635 0.10293666273355484\n",
      "[Step 20413] Loss: 9.33e+07 -1.1481832265853882 0.10295069217681885\n",
      "[Step 20414] Loss: 9.44e+07 -1.1483746767044067 0.10288632661104202\n",
      "[Step 20415] Loss: 9.44e+07 -1.148616909980774 0.10284837335348129\n",
      "[Step 20416] Loss: 9.36e+07 -1.1488465070724487 0.10282114148139954\n",
      "[Step 20417] Loss: 9.42e+07 -1.14898681640625 0.10278566181659698\n",
      "[Step 20418] Loss: 9.49e+07 -1.1492477655410767 0.10275842994451523\n",
      "[Step 20419] Loss: 9.40e+07 -1.1494953632354736 0.10272707790136337\n",
      "[Step 20420] Loss: 9.43e+07 -1.149749994277954 0.10268747061491013\n",
      "[Step 20421] Loss: 9.38e+07 -1.1499871015548706 0.1026453897356987\n",
      "[Step 20422] Loss: 9.48e+07 -1.1501169204711914 0.10262641310691833\n",
      "[Step 20423] Loss: 9.56e+07 -1.1500964164733887 0.10262558609247208\n",
      "[Step 20424] Loss: 9.43e+07 -1.1500424146652222 0.102627232670784\n",
      "[Step 20425] Loss: 9.42e+07 -1.1500129699707031 0.10261815786361694\n",
      "[Step 20426] Loss: 9.56e+07 -1.15022873878479 0.10256534814834595\n",
      "[Step 20427] Loss: 9.44e+07 -1.1503512859344482 0.10253729671239853\n",
      "[Step 20428] Loss: 9.46e+07 -1.150431513786316 0.10252492129802704\n",
      "[Step 20429] Loss: 9.46e+07 -1.150453805923462 0.10250181704759598\n",
      "[Step 20430] Loss: 9.39e+07 -1.1504409313201904 0.10251336544752121\n",
      "[Step 20431] Loss: 9.52e+07 -1.1503698825836182 0.10253234207630157\n",
      "[Step 20432] Loss: 9.42e+07 -1.1502844095230103 0.10252079367637634\n",
      "[Step 20433] Loss: 9.40e+07 -1.1502338647842407 0.10251501947641373\n",
      "[Step 20434] Loss: 9.43e+07 -1.1501448154449463 0.1025257408618927\n",
      "[Step 20435] Loss: 9.44e+07 -1.1500478982925415 0.10252822190523148\n",
      "[Step 20436] Loss: 9.50e+07 -1.1498397588729858 0.1025521457195282\n",
      "[Step 20437] Loss: 9.48e+07 -1.149563193321228 0.10258762538433075\n",
      "[Step 20438] Loss: 9.40e+07 -1.1493574380874634 0.10259422659873962\n",
      "[Step 20439] Loss: 9.38e+07 -1.1491905450820923 0.1026148572564125\n",
      "[Step 20440] Loss: 9.37e+07 -1.148995280265808 0.10261403024196625\n",
      "[Step 20441] Loss: 9.49e+07 -1.1489087343215942 0.10264291614294052\n",
      "[Step 20442] Loss: 9.43e+07 -1.148972511291504 0.102627232670784\n",
      "[Step 20443] Loss: 9.46e+07 -1.1490461826324463 0.10261733084917068\n",
      "[Step 20444] Loss: 9.48e+07 -1.1491262912750244 0.10261238366365433\n",
      "[Step 20445] Loss: 9.47e+07 -1.1493918895721436 0.10256452113389969\n",
      "[Step 20446] Loss: 9.46e+07 -1.149669885635376 0.10254142433404922\n",
      "[Step 20447] Loss: 9.43e+07 -1.1499203443527222 0.10253152251243591\n",
      "[Step 20448] Loss: 9.37e+07 -1.150159239768982 0.10249273478984833\n",
      "[Step 20449] Loss: 9.44e+07 -1.1504522562026978 0.10245808213949203\n",
      "[Step 20450] Loss: 9.44e+07 -1.1507354974746704 0.10246055573225021\n",
      "[Step 20451] Loss: 9.46e+07 -1.1509522199630737 0.10244570672512054\n",
      "[Step 20452] Loss: 9.40e+07 -1.1511900424957275 0.10241352766752243\n",
      "[Step 20453] Loss: 9.44e+07 -1.1514244079589844 0.10239867120981216\n",
      "[Step 20454] Loss: 9.41e+07 -1.1516141891479492 0.10238052159547806\n",
      "[Step 20455] Loss: 9.47e+07 -1.1517034769058228 0.1023615375161171\n",
      "[Step 20456] Loss: 9.43e+07 -1.1517305374145508 0.1023450419306755\n",
      "[Step 20457] Loss: 9.51e+07 -1.1516755819320679 0.10236319154500961\n",
      "[Step 20458] Loss: 9.45e+07 -1.1516551971435547 0.10236401855945587\n",
      "[Step 20459] Loss: 9.45e+07 -1.1515676975250244 0.10237309336662292\n",
      "[Step 20460] Loss: 9.44e+07 -1.1514918804168701 0.10239537060260773\n",
      "[Step 20461] Loss: 9.53e+07 -1.1512911319732666 0.1023796945810318\n",
      "[Step 20462] Loss: 9.33e+07 -1.1511471271514893 0.10238546878099442\n",
      "[Step 20463] Loss: 9.53e+07 -1.151188611984253 0.10236319154500961\n",
      "[Step 20464] Loss: 9.38e+07 -1.1511590480804443 0.10236319154500961\n",
      "[Step 20465] Loss: 9.46e+07 -1.1512150764465332 0.1023532897233963\n",
      "[Step 20466] Loss: 9.44e+07 -1.1512651443481445 0.10235493630170822\n",
      "[Step 20467] Loss: 9.67e+07 -1.1510409116744995 0.10236401855945587\n",
      "[Step 20468] Loss: 9.45e+07 -1.1508759260177612 0.10239124298095703\n",
      "[Step 20469] Loss: 9.44e+07 -1.1507898569107056 0.10239867120981216\n",
      "[Step 20470] Loss: 9.39e+07 -1.1506986618041992 0.10238464176654816\n",
      "[Step 20471] Loss: 9.41e+07 -1.1506719589233398 0.10239042341709137\n",
      "[Step 20472] Loss: 9.43e+07 -1.1506160497665405 0.10238959640264511\n",
      "[Step 20473] Loss: 9.45e+07 -1.1505886316299438 0.10236979275941849\n",
      "[Step 20474] Loss: 9.45e+07 -1.1505098342895508 0.10236319154500961\n",
      "[Step 20475] Loss: 9.51e+07 -1.1502866744995117 0.10239124298095703\n",
      "[Step 20476] Loss: 9.44e+07 -1.1501338481903076 0.10239702463150024\n",
      "[Step 20477] Loss: 9.48e+07 -1.1499121189117432 0.10242754966020584\n",
      "[Step 20478] Loss: 9.42e+07 -1.1496647596359253 0.10245642811059952\n",
      "[Step 20479] Loss: 9.44e+07 -1.1494760513305664 0.10246385633945465\n",
      "[Step 20480] Loss: 9.44e+07 -1.1494477987289429 0.10245313495397568\n",
      "[Step 20481] Loss: 9.40e+07 -1.1493767499923706 0.10246715694665909\n",
      "[Step 20482] Loss: 9.43e+07 -1.149330973625183 0.10245642811059952\n",
      "[Step 20483] Loss: 9.40e+07 -1.1493124961853027 0.10244570672512054\n",
      "[Step 20484] Loss: 9.40e+07 -1.1492778062820435 0.10245395451784134\n",
      "[Step 20485] Loss: 9.49e+07 -1.1493091583251953 0.10245230793952942\n",
      "[Step 20486] Loss: 9.46e+07 -1.1495051383972168 0.10243580490350723\n",
      "[Step 20487] Loss: 9.48e+07 -1.149711012840271 0.10239949822425842\n",
      "[Step 20488] Loss: 9.49e+07 -1.1498104333877563 0.10239042341709137\n",
      "[Step 20489] Loss: 9.45e+07 -1.149754524230957 0.10240527242422104\n",
      "[Step 20490] Loss: 9.47e+07 -1.1497777700424194 0.10240362584590912\n",
      "[Step 20491] Loss: 9.41e+07 -1.1497448682785034 0.10238712280988693\n",
      "[Step 20492] Loss: 9.40e+07 -1.1496309041976929 0.10242094844579697\n",
      "[Step 20493] Loss: 9.43e+07 -1.1494495868682861 0.10244323313236237\n",
      "[Step 20494] Loss: 9.45e+07 -1.1492825746536255 0.10248035937547684\n",
      "[Step 20495] Loss: 9.41e+07 -1.149128794670105 0.10249851644039154\n",
      "[Step 20496] Loss: 9.41e+07 -1.1489795446395874 0.10252079367637634\n",
      "[Step 20497] Loss: 9.39e+07 -1.148813247680664 0.10254142433404922\n",
      "[Step 20498] Loss: 9.47e+07 -1.1485943794250488 0.10255544632673264\n",
      "[Step 20499] Loss: 9.45e+07 -1.1484644412994385 0.10255874693393707\n",
      "[Step 20500] Loss: 9.43e+07 -1.1483184099197388 0.10258185118436813\n",
      "[Step 20501] Loss: 9.34e+07 -1.148110032081604 0.1026189848780632\n",
      "[Step 20502] Loss: 9.42e+07 -1.1479320526123047 0.10263548791408539\n",
      "[Step 20503] Loss: 9.44e+07 -1.1476625204086304 0.10266931354999542\n",
      "[Step 20504] Loss: 9.44e+07 -1.1473497152328491 0.10272707790136337\n",
      "[Step 20505] Loss: 9.48e+07 -1.1472368240356445 0.1027345061302185\n",
      "[Step 20506] Loss: 9.47e+07 -1.14705228805542 0.10278070718050003\n",
      "[Step 20507] Loss: 9.47e+07 -1.1470513343811035 0.10277575999498367\n",
      "[Step 20508] Loss: 9.46e+07 -1.147070288658142 0.10279060900211334\n",
      "[Step 20509] Loss: 9.50e+07 -1.1471693515777588 0.10278896242380142\n",
      "[Step 20510] Loss: 9.45e+07 -1.147265076637268 0.10279803723096848\n",
      "[Step 20511] Loss: 9.31e+07 -1.1473830938339233 0.10276255756616592\n",
      "[Step 20512] Loss: 9.41e+07 -1.1474735736846924 0.10274770855903625\n",
      "[Step 20513] Loss: 9.43e+07 -1.1476205587387085 0.10274110734462738\n",
      "[Step 20514] Loss: 9.38e+07 -1.1477019786834717 0.10274688154459\n",
      "[Step 20515] Loss: 9.43e+07 -1.147683024406433 0.10271800309419632\n",
      "[Step 20516] Loss: 9.44e+07 -1.147592544555664 0.10272377729415894\n",
      "[Step 20517] Loss: 9.54e+07 -1.1474263668060303 0.10272295027971268\n",
      "[Step 20518] Loss: 9.45e+07 -1.1473379135131836 0.10272707790136337\n",
      "[Step 20519] Loss: 9.46e+07 -1.1472808122634888 0.10272542387247086\n",
      "[Step 20520] Loss: 9.42e+07 -1.147240161895752 0.10274770855903625\n",
      "[Step 20521] Loss: 9.47e+07 -1.1472891569137573 0.10271800309419632\n",
      "[Step 20522] Loss: 9.41e+07 -1.1473761796951294 0.10269654542207718\n",
      "[Step 20523] Loss: 9.41e+07 -1.14742910861969 0.10266106575727463\n",
      "[Step 20524] Loss: 9.42e+07 -1.1475578546524048 0.10263053327798843\n",
      "[Step 20525] Loss: 9.55e+07 -1.1479183435440063 0.10256782174110413\n",
      "[Step 20526] Loss: 9.49e+07 -1.1484066247940063 0.10248448699712753\n",
      "[Step 20527] Loss: 9.42e+07 -1.1488087177276611 0.10243003070354462\n",
      "[Step 20528] Loss: 9.40e+07 -1.1492159366607666 0.10234834253787994\n",
      "[Step 20529] Loss: 9.44e+07 -1.1496683359146118 0.10225097090005875\n",
      "[Step 20530] Loss: 9.45e+07 -1.150025725364685 0.10219816118478775\n",
      "[Step 20531] Loss: 9.43e+07 -1.150327205657959 0.10214123129844666\n",
      "[Step 20532] Loss: 9.39e+07 -1.1505547761917114 0.10208099335432053\n",
      "[Step 20533] Loss: 9.44e+07 -1.1507529020309448 0.10204055905342102\n",
      "[Step 20534] Loss: 9.44e+07 -1.1508979797363281 0.10203643888235092\n",
      "[Step 20535] Loss: 9.45e+07 -1.1509547233581543 0.10202240943908691\n",
      "[Step 20536] Loss: 9.41e+07 -1.1510344743728638 0.10201580822467804\n",
      "[Step 20537] Loss: 9.42e+07 -1.1512583494186401 0.10198692977428436\n",
      "[Step 20538] Loss: 9.47e+07 -1.151498556137085 0.10194732248783112\n",
      "[Step 20539] Loss: 9.45e+07 -1.151705265045166 0.10191266983747482\n",
      "[Step 20540] Loss: 9.49e+07 -1.1520328521728516 0.1018747091293335\n",
      "[Step 20541] Loss: 9.48e+07 -1.1524254083633423 0.10183427482843399\n",
      "[Step 20542] Loss: 9.44e+07 -1.152782678604126 0.10177404433488846\n",
      "[Step 20543] Loss: 9.41e+07 -1.1531392335891724 0.10172288864850998\n",
      "[Step 20544] Loss: 9.42e+07 -1.1534074544906616 0.10167255252599716\n",
      "[Step 20545] Loss: 9.51e+07 -1.1535937786102295 0.10164202004671097\n",
      "[Step 20546] Loss: 9.45e+07 -1.153831958770752 0.10159993916749954\n",
      "[Step 20547] Loss: 9.35e+07 -1.1539868116378784 0.10155125707387924\n",
      "[Step 20548] Loss: 9.41e+07 -1.1540861129760742 0.10152897983789444\n",
      "[Step 20549] Loss: 9.45e+07 -1.1542155742645264 0.10149514675140381\n",
      "[Step 20550] Loss: 9.45e+07 -1.1543481349945068 0.10148937255144119\n",
      "[Step 20551] Loss: 9.51e+07 -1.1543430089950562 0.10148689895868301\n",
      "[Step 20552] Loss: 9.54e+07 -1.1541966199874878 0.10148359835147858\n",
      "[Step 20553] Loss: 9.46e+07 -1.1539716720581055 0.10151412338018417\n",
      "[Step 20554] Loss: 9.57e+07 -1.1536201238632202 0.10155703127384186\n",
      "[Step 20555] Loss: 9.40e+07 -1.1532819271087646 0.10161644220352173\n",
      "[Step 20556] Loss: 9.44e+07 -1.1530511379241943 0.1016453206539154\n",
      "[Step 20557] Loss: 9.45e+07 -1.1528992652893066 0.10165687650442123\n",
      "[Step 20558] Loss: 9.40e+07 -1.1528079509735107 0.10166842490434647\n",
      "[Step 20559] Loss: 9.37e+07 -1.1527341604232788 0.10168245434761047\n",
      "[Step 20560] Loss: 9.48e+07 -1.1525958776474 0.10170555859804153\n",
      "[Step 20561] Loss: 9.46e+07 -1.1525053977966309 0.10172783583402634\n",
      "[Step 20562] Loss: 9.51e+07 -1.1526215076446533 0.10171546041965485\n",
      "[Step 20563] Loss: 9.51e+07 -1.152671456336975 0.10170968621969223\n",
      "[Step 20564] Loss: 9.45e+07 -1.152794361114502 0.1016841009259224\n",
      "[Step 20565] Loss: 9.40e+07 -1.1528369188308716 0.10167668014764786\n",
      "[Step 20566] Loss: 9.69e+07 -1.1526820659637451 0.10168575495481491\n",
      "[Step 20567] Loss: 9.48e+07 -1.1525174379348755 0.10169152915477753\n",
      "[Step 20568] Loss: 9.46e+07 -1.152467966079712 0.10171133279800415\n",
      "[Step 20569] Loss: 9.38e+07 -1.152419090270996 0.10172370821237564\n",
      "[Step 20570] Loss: 9.42e+07 -1.1524354219436646 0.10170473158359528\n",
      "[Step 20571] Loss: 9.53e+07 -1.152327537536621 0.1017162874341011\n",
      "[Step 20572] Loss: 9.38e+07 -1.1522315740585327 0.10173196345567703\n",
      "[Step 20573] Loss: 9.39e+07 -1.1521263122558594 0.10174021124839783\n",
      "[Step 20574] Loss: 9.38e+07 -1.1520187854766846 0.1017286628484726\n",
      "[Step 20575] Loss: 9.42e+07 -1.1519386768341064 0.10173030942678452\n",
      "[Step 20576] Loss: 9.50e+07 -1.1517448425292969 0.10173361003398895\n",
      "[Step 20577] Loss: 9.49e+07 -1.15145742893219 0.10176331549882889\n",
      "[Step 20578] Loss: 9.36e+07 -1.1512256860733032 0.10180539637804031\n",
      "[Step 20579] Loss: 9.47e+07 -1.1510404348373413 0.10183015465736389\n",
      "[Step 20580] Loss: 9.49e+07 -1.150866150856018 0.10182107985019684\n",
      "[Step 20581] Loss: 9.60e+07 -1.1510908603668213 0.10178641974925995\n",
      "[Step 20582] Loss: 9.44e+07 -1.1511911153793335 0.1017732173204422\n",
      "[Step 20583] Loss: 9.41e+07 -1.1511869430541992 0.10173691064119339\n",
      "[Step 20584] Loss: 9.41e+07 -1.1510637998580933 0.10175918787717819\n",
      "[Step 20585] Loss: 9.50e+07 -1.1511188745498657 0.10173938423395157\n",
      "[Step 20586] Loss: 9.43e+07 -1.151131510734558 0.10172370821237564\n",
      "[Step 20587] Loss: 9.52e+07 -1.1510014533996582 0.10171463340520859\n",
      "[Step 20588] Loss: 9.50e+07 -1.1510529518127441 0.10171133279800415\n",
      "[Step 20589] Loss: 9.41e+07 -1.1511292457580566 0.10170885920524597\n",
      "[Step 20590] Loss: 9.43e+07 -1.151219367980957 0.10167089849710464\n",
      "[Step 20591] Loss: 9.47e+07 -1.1513268947601318 0.1016453206539154\n",
      "[Step 20592] Loss: 9.38e+07 -1.1514179706573486 0.10161149501800537\n",
      "[Step 20593] Loss: 9.46e+07 -1.151604413986206 0.10157270729541779\n",
      "[Step 20594] Loss: 9.45e+07 -1.1518499851226807 0.10153558105230331\n",
      "[Step 20595] Loss: 9.43e+07 -1.1520161628723145 0.10149762034416199\n",
      "[Step 20596] Loss: 9.39e+07 -1.152154803276062 0.101472869515419\n",
      "[Step 20597] Loss: 9.39e+07 -1.1523182392120361 0.10144976526498795\n",
      "[Step 20598] Loss: 9.47e+07 -1.1525564193725586 0.10140521079301834\n",
      "[Step 20599] Loss: 9.42e+07 -1.1528786420822144 0.10137385129928589\n",
      "[Step 20600] Loss: 9.45e+07 -1.153134822845459 0.10133341699838638\n",
      "[Step 20601] Loss: 9.40e+07 -1.1534960269927979 0.10129381716251373\n",
      "[Step 20602] Loss: 9.50e+07 -1.15390944480896 0.10124265402555466\n",
      "[Step 20603] Loss: 9.48e+07 -1.1541389226913452 0.10122862458229065\n",
      "[Step 20604] Loss: 9.49e+07 -1.1543034315109253 0.10121377557516098\n",
      "[Step 20605] Loss: 9.44e+07 -1.1545182466506958 0.10117582231760025\n",
      "[Step 20606] Loss: 9.38e+07 -1.154738187789917 0.1011708676815033\n",
      "[Step 20607] Loss: 9.44e+07 -1.154868245124817 0.10117746889591217\n",
      "[Step 20608] Loss: 9.49e+07 -1.1550474166870117 0.10116839408874512\n",
      "[Step 20609] Loss: 9.44e+07 -1.1551671028137207 0.10117169469594955\n",
      "[Step 20610] Loss: 9.42e+07 -1.1552553176879883 0.10116179287433624\n",
      "[Step 20611] Loss: 9.46e+07 -1.1552971601486206 0.10116509348154068\n",
      "[Step 20612] Loss: 9.41e+07 -1.1553477048873901 0.10114363580942154\n",
      "[Step 20613] Loss: 9.46e+07 -1.1554713249206543 0.10111062973737717\n",
      "[Step 20614] Loss: 9.42e+07 -1.155573844909668 0.10109413415193558\n",
      "[Step 20615] Loss: 9.42e+07 -1.155616044998169 0.10108505189418793\n",
      "[Step 20616] Loss: 9.37e+07 -1.155565619468689 0.10109495371580124\n",
      "[Step 20617] Loss: 9.47e+07 -1.1554207801818848 0.10110073536634445\n",
      "[Step 20618] Loss: 9.42e+07 -1.1552784442901611 0.1010957807302475\n",
      "[Step 20619] Loss: 9.46e+07 -1.15501868724823 0.10112878680229187\n",
      "[Step 20620] Loss: 9.50e+07 -1.1546521186828613 0.10117416828870773\n",
      "[Step 20621] Loss: 9.40e+07 -1.1542948484420776 0.1012113019824028\n",
      "[Step 20622] Loss: 9.55e+07 -1.1542166471481323 0.10122202336788177\n",
      "[Step 20623] Loss: 9.43e+07 -1.1540639400482178 0.10121294856071472\n",
      "[Step 20624] Loss: 9.47e+07 -1.1538647413253784 0.10124678164720535\n",
      "[Step 20625] Loss: 9.43e+07 -1.15366530418396 0.10127483308315277\n",
      "[Step 20626] Loss: 9.46e+07 -1.1535736322402954 0.10127071291208267\n",
      "[Step 20627] Loss: 9.43e+07 -1.153592586517334 0.10123852640390396\n",
      "[Step 20628] Loss: 9.41e+07 -1.1536622047424316 0.10120964795351028\n",
      "[Step 20629] Loss: 9.44e+07 -1.153756856918335 0.10121790319681168\n",
      "[Step 20630] Loss: 9.42e+07 -1.1537498235702515 0.10120800137519836\n",
      "[Step 20631] Loss: 9.40e+07 -1.1536707878112793 0.10122450441122055\n",
      "[Step 20632] Loss: 9.44e+07 -1.153731346130371 0.10123110562562943\n",
      "[Step 20633] Loss: 9.45e+07 -1.1536918878555298 0.10123192518949509\n",
      "[Step 20634] Loss: 9.41e+07 -1.153687834739685 0.10123440623283386\n",
      "[Step 20635] Loss: 9.43e+07 -1.1536086797714233 0.10123935341835022\n",
      "[Step 20636] Loss: 9.71e+07 -1.1533211469650269 0.10128061473369598\n",
      "[Step 20637] Loss: 9.47e+07 -1.1530152559280396 0.10132599622011185\n",
      "[Step 20638] Loss: 9.36e+07 -1.1527653932571411 0.10135074704885483\n",
      "[Step 20639] Loss: 9.46e+07 -1.1524211168289185 0.10140685737133026\n",
      "[Step 20640] Loss: 9.43e+07 -1.152045726776123 0.10144893825054169\n",
      "[Step 20641] Loss: 9.47e+07 -1.1517720222473145 0.10150092095136642\n",
      "[Step 20642] Loss: 9.51e+07 -1.151419997215271 0.10153228044509888\n",
      "[Step 20643] Loss: 9.45e+07 -1.1512123346328735 0.10157188773155212\n",
      "[Step 20644] Loss: 9.39e+07 -1.151120901107788 0.10156198590993881\n",
      "[Step 20645] Loss: 9.44e+07 -1.1509618759155273 0.10156610608100891\n",
      "[Step 20646] Loss: 9.43e+07 -1.150771975517273 0.10158178955316544\n",
      "[Step 20647] Loss: 9.45e+07 -1.150681972503662 0.10158590972423553\n",
      "[Step 20648] Loss: 9.54e+07 -1.1508228778839111 0.10156528651714325\n",
      "[Step 20649] Loss: 9.41e+07 -1.150928258895874 0.10156610608100891\n",
      "[Step 20650] Loss: 9.36e+07 -1.150941014289856 0.10156115889549255\n",
      "[Step 20651] Loss: 9.49e+07 -1.1510810852050781 0.10157353430986404\n",
      "[Step 20652] Loss: 9.41e+07 -1.1511955261230469 0.10155950486660004\n",
      "[Step 20653] Loss: 9.42e+07 -1.1513160467147827 0.10153970122337341\n",
      "[Step 20654] Loss: 9.51e+07 -1.1513255834579468 0.10153640061616898\n",
      "[Step 20655] Loss: 9.48e+07 -1.1512099504470825 0.10155043005943298\n",
      "[Step 20656] Loss: 9.48e+07 -1.15127432346344 0.10153145343065262\n",
      "[Step 20657] Loss: 9.42e+07 -1.1514123678207397 0.10148771852254868\n",
      "[Step 20658] Loss: 9.42e+07 -1.1514506340026855 0.10148854553699493\n",
      "[Step 20659] Loss: 9.51e+07 -1.1513592004776 0.10151000320911407\n",
      "[Step 20660] Loss: 9.46e+07 -1.1513159275054932 0.1015034019947052\n",
      "[Step 20661] Loss: 9.39e+07 -1.1512391567230225 0.10151990503072739\n",
      "[Step 20662] Loss: 9.47e+07 -1.1513069868087769 0.10150670260190964\n",
      "[Step 20663] Loss: 9.37e+07 -1.1513252258300781 0.1015034019947052\n",
      "[Step 20664] Loss: 9.48e+07 -1.1515018939971924 0.10146874189376831\n",
      "[Step 20665] Loss: 9.46e+07 -1.1517096757888794 0.10143903642892838\n",
      "[Step 20666] Loss: 9.50e+07 -1.1517726182937622 0.10138622671365738\n",
      "[Step 20667] Loss: 9.41e+07 -1.1518186330795288 0.10138705372810364\n",
      "[Step 20668] Loss: 9.43e+07 -1.1518831253051758 0.10139118134975433\n",
      "[Step 20669] Loss: 9.44e+07 -1.151770830154419 0.1014019101858139\n",
      "[Step 20670] Loss: 9.50e+07 -1.1515724658966064 0.10140933096408844\n",
      "[Step 20671] Loss: 9.36e+07 -1.1513748168945312 0.10139860957860947\n",
      "[Step 20672] Loss: 9.40e+07 -1.1512534618377686 0.10140521079301834\n",
      "[Step 20673] Loss: 9.38e+07 -1.1510721445083618 0.10143078863620758\n",
      "[Step 20674] Loss: 9.43e+07 -1.1509199142456055 0.10144811123609543\n",
      "[Step 20675] Loss: 9.40e+07 -1.1508796215057373 0.10145306587219238\n",
      "[Step 20676] Loss: 9.50e+07 -1.1510086059570312 0.1014324352145195\n",
      "[Step 20677] Loss: 9.39e+07 -1.1511541604995728 0.10144316405057907\n",
      "[Step 20678] Loss: 9.41e+07 -1.1513205766677856 0.10142170637845993\n",
      "[Step 20679] Loss: 9.41e+07 -1.1514770984649658 0.10139448195695877\n",
      "[Step 20680] Loss: 9.41e+07 -1.1516520977020264 0.10137137770652771\n",
      "[Step 20681] Loss: 9.42e+07 -1.1518619060516357 0.10132929682731628\n",
      "[Step 20682] Loss: 9.48e+07 -1.1519501209259033 0.10130206495523453\n",
      "[Step 20683] Loss: 9.43e+07 -1.1521172523498535 0.10127483308315277\n",
      "[Step 20684] Loss: 9.41e+07 -1.1521364450454712 0.1012558564543724\n",
      "[Step 20685] Loss: 9.50e+07 -1.1520054340362549 0.1012335792183876\n",
      "[Step 20686] Loss: 9.45e+07 -1.1519097089767456 0.10125751048326492\n",
      "[Step 20687] Loss: 9.40e+07 -1.1517857313156128 0.10124760866165161\n",
      "[Step 20688] Loss: 9.43e+07 -1.15171480178833 0.10124842822551727\n",
      "[Step 20689] Loss: 9.72e+07 -1.1521639823913574 0.10118819773197174\n",
      "[Step 20690] Loss: 9.42e+07 -1.1526622772216797 0.10115271806716919\n",
      "[Step 20691] Loss: 9.48e+07 -1.1531437635421753 0.10109743475914001\n",
      "[Step 20692] Loss: 9.46e+07 -1.1536704301834106 0.10102152079343796\n",
      "[Step 20693] Loss: 9.49e+07 -1.1543006896972656 0.1009456068277359\n",
      "[Step 20694] Loss: 9.40e+07 -1.1549394130706787 0.10085731744766235\n",
      "[Step 20695] Loss: 9.53e+07 -1.1553771495819092 0.1008078083395958\n",
      "[Step 20696] Loss: 9.46e+07 -1.1558253765106201 0.10076242685317993\n",
      "[Step 20697] Loss: 9.48e+07 -1.1562334299087524 0.1007244661450386\n",
      "[Step 20698] Loss: 9.48e+07 -1.1565250158309937 0.10069311410188675\n",
      "[Step 20699] Loss: 9.45e+07 -1.1569405794143677 0.10064113140106201\n",
      "[Step 20700] Loss: 9.48e+07 -1.1574251651763916 0.10059409588575363\n",
      "[Step 20701] Loss: 9.42e+07 -1.1579041481018066 0.10052313655614853\n",
      "[Step 20702] Loss: 9.36e+07 -1.1583616733551025 0.10048188269138336\n",
      "[Step 20703] Loss: 9.41e+07 -1.1587402820587158 0.10040678828954697\n",
      "[Step 20704] Loss: 9.41e+07 -1.159067153930664 0.10036223381757736\n",
      "[Step 20705] Loss: 9.46e+07 -1.1592743396759033 0.10032428056001663\n",
      "[Step 20706] Loss: 9.45e+07 -1.159421443939209 0.10033170133829117\n",
      "[Step 20707] Loss: 9.49e+07 -1.159653663635254 0.10032262653112411\n",
      "[Step 20708] Loss: 9.47e+07 -1.1598308086395264 0.1003127247095108\n",
      "[Step 20709] Loss: 9.46e+07 -1.1600332260131836 0.10028879344463348\n",
      "[Step 20710] Loss: 9.44e+07 -1.1601276397705078 0.10026569664478302\n",
      "[Step 20711] Loss: 9.60e+07 -1.1600406169891357 0.10026981681585312\n",
      "[Step 20712] Loss: 9.41e+07 -1.1599332094192505 0.10028549283742905\n",
      "[Step 20713] Loss: 9.42e+07 -1.1598036289215088 0.10029292106628418\n",
      "[Step 20714] Loss: 9.43e+07 -1.1596214771270752 0.10032015293836594\n",
      "[Step 20715] Loss: 9.41e+07 -1.159380316734314 0.10033995658159256\n",
      "[Step 20716] Loss: 9.41e+07 -1.1591732501983643 0.10034655779600143\n",
      "[Step 20717] Loss: 9.43e+07 -1.1588609218597412 0.10038698464632034\n",
      "[Step 20718] Loss: 9.43e+07 -1.1585489511489868 0.10041999071836472\n",
      "[Step 20719] Loss: 9.41e+07 -1.1582459211349487 0.10046537965536118\n",
      "[Step 20720] Loss: 9.47e+07 -1.1579182147979736 0.1005033329129219\n",
      "[Step 20721] Loss: 9.48e+07 -1.1576170921325684 0.10054624080657959\n",
      "[Step 20722] Loss: 9.48e+07 -1.157503604888916 0.10058337450027466\n",
      "[Step 20723] Loss: 9.33e+07 -1.157385230064392 0.10058172047138214\n",
      "[Step 20724] Loss: 9.37e+07 -1.157270073890686 0.10058172047138214\n",
      "[Step 20725] Loss: 9.51e+07 -1.1571528911590576 0.10057677328586578\n",
      "[Step 20726] Loss: 9.45e+07 -1.157102346420288 0.10053056478500366\n",
      "[Step 20727] Loss: 9.50e+07 -1.1571182012557983 0.10052726417779922\n",
      "[Step 20728] Loss: 9.47e+07 -1.1571258306503296 0.10053138434886932\n",
      "[Step 20729] Loss: 9.46e+07 -1.1571015119552612 0.10052478313446045\n",
      "[Step 20730] Loss: 9.39e+07 -1.1571067571640015 0.10050497949123383\n",
      "[Step 20731] Loss: 9.45e+07 -1.15724778175354 0.10048022866249084\n",
      "[Step 20732] Loss: 9.43e+07 -1.1574134826660156 0.10044557601213455\n",
      "[Step 20733] Loss: 9.48e+07 -1.157488226890564 0.10041669011116028\n",
      "[Step 20734] Loss: 9.39e+07 -1.1576567888259888 0.10040018707513809\n",
      "[Step 20735] Loss: 9.48e+07 -1.1578705310821533 0.10038451105356216\n",
      "[Step 20736] Loss: 9.40e+07 -1.158008098602295 0.10038451105356216\n",
      "[Step 20737] Loss: 9.40e+07 -1.1581836938858032 0.10034490376710892\n",
      "[Step 20738] Loss: 9.37e+07 -1.1582757234573364 0.10032922774553299\n",
      "[Step 20739] Loss: 9.44e+07 -1.1583983898162842 0.10032262653112411\n",
      "[Step 20740] Loss: 9.45e+07 -1.1585381031036377 0.10031602531671524\n",
      "[Step 20741] Loss: 9.42e+07 -1.1586143970489502 0.10030282288789749\n",
      "[Step 20742] Loss: 9.39e+07 -1.1586767435073853 0.1002986952662468\n",
      "[Step 20743] Loss: 9.42e+07 -1.1586329936981201 0.10032262653112411\n",
      "[Step 20744] Loss: 9.45e+07 -1.158584475517273 0.1003127247095108\n",
      "[Step 20745] Loss: 9.37e+07 -1.1585490703582764 0.10029127448797226\n",
      "[Step 20746] Loss: 9.38e+07 -1.1585285663604736 0.10028219223022461\n",
      "[Step 20747] Loss: 9.49e+07 -1.158420443534851 0.10029127448797226\n",
      "[Step 20748] Loss: 9.45e+07 -1.158211350440979 0.10031932592391968\n",
      "[Step 20749] Loss: 9.49e+07 -1.158176064491272 0.10031932592391968\n",
      "[Step 20750] Loss: 9.44e+07 -1.1581224203109741 0.10031025111675262\n",
      "[Step 20751] Loss: 9.46e+07 -1.1580240726470947 0.10032592713832855\n",
      "[Step 20752] Loss: 9.42e+07 -1.158036708831787 0.1003350019454956\n",
      "[Step 20753] Loss: 9.40e+07 -1.158069133758545 0.10034408420324326\n",
      "[Step 20754] Loss: 9.44e+07 -1.1581331491470337 0.10034490376710892\n",
      "[Step 20755] Loss: 9.53e+07 -1.158264398574829 0.10032922774553299\n",
      "[Step 20756] Loss: 9.42e+07 -1.158394694328308 0.10029539465904236\n",
      "[Step 20757] Loss: 9.46e+07 -1.158433437347412 0.10030942410230637\n",
      "[Step 20758] Loss: 9.46e+07 -1.1584954261779785 0.10032179951667786\n",
      "[Step 20759] Loss: 9.41e+07 -1.15861976146698 0.10030777752399445\n",
      "[Step 20760] Loss: 9.44e+07 -1.1587814092636108 0.10029787570238113\n",
      "[Step 20761] Loss: 9.45e+07 -1.1588976383209229 0.10028962045907974\n",
      "[Step 20762] Loss: 9.39e+07 -1.1590111255645752 0.10025909543037415\n",
      "[Step 20763] Loss: 9.40e+07 -1.1591346263885498 0.10025496780872345\n",
      "[Step 20764] Loss: 9.48e+07 -1.1590969562530518 0.10026569664478302\n",
      "[Step 20765] Loss: 9.41e+07 -1.1591453552246094 0.10025331377983093\n",
      "[Step 20766] Loss: 9.44e+07 -1.1591664552688599 0.10023103654384613\n",
      "[Step 20767] Loss: 9.43e+07 -1.1593323945999146 0.1002153605222702\n",
      "[Step 20768] Loss: 9.43e+07 -1.1594396829605103 0.1001972034573555\n",
      "[Step 20769] Loss: 9.50e+07 -1.1594699621200562 0.1001930832862854\n",
      "[Step 20770] Loss: 9.40e+07 -1.1594921350479126 0.1001708060503006\n",
      "[Step 20771] Loss: 9.41e+07 -1.1595206260681152 0.10017905384302139\n",
      "[Step 20772] Loss: 9.43e+07 -1.159716248512268 0.10015182197093964\n",
      "[Step 20773] Loss: 9.41e+07 -1.160019874572754 0.10012129694223404\n",
      "[Step 20774] Loss: 9.50e+07 -1.1604619026184082 0.1000651866197586\n",
      "[Step 20775] Loss: 9.45e+07 -1.160833716392517 0.10000412166118622\n",
      "[Step 20776] Loss: 9.53e+07 -1.1613520383834839 0.09994719177484512\n",
      "[Step 20777] Loss: 9.47e+07 -1.1618404388427734 0.09991831332445145\n",
      "[Step 20778] Loss: 9.51e+07 -1.1624678373336792 0.09985394775867462\n",
      "[Step 20779] Loss: 9.50e+07 -1.1631287336349487 0.09977473318576813\n",
      "[Step 20780] Loss: 9.38e+07 -1.163803219795227 0.0997062474489212\n",
      "[Step 20781] Loss: 9.47e+07 -1.164373517036438 0.09964436292648315\n",
      "[Step 20782] Loss: 9.47e+07 -1.164960503578186 0.09957670420408249\n",
      "[Step 20783] Loss: 9.44e+07 -1.165433645248413 0.09953709691762924\n",
      "[Step 20784] Loss: 9.36e+07 -1.1658810377120972 0.09949666261672974\n",
      "[Step 20785] Loss: 9.59e+07 -1.1665092706680298 0.09941332787275314\n",
      "[Step 20786] Loss: 9.40e+07 -1.167032241821289 0.09933576732873917\n",
      "[Step 20787] Loss: 9.44e+07 -1.167490005493164 0.09927965700626373\n",
      "[Step 20788] Loss: 9.39e+07 -1.1678540706634521 0.09924416989088058\n",
      "[Step 20789] Loss: 9.42e+07 -1.1682788133621216 0.09919466823339462\n",
      "[Step 20790] Loss: 9.47e+07 -1.168776035308838 0.099122054874897\n",
      "[Step 20791] Loss: 9.43e+07 -1.1692676544189453 0.09904861450195312\n",
      "[Step 20792] Loss: 9.39e+07 -1.1697165966033936 0.09899085760116577\n",
      "[Step 20793] Loss: 9.39e+07 -1.1701651811599731 0.09894217550754547\n",
      "[Step 20794] Loss: 9.50e+07 -1.1705739498138428 0.09890009462833405\n",
      "[Step 20795] Loss: 9.39e+07 -1.1709535121917725 0.09885470569133759\n",
      "[Step 20796] Loss: 9.53e+07 -1.1713237762451172 0.0987936481833458\n",
      "[Step 20797] Loss: 9.42e+07 -1.171724796295166 0.0987449660897255\n",
      "[Step 20798] Loss: 9.44e+07 -1.1721339225769043 0.09871608763933182\n",
      "[Step 20799] Loss: 9.48e+07 -1.1725223064422607 0.09867648035287857\n",
      "[Step 20800] Loss: 9.49e+07 -1.1728496551513672 0.09861129522323608\n",
      "[Step 20801] Loss: 9.38e+07 -1.1731548309326172 0.09856673330068588\n",
      "[Step 20802] Loss: 9.46e+07 -1.1735025644302368 0.09852547943592072\n",
      "[Step 20803] Loss: 9.46e+07 -1.1739747524261475 0.09845864027738571\n",
      "[Step 20804] Loss: 9.47e+07 -1.174423336982727 0.09840831160545349\n",
      "[Step 20805] Loss: 9.55e+07 -1.1746870279312134 0.09838768094778061\n",
      "[Step 20806] Loss: 9.41e+07 -1.1749217510223389 0.0983513742685318\n",
      "[Step 20807] Loss: 9.39e+07 -1.1751537322998047 0.09829774498939514\n",
      "[Step 20808] Loss: 9.42e+07 -1.1754345893859863 0.0982540100812912\n",
      "[Step 20809] Loss: 9.48e+07 -1.175858497619629 0.09819955378770828\n",
      "[Step 20810] Loss: 9.53e+07 -1.1764791011810303 0.09812033921480179\n",
      "[Step 20811] Loss: 9.41e+07 -1.177025556564331 0.09804607182741165\n",
      "[Step 20812] Loss: 9.45e+07 -1.1775288581848145 0.09798336774110794\n",
      "[Step 20813] Loss: 9.49e+07 -1.1778939962387085 0.09793385863304138\n",
      "[Step 20814] Loss: 9.48e+07 -1.1782745122909546 0.09787444770336151\n",
      "[Step 20815] Loss: 9.39e+07 -1.178722858428955 0.09781916439533234\n",
      "[Step 20816] Loss: 9.38e+07 -1.179057240486145 0.09780018031597137\n",
      "[Step 20817] Loss: 9.42e+07 -1.1793001890182495 0.09775067865848541\n",
      "[Step 20818] Loss: 9.43e+07 -1.1795125007629395 0.09769951552152634\n",
      "[Step 20819] Loss: 9.36e+07 -1.1796163320541382 0.09768301248550415\n",
      "[Step 20820] Loss: 9.38e+07 -1.1797221899032593 0.09767146408557892\n",
      "[Step 20821] Loss: 9.41e+07 -1.1797376871109009 0.09764670580625534\n",
      "[Step 20822] Loss: 9.49e+07 -1.1799328327178955 0.09761865437030792\n",
      "[Step 20823] Loss: 9.38e+07 -1.1800590753555298 0.09758482128381729\n",
      "[Step 20824] Loss: 9.46e+07 -1.1800826787948608 0.09757161885499954\n",
      "[Step 20825] Loss: 9.37e+07 -1.1800827980041504 0.09756914526224136\n",
      "[Step 20826] Loss: 9.41e+07 -1.1800200939178467 0.09757409989833832\n",
      "[Step 20827] Loss: 9.39e+07 -1.179953932762146 0.09757409989833832\n",
      "[Step 20828] Loss: 9.48e+07 -1.18000328540802 0.09754934161901474\n",
      "[Step 20829] Loss: 9.43e+07 -1.1800440549850464 0.09755099564790726\n",
      "[Step 20830] Loss: 9.47e+07 -1.1802119016647339 0.09753696620464325\n",
      "[Step 20831] Loss: 9.47e+07 -1.1804498434066772 0.09751633554697037\n",
      "[Step 20832] Loss: 9.41e+07 -1.1805907487869263 0.09749900549650192\n",
      "[Step 20833] Loss: 9.39e+07 -1.180680751800537 0.09748002886772156\n",
      "[Step 20834] Loss: 9.41e+07 -1.180712103843689 0.09749158471822739\n",
      "[Step 20835] Loss: 9.47e+07 -1.1807082891464233 0.09748250246047974\n",
      "[Step 20836] Loss: 9.39e+07 -1.1805919408798218 0.09748580306768417\n",
      "[Step 20837] Loss: 9.45e+07 -1.180388331413269 0.09751386195421219\n",
      "[Step 20838] Loss: 9.41e+07 -1.180256962776184 0.09752623736858368\n",
      "[Step 20839] Loss: 9.41e+07 -1.1801189184188843 0.09754439443349838\n",
      "[Step 20840] Loss: 9.44e+07 -1.1801180839538574 0.09753779321908951\n",
      "[Step 20841] Loss: 9.36e+07 -1.1801698207855225 0.09753531217575073\n",
      "[Step 20842] Loss: 9.42e+07 -1.1801462173461914 0.0975460410118103\n",
      "[Step 20843] Loss: 9.33e+07 -1.1801396608352661 0.09756997227668762\n",
      "[Step 20844] Loss: 9.43e+07 -1.1801890134811401 0.09756337106227875\n",
      "[Step 20845] Loss: 9.44e+07 -1.1802599430084229 0.09755676984786987\n",
      "[Step 20846] Loss: 9.41e+07 -1.1803361177444458 0.09755264222621918\n",
      "[Step 20847] Loss: 9.33e+07 -1.180402159690857 0.09753036499023438\n",
      "[Step 20848] Loss: 9.35e+07 -1.1804453134536743 0.09750230610370636\n",
      "[Step 20849] Loss: 9.47e+07 -1.1806319952011108 0.09745940566062927\n",
      "[Step 20850] Loss: 9.43e+07 -1.1807832717895508 0.09743877500295639\n",
      "[Step 20851] Loss: 9.58e+07 -1.1807879209518433 0.0974222719669342\n",
      "[Step 20852] Loss: 9.56e+07 -1.180660605430603 0.09743300080299377\n",
      "[Step 20853] Loss: 9.62e+07 -1.1804403066635132 0.0974569246172905\n",
      "[Step 20854] Loss: 9.39e+07 -1.1802372932434082 0.0974709540605545\n",
      "[Step 20855] Loss: 9.57e+07 -1.1799167394638062 0.09751303493976593\n",
      "[Step 20856] Loss: 9.42e+07 -1.1796587705612183 0.09754356741905212\n",
      "[Step 20857] Loss: 9.47e+07 -1.1795916557312012 0.09754356741905212\n",
      "[Step 20858] Loss: 9.45e+07 -1.1794685125350952 0.09754521399736404\n",
      "[Step 20859] Loss: 9.41e+07 -1.179356575012207 0.09754439443349838\n",
      "[Step 20860] Loss: 9.53e+07 -1.1793938875198364 0.09753036499023438\n",
      "[Step 20861] Loss: 9.48e+07 -1.1793533563613892 0.09753696620464325\n",
      "[Step 20862] Loss: 9.43e+07 -1.1793400049209595 0.09751303493976593\n",
      "[Step 20863] Loss: 9.46e+07 -1.1792877912521362 0.09754439443349838\n",
      "[Step 20864] Loss: 9.41e+07 -1.1792304515838623 0.09754109382629395\n",
      "[Step 20865] Loss: 9.52e+07 -1.1790918111801147 0.097550168633461\n",
      "[Step 20866] Loss: 9.45e+07 -1.1790482997894287 0.09752541035413742\n",
      "[Step 20867] Loss: 9.42e+07 -1.179014801979065 0.09752046316862106\n",
      "[Step 20868] Loss: 9.54e+07 -1.178917646408081 0.0975320115685463\n",
      "[Step 20869] Loss: 9.45e+07 -1.1789129972457886 0.0975278913974762\n",
      "[Step 20870] Loss: 9.56e+07 -1.1787651777267456 0.09755676984786987\n",
      "[Step 20871] Loss: 9.44e+07 -1.1786178350448608 0.09756667166948318\n",
      "[Step 20872] Loss: 9.44e+07 -1.1784509420394897 0.09757987409830093\n",
      "[Step 20873] Loss: 9.45e+07 -1.1784182786941528 0.09758070111274719\n",
      "[Step 20874] Loss: 9.42e+07 -1.178387999534607 0.09757740050554276\n",
      "[Step 20875] Loss: 9.42e+07 -1.1782487630844116 0.09762608259916306\n",
      "[Step 20876] Loss: 9.43e+07 -1.1781543493270874 0.09762030094861984\n",
      "[Step 20877] Loss: 9.42e+07 -1.17811918258667 0.0976252555847168\n",
      "[Step 20878] Loss: 9.43e+07 -1.1781004667282104 0.09762195497751236\n",
      "[Step 20879] Loss: 9.40e+07 -1.1780061721801758 0.0976392850279808\n",
      "[Step 20880] Loss: 9.44e+07 -1.1780400276184082 0.09764588624238968\n",
      "[Step 20881] Loss: 9.53e+07 -1.1779649257659912 0.09765743464231491\n",
      "[Step 20882] Loss: 9.41e+07 -1.1778967380523682 0.09764670580625534\n",
      "[Step 20883] Loss: 9.41e+07 -1.1778607368469238 0.0976516604423523\n",
      "[Step 20884] Loss: 9.40e+07 -1.1777136325836182 0.09766320884227753\n",
      "[Step 20885] Loss: 9.50e+07 -1.1777231693267822 0.09762608259916306\n",
      "[Step 20886] Loss: 9.51e+07 -1.1775346994400024 0.09763763099908829\n",
      "[Step 20887] Loss: 9.40e+07 -1.1774135828018188 0.09764175862073898\n",
      "[Step 20888] Loss: 9.53e+07 -1.1774218082427979 0.09763515740633011\n",
      "[Step 20889] Loss: 9.49e+07 -1.1773135662078857 0.0976475328207016\n",
      "[Step 20890] Loss: 9.46e+07 -1.177165150642395 0.09767311066389084\n",
      "[Step 20891] Loss: 9.40e+07 -1.177021861076355 0.09766733646392822\n",
      "[Step 20892] Loss: 9.34e+07 -1.1768907308578491 0.09768053889274597\n",
      "[Step 20893] Loss: 9.42e+07 -1.1767628192901611 0.09771684557199478\n",
      "[Step 20894] Loss: 9.38e+07 -1.1766350269317627 0.09773004800081253\n",
      "[Step 20895] Loss: 9.41e+07 -1.176537275314331 0.09772427380084991\n",
      "[Step 20896] Loss: 9.29e+07 -1.1764178276062012 0.09774655103683472\n",
      "[Step 20897] Loss: 9.42e+07 -1.1762211322784424 0.09775892645120621\n",
      "[Step 20898] Loss: 9.46e+07 -1.176112174987793 0.09776552766561508\n",
      "[Step 20899] Loss: 9.46e+07 -1.1761128902435303 0.09776388108730316\n",
      "[Step 20900] Loss: 9.42e+07 -1.176119089126587 0.09773994982242584\n",
      "[Step 20901] Loss: 9.42e+07 -1.1761428117752075 0.09775975346565247\n",
      "[Step 20902] Loss: 9.46e+07 -1.1760973930358887 0.09776140004396439\n",
      "[Step 20903] Loss: 9.43e+07 -1.1761201620101929 0.09775645285844803\n",
      "[Step 20904] Loss: 9.46e+07 -1.1761691570281982 0.09776635468006134\n",
      "[Step 20905] Loss: 9.51e+07 -1.1761693954467773 0.09778863191604614\n",
      "[Step 20906] Loss: 9.58e+07 -1.1760367155075073 0.0977894589304924\n",
      "[Step 20907] Loss: 9.45e+07 -1.176048755645752 0.09780678153038025\n",
      "[Step 20908] Loss: 9.50e+07 -1.1761528253555298 0.09778780490159988\n",
      "[Step 20909] Loss: 9.48e+07 -1.176257848739624 0.09777790307998657\n",
      "[Step 20910] Loss: 9.49e+07 -1.176403284072876 0.09776965528726578\n",
      "[Step 20911] Loss: 9.45e+07 -1.1766246557235718 0.09774572402238846\n",
      "[Step 20912] Loss: 9.57e+07 -1.176730751991272 0.0977366492152214\n",
      "[Step 20913] Loss: 9.46e+07 -1.1767544746398926 0.0977490246295929\n",
      "[Step 20914] Loss: 9.49e+07 -1.176914095878601 0.09774737805128098\n",
      "[Step 20915] Loss: 9.42e+07 -1.177170991897583 0.09774325042963028\n",
      "[Step 20916] Loss: 9.48e+07 -1.1772820949554443 0.09772757440805435\n",
      "[Step 20917] Loss: 9.61e+07 -1.1777070760726929 0.09767559170722961\n",
      "[Step 20918] Loss: 9.44e+07 -1.1780509948730469 0.09760875254869461\n",
      "[Step 20919] Loss: 9.42e+07 -1.1783485412597656 0.09758152067661285\n",
      "[Step 20920] Loss: 9.43e+07 -1.1787251234054565 0.09752953797578812\n",
      "[Step 20921] Loss: 9.50e+07 -1.1791914701461792 0.09748580306768417\n",
      "[Step 20922] Loss: 9.39e+07 -1.1796181201934814 0.09741484373807907\n",
      "[Step 20923] Loss: 9.41e+07 -1.1800287961959839 0.09736368805170059\n",
      "[Step 20924] Loss: 9.48e+07 -1.180319905281067 0.09732820838689804\n",
      "[Step 20925] Loss: 9.36e+07 -1.1806265115737915 0.09730592370033264\n",
      "[Step 20926] Loss: 9.44e+07 -1.1809087991714478 0.09726879745721817\n",
      "[Step 20927] Loss: 9.38e+07 -1.1810423135757446 0.09725476801395416\n",
      "[Step 20928] Loss: 9.38e+07 -1.1811528205871582 0.09722671657800674\n",
      "[Step 20929] Loss: 9.43e+07 -1.1812734603881836 0.0972399190068245\n",
      "[Step 20930] Loss: 9.45e+07 -1.1813881397247314 0.09721268713474274\n",
      "[Step 20931] Loss: 9.44e+07 -1.1814038753509521 0.09723001718521118\n",
      "[Step 20932] Loss: 9.47e+07 -1.181447148323059 0.09722176194190979\n",
      "[Step 20933] Loss: 9.44e+07 -1.1814756393432617 0.097213514149189\n",
      "[Step 20934] Loss: 9.40e+07 -1.1815385818481445 0.09720113128423691\n",
      "[Step 20935] Loss: 9.41e+07 -1.1815129518508911 0.0972093865275383\n",
      "[Step 20936] Loss: 9.40e+07 -1.1813963651657104 0.09724321961402893\n",
      "[Step 20937] Loss: 9.41e+07 -1.1812739372253418 0.09726466983556747\n",
      "[Step 20938] Loss: 9.49e+07 -1.1810686588287354 0.09729520231485367\n",
      "[Step 20939] Loss: 9.66e+07 -1.1812562942504883 0.09727951884269714\n",
      "[Step 20940] Loss: 9.44e+07 -1.1813302040100098 0.09727869927883148\n",
      "[Step 20941] Loss: 9.41e+07 -1.1814402341842651 0.09727539867162704\n",
      "[Step 20942] Loss: 9.52e+07 -1.1816800832748413 0.09724486619234085\n",
      "[Step 20943] Loss: 9.48e+07 -1.1819891929626465 0.0971829816699028\n",
      "[Step 20944] Loss: 9.44e+07 -1.1823630332946777 0.09712109714746475\n",
      "[Step 20945] Loss: 9.42e+07 -1.182692527770996 0.0970674604177475\n",
      "[Step 20946] Loss: 9.43e+07 -1.1830952167510986 0.0970328077673912\n",
      "[Step 20947] Loss: 9.52e+07 -1.183417797088623 0.09699402749538422\n",
      "[Step 20948] Loss: 9.41e+07 -1.1837249994277954 0.09696266800165176\n",
      "[Step 20949] Loss: 9.41e+07 -1.1840784549713135 0.09693296253681183\n",
      "[Step 20950] Loss: 9.44e+07 -1.1843912601470947 0.0968908816576004\n",
      "[Step 20951] Loss: 9.53e+07 -1.1848416328430176 0.0968504548072815\n",
      "[Step 20952] Loss: 9.42e+07 -1.1852948665618896 0.09679269045591354\n",
      "[Step 20953] Loss: 9.49e+07 -1.1855719089508057 0.09676133841276169\n",
      "[Step 20954] Loss: 9.44e+07 -1.1857199668884277 0.09675556421279907\n",
      "[Step 20955] Loss: 9.46e+07 -1.186079502105713 0.09672833234071732\n",
      "[Step 20956] Loss: 9.35e+07 -1.1863715648651123 0.0966821238398552\n",
      "[Step 20957] Loss: 9.42e+07 -1.1866542100906372 0.09665077179670334\n",
      "[Step 20958] Loss: 9.41e+07 -1.186954379081726 0.09658723324537277\n",
      "[Step 20959] Loss: 9.44e+07 -1.1873040199279785 0.09655257314443588\n",
      "[Step 20960] Loss: 9.38e+07 -1.1876075267791748 0.09650471806526184\n",
      "[Step 20961] Loss: 9.41e+07 -1.1877949237823486 0.09649234265089035\n",
      "[Step 20962] Loss: 9.39e+07 -1.1879876852035522 0.09647583961486816\n",
      "[Step 20963] Loss: 9.46e+07 -1.1882303953170776 0.09644530713558197\n",
      "[Step 20964] Loss: 9.42e+07 -1.188454031944275 0.09639745205640793\n",
      "[Step 20965] Loss: 9.47e+07 -1.1887708902359009 0.09636939316987991\n",
      "[Step 20966] Loss: 9.44e+07 -1.1889708042144775 0.09633804112672806\n",
      "[Step 20967] Loss: 9.56e+07 -1.1890203952789307 0.09631576389074326\n",
      "[Step 20968] Loss: 9.41e+07 -1.1890783309936523 0.09628688544034958\n",
      "[Step 20969] Loss: 9.60e+07 -1.1889318227767944 0.09629100561141968\n",
      "[Step 20970] Loss: 9.41e+07 -1.1888980865478516 0.09626378118991852\n",
      "[Step 20971] Loss: 9.43e+07 -1.1887685060501099 0.09628193080425262\n",
      "[Step 20972] Loss: 9.40e+07 -1.1885242462158203 0.0963025614619255\n",
      "[Step 20973] Loss: 9.44e+07 -1.1882541179656982 0.09633639454841614\n",
      "[Step 20974] Loss: 9.39e+07 -1.1879560947418213 0.09634794294834137\n",
      "[Step 20975] Loss: 9.47e+07 -1.1876327991485596 0.09636857360601425\n",
      "[Step 20976] Loss: 9.47e+07 -1.1873012781143188 0.09639167785644531\n",
      "[Step 20977] Loss: 9.37e+07 -1.1869866847991943 0.09642715752124786\n",
      "[Step 20978] Loss: 9.41e+07 -1.1867930889129639 0.09641560167074203\n",
      "[Step 20979] Loss: 9.38e+07 -1.1866651773452759 0.09639992564916611\n",
      "[Step 20980] Loss: 9.47e+07 -1.1865134239196777 0.09641312807798386\n",
      "[Step 20981] Loss: 9.49e+07 -1.1864702701568604 0.09640982747077942\n",
      "[Step 20982] Loss: 9.53e+07 -1.186308741569519 0.09643375873565674\n",
      "[Step 20983] Loss: 9.42e+07 -1.1861339807510376 0.09644366055727005\n",
      "[Step 20984] Loss: 9.41e+07 -1.186084508895874 0.09645108133554459\n",
      "[Step 20985] Loss: 9.43e+07 -1.1860953569412231 0.09642055630683899\n",
      "[Step 20986] Loss: 9.46e+07 -1.185999870300293 0.09642715752124786\n",
      "[Step 20987] Loss: 9.44e+07 -1.1858241558074951 0.09644118696451187\n",
      "[Step 20988] Loss: 9.44e+07 -1.1857693195343018 0.096434585750103\n",
      "[Step 20989] Loss: 9.42e+07 -1.1856539249420166 0.09643623232841492\n",
      "[Step 20990] Loss: 9.43e+07 -1.1855052709579468 0.09645356237888336\n",
      "[Step 20991] Loss: 9.39e+07 -1.1854188442230225 0.09646841138601303\n",
      "[Step 20992] Loss: 9.48e+07 -1.1853909492492676 0.09645933657884598\n",
      "[Step 20993] Loss: 9.39e+07 -1.1853508949279785 0.09645108133554459\n",
      "[Step 20994] Loss: 9.39e+07 -1.185282588005066 0.09645520895719528\n",
      "[Step 20995] Loss: 9.46e+07 -1.1851961612701416 0.09644778072834015\n",
      "[Step 20996] Loss: 9.41e+07 -1.1851953268051147 0.09646758437156677\n",
      "[Step 20997] Loss: 9.45e+07 -1.1851507425308228 0.09645933657884598\n",
      "[Step 20998] Loss: 9.45e+07 -1.1850823163986206 0.0964791402220726\n",
      "[Step 20999] Loss: 9.47e+07 -1.1849795579910278 0.09647831320762634\n",
      "[Step 21000] Loss: 9.42e+07 -1.1848466396331787 0.09647748619318008\n",
      "[Step 21001] Loss: 9.50e+07 -1.1846219301223755 0.09649811685085297\n",
      "[Step 21002] Loss: 9.44e+07 -1.1845601797103882 0.0965137928724289\n",
      "[Step 21003] Loss: 9.41e+07 -1.184484601020813 0.09651049226522446\n",
      "[Step 21004] Loss: 9.39e+07 -1.184362769126892 0.09652122110128403\n",
      "[Step 21005] Loss: 9.42e+07 -1.1843160390853882 0.09652204811573029\n",
      "[Step 21006] Loss: 9.43e+07 -1.1842811107635498 0.09651792049407959\n",
      "[Step 21007] Loss: 9.43e+07 -1.1843053102493286 0.09650471806526184\n",
      "[Step 21008] Loss: 9.48e+07 -1.1842422485351562 0.0965319499373436\n",
      "[Step 21009] Loss: 9.31e+07 -1.184167742729187 0.09656165540218353\n",
      "[Step 21010] Loss: 9.42e+07 -1.1839853525161743 0.0965806320309639\n",
      "[Step 21011] Loss: 9.53e+07 -1.1837005615234375 0.09661858528852463\n",
      "[Step 21012] Loss: 9.39e+07 -1.1834115982055664 0.09664664417505264\n",
      "[Step 21013] Loss: 9.48e+07 -1.1833794116973877 0.0966557189822197\n",
      "[Step 21014] Loss: 9.39e+07 -1.1833997964859009 0.09666809439659119\n",
      "[Step 21015] Loss: 9.45e+07 -1.1835789680480957 0.09667469561100006\n",
      "[Step 21016] Loss: 9.48e+07 -1.183837652206421 0.09664829075336456\n",
      "[Step 21017] Loss: 9.48e+07 -1.1839323043823242 0.09665241837501526\n",
      "[Step 21018] Loss: 9.51e+07 -1.183941125869751 0.09665241837501526\n",
      "[Step 21019] Loss: 9.45e+07 -1.1841187477111816 0.096651591360569\n",
      "[Step 21020] Loss: 9.47e+07 -1.1842150688171387 0.09663921594619751\n",
      "[Step 21021] Loss: 9.44e+07 -1.1844240427017212 0.09660620987415314\n",
      "[Step 21022] Loss: 9.50e+07 -1.1847727298736572 0.0965583547949791\n",
      "[Step 21023] Loss: 9.47e+07 -1.1851636171340942 0.09653112292289734\n",
      "[Step 21024] Loss: 9.46e+07 -1.1855409145355225 0.09648986905813217\n",
      "[Step 21025] Loss: 9.50e+07 -1.186039924621582 0.09643540531396866\n",
      "[Step 21026] Loss: 9.44e+07 -1.1865686178207397 0.09639249742031097\n",
      "[Step 21027] Loss: 9.44e+07 -1.186991810798645 0.0963512435555458\n",
      "[Step 21028] Loss: 9.46e+07 -1.1873277425765991 0.09630338847637177\n",
      "[Step 21029] Loss: 9.51e+07 -1.187812089920044 0.09623902291059494\n",
      "[Step 21030] Loss: 9.43e+07 -1.1882665157318115 0.09619034081697464\n",
      "[Step 21031] Loss: 9.38e+07 -1.1886630058288574 0.09614578634500504\n",
      "[Step 21032] Loss: 9.48e+07 -1.1890195608139038 0.09610700607299805\n",
      "[Step 21033] Loss: 9.44e+07 -1.1894532442092896 0.09605501592159271\n",
      "[Step 21034] Loss: 9.47e+07 -1.189773678779602 0.09601293504238129\n",
      "[Step 21035] Loss: 9.47e+07 -1.1900767087936401 0.09598241001367569\n",
      "[Step 21036] Loss: 9.37e+07 -1.1903481483459473 0.09595682471990585\n",
      "[Step 21037] Loss: 9.43e+07 -1.1905333995819092 0.09593620151281357\n",
      "[Step 21038] Loss: 9.35e+07 -1.1906769275665283 0.09592382609844208\n",
      "[Step 21039] Loss: 9.42e+07 -1.1908745765686035 0.09590236842632294\n",
      "[Step 21040] Loss: 9.42e+07 -1.191100835800171 0.09586936235427856\n",
      "[Step 21041] Loss: 9.46e+07 -1.1912399530410767 0.09584461152553558\n",
      "[Step 21042] Loss: 9.53e+07 -1.191538691520691 0.09580500423908234\n",
      "[Step 21043] Loss: 9.47e+07 -1.1917994022369385 0.09577612578868866\n",
      "[Step 21044] Loss: 9.43e+07 -1.1920180320739746 0.0957530215382576\n",
      "[Step 21045] Loss: 9.44e+07 -1.1922225952148438 0.09574063867330551\n",
      "[Step 21046] Loss: 9.43e+07 -1.1924779415130615 0.09570598602294922\n",
      "[Step 21047] Loss: 9.50e+07 -1.1925972700119019 0.09569691121578217\n",
      "[Step 21048] Loss: 9.45e+07 -1.1926637887954712 0.09568535536527634\n",
      "[Step 21049] Loss: 9.39e+07 -1.1926895380020142 0.09570268541574478\n",
      "[Step 21050] Loss: 9.42e+07 -1.1927456855773926 0.0957043394446373\n",
      "[Step 21051] Loss: 9.46e+07 -1.1929104328155518 0.09571506083011627\n",
      "[Step 21052] Loss: 9.46e+07 -1.193241834640503 0.09567875415086746\n",
      "[Step 21053] Loss: 9.60e+07 -1.1933842897415161 0.09568040817975998\n",
      "[Step 21054] Loss: 9.44e+07 -1.1934211254119873 0.09567297995090485\n",
      "[Step 21055] Loss: 9.42e+07 -1.193534016609192 0.09566967934370041\n",
      "[Step 21056] Loss: 9.53e+07 -1.1939117908477783 0.09562842547893524\n",
      "[Step 21057] Loss: 9.40e+07 -1.1942310333251953 0.09557726234197617\n",
      "[Step 21058] Loss: 9.55e+07 -1.1944451332092285 0.09554095566272736\n",
      "[Step 21059] Loss: 9.38e+07 -1.1946349143981934 0.09554095566272736\n",
      "[Step 21060] Loss: 9.43e+07 -1.1948081254959106 0.0955318808555603\n",
      "[Step 21061] Loss: 9.49e+07 -1.1950266361236572 0.09552033245563507\n",
      "[Step 21062] Loss: 9.45e+07 -1.1951786279678345 0.09551455080509186\n",
      "[Step 21063] Loss: 9.41e+07 -1.1953953504562378 0.09548979997634888\n",
      "[Step 21064] Loss: 9.38e+07 -1.1956055164337158 0.09548237174749374\n",
      "[Step 21065] Loss: 9.40e+07 -1.1958140134811401 0.0954650491476059\n",
      "[Step 21066] Loss: 9.40e+07 -1.1960104703903198 0.09544441848993301\n",
      "[Step 21067] Loss: 9.44e+07 -1.1963088512420654 0.09544689208269119\n",
      "[Step 21068] Loss: 9.50e+07 -1.196779727935791 0.09539903700351715\n",
      "[Step 21069] Loss: 9.51e+07 -1.1970980167388916 0.09534292668104172\n",
      "[Step 21070] Loss: 9.36e+07 -1.1973576545715332 0.09530001878738403\n",
      "[Step 21071] Loss: 9.43e+07 -1.1976174116134644 0.09527196735143661\n",
      "[Step 21072] Loss: 9.45e+07 -1.1979743242263794 0.09523400664329529\n",
      "[Step 21073] Loss: 9.39e+07 -1.198380470275879 0.09517212212085724\n",
      "[Step 21074] Loss: 9.39e+07 -1.1987069845199585 0.09514901787042618\n",
      "[Step 21075] Loss: 9.42e+07 -1.1991040706634521 0.09509290754795074\n",
      "[Step 21076] Loss: 9.55e+07 -1.1993457078933716 0.09507228434085846\n",
      "[Step 21077] Loss: 9.50e+07 -1.199812889099121 0.09499389678239822\n",
      "[Step 21078] Loss: 9.39e+07 -1.2002016305923462 0.09493283182382584\n",
      "[Step 21079] Loss: 9.40e+07 -1.200636386871338 0.09487424790859222\n",
      "[Step 21080] Loss: 9.41e+07 -1.2010680437088013 0.0948140099644661\n",
      "[Step 21081] Loss: 9.46e+07 -1.2013548612594604 0.09477688372135162\n",
      "[Step 21082] Loss: 9.52e+07 -1.2018197774887085 0.09472407400608063\n",
      "[Step 21083] Loss: 9.42e+07 -1.202276587486267 0.09467621892690659\n",
      "[Step 21084] Loss: 9.43e+07 -1.202623724937439 0.09463661164045334\n",
      "[Step 21085] Loss: 9.44e+07 -1.2029350996017456 0.09457472711801529\n",
      "[Step 21086] Loss: 9.42e+07 -1.2032603025436401 0.09453346580266953\n",
      "[Step 21087] Loss: 9.50e+07 -1.2037708759307861 0.09447570890188217\n",
      "[Step 21088] Loss: 9.49e+07 -1.2041420936584473 0.09444187581539154\n",
      "[Step 21089] Loss: 9.39e+07 -1.2044347524642944 0.0943717435002327\n",
      "[Step 21090] Loss: 9.57e+07 -1.2044928073883057 0.0943494588136673\n",
      "[Step 21091] Loss: 9.41e+07 -1.2045263051986694 0.0943271815776825\n",
      "[Step 21092] Loss: 9.46e+07 -1.204740285873413 0.09428922832012177\n",
      "[Step 21093] Loss: 9.42e+07 -1.2048513889312744 0.09428014606237411\n",
      "[Step 21094] Loss: 9.46e+07 -1.2051118612289429 0.09424054622650146\n",
      "[Step 21095] Loss: 9.37e+07 -1.2052676677703857 0.09421248733997345\n",
      "[Step 21096] Loss: 9.46e+07 -1.2055760622024536 0.09417865425348282\n",
      "[Step 21097] Loss: 9.34e+07 -1.2058509588241577 0.09413987398147583\n",
      "[Step 21098] Loss: 9.53e+07 -1.205863356590271 0.09411676973104477\n",
      "[Step 21099] Loss: 9.47e+07 -1.205877661705017 0.09410852193832397\n",
      "[Step 21100] Loss: 9.44e+07 -1.2058918476104736 0.09410852193832397\n",
      "[Step 21101] Loss: 9.44e+07 -1.2058863639831543 0.09409119188785553\n",
      "[Step 21102] Loss: 9.41e+07 -1.2058265209197998 0.09408211708068848\n",
      "[Step 21103] Loss: 9.64e+07 -1.206187129020691 0.09404828399419785\n",
      "[Step 21104] Loss: 9.51e+07 -1.2066234350204468 0.09400620311498642\n",
      "[Step 21105] Loss: 9.46e+07 -1.2069615125656128 0.0939822718501091\n",
      "[Step 21106] Loss: 9.36e+07 -1.2072346210479736 0.0939517468214035\n",
      "[Step 21107] Loss: 9.45e+07 -1.2074679136276245 0.09393524378538132\n",
      "[Step 21108] Loss: 9.38e+07 -1.207693338394165 0.09390801191329956\n",
      "[Step 21109] Loss: 9.44e+07 -1.2079914808273315 0.09386923164129257\n",
      "[Step 21110] Loss: 9.39e+07 -1.2082033157348633 0.09384199976921082\n",
      "[Step 21111] Loss: 9.38e+07 -1.208367943763733 0.09381972253322601\n",
      "[Step 21112] Loss: 9.37e+07 -1.2084499597549438 0.0937916710972786\n",
      "[Step 21113] Loss: 9.45e+07 -1.2086297273635864 0.09377104043960571\n",
      "[Step 21114] Loss: 9.38e+07 -1.2087124586105347 0.0937652662396431\n",
      "[Step 21115] Loss: 9.54e+07 -1.2086607217788696 0.0937916710972786\n",
      "[Step 21116] Loss: 9.55e+07 -1.208513855934143 0.0938098207116127\n",
      "[Step 21117] Loss: 9.44e+07 -1.208516240119934 0.0937916710972786\n",
      "[Step 21118] Loss: 9.38e+07 -1.2085349559783936 0.09378176927566528\n",
      "[Step 21119] Loss: 9.41e+07 -1.2084721326828003 0.09377928823232651\n",
      "[Step 21120] Loss: 9.53e+07 -1.2086377143859863 0.0937388613820076\n",
      "[Step 21121] Loss: 9.41e+07 -1.2088232040405273 0.09371328353881836\n",
      "[Step 21122] Loss: 9.42e+07 -1.2089955806732178 0.09371328353881836\n",
      "[Step 21123] Loss: 9.39e+07 -1.209065318107605 0.09369678050279617\n",
      "[Step 21124] Loss: 9.48e+07 -1.2090685367584229 0.09368109703063965\n",
      "[Step 21125] Loss: 9.41e+07 -1.2090649604797363 0.09366707503795624\n",
      "[Step 21126] Loss: 9.44e+07 -1.2091172933578491 0.09365387260913849\n",
      "[Step 21127] Loss: 9.49e+07 -1.2092989683151245 0.09363406896591187\n",
      "[Step 21128] Loss: 9.44e+07 -1.2094519138336182 0.09361426532268524\n",
      "[Step 21129] Loss: 9.45e+07 -1.20957612991333 0.09357878565788269\n",
      "[Step 21130] Loss: 9.39e+07 -1.2097108364105225 0.09356062859296799\n",
      "[Step 21131] Loss: 9.37e+07 -1.209841012954712 0.09354577958583832\n",
      "[Step 21132] Loss: 9.36e+07 -1.2098981142044067 0.09355732798576355\n",
      "[Step 21133] Loss: 9.43e+07 -1.2100272178649902 0.09355402737855911\n",
      "[Step 21134] Loss: 9.42e+07 -1.2100975513458252 0.09355155378580093\n",
      "[Step 21135] Loss: 9.41e+07 -1.2101877927780151 0.0935441255569458\n",
      "[Step 21136] Loss: 9.60e+07 -1.2106646299362183 0.0934995710849762\n",
      "[Step 21137] Loss: 9.43e+07 -1.2111692428588867 0.09344923496246338\n",
      "[Step 21138] Loss: 9.37e+07 -1.211603045463562 0.09341458231210709\n",
      "[Step 21139] Loss: 9.44e+07 -1.2118793725967407 0.09339230507612228\n",
      "[Step 21140] Loss: 9.40e+07 -1.212054967880249 0.09336424618959427\n",
      "[Step 21141] Loss: 9.46e+07 -1.2121959924697876 0.09335104376077652\n",
      "[Step 21142] Loss: 9.40e+07 -1.2123082876205444 0.09333784133195877\n",
      "[Step 21143] Loss: 9.54e+07 -1.2125914096832275 0.09331061691045761\n",
      "[Step 21144] Loss: 9.40e+07 -1.2128682136535645 0.09328833222389221\n",
      "[Step 21145] Loss: 9.39e+07 -1.2131708860397339 0.09326770901679993\n",
      "[Step 21146] Loss: 9.57e+07 -1.2132782936096191 0.09327182918787003\n",
      "[Step 21147] Loss: 9.38e+07 -1.213394284248352 0.0932561531662941\n",
      "[Step 21148] Loss: 9.45e+07 -1.2134124040603638 0.09327512979507446\n",
      "[Step 21149] Loss: 9.41e+07 -1.2134507894515991 0.09327182918787003\n",
      "[Step 21150] Loss: 9.40e+07 -1.2135319709777832 0.09324625134468079\n",
      "[Step 21151] Loss: 9.43e+07 -1.2136796712875366 0.09322480112314224\n",
      "[Step 21152] Loss: 9.42e+07 -1.2137469053268433 0.09321819990873337\n",
      "[Step 21153] Loss: 9.38e+07 -1.2137659788131714 0.09322810173034668\n",
      "[Step 21154] Loss: 9.40e+07 -1.2138004302978516 0.0932115986943245\n",
      "[Step 21155] Loss: 9.42e+07 -1.2138481140136719 0.09320994466543198\n",
      "[Step 21156] Loss: 9.46e+07 -1.2138612270355225 0.09322480112314224\n",
      "[Step 21157] Loss: 9.48e+07 -1.2139493227005005 0.09322480112314224\n",
      "[Step 21158] Loss: 9.49e+07 -1.2141348123550415 0.09320994466543198\n",
      "[Step 21159] Loss: 9.46e+07 -1.2144564390182495 0.0931769385933876\n",
      "[Step 21160] Loss: 9.49e+07 -1.2148581743240356 0.09313981235027313\n",
      "[Step 21161] Loss: 9.43e+07 -1.2152072191238403 0.09308204799890518\n",
      "[Step 21162] Loss: 9.44e+07 -1.2154792547225952 0.0930391401052475\n",
      "[Step 21163] Loss: 9.54e+07 -1.2155907154083252 0.09301604330539703\n",
      "[Step 21164] Loss: 9.41e+07 -1.2156703472137451 0.09301191568374634\n",
      "[Step 21165] Loss: 9.45e+07 -1.2158112525939941 0.0930127426981926\n",
      "[Step 21166] Loss: 9.45e+07 -1.215928077697754 0.09301521629095078\n",
      "[Step 21167] Loss: 9.52e+07 -1.216261625289917 0.09295827895402908\n",
      "[Step 21168] Loss: 9.53e+07 -1.2164138555526733 0.09294012933969498\n",
      "[Step 21169] Loss: 9.45e+07 -1.2165271043777466 0.09293187409639359\n",
      "[Step 21170] Loss: 9.42e+07 -1.2166510820388794 0.0929071232676506\n",
      "[Step 21171] Loss: 9.44e+07 -1.2167348861694336 0.09289639443159103\n",
      "[Step 21172] Loss: 9.41e+07 -1.2168049812316895 0.09288731962442398\n",
      "[Step 21173] Loss: 9.42e+07 -1.2169371843338013 0.09285926073789597\n",
      "[Step 21174] Loss: 9.42e+07 -1.2171213626861572 0.09285183995962143\n",
      "[Step 21175] Loss: 9.37e+07 -1.2174072265625 0.09280810505151749\n",
      "[Step 21176] Loss: 9.35e+07 -1.2176620960235596 0.09276272356510162\n",
      "[Step 21177] Loss: 9.47e+07 -1.2181094884872437 0.09270496666431427\n",
      "[Step 21178] Loss: 9.46e+07 -1.2185651063919067 0.09265215694904327\n",
      "[Step 21179] Loss: 9.42e+07 -1.2189537286758423 0.09259439259767532\n",
      "[Step 21180] Loss: 9.45e+07 -1.2194567918777466 0.0925523117184639\n",
      "[Step 21181] Loss: 9.44e+07 -1.2198692560195923 0.09250445663928986\n",
      "[Step 21182] Loss: 9.47e+07 -1.2201247215270996 0.09247969835996628\n",
      "[Step 21183] Loss: 9.38e+07 -1.2203527688980103 0.09245659410953522\n",
      "[Step 21184] Loss: 9.52e+07 -1.2206779718399048 0.09240956604480743\n",
      "[Step 21185] Loss: 9.49e+07 -1.221079707145691 0.09235428273677826\n",
      "[Step 21186] Loss: 9.55e+07 -1.2212315797805786 0.09235098212957382\n",
      "[Step 21187] Loss: 9.45e+07 -1.2212456464767456 0.09234850108623505\n",
      "[Step 21188] Loss: 9.43e+07 -1.221233606338501 0.09235592931509018\n",
      "[Step 21189] Loss: 9.42e+07 -1.2211803197860718 0.09237490594387054\n",
      "[Step 21190] Loss: 9.38e+07 -1.2211843729019165 0.09239636361598969\n",
      "[Step 21191] Loss: 9.41e+07 -1.2212438583374023 0.09237490594387054\n",
      "[Step 21192] Loss: 9.41e+07 -1.2212622165679932 0.09237820655107498\n",
      "[Step 21193] Loss: 9.39e+07 -1.2213305234909058 0.09236335754394531\n",
      "[Step 21194] Loss: 9.43e+07 -1.221454381942749 0.09235922992229462\n",
      "[Step 21195] Loss: 9.49e+07 -1.2216501235961914 0.09232457727193832\n",
      "[Step 21196] Loss: 9.41e+07 -1.2218130826950073 0.09230724722146988\n",
      "[Step 21197] Loss: 9.52e+07 -1.2218817472457886 0.09229899942874908\n",
      "[Step 21198] Loss: 9.55e+07 -1.2221016883850098 0.09227919578552246\n",
      "[Step 21199] Loss: 9.44e+07 -1.2222166061401367 0.09227341413497925\n",
      "[Step 21200] Loss: 9.39e+07 -1.222321629524231 0.09227589517831802\n",
      "[Step 21201] Loss: 9.44e+07 -1.2225017547607422 0.09226269274950027\n",
      "[Step 21202] Loss: 9.40e+07 -1.2226582765579224 0.09224866330623627\n",
      "[Step 21203] Loss: 9.43e+07 -1.2229079008102417 0.0922379344701767\n",
      "[Step 21204] Loss: 9.50e+07 -1.2230128049850464 0.09222473204135895\n",
      "[Step 21205] Loss: 9.45e+07 -1.223187804222107 0.09222803264856339\n",
      "[Step 21206] Loss: 9.53e+07 -1.2235678434371948 0.09219585359096527\n",
      "[Step 21207] Loss: 9.41e+07 -1.2239209413528442 0.0921628475189209\n",
      "[Step 21208] Loss: 9.50e+07 -1.224151611328125 0.09215377271175385\n",
      "[Step 21209] Loss: 9.48e+07 -1.2244341373443604 0.0921182930469513\n",
      "[Step 21210] Loss: 9.48e+07 -1.2246789932250977 0.09210096299648285\n",
      "[Step 21211] Loss: 9.53e+07 -1.224804162979126 0.09209436178207397\n",
      "[Step 21212] Loss: 9.41e+07 -1.2249258756637573 0.0921059101819992\n",
      "[Step 21213] Loss: 9.46e+07 -1.2248932123184204 0.09211911261081696\n",
      "[Step 21214] Loss: 9.41e+07 -1.2247852087020874 0.09215294569730759\n",
      "[Step 21215] Loss: 9.36e+07 -1.224672555923462 0.09217357635498047\n",
      "[Step 21216] Loss: 9.45e+07 -1.2245054244995117 0.09220658242702484\n",
      "[Step 21217] Loss: 9.42e+07 -1.2243669033050537 0.09223133325576782\n",
      "[Step 21218] Loss: 9.50e+07 -1.2244045734405518 0.09224288910627365\n",
      "[Step 21219] Loss: 9.48e+07 -1.2244950532913208 0.09223133325576782\n",
      "[Step 21220] Loss: 9.47e+07 -1.2245203256607056 0.09223546087741852\n",
      "[Step 21221] Loss: 9.44e+07 -1.2245368957519531 0.09223298728466034\n",
      "[Step 21222] Loss: 9.50e+07 -1.2244858741760254 0.09222473204135895\n",
      "[Step 21223] Loss: 9.43e+07 -1.2246462106704712 0.09220905601978302\n",
      "[Step 21224] Loss: 9.45e+07 -1.2247214317321777 0.09219915419816971\n",
      "[Step 21225] Loss: 9.47e+07 -1.2250354290008545 0.09217357635498047\n",
      "[Step 21226] Loss: 9.39e+07 -1.2253245115280151 0.0921587198972702\n",
      "[Step 21227] Loss: 9.42e+07 -1.2255405187606812 0.0921405702829361\n",
      "[Step 21228] Loss: 9.42e+07 -1.2256540060043335 0.0921405702829361\n",
      "[Step 21229] Loss: 9.68e+07 -1.2255679368972778 0.09215211868286133\n",
      "[Step 21230] Loss: 9.44e+07 -1.2254835367202759 0.09217192232608795\n",
      "[Step 21231] Loss: 9.76e+07 -1.225069284439087 0.09221318364143372\n",
      "[Step 21232] Loss: 9.40e+07 -1.2246835231781006 0.09226763993501663\n",
      "[Step 21233] Loss: 9.42e+07 -1.2244107723236084 0.0923088937997818\n",
      "[Step 21234] Loss: 9.47e+07 -1.2241989374160767 0.09232457727193832\n",
      "[Step 21235] Loss: 9.46e+07 -1.2241088151931763 0.09231549501419067\n",
      "[Step 21236] Loss: 9.51e+07 -1.2239794731140137 0.09232622385025024\n",
      "[Step 21237] Loss: 9.51e+07 -1.2240509986877441 0.09231137484312057\n",
      "[Step 21238] Loss: 9.44e+07 -1.2242788076400757 0.09229321777820587\n",
      "[Step 21239] Loss: 9.41e+07 -1.224478840827942 0.0922602117061615\n",
      "[Step 21240] Loss: 9.38e+07 -1.224621295928955 0.09224370867013931\n",
      "[Step 21241] Loss: 9.41e+07 -1.2247759103775024 0.09221070259809494\n",
      "[Step 21242] Loss: 9.43e+07 -1.2250202894210815 0.09219668060541153\n",
      "[Step 21243] Loss: 9.49e+07 -1.2252082824707031 0.09216367453336716\n",
      "[Step 21244] Loss: 9.36e+07 -1.2253363132476807 0.09215541929006577\n",
      "[Step 21245] Loss: 9.42e+07 -1.225465178489685 0.09211746603250504\n",
      "[Step 21246] Loss: 9.43e+07 -1.2256419658660889 0.09210096299648285\n",
      "[Step 21247] Loss: 9.37e+07 -1.225816011428833 0.09208115935325623\n",
      "[Step 21248] Loss: 9.47e+07 -1.2259361743927002 0.09206218272447586\n",
      "[Step 21249] Loss: 9.47e+07 -1.2259972095489502 0.09204567968845367\n",
      "[Step 21250] Loss: 9.46e+07 -1.2261130809783936 0.09203330427408218\n",
      "[Step 21251] Loss: 9.46e+07 -1.2262299060821533 0.09200524538755417\n",
      "[Step 21252] Loss: 9.48e+07 -1.2262661457061768 0.09199947118759155\n",
      "[Step 21253] Loss: 9.44e+07 -1.2262808084487915 0.09197719395160675\n",
      "[Step 21254] Loss: 9.41e+07 -1.2263734340667725 0.0919417142868042\n",
      "[Step 21255] Loss: 9.44e+07 -1.2265597581863403 0.0918930247426033\n",
      "[Step 21256] Loss: 9.48e+07 -1.2266535758972168 0.09188477694988251\n",
      "[Step 21257] Loss: 9.45e+07 -1.2268754243850708 0.0918525978922844\n",
      "[Step 21258] Loss: 9.53e+07 -1.227073311805725 0.0918261930346489\n",
      "[Step 21259] Loss: 9.52e+07 -1.2274454832077026 0.0917775109410286\n",
      "[Step 21260] Loss: 9.41e+07 -1.2278828620910645 0.09170902520418167\n",
      "[Step 21261] Loss: 9.43e+07 -1.2282670736312866 0.09167354553937912\n",
      "[Step 21262] Loss: 9.41e+07 -1.2285640239715576 0.09162485599517822\n",
      "[Step 21263] Loss: 9.44e+07 -1.2287981510162354 0.09159433096647263\n",
      "[Step 21264] Loss: 9.51e+07 -1.2289084196090698 0.09157535433769226\n",
      "[Step 21265] Loss: 9.53e+07 -1.2292661666870117 0.09152501821517944\n",
      "[Step 21266] Loss: 9.45e+07 -1.2296596765518188 0.09147468209266663\n",
      "[Step 21267] Loss: 9.38e+07 -1.2299801111221313 0.09140866994857788\n",
      "[Step 21268] Loss: 9.43e+07 -1.2302604913711548 0.0913880467414856\n",
      "[Step 21269] Loss: 9.41e+07 -1.2305423021316528 0.0913533866405487\n",
      "[Step 21270] Loss: 9.45e+07 -1.2308710813522339 0.09130965918302536\n",
      "[Step 21271] Loss: 9.48e+07 -1.2310572862625122 0.0912824273109436\n",
      "[Step 21272] Loss: 9.49e+07 -1.2310965061187744 0.0912683978676796\n",
      "[Step 21273] Loss: 9.47e+07 -1.2312275171279907 0.09125189483165741\n",
      "[Step 21274] Loss: 9.46e+07 -1.231456995010376 0.09122136980295181\n",
      "[Step 21275] Loss: 9.44e+07 -1.2317508459091187 0.09117680788040161\n",
      "[Step 21276] Loss: 9.39e+07 -1.2320183515548706 0.09114710241556168\n",
      "[Step 21277] Loss: 9.40e+07 -1.2322806119918823 0.09110419452190399\n",
      "[Step 21278] Loss: 9.41e+07 -1.2324175834655762 0.09110832214355469\n",
      "[Step 21279] Loss: 9.41e+07 -1.2324905395507812 0.09106788784265518\n",
      "[Step 21280] Loss: 9.57e+07 -1.2327804565429688 0.09101755917072296\n",
      "[Step 21281] Loss: 9.49e+07 -1.2331875562667847 0.09099198132753372\n",
      "[Step 21282] Loss: 9.37e+07 -1.233559489250183 0.09093834459781647\n",
      "[Step 21283] Loss: 9.43e+07 -1.2339683771133423 0.09089956432580948\n",
      "[Step 21284] Loss: 9.39e+07 -1.23432195186615 0.090848408639431\n",
      "[Step 21285] Loss: 9.40e+07 -1.2345961332321167 0.09082117676734924\n",
      "[Step 21286] Loss: 9.39e+07 -1.2348175048828125 0.0908038467168808\n",
      "[Step 21287] Loss: 9.47e+07 -1.2349988222122192 0.09079064428806305\n",
      "[Step 21288] Loss: 9.40e+07 -1.2351493835449219 0.09075433760881424\n",
      "[Step 21289] Loss: 9.47e+07 -1.2353219985961914 0.09075599163770676\n",
      "[Step 21290] Loss: 9.63e+07 -1.2357574701309204 0.09070565551519394\n",
      "[Step 21291] Loss: 9.44e+07 -1.2362180948257446 0.09066110104322433\n",
      "[Step 21292] Loss: 9.48e+07 -1.2365700006484985 0.09062479436397552\n",
      "[Step 21293] Loss: 9.48e+07 -1.2367244958877563 0.09058931469917297\n",
      "[Step 21294] Loss: 9.47e+07 -1.236768364906311 0.0905521810054779\n",
      "[Step 21295] Loss: 9.46e+07 -1.2367334365844727 0.09054805338382721\n",
      "[Step 21296] Loss: 9.46e+07 -1.2366948127746582 0.0905422791838646\n",
      "[Step 21297] Loss: 9.54e+07 -1.2368896007537842 0.09052082896232605\n",
      "[Step 21298] Loss: 9.40e+07 -1.2369940280914307 0.09051752835512161\n",
      "[Step 21299] Loss: 9.44e+07 -1.237014651298523 0.09051422774791718\n",
      "[Step 21300] Loss: 9.43e+07 -1.2370988130569458 0.09051010012626648\n",
      "[Step 21301] Loss: 9.44e+07 -1.2371219396591187 0.09048864245414734\n",
      "[Step 21302] Loss: 9.48e+07 -1.2372044324874878 0.09047792106866837\n",
      "[Step 21303] Loss: 9.42e+07 -1.2372596263885498 0.0904671922326088\n",
      "[Step 21304] Loss: 9.45e+07 -1.2372956275939941 0.0904589369893074\n",
      "[Step 21305] Loss: 9.52e+07 -1.2371920347213745 0.09046801924705505\n",
      "[Step 21306] Loss: 9.38e+07 -1.2371270656585693 0.09048204123973846\n",
      "[Step 21307] Loss: 9.39e+07 -1.2371466159820557 0.09047874063253403\n",
      "[Step 21308] Loss: 9.39e+07 -1.2371668815612793 0.09046966582536697\n",
      "[Step 21309] Loss: 9.40e+07 -1.2372196912765503 0.09044408798217773\n",
      "[Step 21310] Loss: 9.40e+07 -1.2373168468475342 0.09041685611009598\n",
      "[Step 21311] Loss: 9.50e+07 -1.2374777793884277 0.09040778130292892\n",
      "[Step 21312] Loss: 9.41e+07 -1.237686038017273 0.09040448069572449\n",
      "[Step 21313] Loss: 9.47e+07 -1.2380728721618652 0.09039540588855743\n",
      "[Step 21314] Loss: 9.44e+07 -1.238402247428894 0.09037642925977707\n",
      "[Step 21315] Loss: 9.41e+07 -1.2387137413024902 0.09033269435167313\n",
      "[Step 21316] Loss: 9.48e+07 -1.2389519214630127 0.0903128907084465\n",
      "[Step 21317] Loss: 9.45e+07 -1.2391726970672607 0.0902642086148262\n",
      "[Step 21318] Loss: 9.45e+07 -1.2393172979354858 0.09025760740041733\n",
      "[Step 21319] Loss: 9.49e+07 -1.2395750284194946 0.09023614972829819\n",
      "[Step 21320] Loss: 9.44e+07 -1.2397456169128418 0.0902237743139267\n",
      "[Step 21321] Loss: 9.42e+07 -1.2398062944412231 0.0902196541428566\n",
      "[Step 21322] Loss: 9.49e+07 -1.2398030757904053 0.09019819647073746\n",
      "[Step 21323] Loss: 9.47e+07 -1.239743709564209 0.09020727127790451\n",
      "[Step 21324] Loss: 9.44e+07 -1.2397775650024414 0.09021800011396408\n",
      "[Step 21325] Loss: 9.40e+07 -1.2398189306259155 0.09020645171403885\n",
      "[Step 21326] Loss: 9.41e+07 -1.2398097515106201 0.09021057188510895\n",
      "[Step 21327] Loss: 9.37e+07 -1.239845633506775 0.09018582105636597\n",
      "[Step 21328] Loss: 9.46e+07 -1.2399835586547852 0.09015776216983795\n",
      "[Step 21329] Loss: 9.44e+07 -1.240094780921936 0.09012558311223984\n",
      "[Step 21330] Loss: 9.41e+07 -1.2402629852294922 0.09009670466184616\n",
      "[Step 21331] Loss: 9.39e+07 -1.2403596639633179 0.09008515626192093\n",
      "[Step 21332] Loss: 9.50e+07 -1.24039888381958 0.0900513231754303\n",
      "[Step 21333] Loss: 9.49e+07 -1.2404054403305054 0.09005462378263474\n",
      "[Step 21334] Loss: 9.54e+07 -1.2403581142425537 0.090055450797081\n",
      "[Step 21335] Loss: 9.42e+07 -1.2402489185333252 0.09005792438983917\n",
      "[Step 21336] Loss: 9.41e+07 -1.2401500940322876 0.09005215018987656\n",
      "[Step 21337] Loss: 9.61e+07 -1.2403652667999268 0.09003894776105881\n",
      "[Step 21338] Loss: 9.36e+07 -1.2405176162719727 0.09003564715385437\n",
      "[Step 21339] Loss: 9.53e+07 -1.2406448125839233 0.08999768644571304\n",
      "[Step 21340] Loss: 9.45e+07 -1.2408256530761719 0.08996386080980301\n",
      "[Step 21341] Loss: 9.49e+07 -1.2409939765930176 0.08995230495929718\n",
      "[Step 21342] Loss: 9.41e+07 -1.2410818338394165 0.08993745595216751\n",
      "[Step 21343] Loss: 9.59e+07 -1.2412477731704712 0.08991929888725281\n",
      "[Step 21344] Loss: 9.44e+07 -1.2414301633834839 0.08990362286567688\n",
      "[Step 21345] Loss: 9.36e+07 -1.241594672203064 0.08989372104406357\n",
      "[Step 21346] Loss: 9.38e+07 -1.241684913635254 0.08987391740083694\n",
      "[Step 21347] Loss: 9.39e+07 -1.2417833805084229 0.08985081315040588\n",
      "[Step 21348] Loss: 9.43e+07 -1.2419184446334839 0.08981450647115707\n",
      "[Step 21349] Loss: 9.41e+07 -1.2420090436935425 0.08980873227119446\n",
      "[Step 21350] Loss: 9.36e+07 -1.24214506149292 0.08980543166399002\n",
      "[Step 21351] Loss: 9.59e+07 -1.2424900531768799 0.08977489918470383\n",
      "[Step 21352] Loss: 9.40e+07 -1.242788553237915 0.08973117172718048\n",
      "[Step 21353] Loss: 9.43e+07 -1.2431213855743408 0.08968909084796906\n",
      "[Step 21354] Loss: 9.53e+07 -1.2434593439102173 0.08964122831821442\n",
      "[Step 21355] Loss: 9.42e+07 -1.2436678409576416 0.08962802588939667\n",
      "[Step 21356] Loss: 9.43e+07 -1.2438299655914307 0.08960657566785812\n",
      "[Step 21357] Loss: 9.38e+07 -1.2439340353012085 0.08957769721746445\n",
      "[Step 21358] Loss: 9.44e+07 -1.2439895868301392 0.08956366777420044\n",
      "[Step 21359] Loss: 9.41e+07 -1.2440234422683716 0.08957109600305557\n",
      "[Step 21360] Loss: 9.37e+07 -1.2440255880355835 0.08957604318857193\n",
      "[Step 21361] Loss: 9.48e+07 -1.2439463138580322 0.08957851678133011\n",
      "[Step 21362] Loss: 9.48e+07 -1.2437565326690674 0.08959914743900299\n",
      "[Step 21363] Loss: 9.42e+07 -1.2435222864151 0.08962637931108475\n",
      "[Step 21364] Loss: 9.37e+07 -1.2433182001113892 0.08965113013982773\n",
      "[Step 21365] Loss: 9.44e+07 -1.243019461631775 0.0896800085902214\n",
      "[Step 21366] Loss: 9.41e+07 -1.2427341938018799 0.08970806747674942\n",
      "[Step 21367] Loss: 9.41e+07 -1.2424122095108032 0.08975344896316528\n",
      "[Step 21368] Loss: 9.41e+07 -1.2419955730438232 0.0897856280207634\n",
      "[Step 21369] Loss: 9.37e+07 -1.2415564060211182 0.08984751254320145\n",
      "[Step 21370] Loss: 9.43e+07 -1.2410430908203125 0.08989537507295609\n",
      "[Step 21371] Loss: 9.44e+07 -1.2406305074691772 0.089949831366539\n",
      "[Step 21372] Loss: 9.51e+07 -1.2401288747787476 0.09000511467456818\n",
      "[Step 21373] Loss: 9.46e+07 -1.2398260831832886 0.09003812074661255\n",
      "[Step 21374] Loss: 9.40e+07 -1.2395747900009155 0.09008102864027023\n",
      "[Step 21375] Loss: 9.39e+07 -1.2393349409103394 0.09011733531951904\n",
      "[Step 21376] Loss: 9.39e+07 -1.23910653591156 0.09013053774833679\n",
      "[Step 21377] Loss: 9.54e+07 -1.2390557527542114 0.09012723714113235\n",
      "[Step 21378] Loss: 9.50e+07 -1.2391527891159058 0.09013548493385315\n",
      "[Step 21379] Loss: 9.45e+07 -1.2392164468765259 0.09014538675546646\n",
      "[Step 21380] Loss: 9.40e+07 -1.239161491394043 0.09013218432664871\n",
      "[Step 21381] Loss: 9.46e+07 -1.239134669303894 0.0901222825050354\n",
      "[Step 21382] Loss: 9.43e+07 -1.239187240600586 0.09010247886180878\n",
      "[Step 21383] Loss: 9.39e+07 -1.2392077445983887 0.09010990709066391\n",
      "[Step 21384] Loss: 9.43e+07 -1.2391506433486938 0.0901264101266861\n",
      "[Step 21385] Loss: 9.43e+07 -1.2391653060913086 0.09013383835554123\n",
      "[Step 21386] Loss: 9.45e+07 -1.2393306493759155 0.09011320769786835\n",
      "[Step 21387] Loss: 9.43e+07 -1.239517092704773 0.09008515626192093\n",
      "[Step 21388] Loss: 9.38e+07 -1.239715337753296 0.09005462378263474\n",
      "[Step 21389] Loss: 9.53e+07 -1.2401200532913208 0.09000924229621887\n",
      "[Step 21390] Loss: 9.33e+07 -1.2404330968856812 0.08998943865299225\n",
      "[Step 21391] Loss: 9.38e+07 -1.240713357925415 0.08994900435209274\n",
      "[Step 21392] Loss: 9.43e+07 -1.2409493923187256 0.08991682529449463\n",
      "[Step 21393] Loss: 9.43e+07 -1.2410873174667358 0.08990197628736496\n",
      "[Step 21394] Loss: 9.42e+07 -1.2411930561065674 0.089882992208004\n",
      "[Step 21395] Loss: 9.40e+07 -1.241325855255127 0.08988134562969208\n",
      "[Step 21396] Loss: 9.44e+07 -1.241413950920105 0.08986401557922363\n",
      "[Step 21397] Loss: 9.40e+07 -1.241550326347351 0.08982770889997482\n",
      "[Step 21398] Loss: 9.55e+07 -1.2418897151947021 0.08976582437753677\n",
      "[Step 21399] Loss: 9.60e+07 -1.2424793243408203 0.08968248963356018\n",
      "[Step 21400] Loss: 9.46e+07 -1.2430702447891235 0.08962225168943405\n",
      "[Step 21401] Loss: 9.42e+07 -1.2436847686767578 0.0895562395453453\n",
      "[Step 21402] Loss: 9.45e+07 -1.244179368019104 0.08950920403003693\n",
      "[Step 21403] Loss: 9.44e+07 -1.2446095943450928 0.08946630358695984\n",
      "[Step 21404] Loss: 9.44e+07 -1.245051383972168 0.0894002914428711\n",
      "[Step 21405] Loss: 9.40e+07 -1.2453665733337402 0.08934088051319122\n",
      "[Step 21406] Loss: 9.45e+07 -1.2455402612686157 0.08930870145559311\n",
      "[Step 21407] Loss: 9.44e+07 -1.245603084564209 0.08929797261953354\n",
      "[Step 21408] Loss: 9.35e+07 -1.2456424236297607 0.08929632604122162\n",
      "[Step 21409] Loss: 9.38e+07 -1.2456085681915283 0.08926909416913986\n",
      "[Step 21410] Loss: 9.49e+07 -1.245693564414978 0.08924103528261185\n",
      "[Step 21411] Loss: 9.42e+07 -1.2457551956176758 0.08924103528261185\n",
      "[Step 21412] Loss: 9.55e+07 -1.246012568473816 0.08918080478906631\n",
      "[Step 21413] Loss: 9.46e+07 -1.246177315711975 0.08916017413139343\n",
      "[Step 21414] Loss: 9.40e+07 -1.2463500499725342 0.0891486257314682\n",
      "[Step 21415] Loss: 9.37e+07 -1.246472716331482 0.08912716805934906\n",
      "[Step 21416] Loss: 9.42e+07 -1.246596097946167 0.08912469446659088\n",
      "[Step 21417] Loss: 9.42e+07 -1.2467890977859497 0.08910159021615982\n",
      "[Step 21418] Loss: 9.40e+07 -1.2469426393508911 0.08907188475131989\n",
      "[Step 21419] Loss: 9.38e+07 -1.2470587491989136 0.08905208110809326\n",
      "[Step 21420] Loss: 9.43e+07 -1.247238039970398 0.0890248492360115\n",
      "[Step 21421] Loss: 9.39e+07 -1.247437596321106 0.08899597078561783\n",
      "[Step 21422] Loss: 9.47e+07 -1.2475268840789795 0.08897864818572998\n",
      "[Step 21423] Loss: 9.47e+07 -1.247584581375122 0.08894151449203491\n",
      "[Step 21424] Loss: 9.39e+07 -1.2476130723953247 0.08892501145601273\n",
      "[Step 21425] Loss: 9.45e+07 -1.2477037906646729 0.08892253786325455\n",
      "[Step 21426] Loss: 9.41e+07 -1.2478582859039307 0.08889695256948471\n",
      "[Step 21427] Loss: 9.44e+07 -1.2480099201202393 0.08887550234794617\n",
      "[Step 21428] Loss: 9.49e+07 -1.2482012510299683 0.08884662389755249\n",
      "[Step 21429] Loss: 9.43e+07 -1.248282551765442 0.08881361782550812\n",
      "[Step 21430] Loss: 9.39e+07 -1.2484184503555298 0.08879216015338898\n",
      "[Step 21431] Loss: 9.47e+07 -1.2485085725784302 0.08878061175346375\n",
      "[Step 21432] Loss: 9.59e+07 -1.248957633972168 0.08870965242385864\n",
      "[Step 21433] Loss: 9.55e+07 -1.2492341995239258 0.08868159353733063\n",
      "[Step 21434] Loss: 9.44e+07 -1.2496145963668823 0.08864198625087738\n",
      "[Step 21435] Loss: 9.43e+07 -1.2500163316726685 0.08857432752847672\n",
      "[Step 21436] Loss: 9.43e+07 -1.2503139972686768 0.08854957669973373\n",
      "[Step 21437] Loss: 9.36e+07 -1.2505282163619995 0.08851327002048492\n",
      "[Step 21438] Loss: 9.45e+07 -1.2506510019302368 0.0884794369339943\n",
      "[Step 21439] Loss: 9.47e+07 -1.2508283853530884 0.08848356455564499\n",
      "[Step 21440] Loss: 9.38e+07 -1.2509993314743042 0.08844808489084244\n",
      "[Step 21441] Loss: 9.36e+07 -1.2511839866638184 0.0884183794260025\n",
      "[Step 21442] Loss: 9.44e+07 -1.2514888048171997 0.08837051689624786\n",
      "[Step 21443] Loss: 9.32e+07 -1.2518266439437866 0.08832843601703644\n",
      "[Step 21444] Loss: 9.49e+07 -1.2520946264266968 0.08830368518829346\n",
      "[Step 21445] Loss: 9.47e+07 -1.2522485256195068 0.08829048275947571\n",
      "[Step 21446] Loss: 9.49e+07 -1.2523369789123535 0.08828965574502945\n",
      "[Step 21447] Loss: 9.37e+07 -1.2523771524429321 0.088272325694561\n",
      "[Step 21448] Loss: 9.45e+07 -1.2523351907730103 0.08825995028018951\n",
      "[Step 21449] Loss: 9.37e+07 -1.2523016929626465 0.0882318988442421\n",
      "[Step 21450] Loss: 9.45e+07 -1.2521581649780273 0.08824262022972107\n",
      "[Step 21451] Loss: 9.46e+07 -1.2520657777786255 0.0882459208369255\n",
      "[Step 21452] Loss: 9.39e+07 -1.2519117593765259 0.08823931962251663\n",
      "[Step 21453] Loss: 9.41e+07 -1.2517348527908325 0.08823850005865097\n",
      "[Step 21454] Loss: 9.40e+07 -1.2515424489974976 0.08825334906578064\n",
      "[Step 21455] Loss: 9.36e+07 -1.2513573169708252 0.08825500309467316\n",
      "[Step 21456] Loss: 9.46e+07 -1.2513320446014404 0.08826242387294769\n",
      "[Step 21457] Loss: 9.37e+07 -1.2512867450714111 0.08824922144412994\n",
      "[Step 21458] Loss: 9.39e+07 -1.251298189163208 0.08825252205133438\n",
      "[Step 21459] Loss: 9.43e+07 -1.2513151168823242 0.0882541760802269\n",
      "[Step 21460] Loss: 9.45e+07 -1.2513657808303833 0.08826160430908203\n",
      "[Step 21461] Loss: 9.42e+07 -1.25143563747406 0.08823437243700027\n",
      "[Step 21462] Loss: 9.30e+07 -1.251451849937439 0.08823271840810776\n",
      "[Step 21463] Loss: 9.37e+07 -1.2514357566833496 0.08822447061538696\n",
      "[Step 21464] Loss: 9.47e+07 -1.2513676881790161 0.08821374177932739\n",
      "[Step 21465] Loss: 9.41e+07 -1.251311182975769 0.0882236436009407\n",
      "[Step 21466] Loss: 9.62e+07 -1.2516491413116455 0.08819311112165451\n",
      "[Step 21467] Loss: 9.34e+07 -1.2520166635513306 0.08811472356319427\n",
      "[Step 21468] Loss: 9.50e+07 -1.2524422407150269 0.08805779367685318\n",
      "[Step 21469] Loss: 9.44e+07 -1.252905249595642 0.08801405876874924\n",
      "[Step 21470] Loss: 9.44e+07 -1.2533680200576782 0.08796372264623642\n",
      "[Step 21471] Loss: 9.45e+07 -1.2539067268371582 0.08790019154548645\n",
      "[Step 21472] Loss: 9.43e+07 -1.2544732093811035 0.08783170580863953\n",
      "[Step 21473] Loss: 9.46e+07 -1.2549790143966675 0.08777394145727158\n",
      "[Step 21474] Loss: 9.42e+07 -1.2554731369018555 0.08770958334207535\n",
      "[Step 21475] Loss: 9.39e+07 -1.255981206893921 0.08766914904117584\n",
      "[Step 21476] Loss: 9.45e+07 -1.2564153671264648 0.08763036876916885\n",
      "[Step 21477] Loss: 9.48e+07 -1.2569202184677124 0.08758664131164551\n",
      "[Step 21478] Loss: 9.37e+07 -1.257415533065796 0.08754703402519226\n",
      "[Step 21479] Loss: 9.54e+07 -1.2577722072601318 0.08751485496759415\n",
      "[Step 21480] Loss: 9.36e+07 -1.258118748664856 0.087493397295475\n",
      "[Step 21481] Loss: 9.42e+07 -1.2584028244018555 0.08746616542339325\n",
      "[Step 21482] Loss: 9.41e+07 -1.2586994171142578 0.08741418272256851\n",
      "[Step 21483] Loss: 9.45e+07 -1.2589337825775146 0.0874042809009552\n",
      "[Step 21484] Loss: 9.41e+07 -1.259060025215149 0.08740923553705215\n",
      "[Step 21485] Loss: 9.45e+07 -1.259121298789978 0.08740593492984772\n",
      "[Step 21486] Loss: 9.44e+07 -1.2591255903244019 0.08741996437311172\n",
      "[Step 21487] Loss: 9.43e+07 -1.259230375289917 0.08743316680192947\n",
      "[Step 21488] Loss: 9.43e+07 -1.2592867612838745 0.08743316680192947\n",
      "[Step 21489] Loss: 9.39e+07 -1.259354829788208 0.08743564039468765\n",
      "[Step 21490] Loss: 9.59e+07 -1.2597121000289917 0.08741831034421921\n",
      "[Step 21491] Loss: 9.38e+07 -1.2600455284118652 0.08739025890827179\n",
      "[Step 21492] Loss: 9.45e+07 -1.2602540254592896 0.08738283067941666\n",
      "[Step 21493] Loss: 9.46e+07 -1.2604986429214478 0.08736220002174377\n",
      "[Step 21494] Loss: 9.44e+07 -1.2606593370437622 0.08735642582178116\n",
      "[Step 21495] Loss: 9.43e+07 -1.2606754302978516 0.08735229820013046\n",
      "[Step 21496] Loss: 9.41e+07 -1.2606275081634521 0.08735477179288864\n",
      "[Step 21497] Loss: 9.44e+07 -1.2606126070022583 0.0873597264289856\n",
      "[Step 21498] Loss: 9.39e+07 -1.2606580257415771 0.0873737558722496\n",
      "[Step 21499] Loss: 9.43e+07 -1.2607932090759277 0.0873374491930008\n",
      "[Step 21500] Loss: 9.44e+07 -1.2610607147216797 0.08731187134981155\n",
      "[Step 21501] Loss: 9.51e+07 -1.261149525642395 0.08730939030647278\n",
      "[Step 21502] Loss: 9.41e+07 -1.2613158226013184 0.08729784190654755\n",
      "[Step 21503] Loss: 9.45e+07 -1.2614195346832275 0.08727886527776718\n",
      "[Step 21504] Loss: 9.39e+07 -1.2613930702209473 0.0872887670993805\n",
      "[Step 21505] Loss: 9.48e+07 -1.2612868547439575 0.08731021732091904\n",
      "[Step 21506] Loss: 9.46e+07 -1.2611451148986816 0.08735725283622742\n",
      "[Step 21507] Loss: 9.47e+07 -1.2609401941299438 0.08739850670099258\n",
      "[Step 21508] Loss: 9.43e+07 -1.2606589794158936 0.08744306117296219\n",
      "[Step 21509] Loss: 9.47e+07 -1.2602572441101074 0.08750329911708832\n",
      "[Step 21510] Loss: 9.48e+07 -1.2598185539245605 0.08756683766841888\n",
      "[Step 21511] Loss: 9.59e+07 -1.2596862316131592 0.08758664131164551\n",
      "[Step 21512] Loss: 9.45e+07 -1.2595643997192383 0.0876254215836525\n",
      "[Step 21513] Loss: 9.56e+07 -1.2593615055084229 0.08765099942684174\n",
      "[Step 21514] Loss: 9.46e+07 -1.2591131925582886 0.0876658484339714\n",
      "[Step 21515] Loss: 9.34e+07 -1.2588696479797363 0.08767823129892349\n",
      "[Step 21516] Loss: 9.45e+07 -1.2585793733596802 0.08769968152046204\n",
      "[Step 21517] Loss: 9.41e+07 -1.2583954334259033 0.08772361278533936\n",
      "[Step 21518] Loss: 9.41e+07 -1.2582305669784546 0.08774589002132416\n",
      "[Step 21519] Loss: 9.46e+07 -1.2582029104232788 0.08775826543569565\n",
      "[Step 21520] Loss: 9.41e+07 -1.2582404613494873 0.08775579184293747\n",
      "[Step 21521] Loss: 9.47e+07 -1.2584508657455444 0.08774836361408234\n",
      "[Step 21522] Loss: 9.43e+07 -1.2586431503295898 0.08770463615655899\n",
      "[Step 21523] Loss: 9.40e+07 -1.258830189704895 0.0876741036772728\n",
      "[Step 21524] Loss: 9.43e+07 -1.2590519189834595 0.08763862401247025\n",
      "[Step 21525] Loss: 9.48e+07 -1.2591043710708618 0.08762872219085693\n",
      "[Step 21526] Loss: 9.49e+07 -1.2591114044189453 0.08763532340526581\n",
      "[Step 21527] Loss: 9.42e+07 -1.259001612663269 0.08764934539794922\n",
      "[Step 21528] Loss: 9.43e+07 -1.258833885192871 0.08765347301959991\n",
      "[Step 21529] Loss: 9.56e+07 -1.2589364051818848 0.08764109760522842\n",
      "[Step 21530] Loss: 9.43e+07 -1.258967399597168 0.08764687180519104\n",
      "[Step 21531] Loss: 9.42e+07 -1.2589221000671387 0.08763449639081955\n",
      "[Step 21532] Loss: 9.39e+07 -1.2588765621185303 0.08764192461967468\n",
      "[Step 21533] Loss: 9.42e+07 -1.2589553594589233 0.08764687180519104\n",
      "[Step 21534] Loss: 9.60e+07 -1.2593433856964111 0.08759324252605438\n",
      "[Step 21535] Loss: 9.53e+07 -1.2595475912094116 0.08758828788995743\n",
      "[Step 21536] Loss: 9.40e+07 -1.2597522735595703 0.08757425844669342\n",
      "[Step 21537] Loss: 9.50e+07 -1.2598429918289185 0.08756023645401001\n",
      "[Step 21538] Loss: 9.50e+07 -1.259880781173706 0.0875420793890953\n",
      "[Step 21539] Loss: 9.47e+07 -1.2599953413009644 0.0875420793890953\n",
      "[Step 21540] Loss: 9.40e+07 -1.2600505352020264 0.08753795176744461\n",
      "[Step 21541] Loss: 9.62e+07 -1.260403037071228 0.08751072734594345\n",
      "[Step 21542] Loss: 9.43e+07 -1.2607784271240234 0.08746946603059769\n",
      "[Step 21543] Loss: 9.43e+07 -1.2610887289047241 0.08741253614425659\n",
      "[Step 21544] Loss: 9.46e+07 -1.261491298675537 0.0873597264289856\n",
      "[Step 21545] Loss: 9.42e+07 -1.2618992328643799 0.0873110443353653\n",
      "[Step 21546] Loss: 9.42e+07 -1.2621783018112183 0.0872805118560791\n",
      "[Step 21547] Loss: 9.41e+07 -1.2624423503875732 0.08724997937679291\n",
      "[Step 21548] Loss: 9.44e+07 -1.2626093626022339 0.08723100274801254\n",
      "[Step 21549] Loss: 9.40e+07 -1.2627184391021729 0.0872400775551796\n",
      "[Step 21550] Loss: 9.44e+07 -1.2628583908081055 0.08723017573356628\n",
      "[Step 21551] Loss: 9.45e+07 -1.2629692554473877 0.08721285313367844\n",
      "[Step 21552] Loss: 9.46e+07 -1.262941598892212 0.0872054249048233\n",
      "[Step 21553] Loss: 9.41e+07 -1.2628669738769531 0.08722028136253357\n",
      "[Step 21554] Loss: 9.35e+07 -1.2627625465393066 0.08724337816238403\n",
      "[Step 21555] Loss: 9.47e+07 -1.2627668380737305 0.0872359573841095\n",
      "[Step 21556] Loss: 9.51e+07 -1.2629350423812866 0.08722852915525436\n",
      "[Step 21557] Loss: 9.46e+07 -1.2631810903549194 0.08719717711210251\n",
      "[Step 21558] Loss: 9.41e+07 -1.2634379863739014 0.08717241883277893\n",
      "[Step 21559] Loss: 9.49e+07 -1.2635767459869385 0.08717159181833267\n",
      "[Step 21560] Loss: 9.46e+07 -1.2635859251022339 0.08716334402561188\n",
      "[Step 21561] Loss: 9.50e+07 -1.2635095119476318 0.08716251701116562\n",
      "[Step 21562] Loss: 9.66e+07 -1.2632848024368286 0.08716004341840744\n",
      "[Step 21563] Loss: 9.42e+07 -1.2631295919418335 0.08718067407608032\n",
      "[Step 21564] Loss: 9.42e+07 -1.263161063194275 0.08717819303274155\n",
      "[Step 21565] Loss: 9.42e+07 -1.2631882429122925 0.0871831476688385\n",
      "[Step 21566] Loss: 9.53e+07 -1.2633726596832275 0.08715426921844482\n",
      "[Step 21567] Loss: 9.39e+07 -1.2635136842727661 0.087156742811203\n",
      "[Step 21568] Loss: 9.44e+07 -1.2636679410934448 0.08714436739683151\n",
      "[Step 21569] Loss: 9.45e+07 -1.2638146877288818 0.0871303379535675\n",
      "[Step 21570] Loss: 9.54e+07 -1.263860821723938 0.0871163085103035\n",
      "[Step 21571] Loss: 9.44e+07 -1.264017105102539 0.08710640668869019\n",
      "[Step 21572] Loss: 9.44e+07 -1.2640894651412964 0.08709485828876495\n",
      "[Step 21573] Loss: 9.48e+07 -1.264258623123169 0.08708825707435608\n",
      "[Step 21574] Loss: 9.42e+07 -1.2644659280776978 0.08706432580947876\n",
      "[Step 21575] Loss: 9.39e+07 -1.2645761966705322 0.0870552510023117\n",
      "[Step 21576] Loss: 9.42e+07 -1.2647439241409302 0.08703627437353134\n",
      "[Step 21577] Loss: 9.34e+07 -1.264798641204834 0.08704287558794022\n",
      "[Step 21578] Loss: 9.45e+07 -1.2648433446884155 0.08700821548700333\n",
      "[Step 21579] Loss: 9.42e+07 -1.2647850513458252 0.08700244128704071\n",
      "[Step 21580] Loss: 9.32e+07 -1.2646511793136597 0.0870189443230629\n",
      "[Step 21581] Loss: 9.41e+07 -1.2645759582519531 0.08702884614467621\n",
      "[Step 21582] Loss: 9.43e+07 -1.2644495964050293 0.08704039454460144\n",
      "[Step 21583] Loss: 9.55e+07 -1.2643600702285767 0.08705195039510727\n",
      "[Step 21584] Loss: 9.48e+07 -1.2641927003860474 0.08707010000944138\n",
      "[Step 21585] Loss: 9.42e+07 -1.264053463935852 0.08708082884550095\n",
      "[Step 21586] Loss: 9.48e+07 -1.263778567314148 0.087103933095932\n",
      "[Step 21587] Loss: 9.33e+07 -1.2634751796722412 0.08713116496801376\n",
      "[Step 21588] Loss: 9.42e+07 -1.2632484436035156 0.0871385857462883\n",
      "[Step 21589] Loss: 9.34e+07 -1.2630932331085205 0.0871691182255745\n",
      "[Step 21590] Loss: 9.51e+07 -1.263100504875183 0.08714436739683151\n",
      "[Step 21591] Loss: 9.36e+07 -1.2631454467773438 0.08713116496801376\n",
      "[Step 21592] Loss: 9.48e+07 -1.263211727142334 0.08712126314640045\n",
      "[Step 21593] Loss: 9.43e+07 -1.2634038925170898 0.08709238469600677\n",
      "[Step 21594] Loss: 9.50e+07 -1.263716697692871 0.08706019818782806\n",
      "[Step 21595] Loss: 9.38e+07 -1.2639297246932983 0.08701647073030472\n",
      "[Step 21596] Loss: 9.37e+07 -1.2642041444778442 0.08699584007263184\n",
      "[Step 21597] Loss: 9.50e+07 -1.2644529342651367 0.0869578868150711\n",
      "[Step 21598] Loss: 9.50e+07 -1.264805793762207 0.08693808317184448\n",
      "[Step 21599] Loss: 9.51e+07 -1.2652919292449951 0.08688940107822418\n",
      "[Step 21600] Loss: 9.51e+07 -1.2656378746032715 0.08683989197015762\n",
      "[Step 21601] Loss: 9.40e+07 -1.2659410238265991 0.08680441230535507\n",
      "[Step 21602] Loss: 9.48e+07 -1.2662928104400635 0.08678542822599411\n",
      "[Step 21603] Loss: 9.43e+07 -1.266593098640442 0.08676150441169739\n",
      "[Step 21604] Loss: 9.40e+07 -1.266944169998169 0.08671446889638901\n",
      "[Step 21605] Loss: 9.39e+07 -1.2672452926635742 0.08668723702430725\n",
      "[Step 21606] Loss: 9.35e+07 -1.2674914598464966 0.08667238801717758\n",
      "[Step 21607] Loss: 9.43e+07 -1.2676924467086792 0.08665011078119278\n",
      "[Step 21608] Loss: 9.44e+07 -1.2679353952407837 0.08663690835237503\n",
      "[Step 21609] Loss: 9.46e+07 -1.2682037353515625 0.08660142868757248\n",
      "[Step 21610] Loss: 9.52e+07 -1.2682963609695435 0.08658327162265778\n",
      "[Step 21611] Loss: 9.45e+07 -1.2684012651443481 0.08656759560108185\n",
      "[Step 21612] Loss: 9.41e+07 -1.2684698104858398 0.08653953671455383\n",
      "[Step 21613] Loss: 9.43e+07 -1.2685164213180542 0.08654366433620453\n",
      "[Step 21614] Loss: 9.47e+07 -1.2684935331344604 0.08654531836509705\n",
      "[Step 21615] Loss: 9.45e+07 -1.268388032913208 0.08654119074344635\n",
      "[Step 21616] Loss: 9.40e+07 -1.2682781219482422 0.08652881532907486\n",
      "[Step 21617] Loss: 9.40e+07 -1.2682240009307861 0.08652551472187042\n",
      "[Step 21618] Loss: 9.54e+07 -1.268423080444336 0.08650488406419754\n",
      "[Step 21619] Loss: 9.46e+07 -1.2685985565185547 0.08646444976329803\n",
      "[Step 21620] Loss: 9.39e+07 -1.2687016725540161 0.0864611491560936\n",
      "[Step 21621] Loss: 9.39e+07 -1.2688283920288086 0.08642897009849548\n",
      "[Step 21622] Loss: 9.43e+07 -1.2688945531845093 0.086430624127388\n",
      "[Step 21623] Loss: 9.63e+07 -1.2692275047302246 0.08638028800487518\n",
      "[Step 21624] Loss: 9.44e+07 -1.2695229053497314 0.08634975552558899\n",
      "[Step 21625] Loss: 9.44e+07 -1.2696905136108398 0.08633077889680862\n",
      "[Step 21626] Loss: 9.44e+07 -1.2698251008987427 0.08632417768239975\n",
      "[Step 21627] Loss: 9.41e+07 -1.2699896097183228 0.08629447221755981\n",
      "[Step 21628] Loss: 9.41e+07 -1.2700871229171753 0.08627384901046753\n",
      "[Step 21629] Loss: 9.44e+07 -1.2701995372772217 0.08625156432390213\n",
      "[Step 21630] Loss: 9.50e+07 -1.2704262733459473 0.08623506128787994\n",
      "[Step 21631] Loss: 9.44e+07 -1.270652413368225 0.08620535582304001\n",
      "[Step 21632] Loss: 9.45e+07 -1.2708040475845337 0.08619050681591034\n",
      "[Step 21633] Loss: 9.45e+07 -1.2709699869155884 0.0861649289727211\n",
      "[Step 21634] Loss: 9.39e+07 -1.2711068391799927 0.08613605052232742\n",
      "[Step 21635] Loss: 9.53e+07 -1.2711209058761597 0.08614017069339752\n",
      "[Step 21636] Loss: 9.40e+07 -1.2711046934127808 0.0861244946718216\n",
      "[Step 21637] Loss: 9.46e+07 -1.271003007888794 0.08613109588623047\n",
      "[Step 21638] Loss: 9.46e+07 -1.2709132432937622 0.08612944930791855\n",
      "[Step 21639] Loss: 9.42e+07 -1.2707821130752563 0.08612944930791855\n",
      "[Step 21640] Loss: 9.58e+07 -1.2705607414245605 0.08615337312221527\n",
      "[Step 21641] Loss: 9.54e+07 -1.2701961994171143 0.08619050681591034\n",
      "[Step 21642] Loss: 9.45e+07 -1.2698644399642944 0.08622764050960541\n",
      "[Step 21643] Loss: 9.45e+07 -1.2694776058197021 0.08626064658164978\n",
      "[Step 21644] Loss: 9.42e+07 -1.269179105758667 0.08626064658164978\n",
      "[Step 21645] Loss: 9.44e+07 -1.26888108253479 0.08630190044641495\n",
      "[Step 21646] Loss: 9.41e+07 -1.2686208486557007 0.08630932867527008\n",
      "[Step 21647] Loss: 9.45e+07 -1.2684084177017212 0.08631592988967896\n",
      "[Step 21648] Loss: 9.47e+07 -1.2682141065597534 0.08634563535451889\n",
      "[Step 21649] Loss: 9.50e+07 -1.2682279348373413 0.08633573353290558\n",
      "[Step 21650] Loss: 9.45e+07 -1.2681543827056885 0.08633243292570114\n",
      "[Step 21651] Loss: 9.44e+07 -1.2681071758270264 0.08632583171129227\n",
      "[Step 21652] Loss: 9.42e+07 -1.2679448127746582 0.08634068071842194\n",
      "[Step 21653] Loss: 9.46e+07 -1.2678130865097046 0.08636543899774551\n",
      "[Step 21654] Loss: 9.43e+07 -1.2676728963851929 0.08636791259050369\n",
      "[Step 21655] Loss: 9.38e+07 -1.2675373554229736 0.08637285977602005\n",
      "[Step 21656] Loss: 9.43e+07 -1.2674654722213745 0.08638688921928406\n",
      "[Step 21657] Loss: 9.39e+07 -1.267336130142212 0.0864042192697525\n",
      "[Step 21658] Loss: 9.47e+07 -1.2673420906066895 0.08639266341924667\n",
      "[Step 21659] Loss: 9.46e+07 -1.2672868967056274 0.08640256524085999\n",
      "[Step 21660] Loss: 9.41e+07 -1.2672849893569946 0.0864000916481018\n",
      "[Step 21661] Loss: 9.46e+07 -1.2673826217651367 0.08640503883361816\n",
      "[Step 21662] Loss: 9.51e+07 -1.26743745803833 0.0863860622048378\n",
      "[Step 21663] Loss: 9.50e+07 -1.2674672603607178 0.08638441562652588\n",
      "[Step 21664] Loss: 9.44e+07 -1.267340898513794 0.08640256524085999\n",
      "[Step 21665] Loss: 9.46e+07 -1.267232060432434 0.08640256524085999\n",
      "[Step 21666] Loss: 9.37e+07 -1.2671489715576172 0.0864042192697525\n",
      "[Step 21667] Loss: 9.48e+07 -1.2672090530395508 0.08637864142656326\n",
      "[Step 21668] Loss: 9.39e+07 -1.267274260520935 0.08636295795440674\n",
      "[Step 21669] Loss: 9.39e+07 -1.2673569917678833 0.08633243292570114\n",
      "[Step 21670] Loss: 9.47e+07 -1.267547607421875 0.08631180226802826\n",
      "[Step 21671] Loss: 9.41e+07 -1.2677948474884033 0.08628705143928528\n",
      "[Step 21672] Loss: 9.38e+07 -1.267971158027649 0.08627136796712875\n",
      "[Step 21673] Loss: 9.43e+07 -1.2681965827941895 0.08623094111680984\n",
      "[Step 21674] Loss: 9.41e+07 -1.2683038711547852 0.08620205521583557\n",
      "[Step 21675] Loss: 9.44e+07 -1.2684210538864136 0.08617730438709259\n",
      "[Step 21676] Loss: 9.51e+07 -1.2684299945831299 0.08616245537996292\n",
      "[Step 21677] Loss: 9.44e+07 -1.2684826850891113 0.08615172654390335\n",
      "[Step 21678] Loss: 9.50e+07 -1.268413782119751 0.08613935112953186\n",
      "[Step 21679] Loss: 9.38e+07 -1.2683383226394653 0.08614925295114517\n",
      "[Step 21680] Loss: 9.34e+07 -1.26826012134552 0.08614099770784378\n",
      "[Step 21681] Loss: 9.38e+07 -1.2681365013122559 0.08615750074386597\n",
      "[Step 21682] Loss: 9.44e+07 -1.2678947448730469 0.08616410195827484\n",
      "[Step 21683] Loss: 9.42e+07 -1.2675700187683105 0.08617153018712997\n",
      "[Step 21684] Loss: 9.40e+07 -1.2672324180603027 0.08619710803031921\n",
      "[Step 21685] Loss: 9.49e+07 -1.267080307006836 0.08620040863752365\n",
      "[Step 21686] Loss: 9.44e+07 -1.2669434547424316 0.08620123565196991\n",
      "[Step 21687] Loss: 9.51e+07 -1.266654133796692 0.08622268587350845\n",
      "[Step 21688] Loss: 9.52e+07 -1.2665126323699951 0.08622928708791733\n",
      "[Step 21689] Loss: 9.42e+07 -1.2663440704345703 0.08623258769512177\n",
      "[Step 21690] Loss: 9.39e+07 -1.2661759853363037 0.08624166250228882\n",
      "[Step 21691] Loss: 9.46e+07 -1.265928864479065 0.0862441435456276\n",
      "[Step 21692] Loss: 9.43e+07 -1.2658814191818237 0.0862400159239769\n",
      "[Step 21693] Loss: 9.43e+07 -1.265944480895996 0.08623918890953064\n",
      "[Step 21694] Loss: 9.41e+07 -1.26590895652771 0.08624166250228882\n",
      "[Step 21695] Loss: 9.42e+07 -1.2658369541168213 0.08623506128787994\n",
      "[Step 21696] Loss: 9.39e+07 -1.2657976150512695 0.08623754233121872\n",
      "[Step 21697] Loss: 9.50e+07 -1.26589035987854 0.0862358883023262\n",
      "[Step 21698] Loss: 9.42e+07 -1.2660943269729614 0.08624248951673508\n",
      "[Step 21699] Loss: 9.42e+07 -1.2663298845291138 0.08622515946626663\n",
      "[Step 21700] Loss: 9.47e+07 -1.2666112184524536 0.08620535582304001\n",
      "[Step 21701] Loss: 9.49e+07 -1.267027735710144 0.08615915477275848\n",
      "[Step 21702] Loss: 9.39e+07 -1.2673810720443726 0.08612366765737534\n",
      "[Step 21703] Loss: 9.39e+07 -1.2677210569381714 0.08610799163579941\n",
      "[Step 21704] Loss: 9.45e+07 -1.2681188583374023 0.08606921136379242\n",
      "[Step 21705] Loss: 9.44e+07 -1.2683358192443848 0.08605270832777023\n",
      "[Step 21706] Loss: 9.47e+07 -1.268472671508789 0.08605106174945831\n",
      "[Step 21707] Loss: 9.42e+07 -1.2684760093688965 0.08605023473501205\n",
      "[Step 21708] Loss: 9.44e+07 -1.268570065498352 0.0860494077205658\n",
      "[Step 21709] Loss: 9.39e+07 -1.2685997486114502 0.08605518192052841\n",
      "[Step 21710] Loss: 9.48e+07 -1.2685754299163818 0.08604776114225388\n",
      "[Step 21711] Loss: 9.40e+07 -1.2685198783874512 0.08604446053504944\n",
      "[Step 21712] Loss: 9.35e+07 -1.2685692310333252 0.08604363352060318\n",
      "[Step 21713] Loss: 9.61e+07 -1.2690024375915527 0.08599742501974106\n",
      "[Step 21714] Loss: 9.38e+07 -1.269389033317566 0.08596524596214294\n",
      "[Step 21715] Loss: 9.48e+07 -1.2695794105529785 0.08594626933336258\n",
      "[Step 21716] Loss: 9.42e+07 -1.269748568534851 0.08593471348285675\n",
      "[Step 21717] Loss: 9.45e+07 -1.2698978185653687 0.08592316508293152\n",
      "[Step 21718] Loss: 9.56e+07 -1.269872784614563 0.085921511054039\n",
      "[Step 21719] Loss: 9.44e+07 -1.2699276208877563 0.08591078221797943\n",
      "[Step 21720] Loss: 9.41e+07 -1.2699061632156372 0.08592398464679718\n",
      "[Step 21721] Loss: 9.43e+07 -1.269829511642456 0.08593554049730301\n",
      "[Step 21722] Loss: 9.39e+07 -1.2697298526763916 0.08592811226844788\n",
      "[Step 21723] Loss: 9.50e+07 -1.2698904275894165 0.08590006083250046\n",
      "[Step 21724] Loss: 9.43e+07 -1.2700241804122925 0.08588025718927383\n",
      "[Step 21725] Loss: 9.37e+07 -1.2701411247253418 0.08585137873888016\n",
      "[Step 21726] Loss: 9.44e+07 -1.2701172828674316 0.08587943017482758\n",
      "[Step 21727] Loss: 9.44e+07 -1.2701612710952759 0.08588437736034393\n",
      "[Step 21728] Loss: 9.43e+07 -1.2701857089996338 0.08588355779647827\n",
      "[Step 21729] Loss: 9.45e+07 -1.2701762914657593 0.08588850498199463\n",
      "[Step 21730] Loss: 9.46e+07 -1.270162582397461 0.08588520437479019\n",
      "[Step 21731] Loss: 9.43e+07 -1.2700831890106201 0.08588933199644089\n",
      "[Step 21732] Loss: 9.41e+07 -1.2699651718139648 0.08589757978916168\n",
      "[Step 21733] Loss: 9.51e+07 -1.269992470741272 0.0858992338180542\n",
      "[Step 21734] Loss: 9.49e+07 -1.2699099779129028 0.08590500801801682\n",
      "[Step 21735] Loss: 9.40e+07 -1.2697981595993042 0.085921511054039\n",
      "[Step 21736] Loss: 9.44e+07 -1.2698599100112915 0.08592728525400162\n",
      "[Step 21737] Loss: 9.53e+07 -1.2701295614242554 0.08590583503246307\n",
      "[Step 21738] Loss: 9.44e+07 -1.2704278230667114 0.08589015901088715\n",
      "[Step 21739] Loss: 9.41e+07 -1.27069890499115 0.08586045354604721\n",
      "[Step 21740] Loss: 9.43e+07 -1.2711026668548584 0.08583569526672363\n",
      "[Step 21741] Loss: 9.45e+07 -1.271411657333374 0.08579608798027039\n",
      "[Step 21742] Loss: 9.48e+07 -1.271620750427246 0.08578866720199585\n",
      "[Step 21743] Loss: 9.41e+07 -1.2717430591583252 0.08579278737306595\n",
      "[Step 21744] Loss: 9.37e+07 -1.271851658821106 0.08580104261636734\n",
      "[Step 21745] Loss: 9.53e+07 -1.2717806100845337 0.08582909405231476\n",
      "[Step 21746] Loss: 9.42e+07 -1.2718404531478882 0.08581837266683578\n",
      "[Step 21747] Loss: 9.44e+07 -1.2718583345413208 0.08583404868841171\n",
      "[Step 21748] Loss: 9.42e+07 -1.271837830543518 0.08585549890995026\n",
      "[Step 21749] Loss: 9.42e+07 -1.2717455625534058 0.08588025718927383\n",
      "[Step 21750] Loss: 9.47e+07 -1.2718061208724976 0.08588603138923645\n",
      "[Step 21751] Loss: 9.39e+07 -1.2717702388763428 0.08590830862522125\n",
      "[Step 21752] Loss: 9.38e+07 -1.2717018127441406 0.08592316508293152\n",
      "[Step 21753] Loss: 9.44e+07 -1.2715808153152466 0.0859396681189537\n",
      "[Step 21754] Loss: 9.43e+07 -1.2713679075241089 0.08596524596214294\n",
      "[Step 21755] Loss: 9.47e+07 -1.2710542678833008 0.08599742501974106\n",
      "[Step 21756] Loss: 9.40e+07 -1.270674705505371 0.08603455871343613\n",
      "[Step 21757] Loss: 9.38e+07 -1.270257592201233 0.0860758125782013\n",
      "[Step 21758] Loss: 9.37e+07 -1.2698410749435425 0.08611872047185898\n",
      "[Step 21759] Loss: 9.44e+07 -1.26954185962677 0.08614347130060196\n",
      "[Step 21760] Loss: 9.42e+07 -1.2693198919296265 0.08615750074386597\n",
      "[Step 21761] Loss: 9.40e+07 -1.2691607475280762 0.08618225902318954\n",
      "[Step 21762] Loss: 9.66e+07 -1.2694755792617798 0.0861649289727211\n",
      "[Step 21763] Loss: 9.48e+07 -1.269869327545166 0.0861426517367363\n",
      "[Step 21764] Loss: 9.35e+07 -1.2701705694198608 0.08611376583576202\n",
      "[Step 21765] Loss: 9.47e+07 -1.2705013751983643 0.08609314262866974\n",
      "[Step 21766] Loss: 9.39e+07 -1.2708933353424072 0.08606673777103424\n",
      "[Step 21767] Loss: 9.41e+07 -1.2713027000427246 0.08602217584848404\n",
      "[Step 21768] Loss: 9.46e+07 -1.2716397047042847 0.08598999679088593\n",
      "[Step 21769] Loss: 9.43e+07 -1.272045612335205 0.08594131469726562\n",
      "[Step 21770] Loss: 9.43e+07 -1.2724254131317139 0.08590253442525864\n",
      "[Step 21771] Loss: 9.50e+07 -1.2728073596954346 0.08587200194597244\n",
      "[Step 21772] Loss: 9.43e+07 -1.273130178451538 0.08584229648113251\n",
      "[Step 21773] Loss: 9.46e+07 -1.27336585521698 0.08580929040908813\n",
      "[Step 21774] Loss: 9.40e+07 -1.2735768556594849 0.08578618615865707\n",
      "[Step 21775] Loss: 9.52e+07 -1.2739496231079102 0.08574245870113373\n",
      "[Step 21776] Loss: 9.39e+07 -1.2743245363235474 0.08569872379302979\n",
      "[Step 21777] Loss: 9.44e+07 -1.2746784687042236 0.08566489815711975\n",
      "[Step 21778] Loss: 9.44e+07 -1.2751221656799316 0.08562280982732773\n",
      "[Step 21779] Loss: 9.42e+07 -1.2754881381988525 0.08558815717697144\n",
      "[Step 21780] Loss: 9.38e+07 -1.2757714986801147 0.08555927872657776\n",
      "[Step 21781] Loss: 9.44e+07 -1.2761577367782593 0.08552461862564087\n",
      "[Step 21782] Loss: 9.46e+07 -1.2766343355178833 0.08549079298973083\n",
      "[Step 21783] Loss: 9.43e+07 -1.2769988775253296 0.08545448631048203\n",
      "[Step 21784] Loss: 9.39e+07 -1.2773789167404175 0.0854165256023407\n",
      "[Step 21785] Loss: 9.36e+07 -1.2776463031768799 0.08539920300245285\n",
      "[Step 21786] Loss: 9.46e+07 -1.2780475616455078 0.08535134047269821\n",
      "[Step 21787] Loss: 9.55e+07 -1.2785441875457764 0.08528038114309311\n",
      "[Step 21788] Loss: 9.43e+07 -1.2789992094039917 0.08524160087108612\n",
      "[Step 21789] Loss: 9.43e+07 -1.2793920040130615 0.08521106839179993\n",
      "[Step 21790] Loss: 9.43e+07 -1.279799222946167 0.08517971634864807\n",
      "[Step 21791] Loss: 9.48e+07 -1.2800997495651245 0.08515578508377075\n",
      "[Step 21792] Loss: 9.46e+07 -1.280470848083496 0.08512277901172638\n",
      "[Step 21793] Loss: 9.42e+07 -1.2807559967041016 0.08509554713964462\n",
      "[Step 21794] Loss: 9.40e+07 -1.280990719795227 0.08507657051086426\n",
      "[Step 21795] Loss: 9.45e+07 -1.281322956085205 0.08506832271814346\n",
      "[Step 21796] Loss: 9.51e+07 -1.2815073728561401 0.08504769206047058\n",
      "[Step 21797] Loss: 9.54e+07 -1.281531572341919 0.0850452184677124\n",
      "[Step 21798] Loss: 9.49e+07 -1.281734824180603 0.0850270614027977\n",
      "[Step 21799] Loss: 9.41e+07 -1.2818716764450073 0.08502046018838882\n",
      "[Step 21800] Loss: 9.52e+07 -1.2821468114852905 0.08499405533075333\n",
      "[Step 21801] Loss: 9.48e+07 -1.2825229167938232 0.0849519744515419\n",
      "[Step 21802] Loss: 9.42e+07 -1.2827785015106201 0.08492392301559448\n",
      "[Step 21803] Loss: 9.46e+07 -1.2829992771148682 0.08490659296512604\n",
      "[Step 21804] Loss: 9.42e+07 -1.2832258939743042 0.08488266170024872\n",
      "[Step 21805] Loss: 9.46e+07 -1.2833447456359863 0.08486203849315643\n",
      "[Step 21806] Loss: 9.49e+07 -1.2834800481796265 0.08484306186437607\n",
      "[Step 21807] Loss: 9.53e+07 -1.283858299255371 0.08481252938508987\n",
      "[Step 21808] Loss: 9.42e+07 -1.2841742038726807 0.08477456867694855\n",
      "[Step 21809] Loss: 9.33e+07 -1.2844488620758057 0.08475229144096375\n",
      "[Step 21810] Loss: 9.41e+07 -1.284623146057129 0.08473826944828033\n",
      "[Step 21811] Loss: 9.41e+07 -1.284685492515564 0.08472918719053268\n",
      "[Step 21812] Loss: 9.49e+07 -1.2846429347991943 0.0847267135977745\n",
      "[Step 21813] Loss: 9.46e+07 -1.284519076347351 0.08473578840494156\n",
      "[Step 21814] Loss: 9.43e+07 -1.284315586090088 0.084739089012146\n",
      "[Step 21815] Loss: 9.37e+07 -1.2841130495071411 0.08475889265537262\n",
      "[Step 21816] Loss: 9.38e+07 -1.2839367389678955 0.0847654938697815\n",
      "[Step 21817] Loss: 9.46e+07 -1.2838350534439087 0.08476796746253967\n",
      "[Step 21818] Loss: 9.49e+07 -1.2836341857910156 0.08478859812021255\n",
      "[Step 21819] Loss: 9.53e+07 -1.2836545705795288 0.08479932695627213\n",
      "[Step 21820] Loss: 9.40e+07 -1.2835897207260132 0.08478529751300812\n",
      "[Step 21821] Loss: 9.47e+07 -1.2835558652877808 0.08478695154190063\n",
      "[Step 21822] Loss: 9.39e+07 -1.2835071086883545 0.08479519933462143\n",
      "[Step 21823] Loss: 9.54e+07 -1.2832895517349243 0.08478942513465881\n",
      "[Step 21824] Loss: 9.48e+07 -1.2832400798797607 0.08478942513465881\n",
      "[Step 21825] Loss: 9.41e+07 -1.2831530570983887 0.08479272574186325\n",
      "[Step 21826] Loss: 9.36e+07 -1.2830097675323486 0.08478942513465881\n",
      "[Step 21827] Loss: 9.48e+07 -1.2829340696334839 0.08479272574186325\n",
      "[Step 21828] Loss: 9.56e+07 -1.2826670408248901 0.0848364606499672\n",
      "[Step 21829] Loss: 9.35e+07 -1.2823669910430908 0.08485213667154312\n",
      "[Step 21830] Loss: 9.52e+07 -1.2823233604431152 0.08485213667154312\n",
      "[Step 21831] Loss: 9.40e+07 -1.2822383642196655 0.08486121147871017\n",
      "[Step 21832] Loss: 9.47e+07 -1.2821974754333496 0.08485708385705948\n",
      "[Step 21833] Loss: 9.46e+07 -1.2821621894836426 0.08486533910036087\n",
      "[Step 21834] Loss: 9.42e+07 -1.2820640802383423 0.08488018810749054\n",
      "[Step 21835] Loss: 9.45e+07 -1.2819933891296387 0.08488266170024872\n",
      "[Step 21836] Loss: 9.45e+07 -1.281978726387024 0.08488596230745316\n",
      "[Step 21837] Loss: 9.47e+07 -1.28206205368042 0.08490411937236786\n",
      "[Step 21838] Loss: 9.41e+07 -1.2820895910263062 0.08490411937236786\n",
      "[Step 21839] Loss: 9.48e+07 -1.2821333408355713 0.08489669114351273\n",
      "[Step 21840] Loss: 9.50e+07 -1.2820924520492554 0.08491154760122299\n",
      "[Step 21841] Loss: 9.44e+07 -1.2820594310760498 0.08491649478673935\n",
      "[Step 21842] Loss: 9.40e+07 -1.2821449041366577 0.08488926291465759\n",
      "[Step 21843] Loss: 9.41e+07 -1.2821881771087646 0.08488431572914124\n",
      "[Step 21844] Loss: 9.37e+07 -1.2823442220687866 0.0848546102643013\n",
      "[Step 21845] Loss: 9.43e+07 -1.282392978668213 0.08484718203544617\n",
      "[Step 21846] Loss: 9.44e+07 -1.2824395895004272 0.08484388142824173\n",
      "[Step 21847] Loss: 9.59e+07 -1.2828291654586792 0.08482243120670319\n",
      "[Step 21848] Loss: 9.41e+07 -1.2831909656524658 0.08476796746253967\n",
      "[Step 21849] Loss: 9.42e+07 -1.2835215330123901 0.08473248779773712\n",
      "[Step 21850] Loss: 9.38e+07 -1.2838366031646729 0.08470196276903152\n",
      "[Step 21851] Loss: 9.48e+07 -1.284057378768921 0.08468710631132126\n",
      "[Step 21852] Loss: 9.42e+07 -1.2843310832977295 0.08468710631132126\n",
      "[Step 21853] Loss: 9.41e+07 -1.2846050262451172 0.08466647565364838\n",
      "[Step 21854] Loss: 9.43e+07 -1.2848401069641113 0.08465410023927689\n",
      "[Step 21855] Loss: 9.50e+07 -1.2849931716918945 0.08463017642498016\n",
      "[Step 21856] Loss: 9.40e+07 -1.285185694694519 0.08460789173841476\n",
      "[Step 21857] Loss: 9.41e+07 -1.2853800058364868 0.08457736670970917\n",
      "[Step 21858] Loss: 9.32e+07 -1.2854763269424438 0.08458726853132248\n",
      "[Step 21859] Loss: 9.46e+07 -1.2856428623199463 0.08454683423042297\n",
      "[Step 21860] Loss: 9.55e+07 -1.2860621213912964 0.08450639992952347\n",
      "[Step 21861] Loss: 9.39e+07 -1.2864359617233276 0.08448164910078049\n",
      "[Step 21862] Loss: 9.40e+07 -1.2866883277893066 0.08446349203586578\n",
      "[Step 21863] Loss: 9.48e+07 -1.2870306968688965 0.08442553877830505\n",
      "[Step 21864] Loss: 9.47e+07 -1.2874442338943481 0.08440243452787399\n",
      "[Step 21865] Loss: 9.38e+07 -1.28770112991333 0.0843900591135025\n",
      "[Step 21866] Loss: 9.41e+07 -1.287824273109436 0.08437768369913101\n",
      "[Step 21867] Loss: 9.41e+07 -1.2879427671432495 0.084349624812603\n",
      "[Step 21868] Loss: 9.48e+07 -1.2882397174835205 0.08432982116937637\n",
      "[Step 21869] Loss: 9.40e+07 -1.2884223461151123 0.08430507034063339\n",
      "[Step 21870] Loss: 9.45e+07 -1.2886656522750854 0.08429021388292313\n",
      "[Step 21871] Loss: 9.42e+07 -1.288718581199646 0.08429104089736938\n",
      "[Step 21872] Loss: 9.63e+07 -1.2885980606079102 0.08430341631174088\n",
      "[Step 21873] Loss: 9.34e+07 -1.2884052991867065 0.08432074636220932\n",
      "[Step 21874] Loss: 9.44e+07 -1.288317084312439 0.08432157337665558\n",
      "[Step 21875] Loss: 9.39e+07 -1.2882754802703857 0.0843454971909523\n",
      "[Step 21876] Loss: 9.36e+07 -1.288289189338684 0.08434879779815674\n",
      "[Step 21877] Loss: 9.46e+07 -1.2883838415145874 0.08434302359819412\n",
      "[Step 21878] Loss: 9.43e+07 -1.2884751558303833 0.08433807641267776\n",
      "[Step 21879] Loss: 9.45e+07 -1.2885072231292725 0.08434879779815674\n",
      "[Step 21880] Loss: 9.38e+07 -1.2885745763778687 0.08435045182704926\n",
      "[Step 21881] Loss: 9.71e+07 -1.2891130447387695 0.08429186791181564\n",
      "[Step 21882] Loss: 9.42e+07 -1.2895556688308716 0.08426133543252945\n",
      "[Step 21883] Loss: 9.38e+07 -1.2899926900863647 0.08420192450284958\n",
      "[Step 21884] Loss: 9.38e+07 -1.2904762029647827 0.08415654301643372\n",
      "[Step 21885] Loss: 9.48e+07 -1.2908376455307007 0.08411940932273865\n",
      "[Step 21886] Loss: 9.50e+07 -1.2911432981491089 0.0840839296579361\n",
      "[Step 21887] Loss: 9.40e+07 -1.2913178205490112 0.08406330645084381\n",
      "[Step 21888] Loss: 9.40e+07 -1.2915526628494263 0.08403937518596649\n",
      "[Step 21889] Loss: 9.41e+07 -1.2916985750198364 0.08401462435722351\n",
      "[Step 21890] Loss: 9.39e+07 -1.2917563915252686 0.08401462435722351\n",
      "[Step 21891] Loss: 9.39e+07 -1.2917954921722412 0.08400802314281464\n",
      "[Step 21892] Loss: 9.43e+07 -1.291816234588623 0.08399729430675507\n",
      "[Step 21893] Loss: 9.41e+07 -1.2917933464050293 0.08398161828517914\n",
      "[Step 21894] Loss: 9.42e+07 -1.291799545288086 0.08396923542022705\n",
      "[Step 21895] Loss: 9.41e+07 -1.291743516921997 0.08397088944911957\n",
      "[Step 21896] Loss: 9.55e+07 -1.2915823459625244 0.08396841585636139\n",
      "[Step 21897] Loss: 9.45e+07 -1.291428565979004 0.08397666364908218\n",
      "[Step 21898] Loss: 9.40e+07 -1.2913230657577515 0.08397583663463593\n",
      "[Step 21899] Loss: 9.40e+07 -1.2911015748977661 0.08399976789951324\n",
      "[Step 21900] Loss: 9.56e+07 -1.2907015085220337 0.08401132375001907\n",
      "[Step 21901] Loss: 9.46e+07 -1.2902278900146484 0.08404432237148285\n",
      "[Step 21902] Loss: 9.37e+07 -1.289780616760254 0.08408641070127487\n",
      "[Step 21903] Loss: 9.47e+07 -1.289410948753357 0.08413509279489517\n",
      "[Step 21904] Loss: 9.46e+07 -1.2890268564224243 0.0841730460524559\n",
      "[Step 21905] Loss: 9.41e+07 -1.2886497974395752 0.08423162996768951\n",
      "[Step 21906] Loss: 9.42e+07 -1.2882492542266846 0.0842885673046112\n",
      "[Step 21907] Loss: 9.38e+07 -1.2879585027694702 0.08432487398386002\n",
      "[Step 21908] Loss: 9.56e+07 -1.2879245281219482 0.0843273475766182\n",
      "[Step 21909] Loss: 9.48e+07 -1.2878450155258179 0.08433394879102707\n",
      "[Step 21910] Loss: 9.48e+07 -1.2878965139389038 0.08433229476213455\n",
      "[Step 21911] Loss: 9.45e+07 -1.288041114807129 0.08430589735507965\n",
      "[Step 21912] Loss: 9.57e+07 -1.2885006666183472 0.08426380902528763\n",
      "[Step 21913] Loss: 9.41e+07 -1.289032220840454 0.08421348035335541\n",
      "[Step 21914] Loss: 9.49e+07 -1.2896554470062256 0.08415654301643372\n",
      "[Step 21915] Loss: 9.38e+07 -1.2901670932769775 0.0841062143445015\n",
      "[Step 21916] Loss: 9.37e+07 -1.2905625104904175 0.08407320827245712\n",
      "[Step 21917] Loss: 9.41e+07 -1.2908855676651 0.08404597640037537\n",
      "[Step 21918] Loss: 9.45e+07 -1.2911442518234253 0.08401791751384735\n",
      "[Step 21919] Loss: 9.32e+07 -1.2913525104522705 0.0840047225356102\n",
      "[Step 21920] Loss: 9.37e+07 -1.291492223739624 0.08398739248514175\n",
      "[Step 21921] Loss: 9.37e+07 -1.291606068611145 0.08399152010679245\n",
      "[Step 21922] Loss: 9.43e+07 -1.2916591167449951 0.08397913724184036\n",
      "[Step 21923] Loss: 9.53e+07 -1.2918426990509033 0.08394201099872589\n",
      "[Step 21924] Loss: 9.44e+07 -1.292142391204834 0.08390817791223526\n",
      "[Step 21925] Loss: 9.49e+07 -1.292445182800293 0.08387599885463715\n",
      "[Step 21926] Loss: 9.48e+07 -1.2928671836853027 0.08384381979703903\n",
      "[Step 21927] Loss: 9.72e+07 -1.2937235832214355 0.08376790583133698\n",
      "[Step 21928] Loss: 9.52e+07 -1.2946614027023315 0.08365321159362793\n",
      "[Step 21929] Loss: 9.40e+07 -1.295474886894226 0.08357647061347961\n",
      "[Step 21930] Loss: 9.42e+07 -1.2961387634277344 0.08351458609104156\n",
      "[Step 21931] Loss: 9.42e+07 -1.2967307567596436 0.08345847576856613\n",
      "[Step 21932] Loss: 9.51e+07 -1.2975105047225952 0.08339576423168182\n",
      "[Step 21933] Loss: 9.41e+07 -1.298216462135315 0.0833272784948349\n",
      "[Step 21934] Loss: 9.44e+07 -1.2989312410354614 0.0832604467868805\n",
      "[Step 21935] Loss: 9.41e+07 -1.2996034622192383 0.08321423828601837\n",
      "[Step 21936] Loss: 9.38e+07 -1.3001924753189087 0.08317215740680695\n",
      "[Step 21937] Loss: 9.44e+07 -1.3006877899169922 0.08315235376358032\n",
      "[Step 21938] Loss: 9.52e+07 -1.3013255596160889 0.0831061452627182\n",
      "[Step 21939] Loss: 9.39e+07 -1.3018957376480103 0.08307726681232452\n",
      "[Step 21940] Loss: 9.39e+07 -1.3024318218231201 0.08303435891866684\n",
      "[Step 21941] Loss: 9.41e+07 -1.3029483556747437 0.08298567682504654\n",
      "[Step 21942] Loss: 9.64e+07 -1.303807020187378 0.08292296528816223\n",
      "[Step 21943] Loss: 9.41e+07 -1.3046809434890747 0.08285447955131531\n",
      "[Step 21944] Loss: 9.43e+07 -1.3055760860443115 0.08277773857116699\n",
      "[Step 21945] Loss: 9.42e+07 -1.306325912475586 0.0827166810631752\n",
      "[Step 21946] Loss: 9.43e+07 -1.3069744110107422 0.08264736831188202\n",
      "[Step 21947] Loss: 9.36e+07 -1.307498812675476 0.0825929120182991\n",
      "[Step 21948] Loss: 9.43e+07 -1.3080480098724365 0.08254587650299072\n",
      "[Step 21949] Loss: 9.44e+07 -1.308652400970459 0.08248646557331085\n",
      "[Step 21950] Loss: 9.41e+07 -1.3092671632766724 0.08244025707244873\n",
      "[Step 21951] Loss: 9.50e+07 -1.3098710775375366 0.08236682415008545\n",
      "[Step 21952] Loss: 9.51e+07 -1.3102498054504395 0.08232144266366959\n",
      "[Step 21953] Loss: 9.41e+07 -1.3105981349945068 0.08228925615549088\n",
      "[Step 21954] Loss: 9.50e+07 -1.3107985258102417 0.08225707709789276\n",
      "[Step 21955] Loss: 9.34e+07 -1.3110116720199585 0.08224222809076309\n",
      "[Step 21956] Loss: 9.38e+07 -1.3111357688903809 0.08222737163305283\n",
      "[Step 21957] Loss: 9.50e+07 -1.3111960887908936 0.08223149925470352\n",
      "[Step 21958] Loss: 9.41e+07 -1.3112825155258179 0.0822257250547409\n",
      "[Step 21959] Loss: 9.49e+07 -1.311465859413147 0.08220922201871872\n",
      "[Step 21960] Loss: 9.37e+07 -1.3115358352661133 0.0822034478187561\n",
      "[Step 21961] Loss: 9.45e+07 -1.3115904331207275 0.08219271898269653\n",
      "[Step 21962] Loss: 9.38e+07 -1.3115657567977905 0.08217786252498627\n",
      "[Step 21963] Loss: 9.46e+07 -1.3114590644836426 0.0821852907538414\n",
      "[Step 21964] Loss: 9.43e+07 -1.3113763332366943 0.08219436556100845\n",
      "[Step 21965] Loss: 9.39e+07 -1.3112610578536987 0.08217621594667435\n",
      "[Step 21966] Loss: 9.41e+07 -1.3111276626586914 0.08216878771781921\n",
      "[Step 21967] Loss: 9.43e+07 -1.3109266757965088 0.08218034356832504\n",
      "[Step 21968] Loss: 9.53e+07 -1.310881495475769 0.08217456191778183\n",
      "[Step 21969] Loss: 9.47e+07 -1.3107247352600098 0.0821894183754921\n",
      "[Step 21970] Loss: 9.38e+07 -1.3105825185775757 0.08220509439706802\n",
      "[Step 21971] Loss: 9.49e+07 -1.3103026151657104 0.0822158232331276\n",
      "[Step 21972] Loss: 9.38e+07 -1.3100073337554932 0.08224552869796753\n",
      "[Step 21973] Loss: 9.53e+07 -1.3097420930862427 0.08222325146198273\n",
      "[Step 21974] Loss: 9.33e+07 -1.3094629049301147 0.08221334964036942\n",
      "[Step 21975] Loss: 9.39e+07 -1.3092683553695679 0.08223727345466614\n",
      "[Step 21976] Loss: 9.41e+07 -1.30917489528656 0.08224470168352127\n",
      "[Step 21977] Loss: 9.42e+07 -1.3091652393341064 0.08223892748355865\n",
      "[Step 21978] Loss: 9.41e+07 -1.309148907661438 0.08222737163305283\n",
      "[Step 21979] Loss: 9.42e+07 -1.3090977668762207 0.08223645389080048\n",
      "[Step 21980] Loss: 9.37e+07 -1.308947205543518 0.08223975449800491\n",
      "[Step 21981] Loss: 9.46e+07 -1.3087804317474365 0.08226863294839859\n",
      "[Step 21982] Loss: 9.41e+07 -1.3085906505584717 0.08226863294839859\n",
      "[Step 21983] Loss: 9.40e+07 -1.308465600013733 0.08227523416280746\n",
      "[Step 21984] Loss: 9.43e+07 -1.3083940744400024 0.08228430896997452\n",
      "[Step 21985] Loss: 9.41e+07 -1.308215856552124 0.08231071382761002\n",
      "[Step 21986] Loss: 9.56e+07 -1.3082810640335083 0.08228843659162521\n",
      "[Step 21987] Loss: 9.46e+07 -1.3084867000579834 0.0822645053267479\n",
      "[Step 21988] Loss: 9.42e+07 -1.3085719347000122 0.08225955069065094\n",
      "[Step 21989] Loss: 9.35e+07 -1.3085969686508179 0.0822562500834465\n",
      "[Step 21990] Loss: 9.41e+07 -1.3085668087005615 0.08225460350513458\n",
      "[Step 21991] Loss: 9.42e+07 -1.3084923028945923 0.08226120471954346\n",
      "[Step 21992] Loss: 9.37e+07 -1.3084226846694946 0.08227770775556564\n",
      "[Step 21993] Loss: 9.44e+07 -1.3082952499389648 0.0822867825627327\n",
      "[Step 21994] Loss: 9.47e+07 -1.3080520629882812 0.08231896162033081\n",
      "[Step 21995] Loss: 9.41e+07 -1.3078067302703857 0.08234866708517075\n",
      "[Step 21996] Loss: 9.36e+07 -1.3075642585754395 0.082349494099617\n",
      "[Step 21997] Loss: 9.39e+07 -1.3072762489318848 0.08236764371395111\n",
      "[Step 21998] Loss: 9.42e+07 -1.3069473505020142 0.08238910138607025\n",
      "[Step 21999] Loss: 9.44e+07 -1.306588053703308 0.08240807801485062\n",
      "[Step 22000] Loss: 9.39e+07 -1.306328296661377 0.08242540806531906\n",
      "[Step 22001] Loss: 9.45e+07 -1.3060343265533447 0.08242953568696976\n",
      "[Step 22002] Loss: 9.39e+07 -1.3058210611343384 0.08243861049413681\n",
      "[Step 22003] Loss: 9.40e+07 -1.3055850267410278 0.0824427381157875\n",
      "[Step 22004] Loss: 9.44e+07 -1.305465817451477 0.08244768530130386\n",
      "[Step 22005] Loss: 9.38e+07 -1.3053971529006958 0.08243530988693237\n",
      "[Step 22006] Loss: 9.42e+07 -1.3052693605422974 0.08242788165807724\n",
      "[Step 22007] Loss: 9.39e+07 -1.305100917816162 0.08241633325815201\n",
      "[Step 22008] Loss: 9.35e+07 -1.3049311637878418 0.08241467922925949\n",
      "[Step 22009] Loss: 9.41e+07 -1.304641842842102 0.08239734917879105\n",
      "[Step 22010] Loss: 9.50e+07 -1.3044779300689697 0.082402303814888\n",
      "[Step 22011] Loss: 9.43e+07 -1.3042875528335571 0.08241715282201767\n",
      "[Step 22012] Loss: 9.54e+07 -1.3040565252304077 0.08243365585803986\n",
      "[Step 22013] Loss: 9.47e+07 -1.303918719291687 0.08244933933019638\n",
      "[Step 22014] Loss: 9.46e+07 -1.3039005994796753 0.08245345950126648\n",
      "[Step 22015] Loss: 9.39e+07 -1.3038768768310547 0.08245676010847092\n",
      "[Step 22016] Loss: 9.52e+07 -1.3040059804916382 0.08243448287248611\n",
      "[Step 22017] Loss: 9.38e+07 -1.3041030168533325 0.08242293447256088\n",
      "[Step 22018] Loss: 9.41e+07 -1.3042620420455933 0.08239570260047913\n",
      "[Step 22019] Loss: 9.43e+07 -1.304291844367981 0.08238744735717773\n",
      "[Step 22020] Loss: 9.43e+07 -1.304220199584961 0.08237919956445694\n",
      "[Step 22021] Loss: 9.37e+07 -1.3041279315948486 0.08239404857158661\n",
      "[Step 22022] Loss: 9.41e+07 -1.3040510416030884 0.08240147680044174\n",
      "[Step 22023] Loss: 9.40e+07 -1.3039231300354004 0.0824245810508728\n",
      "[Step 22024] Loss: 9.54e+07 -1.3040128946304321 0.08241303265094757\n",
      "[Step 22025] Loss: 9.48e+07 -1.30427885055542 0.08237424492835999\n",
      "[Step 22026] Loss: 9.45e+07 -1.3045026063919067 0.08235114812850952\n",
      "[Step 22027] Loss: 9.47e+07 -1.3045811653137207 0.08234124630689621\n",
      "[Step 22028] Loss: 9.44e+07 -1.304694652557373 0.08233794569969177\n",
      "[Step 22029] Loss: 9.41e+07 -1.304795742034912 0.08232638984918594\n",
      "[Step 22030] Loss: 9.44e+07 -1.3049074411392212 0.08231236040592194\n",
      "[Step 22031] Loss: 9.43e+07 -1.3050711154937744 0.08228100836277008\n",
      "[Step 22032] Loss: 9.46e+07 -1.305295467376709 0.08224635571241379\n",
      "[Step 22033] Loss: 9.46e+07 -1.305557131767273 0.08222819864749908\n",
      "[Step 22034] Loss: 9.45e+07 -1.3058489561080933 0.08219766616821289\n",
      "[Step 22035] Loss: 9.40e+07 -1.3060799837112427 0.0821671411395073\n",
      "[Step 22036] Loss: 9.47e+07 -1.306137204170227 0.08215311169624329\n",
      "[Step 22037] Loss: 9.44e+07 -1.306198000907898 0.08210690319538116\n",
      "[Step 22038] Loss: 9.39e+07 -1.3061646223068237 0.08209782838821411\n",
      "[Step 22039] Loss: 9.45e+07 -1.3062304258346558 0.0820920541882515\n",
      "[Step 22040] Loss: 9.46e+07 -1.3063162565231323 0.08207059651613235\n",
      "[Step 22041] Loss: 9.46e+07 -1.3062782287597656 0.08208545297384262\n",
      "[Step 22042] Loss: 9.40e+07 -1.3062167167663574 0.08209040015935898\n",
      "[Step 22043] Loss: 9.39e+07 -1.306043028831482 0.08209287375211716\n",
      "[Step 22044] Loss: 9.53e+07 -1.3057132959365845 0.08210112899541855\n",
      "[Step 22045] Loss: 9.35e+07 -1.3053864240646362 0.08212670683860779\n",
      "[Step 22046] Loss: 9.37e+07 -1.3050305843353271 0.08216384053230286\n",
      "[Step 22047] Loss: 9.42e+07 -1.304788589477539 0.08218034356832504\n",
      "[Step 22048] Loss: 9.37e+07 -1.3045339584350586 0.08221004903316498\n",
      "[Step 22049] Loss: 9.41e+07 -1.304290771484375 0.08223892748355865\n",
      "[Step 22050] Loss: 9.45e+07 -1.303963541984558 0.08226533234119415\n",
      "[Step 22051] Loss: 9.47e+07 -1.303617238998413 0.08229008316993713\n",
      "[Step 22052] Loss: 9.42e+07 -1.3032879829406738 0.08233711868524551\n",
      "[Step 22053] Loss: 9.48e+07 -1.3029401302337646 0.08237259835004807\n",
      "[Step 22054] Loss: 9.45e+07 -1.3025202751159668 0.08240477740764618\n",
      "[Step 22055] Loss: 9.47e+07 -1.302032232284546 0.08244521170854568\n",
      "[Step 22056] Loss: 9.45e+07 -1.3016183376312256 0.08247573673725128\n",
      "[Step 22057] Loss: 9.40e+07 -1.3012564182281494 0.08251534402370453\n",
      "[Step 22058] Loss: 9.39e+07 -1.3008813858032227 0.08255660533905029\n",
      "[Step 22059] Loss: 9.43e+07 -1.3006401062011719 0.08256320655345917\n",
      "[Step 22060] Loss: 9.42e+07 -1.3004884719848633 0.08255990594625473\n",
      "[Step 22061] Loss: 9.63e+07 -1.300704002380371 0.08253514766693115\n",
      "[Step 22062] Loss: 9.53e+07 -1.30077064037323 0.08252937346696854\n",
      "[Step 22063] Loss: 9.44e+07 -1.300784707069397 0.08251039683818817\n",
      "[Step 22064] Loss: 9.58e+07 -1.3009377717971802 0.0824955403804779\n",
      "[Step 22065] Loss: 9.41e+07 -1.3011562824249268 0.08248646557331085\n",
      "[Step 22066] Loss: 9.47e+07 -1.3014048337936401 0.08246996253728867\n",
      "[Step 22067] Loss: 9.43e+07 -1.3016436100006104 0.08245428651571274\n",
      "[Step 22068] Loss: 9.42e+07 -1.301917552947998 0.08244025707244873\n",
      "[Step 22069] Loss: 9.51e+07 -1.3020931482315063 0.08243530988693237\n",
      "[Step 22070] Loss: 9.38e+07 -1.3022428750991821 0.0824287086725235\n",
      "[Step 22071] Loss: 9.35e+07 -1.3024300336837769 0.08240973204374313\n",
      "[Step 22072] Loss: 9.41e+07 -1.3025723695755005 0.08238250017166138\n",
      "[Step 22073] Loss: 9.46e+07 -1.3026503324508667 0.0823536217212677\n",
      "[Step 22074] Loss: 9.41e+07 -1.3027124404907227 0.08234041929244995\n",
      "[Step 22075] Loss: 9.42e+07 -1.302753210067749 0.08232638984918594\n",
      "[Step 22076] Loss: 9.43e+07 -1.302869439125061 0.08231154084205627\n",
      "[Step 22077] Loss: 9.48e+07 -1.3028463125228882 0.08231978863477707\n",
      "[Step 22078] Loss: 9.41e+07 -1.3027983903884888 0.08232638984918594\n",
      "[Step 22079] Loss: 9.42e+07 -1.3027849197387695 0.08232804387807846\n",
      "[Step 22080] Loss: 9.43e+07 -1.3028091192245483 0.08231401443481445\n",
      "[Step 22081] Loss: 9.36e+07 -1.3028113842010498 0.08232638984918594\n",
      "[Step 22082] Loss: 9.49e+07 -1.303002953529358 0.08228843659162521\n",
      "[Step 22083] Loss: 9.43e+07 -1.303310751914978 0.08224057406187057\n",
      "[Step 22084] Loss: 9.43e+07 -1.3036189079284668 0.08220096677541733\n",
      "[Step 22085] Loss: 9.45e+07 -1.3037911653518677 0.08218611776828766\n",
      "[Step 22086] Loss: 9.46e+07 -1.3039019107818604 0.08217374235391617\n",
      "[Step 22087] Loss: 9.53e+07 -1.3042713403701782 0.08212175965309143\n",
      "[Step 22088] Loss: 9.47e+07 -1.304556131362915 0.08211185783147812\n",
      "[Step 22089] Loss: 9.32e+07 -1.3048160076141357 0.08208545297384262\n",
      "[Step 22090] Loss: 9.53e+07 -1.3052901029586792 0.08202521502971649\n",
      "[Step 22091] Loss: 9.43e+07 -1.3058241605758667 0.08196167647838593\n",
      "[Step 22092] Loss: 9.41e+07 -1.3062394857406616 0.08193279802799225\n",
      "[Step 22093] Loss: 9.43e+07 -1.3065789937973022 0.08191052079200745\n",
      "[Step 22094] Loss: 9.42e+07 -1.306915044784546 0.08187998831272125\n",
      "[Step 22095] Loss: 9.38e+07 -1.3072113990783691 0.08185771107673645\n",
      "[Step 22096] Loss: 9.47e+07 -1.3076404333114624 0.08182140439748764\n",
      "[Step 22097] Loss: 9.42e+07 -1.3079966306686401 0.08180078119039536\n",
      "[Step 22098] Loss: 9.44e+07 -1.308336853981018 0.08175291866064072\n",
      "[Step 22099] Loss: 9.36e+07 -1.3086211681365967 0.0817248672246933\n",
      "[Step 22100] Loss: 9.37e+07 -1.3088250160217285 0.08170919120311737\n",
      "[Step 22101] Loss: 9.42e+07 -1.3089709281921387 0.08169680833816528\n",
      "[Step 22102] Loss: 9.41e+07 -1.3091338872909546 0.08167865872383118\n",
      "[Step 22103] Loss: 9.51e+07 -1.3093299865722656 0.08165968209505081\n",
      "[Step 22104] Loss: 9.42e+07 -1.3095531463623047 0.08164647966623306\n",
      "[Step 22105] Loss: 9.42e+07 -1.3098286390304565 0.08164399862289429\n",
      "[Step 22106] Loss: 9.48e+07 -1.3099864721298218 0.08160769939422607\n",
      "[Step 22107] Loss: 9.39e+07 -1.3101744651794434 0.08158459514379501\n",
      "[Step 22108] Loss: 9.45e+07 -1.3104134798049927 0.08157303929328918\n",
      "[Step 22109] Loss: 9.35e+07 -1.3106162548065186 0.08155570924282074\n",
      "[Step 22110] Loss: 9.46e+07 -1.3107914924621582 0.0815260112285614\n",
      "[Step 22111] Loss: 9.37e+07 -1.3109015226364136 0.08152518421411514\n",
      "[Step 22112] Loss: 9.45e+07 -1.311055302619934 0.08152022957801819\n",
      "[Step 22113] Loss: 9.40e+07 -1.3110979795455933 0.0815078541636467\n",
      "[Step 22114] Loss: 9.39e+07 -1.3111684322357178 0.08149547874927521\n",
      "[Step 22115] Loss: 9.51e+07 -1.3110262155532837 0.0815078541636467\n",
      "[Step 22116] Loss: 9.38e+07 -1.310802698135376 0.08152683079242706\n",
      "[Step 22117] Loss: 9.41e+07 -1.3106756210327148 0.0815260112285614\n",
      "[Step 22118] Loss: 9.41e+07 -1.310503363609314 0.08155488967895508\n",
      "[Step 22119] Loss: 9.36e+07 -1.3103759288787842 0.08156561106443405\n",
      "[Step 22120] Loss: 9.39e+07 -1.3102941513061523 0.08157139271497726\n",
      "[Step 22121] Loss: 9.39e+07 -1.3101414442062378 0.08159449696540833\n",
      "[Step 22122] Loss: 9.49e+07 -1.3099004030227661 0.08161594718694687\n",
      "[Step 22123] Loss: 9.55e+07 -1.3095109462738037 0.08165225386619568\n",
      "[Step 22124] Loss: 9.48e+07 -1.3090354204177856 0.08168195933103561\n",
      "[Step 22125] Loss: 9.43e+07 -1.3086977005004883 0.08171083778142929\n",
      "[Step 22126] Loss: 9.41e+07 -1.3084118366241455 0.08174467086791992\n",
      "[Step 22127] Loss: 9.41e+07 -1.3081738948822021 0.08178015053272247\n",
      "[Step 22128] Loss: 9.42e+07 -1.30797278881073 0.08179830014705658\n",
      "[Step 22129] Loss: 9.66e+07 -1.3076331615447998 0.0818222314119339\n",
      "[Step 22130] Loss: 9.44e+07 -1.307399868965149 0.08183956146240234\n",
      "[Step 22131] Loss: 9.39e+07 -1.3071167469024658 0.08183956146240234\n",
      "[Step 22132] Loss: 9.42e+07 -1.306813359260559 0.08186018466949463\n",
      "[Step 22133] Loss: 9.42e+07 -1.3065882921218872 0.08189649134874344\n",
      "[Step 22134] Loss: 9.40e+07 -1.3064688444137573 0.08191877603530884\n",
      "[Step 22135] Loss: 9.44e+07 -1.3063344955444336 0.08193362504243851\n",
      "[Step 22136] Loss: 9.46e+07 -1.3062196969985962 0.08193362504243851\n",
      "[Step 22137] Loss: 9.45e+07 -1.3061983585357666 0.08193115144968033\n",
      "[Step 22138] Loss: 9.40e+07 -1.3062382936477661 0.08191629499197006\n",
      "[Step 22139] Loss: 9.46e+07 -1.306235909461975 0.08191217482089996\n",
      "[Step 22140] Loss: 9.33e+07 -1.3061648607254028 0.08191217482089996\n",
      "[Step 22141] Loss: 9.49e+07 -1.3060754537582397 0.08193527907133102\n",
      "[Step 22142] Loss: 9.39e+07 -1.3059921264648438 0.08194682747125626\n",
      "[Step 22143] Loss: 9.52e+07 -1.3060588836669922 0.08193032443523407\n",
      "[Step 22144] Loss: 9.47e+07 -1.3059895038604736 0.08194930106401443\n",
      "[Step 22145] Loss: 9.40e+07 -1.3058723211288452 0.08194765448570251\n",
      "[Step 22146] Loss: 9.43e+07 -1.3058226108551025 0.08195095509290695\n",
      "[Step 22147] Loss: 9.44e+07 -1.3057652711868286 0.08196663111448288\n",
      "[Step 22148] Loss: 9.45e+07 -1.3058499097824097 0.08193445205688477\n",
      "[Step 22149] Loss: 9.50e+07 -1.3058463335037231 0.08192207664251328\n",
      "[Step 22150] Loss: 9.46e+07 -1.3059462308883667 0.08190309256315231\n",
      "[Step 22151] Loss: 9.36e+07 -1.3059297800064087 0.08190227299928665\n",
      "[Step 22152] Loss: 9.36e+07 -1.305949330329895 0.08190309256315231\n",
      "[Step 22153] Loss: 9.40e+07 -1.3059372901916504 0.0818973183631897\n",
      "[Step 22154] Loss: 9.36e+07 -1.305942177772522 0.08189237117767334\n",
      "[Step 22155] Loss: 9.45e+07 -1.3061083555221558 0.08186596632003784\n",
      "[Step 22156] Loss: 9.46e+07 -1.3062124252319336 0.08183873444795609\n",
      "[Step 22157] Loss: 9.41e+07 -1.3062186241149902 0.08183460682630539\n",
      "[Step 22158] Loss: 9.47e+07 -1.3063304424285889 0.08183213323354721\n",
      "[Step 22159] Loss: 9.36e+07 -1.3063979148864746 0.08181563019752502\n",
      "[Step 22160] Loss: 9.38e+07 -1.3064461946487427 0.08181480318307877\n",
      "[Step 22161] Loss: 9.51e+07 -1.3067667484283447 0.08177437633275986\n",
      "[Step 22162] Loss: 9.44e+07 -1.3071271181106567 0.08173229545354843\n",
      "[Step 22163] Loss: 9.48e+07 -1.3074496984481812 0.08169268816709518\n",
      "[Step 22164] Loss: 9.58e+07 -1.308095932006836 0.08162254840135574\n",
      "[Step 22165] Loss: 9.44e+07 -1.308624029159546 0.0815606638789177\n",
      "[Step 22166] Loss: 9.47e+07 -1.309185266494751 0.08150290697813034\n",
      "[Step 22167] Loss: 9.41e+07 -1.309603214263916 0.08145174384117126\n",
      "[Step 22168] Loss: 9.43e+07 -1.3099597692489624 0.08141956478357315\n",
      "[Step 22169] Loss: 9.33e+07 -1.3102447986602783 0.08138903230428696\n",
      "[Step 22170] Loss: 9.41e+07 -1.3103705644607544 0.08136510848999023\n",
      "[Step 22171] Loss: 9.43e+07 -1.310572624206543 0.08131807297468185\n",
      "[Step 22172] Loss: 9.45e+07 -1.310766577720642 0.08129992336034775\n",
      "[Step 22173] Loss: 9.54e+07 -1.3108141422271729 0.08129662275314331\n",
      "[Step 22174] Loss: 9.42e+07 -1.3108047246932983 0.08130404353141785\n",
      "[Step 22175] Loss: 9.40e+07 -1.310804009437561 0.08130239695310593\n",
      "[Step 22176] Loss: 9.38e+07 -1.3107877969741821 0.08129992336034775\n",
      "[Step 22177] Loss: 9.39e+07 -1.3108290433883667 0.08127763867378235\n",
      "[Step 22178] Loss: 9.44e+07 -1.310972809791565 0.0812685638666153\n",
      "[Step 22179] Loss: 9.37e+07 -1.3110841512680054 0.08127186447381973\n",
      "[Step 22180] Loss: 9.33e+07 -1.311145544052124 0.08126773685216904\n",
      "[Step 22181] Loss: 9.55e+07 -1.3113912343978882 0.08125123381614685\n",
      "[Step 22182] Loss: 9.40e+07 -1.3115957975387573 0.0812380313873291\n",
      "[Step 22183] Loss: 9.65e+07 -1.312157392501831 0.08117532730102539\n",
      "[Step 22184] Loss: 9.44e+07 -1.312570333480835 0.08114562183618546\n",
      "[Step 22185] Loss: 9.44e+07 -1.3130742311477661 0.08108951151371002\n",
      "[Step 22186] Loss: 9.39e+07 -1.313480019569397 0.08106227964162827\n",
      "[Step 22187] Loss: 9.43e+07 -1.3138736486434937 0.08102019876241684\n",
      "[Step 22188] Loss: 9.50e+07 -1.3144038915634155 0.08096904307603836\n",
      "[Step 22189] Loss: 9.38e+07 -1.3148871660232544 0.08091457933187485\n",
      "[Step 22190] Loss: 9.40e+07 -1.3152354955673218 0.08088157325983047\n",
      "[Step 22191] Loss: 9.41e+07 -1.3155474662780762 0.08085104823112488\n",
      "[Step 22192] Loss: 9.42e+07 -1.3159021139144897 0.08082464337348938\n",
      "[Step 22193] Loss: 9.49e+07 -1.3163570165634155 0.08079411089420319\n",
      "[Step 22194] Loss: 9.40e+07 -1.3167345523834229 0.08074872940778732\n",
      "[Step 22195] Loss: 9.42e+07 -1.3170984983444214 0.08071159571409225\n",
      "[Step 22196] Loss: 9.42e+07 -1.3173904418945312 0.08069097250699997\n",
      "[Step 22197] Loss: 9.54e+07 -1.3178718090057373 0.08064310997724533\n",
      "[Step 22198] Loss: 9.42e+07 -1.3182735443115234 0.08058948069810867\n",
      "[Step 22199] Loss: 9.38e+07 -1.3186218738555908 0.08057132363319397\n",
      "[Step 22200] Loss: 9.35e+07 -1.3189096450805664 0.08054327219724655\n",
      "[Step 22201] Loss: 9.46e+07 -1.3190977573394775 0.0805564746260643\n",
      "[Step 22202] Loss: 9.47e+07 -1.3191787004470825 0.08056719601154327\n",
      "[Step 22203] Loss: 9.42e+07 -1.319161295890808 0.08055151998996735\n",
      "[Step 22204] Loss: 9.56e+07 -1.3193936347961426 0.08053337037563324\n",
      "[Step 22205] Loss: 9.42e+07 -1.3197779655456543 0.08050696551799774\n",
      "[Step 22206] Loss: 9.42e+07 -1.3201287984848022 0.08047973364591599\n",
      "[Step 22207] Loss: 9.37e+07 -1.320387601852417 0.08043187856674194\n",
      "[Step 22208] Loss: 9.41e+07 -1.3206456899642944 0.0803963914513588\n",
      "[Step 22209] Loss: 9.39e+07 -1.3208407163619995 0.08037081360816956\n",
      "[Step 22210] Loss: 9.35e+07 -1.3209854364395142 0.08036091178655624\n",
      "[Step 22211] Loss: 9.43e+07 -1.3210062980651855 0.0803477093577385\n",
      "[Step 22212] Loss: 9.58e+07 -1.3212933540344238 0.08031470328569412\n",
      "[Step 22213] Loss: 9.46e+07 -1.321540355682373 0.08028417825698853\n",
      "[Step 22214] Loss: 9.51e+07 -1.321671962738037 0.0802602469921112\n",
      "[Step 22215] Loss: 9.56e+07 -1.3216685056686401 0.0802602469921112\n",
      "[Step 22216] Loss: 9.47e+07 -1.3218293190002441 0.0802643746137619\n",
      "[Step 22217] Loss: 9.46e+07 -1.3220341205596924 0.08024539798498154\n",
      "[Step 22218] Loss: 9.45e+07 -1.3222914934158325 0.08020249009132385\n",
      "[Step 22219] Loss: 9.46e+07 -1.3224761486053467 0.08017855882644653\n",
      "[Step 22220] Loss: 9.44e+07 -1.322597861289978 0.08016618341207504\n",
      "[Step 22221] Loss: 9.52e+07 -1.322558045387268 0.0801628828048706\n",
      "[Step 22222] Loss: 9.39e+07 -1.3224976062774658 0.08015628159046173\n",
      "[Step 22223] Loss: 9.42e+07 -1.3223401308059692 0.08017195761203766\n",
      "[Step 22224] Loss: 9.40e+07 -1.3222190141677856 0.08016535639762878\n",
      "[Step 22225] Loss: 9.45e+07 -1.3220436573028564 0.08017278462648392\n",
      "[Step 22226] Loss: 9.38e+07 -1.3218519687652588 0.08018185943365097\n",
      "[Step 22227] Loss: 9.49e+07 -1.3218179941177368 0.08017608523368835\n",
      "[Step 22228] Loss: 9.39e+07 -1.3217530250549316 0.08016782999038696\n",
      "[Step 22229] Loss: 9.41e+07 -1.3216803073883057 0.08016452938318253\n",
      "[Step 22230] Loss: 9.36e+07 -1.3216066360473633 0.08017278462648392\n",
      "[Step 22231] Loss: 9.41e+07 -1.321520209312439 0.08018846064805984\n",
      "[Step 22232] Loss: 9.41e+07 -1.321392297744751 0.08020413666963577\n",
      "[Step 22233] Loss: 9.41e+07 -1.3211971521377563 0.08022063970565796\n",
      "[Step 22234] Loss: 9.44e+07 -1.3210268020629883 0.08023136854171753\n",
      "[Step 22235] Loss: 9.41e+07 -1.320852279663086 0.08023384213447571\n",
      "[Step 22236] Loss: 9.56e+07 -1.3210231065750122 0.08020000904798508\n",
      "[Step 22237] Loss: 9.36e+07 -1.3211283683776855 0.08017691224813461\n",
      "[Step 22238] Loss: 9.40e+07 -1.3212333917617798 0.0801670104265213\n",
      "[Step 22239] Loss: 9.44e+07 -1.3213273286819458 0.08014390617609024\n",
      "[Step 22240] Loss: 9.42e+07 -1.3213262557983398 0.08017691224813461\n",
      "[Step 22241] Loss: 9.43e+07 -1.3211841583251953 0.08020330965518951\n",
      "[Step 22242] Loss: 9.43e+07 -1.3209812641143799 0.0802198126912117\n",
      "[Step 22243] Loss: 9.35e+07 -1.320842981338501 0.08022311329841614\n",
      "[Step 22244] Loss: 9.38e+07 -1.32075035572052 0.08021899312734604\n",
      "[Step 22245] Loss: 9.44e+07 -1.3206877708435059 0.08021816611289978\n",
      "[Step 22246] Loss: 9.40e+07 -1.3205959796905518 0.08022229373455048\n",
      "[Step 22247] Loss: 9.44e+07 -1.3205726146697998 0.08022476732730865\n",
      "[Step 22248] Loss: 9.59e+07 -1.3207385540008545 0.08022476732730865\n",
      "[Step 22249] Loss: 9.35e+07 -1.320894718170166 0.08021073788404465\n",
      "[Step 22250] Loss: 9.45e+07 -1.3211462497711182 0.08019423484802246\n",
      "[Step 22251] Loss: 9.43e+07 -1.3214292526245117 0.08016370981931686\n",
      "[Step 22252] Loss: 9.48e+07 -1.3215851783752441 0.08014307916164398\n",
      "[Step 22253] Loss: 9.44e+07 -1.3217850923538208 0.08011090010404587\n",
      "[Step 22254] Loss: 9.46e+07 -1.3220360279083252 0.08006881922483444\n",
      "[Step 22255] Loss: 9.40e+07 -1.322222352027893 0.08007459342479706\n",
      "[Step 22256] Loss: 9.36e+07 -1.322429895401001 0.08006386458873749\n",
      "[Step 22257] Loss: 9.37e+07 -1.3225725889205933 0.08004901558160782\n",
      "[Step 22258] Loss: 9.38e+07 -1.322659969329834 0.08004571497440338\n",
      "[Step 22259] Loss: 9.54e+07 -1.3229973316192627 0.08001105487346649\n",
      "[Step 22260] Loss: 9.36e+07 -1.3232685327529907 0.07996650040149689\n",
      "[Step 22261] Loss: 9.38e+07 -1.3235141038894653 0.07992853969335556\n",
      "[Step 22262] Loss: 9.44e+07 -1.3236291408538818 0.07990791648626328\n",
      "[Step 22263] Loss: 9.42e+07 -1.3237189054489136 0.0798872858285904\n",
      "[Step 22264] Loss: 9.52e+07 -1.3239150047302246 0.07986335456371307\n",
      "[Step 22265] Loss: 9.43e+07 -1.3240326642990112 0.07984190434217453\n",
      "[Step 22266] Loss: 9.58e+07 -1.3244199752807617 0.07978662103414536\n",
      "[Step 22267] Loss: 9.44e+07 -1.3248248100280762 0.07972968369722366\n",
      "[Step 22268] Loss: 9.44e+07 -1.325316071510315 0.07967604696750641\n",
      "[Step 22269] Loss: 9.44e+07 -1.3257074356079102 0.07961829006671906\n",
      "[Step 22270] Loss: 9.56e+07 -1.3263131380081177 0.07954567670822144\n",
      "[Step 22271] Loss: 9.37e+07 -1.3267794847488403 0.0794854462146759\n",
      "[Step 22272] Loss: 9.51e+07 -1.3273721933364868 0.07942603528499603\n",
      "[Step 22273] Loss: 9.48e+07 -1.3280203342437744 0.07937157154083252\n",
      "[Step 22274] Loss: 9.39e+07 -1.328640341758728 0.07931381464004517\n",
      "[Step 22275] Loss: 9.43e+07 -1.3291778564453125 0.07926100492477417\n",
      "[Step 22276] Loss: 9.47e+07 -1.329526424407959 0.0792321264743805\n",
      "[Step 22277] Loss: 9.40e+07 -1.3298428058624268 0.07920407503843307\n",
      "[Step 22278] Loss: 9.41e+07 -1.3300632238388062 0.07918509095907211\n",
      "[Step 22279] Loss: 9.46e+07 -1.3302274942398071 0.0791570395231247\n",
      "[Step 22280] Loss: 9.37e+07 -1.330385684967041 0.0791223868727684\n",
      "[Step 22281] Loss: 9.50e+07 -1.3305108547210693 0.07910588383674622\n",
      "[Step 22282] Loss: 9.46e+07 -1.3306214809417725 0.0791223868727684\n",
      "[Step 22283] Loss: 9.44e+07 -1.3306474685668945 0.0791223868727684\n",
      "[Step 22284] Loss: 9.40e+07 -1.3306270837783813 0.0791042298078537\n",
      "[Step 22285] Loss: 9.43e+07 -1.3305795192718506 0.07909762859344482\n",
      "[Step 22286] Loss: 9.62e+07 -1.3308147192001343 0.07904977351427078\n",
      "[Step 22287] Loss: 9.43e+07 -1.3309935331344604 0.07904151827096939\n",
      "[Step 22288] Loss: 9.38e+07 -1.3311487436294556 0.0790250152349472\n",
      "[Step 22289] Loss: 9.39e+07 -1.3312935829162598 0.0790208950638771\n",
      "[Step 22290] Loss: 9.53e+07 -1.3312771320343018 0.07899696379899979\n",
      "[Step 22291] Loss: 9.30e+07 -1.3312098979949951 0.07900769263505936\n",
      "[Step 22292] Loss: 9.45e+07 -1.3310376405715942 0.07901429384946823\n",
      "[Step 22293] Loss: 9.49e+07 -1.3308000564575195 0.07902006804943085\n",
      "[Step 22294] Loss: 9.38e+07 -1.330613136291504 0.07900933921337128\n",
      "[Step 22295] Loss: 9.36e+07 -1.3303953409194946 0.07901594042778015\n",
      "[Step 22296] Loss: 9.45e+07 -1.3301072120666504 0.07903161644935608\n",
      "[Step 22297] Loss: 9.37e+07 -1.3298017978668213 0.07905719429254532\n",
      "[Step 22298] Loss: 9.48e+07 -1.3294041156768799 0.07909102737903595\n",
      "[Step 22299] Loss: 9.48e+07 -1.3291739225387573 0.07910588383674622\n",
      "[Step 22300] Loss: 9.56e+07 -1.329243540763855 0.07908525317907333\n",
      "[Step 22301] Loss: 9.37e+07 -1.3293408155441284 0.0790637955069542\n",
      "[Step 22302] Loss: 9.49e+07 -1.3293856382369995 0.07904564589262009\n",
      "[Step 22303] Loss: 9.44e+07 -1.329331636428833 0.07903904467821121\n",
      "[Step 22304] Loss: 9.50e+07 -1.3294734954833984 0.07901594042778015\n",
      "[Step 22305] Loss: 9.50e+07 -1.3295196294784546 0.07900933921337128\n",
      "[Step 22306] Loss: 9.50e+07 -1.3295526504516602 0.0790068656206131\n",
      "[Step 22307] Loss: 9.44e+07 -1.3295607566833496 0.07899283617734909\n",
      "[Step 22308] Loss: 9.46e+07 -1.3296680450439453 0.07898953557014465\n",
      "[Step 22309] Loss: 9.43e+07 -1.3298002481460571 0.07896395772695541\n",
      "[Step 22310] Loss: 9.44e+07 -1.32993483543396 0.07894580066204071\n",
      "[Step 22311] Loss: 9.52e+07 -1.3301738500595093 0.07893837988376617\n",
      "[Step 22312] Loss: 9.54e+07 -1.33022141456604 0.07891940325498581\n",
      "[Step 22313] Loss: 9.42e+07 -1.3302091360092163 0.07892187684774399\n",
      "[Step 22314] Loss: 9.50e+07 -1.3300135135650635 0.07893095165491104\n",
      "[Step 22315] Loss: 9.66e+07 -1.3302276134490967 0.07888969779014587\n",
      "[Step 22316] Loss: 9.65e+07 -1.3306515216827393 0.07885421067476273\n",
      "[Step 22317] Loss: 9.51e+07 -1.331190586090088 0.07880305498838425\n",
      "[Step 22318] Loss: 9.41e+07 -1.3315715789794922 0.07875024527311325\n",
      "[Step 22319] Loss: 9.46e+07 -1.3318146467208862 0.07872632145881653\n",
      "[Step 22320] Loss: 9.44e+07 -1.3319066762924194 0.07869166135787964\n",
      "[Step 22321] Loss: 9.38e+07 -1.3319965600967407 0.07868258655071259\n",
      "[Step 22322] Loss: 9.44e+07 -1.3320428133010864 0.07867515832185745\n",
      "[Step 22323] Loss: 9.42e+07 -1.3321259021759033 0.07865700870752335\n",
      "[Step 22324] Loss: 9.49e+07 -1.3323848247528076 0.07864132523536682\n",
      "[Step 22325] Loss: 9.39e+07 -1.3324536085128784 0.07865040749311447\n",
      "[Step 22326] Loss: 9.43e+07 -1.3326289653778076 0.0786396786570549\n",
      "[Step 22327] Loss: 9.39e+07 -1.332745909690857 0.07863885164260864\n",
      "[Step 22328] Loss: 9.43e+07 -1.3328347206115723 0.07863060384988785\n",
      "[Step 22329] Loss: 9.38e+07 -1.3330354690551758 0.07862482964992523\n",
      "[Step 22330] Loss: 9.42e+07 -1.333117127418518 0.07863142341375351\n",
      "[Step 22331] Loss: 9.42e+07 -1.3331499099731445 0.0786215290427208\n",
      "[Step 22332] Loss: 9.40e+07 -1.333066463470459 0.07864710688591003\n",
      "[Step 22333] Loss: 9.35e+07 -1.3329542875289917 0.07866442948579788\n",
      "[Step 22334] Loss: 9.54e+07 -1.3330762386322021 0.07866938412189484\n",
      "[Step 22335] Loss: 9.40e+07 -1.3332160711288452 0.07867103070020676\n",
      "[Step 22336] Loss: 9.46e+07 -1.3332149982452393 0.0786924883723259\n",
      "[Step 22337] Loss: 9.46e+07 -1.3332993984222412 0.07869743555784225\n",
      "[Step 22338] Loss: 9.45e+07 -1.33346426486969 0.0786924883723259\n",
      "[Step 22339] Loss: 9.38e+07 -1.333591103553772 0.07867763191461563\n",
      "[Step 22340] Loss: 9.42e+07 -1.3338021039962769 0.07865782827138901\n",
      "[Step 22341] Loss: 9.39e+07 -1.3339753150939941 0.0786438062787056\n",
      "[Step 22342] Loss: 9.43e+07 -1.3340911865234375 0.07865452766418457\n",
      "[Step 22343] Loss: 9.38e+07 -1.334222435951233 0.07865122705698013\n",
      "[Step 22344] Loss: 9.63e+07 -1.3347344398498535 0.07861244678497314\n",
      "[Step 22345] Loss: 9.43e+07 -1.335017204284668 0.07859264314174652\n",
      "[Step 22346] Loss: 9.60e+07 -1.335139513015747 0.07858522236347198\n",
      "[Step 22347] Loss: 9.45e+07 -1.335267424583435 0.07857119292020798\n",
      "[Step 22348] Loss: 9.47e+07 -1.3352667093276978 0.07857532054185867\n",
      "[Step 22349] Loss: 9.39e+07 -1.3352268934249878 0.07858852297067642\n",
      "[Step 22350] Loss: 9.54e+07 -1.3355244398117065 0.07855468988418579\n",
      "[Step 22351] Loss: 9.43e+07 -1.335758090019226 0.0785241574048996\n",
      "[Step 22352] Loss: 9.37e+07 -1.3359819650650024 0.0785159096121788\n",
      "[Step 22353] Loss: 9.33e+07 -1.336140751838684 0.07850105315446854\n",
      "[Step 22354] Loss: 9.38e+07 -1.3362675905227661 0.07846392691135406\n",
      "[Step 22355] Loss: 9.44e+07 -1.3363959789276123 0.07845732569694519\n",
      "[Step 22356] Loss: 9.42e+07 -1.336492657661438 0.07843586802482605\n",
      "[Step 22357] Loss: 9.40e+07 -1.336654543876648 0.07842762023210526\n",
      "[Step 22358] Loss: 9.41e+07 -1.3368009328842163 0.07842101901769638\n",
      "[Step 22359] Loss: 9.43e+07 -1.337073802947998 0.07839874178171158\n",
      "[Step 22360] Loss: 9.39e+07 -1.3373339176177979 0.07838801294565201\n",
      "[Step 22361] Loss: 9.41e+07 -1.337629795074463 0.07836160808801651\n",
      "[Step 22362] Loss: 9.42e+07 -1.3377306461334229 0.0783434510231018\n",
      "[Step 22363] Loss: 9.39e+07 -1.3378206491470337 0.07832364737987518\n",
      "[Step 22364] Loss: 9.54e+07 -1.3380826711654663 0.07829806953668594\n",
      "[Step 22365] Loss: 9.48e+07 -1.3381807804107666 0.07830385118722916\n",
      "[Step 22366] Loss: 9.38e+07 -1.3382339477539062 0.07829312235116959\n",
      "[Step 22367] Loss: 9.49e+07 -1.338209629058838 0.07831292599439621\n",
      "[Step 22368] Loss: 9.39e+07 -1.3381171226501465 0.07833767682313919\n",
      "[Step 22369] Loss: 9.40e+07 -1.3380483388900757 0.07835665345191956\n",
      "[Step 22370] Loss: 9.45e+07 -1.3379043340682983 0.07837068289518356\n",
      "[Step 22371] Loss: 9.49e+07 -1.3378888368606567 0.07838058471679688\n",
      "[Step 22372] Loss: 9.41e+07 -1.3378740549087524 0.07837893813848495\n",
      "[Step 22373] Loss: 9.44e+07 -1.3379085063934326 0.07837068289518356\n",
      "[Step 22374] Loss: 9.49e+07 -1.338126540184021 0.0783698558807373\n",
      "[Step 22375] Loss: 9.38e+07 -1.3383065462112427 0.07835913449525833\n",
      "[Step 22376] Loss: 9.36e+07 -1.3384937047958374 0.07833767682313919\n",
      "[Step 22377] Loss: 9.39e+07 -1.3386754989624023 0.07832282781600952\n",
      "[Step 22378] Loss: 9.46e+07 -1.3387396335601807 0.07830879837274551\n",
      "[Step 22379] Loss: 9.46e+07 -1.3389440774917603 0.07828982174396515\n",
      "[Step 22380] Loss: 9.55e+07 -1.3391051292419434 0.07827001810073853\n",
      "[Step 22381] Loss: 9.51e+07 -1.3394935131072998 0.07823535799980164\n",
      "[Step 22382] Loss: 9.44e+07 -1.339783787727356 0.07819905877113342\n",
      "[Step 22383] Loss: 9.43e+07 -1.3399733304977417 0.07819987833499908\n",
      "[Step 22384] Loss: 9.41e+07 -1.3401153087615967 0.0781792551279068\n",
      "[Step 22385] Loss: 9.40e+07 -1.3400593996047974 0.0781833752989769\n",
      "[Step 22386] Loss: 9.47e+07 -1.3399790525436401 0.07821143418550491\n",
      "[Step 22387] Loss: 9.47e+07 -1.3398196697235107 0.07821803539991379\n",
      "[Step 22388] Loss: 9.45e+07 -1.3398711681365967 0.07819410413503647\n",
      "[Step 22389] Loss: 9.37e+07 -1.3398551940917969 0.07821803539991379\n",
      "[Step 22390] Loss: 9.39e+07 -1.3398635387420654 0.07820317894220352\n",
      "[Step 22391] Loss: 9.35e+07 -1.3398091793060303 0.07819575816392899\n",
      "[Step 22392] Loss: 9.46e+07 -1.3396050930023193 0.07820235937833786\n",
      "[Step 22393] Loss: 9.41e+07 -1.33942711353302 0.07819163054227829\n",
      "[Step 22394] Loss: 9.41e+07 -1.339233636856079 0.07821060717105865\n",
      "[Step 22395] Loss: 9.43e+07 -1.3390450477600098 0.07820896059274673\n",
      "[Step 22396] Loss: 9.47e+07 -1.3389188051223755 0.07820813357830048\n",
      "[Step 22397] Loss: 9.44e+07 -1.3388715982437134 0.07821803539991379\n",
      "[Step 22398] Loss: 9.46e+07 -1.338905930519104 0.07821968197822571\n",
      "[Step 22399] Loss: 9.40e+07 -1.3389731645584106 0.07819905877113342\n",
      "[Step 22400] Loss: 9.40e+07 -1.3390508890151978 0.0781833752989769\n",
      "[Step 22401] Loss: 9.44e+07 -1.3391531705856323 0.07817595452070236\n",
      "[Step 22402] Loss: 9.43e+07 -1.339284896850586 0.07816769927740097\n",
      "[Step 22403] Loss: 9.43e+07 -1.3394625186920166 0.07814789563417435\n",
      "[Step 22404] Loss: 9.45e+07 -1.3397576808929443 0.07810251414775848\n",
      "[Step 22405] Loss: 9.38e+07 -1.339937686920166 0.07806950807571411\n",
      "[Step 22406] Loss: 9.46e+07 -1.340258002281189 0.07804475724697113\n",
      "[Step 22407] Loss: 9.40e+07 -1.3405585289001465 0.07803155481815338\n",
      "[Step 22408] Loss: 9.44e+07 -1.3407779932022095 0.07799442112445831\n",
      "[Step 22409] Loss: 9.38e+07 -1.3409357070922852 0.07798617333173752\n",
      "[Step 22410] Loss: 9.49e+07 -1.3411996364593506 0.07796718925237656\n",
      "[Step 22411] Loss: 9.46e+07 -1.3414452075958252 0.0779399648308754\n",
      "[Step 22412] Loss: 9.45e+07 -1.3415712118148804 0.07791437953710556\n",
      "[Step 22413] Loss: 9.45e+07 -1.3416093587875366 0.07791603356599808\n",
      "[Step 22414] Loss: 9.42e+07 -1.34163236618042 0.07791273295879364\n",
      "[Step 22415] Loss: 9.43e+07 -1.341725468635559 0.07790695875883102\n",
      "[Step 22416] Loss: 9.54e+07 -1.3419631719589233 0.0778871551156044\n",
      "[Step 22417] Loss: 9.47e+07 -1.3423365354537964 0.07785002142190933\n",
      "[Step 22418] Loss: 9.45e+07 -1.3425748348236084 0.07783269137144089\n",
      "[Step 22419] Loss: 9.41e+07 -1.3428174257278442 0.07782857120037079\n",
      "[Step 22420] Loss: 9.39e+07 -1.3430293798446655 0.0778120681643486\n",
      "[Step 22421] Loss: 9.36e+07 -1.3431965112686157 0.07780546694993973\n",
      "[Step 22422] Loss: 9.42e+07 -1.3433386087417603 0.07779556512832642\n",
      "[Step 22423] Loss: 9.37e+07 -1.343502402305603 0.07778730988502502\n",
      "[Step 22424] Loss: 9.41e+07 -1.3437062501907349 0.07778400927782059\n",
      "[Step 22425] Loss: 9.45e+07 -1.3438987731933594 0.07775595784187317\n",
      "[Step 22426] Loss: 9.39e+07 -1.3440898656845093 0.07771387696266174\n",
      "[Step 22427] Loss: 9.40e+07 -1.3441067934036255 0.07772789895534515\n",
      "[Step 22428] Loss: 9.40e+07 -1.344168782234192 0.07771717756986618\n",
      "[Step 22429] Loss: 9.45e+07 -1.3441497087478638 0.07772377878427505\n",
      "[Step 22430] Loss: 9.55e+07 -1.3443597555160522 0.077700674533844\n",
      "[Step 22431] Loss: 9.46e+07 -1.3446290493011475 0.07767509669065475\n",
      "[Step 22432] Loss: 9.42e+07 -1.3448059558868408 0.07766931504011154\n",
      "[Step 22433] Loss: 9.41e+07 -1.3448445796966553 0.07765281200408936\n",
      "[Step 22434] Loss: 9.63e+07 -1.3452129364013672 0.07762063294649124\n",
      "[Step 22435] Loss: 9.43e+07 -1.3454731702804565 0.0775991827249527\n",
      "[Step 22436] Loss: 9.41e+07 -1.3456672430038452 0.07758598029613495\n",
      "[Step 22437] Loss: 9.48e+07 -1.3458855152130127 0.07754801958799362\n",
      "[Step 22438] Loss: 9.48e+07 -1.3461799621582031 0.07753317058086395\n",
      "[Step 22439] Loss: 9.44e+07 -1.3463623523712158 0.07751089334487915\n",
      "[Step 22440] Loss: 9.48e+07 -1.3465684652328491 0.07747623324394226\n",
      "[Step 22441] Loss: 9.41e+07 -1.3467926979064941 0.07744735479354858\n",
      "[Step 22442] Loss: 9.35e+07 -1.3469581604003906 0.07741517573595047\n",
      "[Step 22443] Loss: 9.44e+07 -1.347048282623291 0.07740114629268646\n",
      "[Step 22444] Loss: 9.46e+07 -1.3470706939697266 0.07740114629268646\n",
      "[Step 22445] Loss: 9.47e+07 -1.3472391366958618 0.07738959789276123\n",
      "[Step 22446] Loss: 9.44e+07 -1.3474013805389404 0.07739784568548203\n",
      "[Step 22447] Loss: 9.50e+07 -1.3473976850509644 0.07738794386386871\n",
      "[Step 22448] Loss: 9.48e+07 -1.3472580909729004 0.07738134264945984\n",
      "[Step 22449] Loss: 9.40e+07 -1.3471115827560425 0.0773862972855568\n",
      "[Step 22450] Loss: 9.37e+07 -1.3469041585922241 0.07739784568548203\n",
      "[Step 22451] Loss: 9.46e+07 -1.3467390537261963 0.07740280032157898\n",
      "[Step 22452] Loss: 9.48e+07 -1.3465111255645752 0.0774267241358757\n",
      "[Step 22453] Loss: 9.43e+07 -1.346351981163025 0.0774349793791771\n",
      "[Step 22454] Loss: 9.52e+07 -1.3460979461669922 0.07743910700082779\n",
      "[Step 22455] Loss: 9.44e+07 -1.3459053039550781 0.07745230942964554\n",
      "[Step 22456] Loss: 9.47e+07 -1.3457958698272705 0.07747871428728104\n",
      "[Step 22457] Loss: 9.51e+07 -1.3458524942398071 0.07745891064405441\n",
      "[Step 22458] Loss: 9.37e+07 -1.3458517789840698 0.07745642960071564\n",
      "[Step 22459] Loss: 9.46e+07 -1.3458127975463867 0.07743992656469345\n",
      "[Step 22460] Loss: 9.46e+07 -1.3457059860229492 0.07744075357913971\n",
      "[Step 22461] Loss: 9.46e+07 -1.345511794090271 0.07746138423681259\n",
      "[Step 22462] Loss: 9.41e+07 -1.3454008102416992 0.0774795338511467\n",
      "[Step 22463] Loss: 9.43e+07 -1.345328688621521 0.07750923931598663\n",
      "[Step 22464] Loss: 9.34e+07 -1.3452357053756714 0.07752491533756256\n",
      "[Step 22465] Loss: 9.43e+07 -1.345194935798645 0.077542245388031\n",
      "[Step 22466] Loss: 9.41e+07 -1.345117211341858 0.07756287604570389\n",
      "[Step 22467] Loss: 9.42e+07 -1.3450279235839844 0.07756204903125763\n",
      "[Step 22468] Loss: 9.39e+07 -1.3450926542282104 0.07755874842405319\n",
      "[Step 22469] Loss: 9.38e+07 -1.3451368808746338 0.07755792140960693\n",
      "[Step 22470] Loss: 9.54e+07 -1.344971776008606 0.07755792140960693\n",
      "[Step 22471] Loss: 9.48e+07 -1.3447797298431396 0.0775991827249527\n",
      "[Step 22472] Loss: 9.51e+07 -1.3447242975234985 0.07758350670337677\n",
      "[Step 22473] Loss: 9.36e+07 -1.3445813655853271 0.077595055103302\n",
      "[Step 22474] Loss: 9.44e+07 -1.3443595170974731 0.07763466238975525\n",
      "[Step 22475] Loss: 9.38e+07 -1.3441818952560425 0.07766024023294449\n",
      "[Step 22476] Loss: 9.41e+07 -1.3440954685211182 0.07767839729785919\n",
      "[Step 22477] Loss: 9.44e+07 -1.344192385673523 0.07767096906900406\n",
      "[Step 22478] Loss: 9.47e+07 -1.344361424446106 0.0776742696762085\n",
      "[Step 22479] Loss: 9.32e+07 -1.344504714012146 0.07766106724739075\n",
      "[Step 22480] Loss: 9.44e+07 -1.34468674659729 0.07763548940420151\n",
      "[Step 22481] Loss: 9.45e+07 -1.3449195623397827 0.07761815935373306\n",
      "[Step 22482] Loss: 9.56e+07 -1.3452379703521729 0.07756122201681137\n",
      "[Step 22483] Loss: 9.41e+07 -1.345605731010437 0.0775199681520462\n",
      "[Step 22484] Loss: 9.43e+07 -1.3460395336151123 0.07748531550168991\n",
      "[Step 22485] Loss: 9.37e+07 -1.3463906049728394 0.0774490088224411\n",
      "[Step 22486] Loss: 9.38e+07 -1.346709132194519 0.07741847634315491\n",
      "[Step 22487] Loss: 9.37e+07 -1.3469693660736084 0.07740610092878342\n",
      "[Step 22488] Loss: 9.44e+07 -1.347152590751648 0.07740197330713272\n",
      "[Step 22489] Loss: 9.42e+07 -1.3472957611083984 0.0773821696639061\n",
      "[Step 22490] Loss: 9.43e+07 -1.347353458404541 0.07738464325666428\n",
      "[Step 22491] Loss: 9.45e+07 -1.3472933769226074 0.07736814022064209\n",
      "[Step 22492] Loss: 9.52e+07 -1.3471027612686157 0.07737639546394348\n",
      "[Step 22493] Loss: 9.47e+07 -1.3468785285949707 0.07739454507827759\n",
      "[Step 22494] Loss: 9.44e+07 -1.3466812372207642 0.07741847634315491\n",
      "[Step 22495] Loss: 9.48e+07 -1.3463724851608276 0.0774490088224411\n",
      "[Step 22496] Loss: 9.39e+07 -1.3460829257965088 0.07747045904397964\n",
      "[Step 22497] Loss: 9.52e+07 -1.3457579612731934 0.07748448848724365\n",
      "[Step 22498] Loss: 9.47e+07 -1.3454495668411255 0.07750099152326584\n",
      "[Step 22499] Loss: 9.41e+07 -1.345075249671936 0.07751006633043289\n",
      "[Step 22500] Loss: 9.43e+07 -1.344804286956787 0.0775240957736969\n",
      "[Step 22501] Loss: 9.42e+07 -1.3444812297821045 0.07754141837358475\n",
      "[Step 22502] Loss: 9.39e+07 -1.3441338539123535 0.07754554599523544\n",
      "[Step 22503] Loss: 9.60e+07 -1.3440899848937988 0.07754967361688614\n",
      "[Step 22504] Loss: 9.42e+07 -1.3440293073654175 0.0775463730096817\n",
      "[Step 22505] Loss: 9.41e+07 -1.3439832925796509 0.07752656936645508\n",
      "[Step 22506] Loss: 9.41e+07 -1.3439459800720215 0.0775323435664177\n",
      "[Step 22507] Loss: 9.38e+07 -1.3439064025878906 0.07753399759531021\n",
      "[Step 22508] Loss: 9.47e+07 -1.3439819812774658 0.07752161473035812\n",
      "[Step 22509] Loss: 9.39e+07 -1.3440284729003906 0.07752244174480438\n",
      "[Step 22510] Loss: 9.44e+07 -1.3440831899642944 0.07750263810157776\n",
      "[Step 22511] Loss: 9.38e+07 -1.3441227674484253 0.07749933749437332\n",
      "[Step 22512] Loss: 9.44e+07 -1.3442637920379639 0.07746798545122147\n",
      "[Step 22513] Loss: 9.39e+07 -1.3444682359695435 0.07744570821523666\n",
      "[Step 22514] Loss: 9.42e+07 -1.3446054458618164 0.07743250578641891\n",
      "[Step 22515] Loss: 9.63e+07 -1.3450803756713867 0.07737556844949722\n",
      "[Step 22516] Loss: 9.45e+07 -1.3453903198242188 0.07733596116304398\n",
      "[Step 22517] Loss: 9.38e+07 -1.345643162727356 0.07730872929096222\n",
      "[Step 22518] Loss: 9.40e+07 -1.3459136486053467 0.07728975266218185\n",
      "[Step 22519] Loss: 9.39e+07 -1.3461543321609497 0.07726912945508957\n",
      "[Step 22520] Loss: 9.39e+07 -1.3464237451553345 0.07725014537572861\n",
      "[Step 22521] Loss: 9.42e+07 -1.3466399908065796 0.07723034173250198\n",
      "[Step 22522] Loss: 9.52e+07 -1.3469760417938232 0.07720476388931274\n",
      "[Step 22523] Loss: 9.40e+07 -1.3472704887390137 0.07715938240289688\n",
      "[Step 22524] Loss: 9.45e+07 -1.3474947214126587 0.07714040577411652\n",
      "[Step 22525] Loss: 9.43e+07 -1.3476645946502686 0.07710657268762589\n",
      "[Step 22526] Loss: 9.43e+07 -1.3477256298065186 0.07710657268762589\n",
      "[Step 22527] Loss: 9.59e+07 -1.3476396799087524 0.07711812853813171\n",
      "[Step 22528] Loss: 9.44e+07 -1.3475357294082642 0.07713297754526138\n",
      "[Step 22529] Loss: 9.39e+07 -1.3474177122116089 0.07716763764619827\n",
      "[Step 22530] Loss: 9.48e+07 -1.3472613096237183 0.07716845721006393\n",
      "[Step 22531] Loss: 9.39e+07 -1.3470903635025024 0.07718165963888168\n",
      "[Step 22532] Loss: 9.43e+07 -1.3469268083572388 0.0772014632821083\n",
      "[Step 22533] Loss: 9.47e+07 -1.3469544649124146 0.07719816267490387\n",
      "[Step 22534] Loss: 9.51e+07 -1.3471163511276245 0.0771874338388443\n",
      "[Step 22535] Loss: 9.48e+07 -1.3471248149871826 0.07719073444604874\n",
      "[Step 22536] Loss: 9.43e+07 -1.3470548391342163 0.07720229029655457\n",
      "[Step 22537] Loss: 9.40e+07 -1.3469467163085938 0.07720476388931274\n",
      "[Step 22538] Loss: 9.44e+07 -1.3467520475387573 0.07723034173250198\n",
      "[Step 22539] Loss: 9.42e+07 -1.346554160118103 0.07723942399024963\n",
      "[Step 22540] Loss: 9.41e+07 -1.346401333808899 0.07725344598293304\n",
      "[Step 22541] Loss: 9.51e+07 -1.3463823795318604 0.07727160304784775\n",
      "[Step 22542] Loss: 9.57e+07 -1.3466373682022095 0.07725179940462112\n",
      "[Step 22543] Loss: 9.42e+07 -1.3469187021255493 0.07722539454698563\n",
      "[Step 22544] Loss: 9.47e+07 -1.3470780849456787 0.07722292095422745\n",
      "[Step 22545] Loss: 9.40e+07 -1.3473018407821655 0.07722456753253937\n",
      "[Step 22546] Loss: 9.38e+07 -1.3475120067596436 0.07722126692533493\n",
      "[Step 22547] Loss: 9.48e+07 -1.3475910425186157 0.07721053808927536\n",
      "[Step 22548] Loss: 9.50e+07 -1.3476577997207642 0.0772278681397438\n",
      "[Step 22549] Loss: 9.39e+07 -1.347716212272644 0.0772402435541153\n",
      "[Step 22550] Loss: 9.40e+07 -1.3477373123168945 0.07725179940462112\n",
      "[Step 22551] Loss: 9.50e+07 -1.3476669788360596 0.0772666484117508\n",
      "[Step 22552] Loss: 9.43e+07 -1.3476747274398804 0.07727490365505219\n",
      "[Step 22553] Loss: 9.41e+07 -1.347654104232788 0.07726912945508957\n",
      "[Step 22554] Loss: 9.42e+07 -1.3475397825241089 0.07730378210544586\n",
      "[Step 22555] Loss: 9.51e+07 -1.3475227355957031 0.0773070827126503\n",
      "[Step 22556] Loss: 9.45e+07 -1.3474363088607788 0.07731945812702179\n",
      "[Step 22557] Loss: 9.44e+07 -1.347511887550354 0.07730955630540848\n",
      "[Step 22558] Loss: 9.39e+07 -1.347621202468872 0.077311210334301\n",
      "[Step 22559] Loss: 9.40e+07 -1.34768545627594 0.07730955630540848\n",
      "[Step 22560] Loss: 9.40e+07 -1.3477699756622314 0.07729635387659073\n",
      "[Step 22561] Loss: 9.51e+07 -1.3476978540420532 0.07731451094150543\n",
      "[Step 22562] Loss: 9.49e+07 -1.3475626707077026 0.07731781154870987\n",
      "[Step 22563] Loss: 9.37e+07 -1.3474808931350708 0.0773293599486351\n",
      "[Step 22564] Loss: 9.40e+07 -1.3474047183990479 0.07733513414859772\n",
      "[Step 22565] Loss: 9.37e+07 -1.3473111391067505 0.07734586298465729\n",
      "[Step 22566] Loss: 9.42e+07 -1.3470569849014282 0.07737226784229279\n",
      "[Step 22567] Loss: 9.33e+07 -1.3467766046524048 0.07739371806383133\n",
      "[Step 22568] Loss: 9.46e+07 -1.346535563468933 0.07742177695035934\n",
      "[Step 22569] Loss: 9.40e+07 -1.3463472127914429 0.07743167877197266\n",
      "[Step 22570] Loss: 9.53e+07 -1.346041202545166 0.07744158059358597\n",
      "[Step 22571] Loss: 9.43e+07 -1.3456871509552002 0.07746798545122147\n",
      "[Step 22572] Loss: 9.43e+07 -1.3454476594924927 0.0774754136800766\n",
      "[Step 22573] Loss: 9.35e+07 -1.3452032804489136 0.07749026268720627\n",
      "[Step 22574] Loss: 9.45e+07 -1.3449903726577759 0.07748860865831375\n",
      "[Step 22575] Loss: 9.45e+07 -1.3447116613388062 0.07749439030885696\n",
      "[Step 22576] Loss: 9.45e+07 -1.3445132970809937 0.07750511169433594\n",
      "[Step 22577] Loss: 9.38e+07 -1.344318151473999 0.0775059387087822\n",
      "[Step 22578] Loss: 9.39e+07 -1.3441380262374878 0.07750676572322845\n",
      "[Step 22579] Loss: 9.57e+07 -1.3442349433898926 0.07749686390161514\n",
      "[Step 22580] Loss: 9.42e+07 -1.3442811965942383 0.0774836614727974\n",
      "[Step 22581] Loss: 9.51e+07 -1.3441606760025024 0.07748778909444809\n",
      "[Step 22582] Loss: 9.40e+07 -1.344010353088379 0.07751006633043289\n",
      "[Step 22583] Loss: 9.53e+07 -1.344071865081787 0.07751006633043289\n",
      "[Step 22584] Loss: 9.41e+07 -1.3441076278686523 0.07751171290874481\n",
      "[Step 22585] Loss: 9.37e+07 -1.3440978527069092 0.07749686390161514\n",
      "[Step 22586] Loss: 9.41e+07 -1.3440520763397217 0.07750099152326584\n",
      "[Step 22587] Loss: 9.42e+07 -1.343916893005371 0.07751089334487915\n",
      "[Step 22588] Loss: 9.37e+07 -1.3437917232513428 0.07752656936645508\n",
      "[Step 22589] Loss: 9.40e+07 -1.3437268733978271 0.07753564417362213\n",
      "[Step 22590] Loss: 9.45e+07 -1.3437000513076782 0.07752904295921326\n",
      "[Step 22591] Loss: 9.41e+07 -1.3436460494995117 0.07753151655197144\n",
      "[Step 22592] Loss: 9.50e+07 -1.3435364961624146 0.0775323435664177\n",
      "[Step 22593] Loss: 9.45e+07 -1.3434559106826782 0.07752739638090134\n",
      "[Step 22594] Loss: 9.47e+07 -1.3432838916778564 0.07753647118806839\n",
      "[Step 22595] Loss: 9.47e+07 -1.3430403470993042 0.07755710184574127\n",
      "[Step 22596] Loss: 9.38e+07 -1.3428038358688354 0.07757112383842468\n",
      "[Step 22597] Loss: 9.46e+07 -1.3426182270050049 0.07758350670337677\n",
      "[Step 22598] Loss: 9.39e+07 -1.3423891067504883 0.07759752869606018\n",
      "[Step 22599] Loss: 9.39e+07 -1.3421434164047241 0.07763053476810455\n",
      "[Step 22600] Loss: 9.35e+07 -1.341834306716919 0.07764209061861038\n",
      "[Step 22601] Loss: 9.48e+07 -1.341659665107727 0.07766354084014893\n",
      "[Step 22602] Loss: 9.39e+07 -1.3415160179138184 0.07767261564731598\n",
      "[Step 22603] Loss: 9.36e+07 -1.3414124250411987 0.07767509669065475\n",
      "[Step 22604] Loss: 9.39e+07 -1.3413233757019043 0.07766684144735336\n",
      "[Step 22605] Loss: 9.41e+07 -1.3412264585494995 0.07768169790506363\n",
      "[Step 22606] Loss: 9.43e+07 -1.3410784006118774 0.07770644873380661\n",
      "[Step 22607] Loss: 9.48e+07 -1.3408160209655762 0.0777493566274643\n",
      "[Step 22608] Loss: 9.34e+07 -1.3405400514602661 0.07778318971395493\n",
      "[Step 22609] Loss: 9.52e+07 -1.3405920267105103 0.07779061049222946\n",
      "[Step 22610] Loss: 9.49e+07 -1.3405779600143433 0.07781041413545609\n",
      "[Step 22611] Loss: 9.42e+07 -1.3405730724334717 0.07783187180757523\n",
      "[Step 22612] Loss: 9.51e+07 -1.3404872417449951 0.07783681899309158\n",
      "[Step 22613] Loss: 9.46e+07 -1.3404786586761475 0.07783187180757523\n",
      "[Step 22614] Loss: 9.36e+07 -1.340389370918274 0.0778384730219841\n",
      "[Step 22615] Loss: 9.41e+07 -1.3403477668762207 0.07783351838588715\n",
      "[Step 22616] Loss: 9.44e+07 -1.3404185771942139 0.07784011960029602\n",
      "[Step 22617] Loss: 9.49e+07 -1.3405940532684326 0.07782857120037079\n",
      "[Step 22618] Loss: 9.59e+07 -1.3409096002578735 0.07779886573553085\n",
      "[Step 22619] Loss: 9.48e+07 -1.341090440750122 0.07776833325624466\n",
      "[Step 22620] Loss: 9.49e+07 -1.3411641120910645 0.07775183022022247\n",
      "[Step 22621] Loss: 9.47e+07 -1.3411885499954224 0.07774770259857178\n",
      "[Step 22622] Loss: 9.44e+07 -1.3410942554473877 0.07775513082742691\n",
      "[Step 22623] Loss: 9.41e+07 -1.340991497039795 0.07776008546352386\n",
      "[Step 22624] Loss: 9.40e+07 -1.3408737182617188 0.07777740806341171\n",
      "[Step 22625] Loss: 9.49e+07 -1.3409360647201538 0.07776668667793274\n",
      "[Step 22626] Loss: 9.36e+07 -1.3409883975982666 0.07775348424911499\n",
      "[Step 22627] Loss: 9.40e+07 -1.3409717082977295 0.07773945480585098\n",
      "[Step 22628] Loss: 9.40e+07 -1.3409061431884766 0.07774275541305542\n",
      "[Step 22629] Loss: 9.42e+07 -1.3408793210983276 0.07773945480585098\n",
      "[Step 22630] Loss: 9.43e+07 -1.34096360206604 0.0777411013841629\n",
      "[Step 22631] Loss: 9.40e+07 -1.3410913944244385 0.07772625237703323\n",
      "[Step 22632] Loss: 9.65e+07 -1.3416240215301514 0.07768911868333817\n",
      "[Step 22633] Loss: 9.44e+07 -1.3420836925506592 0.07763713598251343\n",
      "[Step 22634] Loss: 9.44e+07 -1.34249746799469 0.077595055103302\n",
      "[Step 22635] Loss: 9.54e+07 -1.343139886856079 0.0775463730096817\n",
      "[Step 22636] Loss: 9.50e+07 -1.3436139822006226 0.07751006633043289\n",
      "[Step 22637] Loss: 9.55e+07 -1.344316005706787 0.07745973020792007\n",
      "[Step 22638] Loss: 9.48e+07 -1.3448790311813354 0.07739537209272385\n",
      "[Step 22639] Loss: 9.52e+07 -1.3455450534820557 0.07735906541347504\n",
      "[Step 22640] Loss: 9.34e+07 -1.3460795879364014 0.07730625569820404\n",
      "[Step 22641] Loss: 9.43e+07 -1.3467003107070923 0.07724437117576599\n",
      "[Step 22642] Loss: 9.41e+07 -1.3472344875335693 0.07719568908214569\n",
      "[Step 22643] Loss: 9.40e+07 -1.3477137088775635 0.07714453339576721\n",
      "[Step 22644] Loss: 9.39e+07 -1.348135232925415 0.07710574567317963\n",
      "[Step 22645] Loss: 9.52e+07 -1.3486905097961426 0.07704881578683853\n",
      "[Step 22646] Loss: 9.52e+07 -1.3490947484970093 0.07700755447149277\n",
      "[Step 22647] Loss: 9.35e+07 -1.3494431972503662 0.07695969939231873\n",
      "[Step 22648] Loss: 9.44e+07 -1.34967839717865 0.07692091912031174\n",
      "[Step 22649] Loss: 9.52e+07 -1.3501170873641968 0.07687058299779892\n",
      "[Step 22650] Loss: 9.41e+07 -1.3504836559295654 0.07683757692575455\n",
      "[Step 22651] Loss: 9.39e+07 -1.3507978916168213 0.07681695371866226\n",
      "[Step 22652] Loss: 9.41e+07 -1.3509926795959473 0.07681035250425339\n",
      "[Step 22653] Loss: 9.46e+07 -1.3510761260986328 0.0767979696393013\n",
      "[Step 22654] Loss: 9.50e+07 -1.351235270500183 0.07679549604654312\n",
      "[Step 22655] Loss: 9.44e+07 -1.3513964414596558 0.0767897218465805\n",
      "[Step 22656] Loss: 9.54e+07 -1.3517709970474243 0.07676826417446136\n",
      "[Step 22657] Loss: 9.38e+07 -1.3521316051483154 0.07674598693847656\n",
      "[Step 22658] Loss: 9.43e+07 -1.3523824214935303 0.07672783732414246\n",
      "[Step 22659] Loss: 9.40e+07 -1.352575421333313 0.0767047330737114\n",
      "[Step 22660] Loss: 9.39e+07 -1.3526573181152344 0.07668657600879669\n",
      "[Step 22661] Loss: 9.40e+07 -1.352779507637024 0.07666512578725815\n",
      "[Step 22662] Loss: 9.53e+07 -1.3530066013336182 0.0766172707080841\n",
      "[Step 22663] Loss: 9.50e+07 -1.3530936241149902 0.07659664005041122\n",
      "[Step 22664] Loss: 9.39e+07 -1.3532122373580933 0.07658178359270096\n",
      "[Step 22665] Loss: 9.43e+07 -1.3532859086990356 0.07654630392789841\n",
      "[Step 22666] Loss: 9.39e+07 -1.3533756732940674 0.0765364021062851\n",
      "[Step 22667] Loss: 9.45e+07 -1.353556513786316 0.07652732729911804\n",
      "[Step 22668] Loss: 9.42e+07 -1.3538447618484497 0.0764753445982933\n",
      "[Step 22669] Loss: 9.46e+07 -1.354069471359253 0.07648111879825592\n",
      "[Step 22670] Loss: 9.51e+07 -1.3544847965240479 0.07644151151180267\n",
      "[Step 22671] Loss: 9.45e+07 -1.3547773361206055 0.07642500847578049\n",
      "[Step 22672] Loss: 9.47e+07 -1.355002760887146 0.07638788223266602\n",
      "[Step 22673] Loss: 9.49e+07 -1.3550856113433838 0.07637219876050949\n",
      "[Step 22674] Loss: 9.42e+07 -1.355163335800171 0.07634250074625015\n",
      "[Step 22675] Loss: 9.38e+07 -1.3551894426345825 0.07633424550294876\n",
      "[Step 22676] Loss: 9.46e+07 -1.3552525043487549 0.07631609588861465\n",
      "[Step 22677] Loss: 9.45e+07 -1.3553799390792847 0.07630949467420578\n",
      "[Step 22678] Loss: 9.50e+07 -1.3553764820098877 0.07631774246692657\n",
      "[Step 22679] Loss: 9.45e+07 -1.3553608655929565 0.07632187008857727\n",
      "[Step 22680] Loss: 9.50e+07 -1.3555113077163696 0.07629463821649551\n",
      "[Step 22681] Loss: 9.55e+07 -1.355529546737671 0.07630454003810883\n",
      "[Step 22682] Loss: 9.47e+07 -1.3556675910949707 0.07629051059484482\n",
      "[Step 22683] Loss: 9.44e+07 -1.3558214902877808 0.07626823335886002\n",
      "[Step 22684] Loss: 9.40e+07 -1.3558943271636963 0.07626823335886002\n",
      "[Step 22685] Loss: 9.49e+07 -1.3559365272521973 0.07625585794448853\n",
      "[Step 22686] Loss: 9.42e+07 -1.3560421466827393 0.07624100893735886\n",
      "[Step 22687] Loss: 9.44e+07 -1.3562427759170532 0.0762443095445633\n",
      "[Step 22688] Loss: 9.50e+07 -1.356563687324524 0.07622367888689041\n",
      "[Step 22689] Loss: 9.39e+07 -1.356823444366455 0.07619810104370117\n",
      "[Step 22690] Loss: 9.43e+07 -1.357115626335144 0.07617994397878647\n",
      "[Step 22691] Loss: 9.39e+07 -1.3573253154754639 0.07615931332111359\n",
      "[Step 22692] Loss: 9.52e+07 -1.3576995134353638 0.0761122852563858\n",
      "[Step 22693] Loss: 9.35e+07 -1.3580199480056763 0.07608505338430405\n",
      "[Step 22694] Loss: 9.42e+07 -1.3583528995513916 0.07605452090501785\n",
      "[Step 22695] Loss: 9.40e+07 -1.3586246967315674 0.076023168861866\n",
      "[Step 22696] Loss: 9.44e+07 -1.3589686155319214 0.07599593698978424\n",
      "[Step 22697] Loss: 9.34e+07 -1.3592160940170288 0.07599016278982162\n",
      "[Step 22698] Loss: 9.39e+07 -1.359494686126709 0.07595551013946533\n",
      "[Step 22699] Loss: 9.44e+07 -1.3598461151123047 0.07592415064573288\n",
      "[Step 22700] Loss: 9.44e+07 -1.3601582050323486 0.07589774578809738\n",
      "[Step 22701] Loss: 9.40e+07 -1.3604862689971924 0.07588042318820953\n",
      "[Step 22702] Loss: 9.47e+07 -1.3608670234680176 0.07583833485841751\n",
      "[Step 22703] Loss: 9.38e+07 -1.3611695766448975 0.07580945640802383\n",
      "[Step 22704] Loss: 9.42e+07 -1.3614439964294434 0.0757838785648346\n",
      "[Step 22705] Loss: 9.34e+07 -1.3616396188735962 0.07574757188558578\n",
      "[Step 22706] Loss: 9.54e+07 -1.362127423286438 0.07568898797035217\n",
      "[Step 22707] Loss: 9.42e+07 -1.3625649213790894 0.075647734105587\n",
      "[Step 22708] Loss: 9.39e+07 -1.3629841804504395 0.07559575140476227\n",
      "[Step 22709] Loss: 9.46e+07 -1.3633211851119995 0.07556191831827164\n",
      "[Step 22710] Loss: 9.46e+07 -1.363614797592163 0.07554624229669571\n",
      "[Step 22711] Loss: 9.49e+07 -1.364089846611023 0.07549343258142471\n",
      "[Step 22712] Loss: 9.41e+07 -1.3644427061080933 0.07545465230941772\n",
      "[Step 22713] Loss: 9.39e+07 -1.3647328615188599 0.07544639706611633\n",
      "[Step 22714] Loss: 9.51e+07 -1.3648462295532227 0.07543649524450302\n",
      "[Step 22715] Loss: 9.40e+07 -1.364950180053711 0.07540761679410934\n",
      "[Step 22716] Loss: 9.33e+07 -1.3649938106536865 0.07539276778697968\n",
      "[Step 22717] Loss: 9.42e+07 -1.3649965524673462 0.07537708431482315\n",
      "[Step 22718] Loss: 9.43e+07 -1.3650158643722534 0.0753680095076561\n",
      "[Step 22719] Loss: 9.37e+07 -1.3649861812591553 0.0753680095076561\n",
      "[Step 22720] Loss: 9.42e+07 -1.3649369478225708 0.07538781315088272\n",
      "[Step 22721] Loss: 9.45e+07 -1.3649598360061646 0.07537708431482315\n",
      "[Step 22722] Loss: 9.39e+07 -1.3649777173995972 0.07538781315088272\n",
      "[Step 22723] Loss: 9.49e+07 -1.3650343418121338 0.07537378370761871\n",
      "[Step 22724] Loss: 9.36e+07 -1.365111231803894 0.07536223530769348\n",
      "[Step 22725] Loss: 9.45e+07 -1.3654084205627441 0.0753333568572998\n",
      "[Step 22726] Loss: 9.49e+07 -1.3657569885253906 0.07531189918518066\n",
      "[Step 22727] Loss: 9.37e+07 -1.3660218715667725 0.07530035078525543\n",
      "[Step 22728] Loss: 9.48e+07 -1.366212010383606 0.07527229189872742\n",
      "[Step 22729] Loss: 9.43e+07 -1.3663406372070312 0.07527477294206619\n",
      "[Step 22730] Loss: 9.43e+07 -1.3664559125900269 0.07526404410600662\n",
      "[Step 22731] Loss: 9.40e+07 -1.366609811782837 0.0752219632267952\n",
      "[Step 22732] Loss: 9.47e+07 -1.36683189868927 0.07520793378353119\n",
      "[Step 22733] Loss: 9.42e+07 -1.366973638534546 0.07518978416919708\n",
      "[Step 22734] Loss: 9.42e+07 -1.3671635389328003 0.0751650258898735\n",
      "[Step 22735] Loss: 9.49e+07 -1.3675997257232666 0.0751287192106247\n",
      "[Step 22736] Loss: 9.62e+07 -1.3682790994644165 0.0750800371170044\n",
      "[Step 22737] Loss: 9.43e+07 -1.368873953819275 0.07501485198736191\n",
      "[Step 22738] Loss: 9.47e+07 -1.3692805767059326 0.07498431950807571\n",
      "[Step 22739] Loss: 9.39e+07 -1.3695626258850098 0.07496699690818787\n",
      "[Step 22740] Loss: 9.37e+07 -1.369788646697998 0.07493233680725098\n",
      "[Step 22741] Loss: 9.39e+07 -1.3699660301208496 0.07491418719291687\n",
      "[Step 22742] Loss: 9.43e+07 -1.3700827360153198 0.07490840554237366\n",
      "[Step 22743] Loss: 9.41e+07 -1.3701094388961792 0.07491336017847061\n",
      "[Step 22744] Loss: 9.37e+07 -1.3701634407043457 0.07491666078567505\n",
      "[Step 22745] Loss: 9.51e+07 -1.370031476020813 0.07492408901453018\n",
      "[Step 22746] Loss: 9.40e+07 -1.3699227571487427 0.07493316382169724\n",
      "[Step 22747] Loss: 9.42e+07 -1.369720458984375 0.07494059205055237\n",
      "[Step 22748] Loss: 9.39e+07 -1.3694969415664673 0.07496369630098343\n",
      "[Step 22749] Loss: 9.46e+07 -1.3692975044250488 0.07498019933700562\n",
      "[Step 22750] Loss: 9.43e+07 -1.3690509796142578 0.07500164955854416\n",
      "[Step 22751] Loss: 9.38e+07 -1.368905782699585 0.07501732558012009\n",
      "[Step 22752] Loss: 9.43e+07 -1.3688246011734009 0.07503878325223923\n",
      "[Step 22753] Loss: 9.37e+07 -1.3687772750854492 0.07502805441617966\n",
      "[Step 22754] Loss: 9.43e+07 -1.3687888383865356 0.07503465563058853\n",
      "[Step 22755] Loss: 9.45e+07 -1.3687331676483154 0.0750272274017334\n",
      "[Step 22756] Loss: 9.55e+07 -1.3685892820358276 0.0750189796090126\n",
      "[Step 22757] Loss: 9.48e+07 -1.3683607578277588 0.07504290342330933\n",
      "[Step 22758] Loss: 9.43e+07 -1.3680410385131836 0.07505610585212708\n",
      "[Step 22759] Loss: 9.41e+07 -1.3677117824554443 0.07508251070976257\n",
      "[Step 22760] Loss: 9.41e+07 -1.3674553632736206 0.07509984076023102\n",
      "[Step 22761] Loss: 9.44e+07 -1.3671444654464722 0.07511138916015625\n",
      "[Step 22762] Loss: 9.44e+07 -1.3669154644012451 0.07513119280338287\n",
      "[Step 22763] Loss: 9.46e+07 -1.3668402433395386 0.07515182346105576\n",
      "[Step 22764] Loss: 9.56e+07 -1.3670337200164795 0.07512294501066208\n",
      "[Step 22765] Loss: 9.42e+07 -1.367229700088501 0.07510149478912354\n",
      "[Step 22766] Loss: 9.44e+07 -1.3674981594085693 0.0750676617026329\n",
      "[Step 22767] Loss: 9.37e+07 -1.3677843809127808 0.07504703104496002\n",
      "[Step 22768] Loss: 9.41e+07 -1.368088722229004 0.07502145320177078\n",
      "[Step 22769] Loss: 9.47e+07 -1.3683297634124756 0.07498514652252197\n",
      "[Step 22770] Loss: 9.39e+07 -1.3686323165893555 0.07496451586484909\n",
      "[Step 22771] Loss: 9.39e+07 -1.3688414096832275 0.07496121525764465\n",
      "[Step 22772] Loss: 9.41e+07 -1.3690311908721924 0.07492738962173462\n",
      "[Step 22773] Loss: 9.36e+07 -1.3691216707229614 0.07493481040000916\n",
      "[Step 22774] Loss: 9.46e+07 -1.3692314624786377 0.07492408901453018\n",
      "[Step 22775] Loss: 9.49e+07 -1.3694368600845337 0.07491583377122879\n",
      "[Step 22776] Loss: 9.45e+07 -1.369734764099121 0.07491996139287949\n",
      "[Step 22777] Loss: 9.46e+07 -1.369925856590271 0.07491583377122879\n",
      "[Step 22778] Loss: 9.39e+07 -1.3700579404830933 0.07491005957126617\n",
      "[Step 22779] Loss: 9.39e+07 -1.3701386451721191 0.07488448172807693\n",
      "[Step 22780] Loss: 9.38e+07 -1.370182752609253 0.0748770534992218\n",
      "[Step 22781] Loss: 9.41e+07 -1.3701486587524414 0.07487952709197998\n",
      "[Step 22782] Loss: 9.47e+07 -1.370099425315857 0.07486550509929657\n",
      "[Step 22783] Loss: 9.39e+07 -1.3699696063995361 0.07487210631370544\n",
      "[Step 22784] Loss: 9.42e+07 -1.3698070049285889 0.07488860934972763\n",
      "[Step 22785] Loss: 9.41e+07 -1.3696093559265137 0.0749034583568573\n",
      "[Step 22786] Loss: 9.40e+07 -1.3694274425506592 0.074907585978508\n",
      "[Step 22787] Loss: 9.41e+07 -1.3692572116851807 0.07491336017847061\n",
      "[Step 22788] Loss: 9.43e+07 -1.3690980672836304 0.07491088658571243\n",
      "[Step 22789] Loss: 9.40e+07 -1.3689556121826172 0.07491666078567505\n",
      "[Step 22790] Loss: 9.45e+07 -1.3687591552734375 0.07493811100721359\n",
      "[Step 22791] Loss: 9.37e+07 -1.3685121536254883 0.07497359812259674\n",
      "[Step 22792] Loss: 9.33e+07 -1.3682990074157715 0.07498184591531754\n",
      "[Step 22793] Loss: 9.44e+07 -1.3679897785186768 0.07498431950807571\n",
      "[Step 22794] Loss: 9.41e+07 -1.3677245378494263 0.07500000298023224\n",
      "[Step 22795] Loss: 9.42e+07 -1.3674898147583008 0.07502640038728714\n",
      "[Step 22796] Loss: 9.41e+07 -1.3672434091567993 0.07504290342330933\n",
      "[Step 22797] Loss: 9.42e+07 -1.3670246601104736 0.07505693286657333\n",
      "[Step 22798] Loss: 9.38e+07 -1.366851806640625 0.07505198568105698\n",
      "[Step 22799] Loss: 9.40e+07 -1.3666341304779053 0.07506600767374039\n",
      "[Step 22800] Loss: 9.45e+07 -1.366301417350769 0.07508581131696701\n",
      "[Step 22801] Loss: 9.46e+07 -1.3660935163497925 0.07508663833141327\n",
      "[Step 22802] Loss: 9.49e+07 -1.365958571434021 0.07510974258184433\n",
      "[Step 22803] Loss: 9.41e+07 -1.3657240867614746 0.075124591588974\n",
      "[Step 22804] Loss: 9.46e+07 -1.365536093711853 0.07515347748994827\n",
      "[Step 22805] Loss: 9.42e+07 -1.3654048442840576 0.07515265047550201\n",
      "[Step 22806] Loss: 9.42e+07 -1.3653403520584106 0.07515429705381393\n",
      "[Step 22807] Loss: 9.40e+07 -1.3652410507202148 0.07515429705381393\n",
      "[Step 22808] Loss: 9.46e+07 -1.3651139736175537 0.07516667991876602\n",
      "[Step 22809] Loss: 9.35e+07 -1.364938735961914 0.07518648356199265\n",
      "[Step 22810] Loss: 9.44e+07 -1.3648314476013184 0.07518070191144943\n",
      "[Step 22811] Loss: 9.37e+07 -1.3647375106811523 0.07518400251865387\n",
      "[Step 22812] Loss: 9.37e+07 -1.3646156787872314 0.07521288096904755\n",
      "[Step 22813] Loss: 9.44e+07 -1.3644554615020752 0.07523103803396225\n",
      "[Step 22814] Loss: 9.50e+07 -1.3642910718917847 0.07524341344833374\n",
      "[Step 22815] Loss: 9.47e+07 -1.3642643690109253 0.0752483680844307\n",
      "[Step 22816] Loss: 9.42e+07 -1.3642054796218872 0.07526569068431854\n",
      "[Step 22817] Loss: 9.50e+07 -1.3640353679656982 0.07528302073478699\n",
      "[Step 22818] Loss: 9.49e+07 -1.3638849258422852 0.07528384774923325\n",
      "[Step 22819] Loss: 9.44e+07 -1.3636360168457031 0.07528797537088394\n",
      "[Step 22820] Loss: 9.44e+07 -1.363336205482483 0.07531355321407318\n",
      "[Step 22821] Loss: 9.40e+07 -1.3630845546722412 0.07534655928611755\n",
      "[Step 22822] Loss: 9.59e+07 -1.3631510734558105 0.07534903287887573\n",
      "[Step 22823] Loss: 9.46e+07 -1.3630748987197876 0.07535233348608017\n",
      "[Step 22824] Loss: 9.49e+07 -1.3631703853607178 0.07535810768604279\n",
      "[Step 22825] Loss: 9.45e+07 -1.3631243705749512 0.07536140829324722\n",
      "[Step 22826] Loss: 9.41e+07 -1.3630650043487549 0.07535067945718765\n",
      "[Step 22827] Loss: 9.40e+07 -1.3630057573318481 0.07534407824277878\n",
      "[Step 22828] Loss: 9.58e+07 -1.3632081747055054 0.0753333568572998\n",
      "[Step 22829] Loss: 9.42e+07 -1.3632941246032715 0.07532097399234772\n",
      "[Step 22830] Loss: 9.43e+07 -1.3634740114212036 0.07527889311313629\n",
      "[Step 22831] Loss: 9.43e+07 -1.3636471033096313 0.07526817172765732\n",
      "[Step 22832] Loss: 9.41e+07 -1.3638343811035156 0.07525578886270523\n",
      "[Step 22833] Loss: 9.49e+07 -1.3639241456985474 0.07524671405553818\n",
      "[Step 22834] Loss: 9.41e+07 -1.3639825582504272 0.07524258643388748\n",
      "[Step 22835] Loss: 9.41e+07 -1.36411452293396 0.07523186504840851\n",
      "[Step 22836] Loss: 9.47e+07 -1.3643893003463745 0.07520463317632675\n",
      "[Step 22837] Loss: 9.44e+07 -1.3646820783615112 0.07518565654754639\n",
      "[Step 22838] Loss: 9.39e+07 -1.3648436069488525 0.07515265047550201\n",
      "[Step 22839] Loss: 9.36e+07 -1.36490797996521 0.07513614743947983\n",
      "[Step 22840] Loss: 9.43e+07 -1.3649365901947021 0.07511138916015625\n",
      "[Step 22841] Loss: 9.41e+07 -1.3650199174880981 0.07510974258184433\n",
      "[Step 22842] Loss: 9.39e+07 -1.3651522397994995 0.07509076595306396\n",
      "[Step 22843] Loss: 9.47e+07 -1.365270733833313 0.07505940645933151\n",
      "[Step 22844] Loss: 9.46e+07 -1.3655303716659546 0.07504785805940628\n",
      "[Step 22845] Loss: 9.45e+07 -1.3657026290893555 0.07502228021621704\n",
      "[Step 22846] Loss: 9.52e+07 -1.365702509880066 0.07502228021621704\n",
      "[Step 22847] Loss: 9.48e+07 -1.3658298254013062 0.07501402497291565\n",
      "[Step 22848] Loss: 9.43e+07 -1.3659785985946655 0.07499010115861893\n",
      "[Step 22849] Loss: 9.44e+07 -1.366101861000061 0.07497524470090866\n",
      "[Step 22850] Loss: 9.52e+07 -1.366376280784607 0.07495131343603134\n",
      "[Step 22851] Loss: 9.42e+07 -1.3665297031402588 0.07494223862886429\n",
      "[Step 22852] Loss: 9.38e+07 -1.3666516542434692 0.07491996139287949\n",
      "[Step 22853] Loss: 9.39e+07 -1.3667203187942505 0.07491336017847061\n",
      "[Step 22854] Loss: 9.46e+07 -1.3667722940444946 0.07490923255681992\n",
      "[Step 22855] Loss: 9.51e+07 -1.3669856786727905 0.07488612830638885\n",
      "[Step 22856] Loss: 9.44e+07 -1.3671092987060547 0.07488200813531876\n",
      "[Step 22857] Loss: 9.45e+07 -1.3672336339950562 0.07486385107040405\n",
      "[Step 22858] Loss: 9.50e+07 -1.3672524690628052 0.07487045228481293\n",
      "[Step 22859] Loss: 9.37e+07 -1.367208480834961 0.07488282769918442\n",
      "[Step 22860] Loss: 9.38e+07 -1.367069959640503 0.0748811811208725\n",
      "[Step 22861] Loss: 9.44e+07 -1.3669054508209229 0.07490840554237366\n",
      "[Step 22862] Loss: 9.35e+07 -1.3666796684265137 0.07490840554237366\n",
      "[Step 22863] Loss: 9.57e+07 -1.366769790649414 0.0749034583568573\n",
      "[Step 22864] Loss: 9.58e+07 -1.367208480834961 0.0748770534992218\n",
      "[Step 22865] Loss: 9.52e+07 -1.3677061796188354 0.07483084499835968\n",
      "[Step 22866] Loss: 9.39e+07 -1.3681235313415527 0.07480939477682114\n",
      "[Step 22867] Loss: 9.41e+07 -1.3684372901916504 0.07479619234800339\n",
      "[Step 22868] Loss: 9.45e+07 -1.368854284286499 0.07476071268320084\n",
      "[Step 22869] Loss: 9.44e+07 -1.3692175149917603 0.07474420964717865\n",
      "[Step 22870] Loss: 9.45e+07 -1.3695365190505981 0.07472522556781769\n",
      "[Step 22871] Loss: 9.40e+07 -1.3698697090148926 0.07470212131738663\n",
      "[Step 22872] Loss: 9.43e+07 -1.3701860904693604 0.0746905729174614\n",
      "[Step 22873] Loss: 9.52e+07 -1.3706706762313843 0.07464849203824997\n",
      "[Step 22874] Loss: 9.42e+07 -1.3710473775863647 0.07462126016616821\n",
      "[Step 22875] Loss: 9.39e+07 -1.3714054822921753 0.07460641115903854\n",
      "[Step 22876] Loss: 9.38e+07 -1.3718217611312866 0.07455690205097198\n",
      "[Step 22877] Loss: 9.40e+07 -1.3721061944961548 0.07454617321491241\n",
      "[Step 22878] Loss: 9.39e+07 -1.3723703622817993 0.07453214377164841\n",
      "[Step 22879] Loss: 9.46e+07 -1.3727182149887085 0.07451482117176056\n",
      "[Step 22880] Loss: 9.43e+07 -1.3729732036590576 0.07449831813573837\n",
      "[Step 22881] Loss: 9.47e+07 -1.373342752456665 0.0744694396853447\n",
      "[Step 22882] Loss: 9.63e+07 -1.374031901359558 0.0744166299700737\n",
      "[Step 22883] Loss: 9.36e+07 -1.3747143745422363 0.07436299324035645\n",
      "[Step 22884] Loss: 9.41e+07 -1.375388264656067 0.07430853694677353\n",
      "[Step 22885] Loss: 9.42e+07 -1.3760054111480713 0.07425820082426071\n",
      "[Step 22886] Loss: 9.40e+07 -1.3764804601669312 0.07422932237386703\n",
      "[Step 22887] Loss: 9.45e+07 -1.376853346824646 0.07418806105852127\n",
      "[Step 22888] Loss: 9.52e+07 -1.3773658275604248 0.07414763420820236\n",
      "[Step 22889] Loss: 9.44e+07 -1.3777046203613281 0.07409729808568954\n",
      "[Step 22890] Loss: 9.41e+07 -1.3781235218048096 0.07407089322805405\n",
      "[Step 22891] Loss: 9.45e+07 -1.378665804862976 0.07403624057769775\n",
      "[Step 22892] Loss: 9.44e+07 -1.3791391849517822 0.07397352904081345\n",
      "[Step 22893] Loss: 9.47e+07 -1.3795809745788574 0.07394134998321533\n",
      "[Step 22894] Loss: 9.43e+07 -1.3800299167633057 0.0739075168967247\n",
      "[Step 22895] Loss: 9.40e+07 -1.3803960084915161 0.07387038320302963\n",
      "[Step 22896] Loss: 9.48e+07 -1.380761742591858 0.0738588348031044\n",
      "[Step 22897] Loss: 9.41e+07 -1.3811298608779907 0.07384563237428665\n",
      "[Step 22898] Loss: 9.37e+07 -1.3815089464187622 0.07379942387342453\n",
      "[Step 22899] Loss: 9.56e+07 -1.3816787004470825 0.07378952205181122\n",
      "[Step 22900] Loss: 9.43e+07 -1.3818445205688477 0.07378044724464417\n",
      "[Step 22901] Loss: 9.53e+07 -1.3818172216415405 0.07377879321575165\n",
      "[Step 22902] Loss: 9.43e+07 -1.3817778825759888 0.07378952205181122\n",
      "[Step 22903] Loss: 9.40e+07 -1.3817379474639893 0.07379117608070374\n",
      "[Step 22904] Loss: 9.44e+07 -1.3817384243011475 0.07379282265901566\n",
      "[Step 22905] Loss: 9.47e+07 -1.3817956447601318 0.07378457486629486\n",
      "[Step 22906] Loss: 9.41e+07 -1.3818495273590088 0.07376477122306824\n",
      "[Step 22907] Loss: 9.43e+07 -1.3818213939666748 0.0737573429942131\n",
      "[Step 22908] Loss: 9.47e+07 -1.3816968202590942 0.07375239580869675\n",
      "[Step 22909] Loss: 9.48e+07 -1.3817774057388306 0.07372846454381943\n",
      "[Step 22910] Loss: 9.43e+07 -1.3819069862365723 0.07369380444288254\n",
      "[Step 22911] Loss: 9.47e+07 -1.3821666240692139 0.0736640989780426\n",
      "[Step 22912] Loss: 9.41e+07 -1.3823896646499634 0.07362449914216995\n",
      "[Step 22913] Loss: 9.41e+07 -1.3824855089187622 0.07360716909170151\n",
      "[Step 22914] Loss: 9.44e+07 -1.3826926946640015 0.07356426119804382\n",
      "[Step 22915] Loss: 9.43e+07 -1.3828694820404053 0.07353208214044571\n",
      "[Step 22916] Loss: 9.33e+07 -1.3829410076141357 0.07353125512599945\n",
      "[Step 22917] Loss: 9.43e+07 -1.382956624031067 0.0735221803188324\n",
      "[Step 22918] Loss: 9.40e+07 -1.3830074071884155 0.07350320369005203\n",
      "[Step 22919] Loss: 9.43e+07 -1.382916808128357 0.07350485026836395\n",
      "[Step 22920] Loss: 9.44e+07 -1.382932186126709 0.0734999030828476\n",
      "[Step 22921] Loss: 9.59e+07 -1.3832277059555054 0.07346111536026001\n",
      "[Step 22922] Loss: 9.44e+07 -1.3835750818252563 0.07342728972434998\n",
      "[Step 22923] Loss: 9.40e+07 -1.3837776184082031 0.07341161370277405\n",
      "[Step 22924] Loss: 9.38e+07 -1.3838613033294678 0.07343306392431259\n",
      "[Step 22925] Loss: 9.38e+07 -1.3839269876480103 0.07341573387384415\n",
      "[Step 22926] Loss: 9.51e+07 -1.3840582370758057 0.07341903448104858\n",
      "[Step 22927] Loss: 9.43e+07 -1.3841221332550049 0.07342151552438736\n",
      "[Step 22928] Loss: 9.44e+07 -1.384300708770752 0.07341078668832779\n",
      "[Step 22929] Loss: 9.39e+07 -1.384400725364685 0.07341491430997849\n",
      "[Step 22930] Loss: 9.48e+07 -1.384466528892517 0.07341078668832779\n",
      "[Step 22931] Loss: 9.46e+07 -1.384529709815979 0.07340995967388153\n",
      "[Step 22932] Loss: 9.35e+07 -1.384487271308899 0.07341078668832779\n",
      "[Step 22933] Loss: 9.54e+07 -1.3845926523208618 0.07339015603065491\n",
      "[Step 22934] Loss: 9.44e+07 -1.38475501537323 0.0733720064163208\n",
      "[Step 22935] Loss: 9.57e+07 -1.3851408958435059 0.07332827150821686\n",
      "[Step 22936] Loss: 9.39e+07 -1.3855036497116089 0.073282890021801\n",
      "[Step 22937] Loss: 9.47e+07 -1.3860019445419312 0.07322513312101364\n",
      "[Step 22938] Loss: 9.49e+07 -1.3864495754241943 0.07319790124893188\n",
      "[Step 22939] Loss: 9.40e+07 -1.386764407157898 0.07316076755523682\n",
      "[Step 22940] Loss: 9.42e+07 -1.3869264125823975 0.0731285884976387\n",
      "[Step 22941] Loss: 9.44e+07 -1.3871170282363892 0.0731021836400032\n",
      "[Step 22942] Loss: 9.33e+07 -1.3872557878494263 0.07307660579681396\n",
      "[Step 22943] Loss: 9.46e+07 -1.3873283863067627 0.07307413220405579\n",
      "[Step 22944] Loss: 9.43e+07 -1.3874094486236572 0.07307330518960953\n",
      "[Step 22945] Loss: 9.48e+07 -1.3873186111450195 0.07307495176792145\n",
      "[Step 22946] Loss: 9.44e+07 -1.3872145414352417 0.07307907938957214\n",
      "[Step 22947] Loss: 9.41e+07 -1.3870269060134888 0.07308733463287354\n",
      "[Step 22948] Loss: 9.40e+07 -1.386800765991211 0.07310383766889572\n",
      "[Step 22949] Loss: 9.50e+07 -1.3866636753082275 0.07309971004724503\n",
      "[Step 22950] Loss: 9.43e+07 -1.3865059614181519 0.07311208546161652\n",
      "[Step 22951] Loss: 9.39e+07 -1.3863334655761719 0.07312776148319244\n",
      "[Step 22952] Loss: 9.50e+07 -1.3862394094467163 0.07313024252653122\n",
      "[Step 22953] Loss: 9.31e+07 -1.3861083984375 0.07312941551208496\n",
      "[Step 22954] Loss: 9.43e+07 -1.38608980178833 0.07311538606882095\n",
      "[Step 22955] Loss: 9.36e+07 -1.386025309562683 0.07311538606882095\n",
      "[Step 22956] Loss: 9.45e+07 -1.386023759841919 0.07312776148319244\n",
      "[Step 22957] Loss: 9.36e+07 -1.3859877586364746 0.07311291247606277\n",
      "[Step 22958] Loss: 9.39e+07 -1.3859734535217285 0.073124460875988\n",
      "[Step 22959] Loss: 9.46e+07 -1.3860422372817993 0.07313024252653122\n",
      "[Step 22960] Loss: 9.56e+07 -1.3859769105911255 0.07313436269760132\n",
      "[Step 22961] Loss: 9.48e+07 -1.3860187530517578 0.07313106209039688\n",
      "[Step 22962] Loss: 9.33e+07 -1.386024832725525 0.07314426451921463\n",
      "[Step 22963] Loss: 9.38e+07 -1.3859697580337524 0.07314013689756393\n",
      "[Step 22964] Loss: 9.45e+07 -1.3858921527862549 0.0731591209769249\n",
      "[Step 22965] Loss: 9.45e+07 -1.385842204093933 0.07317149639129639\n",
      "[Step 22966] Loss: 9.37e+07 -1.3858455419540405 0.0731731429696083\n",
      "[Step 22967] Loss: 9.44e+07 -1.3857486248016357 0.07318882644176483\n",
      "[Step 22968] Loss: 9.47e+07 -1.3858144283294678 0.07317974418401718\n",
      "[Step 22969] Loss: 9.36e+07 -1.385836124420166 0.07317562401294708\n",
      "[Step 22970] Loss: 9.41e+07 -1.3857282400131226 0.07319294661283493\n",
      "[Step 22971] Loss: 9.48e+07 -1.385540246963501 0.07319294661283493\n",
      "[Step 22972] Loss: 9.44e+07 -1.3853330612182617 0.07320532947778702\n",
      "[Step 22973] Loss: 9.42e+07 -1.3851475715637207 0.07321110367774963\n",
      "[Step 22974] Loss: 9.40e+07 -1.384954810142517 0.07322265207767487\n",
      "[Step 22975] Loss: 9.43e+07 -1.3847993612289429 0.07323915511369705\n",
      "[Step 22976] Loss: 9.42e+07 -1.3846864700317383 0.07323833554983139\n",
      "[Step 22977] Loss: 9.45e+07 -1.3844221830368042 0.07327298820018768\n",
      "[Step 22978] Loss: 9.40e+07 -1.3840148448944092 0.07331836968660355\n",
      "[Step 22979] Loss: 9.35e+07 -1.3835910558700562 0.0733579769730568\n",
      "[Step 22980] Loss: 9.39e+07 -1.3832184076309204 0.07338850945234299\n",
      "[Step 22981] Loss: 9.35e+07 -1.3828307390213013 0.07341573387384415\n",
      "[Step 22982] Loss: 9.43e+07 -1.382391333580017 0.07344792038202286\n",
      "[Step 22983] Loss: 9.40e+07 -1.382030725479126 0.07347019761800766\n",
      "[Step 22984] Loss: 9.38e+07 -1.381737470626831 0.07347844541072845\n",
      "[Step 22985] Loss: 9.53e+07 -1.3813271522521973 0.073513925075531\n",
      "[Step 22986] Loss: 9.44e+07 -1.3810701370239258 0.07352548092603683\n",
      "[Step 22987] Loss: 9.48e+07 -1.380761742591858 0.07355600595474243\n",
      "[Step 22988] Loss: 9.39e+07 -1.3805861473083496 0.07357003539800644\n",
      "[Step 22989] Loss: 9.47e+07 -1.380401611328125 0.07356508821249008\n",
      "[Step 22990] Loss: 9.35e+07 -1.3802499771118164 0.07357416301965714\n",
      "[Step 22991] Loss: 9.37e+07 -1.3800077438354492 0.07358571141958237\n",
      "[Step 22992] Loss: 9.71e+07 -1.380335807800293 0.07355600595474243\n",
      "[Step 22993] Loss: 9.46e+07 -1.3805314302444458 0.07354941219091415\n",
      "[Step 22994] Loss: 9.50e+07 -1.3807801008224487 0.07352878153324127\n",
      "[Step 22995] Loss: 9.50e+07 -1.381253957748413 0.07350567728281021\n",
      "[Step 22996] Loss: 9.41e+07 -1.3816920518875122 0.07346441596746445\n",
      "[Step 22997] Loss: 9.39e+07 -1.3820831775665283 0.07343966513872147\n",
      "[Step 22998] Loss: 9.37e+07 -1.382469892501831 0.07340748608112335\n",
      "[Step 22999] Loss: 9.48e+07 -1.3827385902404785 0.07339015603065491\n",
      "[Step 23000] Loss: 9.43e+07 -1.3829188346862793 0.0733678787946701\n",
      "[Step 23001] Loss: 9.46e+07 -1.3829009532928467 0.07337035238742828\n",
      "[Step 23002] Loss: 9.46e+07 -1.3830974102020264 0.07334230095148087\n",
      "[Step 23003] Loss: 9.41e+07 -1.3832005262374878 0.07332827150821686\n",
      "[Step 23004] Loss: 9.45e+07 -1.3832039833068848 0.07334064692258835\n",
      "[Step 23005] Loss: 9.38e+07 -1.3831613063812256 0.07334230095148087\n",
      "[Step 23006] Loss: 9.39e+07 -1.3831251859664917 0.07335220277309418\n",
      "[Step 23007] Loss: 9.47e+07 -1.383017897605896 0.07335302233695984\n",
      "[Step 23008] Loss: 9.41e+07 -1.3829728364944458 0.07334890216588974\n",
      "[Step 23009] Loss: 9.48e+07 -1.3830286264419556 0.07333817332983017\n",
      "[Step 23010] Loss: 9.43e+07 -1.383087396621704 0.07330682128667831\n",
      "[Step 23011] Loss: 9.43e+07 -1.3831472396850586 0.07329113781452179\n",
      "[Step 23012] Loss: 9.48e+07 -1.3831168413162231 0.07329361885786057\n",
      "[Step 23013] Loss: 9.37e+07 -1.3830403089523315 0.0732927918434143\n",
      "[Step 23014] Loss: 9.46e+07 -1.3828397989273071 0.07332002371549606\n",
      "[Step 23015] Loss: 9.42e+07 -1.382682204246521 0.07334394752979279\n",
      "[Step 23016] Loss: 9.39e+07 -1.3824599981307983 0.07335220277309418\n",
      "[Step 23017] Loss: 9.40e+07 -1.3822249174118042 0.0733802542090416\n",
      "[Step 23018] Loss: 9.53e+07 -1.3818868398666382 0.07339675724506378\n",
      "[Step 23019] Loss: 9.39e+07 -1.3815637826919556 0.07340995967388153\n",
      "[Step 23020] Loss: 9.46e+07 -1.3811767101287842 0.07342316210269928\n",
      "[Step 23021] Loss: 9.38e+07 -1.3808321952819824 0.07343223690986633\n",
      "[Step 23022] Loss: 9.43e+07 -1.3805286884307861 0.07344461977481842\n",
      "[Step 23023] Loss: 9.40e+07 -1.3801370859146118 0.07346606999635696\n",
      "[Step 23024] Loss: 9.41e+07 -1.3796597719192505 0.07351062446832657\n",
      "[Step 23025] Loss: 9.41e+07 -1.3791611194610596 0.07353042811155319\n",
      "[Step 23026] Loss: 9.39e+07 -1.3787118196487427 0.07356508821249008\n",
      "[Step 23027] Loss: 9.40e+07 -1.3783515691757202 0.07359231263399124\n",
      "[Step 23028] Loss: 9.42e+07 -1.3780514001846313 0.07361294329166412\n",
      "[Step 23029] Loss: 9.40e+07 -1.377791166305542 0.07365090399980545\n",
      "[Step 23030] Loss: 9.40e+07 -1.377597451210022 0.0736599788069725\n",
      "[Step 23031] Loss: 9.39e+07 -1.377329707145691 0.07367730140686035\n",
      "[Step 23032] Loss: 9.66e+07 -1.3769019842147827 0.07372599095106125\n",
      "[Step 23033] Loss: 9.44e+07 -1.3765801191329956 0.07374744117259979\n",
      "[Step 23034] Loss: 9.37e+07 -1.3762469291687012 0.07376807183027267\n",
      "[Step 23035] Loss: 9.44e+07 -1.3759175539016724 0.07379695028066635\n",
      "[Step 23036] Loss: 9.54e+07 -1.3757961988449097 0.07380932569503784\n",
      "[Step 23037] Loss: 9.48e+07 -1.37580406665802 0.07380025088787079\n",
      "[Step 23038] Loss: 9.50e+07 -1.3760929107666016 0.0737697184085846\n",
      "[Step 23039] Loss: 9.45e+07 -1.3764445781707764 0.0737309381365776\n",
      "[Step 23040] Loss: 9.45e+07 -1.376697063446045 0.0737086609005928\n",
      "[Step 23041] Loss: 9.46e+07 -1.3767684698104858 0.07369710505008698\n",
      "[Step 23042] Loss: 9.43e+07 -1.3767863512039185 0.07369628548622131\n",
      "[Step 23043] Loss: 9.42e+07 -1.3767772912979126 0.07370205968618393\n",
      "[Step 23044] Loss: 9.43e+07 -1.3767309188842773 0.07371030747890472\n",
      "[Step 23045] Loss: 9.51e+07 -1.3765592575073242 0.07372433692216873\n",
      "[Step 23046] Loss: 9.39e+07 -1.3763635158538818 0.07374249398708344\n",
      "[Step 23047] Loss: 9.43e+07 -1.376126766204834 0.07377301901578903\n",
      "[Step 23048] Loss: 9.44e+07 -1.3757760524749756 0.07380025088787079\n",
      "[Step 23049] Loss: 9.38e+07 -1.3755216598510742 0.07381262630224228\n",
      "[Step 23050] Loss: 9.49e+07 -1.375320315361023 0.07382912933826447\n",
      "[Step 23051] Loss: 9.36e+07 -1.375145673751831 0.07382500171661377\n",
      "[Step 23052] Loss: 9.42e+07 -1.3750014305114746 0.07381509989500046\n",
      "[Step 23053] Loss: 9.46e+07 -1.3748291730880737 0.07383325695991516\n",
      "[Step 23054] Loss: 9.41e+07 -1.3746227025985718 0.0738629624247551\n",
      "[Step 23055] Loss: 9.35e+07 -1.3744564056396484 0.07388276606798172\n",
      "[Step 23056] Loss: 9.45e+07 -1.3743318319320679 0.0738811120390892\n",
      "[Step 23057] Loss: 9.43e+07 -1.3742389678955078 0.0738852396607399\n",
      "[Step 23058] Loss: 9.41e+07 -1.374061942100525 0.07389596849679947\n",
      "[Step 23059] Loss: 9.43e+07 -1.3740359544754028 0.07390008866786957\n",
      "[Step 23060] Loss: 9.35e+07 -1.373969554901123 0.07389678806066513\n",
      "[Step 23061] Loss: 9.42e+07 -1.3738470077514648 0.07390587031841278\n",
      "[Step 23062] Loss: 9.58e+07 -1.3736199140548706 0.07392814755439758\n",
      "[Step 23063] Loss: 9.41e+07 -1.3733744621276855 0.0739297941327095\n",
      "[Step 23064] Loss: 9.57e+07 -1.3729838132858276 0.07394959777593613\n",
      "[Step 23065] Loss: 9.49e+07 -1.3727105855941772 0.07396198064088821\n",
      "[Step 23066] Loss: 9.40e+07 -1.3724522590637207 0.07399167865514755\n",
      "[Step 23067] Loss: 9.41e+07 -1.3722034692764282 0.074009008705616\n",
      "[Step 23068] Loss: 9.45e+07 -1.3719764947891235 0.07402386516332626\n",
      "[Step 23069] Loss: 9.55e+07 -1.371758222579956 0.07402138411998749\n",
      "[Step 23070] Loss: 9.40e+07 -1.3715758323669434 0.07402221113443375\n",
      "[Step 23071] Loss: 9.45e+07 -1.371497392654419 0.07401891052722931\n",
      "[Step 23072] Loss: 9.47e+07 -1.3714923858642578 0.07401230931282043\n",
      "[Step 23073] Loss: 9.40e+07 -1.371448278427124 0.07399085909128189\n",
      "[Step 23074] Loss: 9.46e+07 -1.371460199356079 0.07399580627679825\n",
      "[Step 23075] Loss: 9.48e+07 -1.3716952800750732 0.07398013025522232\n",
      "[Step 23076] Loss: 9.45e+07 -1.3720059394836426 0.0739520788192749\n",
      "[Step 23077] Loss: 9.40e+07 -1.3723218441009521 0.07391824573278427\n",
      "[Step 23078] Loss: 9.43e+07 -1.3725659847259521 0.07388028502464294\n",
      "[Step 23079] Loss: 9.38e+07 -1.372796654701233 0.07385966181755066\n",
      "[Step 23080] Loss: 9.40e+07 -1.373024582862854 0.07384150475263596\n",
      "[Step 23081] Loss: 9.38e+07 -1.3732026815414429 0.07380355149507523\n",
      "[Step 23082] Loss: 9.44e+07 -1.3734192848205566 0.07376641780138016\n",
      "[Step 23083] Loss: 9.44e+07 -1.3735615015029907 0.07375404238700867\n",
      "[Step 23084] Loss: 9.44e+07 -1.3737773895263672 0.07371608912944794\n",
      "[Step 23085] Loss: 9.39e+07 -1.374016284942627 0.07366988062858582\n",
      "[Step 23086] Loss: 9.39e+07 -1.3742023706436157 0.07362861931324005\n",
      "[Step 23087] Loss: 9.57e+07 -1.3746541738510132 0.07359809428453445\n",
      "[Step 23088] Loss: 9.47e+07 -1.3750460147857666 0.07357416301965714\n",
      "[Step 23089] Loss: 9.42e+07 -1.3754340410232544 0.07353538274765015\n",
      "[Step 23090] Loss: 9.42e+07 -1.3758949041366577 0.0734957754611969\n",
      "[Step 23091] Loss: 9.37e+07 -1.3763700723648071 0.07346029579639435\n",
      "[Step 23092] Loss: 9.42e+07 -1.3768696784973145 0.07341408729553223\n",
      "[Step 23093] Loss: 9.38e+07 -1.3773480653762817 0.07336952537298203\n",
      "[Step 23094] Loss: 9.36e+07 -1.3777990341186523 0.07332414388656616\n",
      "[Step 23095] Loss: 9.38e+07 -1.3781366348266602 0.07328619062900543\n",
      "[Step 23096] Loss: 9.44e+07 -1.3783764839172363 0.07327628880739212\n",
      "[Step 23097] Loss: 9.45e+07 -1.3786303997039795 0.07325483113527298\n",
      "[Step 23098] Loss: 9.43e+07 -1.3787761926651 0.07324988394975662\n",
      "[Step 23099] Loss: 9.40e+07 -1.378971815109253 0.07324245572090149\n",
      "[Step 23100] Loss: 9.41e+07 -1.3790833950042725 0.0732259526848793\n",
      "[Step 23101] Loss: 9.37e+07 -1.379206895828247 0.0732259526848793\n",
      "[Step 23102] Loss: 9.37e+07 -1.3792533874511719 0.07322760671377182\n",
      "[Step 23103] Loss: 9.37e+07 -1.379291296005249 0.07324162870645523\n",
      "[Step 23104] Loss: 9.48e+07 -1.3792057037353516 0.07326638698577881\n",
      "[Step 23105] Loss: 9.35e+07 -1.3790671825408936 0.07326473295688629\n",
      "[Step 23106] Loss: 9.40e+07 -1.3789077997207642 0.07328783720731735\n",
      "[Step 23107] Loss: 9.37e+07 -1.3786406517028809 0.07330929487943649\n",
      "[Step 23108] Loss: 9.49e+07 -1.378250241279602 0.07334477454423904\n",
      "[Step 23109] Loss: 9.54e+07 -1.3781272172927856 0.07335550338029861\n",
      "[Step 23110] Loss: 9.47e+07 -1.3780567646026611 0.07336870580911636\n",
      "[Step 23111] Loss: 9.45e+07 -1.3780633211135864 0.07338768243789673\n",
      "[Step 23112] Loss: 9.45e+07 -1.3781830072402954 0.07338520884513855\n",
      "[Step 23113] Loss: 9.43e+07 -1.3781955242156982 0.0733761265873909\n",
      "[Step 23114] Loss: 9.44e+07 -1.378171443939209 0.07337942719459534\n",
      "[Step 23115] Loss: 9.42e+07 -1.3781864643096924 0.07336540520191193\n",
      "[Step 23116] Loss: 9.40e+07 -1.3782105445861816 0.07336292415857315\n",
      "[Step 23117] Loss: 9.37e+07 -1.3780916929244995 0.07336540520191193\n",
      "[Step 23118] Loss: 9.35e+07 -1.377928376197815 0.0733720064163208\n",
      "[Step 23119] Loss: 9.35e+07 -1.3777439594268799 0.07339262962341309\n",
      "[Step 23120] Loss: 9.44e+07 -1.3775748014450073 0.07340171188116074\n",
      "[Step 23121] Loss: 9.34e+07 -1.3774092197418213 0.07340913265943527\n",
      "[Step 23122] Loss: 9.38e+07 -1.3772377967834473 0.0733984112739563\n",
      "[Step 23123] Loss: 9.42e+07 -1.377008318901062 0.07342563569545746\n",
      "[Step 23124] Loss: 9.39e+07 -1.3768422603607178 0.07343801856040955\n",
      "[Step 23125] Loss: 9.47e+07 -1.3768194913864136 0.07345369458198547\n",
      "[Step 23126] Loss: 9.47e+07 -1.376833200454712 0.07344213873147964\n",
      "[Step 23127] Loss: 9.44e+07 -1.3768049478530884 0.07344956696033478\n",
      "[Step 23128] Loss: 9.45e+07 -1.3769065141677856 0.0734470933675766\n",
      "[Step 23129] Loss: 9.39e+07 -1.3769924640655518 0.07343553751707077\n",
      "[Step 23130] Loss: 9.42e+07 -1.3770121335983276 0.07342811673879623\n",
      "[Step 23131] Loss: 9.43e+07 -1.3770416975021362 0.0734248161315918\n",
      "[Step 23132] Loss: 9.44e+07 -1.3770751953125 0.07341573387384415\n",
      "[Step 23133] Loss: 9.47e+07 -1.3770273923873901 0.07340335845947266\n",
      "[Step 23134] Loss: 9.43e+07 -1.3769656419754028 0.07339098304510117\n",
      "[Step 23135] Loss: 9.49e+07 -1.3770406246185303 0.07337117940187454\n",
      "[Step 23136] Loss: 9.43e+07 -1.3771030902862549 0.0733720064163208\n",
      "[Step 23137] Loss: 9.42e+07 -1.3772377967834473 0.07337530702352524\n",
      "[Step 23138] Loss: 9.38e+07 -1.3773550987243652 0.0733579769730568\n",
      "[Step 23139] Loss: 9.35e+07 -1.3773404359817505 0.07336292415857315\n",
      "[Step 23140] Loss: 9.51e+07 -1.3774442672729492 0.07335880398750305\n",
      "[Step 23141] Loss: 9.47e+07 -1.3775482177734375 0.07336375117301941\n",
      "[Step 23142] Loss: 9.42e+07 -1.3777433633804321 0.07336045056581497\n",
      "[Step 23143] Loss: 9.37e+07 -1.3779577016830444 0.07335880398750305\n",
      "[Step 23144] Loss: 9.52e+07 -1.3780736923217773 0.07336045056581497\n",
      "[Step 23145] Loss: 9.55e+07 -1.378420114517212 0.0733191967010498\n",
      "[Step 23146] Loss: 9.35e+07 -1.3788188695907593 0.07330269366502762\n",
      "[Step 23147] Loss: 9.36e+07 -1.379076600074768 0.073282890021801\n",
      "[Step 23148] Loss: 9.39e+07 -1.3792922496795654 0.07326555997133255\n",
      "[Step 23149] Loss: 9.46e+07 -1.3795466423034668 0.07323750853538513\n",
      "[Step 23150] Loss: 9.44e+07 -1.37979257106781 0.07321770489215851\n",
      "[Step 23151] Loss: 9.40e+07 -1.380013346672058 0.0732078030705452\n",
      "[Step 23152] Loss: 9.43e+07 -1.3802474737167358 0.07317809760570526\n",
      "[Step 23153] Loss: 9.48e+07 -1.380373477935791 0.07315994054079056\n",
      "[Step 23154] Loss: 9.48e+07 -1.3805415630340576 0.07315333932638168\n",
      "[Step 23155] Loss: 9.37e+07 -1.3806120157241821 0.07314509153366089\n",
      "[Step 23156] Loss: 9.48e+07 -1.3805521726608276 0.07313354313373566\n",
      "[Step 23157] Loss: 9.43e+07 -1.3804081678390503 0.07314839214086533\n",
      "[Step 23158] Loss: 9.45e+07 -1.3802621364593506 0.07315746694803238\n",
      "[Step 23159] Loss: 9.45e+07 -1.380203127861023 0.0731591209769249\n",
      "[Step 23160] Loss: 9.41e+07 -1.3802474737167358 0.07316572219133377\n",
      "[Step 23161] Loss: 9.37e+07 -1.3802891969680786 0.07317149639129639\n",
      "[Step 23162] Loss: 9.38e+07 -1.3803433179855347 0.07316159456968307\n",
      "[Step 23163] Loss: 9.42e+07 -1.3804434537887573 0.07314921915531158\n",
      "[Step 23164] Loss: 9.43e+07 -1.3805749416351318 0.07313024252653122\n",
      "[Step 23165] Loss: 9.45e+07 -1.380598783493042 0.07314261794090271\n",
      "[Step 23166] Loss: 9.44e+07 -1.3805720806121826 0.07312776148319244\n",
      "[Step 23167] Loss: 9.51e+07 -1.3803902864456177 0.07315663993358612\n",
      "[Step 23168] Loss: 9.47e+07 -1.38018798828125 0.07317892462015152\n",
      "[Step 23169] Loss: 9.51e+07 -1.37993323802948 0.07319790124893188\n",
      "[Step 23170] Loss: 9.41e+07 -1.3797165155410767 0.07321027666330338\n",
      "[Step 23171] Loss: 9.45e+07 -1.3794550895690918 0.07322347909212112\n",
      "[Step 23172] Loss: 9.43e+07 -1.3791463375091553 0.07323750853538513\n",
      "[Step 23173] Loss: 9.40e+07 -1.3789113759994507 0.07325731217861176\n",
      "[Step 23174] Loss: 9.45e+07 -1.3786237239837646 0.07328783720731735\n",
      "[Step 23175] Loss: 9.40e+07 -1.3783760070800781 0.07329361885786057\n",
      "[Step 23176] Loss: 9.44e+07 -1.3780664205551147 0.07330434024333954\n",
      "[Step 23177] Loss: 9.48e+07 -1.3777978420257568 0.07332249730825424\n",
      "[Step 23178] Loss: 9.42e+07 -1.3774487972259521 0.07336210459470749\n",
      "[Step 23179] Loss: 9.39e+07 -1.377094030380249 0.07339758425951004\n",
      "[Step 23180] Loss: 9.41e+07 -1.3767528533935547 0.07342728972434998\n",
      "[Step 23181] Loss: 9.45e+07 -1.376349925994873 0.07345781475305557\n",
      "[Step 23182] Loss: 9.40e+07 -1.3759667873382568 0.07347019761800766\n",
      "[Step 23183] Loss: 9.42e+07 -1.375491738319397 0.07349824905395508\n",
      "[Step 23184] Loss: 9.45e+07 -1.3750017881393433 0.07354115694761276\n",
      "[Step 23185] Loss: 9.38e+07 -1.3745720386505127 0.07357993721961975\n",
      "[Step 23186] Loss: 9.47e+07 -1.3740719556808472 0.07363274693489075\n",
      "[Step 23187] Loss: 9.57e+07 -1.3735285997390747 0.07369958609342575\n",
      "[Step 23188] Loss: 9.40e+07 -1.3730430603027344 0.07372681051492691\n",
      "[Step 23189] Loss: 9.42e+07 -1.3726060390472412 0.0737697184085846\n",
      "[Step 23190] Loss: 9.39e+07 -1.3723382949829102 0.07378869503736496\n",
      "[Step 23191] Loss: 9.38e+07 -1.3720974922180176 0.07381922751665115\n",
      "[Step 23192] Loss: 9.44e+07 -1.3719422817230225 0.07381922751665115\n",
      "[Step 23193] Loss: 9.49e+07 -1.3718562126159668 0.07380355149507523\n",
      "[Step 23194] Loss: 9.44e+07 -1.371699571609497 0.07379117608070374\n",
      "[Step 23195] Loss: 9.44e+07 -1.3716017007827759 0.07380519807338715\n",
      "[Step 23196] Loss: 9.40e+07 -1.371504306793213 0.07380025088787079\n",
      "[Step 23197] Loss: 9.37e+07 -1.3713421821594238 0.07379612326622009\n",
      "[Step 23198] Loss: 9.43e+07 -1.371091365814209 0.07381262630224228\n",
      "[Step 23199] Loss: 9.46e+07 -1.3709070682525635 0.07382088154554367\n",
      "[Step 23200] Loss: 9.53e+07 -1.370942234992981 0.07380437850952148\n",
      "[Step 23201] Loss: 9.38e+07 -1.3710016012191772 0.07381097972393036\n",
      "[Step 23202] Loss: 9.35e+07 -1.371047019958496 0.07381097972393036\n",
      "[Step 23203] Loss: 9.42e+07 -1.3711612224578857 0.07378952205181122\n",
      "[Step 23204] Loss: 9.36e+07 -1.3712185621261597 0.07378209382295609\n",
      "[Step 23205] Loss: 9.43e+07 -1.371209740638733 0.0737919956445694\n",
      "[Step 23206] Loss: 9.43e+07 -1.371066927909851 0.07379447668790817\n",
      "[Step 23207] Loss: 9.46e+07 -1.3710620403289795 0.07377549260854721\n",
      "[Step 23208] Loss: 9.37e+07 -1.3709999322891235 0.07377631962299347\n",
      "[Step 23209] Loss: 9.44e+07 -1.3709017038345337 0.07378044724464417\n",
      "[Step 23210] Loss: 9.42e+07 -1.3708134889602661 0.07377714663743973\n",
      "[Step 23211] Loss: 9.52e+07 -1.3709747791290283 0.0737837478518486\n",
      "[Step 23212] Loss: 9.40e+07 -1.371095061302185 0.0737655907869339\n",
      "[Step 23213] Loss: 9.54e+07 -1.3714518547058105 0.07373011112213135\n",
      "[Step 23214] Loss: 9.59e+07 -1.3720816373825073 0.07368390262126923\n",
      "[Step 23215] Loss: 9.42e+07 -1.372754454612732 0.07363274693489075\n",
      "[Step 23216] Loss: 9.40e+07 -1.3732962608337402 0.0735931396484375\n",
      "[Step 23217] Loss: 9.53e+07 -1.373671054840088 0.07357250899076462\n",
      "[Step 23218] Loss: 9.48e+07 -1.3738577365875244 0.0735626071691513\n",
      "[Step 23219] Loss: 9.42e+07 -1.3740605115890503 0.0735444575548172\n",
      "[Step 23220] Loss: 9.49e+07 -1.3741686344146729 0.07352712750434875\n",
      "[Step 23221] Loss: 9.48e+07 -1.374448537826538 0.07348670065402985\n",
      "[Step 23222] Loss: 9.42e+07 -1.374772071838379 0.07346111536026001\n",
      "[Step 23223] Loss: 9.42e+07 -1.374987006187439 0.07346771657466888\n",
      "[Step 23224] Loss: 9.46e+07 -1.3751248121261597 0.07345946878194809\n",
      "[Step 23225] Loss: 9.50e+07 -1.375325322151184 0.07345369458198547\n",
      "[Step 23226] Loss: 9.48e+07 -1.3754215240478516 0.07344213873147964\n",
      "[Step 23227] Loss: 9.43e+07 -1.3755654096603394 0.07342316210269928\n",
      "[Step 23228] Loss: 9.47e+07 -1.3757978677749634 0.07341573387384415\n",
      "[Step 23229] Loss: 9.39e+07 -1.375994324684143 0.0734066590666771\n",
      "[Step 23230] Loss: 9.42e+07 -1.3761564493179321 0.07338932901620865\n",
      "[Step 23231] Loss: 9.36e+07 -1.3762983083724976 0.07337365299463272\n",
      "[Step 23232] Loss: 9.38e+07 -1.3764160871505737 0.07334642112255096\n",
      "[Step 23233] Loss: 9.39e+07 -1.376519799232483 0.0733315721154213\n",
      "[Step 23234] Loss: 9.47e+07 -1.3767173290252686 0.0733233243227005\n",
      "[Step 23235] Loss: 9.37e+07 -1.3768529891967773 0.07330186665058136\n",
      "[Step 23236] Loss: 9.31e+07 -1.3769359588623047 0.07326308637857437\n",
      "[Step 23237] Loss: 9.36e+07 -1.3769652843475342 0.07326225936412811\n",
      "[Step 23238] Loss: 9.45e+07 -1.3770954608917236 0.07324988394975662\n",
      "[Step 23239] Loss: 9.37e+07 -1.3771206140518188 0.073244109749794\n",
      "[Step 23240] Loss: 9.47e+07 -1.3772228956222534 0.07324575632810593\n",
      "[Step 23241] Loss: 9.42e+07 -1.377192735671997 0.07325401157140732\n",
      "[Step 23242] Loss: 9.41e+07 -1.3770941495895386 0.07326225936412811\n",
      "[Step 23243] Loss: 9.38e+07 -1.3769992589950562 0.07326225936412811\n",
      "[Step 23244] Loss: 9.53e+07 -1.3771060705184937 0.07326061278581619\n",
      "[Step 23245] Loss: 9.36e+07 -1.3772056102752686 0.07326886057853699\n",
      "[Step 23246] Loss: 9.38e+07 -1.3772292137145996 0.07325401157140732\n",
      "[Step 23247] Loss: 9.37e+07 -1.377155065536499 0.07326555997133255\n",
      "[Step 23248] Loss: 9.44e+07 -1.3769348859786987 0.07327546179294586\n",
      "[Step 23249] Loss: 9.37e+07 -1.376710295677185 0.07327381521463394\n",
      "[Step 23250] Loss: 9.41e+07 -1.3765597343444824 0.07328206300735474\n",
      "[Step 23251] Loss: 9.40e+07 -1.3764305114746094 0.07329443842172623\n",
      "[Step 23252] Loss: 9.38e+07 -1.3762887716293335 0.07330022007226944\n",
      "[Step 23253] Loss: 9.39e+07 -1.3760915994644165 0.07332414388656616\n",
      "[Step 23254] Loss: 9.41e+07 -1.3758848905563354 0.0733414739370346\n",
      "[Step 23255] Loss: 9.45e+07 -1.3756057024002075 0.07336375117301941\n",
      "[Step 23256] Loss: 9.37e+07 -1.3753166198730469 0.07338768243789673\n",
      "[Step 23257] Loss: 9.46e+07 -1.3749759197235107 0.07341078668832779\n",
      "[Step 23258] Loss: 9.42e+07 -1.3746036291122437 0.07344049215316772\n",
      "[Step 23259] Loss: 9.41e+07 -1.3741931915283203 0.07348009943962097\n",
      "[Step 23260] Loss: 9.36e+07 -1.373768925666809 0.0735180526971817\n",
      "[Step 23261] Loss: 9.65e+07 -1.3737492561340332 0.07353455573320389\n",
      "[Step 23262] Loss: 9.41e+07 -1.3737198114395142 0.07354941219091415\n",
      "[Step 23263] Loss: 9.36e+07 -1.3736670017242432 0.07356756180524826\n",
      "[Step 23264] Loss: 9.39e+07 -1.3735631704330444 0.07357580959796906\n",
      "[Step 23265] Loss: 9.46e+07 -1.3734447956085205 0.07357993721961975\n",
      "[Step 23266] Loss: 9.41e+07 -1.373354196548462 0.07359066605567932\n",
      "[Step 23267] Loss: 9.35e+07 -1.373274803161621 0.07359066605567932\n",
      "[Step 23268] Loss: 9.43e+07 -1.3731595277786255 0.07359891384840012\n",
      "[Step 23269] Loss: 9.44e+07 -1.3730850219726562 0.07361624389886856\n",
      "[Step 23270] Loss: 9.39e+07 -1.3730113506317139 0.07361377030611038\n",
      "[Step 23271] Loss: 9.36e+07 -1.3728454113006592 0.07363440096378326\n",
      "[Step 23272] Loss: 9.42e+07 -1.3726409673690796 0.073672354221344\n",
      "[Step 23273] Loss: 9.55e+07 -1.372615098953247 0.07368308305740356\n",
      "[Step 23274] Loss: 9.41e+07 -1.372598648071289 0.07369875907897949\n",
      "[Step 23275] Loss: 9.44e+07 -1.3724374771118164 0.07373671233654022\n",
      "[Step 23276] Loss: 9.43e+07 -1.3724185228347778 0.07372929155826569\n",
      "[Step 23277] Loss: 9.54e+07 -1.3722466230392456 0.07376229017972946\n",
      "[Step 23278] Loss: 9.42e+07 -1.372037410736084 0.0737655907869339\n",
      "[Step 23279] Loss: 9.38e+07 -1.3717819452285767 0.07379529625177383\n",
      "[Step 23280] Loss: 9.39e+07 -1.3715742826461792 0.07382418215274811\n",
      "[Step 23281] Loss: 9.40e+07 -1.3714122772216797 0.07384233176708221\n",
      "[Step 23282] Loss: 9.44e+07 -1.3712365627288818 0.07386213541030884\n",
      "[Step 23283] Loss: 9.44e+07 -1.3711062669754028 0.07386543601751328\n",
      "[Step 23284] Loss: 9.49e+07 -1.371124029159546 0.07383820414543152\n",
      "[Step 23285] Loss: 9.42e+07 -1.3710315227508545 0.0738448053598404\n",
      "[Step 23286] Loss: 9.43e+07 -1.3708901405334473 0.07385800778865814\n",
      "[Step 23287] Loss: 9.40e+07 -1.3707196712493896 0.07386460900306702\n",
      "[Step 23288] Loss: 9.56e+07 -1.3708003759384155 0.0738505870103836\n",
      "[Step 23289] Loss: 9.45e+07 -1.3709845542907715 0.07383573055267334\n",
      "[Step 23290] Loss: 9.37e+07 -1.3712207078933716 0.07380932569503784\n",
      "[Step 23291] Loss: 9.45e+07 -1.3713114261627197 0.07379612326622009\n",
      "[Step 23292] Loss: 9.37e+07 -1.3713542222976685 0.07378952205181122\n",
      "[Step 23293] Loss: 9.43e+07 -1.3713339567184448 0.0737878754734993\n",
      "[Step 23294] Loss: 9.49e+07 -1.371486783027649 0.07376641780138016\n",
      "[Step 23295] Loss: 9.41e+07 -1.3716552257537842 0.07376311719417572\n",
      "[Step 23296] Loss: 9.45e+07 -1.3717164993286133 0.07378292083740234\n",
      "[Step 23297] Loss: 9.47e+07 -1.3716142177581787 0.07379282265901566\n",
      "[Step 23298] Loss: 9.38e+07 -1.3714593648910522 0.07379777729511261\n",
      "[Step 23299] Loss: 9.48e+07 -1.3713289499282837 0.07382665574550629\n",
      "[Step 23300] Loss: 9.63e+07 -1.3715481758117676 0.0738060250878334\n",
      "[Step 23301] Loss: 9.41e+07 -1.3717812299728394 0.07378622144460678\n",
      "[Step 23302] Loss: 9.40e+07 -1.3719401359558105 0.07377384603023529\n",
      "[Step 23303] Loss: 9.48e+07 -1.3719302415847778 0.07379529625177383\n",
      "[Step 23304] Loss: 9.37e+07 -1.3718997240066528 0.07379612326622009\n",
      "[Step 23305] Loss: 9.46e+07 -1.371791958808899 0.07380519807338715\n",
      "[Step 23306] Loss: 9.37e+07 -1.3716424703598022 0.07382665574550629\n",
      "[Step 23307] Loss: 9.48e+07 -1.3716305494308472 0.0738365575671196\n",
      "[Step 23308] Loss: 9.46e+07 -1.3715132474899292 0.07382418215274811\n",
      "[Step 23309] Loss: 9.42e+07 -1.3714498281478882 0.07383408397436142\n",
      "[Step 23310] Loss: 9.35e+07 -1.3714218139648438 0.0738365575671196\n",
      "[Step 23311] Loss: 9.36e+07 -1.3713918924331665 0.07384810596704483\n",
      "[Step 23312] Loss: 9.42e+07 -1.3714325428009033 0.0738505870103836\n",
      "[Step 23313] Loss: 9.45e+07 -1.3714808225631714 0.07384563237428665\n",
      "[Step 23314] Loss: 9.43e+07 -1.3714799880981445 0.07385223358869553\n",
      "[Step 23315] Loss: 9.51e+07 -1.3716776371002197 0.07384150475263596\n",
      "[Step 23316] Loss: 9.40e+07 -1.3718417882919312 0.07381179928779602\n",
      "[Step 23317] Loss: 9.41e+07 -1.3720409870147705 0.0737919956445694\n",
      "[Step 23318] Loss: 9.39e+07 -1.372332215309143 0.07378044724464417\n",
      "[Step 23319] Loss: 9.38e+07 -1.3726001977920532 0.0737573429942131\n",
      "[Step 23320] Loss: 9.49e+07 -1.373008370399475 0.07372929155826569\n",
      "[Step 23321] Loss: 9.36e+07 -1.3733787536621094 0.07368308305740356\n",
      "[Step 23322] Loss: 9.43e+07 -1.3737117052078247 0.07366245239973068\n",
      "[Step 23323] Loss: 9.50e+07 -1.3741971254348755 0.07363110035657883\n",
      "[Step 23324] Loss: 9.43e+07 -1.3746726512908936 0.07357416301965714\n",
      "[Step 23325] Loss: 9.44e+07 -1.3750742673873901 0.07354941219091415\n",
      "[Step 23326] Loss: 9.39e+07 -1.375563621520996 0.0734957754611969\n",
      "[Step 23327] Loss: 9.43e+07 -1.376084327697754 0.07343719154596329\n",
      "[Step 23328] Loss: 9.37e+07 -1.376564621925354 0.07340005785226822\n",
      "[Step 23329] Loss: 9.41e+07 -1.3770090341567993 0.07336292415857315\n",
      "[Step 23330] Loss: 9.33e+07 -1.3774397373199463 0.0733191967010498\n",
      "[Step 23331] Loss: 9.44e+07 -1.3777735233306885 0.07327298820018768\n",
      "[Step 23332] Loss: 9.43e+07 -1.3780003786087036 0.07325401157140732\n",
      "[Step 23333] Loss: 9.41e+07 -1.3781003952026367 0.0732482299208641\n",
      "[Step 23334] Loss: 9.40e+07 -1.3782086372375488 0.073244109749794\n",
      "[Step 23335] Loss: 9.51e+07 -1.3781660795211792 0.07325318455696106\n",
      "[Step 23336] Loss: 9.63e+07 -1.3779195547103882 0.07326391339302063\n",
      "[Step 23337] Loss: 9.32e+07 -1.377639651298523 0.07328206300735474\n",
      "[Step 23338] Loss: 9.39e+07 -1.3773345947265625 0.07328949123620987\n",
      "[Step 23339] Loss: 9.36e+07 -1.376995325088501 0.07331672310829163\n",
      "[Step 23340] Loss: 9.50e+07 -1.3769025802612305 0.0733456015586853\n",
      "[Step 23341] Loss: 9.41e+07 -1.37676203250885 0.07335880398750305\n",
      "[Step 23342] Loss: 9.43e+07 -1.3766173124313354 0.0733678787946701\n",
      "[Step 23343] Loss: 9.49e+07 -1.3766323328018188 0.07336870580911636\n",
      "[Step 23344] Loss: 9.39e+07 -1.3766682147979736 0.07336622476577759\n",
      "[Step 23345] Loss: 9.38e+07 -1.3766915798187256 0.07334890216588974\n",
      "[Step 23346] Loss: 9.46e+07 -1.3767719268798828 0.07335550338029861\n",
      "[Step 23347] Loss: 9.51e+07 -1.376755714416504 0.07335054874420166\n",
      "[Step 23348] Loss: 9.41e+07 -1.376768708229065 0.07333569973707199\n",
      "[Step 23349] Loss: 9.45e+07 -1.3767995834350586 0.0733274444937706\n",
      "[Step 23350] Loss: 9.44e+07 -1.3768863677978516 0.07331259548664093\n",
      "[Step 23351] Loss: 9.45e+07 -1.376882553100586 0.0733010396361351\n",
      "[Step 23352] Loss: 9.44e+07 -1.3768507242202759 0.07331342250108719\n",
      "[Step 23353] Loss: 9.54e+07 -1.3767098188400269 0.07332827150821686\n",
      "[Step 23354] Loss: 9.36e+07 -1.3765385150909424 0.07335962355136871\n",
      "[Step 23355] Loss: 9.38e+07 -1.376355528831482 0.07336457818746567\n",
      "[Step 23356] Loss: 9.39e+07 -1.3761807680130005 0.07337448000907898\n",
      "[Step 23357] Loss: 9.41e+07 -1.3760019540786743 0.07340088486671448\n",
      "[Step 23358] Loss: 9.40e+07 -1.3758718967437744 0.07340171188116074\n",
      "[Step 23359] Loss: 9.48e+07 -1.375962495803833 0.0733942836523056\n",
      "[Step 23360] Loss: 9.57e+07 -1.3763058185577393 0.0733497217297554\n",
      "[Step 23361] Loss: 9.77e+07 -1.3771644830703735 0.07328949123620987\n",
      "[Step 23362] Loss: 9.42e+07 -1.3778314590454102 0.07326061278581619\n",
      "[Step 23363] Loss: 9.32e+07 -1.3783576488494873 0.07322017848491669\n",
      "[Step 23364] Loss: 9.41e+07 -1.378821611404419 0.07319707423448563\n",
      "[Step 23365] Loss: 9.43e+07 -1.3792508840560913 0.07317066937685013\n",
      "[Step 23366] Loss: 9.40e+07 -1.3796124458312988 0.07315582036972046\n",
      "[Step 23367] Loss: 9.39e+07 -1.3799562454223633 0.07313518971204758\n",
      "[Step 23368] Loss: 9.37e+07 -1.3802372217178345 0.07312364131212234\n",
      "[Step 23369] Loss: 9.40e+07 -1.380439281463623 0.07308320701122284\n",
      "[Step 23370] Loss: 9.40e+07 -1.3806400299072266 0.07306257635354996\n",
      "[Step 23371] Loss: 9.50e+07 -1.3809666633605957 0.07303205132484436\n",
      "[Step 23372] Loss: 9.34e+07 -1.3812336921691895 0.07300976663827896\n",
      "[Step 23373] Loss: 9.40e+07 -1.3814268112182617 0.07299161702394485\n",
      "[Step 23374] Loss: 9.44e+07 -1.3816919326782227 0.07296521216630936\n",
      "[Step 23375] Loss: 9.58e+07 -1.38225519657135 0.07291900366544724\n",
      "[Step 23376] Loss: 9.41e+07 -1.3827104568481445 0.07287032157182693\n",
      "[Step 23377] Loss: 9.39e+07 -1.3831206560134888 0.07283154129981995\n",
      "[Step 23378] Loss: 9.48e+07 -1.3834073543548584 0.07280100882053375\n",
      "[Step 23379] Loss: 9.46e+07 -1.3836307525634766 0.07278285920619965\n",
      "[Step 23380] Loss: 9.47e+07 -1.3839490413665771 0.07275810092687607\n",
      "[Step 23381] Loss: 9.41e+07 -1.3841818571090698 0.07274489849805832\n",
      "[Step 23382] Loss: 9.49e+07 -1.3845003843307495 0.0727250948548317\n",
      "[Step 23383] Loss: 9.43e+07 -1.3847756385803223 0.07269621640443802\n",
      "[Step 23384] Loss: 9.46e+07 -1.3852063417434692 0.07266486436128616\n",
      "[Step 23385] Loss: 9.46e+07 -1.3855056762695312 0.0726417601108551\n",
      "[Step 23386] Loss: 9.41e+07 -1.3858364820480347 0.07261700183153152\n",
      "[Step 23387] Loss: 9.35e+07 -1.3861095905303955 0.07260049879550934\n",
      "[Step 23388] Loss: 9.47e+07 -1.386423945426941 0.0725707933306694\n",
      "[Step 23389] Loss: 9.45e+07 -1.3866950273513794 0.0725485160946846\n",
      "[Step 23390] Loss: 9.57e+07 -1.3871580362319946 0.07251469045877457\n",
      "[Step 23391] Loss: 9.42e+07 -1.3876131772994995 0.0724693015217781\n",
      "[Step 23392] Loss: 9.38e+07 -1.3879622220993042 0.07243712246417999\n",
      "[Step 23393] Loss: 9.40e+07 -1.388240933418274 0.0724206194281578\n",
      "[Step 23394] Loss: 9.47e+07 -1.3886513710021973 0.07237771153450012\n",
      "[Step 23395] Loss: 9.35e+07 -1.3889901638031006 0.07235296070575714\n",
      "[Step 23396] Loss: 9.39e+07 -1.389196515083313 0.07232820242643356\n",
      "[Step 23397] Loss: 9.40e+07 -1.38938570022583 0.07230345159769058\n",
      "[Step 23398] Loss: 9.58e+07 -1.3898676633834839 0.07227787375450134\n",
      "[Step 23399] Loss: 9.42e+07 -1.3901875019073486 0.07224074006080627\n",
      "[Step 23400] Loss: 9.48e+07 -1.3905951976776123 0.07221516221761703\n",
      "[Step 23401] Loss: 9.58e+07 -1.3912124633789062 0.07216152548789978\n",
      "[Step 23402] Loss: 9.43e+07 -1.3918925523757935 0.07212191820144653\n",
      "[Step 23403] Loss: 9.40e+07 -1.3924388885498047 0.07208891957998276\n",
      "[Step 23404] Loss: 9.46e+07 -1.3930195569992065 0.07206086069345474\n",
      "[Step 23405] Loss: 9.54e+07 -1.3936610221862793 0.07200475037097931\n",
      "[Step 23406] Loss: 9.40e+07 -1.3942534923553467 0.07196597009897232\n",
      "[Step 23407] Loss: 9.47e+07 -1.3948413133621216 0.07192966341972351\n",
      "[Step 23408] Loss: 9.36e+07 -1.3953511714935303 0.07189831137657166\n",
      "[Step 23409] Loss: 9.44e+07 -1.3957157135009766 0.07185787707567215\n",
      "[Step 23410] Loss: 9.36e+07 -1.3959609270095825 0.07183229923248291\n",
      "[Step 23411] Loss: 9.38e+07 -1.3961083889007568 0.07182074338197708\n",
      "[Step 23412] Loss: 9.48e+07 -1.3961215019226074 0.07182487100362778\n",
      "[Step 23413] Loss: 9.51e+07 -1.3962255716323853 0.07180506736040115\n",
      "[Step 23414] Loss: 9.57e+07 -1.3962291479110718 0.07181744277477264\n",
      "[Step 23415] Loss: 9.42e+07 -1.3961434364318848 0.07182074338197708\n",
      "[Step 23416] Loss: 9.50e+07 -1.39597749710083 0.07181744277477264\n",
      "[Step 23417] Loss: 9.36e+07 -1.3958427906036377 0.07182404398918152\n",
      "[Step 23418] Loss: 9.37e+07 -1.395682454109192 0.07184302806854248\n",
      "[Step 23419] Loss: 9.34e+07 -1.3954533338546753 0.07185953110456467\n",
      "[Step 23420] Loss: 9.43e+07 -1.3952174186706543 0.07186117768287659\n",
      "[Step 23421] Loss: 9.41e+07 -1.3949837684631348 0.07186777889728546\n",
      "[Step 23422] Loss: 9.55e+07 -1.3945958614349365 0.07190408557653427\n",
      "[Step 23423] Loss: 9.48e+07 -1.3942958116531372 0.07191646099090576\n",
      "[Step 23424] Loss: 9.44e+07 -1.3940165042877197 0.0719601958990097\n",
      "[Step 23425] Loss: 9.36e+07 -1.3937128782272339 0.07198824733495712\n",
      "[Step 23426] Loss: 9.37e+07 -1.3934921026229858 0.07200144976377487\n",
      "[Step 23427] Loss: 9.45e+07 -1.3932907581329346 0.07202538102865219\n",
      "[Step 23428] Loss: 9.45e+07 -1.3932608366012573 0.07205013185739517\n",
      "[Step 23429] Loss: 9.40e+07 -1.3932359218597412 0.07204683125019073\n",
      "[Step 23430] Loss: 9.43e+07 -1.393194317817688 0.07203692942857742\n",
      "[Step 23431] Loss: 9.32e+07 -1.3930853605270386 0.07204271107912064\n",
      "[Step 23432] Loss: 9.36e+07 -1.3930397033691406 0.07202620804309845\n",
      "[Step 23433] Loss: 9.40e+07 -1.3930970430374146 0.07201382517814636\n",
      "[Step 23434] Loss: 9.38e+07 -1.393099069595337 0.07200970500707626\n",
      "[Step 23435] Loss: 9.40e+07 -1.3930878639221191 0.0720171257853508\n",
      "[Step 23436] Loss: 9.42e+07 -1.3931424617767334 0.07200722396373749\n",
      "[Step 23437] Loss: 9.41e+07 -1.3930671215057373 0.07202868163585663\n",
      "[Step 23438] Loss: 9.43e+07 -1.3929173946380615 0.07203610986471176\n",
      "[Step 23439] Loss: 9.43e+07 -1.392661213874817 0.07205095887184143\n",
      "[Step 23440] Loss: 9.45e+07 -1.3924860954284668 0.07207076251506805\n",
      "[Step 23441] Loss: 9.43e+07 -1.3923612833023071 0.07208231836557388\n",
      "[Step 23442] Loss: 9.35e+07 -1.3922008275985718 0.0720880925655365\n",
      "[Step 23443] Loss: 9.43e+07 -1.391992449760437 0.0720963403582573\n",
      "[Step 23444] Loss: 9.44e+07 -1.3918274641036987 0.07212439924478531\n",
      "[Step 23445] Loss: 9.35e+07 -1.391623616218567 0.07215410470962524\n",
      "[Step 23446] Loss: 9.43e+07 -1.39142906665802 0.0721854567527771\n",
      "[Step 23447] Loss: 9.46e+07 -1.391268253326416 0.07218711078166962\n",
      "[Step 23448] Loss: 9.38e+07 -1.391152024269104 0.07219123095273972\n",
      "[Step 23449] Loss: 9.38e+07 -1.3910599946975708 0.07220690697431564\n",
      "[Step 23450] Loss: 9.47e+07 -1.390853762626648 0.07222093641757965\n",
      "[Step 23451] Loss: 9.44e+07 -1.3905909061431885 0.0722382664680481\n",
      "[Step 23452] Loss: 9.48e+07 -1.3904180526733398 0.07223991304636002\n",
      "[Step 23453] Loss: 9.54e+07 -1.3903465270996094 0.07225311547517776\n",
      "[Step 23454] Loss: 9.36e+07 -1.390226125717163 0.07225559651851654\n",
      "[Step 23455] Loss: 9.36e+07 -1.3901134729385376 0.07225394248962402\n",
      "[Step 23456] Loss: 9.40e+07 -1.3899521827697754 0.07227044552564621\n",
      "[Step 23457] Loss: 9.39e+07 -1.3899118900299072 0.07227540016174316\n",
      "[Step 23458] Loss: 9.41e+07 -1.3898248672485352 0.07227704674005508\n",
      "[Step 23459] Loss: 9.42e+07 -1.3897241353988647 0.07230757921934128\n",
      "[Step 23460] Loss: 9.41e+07 -1.3897360563278198 0.07230180501937866\n",
      "[Step 23461] Loss: 9.38e+07 -1.3897024393081665 0.07229354977607727\n",
      "[Step 23462] Loss: 9.46e+07 -1.3895829916000366 0.07231252640485764\n",
      "[Step 23463] Loss: 9.38e+07 -1.3895102739334106 0.07233315706253052\n",
      "[Step 23464] Loss: 9.46e+07 -1.3895092010498047 0.0723232552409172\n",
      "[Step 23465] Loss: 9.40e+07 -1.3894761800765991 0.07232820242643356\n",
      "[Step 23466] Loss: 9.43e+07 -1.389503002166748 0.0723356306552887\n",
      "[Step 23467] Loss: 9.41e+07 -1.3895505666732788 0.07233645766973495\n",
      "[Step 23468] Loss: 9.37e+07 -1.38956880569458 0.07232572883367538\n",
      "[Step 23469] Loss: 9.42e+07 -1.3895658254623413 0.0723273828625679\n",
      "[Step 23470] Loss: 9.43e+07 -1.3896692991256714 0.07231499999761581\n",
      "[Step 23471] Loss: 9.42e+07 -1.3897311687469482 0.07231830060482025\n",
      "[Step 23472] Loss: 9.37e+07 -1.3898731470108032 0.0723009780049324\n",
      "[Step 23473] Loss: 9.52e+07 -1.3901373147964478 0.07228530198335648\n",
      "[Step 23474] Loss: 9.61e+07 -1.3906502723693848 0.07224486768245697\n",
      "[Step 23475] Loss: 9.46e+07 -1.3910285234451294 0.07221350818872452\n",
      "[Step 23476] Loss: 9.40e+07 -1.3914039134979248 0.07217142730951309\n",
      "[Step 23477] Loss: 9.45e+07 -1.3916516304016113 0.07214337587356567\n",
      "[Step 23478] Loss: 9.43e+07 -1.3919686079025269 0.07213017344474792\n",
      "[Step 23479] Loss: 9.51e+07 -1.3924665451049805 0.07209386676549911\n",
      "[Step 23480] Loss: 9.41e+07 -1.3930071592330933 0.07205095887184143\n",
      "[Step 23481] Loss: 9.42e+07 -1.3934537172317505 0.07202950865030289\n",
      "[Step 23482] Loss: 9.37e+07 -1.3937792778015137 0.07199980318546295\n",
      "[Step 23483] Loss: 9.46e+07 -1.394114375114441 0.07198412716388702\n",
      "[Step 23484] Loss: 9.40e+07 -1.3943474292755127 0.0719684436917305\n",
      "[Step 23485] Loss: 9.42e+07 -1.394667148590088 0.07195029407739639\n",
      "[Step 23486] Loss: 9.43e+07 -1.3949253559112549 0.0719379186630249\n",
      "[Step 23487] Loss: 9.44e+07 -1.3950397968292236 0.07191811501979828\n",
      "[Step 23488] Loss: 9.40e+07 -1.3951208591461182 0.0718974843621254\n",
      "[Step 23489] Loss: 9.39e+07 -1.3951300382614136 0.07187603414058685\n",
      "[Step 23490] Loss: 9.35e+07 -1.3950589895248413 0.07186613231897354\n",
      "[Step 23491] Loss: 9.46e+07 -1.3949061632156372 0.07188015431165695\n",
      "[Step 23492] Loss: 9.47e+07 -1.3949631452560425 0.07188263535499573\n",
      "[Step 23493] Loss: 9.36e+07 -1.395023226737976 0.07187603414058685\n",
      "[Step 23494] Loss: 9.42e+07 -1.3951308727264404 0.07186200469732285\n",
      "[Step 23495] Loss: 9.46e+07 -1.395087718963623 0.07185705006122589\n",
      "[Step 23496] Loss: 9.43e+07 -1.395087718963623 0.07183724641799927\n",
      "[Step 23497] Loss: 9.42e+07 -1.395113468170166 0.07182569801807404\n",
      "[Step 23498] Loss: 9.40e+07 -1.3950705528259277 0.0718306452035904\n",
      "[Step 23499] Loss: 9.35e+07 -1.394977331161499 0.07182734459638596\n",
      "[Step 23500] Loss: 9.41e+07 -1.3948802947998047 0.0718141421675682\n",
      "[Step 23501] Loss: 9.44e+07 -1.3949288129806519 0.07180093973875046\n",
      "[Step 23502] Loss: 9.42e+07 -1.3948012590408325 0.07181249558925629\n",
      "[Step 23503] Loss: 9.47e+07 -1.3945988416671753 0.07181992381811142\n",
      "[Step 23504] Loss: 9.39e+07 -1.3944370746612549 0.07181249558925629\n",
      "[Step 23505] Loss: 9.37e+07 -1.394169569015503 0.07182157039642334\n",
      "[Step 23506] Loss: 9.35e+07 -1.3938684463500977 0.07183147221803665\n",
      "[Step 23507] Loss: 9.43e+07 -1.3935551643371582 0.07184797525405884\n",
      "[Step 23508] Loss: 9.43e+07 -1.3931912183761597 0.07186777889728546\n",
      "[Step 23509] Loss: 9.37e+07 -1.3928290605545044 0.07189418375492096\n",
      "[Step 23510] Loss: 9.45e+07 -1.3924261331558228 0.07190078496932983\n",
      "[Step 23511] Loss: 9.41e+07 -1.3920377492904663 0.07192306220531464\n",
      "[Step 23512] Loss: 9.40e+07 -1.3916155099868774 0.07194864004850388\n",
      "[Step 23513] Loss: 9.34e+07 -1.391159176826477 0.07198494672775269\n",
      "[Step 23514] Loss: 9.42e+07 -1.3906099796295166 0.07201547920703888\n",
      "[Step 23515] Loss: 9.61e+07 -1.3899720907211304 0.07205591350793839\n",
      "[Step 23516] Loss: 9.41e+07 -1.3893909454345703 0.07210129499435425\n",
      "[Step 23517] Loss: 9.47e+07 -1.3888576030731201 0.07214832305908203\n",
      "[Step 23518] Loss: 9.48e+07 -1.3883445262908936 0.07219701260328293\n",
      "[Step 23519] Loss: 9.45e+07 -1.3879767656326294 0.0722382664680481\n",
      "[Step 23520] Loss: 9.43e+07 -1.3877825736999512 0.07225394248962402\n",
      "[Step 23521] Loss: 9.41e+07 -1.387661337852478 0.07227127254009247\n",
      "[Step 23522] Loss: 9.42e+07 -1.3874831199645996 0.07229354977607727\n",
      "[Step 23523] Loss: 9.62e+07 -1.3876612186431885 0.07227952033281326\n",
      "[Step 23524] Loss: 9.46e+07 -1.38796067237854 0.07226219773292542\n",
      "[Step 23525] Loss: 9.52e+07 -1.3884066343307495 0.07222341001033783\n",
      "[Step 23526] Loss: 9.39e+07 -1.388720154762268 0.07222010940313339\n",
      "[Step 23527] Loss: 9.41e+07 -1.3889437913894653 0.07221928983926773\n",
      "[Step 23528] Loss: 9.48e+07 -1.3891061544418335 0.07221103459596634\n",
      "[Step 23529] Loss: 9.38e+07 -1.3892470598220825 0.0722118616104126\n",
      "[Step 23530] Loss: 9.46e+07 -1.3892759084701538 0.0722118616104126\n",
      "[Step 23531] Loss: 9.46e+07 -1.389237880706787 0.07222506403923035\n",
      "[Step 23532] Loss: 9.47e+07 -1.3892616033554077 0.07222919166088104\n",
      "[Step 23533] Loss: 9.41e+07 -1.3892555236816406 0.07222010940313339\n",
      "[Step 23534] Loss: 9.40e+07 -1.3891850709915161 0.07223579287528992\n",
      "[Step 23535] Loss: 9.48e+07 -1.3891890048980713 0.0722382664680481\n",
      "[Step 23536] Loss: 9.39e+07 -1.3891758918762207 0.07224321365356445\n",
      "[Step 23537] Loss: 9.42e+07 -1.3891223669052124 0.07224981486797333\n",
      "[Step 23538] Loss: 9.43e+07 -1.389115571975708 0.07225559651851654\n",
      "[Step 23539] Loss: 9.42e+07 -1.3891273736953735 0.07226137071847916\n",
      "[Step 23540] Loss: 9.41e+07 -1.3891414403915405 0.07226219773292542\n",
      "[Step 23541] Loss: 9.51e+07 -1.3890380859375 0.07228034734725952\n",
      "[Step 23542] Loss: 9.48e+07 -1.3891030550003052 0.07227291911840439\n",
      "[Step 23543] Loss: 9.33e+07 -1.3891645669937134 0.07226714491844177\n",
      "[Step 23544] Loss: 9.36e+07 -1.3891934156417847 0.07228530198335648\n",
      "[Step 23545] Loss: 9.39e+07 -1.389150619506836 0.07229107618331909\n",
      "[Step 23546] Loss: 9.44e+07 -1.3891956806182861 0.07229602336883545\n",
      "[Step 23547] Loss: 9.45e+07 -1.3891291618347168 0.07228364795446396\n",
      "[Step 23548] Loss: 9.39e+07 -1.3890174627304077 0.07229602336883545\n",
      "[Step 23549] Loss: 9.44e+07 -1.3889315128326416 0.07229024916887283\n",
      "[Step 23550] Loss: 9.49e+07 -1.3887910842895508 0.07228530198335648\n",
      "[Step 23551] Loss: 9.44e+07 -1.3887802362442017 0.07228364795446396\n",
      "[Step 23552] Loss: 9.36e+07 -1.3886947631835938 0.0722869485616684\n",
      "[Step 23553] Loss: 9.43e+07 -1.3886202573776245 0.07229850441217422\n",
      "[Step 23554] Loss: 9.35e+07 -1.388630747795105 0.07229024916887283\n",
      "[Step 23555] Loss: 9.38e+07 -1.3886018991470337 0.07227952033281326\n",
      "[Step 23556] Loss: 9.41e+07 -1.3885873556137085 0.07226219773292542\n",
      "[Step 23557] Loss: 9.41e+07 -1.3886431455612183 0.07224404066801071\n",
      "[Step 23558] Loss: 9.44e+07 -1.3887052536010742 0.07224074006080627\n",
      "[Step 23559] Loss: 9.59e+07 -1.3890550136566162 0.07218875735998154\n",
      "[Step 23560] Loss: 9.38e+07 -1.3893697261810303 0.07214832305908203\n",
      "[Step 23561] Loss: 9.39e+07 -1.3896257877349854 0.07212357223033905\n",
      "[Step 23562] Loss: 9.44e+07 -1.3899073600769043 0.07209303975105286\n",
      "[Step 23563] Loss: 9.44e+07 -1.3902885913848877 0.07207736372947693\n",
      "[Step 23564] Loss: 9.37e+07 -1.390645146369934 0.07205425947904587\n",
      "[Step 23565] Loss: 9.40e+07 -1.3910082578659058 0.0720212534070015\n",
      "[Step 23566] Loss: 9.39e+07 -1.3913311958312988 0.07199567556381226\n",
      "[Step 23567] Loss: 9.42e+07 -1.3914895057678223 0.07198412716388702\n",
      "[Step 23568] Loss: 9.41e+07 -1.391545295715332 0.07197339832782745\n",
      "[Step 23569] Loss: 9.46e+07 -1.3914878368377686 0.07198164612054825\n",
      "[Step 23570] Loss: 9.43e+07 -1.391382098197937 0.07198412716388702\n",
      "[Step 23571] Loss: 9.43e+07 -1.3912744522094727 0.07198990136384964\n",
      "[Step 23572] Loss: 9.38e+07 -1.3911113739013672 0.07200557738542557\n",
      "[Step 23573] Loss: 9.47e+07 -1.3909223079681396 0.07200722396373749\n",
      "[Step 23574] Loss: 9.41e+07 -1.3907150030136108 0.07204023003578186\n",
      "[Step 23575] Loss: 9.44e+07 -1.3905303478240967 0.07205261290073395\n",
      "[Step 23576] Loss: 9.35e+07 -1.390406847000122 0.07205673307180405\n",
      "[Step 23577] Loss: 9.39e+07 -1.3902795314788818 0.07207819074392319\n",
      "[Step 23578] Loss: 9.41e+07 -1.3900623321533203 0.0720839649438858\n",
      "[Step 23579] Loss: 9.39e+07 -1.3899112939834595 0.07210129499435425\n",
      "[Step 23580] Loss: 9.39e+07 -1.3898652791976929 0.07210789620876312\n",
      "[Step 23581] Loss: 9.45e+07 -1.3899078369140625 0.07212191820144653\n",
      "[Step 23582] Loss: 9.38e+07 -1.389902114868164 0.07212521880865097\n",
      "[Step 23583] Loss: 9.49e+07 -1.3900306224822998 0.07213347405195236\n",
      "[Step 23584] Loss: 9.48e+07 -1.39018714427948 0.07212687283754349\n",
      "[Step 23585] Loss: 9.34e+07 -1.390320897102356 0.07211697101593018\n",
      "[Step 23586] Loss: 9.48e+07 -1.3903262615203857 0.07211201637983322\n",
      "[Step 23587] Loss: 9.42e+07 -1.390317678451538 0.07209964096546173\n",
      "[Step 23588] Loss: 9.34e+07 -1.3901944160461426 0.07210294157266617\n",
      "[Step 23589] Loss: 9.34e+07 -1.390012502670288 0.07211201637983322\n",
      "[Step 23590] Loss: 9.35e+07 -1.3898003101348877 0.07212687283754349\n",
      "[Step 23591] Loss: 9.40e+07 -1.3895981311798096 0.07214750349521637\n",
      "[Step 23592] Loss: 9.35e+07 -1.3894368410110474 0.07216400653123856\n",
      "[Step 23593] Loss: 9.38e+07 -1.3892968893051147 0.07217885553836823\n",
      "[Step 23594] Loss: 9.45e+07 -1.3892226219177246 0.07218628376722336\n",
      "[Step 23595] Loss: 9.39e+07 -1.3891143798828125 0.0721854567527771\n",
      "[Step 23596] Loss: 9.39e+07 -1.3889527320861816 0.07218711078166962\n",
      "[Step 23597] Loss: 9.46e+07 -1.3889790773391724 0.07218711078166962\n",
      "[Step 23598] Loss: 9.42e+07 -1.3890358209609985 0.07217638194561005\n",
      "[Step 23599] Loss: 9.39e+07 -1.3889884948730469 0.07217802852392197\n",
      "[Step 23600] Loss: 9.42e+07 -1.3889576196670532 0.07217885553836823\n",
      "[Step 23601] Loss: 9.39e+07 -1.3888667821884155 0.07218628376722336\n",
      "[Step 23602] Loss: 9.39e+07 -1.3887498378753662 0.07218793034553528\n",
      "[Step 23603] Loss: 9.37e+07 -1.3886523246765137 0.07220031321048737\n",
      "[Step 23604] Loss: 9.40e+07 -1.3885904550552368 0.0722036138176918\n",
      "[Step 23605] Loss: 9.41e+07 -1.3884752988815308 0.07219618558883667\n",
      "[Step 23606] Loss: 9.36e+07 -1.3883835077285767 0.07220856100320816\n",
      "[Step 23607] Loss: 9.38e+07 -1.3883429765701294 0.07222341001033783\n",
      "[Step 23608] Loss: 9.42e+07 -1.3881940841674805 0.07223579287528992\n",
      "[Step 23609] Loss: 9.34e+07 -1.3880410194396973 0.07222919166088104\n",
      "[Step 23610] Loss: 9.45e+07 -1.3878059387207031 0.07224651426076889\n",
      "[Step 23611] Loss: 9.45e+07 -1.387622356414795 0.07226797193288803\n",
      "[Step 23612] Loss: 9.35e+07 -1.387481451034546 0.07226549834012985\n",
      "[Step 23613] Loss: 9.41e+07 -1.3873145580291748 0.07228612154722214\n",
      "[Step 23614] Loss: 9.38e+07 -1.38717782497406 0.07230345159769058\n",
      "[Step 23615] Loss: 9.38e+07 -1.3869566917419434 0.07231830060482025\n",
      "[Step 23616] Loss: 9.39e+07 -1.3867160081863403 0.0723273828625679\n",
      "[Step 23617] Loss: 9.37e+07 -1.3864766359329224 0.07233810424804688\n",
      "[Step 23618] Loss: 9.45e+07 -1.386229157447815 0.07235130667686462\n",
      "[Step 23619] Loss: 9.46e+07 -1.3859906196594238 0.07236780971288681\n",
      "[Step 23620] Loss: 9.36e+07 -1.3858158588409424 0.07238101214170456\n",
      "[Step 23621] Loss: 9.36e+07 -1.3857218027114868 0.072384312748909\n",
      "[Step 23622] Loss: 9.46e+07 -1.3856632709503174 0.07238844037055969\n",
      "[Step 23623] Loss: 9.48e+07 -1.385725975036621 0.07237359136343002\n",
      "[Step 23624] Loss: 9.42e+07 -1.3857861757278442 0.07236616313457489\n",
      "[Step 23625] Loss: 9.49e+07 -1.3860769271850586 0.07231665402650833\n",
      "[Step 23626] Loss: 9.37e+07 -1.3862868547439575 0.07230015099048615\n",
      "[Step 23627] Loss: 9.45e+07 -1.3865997791290283 0.07228200137615204\n",
      "[Step 23628] Loss: 9.43e+07 -1.3868615627288818 0.07225146889686584\n",
      "[Step 23629] Loss: 9.44e+07 -1.3870347738265991 0.0722382664680481\n",
      "[Step 23630] Loss: 9.39e+07 -1.3871866464614868 0.07222341001033783\n",
      "[Step 23631] Loss: 9.40e+07 -1.3873074054718018 0.07219453155994415\n",
      "[Step 23632] Loss: 9.42e+07 -1.3873906135559082 0.07218381017446518\n",
      "[Step 23633] Loss: 9.45e+07 -1.3875795602798462 0.07216895371675491\n",
      "[Step 23634] Loss: 9.44e+07 -1.387829065322876 0.07215410470962524\n",
      "[Step 23635] Loss: 9.38e+07 -1.388062834739685 0.07213924825191498\n",
      "[Step 23636] Loss: 9.36e+07 -1.3882516622543335 0.07211614400148392\n",
      "[Step 23637] Loss: 9.39e+07 -1.388396143913269 0.07210046797990799\n",
      "[Step 23638] Loss: 9.46e+07 -1.38853919506073 0.07209882140159607\n",
      "[Step 23639] Loss: 9.39e+07 -1.3885951042175293 0.0721062421798706\n",
      "[Step 23640] Loss: 9.48e+07 -1.3885694742202759 0.07209882140159607\n",
      "[Step 23641] Loss: 9.43e+07 -1.3884741067886353 0.0720963403582573\n",
      "[Step 23642] Loss: 9.38e+07 -1.3884050846099854 0.0721186175942421\n",
      "[Step 23643] Loss: 9.43e+07 -1.3884328603744507 0.07213182002305984\n",
      "[Step 23644] Loss: 9.35e+07 -1.3883872032165527 0.07213842123746872\n",
      "[Step 23645] Loss: 9.42e+07 -1.388382911682129 0.07213182002305984\n",
      "[Step 23646] Loss: 9.48e+07 -1.388304352760315 0.07214007526636124\n",
      "[Step 23647] Loss: 9.44e+07 -1.3882789611816406 0.07213924825191498\n",
      "[Step 23648] Loss: 9.39e+07 -1.3881888389587402 0.0721549242734909\n",
      "[Step 23649] Loss: 9.43e+07 -1.3881632089614868 0.0721549242734909\n",
      "[Step 23650] Loss: 9.39e+07 -1.388026475906372 0.0721854567527771\n",
      "[Step 23651] Loss: 9.41e+07 -1.3879138231277466 0.07219371199607849\n",
      "[Step 23652] Loss: 9.42e+07 -1.3878015279769897 0.07220526039600372\n",
      "[Step 23653] Loss: 9.54e+07 -1.3879872560501099 0.07219453155994415\n",
      "[Step 23654] Loss: 9.45e+07 -1.388235092163086 0.07219041138887405\n",
      "[Step 23655] Loss: 9.45e+07 -1.3883588314056396 0.07217472791671753\n",
      "[Step 23656] Loss: 9.41e+07 -1.3883975744247437 0.07216648012399673\n",
      "[Step 23657] Loss: 9.55e+07 -1.388262391090393 0.07219205796718597\n",
      "[Step 23658] Loss: 9.45e+07 -1.3881006240844727 0.07221516221761703\n",
      "[Step 23659] Loss: 9.49e+07 -1.387812852859497 0.0722382664680481\n",
      "[Step 23660] Loss: 9.48e+07 -1.387658715248108 0.07224651426076889\n",
      "[Step 23661] Loss: 9.38e+07 -1.3874626159667969 0.07225889712572098\n",
      "[Step 23662] Loss: 9.44e+07 -1.3873388767242432 0.07227044552564621\n",
      "[Step 23663] Loss: 9.42e+07 -1.387259840965271 0.07225559651851654\n",
      "[Step 23664] Loss: 9.45e+07 -1.3872880935668945 0.07224486768245697\n",
      "[Step 23665] Loss: 9.49e+07 -1.3873809576034546 0.07223991304636002\n",
      "[Step 23666] Loss: 9.44e+07 -1.3875983953475952 0.07222259044647217\n",
      "[Step 23667] Loss: 9.38e+07 -1.3878705501556396 0.07220608741044998\n",
      "[Step 23668] Loss: 9.40e+07 -1.3881109952926636 0.0721854567527771\n",
      "[Step 23669] Loss: 9.39e+07 -1.3883510828018188 0.07218462973833084\n",
      "[Step 23670] Loss: 9.51e+07 -1.3887933492660522 0.07214172184467316\n",
      "[Step 23671] Loss: 9.37e+07 -1.3892098665237427 0.07211697101593018\n",
      "[Step 23672] Loss: 9.41e+07 -1.3896464109420776 0.07207983732223511\n",
      "[Step 23673] Loss: 9.42e+07 -1.3901588916778564 0.07202950865030289\n",
      "[Step 23674] Loss: 9.42e+07 -1.390553593635559 0.07200887799263\n",
      "[Step 23675] Loss: 9.41e+07 -1.390949010848999 0.07196597009897232\n",
      "[Step 23676] Loss: 9.59e+07 -1.391129732131958 0.0719643235206604\n",
      "[Step 23677] Loss: 9.48e+07 -1.391363501548767 0.07195276767015457\n",
      "[Step 23678] Loss: 9.42e+07 -1.3915081024169922 0.07194369286298752\n",
      "[Step 23679] Loss: 9.45e+07 -1.3916444778442383 0.07192141562700272\n",
      "[Step 23680] Loss: 9.40e+07 -1.3917754888534546 0.07190491259098053\n",
      "[Step 23681] Loss: 9.43e+07 -1.3918445110321045 0.07191233336925507\n",
      "[Step 23682] Loss: 9.48e+07 -1.3921046257019043 0.07189005613327026\n",
      "[Step 23683] Loss: 9.43e+07 -1.3924325704574585 0.07186777889728546\n",
      "[Step 23684] Loss: 9.43e+07 -1.3927465677261353 0.07184550166130066\n",
      "[Step 23685] Loss: 9.39e+07 -1.3931732177734375 0.07183147221803665\n",
      "[Step 23686] Loss: 9.38e+07 -1.393455982208252 0.07181249558925629\n",
      "[Step 23687] Loss: 9.45e+07 -1.3937422037124634 0.0718001201748848\n",
      "[Step 23688] Loss: 9.39e+07 -1.3940672874450684 0.07177206128835678\n",
      "[Step 23689] Loss: 9.41e+07 -1.3944147825241089 0.07173740863800049\n",
      "[Step 23690] Loss: 9.43e+07 -1.3947477340698242 0.07172007858753204\n",
      "[Step 23691] Loss: 9.42e+07 -1.3950154781341553 0.07170604914426804\n",
      "[Step 23692] Loss: 9.47e+07 -1.3951632976531982 0.0716945007443428\n",
      "[Step 23693] Loss: 9.45e+07 -1.3954039812088013 0.0716804713010788\n",
      "[Step 23694] Loss: 9.32e+07 -1.3955951929092407 0.071672223508358\n",
      "[Step 23695] Loss: 9.41e+07 -1.3957785367965698 0.07165984809398651\n",
      "[Step 23696] Loss: 9.47e+07 -1.3959461450576782 0.07163921743631363\n",
      "[Step 23697] Loss: 9.42e+07 -1.3960552215576172 0.07161281257867813\n",
      "[Step 23698] Loss: 9.46e+07 -1.3961786031723022 0.07160868495702744\n",
      "[Step 23699] Loss: 9.46e+07 -1.3962758779525757 0.07159878313541412\n",
      "[Step 23700] Loss: 9.45e+07 -1.3964368104934692 0.07157567888498306\n",
      "[Step 23701] Loss: 9.37e+07 -1.3964884281158447 0.07157980650663376\n",
      "[Step 23702] Loss: 9.42e+07 -1.3966014385223389 0.07156825810670853\n",
      "[Step 23703] Loss: 9.40e+07 -1.396661400794983 0.07156330347061157\n",
      "[Step 23704] Loss: 9.38e+07 -1.3967058658599854 0.0715789794921875\n",
      "[Step 23705] Loss: 9.47e+07 -1.396783471107483 0.07159135490655899\n",
      "[Step 23706] Loss: 9.42e+07 -1.3967887163162231 0.07158558070659637\n",
      "[Step 23707] Loss: 9.39e+07 -1.3968126773834229 0.07156660407781601\n",
      "[Step 23708] Loss: 9.41e+07 -1.3968400955200195 0.07155752927064896\n",
      "[Step 23709] Loss: 9.39e+07 -1.3968690633773804 0.07155010104179382\n",
      "[Step 23710] Loss: 9.47e+07 -1.3967310190200806 0.0715484544634819\n",
      "[Step 23711] Loss: 9.41e+07 -1.3966703414916992 0.07154102623462677\n",
      "[Step 23712] Loss: 9.38e+07 -1.3965429067611694 0.07155010104179382\n",
      "[Step 23713] Loss: 9.46e+07 -1.3965073823928833 0.07154185324907303\n",
      "[Step 23714] Loss: 9.42e+07 -1.3964836597442627 0.07155587524175644\n",
      "[Step 23715] Loss: 9.47e+07 -1.3964817523956299 0.0715567022562027\n",
      "[Step 23716] Loss: 9.44e+07 -1.3964813947677612 0.07155175507068634\n",
      "[Step 23717] Loss: 9.31e+07 -1.3964052200317383 0.07155835628509521\n",
      "[Step 23718] Loss: 9.34e+07 -1.3963083028793335 0.07156577706336975\n",
      "[Step 23719] Loss: 9.43e+07 -1.3961507081985474 0.07156495749950409\n",
      "[Step 23720] Loss: 9.45e+07 -1.3960496187210083 0.0715567022562027\n",
      "[Step 23721] Loss: 9.41e+07 -1.3959606885910034 0.07155340164899826\n",
      "[Step 23722] Loss: 9.34e+07 -1.39584219455719 0.07156247645616531\n",
      "[Step 23723] Loss: 9.39e+07 -1.3956942558288574 0.07155505567789078\n",
      "[Step 23724] Loss: 9.47e+07 -1.3956981897354126 0.07154349982738495\n",
      "[Step 23725] Loss: 9.44e+07 -1.3957383632659912 0.07153195142745972\n",
      "[Step 23726] Loss: 9.36e+07 -1.39573335647583 0.0715261697769165\n",
      "[Step 23727] Loss: 9.40e+07 -1.3957356214523315 0.07152039557695389\n",
      "[Step 23728] Loss: 9.44e+07 -1.3957154750823975 0.0715121477842331\n",
      "[Step 23729] Loss: 9.41e+07 -1.3957037925720215 0.07149481773376465\n",
      "[Step 23730] Loss: 9.43e+07 -1.3957678079605103 0.07148656249046326\n",
      "[Step 23731] Loss: 9.43e+07 -1.395786166191101 0.07148326188325882\n",
      "[Step 23732] Loss: 9.43e+07 -1.3957629203796387 0.0714774876832962\n",
      "[Step 23733] Loss: 9.54e+07 -1.3955882787704468 0.07148244231939316\n",
      "[Step 23734] Loss: 9.44e+07 -1.3953582048416138 0.07146346569061279\n",
      "[Step 23735] Loss: 9.43e+07 -1.3952078819274902 0.07146346569061279\n",
      "[Step 23736] Loss: 9.37e+07 -1.39497709274292 0.07147996872663498\n",
      "[Step 23737] Loss: 9.49e+07 -1.3949986696243286 0.07147501409053802\n",
      "[Step 23738] Loss: 9.32e+07 -1.395013689994812 0.07146841287612915\n",
      "[Step 23739] Loss: 9.39e+07 -1.39508855342865 0.07143457978963852\n",
      "[Step 23740] Loss: 9.36e+07 -1.3951458930969238 0.07141890376806259\n",
      "[Step 23741] Loss: 9.39e+07 -1.395230770111084 0.07140487432479858\n",
      "[Step 23742] Loss: 9.39e+07 -1.3951644897460938 0.07139910012483597\n",
      "[Step 23743] Loss: 9.41e+07 -1.3950190544128418 0.07140900194644928\n",
      "[Step 23744] Loss: 9.40e+07 -1.3948485851287842 0.07139910012483597\n",
      "[Step 23745] Loss: 9.39e+07 -1.3946911096572876 0.07140075415372849\n",
      "[Step 23746] Loss: 9.52e+07 -1.3944518566131592 0.07140900194644928\n",
      "[Step 23747] Loss: 9.44e+07 -1.3941423892974854 0.0714147761464119\n",
      "[Step 23748] Loss: 9.39e+07 -1.3938809633255005 0.07142797857522964\n",
      "[Step 23749] Loss: 9.46e+07 -1.3936676979064941 0.0714288055896759\n",
      "[Step 23750] Loss: 9.49e+07 -1.3933390378952026 0.07144943624734879\n",
      "[Step 23751] Loss: 9.45e+07 -1.3929879665374756 0.07147171348333359\n",
      "[Step 23752] Loss: 9.41e+07 -1.3925979137420654 0.07150059193372726\n",
      "[Step 23753] Loss: 9.39e+07 -1.3921740055084229 0.07152286916971207\n",
      "[Step 23754] Loss: 9.40e+07 -1.3917845487594604 0.07155752927064896\n",
      "[Step 23755] Loss: 9.38e+07 -1.3913897275924683 0.07156660407781601\n",
      "[Step 23756] Loss: 9.56e+07 -1.3912198543548584 0.07159135490655899\n",
      "[Step 23757] Loss: 9.43e+07 -1.3911341428756714 0.07159383594989777\n",
      "[Step 23758] Loss: 9.39e+07 -1.3910757303237915 0.07158063352108002\n",
      "[Step 23759] Loss: 9.38e+07 -1.3910027742385864 0.07158970832824707\n",
      "[Step 23760] Loss: 9.53e+07 -1.3911188840866089 0.07157403230667114\n",
      "[Step 23761] Loss: 9.42e+07 -1.3913193941116333 0.07155835628509521\n",
      "[Step 23762] Loss: 9.43e+07 -1.3914250135421753 0.07155010104179382\n",
      "[Step 23763] Loss: 9.37e+07 -1.3915807008743286 0.07153855264186859\n",
      "[Step 23764] Loss: 9.40e+07 -1.3917299509048462 0.07153277099132538\n",
      "[Step 23765] Loss: 9.42e+07 -1.3917609453201294 0.07153855264186859\n",
      "[Step 23766] Loss: 9.47e+07 -1.3917880058288574 0.07153112441301346\n",
      "[Step 23767] Loss: 9.41e+07 -1.3918765783309937 0.07153525203466415\n",
      "[Step 23768] Loss: 9.45e+07 -1.3918639421463013 0.07154680043458939\n",
      "[Step 23769] Loss: 9.42e+07 -1.3918428421020508 0.07156000286340714\n",
      "[Step 23770] Loss: 9.41e+07 -1.3917051553726196 0.07157403230667114\n",
      "[Step 23771] Loss: 9.42e+07 -1.3916141986846924 0.07159383594989777\n",
      "[Step 23772] Loss: 9.49e+07 -1.3913801908493042 0.07161694020032883\n",
      "[Step 23773] Loss: 9.44e+07 -1.3911495208740234 0.07164746522903442\n",
      "[Step 23774] Loss: 9.43e+07 -1.3908766508102417 0.07166726887226105\n",
      "[Step 23775] Loss: 9.37e+07 -1.390578031539917 0.07168872654438019\n",
      "[Step 23776] Loss: 9.50e+07 -1.3903969526290894 0.07170853018760681\n",
      "[Step 23777] Loss: 9.45e+07 -1.3902183771133423 0.07172585278749466\n",
      "[Step 23778] Loss: 9.45e+07 -1.390194058418274 0.07175225764513016\n",
      "[Step 23779] Loss: 9.39e+07 -1.3902257680892944 0.07174648344516754\n",
      "[Step 23780] Loss: 9.53e+07 -1.3901348114013672 0.07176464051008224\n",
      "[Step 23781] Loss: 9.40e+07 -1.3899799585342407 0.07177454233169556\n",
      "[Step 23782] Loss: 9.53e+07 -1.3897228240966797 0.07179433852434158\n",
      "[Step 23783] Loss: 9.38e+07 -1.3895065784454346 0.07180589437484741\n",
      "[Step 23784] Loss: 9.38e+07 -1.389243483543396 0.07182074338197708\n",
      "[Step 23785] Loss: 9.45e+07 -1.3890023231506348 0.07182569801807404\n",
      "[Step 23786] Loss: 9.38e+07 -1.3888254165649414 0.07185127586126328\n",
      "[Step 23787] Loss: 9.41e+07 -1.3886715173721313 0.07187438011169434\n",
      "[Step 23788] Loss: 9.50e+07 -1.3886626958847046 0.07188098132610321\n",
      "[Step 23789] Loss: 9.46e+07 -1.3885748386383057 0.07189418375492096\n",
      "[Step 23790] Loss: 9.49e+07 -1.3883554935455322 0.07191811501979828\n",
      "[Step 23791] Loss: 9.68e+07 -1.3886213302612305 0.07191728800535202\n",
      "[Step 23792] Loss: 9.55e+07 -1.389095425605774 0.07190408557653427\n",
      "[Step 23793] Loss: 9.36e+07 -1.3895509243011475 0.07187768071889877\n",
      "[Step 23794] Loss: 9.35e+07 -1.389880895614624 0.07185374945402145\n",
      "[Step 23795] Loss: 9.45e+07 -1.3901151418685913 0.07183890044689178\n",
      "[Step 23796] Loss: 9.39e+07 -1.3903188705444336 0.07183229923248291\n",
      "[Step 23797] Loss: 9.46e+07 -1.3906782865524292 0.07179929316043854\n",
      "[Step 23798] Loss: 9.63e+07 -1.3913567066192627 0.07175061106681824\n",
      "[Step 23799] Loss: 9.47e+07 -1.3919360637664795 0.07170770317316055\n",
      "[Step 23800] Loss: 9.41e+07 -1.3924072980880737 0.07168707251548767\n",
      "[Step 23801] Loss: 9.44e+07 -1.3927617073059082 0.07167056947946548\n",
      "[Step 23802] Loss: 9.42e+07 -1.3930325508117676 0.07165654748678207\n",
      "[Step 23803] Loss: 9.42e+07 -1.393343448638916 0.0716499462723732\n",
      "[Step 23804] Loss: 9.40e+07 -1.393510103225708 0.07164251804351807\n",
      "[Step 23805] Loss: 9.48e+07 -1.3938286304473877 0.07162601500749588\n",
      "[Step 23806] Loss: 9.36e+07 -1.3941402435302734 0.07160703837871552\n",
      "[Step 23807] Loss: 9.33e+07 -1.3944315910339355 0.07158970832824707\n",
      "[Step 23808] Loss: 9.43e+07 -1.3946982622146606 0.07157237827777863\n",
      "[Step 23809] Loss: 9.38e+07 -1.3949251174926758 0.07155340164899826\n",
      "[Step 23810] Loss: 9.43e+07 -1.3950883150100708 0.07153689861297607\n",
      "[Step 23811] Loss: 9.62e+07 -1.395044207572937 0.07154102623462677\n",
      "[Step 23812] Loss: 9.41e+07 -1.395070195198059 0.071552574634552\n",
      "[Step 23813] Loss: 9.41e+07 -1.3950283527374268 0.07154927402734756\n",
      "[Step 23814] Loss: 9.50e+07 -1.3950566053390503 0.07153937220573425\n",
      "[Step 23815] Loss: 9.43e+07 -1.3951092958450317 0.07154267281293869\n",
      "[Step 23816] Loss: 9.40e+07 -1.3951160907745361 0.07154515385627747\n",
      "[Step 23817] Loss: 9.40e+07 -1.3950241804122925 0.07154597342014313\n",
      "[Step 23818] Loss: 9.36e+07 -1.3949698209762573 0.07155010104179382\n",
      "[Step 23819] Loss: 9.46e+07 -1.3949167728424072 0.07155422866344452\n",
      "[Step 23820] Loss: 9.51e+07 -1.3949460983276367 0.07155422866344452\n",
      "[Step 23821] Loss: 9.46e+07 -1.3951131105422974 0.07154515385627747\n",
      "[Step 23822] Loss: 9.65e+07 -1.3957061767578125 0.07150306552648544\n",
      "[Step 23823] Loss: 9.72e+07 -1.3968082666397095 0.07141973078250885\n",
      "[Step 23824] Loss: 9.45e+07 -1.3977100849151611 0.07136114686727524\n",
      "[Step 23825] Loss: 9.46e+07 -1.398403525352478 0.0713273137807846\n",
      "[Step 23826] Loss: 9.42e+07 -1.3989347219467163 0.071282759308815\n",
      "[Step 23827] Loss: 9.36e+07 -1.3995037078857422 0.07123737782239914\n",
      "[Step 23828] Loss: 9.38e+07 -1.3999700546264648 0.07121757417917252\n",
      "[Step 23829] Loss: 9.39e+07 -1.4004181623458862 0.07118868827819824\n",
      "[Step 23830] Loss: 9.47e+07 -1.4009960889816284 0.07114990800619125\n",
      "[Step 23831] Loss: 9.51e+07 -1.4014134407043457 0.07112350314855576\n",
      "[Step 23832] Loss: 9.37e+07 -1.4018094539642334 0.07110122591257095\n",
      "[Step 23833] Loss: 9.35e+07 -1.4021408557891846 0.07109132409095764\n",
      "[Step 23834] Loss: 9.44e+07 -1.4023748636245728 0.07107729464769363\n",
      "[Step 23835] Loss: 9.34e+07 -1.4026397466659546 0.07104676961898804\n",
      "[Step 23836] Loss: 9.40e+07 -1.4029806852340698 0.07102201133966446\n",
      "[Step 23837] Loss: 9.46e+07 -1.4034004211425781 0.07097828388214111\n",
      "[Step 23838] Loss: 9.40e+07 -1.4037501811981201 0.07096755504608154\n",
      "[Step 23839] Loss: 9.42e+07 -1.4040186405181885 0.07094032317399979\n",
      "[Step 23840] Loss: 9.40e+07 -1.404307246208191 0.07092217355966568\n",
      "[Step 23841] Loss: 9.38e+07 -1.4046047925949097 0.0709015429019928\n",
      "[Step 23842] Loss: 9.39e+07 -1.4048545360565186 0.07088091224431992\n",
      "[Step 23843] Loss: 9.60e+07 -1.4054481983184814 0.07081655412912369\n",
      "[Step 23844] Loss: 9.56e+07 -1.4058138132095337 0.07079097628593445\n",
      "[Step 23845] Loss: 9.47e+07 -1.40614652633667 0.07077199965715408\n",
      "[Step 23846] Loss: 9.45e+07 -1.4063551425933838 0.07075219601392746\n",
      "[Step 23847] Loss: 9.65e+07 -1.4069072008132935 0.07071918994188309\n",
      "[Step 23848] Loss: 9.40e+07 -1.4074053764343262 0.07069195806980133\n",
      "[Step 23849] Loss: 9.43e+07 -1.4078845977783203 0.07067710906267166\n",
      "[Step 23850] Loss: 9.42e+07 -1.4083043336868286 0.07064740359783173\n",
      "[Step 23851] Loss: 9.51e+07 -1.4086015224456787 0.07063254714012146\n",
      "[Step 23852] Loss: 9.37e+07 -1.4087884426116943 0.07061852514743805\n",
      "[Step 23853] Loss: 9.39e+07 -1.4088391065597534 0.07063420116901398\n",
      "[Step 23854] Loss: 9.37e+07 -1.4088621139526367 0.07062182575464249\n",
      "[Step 23855] Loss: 9.37e+07 -1.4089738130569458 0.07060614228248596\n",
      "[Step 23856] Loss: 9.41e+07 -1.409091591835022 0.07060449570417404\n",
      "[Step 23857] Loss: 9.41e+07 -1.4091674089431763 0.07060036808252335\n",
      "[Step 23858] Loss: 9.42e+07 -1.4092925786972046 0.07058386504650116\n",
      "[Step 23859] Loss: 9.40e+07 -1.4094222784042358 0.07057313621044159\n",
      "[Step 23860] Loss: 9.37e+07 -1.4094982147216797 0.07056406140327454\n",
      "[Step 23861] Loss: 9.44e+07 -1.4096530675888062 0.07055415958166122\n",
      "[Step 23862] Loss: 9.52e+07 -1.4100369215011597 0.07053518295288086\n",
      "[Step 23863] Loss: 9.45e+07 -1.410457968711853 0.07048072665929794\n",
      "[Step 23864] Loss: 9.45e+07 -1.4108963012695312 0.07046092301607132\n",
      "[Step 23865] Loss: 9.47e+07 -1.4113476276397705 0.07041388750076294\n",
      "[Step 23866] Loss: 9.39e+07 -1.4116491079330444 0.07039491087198257\n",
      "[Step 23867] Loss: 9.41e+07 -1.4118688106536865 0.07037593424320221\n",
      "[Step 23868] Loss: 9.43e+07 -1.4120635986328125 0.07035117596387863\n",
      "[Step 23869] Loss: 9.49e+07 -1.4120813608169556 0.07034540176391602\n",
      "[Step 23870] Loss: 9.46e+07 -1.412122130393982 0.07034127414226532\n",
      "[Step 23871] Loss: 9.40e+07 -1.412192463874817 0.07031982392072678\n",
      "[Step 23872] Loss: 9.40e+07 -1.412248969078064 0.07031074911355972\n",
      "[Step 23873] Loss: 9.37e+07 -1.4122835397720337 0.07030826807022095\n",
      "[Step 23874] Loss: 9.43e+07 -1.4122097492218018 0.07031404972076416\n",
      "[Step 23875] Loss: 9.48e+07 -1.4120525121688843 0.07031569629907608\n",
      "[Step 23876] Loss: 9.48e+07 -1.4117201566696167 0.07035364955663681\n",
      "[Step 23877] Loss: 9.47e+07 -1.4114186763763428 0.07038748264312744\n",
      "[Step 23878] Loss: 9.42e+07 -1.4109838008880615 0.07042214274406433\n",
      "[Step 23879] Loss: 9.52e+07 -1.4104385375976562 0.07044936716556549\n",
      "[Step 23880] Loss: 9.58e+07 -1.4098061323165894 0.07049474865198135\n",
      "[Step 23881] Loss: 9.37e+07 -1.409224033355713 0.07052198052406311\n",
      "[Step 23882] Loss: 9.44e+07 -1.4086970090866089 0.07057148963212967\n",
      "[Step 23883] Loss: 9.37e+07 -1.4081788063049316 0.07062182575464249\n",
      "[Step 23884] Loss: 9.66e+07 -1.4079973697662354 0.07062512636184692\n",
      "[Step 23885] Loss: 9.49e+07 -1.4078912734985352 0.0706275999546051\n",
      "[Step 23886] Loss: 9.43e+07 -1.4077342748641968 0.0706498771905899\n",
      "[Step 23887] Loss: 9.45e+07 -1.4075771570205688 0.07065482437610626\n",
      "[Step 23888] Loss: 9.35e+07 -1.4073865413665771 0.07065317779779434\n",
      "[Step 23889] Loss: 9.39e+07 -1.4071108102798462 0.07066307961940765\n",
      "[Step 23890] Loss: 9.48e+07 -1.4070488214492798 0.0706622526049614\n",
      "[Step 23891] Loss: 9.43e+07 -1.4068825244903564 0.07065235078334808\n",
      "[Step 23892] Loss: 9.41e+07 -1.4067373275756836 0.07067050784826279\n",
      "[Step 23893] Loss: 9.42e+07 -1.4066416025161743 0.07065235078334808\n",
      "[Step 23894] Loss: 9.36e+07 -1.4065688848495483 0.07065317779779434\n",
      "[Step 23895] Loss: 9.37e+07 -1.4064849615097046 0.07062017172574997\n",
      "[Step 23896] Loss: 9.39e+07 -1.4063889980316162 0.07061026990413666\n",
      "[Step 23897] Loss: 9.42e+07 -1.4061557054519653 0.07061687111854553\n",
      "[Step 23898] Loss: 9.44e+07 -1.4058594703674316 0.07062842696905136\n",
      "[Step 23899] Loss: 9.39e+07 -1.405508041381836 0.0706358477473259\n",
      "[Step 23900] Loss: 9.45e+07 -1.405106544494629 0.07066638022661209\n",
      "[Step 23901] Loss: 9.32e+07 -1.4046639204025269 0.0706804096698761\n",
      "[Step 23902] Loss: 9.34e+07 -1.4042139053344727 0.07067875564098358\n",
      "[Step 23903] Loss: 9.42e+07 -1.4039453268051147 0.07068205624818802\n",
      "[Step 23904] Loss: 9.76e+07 -1.404236078262329 0.07065895199775696\n",
      "[Step 23905] Loss: 9.43e+07 -1.4044002294540405 0.07064410299062729\n",
      "[Step 23906] Loss: 9.40e+07 -1.4045062065124512 0.07062924653291702\n",
      "[Step 23907] Loss: 9.46e+07 -1.4045852422714233 0.07062099874019623\n",
      "[Step 23908] Loss: 9.43e+07 -1.4047120809555054 0.07062099874019623\n",
      "[Step 23909] Loss: 9.75e+07 -1.4053564071655273 0.0705789178609848\n",
      "[Step 23910] Loss: 9.40e+07 -1.4058301448822021 0.07054343819618225\n",
      "[Step 23911] Loss: 9.69e+07 -1.4067775011062622 0.07047082483768463\n",
      "[Step 23912] Loss: 9.51e+07 -1.4075366258621216 0.07040811330080032\n",
      "[Step 23913] Loss: 9.45e+07 -1.408296823501587 0.07036355137825012\n",
      "[Step 23914] Loss: 9.45e+07 -1.408905029296875 0.07031652331352234\n",
      "[Step 23915] Loss: 9.42e+07 -1.4094291925430298 0.07028929144144058\n",
      "[Step 23916] Loss: 9.39e+07 -1.4098570346832275 0.07025545835494995\n",
      "[Step 23917] Loss: 9.41e+07 -1.4102323055267334 0.0702158585190773\n",
      "[Step 23918] Loss: 9.46e+07 -1.4104284048080444 0.07022163271903992\n",
      "[Step 23919] Loss: 9.38e+07 -1.4106428623199463 0.07021255791187286\n",
      "[Step 23920] Loss: 9.44e+07 -1.4108457565307617 0.07020100206136703\n",
      "[Step 23921] Loss: 9.49e+07 -1.4111822843551636 0.07019440084695816\n",
      "[Step 23922] Loss: 9.39e+07 -1.4114348888397217 0.07017955183982849\n",
      "[Step 23923] Loss: 9.46e+07 -1.4117790460586548 0.0701630488038063\n",
      "[Step 23924] Loss: 9.47e+07 -1.4119346141815186 0.07015974819660187\n",
      "[Step 23925] Loss: 9.44e+07 -1.4119930267333984 0.07017046958208084\n",
      "[Step 23926] Loss: 9.46e+07 -1.411933422088623 0.07018615305423737\n",
      "[Step 23927] Loss: 9.43e+07 -1.411838173866272 0.07019687443971634\n",
      "[Step 23928] Loss: 9.39e+07 -1.4116703271865845 0.07021007686853409\n",
      "[Step 23929] Loss: 9.46e+07 -1.4113528728485107 0.0702422559261322\n",
      "[Step 23930] Loss: 9.56e+07 -1.4113048315048218 0.07026701420545578\n",
      "[Step 23931] Loss: 9.47e+07 -1.4113601446151733 0.07026124000549316\n",
      "[Step 23932] Loss: 9.61e+07 -1.4117355346679688 0.07023978233337402\n",
      "[Step 23933] Loss: 9.37e+07 -1.4120664596557617 0.0702241063117981\n",
      "[Step 23934] Loss: 9.40e+07 -1.4122780561447144 0.0702158585190773\n",
      "[Step 23935] Loss: 9.39e+07 -1.4124960899353027 0.07021337747573853\n",
      "[Step 23936] Loss: 9.42e+07 -1.4127143621444702 0.07020677626132965\n",
      "[Step 23937] Loss: 9.54e+07 -1.4131871461868286 0.07017707079648972\n",
      "[Step 23938] Loss: 9.60e+07 -1.413998007774353 0.07011766731739044\n",
      "[Step 23939] Loss: 9.40e+07 -1.4146740436553955 0.07006897777318954\n",
      "[Step 23940] Loss: 9.41e+07 -1.4151270389556885 0.07002277672290802\n",
      "[Step 23941] Loss: 9.42e+07 -1.415525197982788 0.07000131905078888\n",
      "[Step 23942] Loss: 9.40e+07 -1.415732502937317 0.07001204788684845\n",
      "[Step 23943] Loss: 9.32e+07 -1.4158775806427002 0.06999141722917557\n",
      "[Step 23944] Loss: 9.49e+07 -1.4161217212677002 0.06997491419315338\n",
      "[Step 23945] Loss: 9.40e+07 -1.416224479675293 0.06996088474988937\n",
      "[Step 23946] Loss: 9.44e+07 -1.416454553604126 0.06995676457881927\n",
      "[Step 23947] Loss: 9.36e+07 -1.4165806770324707 0.06995180994272232\n",
      "[Step 23948] Loss: 9.41e+07 -1.4167333841323853 0.0699542835354805\n",
      "[Step 23949] Loss: 9.40e+07 -1.416794776916504 0.06994108110666275\n",
      "[Step 23950] Loss: 9.41e+07 -1.416754961013794 0.06992870569229126\n",
      "[Step 23951] Loss: 9.38e+07 -1.4166463613510132 0.06993447989225388\n",
      "[Step 23952] Loss: 9.44e+07 -1.4165687561035156 0.06993613392114639\n",
      "[Step 23953] Loss: 9.41e+07 -1.4164179563522339 0.06994850933551788\n",
      "[Step 23954] Loss: 9.51e+07 -1.416550636291504 0.06993943452835083\n",
      "[Step 23955] Loss: 9.40e+07 -1.4166315793991089 0.06992705911397934\n",
      "[Step 23956] Loss: 9.40e+07 -1.4166076183319092 0.06993035972118378\n",
      "[Step 23957] Loss: 9.41e+07 -1.416570782661438 0.0699196308851242\n",
      "[Step 23958] Loss: 9.41e+07 -1.4165173768997192 0.06991468369960785\n",
      "[Step 23959] Loss: 9.42e+07 -1.4163930416107178 0.06991138309240341\n",
      "[Step 23960] Loss: 9.50e+07 -1.4161897897720337 0.06992210447788239\n",
      "[Step 23961] Loss: 9.40e+07 -1.4159867763519287 0.06994438171386719\n",
      "[Step 23962] Loss: 9.47e+07 -1.4159437417984009 0.06995593756437302\n",
      "[Step 23963] Loss: 9.44e+07 -1.4157928228378296 0.06995263695716858\n",
      "[Step 23964] Loss: 9.46e+07 -1.4156063795089722 0.06995593756437302\n",
      "[Step 23965] Loss: 9.50e+07 -1.415379524230957 0.06995758414268494\n",
      "[Step 23966] Loss: 9.48e+07 -1.4151180982589722 0.06996583938598633\n",
      "[Step 23967] Loss: 9.47e+07 -1.4147870540618896 0.0699724406003952\n",
      "[Step 23968] Loss: 9.43e+07 -1.4144916534423828 0.0699683129787445\n",
      "[Step 23969] Loss: 9.47e+07 -1.4141180515289307 0.06999224424362183\n",
      "[Step 23970] Loss: 9.43e+07 -1.4137338399887085 0.07002029567956924\n",
      "[Step 23971] Loss: 9.41e+07 -1.4133788347244263 0.07005000114440918\n",
      "[Step 23972] Loss: 9.44e+07 -1.4129313230514526 0.07008878141641617\n",
      "[Step 23973] Loss: 9.48e+07 -1.4123761653900146 0.07011766731739044\n",
      "[Step 23974] Loss: 9.38e+07 -1.411903977394104 0.07014654576778412\n",
      "[Step 23975] Loss: 9.42e+07 -1.411503553390503 0.07017872482538223\n",
      "[Step 23976] Loss: 9.43e+07 -1.4112117290496826 0.0701935738325119\n",
      "[Step 23977] Loss: 9.44e+07 -1.410892128944397 0.07024060934782028\n",
      "[Step 23978] Loss: 9.37e+07 -1.4105257987976074 0.07027691602706909\n",
      "[Step 23979] Loss: 9.39e+07 -1.4101510047912598 0.07030992209911346\n",
      "[Step 23980] Loss: 9.52e+07 -1.410003900527954 0.0703132227063179\n",
      "[Step 23981] Loss: 9.40e+07 -1.4099072217941284 0.07030662149190903\n",
      "[Step 23982] Loss: 9.43e+07 -1.409909725189209 0.07029259204864502\n",
      "[Step 23983] Loss: 9.34e+07 -1.4098318815231323 0.07030496746301651\n",
      "[Step 23984] Loss: 9.45e+07 -1.4096767902374268 0.07031652331352234\n",
      "[Step 23985] Loss: 9.46e+07 -1.4095138311386108 0.07032642513513565\n",
      "[Step 23986] Loss: 9.48e+07 -1.4092249870300293 0.07033219933509827\n",
      "[Step 23987] Loss: 9.36e+07 -1.4089277982711792 0.07035860419273376\n",
      "[Step 23988] Loss: 9.47e+07 -1.4086332321166992 0.07038583606481552\n",
      "[Step 23989] Loss: 9.36e+07 -1.4083887338638306 0.07040728628635406\n",
      "[Step 23990] Loss: 9.43e+07 -1.4081714153289795 0.07042131572961807\n",
      "[Step 23991] Loss: 9.43e+07 -1.4078940153121948 0.07044194638729095\n",
      "[Step 23992] Loss: 9.45e+07 -1.4077975749969482 0.07044689357280731\n",
      "[Step 23993] Loss: 9.42e+07 -1.4077239036560059 0.07044606655836105\n",
      "[Step 23994] Loss: 9.42e+07 -1.4075913429260254 0.07046009600162506\n",
      "[Step 23995] Loss: 9.39e+07 -1.4075353145599365 0.07047082483768463\n",
      "[Step 23996] Loss: 9.41e+07 -1.4073785543441772 0.07046587020158768\n",
      "[Step 23997] Loss: 9.43e+07 -1.4071241617202759 0.07049557566642761\n",
      "[Step 23998] Loss: 9.39e+07 -1.4068448543548584 0.07051043212413788\n",
      "[Step 23999] Loss: 9.46e+07 -1.4067147970199585 0.0705162063241005\n",
      "[Step 24000] Loss: 9.49e+07 -1.4065072536468506 0.07054178416728973\n",
      "[Step 24001] Loss: 9.39e+07 -1.4063159227371216 0.07055415958166122\n",
      "[Step 24002] Loss: 9.38e+07 -1.4061295986175537 0.07056653499603271\n",
      "[Step 24003] Loss: 9.46e+07 -1.4060131311416626 0.07057148963212967\n",
      "[Step 24004] Loss: 9.78e+07 -1.4064204692840576 0.07055168598890305\n",
      "[Step 24005] Loss: 9.47e+07 -1.4066747426986694 0.07052858173847198\n",
      "[Step 24006] Loss: 9.32e+07 -1.4068667888641357 0.0705302357673645\n",
      "[Step 24007] Loss: 9.41e+07 -1.40703547000885 0.07052775472402573\n",
      "[Step 24008] Loss: 9.35e+07 -1.4071534872055054 0.07052445411682129\n",
      "[Step 24009] Loss: 9.42e+07 -1.407304286956787 0.07052198052406311\n",
      "[Step 24010] Loss: 9.39e+07 -1.4074974060058594 0.07050630450248718\n",
      "[Step 24011] Loss: 9.40e+07 -1.4075977802276611 0.07049392908811569\n",
      "[Step 24012] Loss: 9.38e+07 -1.4077478647232056 0.07048320025205612\n",
      "[Step 24013] Loss: 9.36e+07 -1.4078917503356934 0.07046009600162506\n",
      "[Step 24014] Loss: 9.41e+07 -1.4080402851104736 0.07046669721603394\n",
      "[Step 24015] Loss: 9.40e+07 -1.4081817865371704 0.07048072665929794\n",
      "[Step 24016] Loss: 9.41e+07 -1.4084172248840332 0.07048484683036804\n",
      "[Step 24017] Loss: 9.43e+07 -1.408637523651123 0.07046422362327576\n",
      "[Step 24018] Loss: 9.37e+07 -1.4088728427886963 0.07044029235839844\n",
      "[Step 24019] Loss: 9.45e+07 -1.4089818000793457 0.07043369114398956\n",
      "[Step 24020] Loss: 9.44e+07 -1.4092613458633423 0.07041718810796738\n",
      "[Step 24021] Loss: 9.38e+07 -1.409536361694336 0.07041718810796738\n",
      "[Step 24022] Loss: 9.48e+07 -1.40973961353302 0.07040894031524658\n",
      "[Step 24023] Loss: 9.40e+07 -1.409944772720337 0.0703965574502945\n",
      "[Step 24024] Loss: 9.55e+07 -1.410378336906433 0.0703619047999382\n",
      "[Step 24025] Loss: 9.42e+07 -1.4107812643051147 0.07030579447746277\n",
      "[Step 24026] Loss: 9.36e+07 -1.411130428314209 0.07027196139097214\n",
      "[Step 24027] Loss: 9.40e+07 -1.4113715887069702 0.07026288658380508\n",
      "[Step 24028] Loss: 9.47e+07 -1.4114642143249512 0.07024885714054108\n",
      "[Step 24029] Loss: 9.42e+07 -1.4116265773773193 0.07024143636226654\n",
      "[Step 24030] Loss: 9.43e+07 -1.4118120670318604 0.07024308294057846\n",
      "[Step 24031] Loss: 9.39e+07 -1.4119430780410767 0.07023895531892776\n",
      "[Step 24032] Loss: 9.37e+07 -1.4120879173278809 0.07023153454065323\n",
      "[Step 24033] Loss: 9.44e+07 -1.412221908569336 0.07022327929735184\n",
      "[Step 24034] Loss: 9.35e+07 -1.4122328758239746 0.07021420449018478\n",
      "[Step 24035] Loss: 9.45e+07 -1.4121733903884888 0.07021337747573853\n",
      "[Step 24036] Loss: 9.53e+07 -1.4122819900512695 0.07021007686853409\n",
      "[Step 24037] Loss: 9.43e+07 -1.4124512672424316 0.0701977014541626\n",
      "[Step 24038] Loss: 9.45e+07 -1.412596344947815 0.07017789781093597\n",
      "[Step 24039] Loss: 9.63e+07 -1.4130592346191406 0.07013994455337524\n",
      "[Step 24040] Loss: 9.36e+07 -1.4134712219238281 0.07012756913900375\n",
      "[Step 24041] Loss: 9.50e+07 -1.4136425256729126 0.07010281085968018\n",
      "[Step 24042] Loss: 9.45e+07 -1.4137635231018066 0.07009868323802948\n",
      "[Step 24043] Loss: 9.42e+07 -1.413849115371704 0.07009868323802948\n",
      "[Step 24044] Loss: 9.44e+07 -1.4139214754104614 0.070100337266922\n",
      "[Step 24045] Loss: 9.51e+07 -1.4138916730880737 0.07011106610298157\n",
      "[Step 24046] Loss: 9.56e+07 -1.4142067432403564 0.07008960843086243\n",
      "[Step 24047] Loss: 9.46e+07 -1.4145560264587402 0.07006567716598511\n",
      "[Step 24048] Loss: 9.45e+07 -1.414983868598938 0.07003019750118256\n",
      "[Step 24049] Loss: 9.40e+07 -1.4153600931167603 0.07000627368688583\n",
      "[Step 24050] Loss: 9.38e+07 -1.4156944751739502 0.0699724406003952\n",
      "[Step 24051] Loss: 9.50e+07 -1.4158611297607422 0.06995923817157745\n",
      "[Step 24052] Loss: 9.38e+07 -1.4159276485443115 0.06995098292827606\n",
      "[Step 24053] Loss: 9.40e+07 -1.416018009185791 0.0699460357427597\n",
      "[Step 24054] Loss: 9.47e+07 -1.4161211252212524 0.06993613392114639\n",
      "[Step 24055] Loss: 9.42e+07 -1.4161633253097534 0.06992870569229126\n",
      "[Step 24056] Loss: 9.46e+07 -1.4161162376403809 0.06992705911397934\n",
      "[Step 24057] Loss: 9.41e+07 -1.4160231351852417 0.06993778049945831\n",
      "[Step 24058] Loss: 9.43e+07 -1.4159009456634521 0.06995511054992676\n",
      "[Step 24059] Loss: 9.48e+07 -1.4156430959701538 0.06997491419315338\n",
      "[Step 24060] Loss: 9.41e+07 -1.4153681993484497 0.07000544667243958\n",
      "[Step 24061] Loss: 9.41e+07 -1.4150853157043457 0.07003515213727951\n",
      "[Step 24062] Loss: 9.43e+07 -1.4148417711257935 0.07005412876605988\n",
      "[Step 24063] Loss: 9.42e+07 -1.414529800415039 0.07006485760211945\n",
      "[Step 24064] Loss: 9.43e+07 -1.414226770401001 0.07007227838039398\n",
      "[Step 24065] Loss: 9.41e+07 -1.413958191871643 0.07009373605251312\n",
      "[Step 24066] Loss: 9.51e+07 -1.4138805866241455 0.07009538263082504\n",
      "[Step 24067] Loss: 9.45e+07 -1.4137537479400635 0.07010693848133087\n",
      "[Step 24068] Loss: 9.44e+07 -1.413722276687622 0.07011023908853531\n",
      "[Step 24069] Loss: 9.37e+07 -1.4136518239974976 0.07011271268129349\n",
      "[Step 24070] Loss: 9.41e+07 -1.4136005640029907 0.070114366710186\n",
      "[Step 24071] Loss: 9.41e+07 -1.413560152053833 0.07012838870286942\n",
      "[Step 24072] Loss: 9.41e+07 -1.4135665893554688 0.0701184868812561\n",
      "[Step 24073] Loss: 9.44e+07 -1.413529872894287 0.07011518627405167\n",
      "[Step 24074] Loss: 9.51e+07 -1.4134023189544678 0.0701184868812561\n",
      "[Step 24075] Loss: 9.42e+07 -1.4133045673370361 0.07011601328849792\n",
      "[Step 24076] Loss: 9.46e+07 -1.4133186340332031 0.07008630782365799\n",
      "[Step 24077] Loss: 9.40e+07 -1.4133111238479614 0.07008878141641617\n",
      "[Step 24078] Loss: 9.45e+07 -1.4132978916168213 0.07009290903806686\n",
      "[Step 24079] Loss: 9.42e+07 -1.4134092330932617 0.0700739324092865\n",
      "[Step 24080] Loss: 9.37e+07 -1.4135041236877441 0.07006155699491501\n",
      "[Step 24081] Loss: 9.41e+07 -1.413608193397522 0.07005412876605988\n",
      "[Step 24082] Loss: 9.39e+07 -1.413681149482727 0.07004587352275848\n",
      "[Step 24083] Loss: 9.52e+07 -1.4139554500579834 0.06999801844358444\n",
      "[Step 24084] Loss: 9.38e+07 -1.4141753911972046 0.06998316943645477\n",
      "[Step 24085] Loss: 9.49e+07 -1.4145324230194092 0.06996088474988937\n",
      "[Step 24086] Loss: 9.46e+07 -1.4148248434066772 0.06993035972118378\n",
      "[Step 24087] Loss: 9.53e+07 -1.414933681488037 0.06991385668516159\n",
      "[Step 24088] Loss: 9.46e+07 -1.4150779247283936 0.06988745182752609\n",
      "[Step 24089] Loss: 9.40e+07 -1.4151698350906372 0.06987342238426208\n",
      "[Step 24090] Loss: 9.39e+07 -1.4151942729949951 0.0698750764131546\n",
      "[Step 24091] Loss: 9.40e+07 -1.4151713848114014 0.06988085061311722\n",
      "[Step 24092] Loss: 9.36e+07 -1.4150309562683105 0.06988827884197235\n",
      "[Step 24093] Loss: 9.48e+07 -1.4148187637329102 0.0698833242058754\n",
      "[Step 24094] Loss: 9.36e+07 -1.4145660400390625 0.06990065425634384\n",
      "[Step 24095] Loss: 9.37e+07 -1.4142801761627197 0.06989818066358566\n",
      "[Step 24096] Loss: 9.37e+07 -1.4139755964279175 0.06991055607795715\n",
      "[Step 24097] Loss: 9.43e+07 -1.413520097732544 0.06993035972118378\n",
      "[Step 24098] Loss: 9.40e+07 -1.4130107164382935 0.06996336579322815\n",
      "[Step 24099] Loss: 9.43e+07 -1.4124486446380615 0.07000544667243958\n",
      "[Step 24100] Loss: 9.35e+07 -1.4119185209274292 0.07003679871559143\n",
      "[Step 24101] Loss: 9.47e+07 -1.4114257097244263 0.07007310539484024\n",
      "[Step 24102] Loss: 9.44e+07 -1.4111562967300415 0.07009538263082504\n",
      "[Step 24103] Loss: 9.36e+07 -1.4109259843826294 0.07009951025247574\n",
      "[Step 24104] Loss: 9.39e+07 -1.410815954208374 0.0701184868812561\n",
      "[Step 24105] Loss: 9.41e+07 -1.4107247591018677 0.07013251632452011\n",
      "[Step 24106] Loss: 9.43e+07 -1.4106751680374146 0.07013746351003647\n",
      "[Step 24107] Loss: 9.38e+07 -1.4106324911117554 0.07015231996774673\n",
      "[Step 24108] Loss: 9.44e+07 -1.410611629486084 0.07015644758939743\n",
      "[Step 24109] Loss: 9.46e+07 -1.4106569290161133 0.07015562057495117\n",
      "[Step 24110] Loss: 9.39e+07 -1.4106019735336304 0.07015231996774673\n",
      "[Step 24111] Loss: 9.55e+07 -1.4108165502548218 0.07012591511011124\n",
      "[Step 24112] Loss: 9.42e+07 -1.4109402894973755 0.07012014091014862\n",
      "[Step 24113] Loss: 9.42e+07 -1.4111005067825317 0.07010528445243835\n",
      "[Step 24114] Loss: 9.42e+07 -1.4111456871032715 0.07011271268129349\n",
      "[Step 24115] Loss: 9.49e+07 -1.4110885858535767 0.07010941207408905\n",
      "[Step 24116] Loss: 9.44e+07 -1.4109413623809814 0.07012014091014862\n",
      "[Step 24117] Loss: 9.45e+07 -1.4109183549880981 0.07012838870286942\n",
      "[Step 24118] Loss: 9.38e+07 -1.4108927249908447 0.07014159113168716\n",
      "[Step 24119] Loss: 9.40e+07 -1.4108643531799316 0.07015149295330048\n",
      "[Step 24120] Loss: 9.38e+07 -1.410802960395813 0.07013829052448273\n",
      "[Step 24121] Loss: 9.47e+07 -1.4106402397155762 0.07014654576778412\n",
      "[Step 24122] Loss: 9.33e+07 -1.410487413406372 0.07016139477491379\n",
      "[Step 24123] Loss: 9.42e+07 -1.4103647470474243 0.07018615305423737\n",
      "[Step 24124] Loss: 9.44e+07 -1.4102891683578491 0.07018119841814041\n",
      "[Step 24125] Loss: 9.39e+07 -1.4101980924606323 0.0701712965965271\n",
      "[Step 24126] Loss: 9.41e+07 -1.4100348949432373 0.0701935738325119\n",
      "[Step 24127] Loss: 9.42e+07 -1.4099183082580566 0.07019687443971634\n",
      "[Step 24128] Loss: 9.36e+07 -1.4098143577575684 0.0701977014541626\n",
      "[Step 24129] Loss: 9.46e+07 -1.4095834493637085 0.07022740691900253\n",
      "[Step 24130] Loss: 9.44e+07 -1.4094263315200806 0.07024390995502472\n",
      "[Step 24131] Loss: 9.37e+07 -1.4093029499053955 0.07024060934782028\n",
      "[Step 24132] Loss: 9.63e+07 -1.4095652103424072 0.07022163271903992\n",
      "[Step 24133] Loss: 9.43e+07 -1.4099055528640747 0.0702117308974266\n",
      "[Step 24134] Loss: 9.50e+07 -1.4104697704315186 0.07017789781093597\n",
      "[Step 24135] Loss: 9.43e+07 -1.4110580682754517 0.07013746351003647\n",
      "[Step 24136] Loss: 9.39e+07 -1.411527156829834 0.07012591511011124\n",
      "[Step 24137] Loss: 9.42e+07 -1.411879539489746 0.07010611146688461\n",
      "[Step 24138] Loss: 9.42e+07 -1.4122765064239502 0.07008960843086243\n",
      "[Step 24139] Loss: 9.42e+07 -1.4125919342041016 0.07006320357322693\n",
      "[Step 24140] Loss: 9.43e+07 -1.4128284454345703 0.07004835456609726\n",
      "[Step 24141] Loss: 9.50e+07 -1.4131994247436523 0.07001947611570358\n",
      "[Step 24142] Loss: 9.37e+07 -1.413507342338562 0.07000379264354706\n",
      "[Step 24143] Loss: 9.39e+07 -1.4137028455734253 0.06998316943645477\n",
      "[Step 24144] Loss: 9.41e+07 -1.4138095378875732 0.06997161358594894\n",
      "[Step 24145] Loss: 9.50e+07 -1.4137957096099854 0.069980688393116\n",
      "[Step 24146] Loss: 9.72e+07 -1.4143190383911133 0.06994438171386719\n",
      "[Step 24147] Loss: 9.43e+07 -1.4147286415100098 0.06992293149232864\n",
      "[Step 24148] Loss: 9.42e+07 -1.4150866270065308 0.06990725547075272\n",
      "[Step 24149] Loss: 9.34e+07 -1.4153820276260376 0.06988249719142914\n",
      "[Step 24150] Loss: 9.41e+07 -1.415730357170105 0.06985527276992798\n",
      "[Step 24151] Loss: 9.42e+07 -1.4162005186080933 0.06981896609067917\n",
      "[Step 24152] Loss: 9.41e+07 -1.4166072607040405 0.06978430598974228\n",
      "[Step 24153] Loss: 9.37e+07 -1.416967749595642 0.06977110356092453\n",
      "[Step 24154] Loss: 9.47e+07 -1.4171960353851318 0.06976615637540817\n",
      "[Step 24155] Loss: 9.38e+07 -1.4173505306243896 0.0697413980960846\n",
      "[Step 24156] Loss: 9.47e+07 -1.4176260232925415 0.06970921903848648\n",
      "[Step 24157] Loss: 9.44e+07 -1.417895793914795 0.06968364119529724\n",
      "[Step 24158] Loss: 9.44e+07 -1.4181528091430664 0.06964568793773651\n",
      "[Step 24159] Loss: 9.42e+07 -1.4182934761047363 0.06963083148002625\n",
      "[Step 24160] Loss: 9.43e+07 -1.418467402458191 0.06962340325117111\n",
      "[Step 24161] Loss: 9.51e+07 -1.4187374114990234 0.06960195302963257\n",
      "[Step 24162] Loss: 9.36e+07 -1.418920636177063 0.069605253636837\n",
      "[Step 24163] Loss: 9.41e+07 -1.4190871715545654 0.0695871040225029\n",
      "[Step 24164] Loss: 9.42e+07 -1.419158697128296 0.06958050280809402\n",
      "[Step 24165] Loss: 9.41e+07 -1.4192382097244263 0.06958875060081482\n",
      "[Step 24166] Loss: 9.40e+07 -1.4193575382232666 0.06956977397203445\n",
      "[Step 24167] Loss: 9.36e+07 -1.4194327592849731 0.06956151872873306\n",
      "[Step 24168] Loss: 9.48e+07 -1.419371485710144 0.06955409795045853\n",
      "[Step 24169] Loss: 9.42e+07 -1.4193886518478394 0.06954997032880783\n",
      "[Step 24170] Loss: 9.37e+07 -1.4193434715270996 0.06954336911439896\n",
      "[Step 24171] Loss: 9.44e+07 -1.4192157983779907 0.0695425420999527\n",
      "[Step 24172] Loss: 9.48e+07 -1.419227123260498 0.06953181326389313\n",
      "[Step 24173] Loss: 9.39e+07 -1.4191950559616089 0.06954749673604965\n",
      "[Step 24174] Loss: 9.47e+07 -1.419069528579712 0.06954749673604965\n",
      "[Step 24175] Loss: 9.47e+07 -1.4189285039901733 0.06953759491443634\n",
      "[Step 24176] Loss: 9.48e+07 -1.418735146522522 0.06953016668558121\n",
      "[Step 24177] Loss: 9.44e+07 -1.4184751510620117 0.0695425420999527\n",
      "[Step 24178] Loss: 9.47e+07 -1.418320655822754 0.06955574452877045\n",
      "[Step 24179] Loss: 9.49e+07 -1.4180818796157837 0.06957802176475525\n",
      "[Step 24180] Loss: 9.51e+07 -1.4180585145950317 0.06957637518644333\n",
      "[Step 24181] Loss: 9.47e+07 -1.4182031154632568 0.06956234574317932\n",
      "[Step 24182] Loss: 9.43e+07 -1.418339490890503 0.0695648193359375\n",
      "[Step 24183] Loss: 9.50e+07 -1.4183694124221802 0.06956564635038376\n",
      "[Step 24184] Loss: 9.40e+07 -1.4184457063674927 0.06955821812152863\n",
      "[Step 24185] Loss: 9.38e+07 -1.4184329509735107 0.06957307457923889\n",
      "[Step 24186] Loss: 9.45e+07 -1.4184727668762207 0.06957390159368515\n",
      "[Step 24187] Loss: 9.43e+07 -1.4184430837631226 0.06956977397203445\n",
      "[Step 24188] Loss: 9.42e+07 -1.4184011220932007 0.06955821812152863\n",
      "[Step 24189] Loss: 9.39e+07 -1.4183136224746704 0.06956151872873306\n",
      "[Step 24190] Loss: 9.50e+07 -1.4181767702102661 0.06957802176475525\n",
      "[Step 24191] Loss: 9.40e+07 -1.4180618524551392 0.06956811994314194\n",
      "[Step 24192] Loss: 9.64e+07 -1.4182153940200806 0.0695466697216034\n",
      "[Step 24193] Loss: 9.40e+07 -1.4183499813079834 0.06953181326389313\n",
      "[Step 24194] Loss: 9.42e+07 -1.4184273481369019 0.06951119005680084\n",
      "[Step 24195] Loss: 9.46e+07 -1.418392300605774 0.06952109187841415\n",
      "[Step 24196] Loss: 9.73e+07 -1.418899655342102 0.06948313117027283\n",
      "[Step 24197] Loss: 9.42e+07 -1.4193637371063232 0.06945507973432541\n",
      "[Step 24198] Loss: 9.46e+07 -1.4198416471481323 0.06940062344074249\n",
      "[Step 24199] Loss: 9.47e+07 -1.4203294515609741 0.06937339156866074\n",
      "[Step 24200] Loss: 9.41e+07 -1.4206501245498657 0.06936431676149368\n",
      "[Step 24201] Loss: 9.47e+07 -1.42112135887146 0.06932388246059418\n",
      "[Step 24202] Loss: 9.46e+07 -1.4215914011001587 0.06929004937410355\n",
      "[Step 24203] Loss: 9.41e+07 -1.4219989776611328 0.06927354633808136\n",
      "[Step 24204] Loss: 9.51e+07 -1.422218918800354 0.06925539672374725\n",
      "[Step 24205] Loss: 9.67e+07 -1.4229130744934082 0.06923972070217133\n",
      "[Step 24206] Loss: 9.34e+07 -1.4235138893127441 0.06919185817241669\n",
      "[Step 24207] Loss: 9.42e+07 -1.4241834878921509 0.069148950278759\n",
      "[Step 24208] Loss: 9.46e+07 -1.4247081279754639 0.0691184252500534\n",
      "[Step 24209] Loss: 9.42e+07 -1.425178050994873 0.06908459216356277\n",
      "[Step 24210] Loss: 9.47e+07 -1.4254612922668457 0.06907716393470764\n",
      "[Step 24211] Loss: 9.52e+07 -1.4255930185317993 0.0690821185708046\n",
      "[Step 24212] Loss: 9.41e+07 -1.4257428646087646 0.06906561553478241\n",
      "[Step 24213] Loss: 9.48e+07 -1.4259679317474365 0.06904498487710953\n",
      "[Step 24214] Loss: 9.40e+07 -1.4260867834091187 0.06903178244829178\n",
      "[Step 24215] Loss: 9.39e+07 -1.4260979890823364 0.06902765482664108\n",
      "[Step 24216] Loss: 9.72e+07 -1.4266144037246704 0.0689987763762474\n",
      "[Step 24217] Loss: 9.42e+07 -1.4269850254058838 0.06897319853305817\n",
      "[Step 24218] Loss: 9.49e+07 -1.4274455308914185 0.06892286241054535\n",
      "[Step 24219] Loss: 9.57e+07 -1.4281728267669678 0.06887336075305939\n",
      "[Step 24220] Loss: 9.44e+07 -1.4288451671600342 0.06882715225219727\n",
      "[Step 24221] Loss: 9.67e+07 -1.4298813343048096 0.06877021491527557\n",
      "[Step 24222] Loss: 9.54e+07 -1.430665373802185 0.0687289610505104\n",
      "[Step 24223] Loss: 9.31e+07 -1.4313881397247314 0.0686885267496109\n",
      "[Step 24224] Loss: 9.50e+07 -1.4321825504302979 0.06862498819828033\n",
      "[Step 24225] Loss: 9.67e+07 -1.4333726167678833 0.06855732947587967\n",
      "[Step 24226] Loss: 9.39e+07 -1.4344816207885742 0.06848637014627457\n",
      "[Step 24227] Loss: 9.45e+07 -1.435543179512024 0.06842365860939026\n",
      "[Step 24228] Loss: 9.72e+07 -1.4369993209838867 0.06833701580762863\n",
      "[Step 24229] Loss: 9.38e+07 -1.438371181488037 0.0682545080780983\n",
      "[Step 24230] Loss: 9.41e+07 -1.4395924806594849 0.06816951185464859\n",
      "[Step 24231] Loss: 9.40e+07 -1.4405704736709595 0.06812165677547455\n",
      "[Step 24232] Loss: 9.47e+07 -1.4415912628173828 0.06805399805307388\n",
      "[Step 24233] Loss: 9.70e+07 -1.4430288076400757 0.06795992702245712\n",
      "[Step 24234] Loss: 9.40e+07 -1.4443738460540771 0.06787246465682983\n",
      "[Step 24235] Loss: 9.40e+07 -1.4454840421676636 0.06781305372714996\n",
      "[Step 24236] Loss: 9.48e+07 -1.4465805292129517 0.0677412673830986\n",
      "[Step 24237] Loss: 9.37e+07 -1.447507619857788 0.06769011169672012\n",
      "[Step 24238] Loss: 9.45e+07 -1.448239803314209 0.06764473021030426\n",
      "[Step 24239] Loss: 9.46e+07 -1.4489377737045288 0.06759769469499588\n",
      "[Step 24240] Loss: 9.38e+07 -1.449535846710205 0.06755148619413376\n",
      "[Step 24241] Loss: 9.38e+07 -1.4500020742416382 0.0675201341509819\n",
      "[Step 24242] Loss: 9.38e+07 -1.4503618478775024 0.06749537587165833\n",
      "[Step 24243] Loss: 9.45e+07 -1.4505510330200195 0.06747722625732422\n",
      "[Step 24244] Loss: 9.74e+07 -1.4512333869934082 0.0674268901348114\n",
      "[Step 24245] Loss: 9.40e+07 -1.4518921375274658 0.06739966571331024\n",
      "[Step 24246] Loss: 9.39e+07 -1.4524028301239014 0.06736583262681961\n",
      "[Step 24247] Loss: 9.47e+07 -1.4529527425765991 0.06732622534036636\n",
      "[Step 24248] Loss: 9.41e+07 -1.4533931016921997 0.06730064749717712\n",
      "[Step 24249] Loss: 9.45e+07 -1.453750491142273 0.06726681441068649\n",
      "[Step 24250] Loss: 9.44e+07 -1.45400869846344 0.06723463535308838\n",
      "[Step 24251] Loss: 9.60e+07 -1.4540444612503052 0.06723298132419586\n",
      "[Step 24252] Loss: 9.50e+07 -1.4542593955993652 0.06722473353147507\n",
      "[Step 24253] Loss: 9.34e+07 -1.454456090927124 0.06720905750989914\n",
      "[Step 24254] Loss: 9.46e+07 -1.4546395540237427 0.06718595325946808\n",
      "[Step 24255] Loss: 9.35e+07 -1.4548158645629883 0.06718182563781738\n",
      "[Step 24256] Loss: 9.42e+07 -1.4550395011901855 0.06718759983778\n",
      "[Step 24257] Loss: 9.40e+07 -1.4552018642425537 0.06717109680175781\n",
      "[Step 24258] Loss: 9.45e+07 -1.455283761024475 0.06714799255132675\n",
      "[Step 24259] Loss: 9.42e+07 -1.4553611278533936 0.06713727116584778\n",
      "[Step 24260] Loss: 9.41e+07 -1.4554425477981567 0.06713148951530457\n",
      "[Step 24261] Loss: 9.38e+07 -1.4554685354232788 0.06711499392986298\n",
      "[Step 24262] Loss: 9.39e+07 -1.4554424285888672 0.0671306699514389\n",
      "[Step 24263] Loss: 9.38e+07 -1.4553409814834595 0.06714139133691788\n",
      "[Step 24264] Loss: 9.43e+07 -1.4551360607147217 0.0671611949801445\n",
      "[Step 24265] Loss: 9.45e+07 -1.4548419713974 0.06716945022344589\n",
      "[Step 24266] Loss: 9.39e+07 -1.4544734954833984 0.06719585508108139\n",
      "[Step 24267] Loss: 9.40e+07 -1.4541749954223633 0.06720905750989914\n",
      "[Step 24268] Loss: 9.43e+07 -1.4539765119552612 0.06722390651702881\n",
      "[Step 24269] Loss: 9.39e+07 -1.4537076950073242 0.06723380833864212\n",
      "[Step 24270] Loss: 9.37e+07 -1.4534177780151367 0.0672585666179657\n",
      "[Step 24271] Loss: 9.50e+07 -1.4529948234558105 0.0672849714756012\n",
      "[Step 24272] Loss: 9.44e+07 -1.4526126384735107 0.06731467694044113\n",
      "[Step 24273] Loss: 9.52e+07 -1.4523262977600098 0.06733117997646332\n",
      "[Step 24274] Loss: 9.43e+07 -1.452065348625183 0.06734602898359299\n",
      "[Step 24275] Loss: 9.45e+07 -1.4518166780471802 0.06734767556190491\n",
      "[Step 24276] Loss: 9.44e+07 -1.4516489505767822 0.06734520196914673\n",
      "[Step 24277] Loss: 9.39e+07 -1.4514786005020142 0.06735510379076004\n",
      "[Step 24278] Loss: 9.44e+07 -1.4512220621109009 0.0673699602484703\n",
      "[Step 24279] Loss: 9.40e+07 -1.4509268999099731 0.06738563627004623\n",
      "[Step 24280] Loss: 9.48e+07 -1.4505975246429443 0.06740296632051468\n",
      "[Step 24281] Loss: 9.35e+07 -1.4503412246704102 0.06742441654205322\n",
      "[Step 24282] Loss: 9.39e+07 -1.4500174522399902 0.06743184477090836\n",
      "[Step 24283] Loss: 9.48e+07 -1.4496698379516602 0.06744174659252167\n",
      "[Step 24284] Loss: 9.44e+07 -1.4492813348770142 0.0674574226140976\n",
      "[Step 24285] Loss: 9.41e+07 -1.4490159749984741 0.06746732443571091\n",
      "[Step 24286] Loss: 9.44e+07 -1.4488023519515991 0.06748795509338379\n",
      "[Step 24287] Loss: 9.38e+07 -1.4485652446746826 0.06749207526445389\n",
      "[Step 24288] Loss: 9.42e+07 -1.448312759399414 0.0675019770860672\n",
      "[Step 24289] Loss: 9.52e+07 -1.447983980178833 0.06752673536539078\n",
      "[Step 24290] Loss: 9.57e+07 -1.4479843378067017 0.06751187890768051\n",
      "[Step 24291] Loss: 9.40e+07 -1.4479509592056274 0.0675061047077179\n",
      "[Step 24292] Loss: 9.54e+07 -1.448067307472229 0.06749207526445389\n",
      "[Step 24293] Loss: 9.46e+07 -1.448161244392395 0.06748052686452866\n",
      "[Step 24294] Loss: 9.34e+07 -1.4481738805770874 0.06747475266456604\n",
      "[Step 24295] Loss: 9.52e+07 -1.448045253753662 0.0674937292933464\n",
      "[Step 24296] Loss: 9.43e+07 -1.4480054378509521 0.06749620288610458\n",
      "[Step 24297] Loss: 9.42e+07 -1.447885513305664 0.0674937292933464\n",
      "[Step 24298] Loss: 9.43e+07 -1.4477232694625854 0.06750940531492233\n",
      "[Step 24299] Loss: 9.38e+07 -1.4475634098052979 0.06753333657979965\n",
      "[Step 24300] Loss: 9.42e+07 -1.4472805261611938 0.06755891442298889\n",
      "[Step 24301] Loss: 9.41e+07 -1.447025179862976 0.0675952211022377\n",
      "[Step 24302] Loss: 9.38e+07 -1.4467171430587769 0.0676216259598732\n",
      "[Step 24303] Loss: 9.50e+07 -1.4466034173965454 0.06761255115270615\n",
      "[Step 24304] Loss: 9.42e+07 -1.446408987045288 0.06761585175991058\n",
      "[Step 24305] Loss: 9.58e+07 -1.4464473724365234 0.06762245297431946\n",
      "[Step 24306] Loss: 9.40e+07 -1.4464027881622314 0.06761502474546432\n",
      "[Step 24307] Loss: 9.45e+07 -1.44623863697052 0.06763152778148651\n",
      "[Step 24308] Loss: 9.40e+07 -1.446052074432373 0.067643903195858\n",
      "[Step 24309] Loss: 9.46e+07 -1.4459964036941528 0.06764060258865356\n",
      "[Step 24310] Loss: 9.42e+07 -1.44598388671875 0.0676480308175087\n",
      "[Step 24311] Loss: 9.42e+07 -1.4458532333374023 0.06765050441026688\n",
      "[Step 24312] Loss: 9.47e+07 -1.4456560611724854 0.06765627861022949\n",
      "[Step 24313] Loss: 9.42e+07 -1.4454665184020996 0.06766948103904724\n",
      "[Step 24314] Loss: 9.39e+07 -1.4452358484268188 0.06767278164625168\n",
      "[Step 24315] Loss: 9.39e+07 -1.444943904876709 0.06768185645341873\n",
      "[Step 24316] Loss: 9.36e+07 -1.4447020292282104 0.06771651655435562\n",
      "[Step 24317] Loss: 9.51e+07 -1.444374918937683 0.06776272505521774\n",
      "[Step 24318] Loss: 9.62e+07 -1.444385051727295 0.06777592748403549\n",
      "[Step 24319] Loss: 9.45e+07 -1.4444072246551514 0.06776932626962662\n",
      "[Step 24320] Loss: 9.40e+07 -1.4443297386169434 0.06776849925518036\n",
      "[Step 24321] Loss: 9.47e+07 -1.4441468715667725 0.06778747588396072\n",
      "[Step 24322] Loss: 9.37e+07 -1.4439133405685425 0.0677982047200203\n",
      "[Step 24323] Loss: 9.38e+07 -1.4436774253845215 0.06780563294887543\n",
      "[Step 24324] Loss: 9.43e+07 -1.4434325695037842 0.06781800836324692\n",
      "[Step 24325] Loss: 9.48e+07 -1.4433537721633911 0.06783121079206467\n",
      "[Step 24326] Loss: 9.46e+07 -1.4431928396224976 0.06783368438482285\n",
      "[Step 24327] Loss: 9.50e+07 -1.4430317878723145 0.0678691640496254\n",
      "[Step 24328] Loss: 9.43e+07 -1.4429194927215576 0.06788566708564758\n",
      "[Step 24329] Loss: 9.42e+07 -1.4428027868270874 0.06789804250001907\n",
      "[Step 24330] Loss: 9.50e+07 -1.442601203918457 0.06790382415056229\n",
      "[Step 24331] Loss: 9.45e+07 -1.4422581195831299 0.0679178461432457\n",
      "[Step 24332] Loss: 9.38e+07 -1.441927433013916 0.06792527437210083\n",
      "[Step 24333] Loss: 9.37e+07 -1.441615343093872 0.06794920563697815\n",
      "[Step 24334] Loss: 9.39e+07 -1.44124174118042 0.06797891110181808\n",
      "[Step 24335] Loss: 9.43e+07 -1.440839409828186 0.06799211353063583\n",
      "[Step 24336] Loss: 9.44e+07 -1.4405113458633423 0.06800943613052368\n",
      "[Step 24337] Loss: 9.45e+07 -1.4401721954345703 0.06803832203149796\n",
      "[Step 24338] Loss: 9.59e+07 -1.4396892786026 0.06807050108909607\n",
      "[Step 24339] Loss: 9.63e+07 -1.4395865201950073 0.06807462126016617\n",
      "[Step 24340] Loss: 9.38e+07 -1.4394216537475586 0.06807462126016617\n",
      "[Step 24341] Loss: 9.44e+07 -1.4392160177230835 0.06809277832508087\n",
      "[Step 24342] Loss: 9.37e+07 -1.4390305280685425 0.06810268014669418\n",
      "[Step 24343] Loss: 9.41e+07 -1.4389535188674927 0.06810185313224792\n",
      "[Step 24344] Loss: 9.42e+07 -1.4389029741287231 0.06810515373945236\n",
      "[Step 24345] Loss: 9.41e+07 -1.4387543201446533 0.06812082976102829\n",
      "[Step 24346] Loss: 9.38e+07 -1.4386367797851562 0.06813321262598038\n",
      "[Step 24347] Loss: 9.35e+07 -1.4384188652038574 0.06814641505479813\n",
      "[Step 24348] Loss: 9.39e+07 -1.43832528591156 0.06814476102590561\n",
      "[Step 24349] Loss: 9.42e+07 -1.438223123550415 0.06816703826189041\n",
      "[Step 24350] Loss: 9.39e+07 -1.4380476474761963 0.06816703826189041\n",
      "[Step 24351] Loss: 9.44e+07 -1.4379801750183105 0.06816786527633667\n",
      "[Step 24352] Loss: 9.47e+07 -1.4380688667297363 0.068153016269207\n",
      "[Step 24353] Loss: 9.33e+07 -1.438127875328064 0.06814806163311005\n",
      "[Step 24354] Loss: 9.71e+07 -1.4387171268463135 0.06809772551059723\n",
      "[Step 24355] Loss: 9.40e+07 -1.4392032623291016 0.06805399805307388\n",
      "[Step 24356] Loss: 9.38e+07 -1.4395878314971924 0.06803006678819656\n",
      "[Step 24357] Loss: 9.38e+07 -1.4399986267089844 0.06799623370170593\n",
      "[Step 24358] Loss: 9.32e+07 -1.4402912855148315 0.06798221170902252\n",
      "[Step 24359] Loss: 9.44e+07 -1.4405107498168945 0.06797395646572113\n",
      "[Step 24360] Loss: 9.40e+07 -1.4406661987304688 0.06796818226575851\n",
      "[Step 24361] Loss: 9.45e+07 -1.4409207105636597 0.0679442510008812\n",
      "[Step 24362] Loss: 9.43e+07 -1.4410911798477173 0.0679360032081604\n",
      "[Step 24363] Loss: 9.39e+07 -1.4412000179290771 0.06792857497930527\n",
      "[Step 24364] Loss: 9.43e+07 -1.4412498474121094 0.06792444735765457\n",
      "[Step 24365] Loss: 9.35e+07 -1.441236972808838 0.06792692840099335\n",
      "[Step 24366] Loss: 9.38e+07 -1.4411414861679077 0.06791537255048752\n",
      "[Step 24367] Loss: 9.39e+07 -1.4409841299057007 0.06792774796485901\n",
      "[Step 24368] Loss: 9.51e+07 -1.4407250881195068 0.06795167922973633\n",
      "[Step 24369] Loss: 9.70e+07 -1.4410241842269897 0.06792362779378891\n",
      "[Step 24370] Loss: 9.32e+07 -1.4412627220153809 0.06790794432163239\n",
      "[Step 24371] Loss: 9.61e+07 -1.441757082939148 0.06788153946399689\n",
      "[Step 24372] Loss: 9.40e+07 -1.4422614574432373 0.06785843521356583\n",
      "[Step 24373] Loss: 9.45e+07 -1.4427835941314697 0.06780727952718735\n",
      "[Step 24374] Loss: 9.42e+07 -1.4432828426361084 0.06777510046958923\n",
      "[Step 24375] Loss: 9.35e+07 -1.443727731704712 0.06774044781923294\n",
      "[Step 24376] Loss: 9.40e+07 -1.444052815437317 0.06771981716156006\n",
      "[Step 24377] Loss: 9.39e+07 -1.4443062543869019 0.0676884576678276\n",
      "[Step 24378] Loss: 9.39e+07 -1.4445499181747437 0.06766123324632645\n",
      "[Step 24379] Loss: 9.48e+07 -1.4446868896484375 0.06765545159578323\n",
      "[Step 24380] Loss: 9.42e+07 -1.4448647499084473 0.06764142960309982\n",
      "[Step 24381] Loss: 9.43e+07 -1.444979190826416 0.06762822717428207\n",
      "[Step 24382] Loss: 9.34e+07 -1.4450839757919312 0.06762657314538956\n",
      "[Step 24383] Loss: 9.37e+07 -1.4451777935028076 0.0676257535815239\n",
      "[Step 24384] Loss: 9.44e+07 -1.4453471899032593 0.06759852170944214\n",
      "[Step 24385] Loss: 9.36e+07 -1.4454513788223267 0.067591093480587\n",
      "[Step 24386] Loss: 9.53e+07 -1.445666790008545 0.067577064037323\n",
      "[Step 24387] Loss: 9.34e+07 -1.4457619190216064 0.06757128983736038\n",
      "[Step 24388] Loss: 9.42e+07 -1.4457734823226929 0.06756468862295151\n",
      "[Step 24389] Loss: 9.41e+07 -1.4457765817642212 0.06756634265184402\n",
      "[Step 24390] Loss: 9.39e+07 -1.4457371234893799 0.06755808740854263\n",
      "[Step 24391] Loss: 9.42e+07 -1.4457777738571167 0.06755395978689194\n",
      "[Step 24392] Loss: 9.45e+07 -1.4457032680511475 0.0675465390086174\n",
      "[Step 24393] Loss: 9.46e+07 -1.4455790519714355 0.06757128983736038\n",
      "[Step 24394] Loss: 9.51e+07 -1.4453212022781372 0.06759274750947952\n",
      "[Step 24395] Loss: 9.53e+07 -1.4449472427368164 0.06761255115270615\n",
      "[Step 24396] Loss: 9.37e+07 -1.44460129737854 0.06763070076704025\n",
      "[Step 24397] Loss: 9.43e+07 -1.444218397140503 0.06764307618141174\n",
      "[Step 24398] Loss: 9.39e+07 -1.443767786026001 0.06766453385353088\n",
      "[Step 24399] Loss: 9.38e+07 -1.4432923793792725 0.06770166009664536\n",
      "[Step 24400] Loss: 9.34e+07 -1.4428503513336182 0.06772394478321075\n",
      "[Step 24401] Loss: 9.41e+07 -1.4423143863677979 0.06778417527675629\n",
      "[Step 24402] Loss: 9.60e+07 -1.442164659500122 0.06778664886951447\n",
      "[Step 24403] Loss: 9.46e+07 -1.4419349431991577 0.06782213598489761\n",
      "[Step 24404] Loss: 9.55e+07 -1.441585659980774 0.06784771382808685\n",
      "[Step 24405] Loss: 9.43e+07 -1.4414116144180298 0.06785266101360321\n",
      "[Step 24406] Loss: 9.44e+07 -1.4412474632263184 0.06787493824958801\n",
      "[Step 24407] Loss: 9.42e+07 -1.441060185432434 0.0678955689072609\n",
      "[Step 24408] Loss: 9.35e+07 -1.4408053159713745 0.0679178461432457\n",
      "[Step 24409] Loss: 9.33e+07 -1.440514087677002 0.06795250624418259\n",
      "[Step 24410] Loss: 9.42e+07 -1.4401911497116089 0.06799376010894775\n",
      "[Step 24411] Loss: 9.43e+07 -1.4399627447128296 0.06802099198102951\n",
      "[Step 24412] Loss: 9.35e+07 -1.4396697282791138 0.06803666800260544\n",
      "[Step 24413] Loss: 9.38e+07 -1.439400315284729 0.06807462126016617\n",
      "[Step 24414] Loss: 9.51e+07 -1.4393507242202759 0.068086177110672\n",
      "[Step 24415] Loss: 9.44e+07 -1.4392892122268677 0.06808782368898392\n",
      "[Step 24416] Loss: 9.35e+07 -1.4391447305679321 0.06810185313224792\n",
      "[Step 24417] Loss: 9.32e+07 -1.4389519691467285 0.06813155859708786\n",
      "[Step 24418] Loss: 9.41e+07 -1.4386894702911377 0.06813981384038925\n",
      "[Step 24419] Loss: 9.50e+07 -1.4385687112808228 0.06813815981149673\n",
      "[Step 24420] Loss: 9.34e+07 -1.4383628368377686 0.06815053522586823\n",
      "[Step 24421] Loss: 9.43e+07 -1.4382339715957642 0.06815961748361588\n",
      "[Step 24422] Loss: 9.42e+07 -1.438007116317749 0.0681876689195633\n",
      "[Step 24423] Loss: 9.39e+07 -1.4377306699752808 0.06821077316999435\n",
      "[Step 24424] Loss: 9.50e+07 -1.4377228021621704 0.06820911914110184\n",
      "[Step 24425] Loss: 9.56e+07 -1.4380052089691162 0.06815796345472336\n",
      "[Step 24426] Loss: 9.42e+07 -1.4382001161575317 0.06813403218984604\n",
      "[Step 24427] Loss: 9.41e+07 -1.438375473022461 0.06810928136110306\n",
      "[Step 24428] Loss: 9.43e+07 -1.4386050701141357 0.06808700412511826\n",
      "[Step 24429] Loss: 9.41e+07 -1.4387805461883545 0.06806884706020355\n",
      "[Step 24430] Loss: 9.42e+07 -1.4388936758041382 0.0680597722530365\n",
      "[Step 24431] Loss: 9.44e+07 -1.439142107963562 0.06803006678819656\n",
      "[Step 24432] Loss: 9.39e+07 -1.4393870830535889 0.06799045950174332\n",
      "[Step 24433] Loss: 9.36e+07 -1.439571499824524 0.06797312945127487\n",
      "[Step 24434] Loss: 9.44e+07 -1.4397072792053223 0.0679624080657959\n",
      "[Step 24435] Loss: 9.39e+07 -1.4397836923599243 0.06792444735765457\n",
      "[Step 24436] Loss: 9.53e+07 -1.4400115013122559 0.06790217012166977\n",
      "[Step 24437] Loss: 9.48e+07 -1.4403605461120605 0.0678650364279747\n",
      "[Step 24438] Loss: 9.47e+07 -1.440698266029358 0.06784524023532867\n",
      "[Step 24439] Loss: 9.42e+07 -1.4409688711166382 0.06781718134880066\n",
      "[Step 24440] Loss: 9.39e+07 -1.441251516342163 0.0677899494767189\n",
      "[Step 24441] Loss: 9.47e+07 -1.4416184425354004 0.06775612384080887\n",
      "[Step 24442] Loss: 9.41e+07 -1.4419394731521606 0.06773466616868973\n",
      "[Step 24443] Loss: 9.46e+07 -1.4422975778579712 0.06773054599761963\n",
      "[Step 24444] Loss: 9.39e+07 -1.4425541162490845 0.06771651655435562\n",
      "[Step 24445] Loss: 9.41e+07 -1.4428097009658813 0.06768928468227386\n",
      "[Step 24446] Loss: 9.43e+07 -1.442978858947754 0.06769175827503204\n",
      "[Step 24447] Loss: 9.50e+07 -1.4433629512786865 0.06767525523900986\n",
      "[Step 24448] Loss: 9.37e+07 -1.4437328577041626 0.06764885038137436\n",
      "[Step 24449] Loss: 9.41e+07 -1.443926453590393 0.06763152778148651\n",
      "[Step 24450] Loss: 9.45e+07 -1.4439733028411865 0.06763730198144913\n",
      "[Step 24451] Loss: 9.38e+07 -1.4440686702728271 0.06764060258865356\n",
      "[Step 24452] Loss: 9.43e+07 -1.4440864324569702 0.06764307618141174\n",
      "[Step 24453] Loss: 9.74e+07 -1.444527268409729 0.06760842353105545\n",
      "[Step 24454] Loss: 9.29e+07 -1.444931149482727 0.06758614629507065\n",
      "[Step 24455] Loss: 9.40e+07 -1.4452942609786987 0.06754405796527863\n",
      "[Step 24456] Loss: 9.39e+07 -1.445647954940796 0.06751023232936859\n",
      "[Step 24457] Loss: 9.46e+07 -1.4460393190383911 0.06748960167169571\n",
      "[Step 24458] Loss: 9.44e+07 -1.4463022947311401 0.06746897101402283\n",
      "[Step 24459] Loss: 9.43e+07 -1.4466687440872192 0.06743679195642471\n",
      "[Step 24460] Loss: 9.51e+07 -1.4470957517623901 0.0674087405204773\n",
      "[Step 24461] Loss: 9.72e+07 -1.4479882717132568 0.06733942776918411\n",
      "[Step 24462] Loss: 9.45e+07 -1.4487775564193726 0.06729239225387573\n",
      "[Step 24463] Loss: 9.38e+07 -1.4494184255599976 0.06724123656749725\n",
      "[Step 24464] Loss: 9.40e+07 -1.4499210119247437 0.06719998270273209\n",
      "[Step 24465] Loss: 9.41e+07 -1.4502646923065186 0.0671793520450592\n",
      "[Step 24466] Loss: 9.46e+07 -1.4506412744522095 0.06715047359466553\n",
      "[Step 24467] Loss: 9.41e+07 -1.4508769512176514 0.06713644415140152\n",
      "[Step 24468] Loss: 9.40e+07 -1.4510809183120728 0.06712901592254639\n",
      "[Step 24469] Loss: 9.66e+07 -1.4516795873641968 0.06707868725061417\n",
      "[Step 24470] Loss: 9.44e+07 -1.4522957801818848 0.06704650074243546\n",
      "[Step 24471] Loss: 9.42e+07 -1.452767252922058 0.06701597571372986\n",
      "[Step 24472] Loss: 9.47e+07 -1.4532852172851562 0.06699534505605698\n",
      "[Step 24473] Loss: 9.50e+07 -1.4536526203155518 0.0669664666056633\n",
      "[Step 24474] Loss: 9.34e+07 -1.4539785385131836 0.06695326417684555\n",
      "[Step 24475] Loss: 9.38e+07 -1.4542242288589478 0.06693676114082336\n",
      "[Step 24476] Loss: 9.39e+07 -1.4544283151626587 0.06692520529031754\n",
      "[Step 24477] Loss: 9.62e+07 -1.4549630880355835 0.06688890606164932\n",
      "[Step 24478] Loss: 9.67e+07 -1.4558756351470947 0.06683114171028137\n",
      "[Step 24479] Loss: 9.39e+07 -1.4565942287445068 0.0667717307806015\n",
      "[Step 24480] Loss: 9.42e+07 -1.4572021961212158 0.06672634929418564\n",
      "[Step 24481] Loss: 9.77e+07 -1.4582358598709106 0.06667106598615646\n",
      "[Step 24482] Loss: 9.40e+07 -1.459168553352356 0.06662072986364365\n",
      "[Step 24483] Loss: 9.42e+07 -1.4600340127944946 0.06658690422773361\n",
      "[Step 24484] Loss: 9.44e+07 -1.4609569311141968 0.06652253866195679\n",
      "[Step 24485] Loss: 9.46e+07 -1.461638331413269 0.06646313518285751\n",
      "[Step 24486] Loss: 9.38e+07 -1.4622246026992798 0.06642930209636688\n",
      "[Step 24487] Loss: 9.44e+07 -1.462624192237854 0.06639216840267181\n",
      "[Step 24488] Loss: 9.48e+07 -1.4630736112594604 0.06635504215955734\n",
      "[Step 24489] Loss: 9.40e+07 -1.4634383916854858 0.06632781028747559\n",
      "[Step 24490] Loss: 9.42e+07 -1.463710069656372 0.0663071796298027\n",
      "[Step 24491] Loss: 9.39e+07 -1.4638928174972534 0.06629067659378052\n",
      "[Step 24492] Loss: 9.77e+07 -1.4645487070083618 0.06624199450016022\n",
      "[Step 24493] Loss: 9.39e+07 -1.4650382995605469 0.0662139430642128\n",
      "[Step 24494] Loss: 9.41e+07 -1.4653847217559814 0.06617268174886703\n",
      "[Step 24495] Loss: 9.42e+07 -1.4656015634536743 0.06615287810564041\n",
      "[Step 24496] Loss: 9.45e+07 -1.4656544923782349 0.06614463031291962\n",
      "[Step 24497] Loss: 9.40e+07 -1.4655128717422485 0.06614463031291962\n",
      "[Step 24498] Loss: 9.40e+07 -1.4654533863067627 0.066138856112957\n",
      "[Step 24499] Loss: 9.54e+07 -1.4653198719024658 0.06616196036338806\n",
      "[Step 24500] Loss: 9.45e+07 -1.465204119682312 0.06617268174886703\n",
      "[Step 24501] Loss: 9.46e+07 -1.4649945497512817 0.066191665828228\n",
      "[Step 24502] Loss: 9.54e+07 -1.464907169342041 0.06618918478488922\n",
      "[Step 24503] Loss: 9.37e+07 -1.4648245573043823 0.06617928296327591\n",
      "[Step 24504] Loss: 9.45e+07 -1.4647296667099 0.0661834105849266\n",
      "[Step 24505] Loss: 9.39e+07 -1.4646424055099487 0.06618093699216843\n",
      "[Step 24506] Loss: 9.44e+07 -1.4646403789520264 0.06616030633449554\n",
      "[Step 24507] Loss: 9.43e+07 -1.4646178483963013 0.06616196036338806\n",
      "[Step 24508] Loss: 9.44e+07 -1.464517593383789 0.06617268174886703\n",
      "[Step 24509] Loss: 9.44e+07 -1.4643115997314453 0.06618671119213104\n",
      "[Step 24510] Loss: 9.46e+07 -1.4640549421310425 0.06620321422815323\n",
      "[Step 24511] Loss: 9.38e+07 -1.4638510942459106 0.06622961908578873\n",
      "[Step 24512] Loss: 9.48e+07 -1.463728904724121 0.0662403479218483\n",
      "[Step 24513] Loss: 9.47e+07 -1.4638077020645142 0.06624942272901535\n",
      "[Step 24514] Loss: 9.40e+07 -1.4638272523880005 0.06625519692897797\n",
      "[Step 24515] Loss: 9.33e+07 -1.463789939880371 0.06624199450016022\n",
      "[Step 24516] Loss: 9.33e+07 -1.4637700319290161 0.06623539328575134\n",
      "[Step 24517] Loss: 9.49e+07 -1.463679552078247 0.06624612212181091\n",
      "[Step 24518] Loss: 9.46e+07 -1.4636727571487427 0.06624364852905273\n",
      "[Step 24519] Loss: 9.41e+07 -1.4635825157165527 0.06622549146413803\n",
      "[Step 24520] Loss: 9.38e+07 -1.4634251594543457 0.06624364852905273\n",
      "[Step 24521] Loss: 9.38e+07 -1.4632277488708496 0.06626015156507492\n",
      "[Step 24522] Loss: 9.42e+07 -1.4630354642868042 0.06626757234334946\n",
      "[Step 24523] Loss: 9.39e+07 -1.4629249572753906 0.06627335399389267\n",
      "[Step 24524] Loss: 9.41e+07 -1.462786316871643 0.06627582758665085\n",
      "[Step 24525] Loss: 9.42e+07 -1.462526559829712 0.06629727780818939\n",
      "[Step 24526] Loss: 9.44e+07 -1.4623562097549438 0.06632450968027115\n",
      "[Step 24527] Loss: 9.52e+07 -1.462103009223938 0.06633935868740082\n",
      "[Step 24528] Loss: 9.46e+07 -1.4617351293563843 0.0663517415523529\n",
      "[Step 24529] Loss: 9.35e+07 -1.4613043069839478 0.0663822665810585\n",
      "[Step 24530] Loss: 9.67e+07 -1.461395263671875 0.06638556718826294\n",
      "[Step 24531] Loss: 9.38e+07 -1.4614169597625732 0.06640289723873138\n",
      "[Step 24532] Loss: 9.43e+07 -1.461491584777832 0.06639629602432251\n",
      "[Step 24533] Loss: 9.48e+07 -1.461612343788147 0.06637649238109589\n",
      "[Step 24534] Loss: 9.37e+07 -1.4616869688034058 0.06636989116668701\n",
      "[Step 24535] Loss: 9.35e+07 -1.4617784023284912 0.06636989116668701\n",
      "[Step 24536] Loss: 9.37e+07 -1.46182382106781 0.06637071818113327\n",
      "[Step 24537] Loss: 9.36e+07 -1.4618293046951294 0.06636164337396622\n",
      "[Step 24538] Loss: 9.38e+07 -1.4617911577224731 0.0663599893450737\n",
      "[Step 24539] Loss: 9.38e+07 -1.4616721868515015 0.06636576354503632\n",
      "[Step 24540] Loss: 9.37e+07 -1.4615389108657837 0.06636824458837509\n",
      "[Step 24541] Loss: 9.39e+07 -1.4613934755325317 0.06637154519557953\n",
      "[Step 24542] Loss: 9.40e+07 -1.4612308740615845 0.06637484580278397\n",
      "[Step 24543] Loss: 9.37e+07 -1.4610271453857422 0.06639134883880615\n",
      "[Step 24544] Loss: 9.72e+07 -1.4613336324691772 0.06636824458837509\n",
      "[Step 24545] Loss: 9.49e+07 -1.4617995023727417 0.06633193790912628\n",
      "[Step 24546] Loss: 9.42e+07 -1.4621840715408325 0.06631295382976532\n",
      "[Step 24547] Loss: 9.46e+07 -1.4625829458236694 0.06629975885152817\n",
      "[Step 24548] Loss: 9.41e+07 -1.4628117084503174 0.06627005338668823\n",
      "[Step 24549] Loss: 9.64e+07 -1.4633585214614868 0.06625189632177353\n",
      "[Step 24550] Loss: 9.35e+07 -1.4637911319732666 0.06622879207134247\n",
      "[Step 24551] Loss: 9.47e+07 -1.4642868041992188 0.0661957859992981\n",
      "[Step 24552] Loss: 9.42e+07 -1.4646110534667969 0.0661834105849266\n",
      "[Step 24553] Loss: 9.36e+07 -1.4649065732955933 0.06615535914897919\n",
      "[Step 24554] Loss: 9.67e+07 -1.4656506776809692 0.06610089540481567\n",
      "[Step 24555] Loss: 9.33e+07 -1.4662874937057495 0.06605798751115799\n",
      "[Step 24556] Loss: 9.40e+07 -1.4668972492218018 0.0660233348608017\n",
      "[Step 24557] Loss: 9.50e+07 -1.4676328897476196 0.06598455458879471\n",
      "[Step 24558] Loss: 9.39e+07 -1.4682846069335938 0.06594329327344894\n",
      "[Step 24559] Loss: 9.41e+07 -1.4687808752059937 0.06590864062309265\n",
      "[Step 24560] Loss: 9.35e+07 -1.4691489934921265 0.06588058918714523\n",
      "[Step 24561] Loss: 9.46e+07 -1.4693573713302612 0.06587150692939758\n",
      "[Step 24562] Loss: 9.52e+07 -1.4694139957427979 0.06586078554391861\n",
      "[Step 24563] Loss: 9.46e+07 -1.4693679809570312 0.0658690333366394\n",
      "[Step 24564] Loss: 9.38e+07 -1.4693647623062134 0.06586573272943497\n",
      "[Step 24565] Loss: 9.31e+07 -1.4693275690078735 0.06587646156549454\n",
      "[Step 24566] Loss: 9.38e+07 -1.4692599773406982 0.06588718295097351\n",
      "[Step 24567] Loss: 9.48e+07 -1.469294548034668 0.06591028720140457\n",
      "[Step 24568] Loss: 9.41e+07 -1.4693723917007446 0.06590781360864639\n",
      "[Step 24569] Loss: 9.37e+07 -1.4693419933319092 0.06591111421585083\n",
      "[Step 24570] Loss: 9.38e+07 -1.4693273305892944 0.06591276824474335\n",
      "[Step 24571] Loss: 9.41e+07 -1.469374656677246 0.06590616703033447\n",
      "[Step 24572] Loss: 9.41e+07 -1.4693775177001953 0.06591854244470596\n",
      "[Step 24573] Loss: 9.41e+07 -1.469326138496399 0.06592348963022232\n",
      "[Step 24574] Loss: 9.36e+07 -1.469199299812317 0.06593091785907745\n",
      "[Step 24575] Loss: 9.39e+07 -1.4691014289855957 0.06594577431678772\n",
      "[Step 24576] Loss: 9.62e+07 -1.4693766832351685 0.06592679023742676\n",
      "[Step 24577] Loss: 9.39e+07 -1.4696582555770874 0.0659300908446312\n",
      "[Step 24578] Loss: 9.39e+07 -1.4698810577392578 0.06592348963022232\n",
      "[Step 24579] Loss: 9.39e+07 -1.4701019525527954 0.06590946763753891\n",
      "[Step 24580] Loss: 9.34e+07 -1.4702675342559814 0.06590781360864639\n",
      "[Step 24581] Loss: 9.42e+07 -1.4702930450439453 0.06590121239423752\n",
      "[Step 24582] Loss: 9.46e+07 -1.4702179431915283 0.06591524183750153\n",
      "[Step 24583] Loss: 9.43e+07 -1.4701746702194214 0.06592844426631927\n",
      "[Step 24584] Loss: 9.43e+07 -1.4701673984527588 0.06594329327344894\n",
      "[Step 24585] Loss: 9.40e+07 -1.4700320959091187 0.06595484912395477\n",
      "[Step 24586] Loss: 9.37e+07 -1.4698920249938965 0.06595897674560547\n",
      "[Step 24587] Loss: 9.42e+07 -1.4696706533432007 0.06598290055990219\n",
      "[Step 24588] Loss: 9.39e+07 -1.46934974193573 0.06598950177431107\n",
      "[Step 24589] Loss: 9.43e+07 -1.4689271450042725 0.06603323668241501\n",
      "[Step 24590] Loss: 9.40e+07 -1.4684492349624634 0.06605881452560425\n",
      "[Step 24591] Loss: 9.34e+07 -1.4679179191589355 0.06608934700489044\n",
      "[Step 24592] Loss: 9.43e+07 -1.4673837423324585 0.06612812727689743\n",
      "[Step 24593] Loss: 9.46e+07 -1.4669595956802368 0.06616690754890442\n",
      "[Step 24594] Loss: 9.40e+07 -1.4664636850357056 0.06620074063539505\n",
      "[Step 24595] Loss: 9.40e+07 -1.4659433364868164 0.06624694913625717\n",
      "[Step 24596] Loss: 9.38e+07 -1.465409278869629 0.0662890300154686\n",
      "[Step 24597] Loss: 9.70e+07 -1.465420126914978 0.06629645824432373\n",
      "[Step 24598] Loss: 9.42e+07 -1.4653148651123047 0.06630553305149078\n",
      "[Step 24599] Loss: 9.49e+07 -1.4653657674789429 0.06629233062267303\n",
      "[Step 24600] Loss: 9.37e+07 -1.465281367301941 0.06631048023700714\n",
      "[Step 24601] Loss: 9.37e+07 -1.465140461921692 0.06631295382976532\n",
      "[Step 24602] Loss: 9.45e+07 -1.464988350868225 0.0663195550441742\n",
      "[Step 24603] Loss: 9.43e+07 -1.4647984504699707 0.06632368266582489\n",
      "[Step 24604] Loss: 9.44e+07 -1.4645346403121948 0.0663294568657875\n",
      "[Step 24605] Loss: 9.37e+07 -1.4642213582992554 0.066355861723423\n",
      "[Step 24606] Loss: 9.45e+07 -1.463982343673706 0.06635668873786926\n",
      "[Step 24607] Loss: 9.42e+07 -1.4636635780334473 0.06636328995227814\n",
      "[Step 24608] Loss: 9.52e+07 -1.4636425971984863 0.0663641169667244\n",
      "[Step 24609] Loss: 9.45e+07 -1.4634714126586914 0.06637649238109589\n",
      "[Step 24610] Loss: 9.59e+07 -1.4630857706069946 0.06639712303876877\n",
      "[Step 24611] Loss: 9.45e+07 -1.462752103805542 0.06641774624586105\n",
      "[Step 24612] Loss: 9.42e+07 -1.4623737335205078 0.06644497811794281\n",
      "[Step 24613] Loss: 9.40e+07 -1.4619930982589722 0.06647055596113205\n",
      "[Step 24614] Loss: 9.44e+07 -1.4617260694503784 0.06651759147644043\n",
      "[Step 24615] Loss: 9.45e+07 -1.4615696668624878 0.06652913987636566\n",
      "[Step 24616] Loss: 9.69e+07 -1.4619044065475464 0.06651841849088669\n",
      "[Step 24617] Loss: 9.48e+07 -1.4623397588729858 0.06648458540439606\n",
      "[Step 24618] Loss: 9.32e+07 -1.4626914262771606 0.06645487993955612\n",
      "[Step 24619] Loss: 9.35e+07 -1.4630167484283447 0.06643012911081314\n",
      "[Step 24620] Loss: 9.41e+07 -1.4633333683013916 0.06641444563865662\n",
      "[Step 24621] Loss: 9.37e+07 -1.4635052680969238 0.06639134883880615\n",
      "[Step 24622] Loss: 9.41e+07 -1.4637290239334106 0.06636906415224075\n",
      "[Step 24623] Loss: 9.45e+07 -1.4638530015945435 0.06636164337396622\n",
      "[Step 24624] Loss: 9.40e+07 -1.464005708694458 0.06635751575231552\n",
      "[Step 24625] Loss: 9.46e+07 -1.464061975479126 0.06634678691625595\n",
      "[Step 24626] Loss: 9.43e+07 -1.464133381843567 0.06634101271629333\n",
      "[Step 24627] Loss: 9.43e+07 -1.4642975330352783 0.06633193790912628\n",
      "[Step 24628] Loss: 9.39e+07 -1.4643940925598145 0.06633441150188446\n",
      "[Step 24629] Loss: 9.52e+07 -1.464603066444397 0.0663195550441742\n",
      "[Step 24630] Loss: 9.41e+07 -1.4647587537765503 0.06632781028747559\n",
      "[Step 24631] Loss: 9.38e+07 -1.4648735523223877 0.06630800664424896\n",
      "[Step 24632] Loss: 9.40e+07 -1.4649362564086914 0.06629810482263565\n",
      "[Step 24633] Loss: 9.52e+07 -1.4648776054382324 0.06631048023700714\n",
      "[Step 24634] Loss: 9.40e+07 -1.464774489402771 0.06630305200815201\n",
      "[Step 24635] Loss: 9.39e+07 -1.4648100137710571 0.06631708145141602\n",
      "[Step 24636] Loss: 9.37e+07 -1.4648171663284302 0.06630883365869522\n",
      "[Step 24637] Loss: 9.46e+07 -1.4648387432098389 0.06630223244428635\n",
      "[Step 24638] Loss: 9.57e+07 -1.4650698900222778 0.06628820300102234\n",
      "[Step 24639] Loss: 9.48e+07 -1.465280294418335 0.06626015156507492\n",
      "[Step 24640] Loss: 9.40e+07 -1.4655115604400635 0.06622879207134247\n",
      "[Step 24641] Loss: 9.30e+07 -1.4657188653945923 0.06621476262807846\n",
      "[Step 24642] Loss: 9.43e+07 -1.4659072160720825 0.06620816141366959\n",
      "[Step 24643] Loss: 9.39e+07 -1.4660258293151855 0.06621146202087402\n",
      "[Step 24644] Loss: 9.44e+07 -1.466107726097107 0.06619825959205627\n",
      "[Step 24645] Loss: 9.46e+07 -1.46627676486969 0.06618176400661469\n",
      "[Step 24646] Loss: 9.49e+07 -1.4665992259979248 0.06615700572729111\n",
      "[Step 24647] Loss: 9.45e+07 -1.4669090509414673 0.06613060086965561\n",
      "[Step 24648] Loss: 9.44e+07 -1.467189073562622 0.06611575186252594\n",
      "[Step 24649] Loss: 9.47e+07 -1.4673569202423096 0.06610997021198273\n",
      "[Step 24650] Loss: 9.40e+07 -1.4675692319869995 0.06610419601202011\n",
      "[Step 24651] Loss: 9.41e+07 -1.4677441120147705 0.066086046397686\n",
      "[Step 24652] Loss: 9.44e+07 -1.4679186344146729 0.0660678893327713\n",
      "[Step 24653] Loss: 9.42e+07 -1.4680360555648804 0.066072016954422\n",
      "[Step 24654] Loss: 9.36e+07 -1.4681456089019775 0.06606046855449677\n",
      "[Step 24655] Loss: 9.39e+07 -1.4682538509368896 0.06603818386793137\n",
      "[Step 24656] Loss: 9.37e+07 -1.4683550596237183 0.06604891270399094\n",
      "[Step 24657] Loss: 9.43e+07 -1.4684977531433105 0.06603406369686127\n",
      "[Step 24658] Loss: 9.48e+07 -1.4686503410339355 0.06602746248245239\n",
      "[Step 24659] Loss: 9.32e+07 -1.468753457069397 0.06601177901029587\n",
      "[Step 24660] Loss: 9.41e+07 -1.4687949419021606 0.06600930541753769\n",
      "[Step 24661] Loss: 9.51e+07 -1.4689691066741943 0.06599362939596176\n",
      "[Step 24662] Loss: 9.33e+07 -1.4690375328063965 0.06598290055990219\n",
      "[Step 24663] Loss: 9.38e+07 -1.4690035581588745 0.06597712635993958\n",
      "[Step 24664] Loss: 9.44e+07 -1.4689929485321045 0.06597382575273514\n",
      "[Step 24665] Loss: 9.38e+07 -1.4688692092895508 0.06599032878875732\n",
      "[Step 24666] Loss: 9.33e+07 -1.4686402082443237 0.06601177901029587\n",
      "[Step 24667] Loss: 9.46e+07 -1.468459129333496 0.06602250784635544\n",
      "[Step 24668] Loss: 9.48e+07 -1.4681981801986694 0.06603818386793137\n",
      "[Step 24669] Loss: 9.42e+07 -1.467972755432129 0.06604643911123276\n",
      "[Step 24670] Loss: 9.47e+07 -1.4676425457000732 0.06604891270399094\n",
      "[Step 24671] Loss: 9.40e+07 -1.467184066772461 0.06606871634721756\n",
      "[Step 24672] Loss: 9.36e+07 -1.466739535331726 0.06609676778316498\n",
      "[Step 24673] Loss: 9.41e+07 -1.4662470817565918 0.06613390147686005\n",
      "[Step 24674] Loss: 9.35e+07 -1.4656827449798584 0.06616443395614624\n",
      "[Step 24675] Loss: 9.67e+07 -1.4649134874343872 0.06621311604976654\n",
      "[Step 24676] Loss: 9.36e+07 -1.4641978740692139 0.06623952090740204\n",
      "[Step 24677] Loss: 9.32e+07 -1.4635086059570312 0.06629067659378052\n",
      "[Step 24678] Loss: 9.41e+07 -1.4627572298049927 0.06631790846586227\n",
      "[Step 24679] Loss: 9.69e+07 -1.462571620941162 0.06631873548030853\n",
      "[Step 24680] Loss: 9.42e+07 -1.4624335765838623 0.06632120907306671\n",
      "[Step 24681] Loss: 9.33e+07 -1.4622246026992798 0.06632368266582489\n",
      "[Step 24682] Loss: 9.34e+07 -1.461936593055725 0.06633688509464264\n",
      "[Step 24683] Loss: 9.50e+07 -1.461898922920227 0.06633688509464264\n",
      "[Step 24684] Loss: 9.36e+07 -1.4618091583251953 0.06632615625858307\n",
      "[Step 24685] Loss: 9.47e+07 -1.461919903755188 0.06630387902259827\n",
      "[Step 24686] Loss: 9.46e+07 -1.4620888233184814 0.06629067659378052\n",
      "[Step 24687] Loss: 9.54e+07 -1.462505578994751 0.06626015156507492\n",
      "[Step 24688] Loss: 9.34e+07 -1.4629265069961548 0.06622466444969177\n",
      "[Step 24689] Loss: 9.36e+07 -1.463250994682312 0.06620238721370697\n",
      "[Step 24690] Loss: 9.52e+07 -1.463455080986023 0.06617928296327591\n",
      "[Step 24691] Loss: 9.54e+07 -1.4639403820037842 0.06614050269126892\n",
      "[Step 24692] Loss: 9.30e+07 -1.4643446207046509 0.06610997021198273\n",
      "[Step 24693] Loss: 9.48e+07 -1.4648106098175049 0.06608439236879349\n",
      "[Step 24694] Loss: 9.53e+07 -1.4654496908187866 0.0660456120967865\n",
      "[Step 24695] Loss: 9.32e+07 -1.4660285711288452 0.06600187718868256\n",
      "[Step 24696] Loss: 9.47e+07 -1.4666838645935059 0.06596557796001434\n",
      "[Step 24697] Loss: 9.43e+07 -1.4671690464019775 0.06593257188796997\n",
      "[Step 24698] Loss: 9.47e+07 -1.467743158340454 0.06590864062309265\n",
      "[Step 24699] Loss: 9.45e+07 -1.4682484865188599 0.06586243212223053\n",
      "[Step 24700] Loss: 9.38e+07 -1.468634843826294 0.06584015488624573\n",
      "[Step 24701] Loss: 9.42e+07 -1.468875765800476 0.06583438068628311\n",
      "[Step 24702] Loss: 9.42e+07 -1.469144344329834 0.0658285990357399\n",
      "[Step 24703] Loss: 9.41e+07 -1.4693307876586914 0.06580879539251328\n",
      "[Step 24704] Loss: 9.42e+07 -1.46951162815094 0.06580714881420135\n",
      "[Step 24705] Loss: 9.48e+07 -1.4695299863815308 0.06581127643585205\n",
      "[Step 24706] Loss: 9.59e+07 -1.4698139429092407 0.0657939463853836\n",
      "[Step 24707] Loss: 9.34e+07 -1.469971776008606 0.06576671451330185\n",
      "[Step 24708] Loss: 9.48e+07 -1.4700149297714233 0.06575929373502731\n",
      "[Step 24709] Loss: 9.38e+07 -1.4699653387069702 0.06575599312782288\n",
      "[Step 24710] Loss: 9.39e+07 -1.4698737859725952 0.06576506793498993\n",
      "[Step 24711] Loss: 9.39e+07 -1.4698935747146606 0.06576011329889297\n",
      "[Step 24712] Loss: 9.41e+07 -1.4699054956436157 0.06577084213495255\n",
      "[Step 24713] Loss: 9.39e+07 -1.4699398279190063 0.06577331572771072\n",
      "[Step 24714] Loss: 9.47e+07 -1.4701004028320312 0.065749391913414\n",
      "[Step 24715] Loss: 9.33e+07 -1.4702019691467285 0.06574113667011261\n",
      "[Step 24716] Loss: 9.58e+07 -1.470501184463501 0.06572380661964417\n",
      "[Step 24717] Loss: 9.55e+07 -1.470659852027893 0.06572216004133224\n",
      "[Step 24718] Loss: 9.46e+07 -1.47074294090271 0.06572628766298294\n",
      "[Step 24719] Loss: 9.56e+07 -1.4709453582763672 0.06571473181247711\n",
      "[Step 24720] Loss: 9.36e+07 -1.4711276292800903 0.06570730358362198\n",
      "[Step 24721] Loss: 9.54e+07 -1.4714605808258057 0.06569905579090118\n",
      "[Step 24722] Loss: 9.40e+07 -1.4717128276824951 0.0656866803765297\n",
      "[Step 24723] Loss: 9.44e+07 -1.471941590309143 0.06568585336208344\n",
      "[Step 24724] Loss: 9.42e+07 -1.4721448421478271 0.06568172574043274\n",
      "[Step 24725] Loss: 9.48e+07 -1.472514271736145 0.06566687673330307\n",
      "[Step 24726] Loss: 9.42e+07 -1.472816824913025 0.06565697491168976\n",
      "[Step 24727] Loss: 9.44e+07 -1.4731082916259766 0.06562314182519913\n",
      "[Step 24728] Loss: 9.42e+07 -1.4734381437301636 0.06560829281806946\n",
      "[Step 24729] Loss: 9.43e+07 -1.4738152027130127 0.06557033210992813\n",
      "[Step 24730] Loss: 9.72e+07 -1.4746389389038086 0.06552577763795853\n",
      "[Step 24731] Loss: 9.47e+07 -1.4753237962722778 0.06548039615154266\n",
      "[Step 24732] Loss: 9.43e+07 -1.4759845733642578 0.06544739007949829\n",
      "[Step 24733] Loss: 9.37e+07 -1.4765291213989258 0.06543583422899246\n",
      "[Step 24734] Loss: 9.43e+07 -1.4768885374069214 0.0654168576002121\n",
      "[Step 24735] Loss: 9.34e+07 -1.477130651473999 0.06543171405792236\n",
      "[Step 24736] Loss: 9.62e+07 -1.477696418762207 0.0653945803642273\n",
      "[Step 24737] Loss: 9.38e+07 -1.4781805276870728 0.06537064909934998\n",
      "[Step 24738] Loss: 9.34e+07 -1.478602647781372 0.06534094363451004\n",
      "[Step 24739] Loss: 9.41e+07 -1.4790222644805908 0.06530959159135818\n",
      "[Step 24740] Loss: 9.46e+07 -1.4794729948043823 0.06528978794813156\n",
      "[Step 24741] Loss: 9.47e+07 -1.47977876663208 0.06525100767612457\n",
      "[Step 24742] Loss: 9.36e+07 -1.4800153970718384 0.06524110585451126\n",
      "[Step 24743] Loss: 9.37e+07 -1.4802314043045044 0.06523203104734421\n",
      "[Step 24744] Loss: 9.37e+07 -1.4803224802017212 0.065226249396801\n",
      "[Step 24745] Loss: 9.47e+07 -1.480452060699463 0.06523037701845169\n",
      "[Step 24746] Loss: 9.44e+07 -1.480666995048523 0.06523037701845169\n",
      "[Step 24747] Loss: 9.44e+07 -1.4809201955795288 0.06520727276802063\n",
      "[Step 24748] Loss: 9.42e+07 -1.4812002182006836 0.06518664211034775\n",
      "[Step 24749] Loss: 9.41e+07 -1.4814002513885498 0.06519324332475662\n",
      "[Step 24750] Loss: 9.39e+07 -1.4815607070922852 0.06515859067440033\n",
      "[Step 24751] Loss: 9.47e+07 -1.4816553592681885 0.06515281647443771\n",
      "[Step 24752] Loss: 9.37e+07 -1.481657862663269 0.06515281647443771\n",
      "[Step 24753] Loss: 9.41e+07 -1.4816280603408813 0.06515529006719589\n",
      "[Step 24754] Loss: 9.49e+07 -1.4817407131195068 0.06514951586723328\n",
      "[Step 24755] Loss: 9.42e+07 -1.4818581342697144 0.06513218581676483\n",
      "[Step 24756] Loss: 9.36e+07 -1.482004165649414 0.06511320918798447\n",
      "[Step 24757] Loss: 9.39e+07 -1.4820327758789062 0.06511073559522629\n",
      "[Step 24758] Loss: 9.43e+07 -1.482118844985962 0.06510908156633377\n",
      "[Step 24759] Loss: 9.50e+07 -1.4820213317871094 0.06510578095912933\n",
      "[Step 24760] Loss: 9.39e+07 -1.4819270372390747 0.06509587913751602\n",
      "[Step 24761] Loss: 9.74e+07 -1.4823286533355713 0.06507937610149384\n",
      "[Step 24762] Loss: 9.37e+07 -1.4825754165649414 0.0650496706366539\n",
      "[Step 24763] Loss: 9.60e+07 -1.483173131942749 0.06500264257192612\n",
      "[Step 24764] Loss: 9.39e+07 -1.4836238622665405 0.0649828389286995\n",
      "[Step 24765] Loss: 9.40e+07 -1.483941912651062 0.064956434071064\n",
      "[Step 24766] Loss: 9.59e+07 -1.48405921459198 0.0649605542421341\n",
      "[Step 24767] Loss: 9.36e+07 -1.4841537475585938 0.06493745744228363\n",
      "[Step 24768] Loss: 9.44e+07 -1.4842692613601685 0.06495395302772522\n",
      "[Step 24769] Loss: 9.38e+07 -1.4842877388000488 0.06495313346385956\n",
      "[Step 24770] Loss: 9.38e+07 -1.4842514991760254 0.06496798247098923\n",
      "[Step 24771] Loss: 9.38e+07 -1.484179139137268 0.06497623771429062\n",
      "[Step 24772] Loss: 9.43e+07 -1.4840261936187744 0.06499025970697403\n",
      "[Step 24773] Loss: 9.31e+07 -1.4838590621948242 0.06498695909976959\n",
      "[Step 24774] Loss: 9.40e+07 -1.48367178440094 0.06500181555747986\n",
      "[Step 24775] Loss: 9.40e+07 -1.483449101448059 0.06501254439353943\n",
      "[Step 24776] Loss: 9.44e+07 -1.4832888841629028 0.06501831859350204\n",
      "[Step 24777] Loss: 9.41e+07 -1.4831156730651855 0.06502986699342728\n",
      "[Step 24778] Loss: 9.40e+07 -1.4829457998275757 0.06503976881504059\n",
      "[Step 24779] Loss: 9.45e+07 -1.4828838109970093 0.06504885107278824\n",
      "[Step 24780] Loss: 9.40e+07 -1.482811689376831 0.06504389643669128\n",
      "[Step 24781] Loss: 9.42e+07 -1.4826791286468506 0.06505132466554642\n",
      "[Step 24782] Loss: 9.42e+07 -1.4824284315109253 0.06508680433034897\n",
      "[Step 24783] Loss: 9.46e+07 -1.4822443723678589 0.06509587913751602\n",
      "[Step 24784] Loss: 9.37e+07 -1.4821542501449585 0.06510083377361298\n",
      "[Step 24785] Loss: 9.43e+07 -1.4819451570510864 0.06511981040239334\n",
      "[Step 24786] Loss: 9.41e+07 -1.4817554950714111 0.0651387870311737\n",
      "[Step 24787] Loss: 9.35e+07 -1.4815146923065186 0.06515446305274963\n",
      "[Step 24788] Loss: 9.48e+07 -1.481154203414917 0.06518252193927765\n",
      "[Step 24789] Loss: 9.38e+07 -1.4807934761047363 0.065187469124794\n",
      "[Step 24790] Loss: 9.41e+07 -1.4805583953857422 0.06520149856805801\n",
      "[Step 24791] Loss: 9.51e+07 -1.4801921844482422 0.06524193286895752\n",
      "[Step 24792] Loss: 9.45e+07 -1.4798216819763184 0.06524770706892014\n",
      "[Step 24793] Loss: 9.40e+07 -1.4793812036514282 0.06526833027601242\n",
      "[Step 24794] Loss: 9.42e+07 -1.4790817499160767 0.06527988612651825\n",
      "[Step 24795] Loss: 9.46e+07 -1.4787392616271973 0.06528235971927643\n",
      "[Step 24796] Loss: 9.36e+07 -1.4783869981765747 0.06527741253376007\n",
      "[Step 24797] Loss: 9.40e+07 -1.477999210357666 0.0653013363480568\n",
      "[Step 24798] Loss: 9.60e+07 -1.4775172472000122 0.06531701982021332\n",
      "[Step 24799] Loss: 9.40e+07 -1.4770429134368896 0.06535827368497849\n",
      "[Step 24800] Loss: 9.45e+07 -1.4765338897705078 0.06539788097143173\n",
      "[Step 24801] Loss: 9.39e+07 -1.4759926795959473 0.06542345881462097\n",
      "[Step 24802] Loss: 9.44e+07 -1.47550368309021 0.06545481830835342\n",
      "[Step 24803] Loss: 9.40e+07 -1.4749919176101685 0.06548534333705902\n",
      "[Step 24804] Loss: 9.43e+07 -1.4746037721633911 0.06550844758749008\n",
      "[Step 24805] Loss: 9.30e+07 -1.4742157459259033 0.06552660465240479\n",
      "[Step 24806] Loss: 9.51e+07 -1.4738188982009888 0.06554888188838959\n",
      "[Step 24807] Loss: 9.43e+07 -1.473433017730713 0.06557858735322952\n",
      "[Step 24808] Loss: 9.49e+07 -1.473073124885559 0.06559343636035919\n",
      "[Step 24809] Loss: 9.38e+07 -1.4726102352142334 0.0656338706612587\n",
      "[Step 24810] Loss: 9.39e+07 -1.4721088409423828 0.06566192209720612\n",
      "[Step 24811] Loss: 9.42e+07 -1.471544861793518 0.06571720540523529\n",
      "[Step 24812] Loss: 9.68e+07 -1.4713685512542725 0.0657271072268486\n",
      "[Step 24813] Loss: 9.54e+07 -1.471459150314331 0.06571720540523529\n",
      "[Step 24814] Loss: 9.37e+07 -1.4715052843093872 0.0657089576125145\n",
      "[Step 24815] Loss: 9.40e+07 -1.4715090990066528 0.06571555882692337\n",
      "[Step 24816] Loss: 9.43e+07 -1.4714117050170898 0.06571803241968155\n",
      "[Step 24817] Loss: 9.43e+07 -1.4712505340576172 0.06574196368455887\n",
      "[Step 24818] Loss: 9.42e+07 -1.4711157083511353 0.06573370844125748\n",
      "[Step 24819] Loss: 9.43e+07 -1.4710524082183838 0.0657229870557785\n",
      "[Step 24820] Loss: 9.44e+07 -1.471065878868103 0.06571225821971893\n",
      "[Step 24821] Loss: 9.48e+07 -1.4709937572479248 0.06572216004133224\n",
      "[Step 24822] Loss: 9.45e+07 -1.4708025455474854 0.06573949009180069\n",
      "[Step 24823] Loss: 9.35e+07 -1.4706090688705444 0.06573866307735443\n",
      "[Step 24824] Loss: 9.35e+07 -1.470410943031311 0.065749391913414\n",
      "[Step 24825] Loss: 9.36e+07 -1.4701645374298096 0.06577331572771072\n",
      "[Step 24826] Loss: 9.43e+07 -1.4698973894119263 0.06578074395656586\n",
      "[Step 24827] Loss: 9.40e+07 -1.4695428609848022 0.06581209599971771\n",
      "[Step 24828] Loss: 9.34e+07 -1.4691781997680664 0.06583438068628311\n",
      "[Step 24829] Loss: 9.42e+07 -1.4687167406082153 0.0658550038933754\n",
      "[Step 24830] Loss: 9.44e+07 -1.4682949781417847 0.06589378416538239\n",
      "[Step 24831] Loss: 9.41e+07 -1.4678781032562256 0.06592844426631927\n",
      "[Step 24832] Loss: 9.40e+07 -1.4675031900405884 0.06595319509506226\n",
      "[Step 24833] Loss: 9.62e+07 -1.4670169353485107 0.06597878038883209\n",
      "[Step 24834] Loss: 9.40e+07 -1.466547966003418 0.06600683182477951\n",
      "[Step 24835] Loss: 9.47e+07 -1.466210126876831 0.06603818386793137\n",
      "[Step 24836] Loss: 9.39e+07 -1.4658619165420532 0.06605386734008789\n",
      "[Step 24837] Loss: 9.44e+07 -1.4656809568405151 0.06605716794729233\n",
      "[Step 24838] Loss: 9.57e+07 -1.4653563499450684 0.06606046855449677\n",
      "[Step 24839] Loss: 9.39e+07 -1.4649938344955444 0.06609346717596054\n",
      "[Step 24840] Loss: 9.40e+07 -1.4646821022033691 0.06610254943370819\n",
      "[Step 24841] Loss: 9.37e+07 -1.4643375873565674 0.06613720208406448\n",
      "[Step 24842] Loss: 9.38e+07 -1.4640060663223267 0.06613637506961823\n",
      "[Step 24843] Loss: 9.41e+07 -1.463680624961853 0.06615205854177475\n",
      "[Step 24844] Loss: 9.71e+07 -1.4638702869415283 0.06613142788410187\n",
      "[Step 24845] Loss: 9.38e+07 -1.4640077352523804 0.06610749661922455\n",
      "[Step 24846] Loss: 9.30e+07 -1.46405029296875 0.06609346717596054\n",
      "[Step 24847] Loss: 9.40e+07 -1.4641164541244507 0.06608109176158905\n",
      "[Step 24848] Loss: 9.39e+07 -1.464205026626587 0.06607449054718018\n",
      "[Step 24849] Loss: 9.43e+07 -1.464328646659851 0.06607118993997574\n",
      "[Step 24850] Loss: 9.42e+07 -1.4644438028335571 0.06604808568954468\n",
      "[Step 24851] Loss: 9.46e+07 -1.4645506143569946 0.06603901088237762\n",
      "[Step 24852] Loss: 9.33e+07 -1.4646028280258179 0.06603818386793137\n",
      "[Step 24853] Loss: 9.68e+07 -1.4650905132293701 0.066019207239151\n",
      "[Step 24854] Loss: 9.43e+07 -1.465508222579956 0.06597878038883209\n",
      "[Step 24855] Loss: 9.36e+07 -1.4658342599868774 0.06594081968069077\n",
      "[Step 24856] Loss: 9.39e+07 -1.466074824333191 0.06592514365911484\n",
      "[Step 24857] Loss: 9.39e+07 -1.4661670923233032 0.06589378416538239\n",
      "[Step 24858] Loss: 9.34e+07 -1.466217279434204 0.06588553637266159\n",
      "[Step 24859] Loss: 9.35e+07 -1.4662244319915771 0.06588800996541977\n",
      "[Step 24860] Loss: 9.44e+07 -1.4661798477172852 0.06589378416538239\n",
      "[Step 24861] Loss: 9.38e+07 -1.4661283493041992 0.06590616703033447\n",
      "[Step 24862] Loss: 9.37e+07 -1.4659818410873413 0.06592267006635666\n",
      "[Step 24863] Loss: 9.43e+07 -1.4658645391464233 0.06592927128076553\n",
      "[Step 24864] Loss: 9.35e+07 -1.4657293558120728 0.06594081968069077\n",
      "[Step 24865] Loss: 9.47e+07 -1.4657244682312012 0.06593504548072815\n",
      "[Step 24866] Loss: 9.47e+07 -1.465796947479248 0.06591936945915222\n",
      "[Step 24867] Loss: 9.40e+07 -1.4658725261688232 0.06590946763753891\n",
      "[Step 24868] Loss: 9.43e+07 -1.465872883796692 0.0659177154302597\n",
      "[Step 24869] Loss: 9.39e+07 -1.465842366218567 0.06591606885194778\n",
      "[Step 24870] Loss: 9.35e+07 -1.465696930885315 0.06593669205904007\n",
      "[Step 24871] Loss: 9.55e+07 -1.465721845626831 0.06593504548072815\n",
      "[Step 24872] Loss: 9.38e+07 -1.465837836265564 0.06592101603746414\n",
      "[Step 24873] Loss: 9.39e+07 -1.4659228324890137 0.06591276824474335\n",
      "[Step 24874] Loss: 9.50e+07 -1.4661072492599487 0.06589791178703308\n",
      "[Step 24875] Loss: 9.38e+07 -1.4662079811096191 0.0659036859869957\n",
      "[Step 24876] Loss: 9.40e+07 -1.4663527011871338 0.06590616703033447\n",
      "[Step 24877] Loss: 9.36e+07 -1.4663565158843994 0.06589626520872116\n",
      "[Step 24878] Loss: 9.51e+07 -1.4665195941925049 0.06586325913667679\n",
      "[Step 24879] Loss: 9.51e+07 -1.4665311574935913 0.06584510207176208\n",
      "[Step 24880] Loss: 9.36e+07 -1.4664559364318848 0.06584510207176208\n",
      "[Step 24881] Loss: 9.49e+07 -1.4662457704544067 0.06584428250789642\n",
      "[Step 24882] Loss: 9.59e+07 -1.4658453464508057 0.06584592908620834\n",
      "[Step 24883] Loss: 9.54e+07 -1.4656654596328735 0.06583850085735321\n",
      "[Step 24884] Loss: 9.37e+07 -1.4654964208602905 0.06584180146455765\n",
      "[Step 24885] Loss: 9.44e+07 -1.4654107093811035 0.06583108007907867\n",
      "[Step 24886] Loss: 9.35e+07 -1.4652754068374634 0.0658327266573906\n",
      "[Step 24887] Loss: 9.40e+07 -1.465151309967041 0.06582777947187424\n",
      "[Step 24888] Loss: 9.41e+07 -1.4649739265441895 0.06583602726459503\n",
      "[Step 24889] Loss: 9.42e+07 -1.4647488594055176 0.06585583090782166\n",
      "[Step 24890] Loss: 9.41e+07 -1.4645384550094604 0.06586243212223053\n",
      "[Step 24891] Loss: 9.36e+07 -1.4642986059188843 0.06588306277990341\n",
      "[Step 24892] Loss: 9.37e+07 -1.4640240669250488 0.06587646156549454\n",
      "[Step 24893] Loss: 9.42e+07 -1.46376633644104 0.06588636338710785\n",
      "[Step 24894] Loss: 9.39e+07 -1.4634634256362915 0.06590781360864639\n",
      "[Step 24895] Loss: 9.69e+07 -1.463626503944397 0.0658913105726242\n",
      "[Step 24896] Loss: 9.51e+07 -1.4638631343841553 0.0658814087510109\n",
      "[Step 24897] Loss: 9.44e+07 -1.4642000198364258 0.0658690333366394\n",
      "[Step 24898] Loss: 9.41e+07 -1.4644023180007935 0.06585830450057983\n",
      "[Step 24899] Loss: 9.39e+07 -1.4644943475723267 0.06584098190069199\n",
      "[Step 24900] Loss: 9.43e+07 -1.4646567106246948 0.06582365185022354\n",
      "[Step 24901] Loss: 9.44e+07 -1.464800238609314 0.06581539660692215\n",
      "[Step 24902] Loss: 9.43e+07 -1.4650160074234009 0.0657939463853836\n",
      "[Step 24903] Loss: 9.49e+07 -1.465130090713501 0.06577909737825394\n",
      "[Step 24904] Loss: 9.49e+07 -1.4650709629058838 0.0657799169421196\n",
      "[Step 24905] Loss: 9.55e+07 -1.4648566246032715 0.0657980740070343\n",
      "[Step 24906] Loss: 9.38e+07 -1.46456778049469 0.06579889357089996\n",
      "[Step 24907] Loss: 9.31e+07 -1.4642574787139893 0.06581375002861023\n",
      "[Step 24908] Loss: 9.45e+07 -1.4640551805496216 0.0658327266573906\n",
      "[Step 24909] Loss: 9.58e+07 -1.4641873836517334 0.06581705063581467\n",
      "[Step 24910] Loss: 9.41e+07 -1.4643237590789795 0.06581952422857285\n",
      "[Step 24911] Loss: 9.38e+07 -1.4643592834472656 0.06582612544298172\n",
      "[Step 24912] Loss: 9.40e+07 -1.46431565284729 0.06581705063581467\n",
      "[Step 24913] Loss: 9.44e+07 -1.4642150402069092 0.06581622362136841\n",
      "[Step 24914] Loss: 9.42e+07 -1.4642138481140137 0.06580879539251328\n",
      "[Step 24915] Loss: 9.52e+07 -1.4644221067428589 0.06580797582864761\n",
      "[Step 24916] Loss: 9.41e+07 -1.4644526243209839 0.06581952422857285\n",
      "[Step 24917] Loss: 9.42e+07 -1.4644650220870972 0.06580962240695953\n",
      "[Step 24918] Loss: 9.38e+07 -1.4644359350204468 0.0658203512430191\n",
      "[Step 24919] Loss: 9.39e+07 -1.464329719543457 0.06582695245742798\n",
      "[Step 24920] Loss: 9.52e+07 -1.46413254737854 0.06584840267896652\n",
      "[Step 24921] Loss: 9.63e+07 -1.4643853902816772 0.06583520025014877\n",
      "[Step 24922] Loss: 9.34e+07 -1.4645830392837524 0.06582612544298172\n",
      "[Step 24923] Loss: 9.34e+07 -1.4647284746170044 0.0658285990357399\n",
      "[Step 24924] Loss: 9.43e+07 -1.4648953676223755 0.06582282483577728\n",
      "[Step 24925] Loss: 9.40e+07 -1.4649025201797485 0.06582695245742798\n",
      "[Step 24926] Loss: 9.49e+07 -1.4650518894195557 0.06581869721412659\n",
      "[Step 24927] Loss: 9.45e+07 -1.4651665687561035 0.06581292301416397\n",
      "[Step 24928] Loss: 9.39e+07 -1.4651484489440918 0.06580962240695953\n",
      "[Step 24929] Loss: 9.43e+07 -1.465072512626648 0.06581539660692215\n",
      "[Step 24930] Loss: 9.35e+07 -1.4649419784545898 0.06582529842853546\n",
      "[Step 24931] Loss: 9.40e+07 -1.464764952659607 0.06583685427904129\n",
      "[Step 24932] Loss: 9.49e+07 -1.4644734859466553 0.06584758311510086\n",
      "[Step 24933] Loss: 9.39e+07 -1.4641492366790771 0.06587398797273636\n",
      "[Step 24934] Loss: 9.45e+07 -1.4639136791229248 0.06589048355817795\n",
      "[Step 24935] Loss: 9.41e+07 -1.4636324644088745 0.06591854244470596\n",
      "[Step 24936] Loss: 9.42e+07 -1.4633851051330566 0.06593421846628189\n",
      "[Step 24937] Loss: 9.34e+07 -1.4631012678146362 0.06593504548072815\n",
      "[Step 24938] Loss: 9.48e+07 -1.462730050086975 0.06596557796001434\n",
      "[Step 24939] Loss: 9.50e+07 -1.4623162746429443 0.06598208099603653\n",
      "[Step 24940] Loss: 9.53e+07 -1.4618622064590454 0.0660150796175003\n",
      "[Step 24941] Loss: 9.50e+07 -1.4615962505340576 0.06601590663194656\n",
      "[Step 24942] Loss: 9.59e+07 -1.461566686630249 0.06601177901029587\n",
      "[Step 24943] Loss: 9.44e+07 -1.461531639099121 0.0660150796175003\n",
      "[Step 24944] Loss: 9.52e+07 -1.4617366790771484 0.06599775701761246\n",
      "[Step 24945] Loss: 9.47e+07 -1.4620814323425293 0.06595897674560547\n",
      "[Step 24946] Loss: 9.37e+07 -1.462454080581665 0.06592018902301788\n",
      "[Step 24947] Loss: 9.56e+07 -1.4630498886108398 0.06588058918714523\n",
      "[Step 24948] Loss: 9.49e+07 -1.463714361190796 0.06583438068628311\n",
      "[Step 24949] Loss: 9.38e+07 -1.4643210172653198 0.06579311937093735\n",
      "[Step 24950] Loss: 9.45e+07 -1.4648369550704956 0.0657716691493988\n",
      "[Step 24951] Loss: 9.44e+07 -1.46518075466156 0.06574361026287079\n",
      "[Step 24952] Loss: 9.40e+07 -1.465433120727539 0.06571803241968155\n",
      "[Step 24953] Loss: 9.44e+07 -1.465661883354187 0.0657007023692131\n",
      "[Step 24954] Loss: 9.39e+07 -1.4658766984939575 0.06569822877645493\n",
      "[Step 24955] Loss: 9.40e+07 -1.4660142660140991 0.06569162756204605\n",
      "[Step 24956] Loss: 9.41e+07 -1.4660764932632446 0.06568089872598648\n",
      "[Step 24957] Loss: 9.44e+07 -1.4661831855773926 0.06567512452602386\n",
      "[Step 24958] Loss: 9.38e+07 -1.4663525819778442 0.06566357612609863\n",
      "[Step 24959] Loss: 9.43e+07 -1.4665244817733765 0.0656520202755928\n",
      "[Step 24960] Loss: 9.36e+07 -1.4665976762771606 0.06564541906118393\n",
      "[Step 24961] Loss: 9.37e+07 -1.4666039943695068 0.06564624607563019\n",
      "[Step 24962] Loss: 9.39e+07 -1.466650128364563 0.06565120071172714\n",
      "[Step 24963] Loss: 9.39e+07 -1.4667168855667114 0.06565780192613602\n",
      "[Step 24964] Loss: 9.60e+07 -1.4665437936782837 0.06565697491168976\n",
      "[Step 24965] Loss: 9.43e+07 -1.466386318206787 0.06564624607563019\n",
      "[Step 24966] Loss: 9.46e+07 -1.466343641281128 0.06566522270441055\n",
      "[Step 24967] Loss: 9.43e+07 -1.4662134647369385 0.06565780192613602\n",
      "[Step 24968] Loss: 9.38e+07 -1.4661015272140503 0.0656602755188942\n",
      "[Step 24969] Loss: 9.40e+07 -1.4659861326217651 0.06566274911165237\n",
      "[Step 24970] Loss: 9.46e+07 -1.4658185243606567 0.0656743049621582\n",
      "[Step 24971] Loss: 9.48e+07 -1.4656645059585571 0.06569245457649231\n",
      "[Step 24972] Loss: 9.57e+07 -1.4657081365585327 0.06569162756204605\n",
      "[Step 24973] Loss: 9.38e+07 -1.46567702293396 0.06567347794771194\n",
      "[Step 24974] Loss: 9.38e+07 -1.4656466245651245 0.065682552754879\n",
      "[Step 24975] Loss: 9.44e+07 -1.4655466079711914 0.06569080054759979\n",
      "[Step 24976] Loss: 9.41e+07 -1.46552574634552 0.06568089872598648\n",
      "[Step 24977] Loss: 9.46e+07 -1.4653711318969727 0.06568998098373413\n",
      "[Step 24978] Loss: 9.43e+07 -1.4652118682861328 0.06568172574043274\n",
      "[Step 24979] Loss: 9.34e+07 -1.4649877548217773 0.065696582198143\n",
      "[Step 24980] Loss: 9.39e+07 -1.464721441268921 0.06571638584136963\n",
      "[Step 24981] Loss: 9.50e+07 -1.464686393737793 0.0657007023692131\n",
      "[Step 24982] Loss: 9.34e+07 -1.4646121263504028 0.06569410115480423\n",
      "[Step 24983] Loss: 9.48e+07 -1.4644938707351685 0.06570565700531006\n",
      "[Step 24984] Loss: 9.48e+07 -1.4642406702041626 0.06571225821971893\n",
      "[Step 24985] Loss: 9.48e+07 -1.4641828536987305 0.06571803241968155\n",
      "[Step 24986] Loss: 9.37e+07 -1.4640531539916992 0.06571555882692337\n",
      "[Step 24987] Loss: 9.47e+07 -1.4638395309448242 0.0657229870557785\n",
      "[Step 24988] Loss: 9.46e+07 -1.4637479782104492 0.06570648401975632\n",
      "[Step 24989] Loss: 9.39e+07 -1.4636571407318115 0.06570648401975632\n",
      "[Step 24990] Loss: 9.37e+07 -1.4634844064712524 0.065696582198143\n",
      "[Step 24991] Loss: 9.36e+07 -1.4632803201675415 0.06570152938365936\n",
      "[Step 24992] Loss: 9.48e+07 -1.4629648923873901 0.06573618948459625\n",
      "[Step 24993] Loss: 9.47e+07 -1.4627702236175537 0.06574773788452148\n",
      "[Step 24994] Loss: 9.37e+07 -1.4625333547592163 0.0657535120844841\n",
      "[Step 24995] Loss: 9.43e+07 -1.4622788429260254 0.06576754152774811\n",
      "[Step 24996] Loss: 9.48e+07 -1.4621721506118774 0.06576589494943619\n",
      "[Step 24997] Loss: 9.40e+07 -1.4620884656906128 0.06577909737825394\n",
      "[Step 24998] Loss: 9.37e+07 -1.4619131088256836 0.0658063217997551\n",
      "[Step 24999] Loss: 9.52e+07 -1.4619114398956299 0.06582117825746536\n",
      "[Step 25000] Loss: 9.67e+07 -1.4622963666915894 0.06578899174928665\n",
      "[Step 25001] Loss: 9.41e+07 -1.4625177383422852 0.06577084213495255\n",
      "[Step 25002] Loss: 9.41e+07 -1.4627193212509155 0.06578651815652847\n",
      "[Step 25003] Loss: 9.43e+07 -1.4630144834518433 0.06577414274215698\n",
      "[Step 25004] Loss: 9.38e+07 -1.4632996320724487 0.06575186550617218\n",
      "[Step 25005] Loss: 9.41e+07 -1.4635404348373413 0.06575516611337662\n",
      "[Step 25006] Loss: 9.42e+07 -1.4637891054153442 0.06574856489896774\n",
      "[Step 25007] Loss: 9.39e+07 -1.463956356048584 0.06575516611337662\n",
      "[Step 25008] Loss: 9.51e+07 -1.4639654159545898 0.06578734517097473\n",
      "[Step 25009] Loss: 9.38e+07 -1.463934063911438 0.0657939463853836\n",
      "[Step 25010] Loss: 9.43e+07 -1.4639068841934204 0.06581457704305649\n",
      "[Step 25011] Loss: 9.45e+07 -1.4638687372207642 0.06580302119255066\n",
      "[Step 25012] Loss: 9.40e+07 -1.4639167785644531 0.06580797582864761\n",
      "[Step 25013] Loss: 9.48e+07 -1.4641014337539673 0.0657939463853836\n",
      "[Step 25014] Loss: 9.43e+07 -1.4642269611358643 0.06578157097101212\n",
      "[Step 25015] Loss: 9.40e+07 -1.464206337928772 0.06578899174928665\n",
      "[Step 25016] Loss: 9.52e+07 -1.4640432596206665 0.06580054759979248\n",
      "[Step 25017] Loss: 9.36e+07 -1.4638526439666748 0.06581292301416397\n",
      "[Step 25018] Loss: 9.42e+07 -1.4636861085891724 0.06584428250789642\n",
      "[Step 25019] Loss: 9.49e+07 -1.463701844215393 0.06585005670785904\n",
      "[Step 25020] Loss: 9.40e+07 -1.46370530128479 0.06583768129348755\n",
      "[Step 25021] Loss: 9.43e+07 -1.463842511177063 0.06582612544298172\n",
      "[Step 25022] Loss: 9.40e+07 -1.4639464616775513 0.06581622362136841\n",
      "[Step 25023] Loss: 9.41e+07 -1.4640637636184692 0.06581539660692215\n",
      "[Step 25024] Loss: 9.41e+07 -1.4640512466430664 0.06581044942140579\n",
      "[Step 25025] Loss: 9.40e+07 -1.4639695882797241 0.06582282483577728\n",
      "[Step 25026] Loss: 9.42e+07 -1.4638594388961792 0.06583189964294434\n",
      "[Step 25027] Loss: 9.42e+07 -1.463791012763977 0.06582612544298172\n",
      "[Step 25028] Loss: 9.46e+07 -1.4637068510055542 0.0658467561006546\n",
      "[Step 25029] Loss: 9.44e+07 -1.463701844215393 0.06585830450057983\n",
      "[Step 25030] Loss: 9.39e+07 -1.4637317657470703 0.06585418432950974\n",
      "[Step 25031] Loss: 9.43e+07 -1.4637290239334106 0.06584840267896652\n",
      "[Step 25032] Loss: 9.40e+07 -1.4636834859848022 0.06585253030061722\n",
      "[Step 25033] Loss: 9.43e+07 -1.463600754737854 0.06585830450057983\n",
      "[Step 25034] Loss: 9.47e+07 -1.4636155366897583 0.06585583090782166\n",
      "[Step 25035] Loss: 9.47e+07 -1.4637166261672974 0.06581457704305649\n",
      "[Step 25036] Loss: 9.39e+07 -1.4636882543563843 0.06581705063581467\n",
      "[Step 25037] Loss: 9.43e+07 -1.4637151956558228 0.06581292301416397\n",
      "[Step 25038] Loss: 9.40e+07 -1.4636695384979248 0.06582942605018616\n",
      "[Step 25039] Loss: 9.44e+07 -1.463642954826355 0.06583602726459503\n",
      "[Step 25040] Loss: 9.37e+07 -1.4636038541793823 0.06582942605018616\n",
      "[Step 25041] Loss: 9.45e+07 -1.463636040687561 0.06583189964294434\n",
      "[Step 25042] Loss: 9.45e+07 -1.4636598825454712 0.06583520025014877\n",
      "[Step 25043] Loss: 9.39e+07 -1.4636343717575073 0.06583025306463242\n",
      "[Step 25044] Loss: 9.53e+07 -1.463529348373413 0.06584180146455765\n",
      "[Step 25045] Loss: 9.41e+07 -1.4633829593658447 0.06583520025014877\n",
      "[Step 25046] Loss: 9.52e+07 -1.4634172916412354 0.06583685427904129\n",
      "[Step 25047] Loss: 9.39e+07 -1.4633523225784302 0.06582529842853546\n",
      "[Step 25048] Loss: 9.40e+07 -1.4632493257522583 0.06583025306463242\n",
      "[Step 25049] Loss: 9.45e+07 -1.4632420539855957 0.0658327266573906\n",
      "[Step 25050] Loss: 9.36e+07 -1.4631175994873047 0.06582282483577728\n",
      "[Step 25051] Loss: 9.39e+07 -1.4629504680633545 0.06582612544298172\n",
      "[Step 25052] Loss: 9.59e+07 -1.4630212783813477 0.06583768129348755\n",
      "[Step 25053] Loss: 9.39e+07 -1.463042140007019 0.06583768129348755\n",
      "[Step 25054] Loss: 9.46e+07 -1.463159441947937 0.06583355367183685\n",
      "[Step 25055] Loss: 9.40e+07 -1.4632618427276611 0.06583932787179947\n",
      "[Step 25056] Loss: 9.45e+07 -1.4633984565734863 0.06583932787179947\n",
      "[Step 25057] Loss: 9.56e+07 -1.4633487462997437 0.06586490571498871\n",
      "[Step 25058] Loss: 9.57e+07 -1.4635921716690063 0.06586160510778427\n",
      "[Step 25059] Loss: 9.37e+07 -1.4638404846191406 0.06584180146455765\n",
      "[Step 25060] Loss: 9.51e+07 -1.4642152786254883 0.06582942605018616\n",
      "[Step 25061] Loss: 9.41e+07 -1.4645811319351196 0.06582117825746536\n",
      "[Step 25062] Loss: 9.38e+07 -1.464827299118042 0.06581622362136841\n",
      "[Step 25063] Loss: 9.47e+07 -1.4650238752365112 0.06581044942140579\n",
      "[Step 25064] Loss: 9.45e+07 -1.4652628898620605 0.06581209599971771\n",
      "[Step 25065] Loss: 9.55e+07 -1.4658945798873901 0.0657799169421196\n",
      "[Step 25066] Loss: 9.44e+07 -1.4664514064788818 0.06574030965566635\n",
      "[Step 25067] Loss: 9.41e+07 -1.4668415784835815 0.06570400297641754\n",
      "[Step 25068] Loss: 9.42e+07 -1.4672443866729736 0.06567677855491638\n",
      "[Step 25069] Loss: 9.48e+07 -1.4677156209945679 0.06565944850444794\n",
      "[Step 25070] Loss: 9.42e+07 -1.4681931734085083 0.06565120071172714\n",
      "[Step 25071] Loss: 9.38e+07 -1.4685091972351074 0.06565450131893158\n",
      "[Step 25072] Loss: 9.37e+07 -1.4687764644622803 0.06564871966838837\n",
      "[Step 25073] Loss: 9.41e+07 -1.468923807144165 0.06563469767570496\n",
      "[Step 25074] Loss: 9.44e+07 -1.469192624092102 0.06561819463968277\n",
      "[Step 25075] Loss: 9.63e+07 -1.4692081212997437 0.06562396883964539\n",
      "[Step 25076] Loss: 9.38e+07 -1.4691637754440308 0.06561406701803207\n",
      "[Step 25077] Loss: 9.49e+07 -1.4693104028701782 0.0656033381819725\n",
      "[Step 25078] Loss: 9.47e+07 -1.469321846961975 0.06560251116752625\n",
      "[Step 25079] Loss: 9.61e+07 -1.4697628021240234 0.0655851885676384\n",
      "[Step 25080] Loss: 9.41e+07 -1.4702426195144653 0.06555382907390594\n",
      "[Step 25081] Loss: 9.39e+07 -1.4707515239715576 0.06551092118024826\n",
      "[Step 25082] Loss: 9.55e+07 -1.4715427160263062 0.06547132134437561\n",
      "[Step 25083] Loss: 9.41e+07 -1.4722219705581665 0.06542345881462097\n",
      "[Step 25084] Loss: 9.49e+07 -1.472678303718567 0.06540282815694809\n",
      "[Step 25085] Loss: 9.37e+07 -1.4730488061904907 0.06538797914981842\n",
      "[Step 25086] Loss: 9.56e+07 -1.473656415939331 0.06535910069942474\n",
      "[Step 25087] Loss: 9.39e+07 -1.4741401672363281 0.06531619280576706\n",
      "[Step 25088] Loss: 9.40e+07 -1.4745043516159058 0.06528813391923904\n",
      "[Step 25089] Loss: 9.73e+07 -1.4753352403640747 0.06524275243282318\n",
      "[Step 25090] Loss: 9.33e+07 -1.476041555404663 0.06519819796085358\n",
      "[Step 25091] Loss: 9.42e+07 -1.4766467809677124 0.06515611708164215\n",
      "[Step 25092] Loss: 9.38e+07 -1.4771721363067627 0.0651165097951889\n",
      "[Step 25093] Loss: 9.41e+07 -1.4775240421295166 0.06508433073759079\n",
      "[Step 25094] Loss: 9.47e+07 -1.4777460098266602 0.06507524847984314\n",
      "[Step 25095] Loss: 9.45e+07 -1.477910041809082 0.06507937610149384\n",
      "[Step 25096] Loss: 9.47e+07 -1.4779291152954102 0.0650719478726387\n",
      "[Step 25097] Loss: 9.47e+07 -1.4780563116073608 0.06507360190153122\n",
      "[Step 25098] Loss: 9.52e+07 -1.4780335426330566 0.06509753316640854\n",
      "[Step 25099] Loss: 9.51e+07 -1.4778382778167725 0.0650983527302742\n",
      "[Step 25100] Loss: 9.38e+07 -1.4776593446731567 0.06510495394468307\n",
      "[Step 25101] Loss: 9.39e+07 -1.4774956703186035 0.06512145698070526\n",
      "[Step 25102] Loss: 9.48e+07 -1.4774469137191772 0.06512228399515152\n",
      "[Step 25103] Loss: 9.39e+07 -1.4774014949798584 0.06514126062393188\n",
      "[Step 25104] Loss: 9.43e+07 -1.4772603511810303 0.0651651918888092\n",
      "[Step 25105] Loss: 9.40e+07 -1.477156400680542 0.06516601890325546\n",
      "[Step 25106] Loss: 9.38e+07 -1.4769583940505981 0.06518664211034775\n",
      "[Step 25107] Loss: 9.34e+07 -1.4767662286758423 0.06519324332475662\n",
      "[Step 25108] Loss: 9.49e+07 -1.476496934890747 0.0651998445391655\n",
      "[Step 25109] Loss: 9.47e+07 -1.476102352142334 0.06522047519683838\n",
      "[Step 25110] Loss: 9.38e+07 -1.4756479263305664 0.06524193286895752\n",
      "[Step 25111] Loss: 9.37e+07 -1.4752559661865234 0.06526833027601242\n",
      "[Step 25112] Loss: 9.70e+07 -1.4754022359848022 0.0652666836977005\n",
      "[Step 25113] Loss: 9.38e+07 -1.475425362586975 0.06525513529777527\n",
      "[Step 25114] Loss: 9.41e+07 -1.4754197597503662 0.06526090949773788\n",
      "[Step 25115] Loss: 9.42e+07 -1.47539222240448 0.06525925546884537\n",
      "[Step 25116] Loss: 9.41e+07 -1.4753167629241943 0.06525925546884537\n",
      "[Step 25117] Loss: 9.36e+07 -1.4751828908920288 0.0652848333120346\n",
      "[Step 25118] Loss: 9.39e+07 -1.4750319719314575 0.06528731435537338\n",
      "[Step 25119] Loss: 9.38e+07 -1.4748846292495728 0.06529968976974487\n",
      "[Step 25120] Loss: 9.40e+07 -1.4746650457382202 0.06532939523458481\n",
      "[Step 25121] Loss: 9.42e+07 -1.4744644165039062 0.06533516943454742\n",
      "[Step 25122] Loss: 9.73e+07 -1.474800705909729 0.0653194934129715\n",
      "[Step 25123] Loss: 9.51e+07 -1.4752768278121948 0.0652889609336853\n",
      "[Step 25124] Loss: 9.40e+07 -1.4756742715835571 0.06526173651218414\n",
      "[Step 25125] Loss: 9.40e+07 -1.4759628772735596 0.06525348126888275\n",
      "[Step 25126] Loss: 9.75e+07 -1.4767106771469116 0.06521222740411758\n",
      "[Step 25127] Loss: 9.38e+07 -1.4773571491241455 0.06516849249601364\n",
      "[Step 25128] Loss: 9.32e+07 -1.4778354167938232 0.06513631343841553\n",
      "[Step 25129] Loss: 9.48e+07 -1.4780853986740112 0.06510825455188751\n",
      "[Step 25130] Loss: 9.43e+07 -1.47828209400177 0.06509257853031158\n",
      "[Step 25131] Loss: 9.39e+07 -1.4783440828323364 0.0650802031159401\n",
      "[Step 25132] Loss: 9.48e+07 -1.478511929512024 0.06507277488708496\n",
      "[Step 25133] Loss: 9.38e+07 -1.4785640239715576 0.06506452709436417\n",
      "[Step 25134] Loss: 9.51e+07 -1.4784358739852905 0.06507854908704758\n",
      "[Step 25135] Loss: 9.46e+07 -1.4782873392105103 0.06509753316640854\n",
      "[Step 25136] Loss: 9.41e+07 -1.478247046470642 0.06510578095912933\n",
      "[Step 25137] Loss: 9.52e+07 -1.4781121015548706 0.06509917974472046\n",
      "[Step 25138] Loss: 9.47e+07 -1.4779760837554932 0.06511568278074265\n",
      "[Step 25139] Loss: 9.43e+07 -1.4778916835784912 0.06513631343841553\n",
      "[Step 25140] Loss: 9.45e+07 -1.4778900146484375 0.06513714045286179\n",
      "[Step 25141] Loss: 9.41e+07 -1.4778032302856445 0.06514868885278702\n",
      "[Step 25142] Loss: 9.48e+07 -1.4775415658950806 0.06515446305274963\n",
      "[Step 25143] Loss: 9.36e+07 -1.4772393703460693 0.06517426669597626\n",
      "[Step 25144] Loss: 9.44e+07 -1.4769799709320068 0.06520479917526245\n",
      "[Step 25145] Loss: 9.44e+07 -1.4767662286758423 0.0652221292257309\n",
      "[Step 25146] Loss: 9.45e+07 -1.476623296737671 0.06522130221128464\n",
      "[Step 25147] Loss: 9.67e+07 -1.4769823551177979 0.06521552801132202\n",
      "[Step 25148] Loss: 9.46e+07 -1.4773268699645996 0.06519737094640732\n",
      "[Step 25149] Loss: 9.40e+07 -1.477638840675354 0.06517509371042252\n",
      "[Step 25150] Loss: 9.38e+07 -1.4779123067855835 0.06516353785991669\n",
      "[Step 25151] Loss: 9.39e+07 -1.478081226348877 0.06515034288167953\n",
      "[Step 25152] Loss: 9.38e+07 -1.4781614542007446 0.06515529006719589\n",
      "[Step 25153] Loss: 9.37e+07 -1.4782133102416992 0.06516766548156738\n",
      "[Step 25154] Loss: 9.56e+07 -1.4780668020248413 0.06517592072486877\n",
      "[Step 25155] Loss: 9.44e+07 -1.4778109788894653 0.06518994271755219\n",
      "[Step 25156] Loss: 9.42e+07 -1.4775933027267456 0.06519407033920288\n",
      "[Step 25157] Loss: 9.51e+07 -1.4775686264038086 0.06520479917526245\n",
      "[Step 25158] Loss: 9.46e+07 -1.4777355194091797 0.06520067155361176\n",
      "[Step 25159] Loss: 9.51e+07 -1.478081464767456 0.06516271829605103\n",
      "[Step 25160] Loss: 9.38e+07 -1.4782534837722778 0.0651429146528244\n",
      "[Step 25161] Loss: 9.40e+07 -1.4783446788787842 0.06514044106006622\n",
      "[Step 25162] Loss: 9.41e+07 -1.47852623462677 0.0651429146528244\n",
      "[Step 25163] Loss: 9.38e+07 -1.4785902500152588 0.06514126062393188\n",
      "[Step 25164] Loss: 9.40e+07 -1.4786639213562012 0.06513631343841553\n",
      "[Step 25165] Loss: 9.59e+07 -1.4789685010910034 0.0651024803519249\n",
      "[Step 25166] Loss: 9.44e+07 -1.479089617729187 0.0650901049375534\n",
      "[Step 25167] Loss: 9.38e+07 -1.4791899919509888 0.06508763134479523\n",
      "[Step 25168] Loss: 9.38e+07 -1.4792426824569702 0.06508680433034897\n",
      "[Step 25169] Loss: 9.40e+07 -1.4791474342346191 0.06508680433034897\n",
      "[Step 25170] Loss: 9.36e+07 -1.479072093963623 0.06508350372314453\n",
      "[Step 25171] Loss: 9.45e+07 -1.4789185523986816 0.06509093195199966\n",
      "[Step 25172] Loss: 9.39e+07 -1.4787869453430176 0.06507442891597748\n",
      "[Step 25173] Loss: 9.38e+07 -1.4786458015441895 0.06507030129432678\n",
      "[Step 25174] Loss: 9.40e+07 -1.4785343408584595 0.06505957245826721\n",
      "[Step 25175] Loss: 9.42e+07 -1.4785302877426147 0.06506122648715973\n",
      "[Step 25176] Loss: 9.37e+07 -1.4785313606262207 0.06505627185106277\n",
      "[Step 25177] Loss: 9.45e+07 -1.4785069227218628 0.06505709886550903\n",
      "[Step 25178] Loss: 9.44e+07 -1.478377342224121 0.06505957245826721\n",
      "[Step 25179] Loss: 9.44e+07 -1.4781336784362793 0.06506947427988052\n",
      "[Step 25180] Loss: 9.40e+07 -1.477903127670288 0.06508350372314453\n",
      "[Step 25181] Loss: 9.48e+07 -1.4778592586517334 0.06507112830877304\n",
      "[Step 25182] Loss: 9.42e+07 -1.477798342704773 0.06506864726543427\n",
      "[Step 25183] Loss: 9.40e+07 -1.4777066707611084 0.06505627185106277\n",
      "[Step 25184] Loss: 9.35e+07 -1.4776179790496826 0.06505627185106277\n",
      "[Step 25185] Loss: 9.43e+07 -1.4774339199066162 0.0650678277015686\n",
      "[Step 25186] Loss: 9.38e+07 -1.477237343788147 0.06508597731590271\n",
      "[Step 25187] Loss: 9.37e+07 -1.4770393371582031 0.06508184969425201\n",
      "[Step 25188] Loss: 9.39e+07 -1.4769008159637451 0.06509917974472046\n",
      "[Step 25189] Loss: 9.44e+07 -1.476739525794983 0.06511155515909195\n",
      "[Step 25190] Loss: 9.40e+07 -1.4765750169754028 0.06512228399515152\n",
      "[Step 25191] Loss: 9.37e+07 -1.4764217138290405 0.06513631343841553\n",
      "[Step 25192] Loss: 9.40e+07 -1.4762673377990723 0.0651429146528244\n",
      "[Step 25193] Loss: 9.39e+07 -1.4761435985565186 0.06516106426715851\n",
      "[Step 25194] Loss: 9.42e+07 -1.4760730266571045 0.06516024470329285\n",
      "[Step 25195] Loss: 9.38e+07 -1.475939154624939 0.06518829613924026\n",
      "[Step 25196] Loss: 9.38e+07 -1.4758251905441284 0.06518994271755219\n",
      "[Step 25197] Loss: 9.41e+07 -1.4757916927337646 0.06518994271755219\n",
      "[Step 25198] Loss: 9.40e+07 -1.4756505489349365 0.06518499553203583\n",
      "[Step 25199] Loss: 9.64e+07 -1.4759389162063599 0.06518004089593887\n",
      "[Step 25200] Loss: 9.39e+07 -1.4761970043182373 0.06515446305274963\n",
      "[Step 25201] Loss: 9.46e+07 -1.4763131141662598 0.06515281647443771\n",
      "[Step 25202] Loss: 9.39e+07 -1.4763387441635132 0.06515859067440033\n",
      "[Step 25203] Loss: 9.43e+07 -1.4764103889465332 0.0651470422744751\n",
      "[Step 25204] Loss: 9.38e+07 -1.4763917922973633 0.06515364348888397\n",
      "[Step 25205] Loss: 9.38e+07 -1.4764240980148315 0.06516189128160477\n",
      "[Step 25206] Loss: 9.43e+07 -1.4764587879180908 0.06515859067440033\n",
      "[Step 25207] Loss: 9.42e+07 -1.4762771129608154 0.06516106426715851\n",
      "[Step 25208] Loss: 9.44e+07 -1.4761862754821777 0.06516436487436295\n",
      "[Step 25209] Loss: 9.33e+07 -1.4760619401931763 0.06517262011766434\n",
      "[Step 25210] Loss: 9.42e+07 -1.475811243057251 0.06518334150314331\n",
      "[Step 25211] Loss: 9.61e+07 -1.475379228591919 0.06519489735364914\n",
      "[Step 25212] Loss: 9.35e+07 -1.4749137163162231 0.06522130221128464\n",
      "[Step 25213] Loss: 9.45e+07 -1.4745022058486938 0.06525595486164093\n",
      "[Step 25214] Loss: 9.51e+07 -1.4743595123291016 0.06525513529777527\n",
      "[Step 25215] Loss: 9.46e+07 -1.4742785692214966 0.06526421010494232\n",
      "[Step 25216] Loss: 9.42e+07 -1.474331021308899 0.06526502966880798\n",
      "[Step 25217] Loss: 9.53e+07 -1.4742670059204102 0.06526833027601242\n",
      "[Step 25218] Loss: 9.51e+07 -1.4744313955307007 0.06525595486164093\n",
      "[Step 25219] Loss: 9.40e+07 -1.4745492935180664 0.06526173651218414\n",
      "[Step 25220] Loss: 9.43e+07 -1.4747291803359985 0.06525513529777527\n",
      "[Step 25221] Loss: 9.37e+07 -1.4748990535736084 0.06522790342569351\n",
      "[Step 25222] Loss: 9.39e+07 -1.4750741720199585 0.06520892679691315\n",
      "[Step 25223] Loss: 9.37e+07 -1.4752229452133179 0.06519489735364914\n",
      "[Step 25224] Loss: 9.46e+07 -1.4754868745803833 0.06518169492483139\n",
      "[Step 25225] Loss: 9.44e+07 -1.475635290145874 0.06517262011766434\n",
      "[Step 25226] Loss: 9.41e+07 -1.475752353668213 0.06516353785991669\n",
      "[Step 25227] Loss: 9.44e+07 -1.4759489297866821 0.06513383984565735\n",
      "[Step 25228] Loss: 9.71e+07 -1.4766072034835815 0.06509670615196228\n",
      "[Step 25229] Loss: 9.52e+07 -1.4772499799728394 0.06507442891597748\n",
      "[Step 25230] Loss: 9.40e+07 -1.477793574333191 0.06504885107278824\n",
      "[Step 25231] Loss: 9.45e+07 -1.478214979171753 0.06500594317913055\n",
      "[Step 25232] Loss: 9.45e+07 -1.4786540269851685 0.0649828389286995\n",
      "[Step 25233] Loss: 9.41e+07 -1.47905433177948 0.06493993103504181\n",
      "[Step 25234] Loss: 9.44e+07 -1.4793729782104492 0.06490609794855118\n",
      "[Step 25235] Loss: 9.39e+07 -1.4795985221862793 0.06489289551973343\n",
      "[Step 25236] Loss: 9.45e+07 -1.479682207107544 0.0648994967341423\n",
      "[Step 25237] Loss: 9.46e+07 -1.4796968698501587 0.06488629430532455\n",
      "[Step 25238] Loss: 9.46e+07 -1.47970449924469 0.06488712131977081\n",
      "[Step 25239] Loss: 9.40e+07 -1.4796009063720703 0.06489785015583038\n",
      "[Step 25240] Loss: 9.57e+07 -1.4793682098388672 0.0649077519774437\n",
      "[Step 25241] Loss: 9.36e+07 -1.479142427444458 0.0649217739701271\n",
      "[Step 25242] Loss: 9.41e+07 -1.4787925481796265 0.06492920219898224\n",
      "[Step 25243] Loss: 9.42e+07 -1.4784401655197144 0.06495478004217148\n",
      "[Step 25244] Loss: 9.43e+07 -1.4781240224838257 0.06497128307819366\n",
      "[Step 25245] Loss: 9.42e+07 -1.4778095483779907 0.06497953832149506\n",
      "[Step 25246] Loss: 9.42e+07 -1.4774818420410156 0.06499438732862473\n",
      "[Step 25247] Loss: 9.38e+07 -1.4771127700805664 0.06502822041511536\n",
      "[Step 25248] Loss: 9.40e+07 -1.4768019914627075 0.06505049765110016\n",
      "[Step 25249] Loss: 9.43e+07 -1.4764219522476196 0.06507030129432678\n",
      "[Step 25250] Loss: 9.36e+07 -1.476090669631958 0.06510165333747864\n",
      "[Step 25251] Loss: 9.44e+07 -1.4756797552108765 0.06511403620243073\n",
      "[Step 25252] Loss: 9.35e+07 -1.475270390510559 0.06514374166727066\n",
      "[Step 25253] Loss: 9.39e+07 -1.4748810529708862 0.06516601890325546\n",
      "[Step 25254] Loss: 9.43e+07 -1.4745570421218872 0.06518829613924026\n",
      "[Step 25255] Loss: 9.39e+07 -1.4742094278335571 0.06521882861852646\n",
      "[Step 25256] Loss: 9.41e+07 -1.4738272428512573 0.06523863226175308\n",
      "[Step 25257] Loss: 9.42e+07 -1.4733819961547852 0.06527328491210938\n",
      "[Step 25258] Loss: 9.42e+07 -1.4729353189468384 0.0652848333120346\n",
      "[Step 25259] Loss: 9.53e+07 -1.4724878072738647 0.06529803574085236\n",
      "[Step 25260] Loss: 9.38e+07 -1.4720155000686646 0.06531453877687454\n",
      "[Step 25261] Loss: 9.37e+07 -1.4714735746383667 0.06535002589225769\n",
      "[Step 25262] Loss: 9.41e+07 -1.4709800481796265 0.06539705395698547\n",
      "[Step 25263] Loss: 9.37e+07 -1.470427393913269 0.06543006002902985\n",
      "[Step 25264] Loss: 9.37e+07 -1.4699318408966064 0.06544739007949829\n",
      "[Step 25265] Loss: 9.35e+07 -1.4695026874542236 0.06547379493713379\n",
      "[Step 25266] Loss: 9.38e+07 -1.4690449237823486 0.06551092118024826\n",
      "[Step 25267] Loss: 9.37e+07 -1.4686682224273682 0.0655546560883522\n",
      "[Step 25268] Loss: 9.37e+07 -1.468263864517212 0.06556621193885803\n",
      "[Step 25269] Loss: 9.44e+07 -1.4679505825042725 0.0655851885676384\n",
      "[Step 25270] Loss: 9.37e+07 -1.46756112575531 0.06561076641082764\n",
      "[Step 25271] Loss: 9.44e+07 -1.4672096967697144 0.06560911238193512\n",
      "[Step 25272] Loss: 9.44e+07 -1.4668279886245728 0.065629743039608\n",
      "[Step 25273] Loss: 9.41e+07 -1.46649968624115 0.06564954668283463\n",
      "[Step 25274] Loss: 9.38e+07 -1.4661667346954346 0.06567182391881943\n",
      "[Step 25275] Loss: 9.35e+07 -1.4657703638076782 0.06569410115480423\n",
      "[Step 25276] Loss: 9.38e+07 -1.4653356075286865 0.06571060419082642\n",
      "[Step 25277] Loss: 9.43e+07 -1.4650105237960815 0.0657312348484993\n",
      "[Step 25278] Loss: 9.38e+07 -1.4646905660629272 0.06574279069900513\n",
      "[Step 25279] Loss: 9.41e+07 -1.4644025564193726 0.06576094031333923\n",
      "[Step 25280] Loss: 9.36e+07 -1.46404230594635 0.06577001512050629\n",
      "[Step 25281] Loss: 9.69e+07 -1.4640929698944092 0.06578074395656586\n",
      "[Step 25282] Loss: 9.48e+07 -1.4643563032150269 0.06575021147727966\n",
      "[Step 25283] Loss: 9.42e+07 -1.4646650552749634 0.06573040783405304\n",
      "[Step 25284] Loss: 9.50e+07 -1.4649611711502075 0.06569162756204605\n",
      "[Step 25285] Loss: 9.37e+07 -1.4651854038238525 0.06567017734050751\n",
      "[Step 25286] Loss: 9.46e+07 -1.4652423858642578 0.06567017734050751\n",
      "[Step 25287] Loss: 9.35e+07 -1.4652719497680664 0.06566852331161499\n",
      "[Step 25288] Loss: 9.54e+07 -1.4652204513549805 0.06566935032606125\n",
      "[Step 25289] Loss: 9.47e+07 -1.465113639831543 0.0656743049621582\n",
      "[Step 25290] Loss: 9.38e+07 -1.4649089574813843 0.06567595154047012\n",
      "[Step 25291] Loss: 9.43e+07 -1.4646674394607544 0.06567925214767456\n",
      "[Step 25292] Loss: 9.42e+07 -1.4644564390182495 0.06568585336208344\n",
      "[Step 25293] Loss: 9.35e+07 -1.4641939401626587 0.06570813059806824\n",
      "[Step 25294] Loss: 9.42e+07 -1.4638768434524536 0.06572050601243973\n",
      "[Step 25295] Loss: 9.41e+07 -1.4635783433914185 0.06574609130620956\n",
      "[Step 25296] Loss: 9.42e+07 -1.4634418487548828 0.06575599312782288\n",
      "[Step 25297] Loss: 9.37e+07 -1.463249683380127 0.06576754152774811\n",
      "[Step 25298] Loss: 9.39e+07 -1.4630590677261353 0.06578734517097473\n",
      "[Step 25299] Loss: 9.53e+07 -1.462795376777649 0.06579559296369553\n",
      "[Step 25300] Loss: 9.43e+07 -1.4624541997909546 0.06582695245742798\n",
      "[Step 25301] Loss: 9.42e+07 -1.4622029066085815 0.06583602726459503\n",
      "[Step 25302] Loss: 9.48e+07 -1.4620741605758667 0.06584180146455765\n",
      "[Step 25303] Loss: 9.47e+07 -1.4618891477584839 0.0658550038933754\n",
      "[Step 25304] Loss: 9.33e+07 -1.4616644382476807 0.06586325913667679\n",
      "[Step 25305] Loss: 9.43e+07 -1.4614814519882202 0.06587480753660202\n",
      "[Step 25306] Loss: 9.38e+07 -1.4613078832626343 0.0659036859869957\n",
      "[Step 25307] Loss: 9.58e+07 -1.4614750146865845 0.06587893515825272\n",
      "[Step 25308] Loss: 9.38e+07 -1.4616103172302246 0.06586573272943497\n",
      "[Step 25309] Loss: 9.42e+07 -1.4617961645126343 0.06585583090782166\n",
      "[Step 25310] Loss: 9.39e+07 -1.46189284324646 0.06584428250789642\n",
      "[Step 25311] Loss: 9.45e+07 -1.4619286060333252 0.06583602726459503\n",
      "[Step 25312] Loss: 9.39e+07 -1.4619359970092773 0.06585170328617096\n",
      "[Step 25313] Loss: 9.35e+07 -1.4619052410125732 0.06585913151502609\n",
      "[Step 25314] Loss: 9.42e+07 -1.4619523286819458 0.06585748493671417\n",
      "[Step 25315] Loss: 9.38e+07 -1.462035894393921 0.06584098190069199\n",
      "[Step 25316] Loss: 9.40e+07 -1.4621424674987793 0.06582199782133102\n",
      "[Step 25317] Loss: 9.47e+07 -1.4621119499206543 0.0658426284790039\n",
      "[Step 25318] Loss: 9.60e+07 -1.4624630212783813 0.06581457704305649\n",
      "[Step 25319] Loss: 9.39e+07 -1.4627186059951782 0.06581787765026093\n",
      "[Step 25320] Loss: 9.45e+07 -1.4628493785858154 0.06582199782133102\n",
      "[Step 25321] Loss: 9.38e+07 -1.4628636837005615 0.06583189964294434\n",
      "[Step 25322] Loss: 9.37e+07 -1.4628509283065796 0.06583768129348755\n",
      "[Step 25323] Loss: 9.45e+07 -1.4627727270126343 0.0658467561006546\n",
      "[Step 25324] Loss: 9.37e+07 -1.4627690315246582 0.06585253030061722\n",
      "[Step 25325] Loss: 9.54e+07 -1.4630876779556274 0.06583108007907867\n",
      "[Step 25326] Loss: 9.39e+07 -1.4633210897445679 0.0658327266573906\n",
      "[Step 25327] Loss: 9.39e+07 -1.4635194540023804 0.0658327266573906\n",
      "[Step 25328] Loss: 9.51e+07 -1.4635365009307861 0.06582529842853546\n",
      "[Step 25329] Loss: 9.46e+07 -1.4636619091033936 0.06582117825746536\n",
      "[Step 25330] Loss: 9.50e+07 -1.463692545890808 0.06581787765026093\n",
      "[Step 25331] Loss: 9.41e+07 -1.4635900259017944 0.0658244788646698\n",
      "[Step 25332] Loss: 9.36e+07 -1.4634239673614502 0.0658467561006546\n",
      "[Step 25333] Loss: 9.48e+07 -1.4632965326309204 0.06585830450057983\n",
      "[Step 25334] Loss: 9.42e+07 -1.4631145000457764 0.06587068736553192\n",
      "[Step 25335] Loss: 9.39e+07 -1.4630026817321777 0.06588223576545715\n",
      "[Step 25336] Loss: 9.54e+07 -1.4627974033355713 0.0658913105726242\n",
      "[Step 25337] Loss: 9.42e+07 -1.4624993801116943 0.06590534001588821\n",
      "[Step 25338] Loss: 9.38e+07 -1.4621706008911133 0.06593504548072815\n",
      "[Step 25339] Loss: 9.56e+07 -1.4621102809906006 0.06593669205904007\n",
      "[Step 25340] Loss: 9.39e+07 -1.4620212316513062 0.06593421846628189\n",
      "[Step 25341] Loss: 9.38e+07 -1.4618631601333618 0.06593917310237885\n",
      "[Step 25342] Loss: 9.40e+07 -1.4616739749908447 0.06596309691667557\n",
      "[Step 25343] Loss: 9.42e+07 -1.4615780115127563 0.06597382575273514\n",
      "[Step 25344] Loss: 9.43e+07 -1.4615753889083862 0.06596557796001434\n",
      "[Step 25345] Loss: 9.33e+07 -1.4615752696990967 0.06595814973115921\n",
      "[Step 25346] Loss: 9.40e+07 -1.461602807044983 0.06593917310237885\n",
      "[Step 25347] Loss: 9.42e+07 -1.4616566896438599 0.06591194123029709\n",
      "[Step 25348] Loss: 9.40e+07 -1.4617177248001099 0.06588883697986603\n",
      "[Step 25349] Loss: 9.39e+07 -1.4617490768432617 0.06587480753660202\n",
      "[Step 25350] Loss: 9.39e+07 -1.4617919921875 0.06587646156549454\n",
      "[Step 25351] Loss: 9.48e+07 -1.4618961811065674 0.0658508837223053\n",
      "[Step 25352] Loss: 9.36e+07 -1.4619371891021729 0.06585335731506348\n",
      "[Step 25353] Loss: 9.43e+07 -1.4619823694229126 0.06583850085735321\n",
      "[Step 25354] Loss: 9.47e+07 -1.4621658325195312 0.06581292301416397\n",
      "[Step 25355] Loss: 9.38e+07 -1.4623992443084717 0.06578899174928665\n",
      "[Step 25356] Loss: 9.41e+07 -1.4625582695007324 0.06577414274215698\n",
      "[Step 25357] Loss: 9.40e+07 -1.4627277851104736 0.06577331572771072\n",
      "[Step 25358] Loss: 9.37e+07 -1.4628139734268188 0.06575433909893036\n",
      "[Step 25359] Loss: 9.46e+07 -1.4630619287490845 0.06572793424129486\n",
      "[Step 25360] Loss: 9.33e+07 -1.4632506370544434 0.06572463363409042\n",
      "[Step 25361] Loss: 9.38e+07 -1.4633835554122925 0.06572216004133224\n",
      "[Step 25362] Loss: 9.38e+07 -1.4635474681854248 0.06571143120527267\n",
      "[Step 25363] Loss: 9.41e+07 -1.463672399520874 0.0656866803765297\n",
      "[Step 25364] Loss: 9.46e+07 -1.4638208150863647 0.06567925214767456\n",
      "[Step 25365] Loss: 9.40e+07 -1.4639276266098022 0.06567347794771194\n",
      "[Step 25366] Loss: 9.62e+07 -1.4642812013626099 0.0656520202755928\n",
      "[Step 25367] Loss: 9.46e+07 -1.4647243022918701 0.06562809646129608\n",
      "[Step 25368] Loss: 9.42e+07 -1.4651747941970825 0.06559921056032181\n",
      "[Step 25369] Loss: 9.40e+07 -1.4655697345733643 0.06559096276760101\n",
      "[Step 25370] Loss: 9.42e+07 -1.4659415483474731 0.06557198613882065\n",
      "[Step 25371] Loss: 9.41e+07 -1.4663695096969604 0.06555218249559402\n",
      "[Step 25372] Loss: 9.46e+07 -1.466611385345459 0.06553155183792114\n",
      "[Step 25373] Loss: 9.39e+07 -1.466800570487976 0.06551587581634521\n",
      "[Step 25374] Loss: 9.62e+07 -1.466842532157898 0.06550431996583939\n",
      "[Step 25375] Loss: 9.36e+07 -1.4668502807617188 0.06552495062351227\n",
      "[Step 25376] Loss: 9.39e+07 -1.466914415359497 0.06551257520914078\n",
      "[Step 25377] Loss: 9.39e+07 -1.4669955968856812 0.06552412360906601\n",
      "[Step 25378] Loss: 9.40e+07 -1.4671630859375 0.06551917642354965\n",
      "[Step 25379] Loss: 9.40e+07 -1.4673305749893188 0.06551257520914078\n",
      "[Step 25380] Loss: 9.48e+07 -1.4673359394073486 0.06551504880189896\n",
      "[Step 25381] Loss: 9.39e+07 -1.4672999382019043 0.06552495062351227\n",
      "[Step 25382] Loss: 9.41e+07 -1.467122197151184 0.06554392725229263\n",
      "[Step 25383] Loss: 9.44e+07 -1.467082142829895 0.06553567945957184\n",
      "[Step 25384] Loss: 9.37e+07 -1.4671306610107422 0.06554640829563141\n",
      "[Step 25385] Loss: 9.44e+07 -1.467020869255066 0.06555382907390594\n",
      "[Step 25386] Loss: 9.43e+07 -1.4668177366256714 0.06558353453874588\n",
      "[Step 25387] Loss: 9.41e+07 -1.46653151512146 0.06560169160366058\n",
      "[Step 25388] Loss: 9.39e+07 -1.4661277532577515 0.06561654061079025\n",
      "[Step 25389] Loss: 9.39e+07 -1.465777039527893 0.06562479585409164\n",
      "[Step 25390] Loss: 9.49e+07 -1.4654285907745361 0.06564954668283463\n",
      "[Step 25391] Loss: 9.38e+07 -1.4651321172714233 0.0656602755188942\n",
      "[Step 25392] Loss: 9.38e+07 -1.4649097919464111 0.06566357612609863\n",
      "[Step 25393] Loss: 9.47e+07 -1.4646261930465698 0.0656866803765297\n",
      "[Step 25394] Loss: 9.41e+07 -1.4643592834472656 0.06570318341255188\n",
      "[Step 25395] Loss: 9.38e+07 -1.4640320539474487 0.06572876125574112\n",
      "[Step 25396] Loss: 9.47e+07 -1.4636262655258179 0.06574609130620956\n",
      "[Step 25397] Loss: 9.72e+07 -1.46376371383667 0.06573536247015\n",
      "[Step 25398] Loss: 9.41e+07 -1.4639086723327637 0.06574609130620956\n",
      "[Step 25399] Loss: 9.70e+07 -1.4645448923110962 0.06571720540523529\n",
      "[Step 25400] Loss: 9.56e+07 -1.4654351472854614 0.06567017734050751\n",
      "[Step 25401] Loss: 9.41e+07 -1.4662100076675415 0.06563139706850052\n",
      "[Step 25402] Loss: 9.45e+07 -1.46682870388031 0.06560499221086502\n",
      "[Step 25403] Loss: 9.39e+07 -1.4674646854400635 0.0655670315027237\n",
      "[Step 25404] Loss: 9.41e+07 -1.4680554866790771 0.0655142217874527\n",
      "[Step 25405] Loss: 9.40e+07 -1.4685944318771362 0.06547709554433823\n",
      "[Step 25406] Loss: 9.43e+07 -1.4690282344818115 0.06543996185064316\n",
      "[Step 25407] Loss: 9.33e+07 -1.4693853855133057 0.06541521102190018\n",
      "[Step 25408] Loss: 9.39e+07 -1.4696452617645264 0.06539540737867355\n",
      "[Step 25409] Loss: 9.43e+07 -1.4699629545211792 0.06539788097143173\n",
      "[Step 25410] Loss: 9.42e+07 -1.4702812433242798 0.06537477672100067\n",
      "[Step 25411] Loss: 9.46e+07 -1.4706552028656006 0.06534919887781143\n",
      "[Step 25412] Loss: 9.41e+07 -1.4709113836288452 0.06530876457691193\n",
      "[Step 25413] Loss: 9.43e+07 -1.4712932109832764 0.06527905911207199\n",
      "[Step 25414] Loss: 9.45e+07 -1.4715763330459595 0.0652625560760498\n",
      "[Step 25415] Loss: 9.45e+07 -1.4719854593276978 0.06524770706892014\n",
      "[Step 25416] Loss: 9.39e+07 -1.4722663164138794 0.06524605304002762\n",
      "[Step 25417] Loss: 9.46e+07 -1.4725433588027954 0.06523203104734421\n",
      "[Step 25418] Loss: 9.45e+07 -1.47270667552948 0.065226249396801\n",
      "[Step 25419] Loss: 9.54e+07 -1.473120093345642 0.06519654393196106\n",
      "[Step 25420] Loss: 9.34e+07 -1.4734445810317993 0.06518664211034775\n",
      "[Step 25421] Loss: 9.74e+07 -1.4742326736450195 0.06513465940952301\n",
      "[Step 25422] Loss: 9.41e+07 -1.4748167991638184 0.06509753316640854\n",
      "[Step 25423] Loss: 9.38e+07 -1.4752873182296753 0.06507524847984314\n",
      "[Step 25424] Loss: 9.39e+07 -1.4756838083267212 0.06506947427988052\n",
      "[Step 25425] Loss: 9.34e+07 -1.4759949445724487 0.06505627185106277\n",
      "[Step 25426] Loss: 9.43e+07 -1.4762678146362305 0.06504389643669128\n",
      "[Step 25427] Loss: 9.43e+07 -1.4763543605804443 0.06504637002944946\n",
      "[Step 25428] Loss: 9.43e+07 -1.4763485193252563 0.06506370007991791\n",
      "[Step 25429] Loss: 9.36e+07 -1.4763067960739136 0.06506039947271347\n",
      "[Step 25430] Loss: 9.44e+07 -1.4761390686035156 0.06506617367267609\n",
      "[Step 25431] Loss: 9.45e+07 -1.476119875907898 0.06508184969425201\n",
      "[Step 25432] Loss: 9.37e+07 -1.4760799407958984 0.06511155515909195\n",
      "[Step 25433] Loss: 9.38e+07 -1.4760421514511108 0.06512311100959778\n",
      "[Step 25434] Loss: 9.45e+07 -1.4758955240249634 0.06513218581676483\n",
      "[Step 25435] Loss: 9.39e+07 -1.4757386445999146 0.0651387870311737\n",
      "[Step 25436] Loss: 9.41e+07 -1.475522518157959 0.06513135880231857\n",
      "[Step 25437] Loss: 9.37e+07 -1.4753353595733643 0.06511981040239334\n",
      "[Step 25438] Loss: 9.41e+07 -1.4752265214920044 0.0651429146528244\n",
      "[Step 25439] Loss: 9.46e+07 -1.4752484560012817 0.06513465940952301\n",
      "[Step 25440] Loss: 9.38e+07 -1.4751765727996826 0.06514374166727066\n",
      "[Step 25441] Loss: 9.38e+07 -1.475026249885559 0.06515281647443771\n",
      "[Step 25442] Loss: 9.43e+07 -1.4748965501785278 0.06516601890325546\n",
      "[Step 25443] Loss: 9.37e+07 -1.4747995138168335 0.0651651918888092\n",
      "[Step 25444] Loss: 9.35e+07 -1.4746955633163452 0.06516271829605103\n",
      "[Step 25445] Loss: 9.43e+07 -1.4744960069656372 0.0651693195104599\n",
      "[Step 25446] Loss: 9.39e+07 -1.4743084907531738 0.0651651918888092\n",
      "[Step 25447] Loss: 9.33e+07 -1.4740135669708252 0.06518086791038513\n",
      "[Step 25448] Loss: 9.49e+07 -1.4739880561828613 0.06517922133207321\n",
      "[Step 25449] Loss: 9.36e+07 -1.473855972290039 0.06517674028873444\n",
      "[Step 25450] Loss: 9.47e+07 -1.4736624956130981 0.06517262011766434\n",
      "[Step 25451] Loss: 9.44e+07 -1.4733622074127197 0.06519489735364914\n",
      "[Step 25452] Loss: 9.43e+07 -1.4730361700057983 0.06520479917526245\n",
      "[Step 25453] Loss: 9.47e+07 -1.472664475440979 0.06523120403289795\n",
      "[Step 25454] Loss: 9.44e+07 -1.4722011089324951 0.06527163088321686\n",
      "[Step 25455] Loss: 9.34e+07 -1.471698522567749 0.06529226154088974\n",
      "[Step 25456] Loss: 9.37e+07 -1.4711815118789673 0.0653112381696701\n",
      "[Step 25457] Loss: 9.43e+07 -1.4706147909164429 0.0653558000922203\n",
      "[Step 25458] Loss: 9.46e+07 -1.4702298641204834 0.06538550555706024\n",
      "[Step 25459] Loss: 9.68e+07 -1.4703649282455444 0.06537147611379623\n",
      "[Step 25460] Loss: 9.40e+07 -1.4704225063323975 0.06536982208490372\n",
      "[Step 25461] Loss: 9.40e+07 -1.4704755544662476 0.06536570191383362\n",
      "[Step 25462] Loss: 9.35e+07 -1.470489740371704 0.0653640478849411\n",
      "[Step 25463] Loss: 9.32e+07 -1.4704355001449585 0.06537147611379623\n",
      "[Step 25464] Loss: 9.73e+07 -1.4708831310272217 0.06534507125616074\n",
      "[Step 25465] Loss: 9.51e+07 -1.4711496829986572 0.06532609462738037\n",
      "[Step 25466] Loss: 9.50e+07 -1.47122061252594 0.06532196700572968\n",
      "[Step 25467] Loss: 9.41e+07 -1.4712297916412354 0.0653112381696701\n",
      "[Step 25468] Loss: 9.39e+07 -1.4711931943893433 0.06531453877687454\n",
      "[Step 25469] Loss: 9.40e+07 -1.4711226224899292 0.06532856822013855\n",
      "[Step 25470] Loss: 9.40e+07 -1.471147060394287 0.06532526761293411\n",
      "[Step 25471] Loss: 9.74e+07 -1.471665620803833 0.06529391556978226\n",
      "[Step 25472] Loss: 9.39e+07 -1.4721465110778809 0.06526998430490494\n",
      "[Step 25473] Loss: 9.42e+07 -1.4725691080093384 0.06525100767612457\n",
      "[Step 25474] Loss: 9.42e+07 -1.4729316234588623 0.06522047519683838\n",
      "[Step 25475] Loss: 9.59e+07 -1.4735311269760132 0.06519902497529984\n",
      "[Step 25476] Loss: 9.38e+07 -1.4740220308303833 0.06516353785991669\n",
      "[Step 25477] Loss: 9.46e+07 -1.474388599395752 0.06513465940952301\n",
      "[Step 25478] Loss: 9.41e+07 -1.4746612310409546 0.0650901049375534\n",
      "[Step 25479] Loss: 9.41e+07 -1.4749428033828735 0.06506452709436417\n",
      "[Step 25480] Loss: 9.43e+07 -1.4751248359680176 0.06505297124385834\n",
      "[Step 25481] Loss: 9.49e+07 -1.4751429557800293 0.06505709886550903\n",
      "[Step 25482] Loss: 9.48e+07 -1.4751323461532593 0.06506700068712234\n",
      "[Step 25483] Loss: 9.58e+07 -1.4749354124069214 0.06507937610149384\n",
      "[Step 25484] Loss: 9.39e+07 -1.4747636318206787 0.0650983527302742\n",
      "[Step 25485] Loss: 9.38e+07 -1.4746006727218628 0.06510083377361298\n",
      "[Step 25486] Loss: 9.43e+07 -1.4745367765426636 0.06510578095912933\n",
      "[Step 25487] Loss: 9.39e+07 -1.4744962453842163 0.06512971222400665\n",
      "[Step 25488] Loss: 9.49e+07 -1.474634051322937 0.06512558460235596\n",
      "[Step 25489] Loss: 9.42e+07 -1.474794626235962 0.06511238217353821\n",
      "[Step 25490] Loss: 9.38e+07 -1.474900722503662 0.06510000675916672\n",
      "[Step 25491] Loss: 9.57e+07 -1.475231647491455 0.0650719478726387\n",
      "[Step 25492] Loss: 9.41e+07 -1.4754629135131836 0.06506122648715973\n",
      "[Step 25493] Loss: 9.42e+07 -1.4756877422332764 0.06504719704389572\n",
      "[Step 25494] Loss: 9.40e+07 -1.475859522819519 0.06502986699342728\n",
      "[Step 25495] Loss: 9.53e+07 -1.4761805534362793 0.06500181555747986\n",
      "[Step 25496] Loss: 9.43e+07 -1.476655125617981 0.06495560705661774\n",
      "[Step 25497] Loss: 9.51e+07 -1.477285385131836 0.064917653799057\n",
      "[Step 25498] Loss: 9.40e+07 -1.4778848886489868 0.0648772194981575\n",
      "[Step 25499] Loss: 9.38e+07 -1.4783456325531006 0.06484834104776382\n",
      "[Step 25500] Loss: 9.43e+07 -1.4787547588348389 0.06481120735406876\n",
      "[Step 25501] Loss: 9.38e+07 -1.4791032075881958 0.06477737426757812\n",
      "[Step 25502] Loss: 9.39e+07 -1.4794416427612305 0.0647394210100174\n",
      "[Step 25503] Loss: 9.50e+07 -1.4796007871627808 0.06471879035234451\n",
      "[Step 25504] Loss: 9.43e+07 -1.4798129796981812 0.06468743830919266\n",
      "[Step 25505] Loss: 9.40e+07 -1.4799931049346924 0.06467918306589127\n",
      "[Step 25506] Loss: 9.38e+07 -1.4801543951034546 0.06465525925159454\n",
      "[Step 25507] Loss: 9.41e+07 -1.4803310632705688 0.06462638080120087\n",
      "[Step 25508] Loss: 9.73e+07 -1.4809867143630981 0.06459502130746841\n",
      "[Step 25509] Loss: 9.56e+07 -1.4818909168243408 0.06453313678503036\n",
      "[Step 25510] Loss: 9.32e+07 -1.4826585054397583 0.06448692828416824\n",
      "[Step 25511] Loss: 9.36e+07 -1.483296275138855 0.0644431933760643\n",
      "[Step 25512] Loss: 9.51e+07 -1.4836935997009277 0.06441761553287506\n",
      "[Step 25513] Loss: 9.34e+07 -1.4840278625488281 0.06440111249685287\n",
      "[Step 25514] Loss: 9.38e+07 -1.4843019247055054 0.06439369171857834\n",
      "[Step 25515] Loss: 9.40e+07 -1.484493613243103 0.06439203768968582\n",
      "[Step 25516] Loss: 9.44e+07 -1.4845622777938843 0.0643986389040947\n",
      "[Step 25517] Loss: 9.40e+07 -1.4845319986343384 0.0644126683473587\n",
      "[Step 25518] Loss: 9.37e+07 -1.484412431716919 0.06442257016897202\n",
      "[Step 25519] Loss: 9.46e+07 -1.4843894243240356 0.06441431492567062\n",
      "[Step 25520] Loss: 9.39e+07 -1.4842883348464966 0.06442834436893463\n",
      "[Step 25521] Loss: 9.42e+07 -1.4842908382415771 0.06441431492567062\n",
      "[Step 25522] Loss: 9.39e+07 -1.4843194484710693 0.06440936774015427\n",
      "[Step 25523] Loss: 9.40e+07 -1.4843530654907227 0.0643862634897232\n",
      "[Step 25524] Loss: 9.40e+07 -1.4843755960464478 0.06438460946083069\n",
      "[Step 25525] Loss: 9.40e+07 -1.4844080209732056 0.06438791006803513\n",
      "[Step 25526] Loss: 9.40e+07 -1.4843716621398926 0.06440029293298721\n",
      "[Step 25527] Loss: 9.36e+07 -1.4843263626098633 0.06440606713294983\n",
      "[Step 25528] Loss: 9.49e+07 -1.484416127204895 0.0643986389040947\n",
      "[Step 25529] Loss: 9.61e+07 -1.4848153591156006 0.06438130885362625\n",
      "[Step 25530] Loss: 9.40e+07 -1.4851359128952026 0.06436728686094284\n",
      "[Step 25531] Loss: 9.46e+07 -1.4852238893508911 0.06434665620326996\n",
      "[Step 25532] Loss: 9.41e+07 -1.485224723815918 0.06432850658893585\n",
      "[Step 25533] Loss: 9.53e+07 -1.4853851795196533 0.064341701567173\n",
      "[Step 25534] Loss: 9.39e+07 -1.4854187965393066 0.06433592736721039\n",
      "[Step 25535] Loss: 9.36e+07 -1.4854083061218262 0.06433922797441483\n",
      "[Step 25536] Loss: 9.42e+07 -1.4853256940841675 0.06435738503932953\n",
      "[Step 25537] Loss: 9.56e+07 -1.4855098724365234 0.06436150521039963\n",
      "[Step 25538] Loss: 9.42e+07 -1.4857724905014038 0.06435655802488327\n",
      "[Step 25539] Loss: 9.46e+07 -1.4859027862548828 0.06436068564653397\n",
      "[Step 25540] Loss: 9.41e+07 -1.4859119653701782 0.0643681064248085\n",
      "[Step 25541] Loss: 9.38e+07 -1.4858412742614746 0.0643639862537384\n",
      "[Step 25542] Loss: 9.44e+07 -1.4857958555221558 0.06436315923929214\n",
      "[Step 25543] Loss: 9.47e+07 -1.4857687950134277 0.06436893343925476\n",
      "[Step 25544] Loss: 9.43e+07 -1.4856560230255127 0.06437306106090546\n",
      "[Step 25545] Loss: 9.40e+07 -1.4854918718338013 0.06436893343925476\n",
      "[Step 25546] Loss: 9.41e+07 -1.485465168952942 0.06436480581760406\n",
      "[Step 25547] Loss: 9.50e+07 -1.4855937957763672 0.06434005498886108\n",
      "[Step 25548] Loss: 9.41e+07 -1.485705852508545 0.06433180719614029\n",
      "[Step 25549] Loss: 9.49e+07 -1.4858368635177612 0.06431200355291367\n",
      "[Step 25550] Loss: 9.41e+07 -1.4858773946762085 0.06430704891681671\n",
      "[Step 25551] Loss: 9.37e+07 -1.485837697982788 0.06430787593126297\n",
      "[Step 25552] Loss: 9.38e+07 -1.48577880859375 0.06429550051689148\n",
      "[Step 25553] Loss: 9.36e+07 -1.4856884479522705 0.06429962068796158\n",
      "[Step 25554] Loss: 9.37e+07 -1.485593557357788 0.06432437896728516\n",
      "[Step 25555] Loss: 9.39e+07 -1.4854704141616821 0.06434335559606552\n",
      "[Step 25556] Loss: 9.41e+07 -1.48533296585083 0.06435655802488327\n",
      "[Step 25557] Loss: 9.44e+07 -1.4850722551345825 0.0643639862537384\n",
      "[Step 25558] Loss: 9.39e+07 -1.484841227531433 0.06437800824642181\n",
      "[Step 25559] Loss: 9.37e+07 -1.4846245050430298 0.06437883526086807\n",
      "[Step 25560] Loss: 9.43e+07 -1.4843696355819702 0.0643903911113739\n",
      "[Step 25561] Loss: 9.46e+07 -1.4840680360794067 0.06441101431846619\n",
      "[Step 25562] Loss: 9.46e+07 -1.483644723892212 0.06443577259778976\n",
      "[Step 25563] Loss: 9.47e+07 -1.4834152460098267 0.06443329900503159\n",
      "[Step 25564] Loss: 9.35e+07 -1.4831360578536987 0.06443411856889725\n",
      "[Step 25565] Loss: 9.49e+07 -1.483076572418213 0.06443741917610168\n",
      "[Step 25566] Loss: 9.40e+07 -1.482988953590393 0.06442917138338089\n",
      "[Step 25567] Loss: 9.41e+07 -1.4828622341156006 0.06444154679775238\n",
      "[Step 25568] Loss: 9.32e+07 -1.4826231002807617 0.06445062160491943\n",
      "[Step 25569] Loss: 9.37e+07 -1.4822944402694702 0.06447125226259232\n",
      "[Step 25570] Loss: 9.42e+07 -1.482023000717163 0.06447785347700119\n",
      "[Step 25571] Loss: 9.39e+07 -1.4816848039627075 0.06449105590581894\n",
      "[Step 25572] Loss: 9.37e+07 -1.481311559677124 0.06448445469141006\n",
      "[Step 25573] Loss: 9.38e+07 -1.480945348739624 0.06450343132019043\n",
      "[Step 25574] Loss: 9.52e+07 -1.4804867506027222 0.06452983617782593\n",
      "[Step 25575] Loss: 9.51e+07 -1.479892611503601 0.06455706804990768\n",
      "[Step 25576] Loss: 9.38e+07 -1.4793399572372437 0.0645809918642044\n",
      "[Step 25577] Loss: 9.35e+07 -1.478859305381775 0.06459172070026398\n",
      "[Step 25578] Loss: 9.42e+07 -1.478442907333374 0.06459089368581772\n",
      "[Step 25579] Loss: 9.51e+07 -1.477909803390503 0.06461399793624878\n",
      "[Step 25580] Loss: 9.45e+07 -1.477545976638794 0.06462059915065765\n",
      "[Step 25581] Loss: 9.44e+07 -1.4770832061767578 0.06463215500116348\n",
      "[Step 25582] Loss: 9.45e+07 -1.4767045974731445 0.0646338015794754\n",
      "[Step 25583] Loss: 9.58e+07 -1.4761526584625244 0.06465773284435272\n",
      "[Step 25584] Loss: 9.40e+07 -1.475739598274231 0.06467093527317047\n",
      "[Step 25585] Loss: 9.40e+07 -1.4753612279891968 0.06468496471643448\n",
      "[Step 25586] Loss: 9.35e+07 -1.4749891757965088 0.06468743830919266\n",
      "[Step 25587] Loss: 9.40e+07 -1.4745616912841797 0.0647006407380104\n",
      "[Step 25588] Loss: 9.38e+07 -1.4741307497024536 0.06471384316682816\n",
      "[Step 25589] Loss: 9.42e+07 -1.4737719297409058 0.06472374498844147\n",
      "[Step 25590] Loss: 9.44e+07 -1.4735429286956787 0.06473777443170547\n",
      "[Step 25591] Loss: 9.39e+07 -1.4733115434646606 0.06475592404603958\n",
      "[Step 25592] Loss: 9.45e+07 -1.4732152223587036 0.06474766880273819\n",
      "[Step 25593] Loss: 9.40e+07 -1.4731757640838623 0.06474107503890991\n",
      "[Step 25594] Loss: 9.47e+07 -1.4732542037963867 0.06472457200288773\n",
      "[Step 25595] Loss: 9.41e+07 -1.4733259677886963 0.06470724195241928\n",
      "[Step 25596] Loss: 9.38e+07 -1.4733211994171143 0.06471548974514008\n",
      "[Step 25597] Loss: 9.40e+07 -1.4732131958007812 0.06472621858119965\n",
      "[Step 25598] Loss: 9.37e+07 -1.4731600284576416 0.06473364681005478\n",
      "[Step 25599] Loss: 9.37e+07 -1.473183274269104 0.06471714377403259\n",
      "[Step 25600] Loss: 9.41e+07 -1.4732757806777954 0.06472457200288773\n",
      "[Step 25601] Loss: 9.42e+07 -1.4733617305755615 0.06471548974514008\n",
      "[Step 25602] Loss: 9.43e+07 -1.4734476804733276 0.06472127139568329\n",
      "[Step 25603] Loss: 9.55e+07 -1.4733092784881592 0.06473612040281296\n",
      "[Step 25604] Loss: 9.38e+07 -1.4730974435806274 0.06474602222442627\n",
      "[Step 25605] Loss: 9.56e+07 -1.4730877876281738 0.06474766880273819\n",
      "[Step 25606] Loss: 9.47e+07 -1.4730112552642822 0.06474107503890991\n",
      "[Step 25607] Loss: 9.42e+07 -1.4728890657424927 0.06474024802446365\n",
      "[Step 25608] Loss: 9.37e+07 -1.4726797342300415 0.06476499885320663\n",
      "[Step 25609] Loss: 9.51e+07 -1.4726659059524536 0.0647658258676529\n",
      "[Step 25610] Loss: 9.47e+07 -1.472758173942566 0.06475179642438889\n",
      "[Step 25611] Loss: 9.51e+07 -1.4730772972106934 0.06473859399557114\n",
      "[Step 25612] Loss: 9.42e+07 -1.4733126163482666 0.06471384316682816\n",
      "[Step 25613] Loss: 9.67e+07 -1.47390878200531 0.06467506289482117\n",
      "[Step 25614] Loss: 9.42e+07 -1.474622368812561 0.06462720036506653\n",
      "[Step 25615] Loss: 9.43e+07 -1.4753488302230835 0.06459089368581772\n",
      "[Step 25616] Loss: 9.35e+07 -1.4759399890899658 0.06457027047872543\n",
      "[Step 25617] Loss: 9.40e+07 -1.4764827489852905 0.06454221159219742\n",
      "[Step 25618] Loss: 9.42e+07 -1.4770201444625854 0.06450095772743225\n",
      "[Step 25619] Loss: 9.51e+07 -1.4776058197021484 0.0644737258553505\n",
      "[Step 25620] Loss: 9.39e+07 -1.4780526161193848 0.064447320997715\n",
      "[Step 25621] Loss: 9.45e+07 -1.478354573249817 0.064447320997715\n",
      "[Step 25622] Loss: 9.38e+07 -1.4786431789398193 0.06440359354019165\n",
      "[Step 25623] Loss: 9.39e+07 -1.4788669347763062 0.06437718868255615\n",
      "[Step 25624] Loss: 9.37e+07 -1.4790148735046387 0.0643639862537384\n",
      "[Step 25625] Loss: 9.48e+07 -1.4792156219482422 0.06435490399599075\n",
      "[Step 25626] Loss: 9.46e+07 -1.47925865650177 0.06436233222484589\n",
      "[Step 25627] Loss: 9.44e+07 -1.4792546033859253 0.06435573101043701\n",
      "[Step 25628] Loss: 9.40e+07 -1.4792921543121338 0.06436563283205032\n",
      "[Step 25629] Loss: 9.41e+07 -1.4792011976242065 0.0643722340464592\n",
      "[Step 25630] Loss: 9.48e+07 -1.4792572259902954 0.06437800824642181\n",
      "[Step 25631] Loss: 9.45e+07 -1.4794695377349854 0.06436150521039963\n",
      "[Step 25632] Loss: 9.39e+07 -1.4797067642211914 0.06436068564653397\n",
      "[Step 25633] Loss: 9.51e+07 -1.4797561168670654 0.06435655802488327\n",
      "[Step 25634] Loss: 9.39e+07 -1.479736089706421 0.06438048928976059\n",
      "[Step 25635] Loss: 9.45e+07 -1.4797742366790771 0.06437306106090546\n",
      "[Step 25636] Loss: 9.43e+07 -1.479733943939209 0.0643722340464592\n",
      "[Step 25637] Loss: 9.41e+07 -1.4796000719070435 0.0643763616681099\n",
      "[Step 25638] Loss: 9.45e+07 -1.4793577194213867 0.06437800824642181\n",
      "[Step 25639] Loss: 9.67e+07 -1.4795738458633423 0.06436233222484589\n",
      "[Step 25640] Loss: 9.44e+07 -1.4797570705413818 0.06436893343925476\n",
      "[Step 25641] Loss: 9.47e+07 -1.4801123142242432 0.06436315923929214\n",
      "[Step 25642] Loss: 9.47e+07 -1.4803380966186523 0.06434418261051178\n",
      "[Step 25643] Loss: 9.37e+07 -1.480451226234436 0.06434088200330734\n",
      "[Step 25644] Loss: 9.38e+07 -1.4804574251174927 0.06434005498886108\n",
      "[Step 25645] Loss: 9.40e+07 -1.4804869890213013 0.06433428078889847\n",
      "[Step 25646] Loss: 9.42e+07 -1.480434536933899 0.06433015316724777\n",
      "[Step 25647] Loss: 9.42e+07 -1.4802501201629639 0.06433592736721039\n",
      "[Step 25648] Loss: 9.47e+07 -1.480035424232483 0.06434665620326996\n",
      "[Step 25649] Loss: 9.34e+07 -1.479771375656128 0.06435903161764145\n",
      "[Step 25650] Loss: 9.35e+07 -1.479447364807129 0.06436893343925476\n",
      "[Step 25651] Loss: 9.48e+07 -1.4791368246078491 0.06439121067523956\n",
      "[Step 25652] Loss: 9.41e+07 -1.4788095951080322 0.06441101431846619\n",
      "[Step 25653] Loss: 9.35e+07 -1.4784473180770874 0.06442917138338089\n",
      "[Step 25654] Loss: 9.42e+07 -1.4781802892684937 0.0644390732049942\n",
      "[Step 25655] Loss: 9.36e+07 -1.477908968925476 0.06445639580488205\n",
      "[Step 25656] Loss: 9.44e+07 -1.4776734113693237 0.06448610126972198\n",
      "[Step 25657] Loss: 9.44e+07 -1.4773650169372559 0.06449518352746964\n",
      "[Step 25658] Loss: 9.39e+07 -1.4770177602767944 0.06450590491294861\n",
      "[Step 25659] Loss: 9.49e+07 -1.4768294095993042 0.0645224079489708\n",
      "[Step 25660] Loss: 9.46e+07 -1.4766530990600586 0.06453561037778854\n",
      "[Step 25661] Loss: 9.44e+07 -1.4765342473983765 0.06452323496341705\n",
      "[Step 25662] Loss: 9.48e+07 -1.476332426071167 0.06453809142112732\n",
      "[Step 25663] Loss: 9.41e+07 -1.4760997295379639 0.06455128639936447\n",
      "[Step 25664] Loss: 9.60e+07 -1.4762701988220215 0.06452406197786331\n",
      "[Step 25665] Loss: 9.42e+07 -1.476409673690796 0.06450508534908295\n",
      "[Step 25666] Loss: 9.52e+07 -1.4765151739120483 0.06450343132019043\n",
      "[Step 25667] Loss: 9.46e+07 -1.4765547513961792 0.06447125226259232\n",
      "[Step 25668] Loss: 9.40e+07 -1.4765431880950928 0.06447289884090424\n",
      "[Step 25669] Loss: 9.42e+07 -1.476413607597351 0.0644695982336998\n",
      "[Step 25670] Loss: 9.40e+07 -1.476331353187561 0.06445969641208649\n",
      "[Step 25671] Loss: 9.37e+07 -1.4763147830963135 0.06444154679775238\n",
      "[Step 25672] Loss: 9.72e+07 -1.4767950773239136 0.06441514194011688\n",
      "[Step 25673] Loss: 9.37e+07 -1.4772067070007324 0.06438378989696503\n",
      "[Step 25674] Loss: 9.43e+07 -1.477515697479248 0.06436645984649658\n",
      "[Step 25675] Loss: 9.37e+07 -1.477759838104248 0.06435243040323257\n",
      "[Step 25676] Loss: 9.50e+07 -1.4778263568878174 0.06435408443212509\n",
      "[Step 25677] Loss: 9.40e+07 -1.4780056476593018 0.06434418261051178\n",
      "[Step 25678] Loss: 9.34e+07 -1.4781001806259155 0.06434418261051178\n",
      "[Step 25679] Loss: 9.38e+07 -1.478108286857605 0.06434830278158188\n",
      "[Step 25680] Loss: 9.44e+07 -1.4780035018920898 0.06434418261051178\n",
      "[Step 25681] Loss: 9.43e+07 -1.4779503345489502 0.06435325741767883\n",
      "[Step 25682] Loss: 9.44e+07 -1.4779284000396729 0.06434088200330734\n",
      "[Step 25683] Loss: 9.39e+07 -1.4778034687042236 0.06435985863208771\n",
      "[Step 25684] Loss: 9.33e+07 -1.4776742458343506 0.06438378989696503\n",
      "[Step 25685] Loss: 9.54e+07 -1.477368712425232 0.064394511282444\n",
      "[Step 25686] Loss: 9.44e+07 -1.4770302772521973 0.06441514194011688\n",
      "[Step 25687] Loss: 9.43e+07 -1.4767298698425293 0.06443989276885986\n",
      "[Step 25688] Loss: 9.44e+07 -1.476340413093567 0.06447950005531311\n",
      "[Step 25689] Loss: 9.34e+07 -1.4759114980697632 0.06450425833463669\n",
      "[Step 25690] Loss: 9.37e+07 -1.4754581451416016 0.06454798579216003\n",
      "[Step 25691] Loss: 9.65e+07 -1.4755526781082153 0.06454963982105255\n",
      "[Step 25692] Loss: 9.40e+07 -1.4757046699523926 0.0645446851849556\n",
      "[Step 25693] Loss: 9.40e+07 -1.4758648872375488 0.06455376744270325\n",
      "[Step 25694] Loss: 9.45e+07 -1.4760124683380127 0.06453891098499298\n",
      "[Step 25695] Loss: 9.40e+07 -1.4761229753494263 0.06452736258506775\n",
      "[Step 25696] Loss: 9.57e+07 -1.47645902633667 0.06450260430574417\n",
      "[Step 25697] Loss: 9.38e+07 -1.476760745048523 0.06449765712022781\n",
      "[Step 25698] Loss: 9.39e+07 -1.4770081043243408 0.06449435651302338\n",
      "[Step 25699] Loss: 9.45e+07 -1.477271556854248 0.06448940187692642\n",
      "[Step 25700] Loss: 9.43e+07 -1.4774988889694214 0.06446629762649536\n",
      "[Step 25701] Loss: 9.49e+07 -1.4776101112365723 0.06444979459047318\n",
      "[Step 25702] Loss: 9.42e+07 -1.4777535200119019 0.06444649398326874\n",
      "[Step 25703] Loss: 9.44e+07 -1.477973461151123 0.06442999839782715\n",
      "[Step 25704] Loss: 9.41e+07 -1.478076696395874 0.06440524011850357\n",
      "[Step 25705] Loss: 9.41e+07 -1.4780672788619995 0.06440689414739609\n",
      "[Step 25706] Loss: 9.37e+07 -1.477990984916687 0.06439286470413208\n",
      "[Step 25707] Loss: 9.39e+07 -1.477823257446289 0.06438048928976059\n",
      "[Step 25708] Loss: 9.41e+07 -1.4775691032409668 0.06439699232578278\n",
      "[Step 25709] Loss: 9.37e+07 -1.47727370262146 0.06442669779062271\n",
      "[Step 25710] Loss: 9.43e+07 -1.4769877195358276 0.06445392221212387\n",
      "[Step 25711] Loss: 9.39e+07 -1.4766844511032104 0.06445722281932831\n",
      "[Step 25712] Loss: 9.55e+07 -1.4765665531158447 0.06445722281932831\n",
      "[Step 25713] Loss: 9.30e+07 -1.476463794708252 0.06445722281932831\n",
      "[Step 25714] Loss: 9.44e+07 -1.4764187335968018 0.0644431933760643\n",
      "[Step 25715] Loss: 9.45e+07 -1.4763041734695435 0.06444402039051056\n",
      "[Step 25716] Loss: 9.43e+07 -1.476307988166809 0.06443247199058533\n",
      "[Step 25717] Loss: 9.42e+07 -1.4763593673706055 0.06443081796169281\n",
      "[Step 25718] Loss: 9.44e+07 -1.4763975143432617 0.06443411856889725\n",
      "[Step 25719] Loss: 9.42e+07 -1.47651207447052 0.06443741917610168\n",
      "[Step 25720] Loss: 9.37e+07 -1.4766491651535034 0.06443659216165543\n",
      "[Step 25721] Loss: 9.48e+07 -1.4769320487976074 0.06441514194011688\n",
      "[Step 25722] Loss: 9.43e+07 -1.4771989583969116 0.06439699232578278\n",
      "[Step 25723] Loss: 9.47e+07 -1.4775338172912598 0.06436728686094284\n",
      "[Step 25724] Loss: 9.35e+07 -1.4777448177337646 0.0643499568104744\n",
      "[Step 25725] Loss: 9.41e+07 -1.4778772592544556 0.06433922797441483\n",
      "[Step 25726] Loss: 9.62e+07 -1.4783815145492554 0.06430870294570923\n",
      "[Step 25727] Loss: 9.56e+07 -1.4790265560150146 0.0642666146159172\n",
      "[Step 25728] Loss: 9.42e+07 -1.4796446561813354 0.06422123312950134\n",
      "[Step 25729] Loss: 9.40e+07 -1.4800727367401123 0.0641733780503273\n",
      "[Step 25730] Loss: 9.38e+07 -1.4803777933120728 0.06413954496383667\n",
      "[Step 25731] Loss: 9.59e+07 -1.4809105396270752 0.06411396712064743\n",
      "[Step 25732] Loss: 9.35e+07 -1.4813580513000488 0.06408261507749557\n",
      "[Step 25733] Loss: 9.40e+07 -1.481732726097107 0.06403475254774094\n",
      "[Step 25734] Loss: 9.39e+07 -1.4820584058761597 0.06401907652616501\n",
      "[Step 25735] Loss: 9.51e+07 -1.4822356700897217 0.06401164829730988\n",
      "[Step 25736] Loss: 9.45e+07 -1.4823846817016602 0.064005047082901\n",
      "[Step 25737] Loss: 9.43e+07 -1.4825165271759033 0.06400174647569656\n",
      "[Step 25738] Loss: 9.60e+07 -1.4829648733139038 0.06399102509021759\n",
      "[Step 25739] Loss: 9.41e+07 -1.4832574129104614 0.06396626681089401\n",
      "[Step 25740] Loss: 9.39e+07 -1.4834271669387817 0.06394893676042557\n",
      "[Step 25741] Loss: 9.45e+07 -1.4836353063583374 0.06393986195325851\n",
      "[Step 25742] Loss: 9.41e+07 -1.4837782382965088 0.0639299601316452\n",
      "[Step 25743] Loss: 9.45e+07 -1.4837929010391235 0.06393986195325851\n",
      "[Step 25744] Loss: 9.48e+07 -1.4839285612106323 0.06392253190279007\n",
      "[Step 25745] Loss: 9.35e+07 -1.4840482473373413 0.0639258325099945\n",
      "[Step 25746] Loss: 9.42e+07 -1.4841617345809937 0.06392171233892441\n",
      "[Step 25747] Loss: 9.57e+07 -1.4844517707824707 0.06390438228845596\n",
      "[Step 25748] Loss: 9.38e+07 -1.4846853017807007 0.06390685588121414\n",
      "[Step 25749] Loss: 9.41e+07 -1.484775185585022 0.06390933692455292\n",
      "[Step 25750] Loss: 9.41e+07 -1.4847999811172485 0.06387963145971298\n",
      "[Step 25751] Loss: 9.41e+07 -1.484735369682312 0.06387303024530411\n",
      "[Step 25752] Loss: 9.39e+07 -1.484634518623352 0.0638672485947609\n",
      "[Step 25753] Loss: 9.40e+07 -1.484525442123413 0.06389117985963821\n",
      "[Step 25754] Loss: 9.49e+07 -1.484372615814209 0.06390603631734848\n",
      "[Step 25755] Loss: 9.42e+07 -1.4843132495880127 0.06392005831003189\n",
      "[Step 25756] Loss: 9.38e+07 -1.4842673540115356 0.06390933692455292\n",
      "[Step 25757] Loss: 9.38e+07 -1.4841959476470947 0.06390850991010666\n",
      "[Step 25758] Loss: 9.52e+07 -1.4839768409729004 0.06390850991010666\n",
      "[Step 25759] Loss: 9.31e+07 -1.4837218523025513 0.06391841173171997\n",
      "[Step 25760] Loss: 9.48e+07 -1.483412504196167 0.06393243372440338\n",
      "[Step 25761] Loss: 9.38e+07 -1.4831637144088745 0.06395223736763\n",
      "[Step 25762] Loss: 9.41e+07 -1.483035683631897 0.06396543979644775\n",
      "[Step 25763] Loss: 9.41e+07 -1.4829025268554688 0.06395883858203888\n",
      "[Step 25764] Loss: 9.47e+07 -1.4829124212265015 0.06394646316766739\n",
      "[Step 25765] Loss: 9.38e+07 -1.4829134941101074 0.0639340877532959\n",
      "[Step 25766] Loss: 9.43e+07 -1.4828553199768066 0.06393161416053772\n",
      "[Step 25767] Loss: 9.39e+07 -1.4828426837921143 0.06392088532447815\n",
      "[Step 25768] Loss: 9.42e+07 -1.4828321933746338 0.06389860808849335\n",
      "[Step 25769] Loss: 9.49e+07 -1.4829200506210327 0.0638854056596756\n",
      "[Step 25770] Loss: 9.40e+07 -1.4830217361450195 0.06388045102357864\n",
      "[Step 25771] Loss: 9.40e+07 -1.483077883720398 0.0638631284236908\n",
      "[Step 25772] Loss: 9.54e+07 -1.4829148054122925 0.06386560201644897\n",
      "[Step 25773] Loss: 9.37e+07 -1.482759714126587 0.06387384980916977\n",
      "[Step 25774] Loss: 9.36e+07 -1.482618808746338 0.06389035284519196\n",
      "[Step 25775] Loss: 9.40e+07 -1.4823992252349854 0.06389778107404709\n",
      "[Step 25776] Loss: 9.37e+07 -1.4821155071258545 0.0639076828956604\n",
      "[Step 25777] Loss: 9.43e+07 -1.481788992881775 0.06392913311719894\n",
      "[Step 25778] Loss: 9.49e+07 -1.4815829992294312 0.06394398957490921\n",
      "[Step 25779] Loss: 9.40e+07 -1.4814566373825073 0.06395471841096878\n",
      "[Step 25780] Loss: 9.35e+07 -1.481300950050354 0.06395966559648514\n",
      "[Step 25781] Loss: 9.38e+07 -1.4811549186706543 0.06397534161806107\n",
      "[Step 25782] Loss: 9.39e+07 -1.48098886013031 0.06398607045412064\n",
      "[Step 25783] Loss: 9.38e+07 -1.4807946681976318 0.06400422751903534\n",
      "[Step 25784] Loss: 9.37e+07 -1.480544090270996 0.06402073055505753\n",
      "[Step 25785] Loss: 9.48e+07 -1.480385661125183 0.06403310596942902\n",
      "[Step 25786] Loss: 9.40e+07 -1.4802602529525757 0.06404878199100494\n",
      "[Step 25787] Loss: 9.37e+07 -1.4799860715866089 0.06405538320541382\n",
      "[Step 25788] Loss: 9.37e+07 -1.4796864986419678 0.06407353281974792\n",
      "[Step 25789] Loss: 9.33e+07 -1.4793789386749268 0.0640982910990715\n",
      "[Step 25790] Loss: 9.42e+07 -1.4792611598968506 0.06410489231348038\n",
      "[Step 25791] Loss: 9.36e+07 -1.4791799783706665 0.064110666513443\n",
      "[Step 25792] Loss: 9.37e+07 -1.4790512323379517 0.06411892175674438\n",
      "[Step 25793] Loss: 9.40e+07 -1.4788479804992676 0.0641329437494278\n",
      "[Step 25794] Loss: 9.53e+07 -1.4787975549697876 0.06413954496383667\n",
      "[Step 25795] Loss: 9.52e+07 -1.4785720109939575 0.06416594982147217\n",
      "[Step 25796] Loss: 9.45e+07 -1.4783090353012085 0.0641816258430481\n",
      "[Step 25797] Loss: 9.42e+07 -1.4781391620635986 0.06418658047914505\n",
      "[Step 25798] Loss: 9.45e+07 -1.4778239727020264 0.0642080307006836\n",
      "[Step 25799] Loss: 9.36e+07 -1.4775731563568115 0.06422948837280273\n",
      "[Step 25800] Loss: 9.39e+07 -1.4772897958755493 0.06423526257276535\n",
      "[Step 25801] Loss: 9.40e+07 -1.4770371913909912 0.06425506621599197\n",
      "[Step 25802] Loss: 9.40e+07 -1.4767723083496094 0.06426744163036346\n",
      "[Step 25803] Loss: 9.35e+07 -1.4764765501022339 0.06429550051689148\n",
      "[Step 25804] Loss: 9.37e+07 -1.4761985540390015 0.06431777775287628\n",
      "[Step 25805] Loss: 9.34e+07 -1.4759876728057861 0.06434500217437744\n",
      "[Step 25806] Loss: 9.40e+07 -1.4757541418075562 0.06435820460319519\n",
      "[Step 25807] Loss: 9.42e+07 -1.4754889011383057 0.06437966227531433\n",
      "[Step 25808] Loss: 9.58e+07 -1.4755488634109497 0.06438460946083069\n",
      "[Step 25809] Loss: 9.41e+07 -1.4756046533584595 0.06439286470413208\n",
      "[Step 25810] Loss: 9.41e+07 -1.4755712747573853 0.06437553465366364\n",
      "[Step 25811] Loss: 9.34e+07 -1.4755611419677734 0.06437718868255615\n",
      "[Step 25812] Loss: 9.44e+07 -1.4755445718765259 0.06438378989696503\n",
      "[Step 25813] Loss: 9.39e+07 -1.4755905866622925 0.06437966227531433\n",
      "[Step 25814] Loss: 9.38e+07 -1.475561499595642 0.06437388807535172\n",
      "[Step 25815] Loss: 9.38e+07 -1.475492238998413 0.06438130885362625\n",
      "[Step 25816] Loss: 9.48e+07 -1.4753108024597168 0.06438873708248138\n",
      "[Step 25817] Loss: 9.46e+07 -1.4752695560455322 0.06438460946083069\n",
      "[Step 25818] Loss: 9.47e+07 -1.475186824798584 0.06437058746814728\n",
      "[Step 25819] Loss: 9.41e+07 -1.475150227546692 0.0643986389040947\n",
      "[Step 25820] Loss: 9.40e+07 -1.4751118421554565 0.06439781188964844\n",
      "[Step 25821] Loss: 9.41e+07 -1.4750065803527832 0.06439533829689026\n",
      "[Step 25822] Loss: 9.47e+07 -1.4748960733413696 0.06440276652574539\n",
      "[Step 25823] Loss: 9.40e+07 -1.4747767448425293 0.06440359354019165\n",
      "[Step 25824] Loss: 9.42e+07 -1.4747021198272705 0.06442339718341827\n",
      "[Step 25825] Loss: 9.41e+07 -1.474593997001648 0.06444154679775238\n",
      "[Step 25826] Loss: 9.46e+07 -1.4744572639465332 0.06444237381219864\n",
      "[Step 25827] Loss: 9.55e+07 -1.4742270708084106 0.06446382403373718\n",
      "[Step 25828] Loss: 9.42e+07 -1.4740045070648193 0.0644695982336998\n",
      "[Step 25829] Loss: 9.67e+07 -1.4742316007614136 0.06445969641208649\n",
      "[Step 25830] Loss: 9.34e+07 -1.4744256734848022 0.06446299701929092\n",
      "[Step 25831] Loss: 9.36e+07 -1.474544882774353 0.06445887684822083\n",
      "[Step 25832] Loss: 9.45e+07 -1.4747322797775269 0.06444484740495682\n",
      "[Step 25833] Loss: 9.40e+07 -1.474954605102539 0.06442917138338089\n",
      "[Step 25834] Loss: 9.53e+07 -1.4753655195236206 0.06440689414739609\n",
      "[Step 25835] Loss: 9.73e+07 -1.4762533903121948 0.06435078382492065\n",
      "[Step 25836] Loss: 9.43e+07 -1.4770221710205078 0.06431860476732254\n",
      "[Step 25837] Loss: 9.61e+07 -1.478011131286621 0.06425836682319641\n",
      "[Step 25838] Loss: 9.41e+07 -1.4789015054702759 0.06419400870800018\n",
      "[Step 25839] Loss: 9.40e+07 -1.4797147512435913 0.06413789838552475\n",
      "[Step 25840] Loss: 9.48e+07 -1.4803608655929565 0.06409993767738342\n",
      "[Step 25841] Loss: 9.39e+07 -1.4809337854385376 0.06405702978372574\n",
      "[Step 25842] Loss: 9.37e+07 -1.4814131259918213 0.06403392553329468\n",
      "[Step 25843] Loss: 9.44e+07 -1.4819623231887817 0.06401907652616501\n",
      "[Step 25844] Loss: 9.67e+07 -1.4829106330871582 0.06396296620368958\n",
      "[Step 25845] Loss: 9.49e+07 -1.4838117361068726 0.06391015648841858\n",
      "[Step 25846] Loss: 9.62e+07 -1.484981656074524 0.0638408437371254\n",
      "[Step 25847] Loss: 9.43e+07 -1.4859968423843384 0.063788041472435\n",
      "[Step 25848] Loss: 9.39e+07 -1.4868481159210205 0.06373687833547592\n",
      "[Step 25849] Loss: 9.40e+07 -1.4876208305358887 0.06369149684906006\n",
      "[Step 25850] Loss: 9.38e+07 -1.488353967666626 0.06365601718425751\n",
      "[Step 25851] Loss: 9.59e+07 -1.4888426065444946 0.06361063569784164\n",
      "[Step 25852] Loss: 9.33e+07 -1.4892218112945557 0.06360815465450287\n",
      "[Step 25853] Loss: 9.40e+07 -1.4894402027130127 0.06358670443296432\n",
      "[Step 25854] Loss: 9.42e+07 -1.489616870880127 0.06359577924013138\n",
      "[Step 25855] Loss: 9.41e+07 -1.4896596670150757 0.06360403448343277\n",
      "[Step 25856] Loss: 9.38e+07 -1.4896996021270752 0.06360650807619095\n",
      "[Step 25857] Loss: 9.42e+07 -1.4896578788757324 0.06360650807619095\n",
      "[Step 25858] Loss: 9.55e+07 -1.4898563623428345 0.06358670443296432\n",
      "[Step 25859] Loss: 9.36e+07 -1.4900473356246948 0.06355699896812439\n",
      "[Step 25860] Loss: 9.42e+07 -1.490248680114746 0.06354214996099472\n",
      "[Step 25861] Loss: 9.36e+07 -1.4903672933578491 0.06353636831045151\n",
      "[Step 25862] Loss: 9.45e+07 -1.4905099868774414 0.06352564692497253\n",
      "[Step 25863] Loss: 9.35e+07 -1.490622878074646 0.06352564692497253\n",
      "[Step 25864] Loss: 9.38e+07 -1.490712285041809 0.06351161748170853\n",
      "[Step 25865] Loss: 9.45e+07 -1.4907536506652832 0.06351656466722488\n",
      "[Step 25866] Loss: 9.41e+07 -1.490844488143921 0.0635000690817833\n",
      "[Step 25867] Loss: 9.39e+07 -1.4908638000488281 0.06350088864564896\n",
      "[Step 25868] Loss: 9.51e+07 -1.491094946861267 0.06347283720970154\n",
      "[Step 25869] Loss: 9.71e+07 -1.4917562007904053 0.06343735754489899\n",
      "[Step 25870] Loss: 9.48e+07 -1.4922987222671509 0.06341837346553802\n",
      "[Step 25871] Loss: 9.41e+07 -1.492775321006775 0.0633944496512413\n",
      "[Step 25872] Loss: 9.39e+07 -1.4931056499481201 0.06338124722242355\n",
      "[Step 25873] Loss: 9.41e+07 -1.4934455156326294 0.06337381899356842\n",
      "[Step 25874] Loss: 9.37e+07 -1.4936649799346924 0.06336639076471329\n",
      "[Step 25875] Loss: 9.33e+07 -1.4938733577728271 0.0633498877286911\n",
      "[Step 25876] Loss: 9.39e+07 -1.493943452835083 0.063345767557621\n",
      "[Step 25877] Loss: 9.39e+07 -1.4939916133880615 0.0633276104927063\n",
      "[Step 25878] Loss: 9.37e+07 -1.4939228296279907 0.0633234828710556\n",
      "[Step 25879] Loss: 9.37e+07 -1.4938360452651978 0.06334906816482544\n",
      "[Step 25880] Loss: 9.48e+07 -1.4939106702804565 0.063345767557621\n",
      "[Step 25881] Loss: 9.40e+07 -1.4938929080963135 0.0633416399359703\n",
      "[Step 25882] Loss: 9.52e+07 -1.4940056800842285 0.06332430988550186\n",
      "[Step 25883] Loss: 9.37e+07 -1.494107961654663 0.06334246695041656\n",
      "[Step 25884] Loss: 9.36e+07 -1.4941177368164062 0.06335154175758362\n",
      "[Step 25885] Loss: 9.41e+07 -1.4940924644470215 0.06336474418640137\n",
      "[Step 25886] Loss: 9.44e+07 -1.4939402341842651 0.06337794661521912\n",
      "[Step 25887] Loss: 9.47e+07 -1.4937312602996826 0.06337877362966537\n",
      "[Step 25888] Loss: 9.38e+07 -1.4936175346374512 0.06338702142238617\n",
      "[Step 25889] Loss: 9.45e+07 -1.4934519529342651 0.06339362263679504\n",
      "[Step 25890] Loss: 9.40e+07 -1.4932522773742676 0.06339114904403687\n",
      "[Step 25891] Loss: 9.43e+07 -1.4929702281951904 0.06339939683675766\n",
      "[Step 25892] Loss: 9.66e+07 -1.4925020933151245 0.06341589987277985\n",
      "[Step 25893] Loss: 9.49e+07 -1.4921931028366089 0.06343405693769455\n",
      "[Step 25894] Loss: 9.39e+07 -1.4917744398117065 0.06344643235206604\n",
      "[Step 25895] Loss: 9.39e+07 -1.4913381338119507 0.06346788257360458\n",
      "[Step 25896] Loss: 9.41e+07 -1.490996241569519 0.06348356604576111\n",
      "[Step 25897] Loss: 9.37e+07 -1.4906318187713623 0.06348851323127747\n",
      "[Step 25898] Loss: 9.41e+07 -1.4902552366256714 0.06350584328174591\n",
      "[Step 25899] Loss: 9.39e+07 -1.4898790121078491 0.06353142112493515\n",
      "[Step 25900] Loss: 9.39e+07 -1.4894505739212036 0.06355039775371552\n",
      "[Step 25901] Loss: 9.38e+07 -1.4890151023864746 0.06357762962579727\n",
      "[Step 25902] Loss: 9.40e+07 -1.4885823726654053 0.06360156089067459\n",
      "[Step 25903] Loss: 9.44e+07 -1.4882007837295532 0.06361805647611618\n",
      "[Step 25904] Loss: 9.42e+07 -1.4877930879592896 0.06365106254816055\n",
      "[Step 25905] Loss: 9.36e+07 -1.4873696565628052 0.06367582082748413\n",
      "[Step 25906] Loss: 9.37e+07 -1.4870301485061646 0.06369232386350632\n",
      "[Step 25907] Loss: 9.44e+07 -1.486846685409546 0.06370799988508224\n",
      "[Step 25908] Loss: 9.45e+07 -1.4867758750915527 0.06372202932834625\n",
      "[Step 25909] Loss: 9.37e+07 -1.4866281747817993 0.0637170746922493\n",
      "[Step 25910] Loss: 9.42e+07 -1.4865355491638184 0.06371542811393738\n",
      "[Step 25911] Loss: 9.41e+07 -1.4863284826278687 0.06371954828500748\n",
      "[Step 25912] Loss: 9.44e+07 -1.486199140548706 0.06372945010662079\n",
      "[Step 25913] Loss: 9.37e+07 -1.4860390424728394 0.0637434795498848\n",
      "[Step 25914] Loss: 9.39e+07 -1.4859386682510376 0.06373770534992218\n",
      "[Step 25915] Loss: 9.48e+07 -1.4856873750686646 0.06373853236436844\n",
      "[Step 25916] Loss: 9.40e+07 -1.4854493141174316 0.06374678015708923\n",
      "[Step 25917] Loss: 9.49e+07 -1.4850867986679077 0.06375998258590698\n",
      "[Step 25918] Loss: 9.40e+07 -1.4846752882003784 0.06378474086523056\n",
      "[Step 25919] Loss: 9.38e+07 -1.484339714050293 0.06380536407232285\n",
      "[Step 25920] Loss: 9.71e+07 -1.4845387935638428 0.06380124390125275\n",
      "[Step 25921] Loss: 9.37e+07 -1.4846948385238647 0.06379794329404831\n",
      "[Step 25922] Loss: 9.39e+07 -1.4847617149353027 0.06378556042909622\n",
      "[Step 25923] Loss: 9.40e+07 -1.4847590923309326 0.06379381567239761\n",
      "[Step 25924] Loss: 9.42e+07 -1.484809398651123 0.06379876285791397\n",
      "[Step 25925] Loss: 9.38e+07 -1.4847066402435303 0.06381279230117798\n",
      "[Step 25926] Loss: 9.38e+07 -1.4845443964004517 0.06383342295885086\n",
      "[Step 25927] Loss: 9.38e+07 -1.4844176769256592 0.06384579837322235\n",
      "[Step 25928] Loss: 9.42e+07 -1.4842045307159424 0.06385982781648636\n",
      "[Step 25929] Loss: 9.43e+07 -1.4840725660324097 0.06386807560920715\n",
      "[Step 25930] Loss: 9.37e+07 -1.4839601516723633 0.0638812780380249\n",
      "[Step 25931] Loss: 9.42e+07 -1.4839621782302856 0.06387054920196533\n",
      "[Step 25932] Loss: 9.36e+07 -1.4840152263641357 0.06385982781648636\n",
      "[Step 25933] Loss: 9.42e+07 -1.4840002059936523 0.06386477500200272\n",
      "[Step 25934] Loss: 9.38e+07 -1.4838672876358032 0.06387880444526672\n",
      "[Step 25935] Loss: 9.41e+07 -1.4836921691894531 0.06388045102357864\n",
      "[Step 25936] Loss: 9.48e+07 -1.4833433628082275 0.06390850991010666\n",
      "[Step 25937] Loss: 9.46e+07 -1.4830284118652344 0.06392831355333328\n",
      "[Step 25938] Loss: 9.40e+07 -1.4826387166976929 0.06394068896770477\n",
      "[Step 25939] Loss: 9.40e+07 -1.4822615385055542 0.06397039443254471\n",
      "[Step 25940] Loss: 9.60e+07 -1.4816868305206299 0.0639967992901802\n",
      "[Step 25941] Loss: 9.49e+07 -1.481339693069458 0.06401000171899796\n",
      "[Step 25942] Loss: 9.33e+07 -1.4809637069702148 0.06403310596942902\n",
      "[Step 25943] Loss: 9.41e+07 -1.4805446863174438 0.06407518684864044\n",
      "[Step 25944] Loss: 9.39e+07 -1.4802719354629517 0.06410159170627594\n",
      "[Step 25945] Loss: 9.42e+07 -1.4800238609313965 0.06411726772785187\n",
      "[Step 25946] Loss: 9.62e+07 -1.4795957803726196 0.06413707137107849\n",
      "[Step 25947] Loss: 9.39e+07 -1.479204535484314 0.06416347622871399\n",
      "[Step 25948] Loss: 9.40e+07 -1.4788206815719604 0.06419812887907028\n",
      "[Step 25949] Loss: 9.44e+07 -1.4784401655197144 0.06422041356563568\n",
      "[Step 25950] Loss: 9.45e+07 -1.478222370147705 0.06423773616552353\n",
      "[Step 25951] Loss: 9.46e+07 -1.4779945611953735 0.06425423920154572\n",
      "[Step 25952] Loss: 9.42e+07 -1.4777237176895142 0.06426744163036346\n",
      "[Step 25953] Loss: 9.68e+07 -1.4772909879684448 0.06429219990968704\n",
      "[Step 25954] Loss: 9.46e+07 -1.4768303632736206 0.06431365013122559\n",
      "[Step 25955] Loss: 9.48e+07 -1.4762977361679077 0.06434418261051178\n",
      "[Step 25956] Loss: 9.40e+07 -1.475799322128296 0.06437140703201294\n",
      "[Step 25957] Loss: 9.32e+07 -1.475282907485962 0.06439286470413208\n",
      "[Step 25958] Loss: 9.39e+07 -1.4747955799102783 0.06441844254732132\n",
      "[Step 25959] Loss: 9.46e+07 -1.4744082689285278 0.06444071978330612\n",
      "[Step 25960] Loss: 9.66e+07 -1.474531888961792 0.06445639580488205\n",
      "[Step 25961] Loss: 9.51e+07 -1.474865436553955 0.06443411856889725\n",
      "[Step 25962] Loss: 9.43e+07 -1.4750899076461792 0.06442174315452576\n",
      "[Step 25963] Loss: 9.38e+07 -1.4752815961837769 0.06440689414739609\n",
      "[Step 25964] Loss: 9.38e+07 -1.4754430055618286 0.06440111249685287\n",
      "[Step 25965] Loss: 9.39e+07 -1.4755549430847168 0.06439533829689026\n",
      "[Step 25966] Loss: 9.36e+07 -1.4756646156311035 0.064394511282444\n",
      "[Step 25967] Loss: 9.36e+07 -1.4756884574890137 0.06441431492567062\n",
      "[Step 25968] Loss: 9.39e+07 -1.4757765531539917 0.06441184133291245\n",
      "[Step 25969] Loss: 9.43e+07 -1.4759117364883423 0.06440771371126175\n",
      "[Step 25970] Loss: 9.50e+07 -1.4761255979537964 0.06439946591854095\n",
      "[Step 25971] Loss: 9.36e+07 -1.476294994354248 0.06440029293298721\n",
      "[Step 25972] Loss: 9.45e+07 -1.4762921333312988 0.0643986389040947\n",
      "[Step 25973] Loss: 9.39e+07 -1.476273536682129 0.06438543647527695\n",
      "[Step 25974] Loss: 9.37e+07 -1.476231336593628 0.06440029293298721\n",
      "[Step 25975] Loss: 9.39e+07 -1.4762487411499023 0.06440029293298721\n",
      "[Step 25976] Loss: 9.40e+07 -1.4762977361679077 0.06438791006803513\n",
      "[Step 25977] Loss: 9.70e+07 -1.4768553972244263 0.06435903161764145\n",
      "[Step 25978] Loss: 9.47e+07 -1.4775028228759766 0.06434252858161926\n",
      "[Step 25979] Loss: 9.45e+07 -1.4780418872833252 0.06431447714567184\n",
      "[Step 25980] Loss: 9.48e+07 -1.4787169694900513 0.06428229808807373\n",
      "[Step 25981] Loss: 9.42e+07 -1.4792242050170898 0.06425176560878754\n",
      "[Step 25982] Loss: 9.56e+07 -1.479527473449707 0.06425919383764267\n",
      "[Step 25983] Loss: 9.47e+07 -1.4797271490097046 0.06423690915107727\n",
      "[Step 25984] Loss: 9.60e+07 -1.4797462224960327 0.06423360854387283\n",
      "[Step 25985] Loss: 9.49e+07 -1.47996985912323 0.06423443555831909\n",
      "[Step 25986] Loss: 9.48e+07 -1.4800218343734741 0.0642220601439476\n",
      "[Step 25987] Loss: 9.46e+07 -1.480197787284851 0.06419318169355392\n",
      "[Step 25988] Loss: 9.44e+07 -1.4803924560546875 0.06417832523584366\n",
      "[Step 25989] Loss: 9.40e+07 -1.4804991483688354 0.06417667865753174\n",
      "[Step 25990] Loss: 9.46e+07 -1.4806904792785645 0.06416594982147217\n",
      "[Step 25991] Loss: 9.38e+07 -1.4808908700942993 0.06415274739265442\n",
      "[Step 25992] Loss: 9.35e+07 -1.4809967279434204 0.06414449959993362\n",
      "[Step 25993] Loss: 9.38e+07 -1.4810452461242676 0.06413707137107849\n",
      "[Step 25994] Loss: 9.36e+07 -1.481107473373413 0.0641329437494278\n",
      "[Step 25995] Loss: 9.35e+07 -1.4811062812805176 0.06413954496383667\n",
      "[Step 25996] Loss: 9.33e+07 -1.4810905456542969 0.06413789838552475\n",
      "[Step 25997] Loss: 9.34e+07 -1.4810292720794678 0.06414037197828293\n",
      "[Step 25998] Loss: 9.64e+07 -1.4813281297683716 0.06411974132061005\n",
      "[Step 25999] Loss: 9.40e+07 -1.4814811944961548 0.06411149352788925\n",
      "[Step 26000] Loss: 9.49e+07 -1.4814718961715698 0.0641065388917923\n",
      "[Step 26001] Loss: 9.48e+07 -1.4816259145736694 0.06410901993513107\n",
      "[Step 26002] Loss: 9.53e+07 -1.4820411205291748 0.06406858563423157\n",
      "[Step 26003] Loss: 9.44e+07 -1.4822577238082886 0.0640537291765213\n",
      "[Step 26004] Loss: 9.32e+07 -1.4823951721191406 0.06404218077659607\n",
      "[Step 26005] Loss: 9.39e+07 -1.4825032949447632 0.06402980536222458\n",
      "[Step 26006] Loss: 9.35e+07 -1.482545256614685 0.06402237713336945\n",
      "[Step 26007] Loss: 9.41e+07 -1.4826098680496216 0.06403062492609024\n",
      "[Step 26008] Loss: 9.45e+07 -1.4825778007507324 0.06403805315494537\n",
      "[Step 26009] Loss: 9.39e+07 -1.4825100898742676 0.06403475254774094\n",
      "[Step 26010] Loss: 9.39e+07 -1.4823940992355347 0.06403640657663345\n",
      "[Step 26011] Loss: 9.35e+07 -1.4822481870651245 0.06403062492609024\n",
      "[Step 26012] Loss: 9.43e+07 -1.4819995164871216 0.06404795497655869\n",
      "[Step 26013] Loss: 9.51e+07 -1.4820406436920166 0.06406611204147339\n",
      "[Step 26014] Loss: 9.43e+07 -1.4821290969848633 0.06406445801258087\n",
      "[Step 26015] Loss: 9.42e+07 -1.4822142124176025 0.06406363099813461\n",
      "[Step 26016] Loss: 9.38e+07 -1.4821891784667969 0.06407683342695236\n",
      "[Step 26017] Loss: 9.47e+07 -1.4821207523345947 0.06408343464136124\n",
      "[Step 26018] Loss: 9.42e+07 -1.4818928241729736 0.06409251689910889\n",
      "[Step 26019] Loss: 9.39e+07 -1.481654405593872 0.06410983949899673\n",
      "[Step 26020] Loss: 9.70e+07 -1.4818751811981201 0.0640982910990715\n",
      "[Step 26021] Loss: 9.45e+07 -1.4821419715881348 0.06408261507749557\n",
      "[Step 26022] Loss: 9.36e+07 -1.4823501110076904 0.06405125558376312\n",
      "[Step 26023] Loss: 9.44e+07 -1.4826966524124146 0.06402650475502014\n",
      "[Step 26024] Loss: 9.48e+07 -1.4830025434494019 0.06401494890451431\n",
      "[Step 26025] Loss: 9.39e+07 -1.4832489490509033 0.06400422751903534\n",
      "[Step 26026] Loss: 9.42e+07 -1.4835493564605713 0.0639868974685669\n",
      "[Step 26027] Loss: 9.41e+07 -1.483829140663147 0.06396956741809845\n",
      "[Step 26028] Loss: 9.38e+07 -1.4840937852859497 0.06393738836050034\n",
      "[Step 26029] Loss: 9.38e+07 -1.4842767715454102 0.06394068896770477\n",
      "[Step 26030] Loss: 9.44e+07 -1.4843820333480835 0.06393243372440338\n",
      "[Step 26031] Loss: 9.41e+07 -1.4844756126403809 0.06392088532447815\n",
      "[Step 26032] Loss: 9.50e+07 -1.4847204685211182 0.06391015648841858\n",
      "[Step 26033] Loss: 9.48e+07 -1.485037922859192 0.06389365345239639\n",
      "[Step 26034] Loss: 9.39e+07 -1.4852688312530518 0.06386230140924454\n",
      "[Step 26035] Loss: 9.38e+07 -1.4854053258895874 0.0638408437371254\n",
      "[Step 26036] Loss: 9.39e+07 -1.4854662418365479 0.06383342295885086\n",
      "[Step 26037] Loss: 9.42e+07 -1.4853967428207397 0.06384662538766861\n",
      "[Step 26038] Loss: 9.37e+07 -1.4852386713027954 0.06384992599487305\n",
      "[Step 26039] Loss: 9.42e+07 -1.4851502180099487 0.06384744495153427\n",
      "[Step 26040] Loss: 9.41e+07 -1.4850491285324097 0.06384332478046417\n",
      "[Step 26041] Loss: 9.37e+07 -1.4848642349243164 0.06384249776601791\n",
      "[Step 26042] Loss: 9.38e+07 -1.4847118854522705 0.06384579837322235\n",
      "[Step 26043] Loss: 9.31e+07 -1.484482765197754 0.06386064738035202\n",
      "[Step 26044] Loss: 9.43e+07 -1.4841117858886719 0.06386477500200272\n",
      "[Step 26045] Loss: 9.40e+07 -1.483734369277954 0.06387220323085785\n",
      "[Step 26046] Loss: 9.34e+07 -1.483362078666687 0.06388293206691742\n",
      "[Step 26047] Loss: 9.37e+07 -1.483006477355957 0.06390190869569778\n",
      "[Step 26048] Loss: 9.37e+07 -1.4827799797058105 0.06389860808849335\n",
      "[Step 26049] Loss: 9.45e+07 -1.4824365377426147 0.06391263753175735\n",
      "[Step 26050] Loss: 9.38e+07 -1.482019066810608 0.06393243372440338\n",
      "[Step 26051] Loss: 9.59e+07 -1.481431245803833 0.06396792083978653\n",
      "[Step 26052] Loss: 9.37e+07 -1.4808727502822876 0.06399597227573395\n",
      "[Step 26053] Loss: 9.44e+07 -1.4805502891540527 0.06399844586849213\n",
      "[Step 26054] Loss: 9.38e+07 -1.480255126953125 0.06400834769010544\n",
      "[Step 26055] Loss: 9.44e+07 -1.4799933433532715 0.0640232041478157\n",
      "[Step 26056] Loss: 9.41e+07 -1.4797430038452148 0.06401412934064865\n",
      "[Step 26057] Loss: 9.46e+07 -1.479500412940979 0.06401742994785309\n",
      "[Step 26058] Loss: 9.41e+07 -1.4793490171432495 0.06400752812623978\n",
      "[Step 26059] Loss: 9.42e+07 -1.4792314767837524 0.06400670111179352\n",
      "[Step 26060] Loss: 9.39e+07 -1.4791890382766724 0.06400670111179352\n",
      "[Step 26061] Loss: 9.38e+07 -1.479156732559204 0.06401742994785309\n",
      "[Step 26062] Loss: 9.53e+07 -1.4789420366287231 0.06400009989738464\n",
      "[Step 26063] Loss: 9.40e+07 -1.4788261651992798 0.06400257349014282\n",
      "[Step 26064] Loss: 9.44e+07 -1.4786654710769653 0.06400422751903534\n",
      "[Step 26065] Loss: 9.47e+07 -1.478359580039978 0.06401082873344421\n",
      "[Step 26066] Loss: 9.45e+07 -1.4781560897827148 0.0640091747045517\n",
      "[Step 26067] Loss: 9.42e+07 -1.4778982400894165 0.0640232041478157\n",
      "[Step 26068] Loss: 9.71e+07 -1.4781475067138672 0.06401660293340683\n",
      "[Step 26069] Loss: 9.36e+07 -1.4783942699432373 0.0639967992901802\n",
      "[Step 26070] Loss: 9.41e+07 -1.4786595106124878 0.06396626681089401\n",
      "[Step 26071] Loss: 9.48e+07 -1.4787200689315796 0.06395883858203888\n",
      "[Step 26072] Loss: 9.41e+07 -1.4787187576293945 0.06396379321813583\n",
      "[Step 26073] Loss: 9.32e+07 -1.4786291122436523 0.06396296620368958\n",
      "[Step 26074] Loss: 9.32e+07 -1.4784886837005615 0.06396213918924332\n",
      "[Step 26075] Loss: 9.45e+07 -1.4783943891525269 0.06396709382534027\n",
      "[Step 26076] Loss: 9.43e+07 -1.4782794713974 0.06396874040365219\n",
      "[Step 26077] Loss: 9.38e+07 -1.4780887365341187 0.06398359686136246\n",
      "[Step 26078] Loss: 9.40e+07 -1.4778982400894165 0.06399267166852951\n",
      "[Step 26079] Loss: 9.76e+07 -1.4782332181930542 0.06395883858203888\n",
      "[Step 26080] Loss: 9.63e+07 -1.4789352416992188 0.06393078714609146\n",
      "[Step 26081] Loss: 9.35e+07 -1.4795548915863037 0.06389695405960083\n",
      "[Step 26082] Loss: 9.38e+07 -1.480025053024292 0.06386394798755646\n",
      "[Step 26083] Loss: 9.58e+07 -1.480755090713501 0.06382434070110321\n",
      "[Step 26084] Loss: 9.41e+07 -1.481425404548645 0.06379051506519318\n",
      "[Step 26085] Loss: 9.38e+07 -1.4820369482040405 0.0637657567858696\n",
      "[Step 26086] Loss: 9.37e+07 -1.4826396703720093 0.06373357772827148\n",
      "[Step 26087] Loss: 9.42e+07 -1.483024001121521 0.06371377408504486\n",
      "[Step 26088] Loss: 9.42e+07 -1.4834049940109253 0.06368159502744675\n",
      "[Step 26089] Loss: 9.41e+07 -1.4837751388549805 0.06364034116268158\n",
      "[Step 26090] Loss: 9.34e+07 -1.484046459197998 0.06363291293382645\n",
      "[Step 26091] Loss: 9.40e+07 -1.4841582775115967 0.06361393630504608\n",
      "[Step 26092] Loss: 9.43e+07 -1.4842631816864014 0.06361475586891174\n",
      "[Step 26093] Loss: 9.41e+07 -1.4843860864639282 0.06360568106174469\n",
      "[Step 26094] Loss: 9.34e+07 -1.484453558921814 0.06360815465450287\n",
      "[Step 26095] Loss: 9.36e+07 -1.4844897985458374 0.06362631171941757\n",
      "[Step 26096] Loss: 9.39e+07 -1.4844820499420166 0.06361310929059982\n",
      "[Step 26097] Loss: 9.36e+07 -1.4845061302185059 0.06360238045454025\n",
      "[Step 26098] Loss: 9.31e+07 -1.4844447374343872 0.06359907984733582\n",
      "[Step 26099] Loss: 9.45e+07 -1.484344482421875 0.06360073387622833\n",
      "[Step 26100] Loss: 9.39e+07 -1.4842488765716553 0.06360733509063721\n",
      "[Step 26101] Loss: 9.49e+07 -1.4843112230300903 0.0636114552617073\n",
      "[Step 26102] Loss: 9.39e+07 -1.4843474626541138 0.06360650807619095\n",
      "[Step 26103] Loss: 9.41e+07 -1.484274983406067 0.06361063569784164\n",
      "[Step 26104] Loss: 9.39e+07 -1.4841607809066772 0.0636419877409935\n",
      "[Step 26105] Loss: 9.65e+07 -1.4845199584960938 0.06362961232662201\n",
      "[Step 26106] Loss: 9.32e+07 -1.4848017692565918 0.06362465769052505\n",
      "[Step 26107] Loss: 9.64e+07 -1.4854958057403564 0.0635891780257225\n",
      "[Step 26108] Loss: 9.41e+07 -1.4860820770263672 0.06355369836091995\n",
      "[Step 26109] Loss: 9.40e+07 -1.4866626262664795 0.06354627013206482\n",
      "[Step 26110] Loss: 9.36e+07 -1.4871214628219604 0.06351491808891296\n",
      "[Step 26111] Loss: 9.35e+07 -1.4875282049179077 0.0635182186961174\n",
      "[Step 26112] Loss: 9.43e+07 -1.4877630472183228 0.06349428743124008\n",
      "[Step 26113] Loss: 9.39e+07 -1.4880398511886597 0.06347613781690598\n",
      "[Step 26114] Loss: 9.34e+07 -1.4883159399032593 0.06347448378801346\n",
      "[Step 26115] Loss: 9.37e+07 -1.4885635375976562 0.06347613781690598\n",
      "[Step 26116] Loss: 9.45e+07 -1.4888272285461426 0.06347448378801346\n",
      "[Step 26117] Loss: 9.45e+07 -1.4891011714935303 0.06346870958805084\n",
      "[Step 26118] Loss: 9.44e+07 -1.4893378019332886 0.06345963478088379\n",
      "[Step 26119] Loss: 9.46e+07 -1.4895888566970825 0.06344890594482422\n",
      "[Step 26120] Loss: 9.41e+07 -1.4898338317871094 0.06343405693769455\n",
      "[Step 26121] Loss: 9.40e+07 -1.4900212287902832 0.06343653053045273\n",
      "[Step 26122] Loss: 9.52e+07 -1.490374207496643 0.06341589987277985\n",
      "[Step 26123] Loss: 9.53e+07 -1.4905179738998413 0.06341259926557541\n",
      "[Step 26124] Loss: 9.37e+07 -1.4905545711517334 0.0634167268872261\n",
      "[Step 26125] Loss: 9.37e+07 -1.4904567003250122 0.06341342628002167\n",
      "[Step 26126] Loss: 9.40e+07 -1.490293025970459 0.06342992931604385\n",
      "[Step 26127] Loss: 9.45e+07 -1.490317702293396 0.06343322992324829\n",
      "[Step 26128] Loss: 9.42e+07 -1.4902151823043823 0.06344807893037796\n",
      "[Step 26129] Loss: 9.33e+07 -1.4900681972503662 0.06347531080245972\n",
      "[Step 26130] Loss: 9.40e+07 -1.4899318218231201 0.06348851323127747\n",
      "[Step 26131] Loss: 9.43e+07 -1.4896929264068604 0.06350088864564896\n",
      "[Step 26132] Loss: 9.43e+07 -1.4894728660583496 0.0635041892528534\n",
      "[Step 26133] Loss: 9.40e+07 -1.4893051385879517 0.06352729350328445\n",
      "[Step 26134] Loss: 9.66e+07 -1.489650845527649 0.06349428743124008\n",
      "[Step 26135] Loss: 9.37e+07 -1.4900943040847778 0.06347613781690598\n",
      "[Step 26136] Loss: 9.45e+07 -1.4905641078948975 0.06344890594482422\n",
      "[Step 26137] Loss: 9.44e+07 -1.490890383720398 0.0634167268872261\n",
      "[Step 26138] Loss: 9.42e+07 -1.4912755489349365 0.06338867545127869\n",
      "[Step 26139] Loss: 9.41e+07 -1.4916898012161255 0.06335318833589554\n",
      "[Step 26140] Loss: 9.34e+07 -1.4919615983963013 0.06333586573600769\n",
      "[Step 26141] Loss: 9.48e+07 -1.4920873641967773 0.06332843750715256\n",
      "[Step 26142] Loss: 9.39e+07 -1.492141842842102 0.0633234828710556\n",
      "[Step 26143] Loss: 9.44e+07 -1.4922964572906494 0.06330780684947968\n",
      "[Step 26144] Loss: 9.40e+07 -1.4923930168151855 0.06331110745668411\n",
      "[Step 26145] Loss: 9.35e+07 -1.49245023727417 0.06331688165664673\n",
      "[Step 26146] Loss: 9.43e+07 -1.4924858808517456 0.06332430988550186\n",
      "[Step 26147] Loss: 9.66e+07 -1.4929230213165283 0.06329790502786636\n",
      "[Step 26148] Loss: 9.33e+07 -1.4932235479354858 0.06328800320625305\n",
      "[Step 26149] Loss: 9.40e+07 -1.4935548305511475 0.06328800320625305\n",
      "[Step 26150] Loss: 9.36e+07 -1.4937963485717773 0.06329130381345749\n",
      "[Step 26151] Loss: 9.37e+07 -1.493903636932373 0.06330203264951706\n",
      "[Step 26152] Loss: 9.39e+07 -1.4940106868743896 0.06331358104944229\n",
      "[Step 26153] Loss: 9.46e+07 -1.4940577745437622 0.06330946087837219\n",
      "[Step 26154] Loss: 9.48e+07 -1.4939624071121216 0.06332018226385117\n",
      "[Step 26155] Loss: 9.41e+07 -1.4939156770706177 0.06332926452159882\n",
      "[Step 26156] Loss: 9.33e+07 -1.4938079118728638 0.06335236877202988\n",
      "[Step 26157] Loss: 9.38e+07 -1.4936095476150513 0.06334906816482544\n",
      "[Step 26158] Loss: 9.43e+07 -1.4934754371643066 0.06334906816482544\n",
      "[Step 26159] Loss: 9.41e+07 -1.4933512210845947 0.06333833932876587\n",
      "[Step 26160] Loss: 9.41e+07 -1.493213176727295 0.06334411352872849\n",
      "[Step 26161] Loss: 9.41e+07 -1.4930357933044434 0.06335814297199249\n",
      "[Step 26162] Loss: 9.57e+07 -1.4930328130722046 0.0633540153503418\n",
      "[Step 26163] Loss: 9.39e+07 -1.4929943084716797 0.06336474418640137\n",
      "[Step 26164] Loss: 9.44e+07 -1.493070125579834 0.06334494054317474\n",
      "[Step 26165] Loss: 9.49e+07 -1.4932552576065063 0.06332513689994812\n",
      "[Step 26166] Loss: 9.37e+07 -1.4933574199676514 0.063331738114357\n",
      "[Step 26167] Loss: 9.41e+07 -1.4934123754501343 0.06333833932876587\n",
      "[Step 26168] Loss: 9.44e+07 -1.493425965309143 0.06332430988550186\n",
      "[Step 26169] Loss: 9.40e+07 -1.4934463500976562 0.06330863386392593\n",
      "[Step 26170] Loss: 9.37e+07 -1.4934241771697998 0.06329873204231262\n",
      "[Step 26171] Loss: 9.46e+07 -1.4933401346206665 0.06329460442066193\n",
      "[Step 26172] Loss: 9.39e+07 -1.4932516813278198 0.06329873204231262\n",
      "[Step 26173] Loss: 9.38e+07 -1.493127703666687 0.0633193626999855\n",
      "[Step 26174] Loss: 9.47e+07 -1.4931352138519287 0.06330697983503342\n",
      "[Step 26175] Loss: 9.44e+07 -1.492983102798462 0.06331028044223785\n",
      "[Step 26176] Loss: 9.43e+07 -1.492787480354309 0.06332678347826004\n",
      "[Step 26177] Loss: 9.47e+07 -1.492668628692627 0.06332513689994812\n",
      "[Step 26178] Loss: 9.40e+07 -1.492523431777954 0.06334081292152405\n",
      "[Step 26179] Loss: 9.51e+07 -1.4926369190216064 0.06333833932876587\n",
      "[Step 26180] Loss: 9.72e+07 -1.49321711063385 0.06332100927829742\n",
      "[Step 26181] Loss: 9.44e+07 -1.4937630891799927 0.06329295784235\n",
      "[Step 26182] Loss: 9.45e+07 -1.494124412536621 0.06326902657747269\n",
      "[Step 26183] Loss: 9.37e+07 -1.494377851486206 0.06325499713420868\n",
      "[Step 26184] Loss: 9.37e+07 -1.4945443868637085 0.06325087696313858\n",
      "[Step 26185] Loss: 9.44e+07 -1.4948185682296753 0.06323602050542831\n",
      "[Step 26186] Loss: 9.43e+07 -1.495155930519104 0.06319724023342133\n",
      "[Step 26187] Loss: 9.39e+07 -1.495429515838623 0.06317496299743652\n",
      "[Step 26188] Loss: 9.35e+07 -1.4955893754959106 0.06316753476858139\n",
      "[Step 26189] Loss: 9.61e+07 -1.4955474138259888 0.06317413598299026\n",
      "[Step 26190] Loss: 9.39e+07 -1.4954524040222168 0.06317660957574844\n",
      "[Step 26191] Loss: 9.36e+07 -1.4952733516693115 0.06320301443338394\n",
      "[Step 26192] Loss: 9.43e+07 -1.4951622486114502 0.06321044266223907\n",
      "[Step 26193] Loss: 9.40e+07 -1.4950690269470215 0.06321704387664795\n",
      "[Step 26194] Loss: 9.42e+07 -1.4949547052383423 0.063226118683815\n",
      "[Step 26195] Loss: 9.38e+07 -1.494868278503418 0.06322859227657318\n",
      "[Step 26196] Loss: 9.53e+07 -1.494969129562378 0.063226118683815\n",
      "[Step 26197] Loss: 9.53e+07 -1.495199203491211 0.06322859227657318\n",
      "[Step 26198] Loss: 9.39e+07 -1.495415449142456 0.0632219910621643\n",
      "[Step 26199] Loss: 9.36e+07 -1.4955534934997559 0.06321126967668533\n",
      "[Step 26200] Loss: 9.39e+07 -1.4955918788909912 0.06321951746940613\n",
      "[Step 26201] Loss: 9.39e+07 -1.495614767074585 0.06322694569826126\n",
      "[Step 26202] Loss: 9.41e+07 -1.4955765008926392 0.06322777271270752\n",
      "[Step 26203] Loss: 9.35e+07 -1.4954819679260254 0.06324509531259537\n",
      "[Step 26204] Loss: 9.42e+07 -1.495390772819519 0.06325995177030563\n",
      "[Step 26205] Loss: 9.41e+07 -1.4952529668807983 0.06326159834861755\n",
      "[Step 26206] Loss: 9.37e+07 -1.4950522184371948 0.06328058242797852\n",
      "[Step 26207] Loss: 9.31e+07 -1.4948346614837646 0.06329790502786636\n",
      "[Step 26208] Loss: 9.45e+07 -1.4945093393325806 0.06332266330718994\n",
      "[Step 26209] Loss: 9.40e+07 -1.4941660165786743 0.06333008408546448\n",
      "[Step 26210] Loss: 9.44e+07 -1.4938844442367554 0.06334494054317474\n",
      "[Step 26211] Loss: 9.36e+07 -1.4935743808746338 0.06337134540081024\n",
      "[Step 26212] Loss: 9.37e+07 -1.4932866096496582 0.06338372081518173\n",
      "[Step 26213] Loss: 9.44e+07 -1.493011474609375 0.06340435147285461\n",
      "[Step 26214] Loss: 9.40e+07 -1.4927418231964111 0.06341259926557541\n",
      "[Step 26215] Loss: 9.43e+07 -1.4925276041030884 0.06341837346553802\n",
      "[Step 26216] Loss: 9.44e+07 -1.4923150539398193 0.0634431317448616\n",
      "[Step 26217] Loss: 9.45e+07 -1.4921848773956299 0.06344560533761978\n",
      "[Step 26218] Loss: 9.37e+07 -1.492038607597351 0.06345303356647491\n",
      "[Step 26219] Loss: 9.49e+07 -1.4917564392089844 0.06347448378801346\n",
      "[Step 26220] Loss: 9.55e+07 -1.491723656654358 0.06346706300973892\n",
      "[Step 26221] Loss: 9.37e+07 -1.491713523864746 0.06346046179533005\n",
      "[Step 26222] Loss: 9.47e+07 -1.491662621498108 0.06347118318080902\n",
      "[Step 26223] Loss: 9.47e+07 -1.4917092323303223 0.06347613781690598\n",
      "[Step 26224] Loss: 9.36e+07 -1.4917583465576172 0.06346210837364197\n",
      "[Step 26225] Loss: 9.40e+07 -1.4917000532150269 0.06347118318080902\n",
      "[Step 26226] Loss: 9.47e+07 -1.4915165901184082 0.06348438560962677\n",
      "[Step 26227] Loss: 9.35e+07 -1.4913599491119385 0.06348191201686859\n",
      "[Step 26228] Loss: 9.40e+07 -1.4911483526229858 0.0635041892528534\n",
      "[Step 26229] Loss: 9.35e+07 -1.4909425973892212 0.06351244449615479\n",
      "[Step 26230] Loss: 9.45e+07 -1.4908483028411865 0.06353389471769333\n",
      "[Step 26231] Loss: 9.38e+07 -1.4907194375991821 0.06353059411048889\n",
      "[Step 26232] Loss: 9.43e+07 -1.4905240535736084 0.06353224813938141\n",
      "[Step 26233] Loss: 9.34e+07 -1.4903508424758911 0.06354957073926926\n",
      "[Step 26234] Loss: 9.45e+07 -1.4902219772338867 0.06354957073926926\n",
      "[Step 26235] Loss: 9.45e+07 -1.490086555480957 0.06354627013206482\n",
      "[Step 26236] Loss: 9.43e+07 -1.4899173974990845 0.06354709714651108\n",
      "[Step 26237] Loss: 9.37e+07 -1.489781379699707 0.0635586529970169\n",
      "[Step 26238] Loss: 9.35e+07 -1.4895421266555786 0.06358670443296432\n",
      "[Step 26239] Loss: 9.47e+07 -1.4891700744628906 0.06361475586891174\n",
      "[Step 26240] Loss: 9.44e+07 -1.4887349605560303 0.06364694237709045\n",
      "[Step 26241] Loss: 9.35e+07 -1.4882855415344238 0.063668392598629\n",
      "[Step 26242] Loss: 9.54e+07 -1.4877949953079224 0.06368902325630188\n",
      "[Step 26243] Loss: 9.36e+07 -1.4873980283737183 0.06372202932834625\n",
      "[Step 26244] Loss: 9.69e+07 -1.4875242710113525 0.06371130049228668\n",
      "[Step 26245] Loss: 9.51e+07 -1.4874550104141235 0.0637088268995285\n",
      "[Step 26246] Loss: 9.61e+07 -1.4878919124603271 0.06368902325630188\n",
      "[Step 26247] Loss: 9.46e+07 -1.4881906509399414 0.06367169320583344\n",
      "[Step 26248] Loss: 9.34e+07 -1.4883852005004883 0.06366096436977386\n",
      "[Step 26249] Loss: 9.67e+07 -1.489033818244934 0.06362053751945496\n",
      "[Step 26250] Loss: 9.43e+07 -1.4897150993347168 0.06357680261135101\n",
      "[Step 26251] Loss: 9.68e+07 -1.4907933473587036 0.06351491808891296\n",
      "[Step 26252] Loss: 9.45e+07 -1.4917798042297363 0.06345055997371674\n",
      "[Step 26253] Loss: 9.43e+07 -1.4926471710205078 0.0634167268872261\n",
      "[Step 26254] Loss: 9.45e+07 -1.4933178424835205 0.06338619440793991\n",
      "[Step 26255] Loss: 9.43e+07 -1.493916630744934 0.06334741413593292\n",
      "[Step 26256] Loss: 9.35e+07 -1.4944003820419312 0.06333833932876587\n",
      "[Step 26257] Loss: 9.42e+07 -1.4947236776351929 0.06329955905675888\n",
      "[Step 26258] Loss: 9.39e+07 -1.49496328830719 0.0633053332567215\n",
      "[Step 26259] Loss: 9.44e+07 -1.4952595233917236 0.06327810138463974\n",
      "[Step 26260] Loss: 9.44e+07 -1.4954516887664795 0.06325995177030563\n",
      "[Step 26261] Loss: 9.44e+07 -1.4957466125488281 0.06322281807661057\n",
      "[Step 26262] Loss: 9.47e+07 -1.4960739612579346 0.06320054084062576\n",
      "[Step 26263] Loss: 9.36e+07 -1.4963093996047974 0.063173308968544\n",
      "[Step 26264] Loss: 9.37e+07 -1.4965821504592896 0.06313535571098328\n",
      "[Step 26265] Loss: 9.44e+07 -1.4968844652175903 0.06309739500284195\n",
      "[Step 26266] Loss: 9.43e+07 -1.4972171783447266 0.06305944174528122\n",
      "[Step 26267] Loss: 9.57e+07 -1.4973394870758057 0.0630355104804039\n",
      "[Step 26268] Loss: 9.35e+07 -1.4973894357681274 0.06302890926599503\n",
      "[Step 26269] Loss: 9.39e+07 -1.4973669052124023 0.06302643567323685\n",
      "[Step 26270] Loss: 9.34e+07 -1.4973784685134888 0.06301406025886536\n",
      "[Step 26271] Loss: 9.44e+07 -1.4974511861801147 0.06301653385162354\n",
      "[Step 26272] Loss: 9.51e+07 -1.497711420059204 0.06299342960119247\n",
      "[Step 26273] Loss: 9.40e+07 -1.497888445854187 0.06297775357961655\n",
      "[Step 26274] Loss: 9.40e+07 -1.4981337785720825 0.06294144690036774\n",
      "[Step 26275] Loss: 9.36e+07 -1.4982876777648926 0.0629199966788292\n",
      "[Step 26276] Loss: 9.56e+07 -1.498781442642212 0.06287131458520889\n",
      "[Step 26277] Loss: 9.43e+07 -1.4991954565048218 0.0628449097275734\n",
      "[Step 26278] Loss: 9.41e+07 -1.4994913339614868 0.06283335387706757\n",
      "[Step 26279] Loss: 9.52e+07 -1.499948263168335 0.0627879723906517\n",
      "[Step 26280] Loss: 9.42e+07 -1.5004289150238037 0.06276899576187134\n",
      "[Step 26281] Loss: 9.39e+07 -1.5008684396743774 0.06274589151144028\n",
      "[Step 26282] Loss: 9.42e+07 -1.5012372732162476 0.06273268908262253\n",
      "[Step 26283] Loss: 9.38e+07 -1.5015177726745605 0.06270381063222885\n",
      "[Step 26284] Loss: 9.51e+07 -1.501837968826294 0.06269555538892746\n",
      "[Step 26285] Loss: 9.37e+07 -1.5020772218704224 0.0626864805817604\n",
      "[Step 26286] Loss: 9.40e+07 -1.5021830797195435 0.06267905235290527\n",
      "[Step 26287] Loss: 9.36e+07 -1.5022878646850586 0.0626724511384964\n",
      "[Step 26288] Loss: 9.35e+07 -1.502299189567566 0.06266915053129196\n",
      "[Step 26289] Loss: 9.42e+07 -1.5021663904190063 0.0626765787601471\n",
      "[Step 26290] Loss: 9.35e+07 -1.5020384788513184 0.06270381063222885\n",
      "[Step 26291] Loss: 9.41e+07 -1.5018664598464966 0.06270875781774521\n",
      "[Step 26292] Loss: 9.49e+07 -1.5018150806427002 0.06271041184663773\n",
      "[Step 26293] Loss: 9.39e+07 -1.5017086267471313 0.06271041184663773\n",
      "[Step 26294] Loss: 9.42e+07 -1.5015807151794434 0.06272691488265991\n",
      "[Step 26295] Loss: 9.50e+07 -1.5017253160476685 0.0627170130610466\n",
      "[Step 26296] Loss: 9.60e+07 -1.502173900604248 0.06268812716007233\n",
      "[Step 26297] Loss: 9.45e+07 -1.5024689435958862 0.0626765787601471\n",
      "[Step 26298] Loss: 9.44e+07 -1.5027741193771362 0.06266915053129196\n",
      "[Step 26299] Loss: 9.42e+07 -1.5031248331069946 0.06263202428817749\n",
      "[Step 26300] Loss: 9.44e+07 -1.503350019454956 0.06261056661605835\n",
      "[Step 26301] Loss: 9.72e+07 -1.503318428993225 0.06259241700172424\n",
      "[Step 26302] Loss: 9.39e+07 -1.5032390356063843 0.0625973641872406\n",
      "[Step 26303] Loss: 9.43e+07 -1.5032744407653809 0.06259241700172424\n",
      "[Step 26304] Loss: 9.41e+07 -1.5032387971878052 0.0625932365655899\n",
      "[Step 26305] Loss: 9.48e+07 -1.5031273365020752 0.06260313838720322\n",
      "[Step 26306] Loss: 9.32e+07 -1.5029797554016113 0.06262046843767166\n",
      "[Step 26307] Loss: 9.48e+07 -1.5027154684066772 0.06264357268810272\n",
      "[Step 26308] Loss: 9.73e+07 -1.5029809474945068 0.06262294203042984\n",
      "[Step 26309] Loss: 9.41e+07 -1.5031038522720337 0.06261716783046722\n",
      "[Step 26310] Loss: 9.35e+07 -1.5031803846359253 0.06260313838720322\n",
      "[Step 26311] Loss: 9.47e+07 -1.5031541585922241 0.06260313838720322\n",
      "[Step 26312] Loss: 9.41e+07 -1.5031269788742065 0.06260973960161209\n",
      "[Step 26313] Loss: 9.48e+07 -1.5030255317687988 0.06260396540164948\n",
      "[Step 26314] Loss: 9.41e+07 -1.5029735565185547 0.06260561943054199\n",
      "[Step 26315] Loss: 9.54e+07 -1.503054141998291 0.06260231882333755\n",
      "[Step 26316] Loss: 9.43e+07 -1.503161907196045 0.06259571760892868\n",
      "[Step 26317] Loss: 9.46e+07 -1.503346562385559 0.06259653717279434\n",
      "[Step 26318] Loss: 9.43e+07 -1.5034996271133423 0.06260313838720322\n",
      "[Step 26319] Loss: 9.39e+07 -1.5034968852996826 0.06261222064495087\n",
      "[Step 26320] Loss: 9.42e+07 -1.5035172700881958 0.06261634081602097\n",
      "[Step 26321] Loss: 9.41e+07 -1.503531813621521 0.06262624263763428\n",
      "[Step 26322] Loss: 9.42e+07 -1.5034844875335693 0.06262129545211792\n",
      "[Step 26323] Loss: 9.73e+07 -1.5039207935333252 0.06258828938007355\n",
      "[Step 26324] Loss: 9.40e+07 -1.5041877031326294 0.06256023794412613\n",
      "[Step 26325] Loss: 9.59e+07 -1.5047240257263184 0.06253630667924881\n",
      "[Step 26326] Loss: 9.39e+07 -1.5051116943359375 0.06251402944326401\n",
      "[Step 26327] Loss: 9.47e+07 -1.5055850744247437 0.06249009817838669\n",
      "[Step 26328] Loss: 9.50e+07 -1.505928874015808 0.062484320253133774\n",
      "[Step 26329] Loss: 9.44e+07 -1.5061593055725098 0.06247854605317116\n",
      "[Step 26330] Loss: 9.35e+07 -1.506300687789917 0.06247524544596672\n",
      "[Step 26331] Loss: 9.41e+07 -1.50635826587677 0.06247606873512268\n",
      "[Step 26332] Loss: 9.44e+07 -1.5063035488128662 0.06247441843152046\n",
      "[Step 26333] Loss: 9.30e+07 -1.5062072277069092 0.0624735951423645\n",
      "[Step 26334] Loss: 9.36e+07 -1.5060557126998901 0.062484320253133774\n",
      "[Step 26335] Loss: 9.35e+07 -1.505822777748108 0.06249257177114487\n",
      "[Step 26336] Loss: 9.50e+07 -1.5057791471481323 0.06248679757118225\n",
      "[Step 26337] Loss: 9.33e+07 -1.5056369304656982 0.06249092146754265\n",
      "[Step 26338] Loss: 9.35e+07 -1.5054017305374146 0.06249752268195152\n",
      "[Step 26339] Loss: 9.42e+07 -1.5052345991134644 0.06249669939279556\n",
      "[Step 26340] Loss: 9.42e+07 -1.5050981044769287 0.0625\n",
      "[Step 26341] Loss: 9.39e+07 -1.5048941373825073 0.06251237541437149\n",
      "[Step 26342] Loss: 9.40e+07 -1.5046789646148682 0.0625222772359848\n",
      "[Step 26343] Loss: 9.49e+07 -1.5046348571777344 0.06251237541437149\n",
      "[Step 26344] Loss: 9.40e+07 -1.504472017288208 0.06253383308649063\n",
      "[Step 26345] Loss: 9.42e+07 -1.5043710470199585 0.06255198270082474\n",
      "[Step 26346] Loss: 9.39e+07 -1.5042669773101807 0.06258003413677216\n",
      "[Step 26347] Loss: 9.41e+07 -1.5040546655654907 0.06257838755846024\n",
      "[Step 26348] Loss: 9.37e+07 -1.5038182735443115 0.06257343292236328\n",
      "[Step 26349] Loss: 9.68e+07 -1.504064679145813 0.06254620850086212\n",
      "[Step 26350] Loss: 9.48e+07 -1.504447102546692 0.06250907480716705\n",
      "[Step 26351] Loss: 9.40e+07 -1.5047203302383423 0.06249009817838669\n",
      "[Step 26352] Loss: 9.41e+07 -1.5050699710845947 0.06247441843152046\n",
      "[Step 26353] Loss: 9.36e+07 -1.5054395198822021 0.06245049089193344\n",
      "[Step 26354] Loss: 9.34e+07 -1.5057045221328735 0.06242986395955086\n",
      "[Step 26355] Loss: 9.43e+07 -1.505950927734375 0.06240015849471092\n",
      "[Step 26356] Loss: 9.41e+07 -1.5062458515167236 0.06238200515508652\n",
      "[Step 26357] Loss: 9.61e+07 -1.506797432899475 0.06234569847583771\n",
      "[Step 26358] Loss: 9.44e+07 -1.507339358329773 0.06230361759662628\n",
      "[Step 26359] Loss: 9.51e+07 -1.5080260038375854 0.06224833428859711\n",
      "[Step 26360] Loss: 9.39e+07 -1.508750319480896 0.062202125787734985\n",
      "[Step 26361] Loss: 9.37e+07 -1.509286642074585 0.06216499209403992\n",
      "[Step 26362] Loss: 9.50e+07 -1.5098217725753784 0.06214684247970581\n",
      "[Step 26363] Loss: 9.44e+07 -1.5103415250778198 0.06212043762207031\n",
      "[Step 26364] Loss: 9.38e+07 -1.5108633041381836 0.062094856053590775\n",
      "[Step 26365] Loss: 9.41e+07 -1.5113469362258911 0.062068451195955276\n",
      "[Step 26366] Loss: 9.42e+07 -1.5118176937103271 0.06202719733119011\n",
      "[Step 26367] Loss: 9.71e+07 -1.5127204656600952 0.06198016181588173\n",
      "[Step 26368] Loss: 9.37e+07 -1.5135469436645508 0.061933957040309906\n",
      "[Step 26369] Loss: 9.37e+07 -1.5142693519592285 0.06188197061419487\n",
      "[Step 26370] Loss: 9.30e+07 -1.5148816108703613 0.06185474246740341\n",
      "[Step 26371] Loss: 9.42e+07 -1.5153104066848755 0.061825864017009735\n",
      "[Step 26372] Loss: 9.61e+07 -1.5160967111587524 0.06176397576928139\n",
      "[Step 26373] Loss: 9.69e+07 -1.5172765254974365 0.061693016439676285\n",
      "[Step 26374] Loss: 9.48e+07 -1.5182386636734009 0.061643507331609726\n",
      "[Step 26375] Loss: 9.37e+07 -1.5190421342849731 0.06158822402358055\n",
      "[Step 26376] Loss: 9.41e+07 -1.5196547508239746 0.061560992151498795\n",
      "[Step 26377] Loss: 9.41e+07 -1.5201057195663452 0.06151808798313141\n",
      "[Step 26378] Loss: 9.42e+07 -1.5204960107803345 0.0615081861615181\n",
      "[Step 26379] Loss: 9.35e+07 -1.5207815170288086 0.061473529785871506\n",
      "[Step 26380] Loss: 9.40e+07 -1.5209124088287354 0.06145372614264488\n",
      "[Step 26381] Loss: 9.37e+07 -1.5210071802139282 0.06146032735705376\n",
      "[Step 26382] Loss: 9.39e+07 -1.5209832191467285 0.061464451253414154\n",
      "[Step 26383] Loss: 9.42e+07 -1.5209736824035645 0.061464451253414154\n",
      "[Step 26384] Loss: 9.40e+07 -1.5209743976593018 0.061463627964258194\n",
      "[Step 26385] Loss: 9.65e+07 -1.5213857889175415 0.061449598520994186\n",
      "[Step 26386] Loss: 9.36e+07 -1.5216680765151978 0.06142154708504677\n",
      "[Step 26387] Loss: 9.36e+07 -1.521891713142395 0.06139761582016945\n",
      "[Step 26388] Loss: 9.37e+07 -1.5220327377319336 0.06138111278414726\n",
      "[Step 26389] Loss: 9.36e+07 -1.52219820022583 0.06137368828058243\n",
      "[Step 26390] Loss: 9.66e+07 -1.5227267742156982 0.061353057622909546\n",
      "[Step 26391] Loss: 9.54e+07 -1.5230714082717896 0.06132087856531143\n",
      "[Step 26392] Loss: 9.43e+07 -1.523211121559143 0.061317577958106995\n",
      "[Step 26393] Loss: 9.44e+07 -1.5233973264694214 0.06131097674369812\n",
      "[Step 26394] Loss: 9.35e+07 -1.523483157157898 0.061304375529289246\n",
      "[Step 26395] Loss: 9.43e+07 -1.5235986709594727 0.06129612401127815\n",
      "[Step 26396] Loss: 9.38e+07 -1.523668646812439 0.06129860132932663\n",
      "[Step 26397] Loss: 9.46e+07 -1.5236132144927979 0.06130107492208481\n",
      "[Step 26398] Loss: 9.44e+07 -1.5235356092453003 0.06131922826170921\n",
      "[Step 26399] Loss: 9.66e+07 -1.5239135026931763 0.06129695102572441\n",
      "[Step 26400] Loss: 9.34e+07 -1.5241860151290894 0.06126559525728226\n",
      "[Step 26401] Loss: 9.38e+07 -1.524387001991272 0.06124826520681381\n",
      "[Step 26402] Loss: 9.60e+07 -1.524877667427063 0.06122268736362457\n",
      "[Step 26403] Loss: 9.37e+07 -1.5252692699432373 0.06121113523840904\n",
      "[Step 26404] Loss: 9.43e+07 -1.5255422592163086 0.06119133159518242\n",
      "[Step 26405] Loss: 9.50e+07 -1.5256407260894775 0.06119133159518242\n",
      "[Step 26406] Loss: 9.47e+07 -1.5256356000900269 0.06119215860962868\n",
      "[Step 26407] Loss: 9.44e+07 -1.525546669960022 0.06119875982403755\n",
      "[Step 26408] Loss: 9.46e+07 -1.5253630876541138 0.061196282505989075\n",
      "[Step 26409] Loss: 9.44e+07 -1.525251030921936 0.061206184327602386\n",
      "[Step 26410] Loss: 9.40e+07 -1.5251888036727905 0.06121113523840904\n",
      "[Step 26411] Loss: 9.33e+07 -1.5250524282455444 0.06121113523840904\n",
      "[Step 26412] Loss: 9.37e+07 -1.5249112844467163 0.06121031194925308\n",
      "[Step 26413] Loss: 9.40e+07 -1.5246996879577637 0.06122268736362457\n",
      "[Step 26414] Loss: 9.39e+07 -1.5244479179382324 0.0612383633852005\n",
      "[Step 26415] Loss: 9.42e+07 -1.5240974426269531 0.06126146763563156\n",
      "[Step 26416] Loss: 9.45e+07 -1.5236529111862183 0.0612911731004715\n",
      "[Step 26417] Loss: 9.44e+07 -1.5232917070388794 0.06131840497255325\n",
      "[Step 26418] Loss: 9.37e+07 -1.5229464769363403 0.06133490428328514\n",
      "[Step 26419] Loss: 9.36e+07 -1.5226110219955444 0.061354707926511765\n",
      "[Step 26420] Loss: 9.65e+07 -1.522712230682373 0.061342332512140274\n",
      "[Step 26421] Loss: 9.48e+07 -1.5228691101074219 0.06130272522568703\n",
      "[Step 26422] Loss: 9.41e+07 -1.522985816001892 0.06128374859690666\n",
      "[Step 26423] Loss: 9.46e+07 -1.5229740142822266 0.06128374859690666\n",
      "[Step 26424] Loss: 9.52e+07 -1.5231157541275024 0.06127054616808891\n",
      "[Step 26425] Loss: 9.34e+07 -1.5232166051864624 0.061268068850040436\n",
      "[Step 26426] Loss: 9.42e+07 -1.5232863426208496 0.06125899404287338\n",
      "[Step 26427] Loss: 9.37e+07 -1.5233873128890991 0.06125156581401825\n",
      "[Step 26428] Loss: 9.40e+07 -1.523451566696167 0.06124991551041603\n",
      "[Step 26429] Loss: 9.35e+07 -1.523475170135498 0.06124909222126007\n",
      "[Step 26430] Loss: 9.42e+07 -1.523395299911499 0.061256516724824905\n",
      "[Step 26431] Loss: 9.47e+07 -1.523417353630066 0.0612383633852005\n",
      "[Step 26432] Loss: 9.39e+07 -1.523370385169983 0.061246614903211594\n",
      "[Step 26433] Loss: 9.64e+07 -1.5236735343933105 0.06122433766722679\n",
      "[Step 26434] Loss: 9.41e+07 -1.5240603685379028 0.06119050830602646\n",
      "[Step 26435] Loss: 9.43e+07 -1.5243430137634277 0.0611674040555954\n",
      "[Step 26436] Loss: 9.42e+07 -1.5244914293289185 0.061147600412368774\n",
      "[Step 26437] Loss: 9.35e+07 -1.5245884656906128 0.0611451230943203\n",
      "[Step 26438] Loss: 9.40e+07 -1.5245712995529175 0.06113934889435768\n",
      "[Step 26439] Loss: 9.41e+07 -1.5245091915130615 0.061136048287153244\n",
      "[Step 26440] Loss: 9.39e+07 -1.5243744850158691 0.061135221272706985\n",
      "[Step 26441] Loss: 9.45e+07 -1.5241634845733643 0.06113192066550255\n",
      "[Step 26442] Loss: 9.50e+07 -1.5237884521484375 0.06114925071597099\n",
      "[Step 26443] Loss: 9.44e+07 -1.5235068798065186 0.06116410344839096\n",
      "[Step 26444] Loss: 9.42e+07 -1.5232069492340088 0.061183080077171326\n",
      "[Step 26445] Loss: 9.60e+07 -1.5227633714675903 0.06119298189878464\n",
      "[Step 26446] Loss: 9.35e+07 -1.5223702192306519 0.06121691316366196\n",
      "[Step 26447] Loss: 9.34e+07 -1.5220013856887817 0.061231762170791626\n",
      "[Step 26448] Loss: 9.61e+07 -1.5221095085144043 0.06121443584561348\n",
      "[Step 26449] Loss: 9.43e+07 -1.5220657587051392 0.061220213770866394\n",
      "[Step 26450] Loss: 9.33e+07 -1.521944522857666 0.06124826520681381\n",
      "[Step 26451] Loss: 9.46e+07 -1.5218621492385864 0.06124826520681381\n",
      "[Step 26452] Loss: 9.41e+07 -1.5218794345855713 0.06124826520681381\n",
      "[Step 26453] Loss: 9.39e+07 -1.521898865699768 0.06125156581401825\n",
      "[Step 26454] Loss: 9.38e+07 -1.5218932628631592 0.061264768242836\n",
      "[Step 26455] Loss: 9.42e+07 -1.5218708515167236 0.061268068850040436\n",
      "[Step 26456] Loss: 9.43e+07 -1.521798014640808 0.06127632036805153\n",
      "[Step 26457] Loss: 9.44e+07 -1.52166748046875 0.0612829215824604\n",
      "[Step 26458] Loss: 9.45e+07 -1.521675705909729 0.06127714738249779\n",
      "[Step 26459] Loss: 9.51e+07 -1.5215635299682617 0.061279620975255966\n",
      "[Step 26460] Loss: 9.44e+07 -1.5214250087738037 0.061293650418519974\n",
      "[Step 26461] Loss: 9.45e+07 -1.5212162733078003 0.06130272522568703\n",
      "[Step 26462] Loss: 9.46e+07 -1.521117925643921 0.06130025163292885\n",
      "[Step 26463] Loss: 9.48e+07 -1.5212583541870117 0.06129860132932663\n",
      "[Step 26464] Loss: 9.46e+07 -1.5213061571121216 0.061294473707675934\n",
      "[Step 26465] Loss: 9.37e+07 -1.5213621854782104 0.06129612401127815\n",
      "[Step 26466] Loss: 9.40e+07 -1.5213700532913208 0.06129777431488037\n",
      "[Step 26467] Loss: 9.36e+07 -1.52133047580719 0.061315104365348816\n",
      "[Step 26468] Loss: 9.43e+07 -1.5213173627853394 0.06133325397968292\n",
      "[Step 26469] Loss: 9.46e+07 -1.5212843418121338 0.061340682208538055\n",
      "[Step 26470] Loss: 9.51e+07 -1.5214616060256958 0.06133820489048958\n",
      "[Step 26471] Loss: 9.37e+07 -1.5215376615524292 0.061342332512140274\n",
      "[Step 26472] Loss: 9.41e+07 -1.5214658975601196 0.06134810671210289\n",
      "[Step 26473] Loss: 9.42e+07 -1.5214283466339111 0.06134810671210289\n",
      "[Step 26474] Loss: 9.37e+07 -1.521388053894043 0.06135140731930733\n",
      "[Step 26475] Loss: 9.48e+07 -1.521446704864502 0.06134398281574249\n",
      "[Step 26476] Loss: 9.51e+07 -1.5216799974441528 0.06132500618696213\n",
      "[Step 26477] Loss: 9.42e+07 -1.5217885971069336 0.061315927654504776\n",
      "[Step 26478] Loss: 9.41e+07 -1.521815538406372 0.06133325397968292\n",
      "[Step 26479] Loss: 9.45e+07 -1.5220346450805664 0.06132005527615547\n",
      "[Step 26480] Loss: 9.71e+07 -1.5226993560791016 0.061306025832891464\n",
      "[Step 26481] Loss: 9.53e+07 -1.5234668254852295 0.061258167028427124\n",
      "[Step 26482] Loss: 9.44e+07 -1.5241869688034058 0.061233412474393845\n",
      "[Step 26483] Loss: 9.45e+07 -1.5249325037002563 0.061194632202386856\n",
      "[Step 26484] Loss: 9.41e+07 -1.52554452419281 0.061159975826740265\n",
      "[Step 26485] Loss: 9.48e+07 -1.5259538888931274 0.06115172430872917\n",
      "[Step 26486] Loss: 9.44e+07 -1.5263975858688354 0.06111954525113106\n",
      "[Step 26487] Loss: 9.49e+07 -1.5269850492477417 0.06108901649713516\n",
      "[Step 26488] Loss: 9.36e+07 -1.5274958610534668 0.06105353310704231\n",
      "[Step 26489] Loss: 9.62e+07 -1.528250813484192 0.060999076813459396\n",
      "[Step 26490] Loss: 9.38e+07 -1.528882622718811 0.060966070741415024\n",
      "[Step 26491] Loss: 9.32e+07 -1.5294010639190674 0.06094296649098396\n",
      "[Step 26492] Loss: 9.44e+07 -1.52978515625 0.060919035226106644\n",
      "[Step 26493] Loss: 9.43e+07 -1.5303411483764648 0.06088273227214813\n",
      "[Step 26494] Loss: 9.36e+07 -1.5308902263641357 0.060856327414512634\n",
      "[Step 26495] Loss: 9.40e+07 -1.5313849449157715 0.06081011891365051\n",
      "[Step 26496] Loss: 9.36e+07 -1.5317933559417725 0.06078949198126793\n",
      "[Step 26497] Loss: 9.44e+07 -1.5320998430252075 0.06076886132359505\n",
      "[Step 26498] Loss: 9.42e+07 -1.5322794914245605 0.06074328348040581\n",
      "[Step 26499] Loss: 9.44e+07 -1.5324008464813232 0.06074080616235733\n",
      "[Step 26500] Loss: 9.68e+07 -1.5329196453094482 0.06071522831916809\n",
      "[Step 26501] Loss: 9.42e+07 -1.533325433731079 0.060685522854328156\n",
      "[Step 26502] Loss: 9.38e+07 -1.5336061716079712 0.060662418603897095\n",
      "[Step 26503] Loss: 9.44e+07 -1.5339900255203247 0.060638491064310074\n",
      "[Step 26504] Loss: 9.34e+07 -1.534249186515808 0.06061786040663719\n",
      "[Step 26505] Loss: 9.53e+07 -1.5346181392669678 0.060590632259845734\n",
      "[Step 26506] Loss: 9.36e+07 -1.5348986387252808 0.060563404113054276\n",
      "[Step 26507] Loss: 9.44e+07 -1.5352927446365356 0.06053204834461212\n",
      "[Step 26508] Loss: 9.36e+07 -1.5355548858642578 0.06052544713020325\n",
      "[Step 26509] Loss: 9.42e+07 -1.5358073711395264 0.06049739196896553\n",
      "[Step 26510] Loss: 9.45e+07 -1.5361709594726562 0.060480065643787384\n",
      "[Step 26511] Loss: 9.43e+07 -1.536387324333191 0.060466036200523376\n",
      "[Step 26512] Loss: 9.48e+07 -1.5364983081817627 0.06044705957174301\n",
      "[Step 26513] Loss: 9.34e+07 -1.5366017818450928 0.06045696139335632\n",
      "[Step 26514] Loss: 9.71e+07 -1.537156581878662 0.060419827699661255\n",
      "[Step 26515] Loss: 9.58e+07 -1.5379102230072021 0.06036454439163208\n",
      "[Step 26516] Loss: 9.39e+07 -1.538677453994751 0.060310084372758865\n",
      "[Step 26517] Loss: 9.51e+07 -1.5392736196517944 0.06029358133673668\n",
      "[Step 26518] Loss: 9.43e+07 -1.5397242307662964 0.06027790531516075\n",
      "[Step 26519] Loss: 9.49e+07 -1.5400381088256836 0.06025232747197151\n",
      "[Step 26520] Loss: 9.51e+07 -1.540216088294983 0.06023912504315376\n",
      "[Step 26521] Loss: 9.41e+07 -1.5405141115188599 0.06022922322154045\n",
      "[Step 26522] Loss: 9.43e+07 -1.5409488677978516 0.06019621714949608\n",
      "[Step 26523] Loss: 9.41e+07 -1.5413239002227783 0.060187142342329025\n",
      "[Step 26524] Loss: 9.57e+07 -1.541906476020813 0.06015908718109131\n",
      "[Step 26525] Loss: 9.57e+07 -1.542744517326355 0.060128554701805115\n",
      "[Step 26526] Loss: 9.42e+07 -1.5434132814407349 0.060093898326158524\n",
      "[Step 26527] Loss: 9.40e+07 -1.5440499782562256 0.0600518174469471\n",
      "[Step 26528] Loss: 9.44e+07 -1.5446325540542603 0.060029540210962296\n",
      "[Step 26529] Loss: 9.39e+07 -1.5450588464736938 0.06000395864248276\n",
      "[Step 26530] Loss: 9.38e+07 -1.5453754663467407 0.05997590720653534\n",
      "[Step 26531] Loss: 9.42e+07 -1.5455360412597656 0.05998745560646057\n",
      "[Step 26532] Loss: 9.41e+07 -1.5455597639083862 0.05998745560646057\n",
      "[Step 26533] Loss: 9.40e+07 -1.545459270477295 0.059994883835315704\n",
      "[Step 26534] Loss: 9.47e+07 -1.5452011823654175 0.06002293899655342\n",
      "[Step 26535] Loss: 9.44e+07 -1.5448812246322632 0.060043565928936005\n",
      "[Step 26536] Loss: 9.37e+07 -1.5444778203964233 0.06006419658660889\n",
      "[Step 26537] Loss: 9.46e+07 -1.5439653396606445 0.06009802594780922\n",
      "[Step 26538] Loss: 9.38e+07 -1.5434108972549438 0.06012030318379402\n",
      "[Step 26539] Loss: 9.53e+07 -1.543146014213562 0.06011947989463806\n",
      "[Step 26540] Loss: 9.34e+07 -1.5428398847579956 0.060140106827020645\n",
      "[Step 26541] Loss: 9.42e+07 -1.5424227714538574 0.06015991047024727\n",
      "[Step 26542] Loss: 9.35e+07 -1.541953206062317 0.06018301472067833\n",
      "[Step 26543] Loss: 9.36e+07 -1.541487216949463 0.060215193778276443\n",
      "[Step 26544] Loss: 9.42e+07 -1.5409446954727173 0.06023994833230972\n",
      "[Step 26545] Loss: 9.45e+07 -1.5403496026992798 0.06028945744037628\n",
      "[Step 26546] Loss: 9.35e+07 -1.5397614240646362 0.06034061685204506\n",
      "[Step 26547] Loss: 9.38e+07 -1.5391842126846313 0.0603620707988739\n",
      "[Step 26548] Loss: 9.39e+07 -1.538572907447815 0.06040167436003685\n",
      "[Step 26549] Loss: 9.40e+07 -1.5380185842514038 0.06044623255729675\n",
      "[Step 26550] Loss: 9.37e+07 -1.5374164581298828 0.06048418954014778\n",
      "[Step 26551] Loss: 9.41e+07 -1.5367870330810547 0.06052379682660103\n",
      "[Step 26552] Loss: 9.41e+07 -1.5362282991409302 0.060550201684236526\n",
      "[Step 26553] Loss: 9.48e+07 -1.5356115102767944 0.06059228256344795\n",
      "[Step 26554] Loss: 9.36e+07 -1.534991979598999 0.06063023954629898\n",
      "[Step 26555] Loss: 9.46e+07 -1.5343807935714722 0.060648392885923386\n",
      "[Step 26556] Loss: 9.45e+07 -1.5338231325149536 0.06066736951470375\n",
      "[Step 26557] Loss: 9.46e+07 -1.5332435369491577 0.060708627104759216\n",
      "[Step 26558] Loss: 9.43e+07 -1.532810926437378 0.06073750555515289\n",
      "[Step 26559] Loss: 9.41e+07 -1.5323683023452759 0.06074988469481468\n",
      "[Step 26560] Loss: 9.44e+07 -1.5319744348526 0.06078536435961723\n",
      "[Step 26561] Loss: 9.47e+07 -1.5316911935806274 0.0608043447136879\n",
      "[Step 26562] Loss: 9.41e+07 -1.5314100980758667 0.06082744523882866\n",
      "[Step 26563] Loss: 9.46e+07 -1.5310860872268677 0.06085219979286194\n",
      "[Step 26564] Loss: 9.39e+07 -1.530757188796997 0.060868702828884125\n",
      "[Step 26565] Loss: 9.48e+07 -1.5303338766098022 0.06089510768651962\n",
      "[Step 26566] Loss: 9.48e+07 -1.5299817323684692 0.06090913712978363\n",
      "[Step 26567] Loss: 9.46e+07 -1.5297789573669434 0.060929764062166214\n",
      "[Step 26568] Loss: 9.48e+07 -1.529673457145691 0.06094378978013992\n",
      "[Step 26569] Loss: 9.41e+07 -1.5294756889343262 0.06094791740179062\n",
      "[Step 26570] Loss: 9.52e+07 -1.529570460319519 0.06094461679458618\n",
      "[Step 26571] Loss: 9.43e+07 -1.5296696424484253 0.06094956770539284\n",
      "[Step 26572] Loss: 9.39e+07 -1.5297236442565918 0.06094709038734436\n",
      "[Step 26573] Loss: 9.68e+07 -1.530246376991272 0.060919035226106644\n",
      "[Step 26574] Loss: 9.47e+07 -1.5306284427642822 0.060893457382917404\n",
      "[Step 26575] Loss: 9.71e+07 -1.5314456224441528 0.06084229797124863\n",
      "[Step 26576] Loss: 9.40e+07 -1.5321966409683228 0.06080269441008568\n",
      "[Step 26577] Loss: 9.47e+07 -1.532965898513794 0.06075318530201912\n",
      "[Step 26578] Loss: 9.53e+07 -1.5335254669189453 0.06071440130472183\n",
      "[Step 26579] Loss: 9.44e+07 -1.5339275598526 0.06069542467594147\n",
      "[Step 26580] Loss: 9.37e+07 -1.5342062711715698 0.06066984683275223\n",
      "[Step 26581] Loss: 9.39e+07 -1.534411907196045 0.06065746769309044\n",
      "[Step 26582] Loss: 9.41e+07 -1.534561276435852 0.06063106283545494\n",
      "[Step 26583] Loss: 9.42e+07 -1.534670114517212 0.06062858924269676\n",
      "[Step 26584] Loss: 9.42e+07 -1.5348535776138306 0.06061621010303497\n",
      "[Step 26585] Loss: 9.41e+07 -1.5349388122558594 0.06060713529586792\n",
      "[Step 26586] Loss: 9.41e+07 -1.5349427461624146 0.0606096088886261\n",
      "[Step 26587] Loss: 9.33e+07 -1.5349031686782837 0.06061951071023941\n",
      "[Step 26588] Loss: 9.42e+07 -1.5348995923995972 0.06060630828142166\n",
      "[Step 26589] Loss: 9.40e+07 -1.534919261932373 0.060599710792303085\n",
      "[Step 26590] Loss: 9.36e+07 -1.5349196195602417 0.060586508363485336\n",
      "[Step 26591] Loss: 9.41e+07 -1.5349143743515015 0.06057825684547424\n",
      "[Step 26592] Loss: 9.40e+07 -1.5348546504974365 0.06059310957789421\n",
      "[Step 26593] Loss: 9.42e+07 -1.5348467826843262 0.06059145927429199\n",
      "[Step 26594] Loss: 9.39e+07 -1.5347896814346313 0.060599710792303085\n",
      "[Step 26595] Loss: 9.42e+07 -1.5346262454986572 0.06059641018509865\n",
      "[Step 26596] Loss: 9.41e+07 -1.5343772172927856 0.060613736510276794\n",
      "[Step 26597] Loss: 9.40e+07 -1.5341020822525024 0.0606318898499012\n",
      "[Step 26598] Loss: 9.49e+07 -1.5339601039886475 0.0606318898499012\n",
      "[Step 26599] Loss: 9.41e+07 -1.5338250398635864 0.06064344197511673\n",
      "[Step 26600] Loss: 9.38e+07 -1.533599615097046 0.06066571921110153\n",
      "[Step 26601] Loss: 9.51e+07 -1.5335330963134766 0.06066571921110153\n",
      "[Step 26602] Loss: 9.37e+07 -1.533426284790039 0.06066406890749931\n",
      "[Step 26603] Loss: 9.44e+07 -1.5333142280578613 0.06066901981830597\n",
      "[Step 26604] Loss: 9.41e+07 -1.5331546068191528 0.060687173157930374\n",
      "[Step 26605] Loss: 9.37e+07 -1.5330241918563843 0.060698725283145905\n",
      "[Step 26606] Loss: 9.34e+07 -1.5329147577285767 0.06070780009031296\n",
      "[Step 26607] Loss: 9.37e+07 -1.5328404903411865 0.06070037558674812\n",
      "[Step 26608] Loss: 9.50e+07 -1.532583236694336 0.06072595342993736\n",
      "[Step 26609] Loss: 9.45e+07 -1.5322322845458984 0.06072760373353958\n",
      "[Step 26610] Loss: 9.57e+07 -1.5317376852035522 0.06075400859117508\n",
      "[Step 26611] Loss: 9.73e+07 -1.5317729711532593 0.06074410676956177\n",
      "[Step 26612] Loss: 9.41e+07 -1.5319290161132812 0.06073008105158806\n",
      "[Step 26613] Loss: 9.44e+07 -1.5319703817367554 0.06073915585875511\n",
      "[Step 26614] Loss: 9.41e+07 -1.5320522785186768 0.06072100251913071\n",
      "[Step 26615] Loss: 9.31e+07 -1.5320703983306885 0.06072595342993736\n",
      "[Step 26616] Loss: 9.65e+07 -1.5324455499649048 0.06070450320839882\n",
      "[Step 26617] Loss: 9.44e+07 -1.5328562259674072 0.060671497136354446\n",
      "[Step 26618] Loss: 9.39e+07 -1.5332003831863403 0.06064261496067047\n",
      "[Step 26619] Loss: 9.44e+07 -1.5335465669631958 0.0606096088886261\n",
      "[Step 26620] Loss: 9.39e+07 -1.533801555633545 0.06059145927429199\n",
      "[Step 26621] Loss: 9.38e+07 -1.5340865850448608 0.06058238074183464\n",
      "[Step 26622] Loss: 9.40e+07 -1.5343269109725952 0.06055597588419914\n",
      "[Step 26623] Loss: 9.38e+07 -1.534482717514038 0.06054607406258583\n",
      "[Step 26624] Loss: 9.40e+07 -1.5345959663391113 0.06054690107703209\n",
      "[Step 26625] Loss: 9.43e+07 -1.5346903800964355 0.0605303980410099\n",
      "[Step 26626] Loss: 9.67e+07 -1.535164475440979 0.06048831716179848\n",
      "[Step 26627] Loss: 9.37e+07 -1.5355560779571533 0.060456134378910065\n",
      "[Step 26628] Loss: 9.52e+07 -1.536091685295105 0.06042395532131195\n",
      "[Step 26629] Loss: 9.48e+07 -1.5364789962768555 0.06039094924926758\n",
      "[Step 26630] Loss: 9.41e+07 -1.5368101596832275 0.06037939712405205\n",
      "[Step 26631] Loss: 9.39e+07 -1.537099003791809 0.06035134196281433\n",
      "[Step 26632] Loss: 9.44e+07 -1.537216067314148 0.06033896654844284\n",
      "[Step 26633] Loss: 9.56e+07 -1.53750741481781 0.06031916290521622\n",
      "[Step 26634] Loss: 9.47e+07 -1.5376355648040771 0.06032741442322731\n",
      "[Step 26635] Loss: 9.50e+07 -1.5379784107208252 0.06031833589076996\n",
      "[Step 26636] Loss: 9.39e+07 -1.5382554531097412 0.06030183285474777\n",
      "[Step 26637] Loss: 9.41e+07 -1.5385233163833618 0.0602911077439785\n",
      "[Step 26638] Loss: 9.33e+07 -1.5387277603149414 0.060296058654785156\n",
      "[Step 26639] Loss: 9.39e+07 -1.538893699645996 0.06028285622596741\n",
      "[Step 26640] Loss: 9.38e+07 -1.538997769355774 0.06028285622596741\n",
      "[Step 26641] Loss: 9.45e+07 -1.5391621589660645 0.06027790531516075\n",
      "[Step 26642] Loss: 9.43e+07 -1.5393476486206055 0.06026718020439148\n",
      "[Step 26643] Loss: 9.41e+07 -1.5393764972686768 0.060264702886343\n",
      "[Step 26644] Loss: 9.66e+07 -1.5397977828979492 0.06023912504315376\n",
      "[Step 26645] Loss: 9.49e+07 -1.540260910987854 0.06021684408187866\n",
      "[Step 26646] Loss: 9.50e+07 -1.5408687591552734 0.0601937398314476\n",
      "[Step 26647] Loss: 9.41e+07 -1.541403889656067 0.06016898900270462\n",
      "[Step 26648] Loss: 9.46e+07 -1.5417026281356812 0.06014753505587578\n",
      "[Step 26649] Loss: 9.43e+07 -1.542040467262268 0.060117002576589584\n",
      "[Step 26650] Loss: 9.47e+07 -1.5424609184265137 0.06010132655501366\n",
      "[Step 26651] Loss: 9.40e+07 -1.5428798198699951 0.06007492169737816\n",
      "[Step 26652] Loss: 9.45e+07 -1.5432265996932983 0.0600518174469471\n",
      "[Step 26653] Loss: 9.54e+07 -1.5436437129974365 0.0600254125893116\n",
      "[Step 26654] Loss: 9.41e+07 -1.5440876483917236 0.059993233531713486\n",
      "[Step 26655] Loss: 9.55e+07 -1.544750690460205 0.0599503256380558\n",
      "[Step 26656] Loss: 9.35e+07 -1.5452836751937866 0.05991731956601143\n",
      "[Step 26657] Loss: 9.44e+07 -1.5455904006958008 0.05989999324083328\n",
      "[Step 26658] Loss: 9.45e+07 -1.5457253456115723 0.059885963797569275\n",
      "[Step 26659] Loss: 9.52e+07 -1.545711874961853 0.05988018959760666\n",
      "[Step 26660] Loss: 9.33e+07 -1.5456432104110718 0.0598793625831604\n",
      "[Step 26661] Loss: 9.39e+07 -1.545585036277771 0.05987771227955818\n",
      "[Step 26662] Loss: 9.42e+07 -1.5455304384231567 0.05988926440477371\n",
      "[Step 26663] Loss: 9.36e+07 -1.5454978942871094 0.05988183990120888\n",
      "[Step 26664] Loss: 9.46e+07 -1.545366883277893 0.059871114790439606\n",
      "[Step 26665] Loss: 9.37e+07 -1.545141339302063 0.059871938079595566\n",
      "[Step 26666] Loss: 9.40e+07 -1.5448219776153564 0.05990246683359146\n",
      "[Step 26667] Loss: 9.40e+07 -1.5445369482040405 0.059909895062446594\n",
      "[Step 26668] Loss: 9.42e+07 -1.5443042516708374 0.05992557108402252\n",
      "[Step 26669] Loss: 9.44e+07 -1.5442497730255127 0.059910718351602554\n",
      "[Step 26670] Loss: 9.63e+07 -1.5445903539657593 0.059899166226387024\n",
      "[Step 26671] Loss: 9.46e+07 -1.544745922088623 0.05988926440477371\n",
      "[Step 26672] Loss: 9.53e+07 -1.5446721315383911 0.05989421531558037\n",
      "[Step 26673] Loss: 9.40e+07 -1.544527292251587 0.05988679081201553\n",
      "[Step 26674] Loss: 9.39e+07 -1.544442057609558 0.05988679081201553\n",
      "[Step 26675] Loss: 9.52e+07 -1.5442506074905396 0.05989999324083328\n",
      "[Step 26676] Loss: 9.42e+07 -1.5440607070922852 0.05989009141921997\n",
      "[Step 26677] Loss: 9.38e+07 -1.5439069271087646 0.05988101288676262\n",
      "[Step 26678] Loss: 9.46e+07 -1.5436614751815796 0.05987853929400444\n",
      "[Step 26679] Loss: 9.39e+07 -1.5434308052062988 0.05987853929400444\n",
      "[Step 26680] Loss: 9.66e+07 -1.5435398817062378 0.05987028777599335\n",
      "[Step 26681] Loss: 9.40e+07 -1.5435177087783813 0.05986946448683739\n",
      "[Step 26682] Loss: 9.46e+07 -1.5436022281646729 0.05985791236162186\n",
      "[Step 26683] Loss: 9.41e+07 -1.5436357259750366 0.05985873565077782\n",
      "[Step 26684] Loss: 9.47e+07 -1.5437091588974 0.059860385954380035\n",
      "[Step 26685] Loss: 9.40e+07 -1.5436917543411255 0.059860385954380035\n",
      "[Step 26686] Loss: 9.42e+07 -1.54376220703125 0.05985378473997116\n",
      "[Step 26687] Loss: 9.43e+07 -1.5438753366470337 0.05984140932559967\n",
      "[Step 26688] Loss: 9.37e+07 -1.5439389944076538 0.05983975902199745\n",
      "[Step 26689] Loss: 9.43e+07 -1.5440036058425903 0.059834808111190796\n",
      "[Step 26690] Loss: 9.41e+07 -1.5441079139709473 0.059836458414793015\n",
      "[Step 26691] Loss: 9.42e+07 -1.5441678762435913 0.05982985720038414\n",
      "[Step 26692] Loss: 9.45e+07 -1.5441547632217407 0.05984305962920189\n",
      "[Step 26693] Loss: 9.62e+07 -1.5445364713668823 0.05981665477156639\n",
      "[Step 26694] Loss: 9.42e+07 -1.5447221994400024 0.05980180203914642\n",
      "[Step 26695] Loss: 9.36e+07 -1.5448800325393677 0.059799324721097946\n",
      "[Step 26696] Loss: 9.55e+07 -1.545255184173584 0.05976467207074165\n",
      "[Step 26697] Loss: 9.41e+07 -1.5455477237701416 0.059739917516708374\n",
      "[Step 26698] Loss: 9.44e+07 -1.5458472967147827 0.05972423776984215\n",
      "[Step 26699] Loss: 9.41e+07 -1.5461229085922241 0.059715986251831055\n",
      "[Step 26700] Loss: 9.41e+07 -1.5462559461593628 0.059692058712244034\n",
      "[Step 26701] Loss: 9.53e+07 -1.5466852188110352 0.05965162813663483\n",
      "[Step 26702] Loss: 9.47e+07 -1.547204613685608 0.059606242924928665\n",
      "[Step 26703] Loss: 9.43e+07 -1.5475516319274902 0.05959964171051979\n",
      "[Step 26704] Loss: 9.38e+07 -1.5478005409240723 0.059593040496110916\n",
      "[Step 26705] Loss: 9.44e+07 -1.547861099243164 0.05958808958530426\n",
      "[Step 26706] Loss: 9.44e+07 -1.54781973361969 0.05958973988890648\n",
      "[Step 26707] Loss: 9.51e+07 -1.5479567050933838 0.05957653746008873\n",
      "[Step 26708] Loss: 9.41e+07 -1.5481406450271606 0.05955343693494797\n",
      "[Step 26709] Loss: 9.41e+07 -1.548263430595398 0.059545185416936874\n",
      "[Step 26710] Loss: 9.56e+07 -1.548522710800171 0.059522081166505814\n",
      "[Step 26711] Loss: 9.39e+07 -1.5486844778060913 0.059507228434085846\n",
      "[Step 26712] Loss: 9.52e+07 -1.5489673614501953 0.0594898983836174\n",
      "[Step 26713] Loss: 9.41e+07 -1.549108624458313 0.059485774487257004\n",
      "[Step 26714] Loss: 9.37e+07 -1.5492483377456665 0.05949484929442406\n",
      "[Step 26715] Loss: 9.39e+07 -1.5492647886276245 0.059496499598026276\n",
      "[Step 26716] Loss: 9.38e+07 -1.54925537109375 0.05949897691607475\n",
      "[Step 26717] Loss: 9.45e+07 -1.5491136312484741 0.059518780559301376\n",
      "[Step 26718] Loss: 9.43e+07 -1.5488862991333008 0.05954023450613022\n",
      "[Step 26719] Loss: 9.45e+07 -1.5487251281738281 0.05954765900969505\n",
      "[Step 26720] Loss: 9.42e+07 -1.5484980344772339 0.0595608614385128\n",
      "[Step 26721] Loss: 9.41e+07 -1.548352599143982 0.05957818776369095\n",
      "[Step 26722] Loss: 9.41e+07 -1.548084020614624 0.05958808958530426\n",
      "[Step 26723] Loss: 9.42e+07 -1.547793984413147 0.05962274596095085\n",
      "[Step 26724] Loss: 9.41e+07 -1.547526478767395 0.05965080112218857\n",
      "[Step 26725] Loss: 9.34e+07 -1.547253966331482 0.05966318026185036\n",
      "[Step 26726] Loss: 9.42e+07 -1.5468820333480835 0.05970031023025513\n",
      "[Step 26727] Loss: 9.39e+07 -1.5464915037155151 0.059727538377046585\n",
      "[Step 26728] Loss: 9.44e+07 -1.5459873676300049 0.05975642055273056\n",
      "[Step 26729] Loss: 9.39e+07 -1.5454423427581787 0.05979272350668907\n",
      "[Step 26730] Loss: 9.45e+07 -1.5448381900787354 0.05983975902199745\n",
      "[Step 26731] Loss: 9.47e+07 -1.5443894863128662 0.059884313493967056\n",
      "[Step 26732] Loss: 9.42e+07 -1.543984293937683 0.05991401895880699\n",
      "[Step 26733] Loss: 9.42e+07 -1.5436691045761108 0.059931349009275436\n",
      "[Step 26734] Loss: 9.37e+07 -1.543302297592163 0.05994125083088875\n",
      "[Step 26735] Loss: 9.41e+07 -1.5428565740585327 0.05996517837047577\n",
      "[Step 26736] Loss: 9.48e+07 -1.5423319339752197 0.059994056820869446\n",
      "[Step 26737] Loss: 9.34e+07 -1.5417646169662476 0.06003944203257561\n",
      "[Step 26738] Loss: 9.40e+07 -1.5411536693572998 0.06008234992623329\n",
      "[Step 26739] Loss: 9.39e+07 -1.5405226945877075 0.06009802594780922\n",
      "[Step 26740] Loss: 9.56e+07 -1.5401835441589355 0.06011040136218071\n",
      "[Step 26741] Loss: 9.37e+07 -1.539918065071106 0.060141757130622864\n",
      "[Step 26742] Loss: 9.47e+07 -1.5397969484329224 0.06013350561261177\n",
      "[Step 26743] Loss: 9.68e+07 -1.5401532649993896 0.06010627746582031\n",
      "[Step 26744] Loss: 9.38e+07 -1.5404106378555298 0.06007162109017372\n",
      "[Step 26745] Loss: 9.37e+07 -1.5406088829040527 0.060066670179367065\n",
      "[Step 26746] Loss: 9.47e+07 -1.5408493280410767 0.06005099415779114\n",
      "[Step 26747] Loss: 9.31e+07 -1.5410375595092773 0.06005016714334488\n",
      "[Step 26748] Loss: 9.49e+07 -1.5411748886108398 0.06005924567580223\n",
      "[Step 26749] Loss: 9.59e+07 -1.5416114330291748 0.06002871319651604\n",
      "[Step 26750] Loss: 9.38e+07 -1.5419386625289917 0.06000973656773567\n",
      "[Step 26751] Loss: 9.43e+07 -1.54225754737854 0.05998910591006279\n",
      "[Step 26752] Loss: 9.44e+07 -1.542432188987732 0.059981681406497955\n",
      "[Step 26753] Loss: 9.38e+07 -1.542519450187683 0.05995280295610428\n",
      "[Step 26754] Loss: 9.39e+07 -1.5425007343292236 0.05994207412004471\n",
      "[Step 26755] Loss: 9.46e+07 -1.5425572395324707 0.059932172298431396\n",
      "[Step 26756] Loss: 9.42e+07 -1.542507290840149 0.059921447187662125\n",
      "[Step 26757] Loss: 9.47e+07 -1.5425431728363037 0.05991401895880699\n",
      "[Step 26758] Loss: 9.37e+07 -1.5425413846969604 0.05991566926240921\n",
      "[Step 26759] Loss: 9.43e+07 -1.5426102876663208 0.059910718351602554\n",
      "[Step 26760] Loss: 9.37e+07 -1.5426084995269775 0.05991896986961365\n",
      "[Step 26761] Loss: 9.42e+07 -1.5425188541412354 0.05992309749126434\n",
      "[Step 26762] Loss: 9.42e+07 -1.5424940586090088 0.05991484597325325\n",
      "[Step 26763] Loss: 9.62e+07 -1.5428574085235596 0.05987688899040222\n",
      "[Step 26764] Loss: 9.55e+07 -1.5434120893478394 0.05985378473997116\n",
      "[Step 26765] Loss: 9.44e+07 -1.5439789295196533 0.05980510264635086\n",
      "[Step 26766] Loss: 9.45e+07 -1.544346570968628 0.05977457016706467\n",
      "[Step 26767] Loss: 9.48e+07 -1.5446566343307495 0.05975394323468208\n",
      "[Step 26768] Loss: 9.40e+07 -1.5449258089065552 0.05973083898425102\n",
      "[Step 26769] Loss: 9.45e+07 -1.545111060142517 0.05971186235547066\n",
      "[Step 26770] Loss: 9.41e+07 -1.5451853275299072 0.059704434126615524\n",
      "[Step 26771] Loss: 9.54e+07 -1.5451092720031738 0.05972011387348175\n",
      "[Step 26772] Loss: 9.35e+07 -1.5450003147125244 0.05973001569509506\n",
      "[Step 26773] Loss: 9.45e+07 -1.5450376272201538 0.05973083898425102\n",
      "[Step 26774] Loss: 9.38e+07 -1.5449990034103394 0.05974569171667099\n",
      "[Step 26775] Loss: 9.70e+07 -1.545424461364746 0.05971763655543327\n",
      "[Step 26776] Loss: 9.43e+07 -1.5458306074142456 0.05968380719423294\n",
      "[Step 26777] Loss: 9.45e+07 -1.5461008548736572 0.05965162813663483\n",
      "[Step 26778] Loss: 9.34e+07 -1.5462826490402222 0.05964585021138191\n",
      "[Step 26779] Loss: 9.44e+07 -1.5463056564331055 0.05963264778256416\n",
      "[Step 26780] Loss: 9.39e+07 -1.546215295791626 0.05964832752943039\n",
      "[Step 26781] Loss: 9.41e+07 -1.5461097955703735 0.059667304158210754\n",
      "[Step 26782] Loss: 9.40e+07 -1.5458927154541016 0.05967060476541519\n",
      "[Step 26783] Loss: 9.39e+07 -1.545637845993042 0.059677205979824066\n",
      "[Step 26784] Loss: 9.50e+07 -1.545620322227478 0.0596846304833889\n",
      "[Step 26785] Loss: 9.38e+07 -1.5454777479171753 0.05969370901584625\n",
      "[Step 26786] Loss: 9.38e+07 -1.545275330543518 0.05971186235547066\n",
      "[Step 26787] Loss: 9.42e+07 -1.5450693368911743 0.05973166599869728\n",
      "[Step 26788] Loss: 9.39e+07 -1.5448129177093506 0.05974156782031059\n",
      "[Step 26789] Loss: 9.48e+07 -1.5444655418395996 0.05975889414548874\n",
      "[Step 26790] Loss: 9.42e+07 -1.5440810918807983 0.0597861222922802\n",
      "[Step 26791] Loss: 9.45e+07 -1.5435724258422852 0.05980922654271126\n",
      "[Step 26792] Loss: 9.39e+07 -1.5431214570999146 0.05984305962920189\n",
      "[Step 26793] Loss: 9.52e+07 -1.5430293083190918 0.05985543504357338\n",
      "[Step 26794] Loss: 9.40e+07 -1.5428836345672607 0.05985213443636894\n",
      "[Step 26795] Loss: 9.41e+07 -1.5427292585372925 0.05985873565077782\n",
      "[Step 26796] Loss: 9.56e+07 -1.5423741340637207 0.05986698716878891\n",
      "[Step 26797] Loss: 9.43e+07 -1.5420972108840942 0.0598793625831604\n",
      "[Step 26798] Loss: 9.36e+07 -1.5418648719787598 0.05989504233002663\n",
      "[Step 26799] Loss: 9.41e+07 -1.5415300130844116 0.05990411713719368\n",
      "[Step 26800] Loss: 9.42e+07 -1.5412075519561768 0.05991896986961365\n",
      "[Step 26801] Loss: 9.42e+07 -1.5409682989120483 0.05992969870567322\n",
      "[Step 26802] Loss: 9.39e+07 -1.5406951904296875 0.059946201741695404\n",
      "[Step 26803] Loss: 9.39e+07 -1.540307879447937 0.0599503256380558\n",
      "[Step 26804] Loss: 9.39e+07 -1.5398722887039185 0.05997425690293312\n",
      "[Step 26805] Loss: 9.45e+07 -1.5393069982528687 0.05999653413891792\n",
      "[Step 26806] Loss: 9.56e+07 -1.5390781164169312 0.06000973656773567\n",
      "[Step 26807] Loss: 9.51e+07 -1.538733959197998 0.06002293899655342\n",
      "[Step 26808] Loss: 9.52e+07 -1.5385829210281372 0.060030363500118256\n",
      "[Step 26809] Loss: 9.71e+07 -1.538880467414856 0.06001138687133789\n",
      "[Step 26810] Loss: 9.53e+07 -1.539358377456665 0.05999735742807388\n",
      "[Step 26811] Loss: 9.46e+07 -1.5397125482559204 0.05995940417051315\n",
      "[Step 26812] Loss: 9.40e+07 -1.5400208234786987 0.05992722138762474\n",
      "[Step 26813] Loss: 9.35e+07 -1.5403043031692505 0.05989999324083328\n",
      "[Step 26814] Loss: 9.38e+07 -1.5405150651931763 0.05988926440477371\n",
      "[Step 26815] Loss: 9.33e+07 -1.5405842065811157 0.05986863747239113\n",
      "[Step 26816] Loss: 9.42e+07 -1.5406173467636108 0.05986451357603073\n",
      "[Step 26817] Loss: 9.50e+07 -1.5406981706619263 0.05985791236162186\n",
      "[Step 26818] Loss: 9.39e+07 -1.5407048463821411 0.059862036257982254\n",
      "[Step 26819] Loss: 9.39e+07 -1.5406819581985474 0.05984140932559967\n",
      "[Step 26820] Loss: 9.35e+07 -1.540637493133545 0.05984058231115341\n",
      "[Step 26821] Loss: 9.50e+07 -1.5407673120498657 0.05981995537877083\n",
      "[Step 26822] Loss: 9.51e+07 -1.5410081148147583 0.0598042756319046\n",
      "[Step 26823] Loss: 9.53e+07 -1.5410665273666382 0.059800975024700165\n",
      "[Step 26824] Loss: 9.37e+07 -1.5410977602005005 0.05980262532830238\n",
      "[Step 26825] Loss: 9.37e+07 -1.5410692691802979 0.05979355052113533\n",
      "[Step 26826] Loss: 9.50e+07 -1.5408849716186523 0.05979767441749573\n",
      "[Step 26827] Loss: 9.53e+07 -1.5408698320388794 0.059789422899484634\n",
      "[Step 26828] Loss: 9.52e+07 -1.54091477394104 0.05978117138147354\n",
      "[Step 26829] Loss: 9.34e+07 -1.5409971475601196 0.05978447198867798\n",
      "[Step 26830] Loss: 9.50e+07 -1.5413211584091187 0.05977209657430649\n",
      "[Step 26831] Loss: 9.44e+07 -1.5416215658187866 0.05975889414548874\n",
      "[Step 26832] Loss: 9.43e+07 -1.5418686866760254 0.05973661690950394\n",
      "[Step 26833] Loss: 9.37e+07 -1.5420572757720947 0.059726715087890625\n",
      "[Step 26834] Loss: 9.67e+07 -1.5427100658416748 0.05968545749783516\n",
      "[Step 26835] Loss: 9.42e+07 -1.5431814193725586 0.05966070294380188\n",
      "[Step 26836] Loss: 9.41e+07 -1.5435781478881836 0.05963347479701042\n",
      "[Step 26837] Loss: 9.40e+07 -1.5438933372497559 0.05962604656815529\n",
      "[Step 26838] Loss: 9.43e+07 -1.5441056489944458 0.05960211902856827\n",
      "[Step 26839] Loss: 9.39e+07 -1.5443618297576904 0.05959881842136383\n",
      "[Step 26840] Loss: 9.41e+07 -1.5445072650909424 0.059582315385341644\n",
      "[Step 26841] Loss: 9.44e+07 -1.5445021390914917 0.05957323685288429\n",
      "[Step 26842] Loss: 9.41e+07 -1.544495701789856 0.05956581234931946\n",
      "[Step 26843] Loss: 9.41e+07 -1.5443453788757324 0.059583138674497604\n",
      "[Step 26844] Loss: 9.43e+07 -1.5442200899124146 0.05959964171051979\n",
      "[Step 26845] Loss: 9.51e+07 -1.5439252853393555 0.059616971760988235\n",
      "[Step 26846] Loss: 9.44e+07 -1.543554663658142 0.0596359483897686\n",
      "[Step 26847] Loss: 9.70e+07 -1.543664574623108 0.059618622064590454\n",
      "[Step 26848] Loss: 9.47e+07 -1.5436451435089111 0.05961532145738602\n",
      "[Step 26849] Loss: 9.41e+07 -1.5435608625411987 0.0596136711537838\n",
      "[Step 26850] Loss: 9.61e+07 -1.5438753366470337 0.05960459262132645\n",
      "[Step 26851] Loss: 9.36e+07 -1.5441668033599854 0.05958396568894386\n",
      "[Step 26852] Loss: 9.38e+07 -1.5443536043167114 0.0595649890601635\n",
      "[Step 26853] Loss: 9.35e+07 -1.5444753170013428 0.05955013632774353\n",
      "[Step 26854] Loss: 9.37e+07 -1.544538974761963 0.05954683572053909\n",
      "[Step 26855] Loss: 9.45e+07 -1.5445556640625 0.05954765900969505\n",
      "[Step 26856] Loss: 9.44e+07 -1.5444551706314087 0.05955343693494797\n",
      "[Step 26857] Loss: 9.41e+07 -1.5442793369293213 0.05956333875656128\n",
      "[Step 26858] Loss: 9.70e+07 -1.5445902347564697 0.05954683572053909\n",
      "[Step 26859] Loss: 9.51e+07 -1.5450559854507446 0.059521254152059555\n",
      "[Step 26860] Loss: 9.40e+07 -1.5454031229019165 0.05951713025569916\n",
      "[Step 26861] Loss: 9.32e+07 -1.5456478595733643 0.05950310081243515\n",
      "[Step 26862] Loss: 9.39e+07 -1.5457215309143066 0.05949897691607475\n",
      "[Step 26863] Loss: 9.34e+07 -1.5456998348236084 0.059498149901628494\n",
      "[Step 26864] Loss: 9.54e+07 -1.5458173751831055 0.05948824808001518\n",
      "[Step 26865] Loss: 9.38e+07 -1.5458378791809082 0.05949980020523071\n",
      "[Step 26866] Loss: 9.53e+07 -1.54606032371521 0.05951382964849472\n",
      "[Step 26867] Loss: 9.41e+07 -1.5462234020233154 0.05951300263404846\n",
      "[Step 26868] Loss: 9.53e+07 -1.546522617340088 0.05948907509446144\n",
      "[Step 26869] Loss: 9.32e+07 -1.546663761138916 0.059484124183654785\n",
      "[Step 26870] Loss: 9.53e+07 -1.5469774007797241 0.059473395347595215\n",
      "[Step 26871] Loss: 9.49e+07 -1.5473065376281738 0.059459369629621506\n",
      "[Step 26872] Loss: 9.68e+07 -1.548021674156189 0.05941728875041008\n",
      "[Step 26873] Loss: 9.40e+07 -1.5486047267913818 0.059410687536001205\n",
      "[Step 26874] Loss: 9.46e+07 -1.549012541770935 0.05937933176755905\n",
      "[Step 26875] Loss: 9.39e+07 -1.5493059158325195 0.05935952812433243\n",
      "[Step 26876] Loss: 9.42e+07 -1.549514651298523 0.05935457721352577\n",
      "[Step 26877] Loss: 9.37e+07 -1.5496773719787598 0.059349626302719116\n",
      "[Step 26878] Loss: 9.53e+07 -1.5499948263168335 0.0593438521027565\n",
      "[Step 26879] Loss: 9.38e+07 -1.5502959489822388 0.059338074177503586\n",
      "[Step 26880] Loss: 9.39e+07 -1.550571322441101 0.059312496334314346\n",
      "[Step 26881] Loss: 9.43e+07 -1.5507237911224365 0.059302594512701035\n",
      "[Step 26882] Loss: 9.41e+07 -1.5507183074951172 0.059313319623470306\n",
      "[Step 26883] Loss: 9.45e+07 -1.550552487373352 0.05932899937033653\n",
      "[Step 26884] Loss: 9.49e+07 -1.5505949258804321 0.05933312326669693\n",
      "[Step 26885] Loss: 9.43e+07 -1.55067777633667 0.05934137478470802\n",
      "[Step 26886] Loss: 9.36e+07 -1.550661325454712 0.05934715270996094\n",
      "[Step 26887] Loss: 9.47e+07 -1.550466775894165 0.05936200171709061\n",
      "[Step 26888] Loss: 9.50e+07 -1.5501199960708618 0.05937190353870392\n",
      "[Step 26889] Loss: 9.61e+07 -1.5501633882522583 0.059387583285570145\n",
      "[Step 26890] Loss: 9.47e+07 -1.5504028797149658 0.05937933176755905\n",
      "[Step 26891] Loss: 9.53e+07 -1.5508722066879272 0.05935210362076759\n",
      "[Step 26892] Loss: 9.41e+07 -1.5512752532958984 0.05933064967393875\n",
      "[Step 26893] Loss: 9.37e+07 -1.551528811454773 0.059313319623470306\n",
      "[Step 26894] Loss: 9.40e+07 -1.5516244173049927 0.059313319623470306\n",
      "[Step 26895] Loss: 9.39e+07 -1.5517373085021973 0.05930589511990547\n",
      "[Step 26896] Loss: 9.51e+07 -1.5519570112228394 0.059302594512701035\n",
      "[Step 26897] Loss: 9.46e+07 -1.5520581007003784 0.059289392083883286\n",
      "[Step 26898] Loss: 9.60e+07 -1.5524544715881348 0.05927371233701706\n",
      "[Step 26899] Loss: 9.35e+07 -1.5527126789093018 0.05925638601183891\n",
      "[Step 26900] Loss: 9.35e+07 -1.5529272556304932 0.05923410877585411\n",
      "[Step 26901] Loss: 9.41e+07 -1.5530470609664917 0.05921430513262749\n",
      "[Step 26902] Loss: 9.43e+07 -1.5531526803970337 0.05920275300741196\n",
      "[Step 26903] Loss: 9.38e+07 -1.5531644821166992 0.05918624997138977\n",
      "[Step 26904] Loss: 9.42e+07 -1.5530513525009155 0.0591978020966053\n",
      "[Step 26905] Loss: 9.64e+07 -1.553389549255371 0.05917469784617424\n",
      "[Step 26906] Loss: 9.39e+07 -1.5537701845169067 0.059158194810152054\n",
      "[Step 26907] Loss: 9.39e+07 -1.5540587902069092 0.059121064841747284\n",
      "[Step 26908] Loss: 9.46e+07 -1.5543806552886963 0.05908970907330513\n",
      "[Step 26909] Loss: 9.38e+07 -1.5545728206634521 0.0590781569480896\n",
      "[Step 26910] Loss: 9.51e+07 -1.5549039840698242 0.059071555733680725\n",
      "[Step 26911] Loss: 9.38e+07 -1.5551340579986572 0.05905422568321228\n",
      "[Step 26912] Loss: 9.36e+07 -1.555289626121521 0.05903854966163635\n",
      "[Step 26913] Loss: 9.66e+07 -1.5558326244354248 0.0590071938931942\n",
      "[Step 26914] Loss: 9.69e+07 -1.5567927360534668 0.05894943326711655\n",
      "[Step 26915] Loss: 9.42e+07 -1.5575984716415405 0.05889910086989403\n",
      "[Step 26916] Loss: 9.47e+07 -1.558220386505127 0.05887269601225853\n",
      "[Step 26917] Loss: 9.41e+07 -1.5588713884353638 0.05883391574025154\n",
      "[Step 26918] Loss: 9.46e+07 -1.5594934225082397 0.05879843607544899\n",
      "[Step 26919] Loss: 9.68e+07 -1.5604737997055054 0.0587414987385273\n",
      "[Step 26920] Loss: 9.41e+07 -1.5613499879837036 0.058693643659353256\n",
      "[Step 26921] Loss: 9.43e+07 -1.5621180534362793 0.05867466330528259\n",
      "[Step 26922] Loss: 9.40e+07 -1.5627654790878296 0.05862680822610855\n",
      "[Step 26923] Loss: 9.54e+07 -1.563578486442566 0.058576472103595734\n",
      "[Step 26924] Loss: 9.40e+07 -1.56419837474823 0.058539342135190964\n",
      "[Step 26925] Loss: 9.40e+07 -1.5646929740905762 0.05850963667035103\n",
      "[Step 26926] Loss: 9.47e+07 -1.5653510093688965 0.05846920609474182\n",
      "[Step 26927] Loss: 9.41e+07 -1.5658327341079712 0.05844857543706894\n",
      "[Step 26928] Loss: 9.48e+07 -1.5661827325820923 0.05843702331185341\n",
      "[Step 26929] Loss: 9.66e+07 -1.5669394731521606 0.05840567126870155\n",
      "[Step 26930] Loss: 9.51e+07 -1.5675280094146729 0.0583784393966198\n",
      "[Step 26931] Loss: 9.38e+07 -1.567960262298584 0.05836358666419983\n",
      "[Step 26932] Loss: 9.45e+07 -1.5683518648147583 0.058370187878608704\n",
      "[Step 26933] Loss: 9.44e+07 -1.5685707330703735 0.05836193636059761\n",
      "[Step 26934] Loss: 9.41e+07 -1.5686726570129395 0.05835286155343056\n",
      "[Step 26935] Loss: 9.50e+07 -1.5685672760009766 0.05837101489305496\n",
      "[Step 26936] Loss: 9.51e+07 -1.5686498880386353 0.058366887271404266\n",
      "[Step 26937] Loss: 9.44e+07 -1.568644404411316 0.05836276337504387\n",
      "[Step 26938] Loss: 9.39e+07 -1.5686070919036865 0.058370187878608704\n",
      "[Step 26939] Loss: 9.71e+07 -1.5690163373947144 0.05834873393177986\n",
      "[Step 26940] Loss: 9.38e+07 -1.5694350004196167 0.058319855481386185\n",
      "[Step 26941] Loss: 9.39e+07 -1.5697131156921387 0.05831078067421913\n",
      "[Step 26942] Loss: 9.38e+07 -1.5699681043624878 0.05829345062375069\n",
      "[Step 26943] Loss: 9.33e+07 -1.570194125175476 0.05827777460217476\n",
      "[Step 26944] Loss: 9.34e+07 -1.5703537464141846 0.058283548802137375\n",
      "[Step 26945] Loss: 9.43e+07 -1.5705595016479492 0.0582728236913681\n",
      "[Step 26946] Loss: 9.53e+07 -1.5709517002105713 0.05824971944093704\n",
      "[Step 26947] Loss: 9.38e+07 -1.5711952447891235 0.05824229121208191\n",
      "[Step 26948] Loss: 9.35e+07 -1.5713366270065308 0.05824971944093704\n",
      "[Step 26949] Loss: 9.69e+07 -1.5718662738800049 0.05823734030127525\n",
      "[Step 26950] Loss: 9.49e+07 -1.5724416971206665 0.05820268765091896\n",
      "[Step 26951] Loss: 9.55e+07 -1.5732481479644775 0.05817050486803055\n",
      "[Step 26952] Loss: 9.45e+07 -1.5740809440612793 0.058137498795986176\n",
      "[Step 26953] Loss: 9.46e+07 -1.5747262239456177 0.058112747967243195\n",
      "[Step 26954] Loss: 9.39e+07 -1.5752313137054443 0.058087993413209915\n",
      "[Step 26955] Loss: 9.34e+07 -1.5755149126052856 0.058065712451934814\n",
      "[Step 26956] Loss: 9.45e+07 -1.5758663415908813 0.05803023278713226\n",
      "[Step 26957] Loss: 9.43e+07 -1.5761295557022095 0.05802610516548157\n",
      "[Step 26958] Loss: 9.43e+07 -1.5763752460479736 0.058003004640340805\n",
      "[Step 26959] Loss: 9.39e+07 -1.5765694379806519 0.05798402428627014\n",
      "[Step 26960] Loss: 9.41e+07 -1.5767141580581665 0.05797494947910309\n",
      "[Step 26961] Loss: 9.46e+07 -1.576891303062439 0.05797164887189865\n",
      "[Step 26962] Loss: 9.37e+07 -1.5769850015640259 0.057957619428634644\n",
      "[Step 26963] Loss: 9.40e+07 -1.5770108699798584 0.0579584464430809\n",
      "[Step 26964] Loss: 9.45e+07 -1.5769275426864624 0.057967521250247955\n",
      "[Step 26965] Loss: 9.44e+07 -1.5768179893493652 0.05797082185745239\n",
      "[Step 26966] Loss: 9.53e+07 -1.5765833854675293 0.05797742307186127\n",
      "[Step 26967] Loss: 9.50e+07 -1.5761774778366089 0.05799640342593193\n",
      "[Step 26968] Loss: 9.50e+07 -1.5760328769683838 0.0580071285367012\n",
      "[Step 26969] Loss: 9.35e+07 -1.575913667678833 0.05801290273666382\n",
      "[Step 26970] Loss: 9.53e+07 -1.575951337814331 0.058004654943943024\n",
      "[Step 26971] Loss: 9.43e+07 -1.5759698152542114 0.058005478233098984\n",
      "[Step 26972] Loss: 9.40e+07 -1.5760027170181274 0.058005478233098984\n",
      "[Step 26973] Loss: 9.40e+07 -1.5760375261306763 0.05799640342593193\n",
      "[Step 26974] Loss: 9.68e+07 -1.576474666595459 0.057979900389909744\n",
      "[Step 26975] Loss: 9.40e+07 -1.5768556594848633 0.057954318821430206\n",
      "[Step 26976] Loss: 9.37e+07 -1.577121615409851 0.057942766696214676\n",
      "[Step 26977] Loss: 9.39e+07 -1.5773630142211914 0.05792791396379471\n",
      "[Step 26978] Loss: 9.47e+07 -1.577633023262024 0.05791636183857918\n",
      "[Step 26979] Loss: 9.42e+07 -1.5777517557144165 0.05789903551340103\n",
      "[Step 26980] Loss: 9.41e+07 -1.5777791738510132 0.05789656192064285\n",
      "[Step 26981] Loss: 9.36e+07 -1.57771635055542 0.05791306123137474\n",
      "[Step 26982] Loss: 9.49e+07 -1.577627182006836 0.05791223794221878\n",
      "[Step 26983] Loss: 9.41e+07 -1.5774644613265991 0.05792544037103653\n",
      "[Step 26984] Loss: 9.37e+07 -1.5771820545196533 0.05792461335659027\n",
      "[Step 26985] Loss: 9.44e+07 -1.5768266916275024 0.05793699249625206\n",
      "[Step 26986] Loss: 9.50e+07 -1.5766948461532593 0.05792296305298805\n",
      "[Step 26987] Loss: 9.46e+07 -1.5764707326889038 0.057932864874601364\n",
      "[Step 26988] Loss: 9.48e+07 -1.57623291015625 0.05793781578540802\n",
      "[Step 26989] Loss: 9.41e+07 -1.5760154724121094 0.057957619428634644\n",
      "[Step 26990] Loss: 9.46e+07 -1.5756988525390625 0.05797164887189865\n",
      "[Step 26991] Loss: 9.44e+07 -1.5754601955413818 0.05799310281872749\n",
      "[Step 26992] Loss: 9.43e+07 -1.5751551389694214 0.0580112561583519\n",
      "[Step 26993] Loss: 9.45e+07 -1.574729323387146 0.05802033096551895\n",
      "[Step 26994] Loss: 9.43e+07 -1.5743235349655151 0.05803188309073448\n",
      "[Step 26995] Loss: 9.60e+07 -1.5737725496292114 0.05806901305913925\n",
      "[Step 26996] Loss: 9.55e+07 -1.5734765529632568 0.0580780915915966\n",
      "[Step 26997] Loss: 9.39e+07 -1.5731396675109863 0.05809871852397919\n",
      "[Step 26998] Loss: 9.68e+07 -1.5732694864273071 0.05808056518435478\n",
      "[Step 26999] Loss: 9.38e+07 -1.573314905166626 0.05807974189519882\n",
      "[Step 27000] Loss: 9.43e+07 -1.5732276439666748 0.05808056518435478\n",
      "[Step 27001] Loss: 9.40e+07 -1.573076844215393 0.05808304250240326\n",
      "[Step 27002] Loss: 9.64e+07 -1.572679042816162 0.058087993413209915\n",
      "[Step 27003] Loss: 9.47e+07 -1.5721477270126343 0.05810697004199028\n",
      "[Step 27004] Loss: 9.60e+07 -1.571874737739563 0.05811027064919472\n",
      "[Step 27005] Loss: 9.49e+07 -1.5717453956604004 0.058125123381614685\n",
      "[Step 27006] Loss: 9.61e+07 -1.571936011314392 0.05811852216720581\n",
      "[Step 27007] Loss: 9.41e+07 -1.572051763534546 0.05810697004199028\n",
      "[Step 27008] Loss: 9.36e+07 -1.5720934867858887 0.0581086203455925\n",
      "[Step 27009] Loss: 9.40e+07 -1.5719701051712036 0.05812017247080803\n",
      "[Step 27010] Loss: 9.37e+07 -1.571792721748352 0.05812924727797508\n",
      "[Step 27011] Loss: 9.62e+07 -1.5713859796524048 0.05815235152840614\n",
      "[Step 27012] Loss: 9.38e+07 -1.5710418224334717 0.058175455778837204\n",
      "[Step 27013] Loss: 9.39e+07 -1.57061767578125 0.05818948522210121\n",
      "[Step 27014] Loss: 9.41e+07 -1.570121169090271 0.05821589007973671\n",
      "[Step 27015] Loss: 9.53e+07 -1.5694881677627563 0.0582282654941082\n",
      "[Step 27016] Loss: 9.43e+07 -1.5688084363937378 0.05824971944093704\n",
      "[Step 27017] Loss: 9.69e+07 -1.5686304569244385 0.05825384333729744\n",
      "[Step 27018] Loss: 9.35e+07 -1.5683784484863281 0.05826292186975479\n",
      "[Step 27019] Loss: 9.42e+07 -1.5680509805679321 0.058281075209379196\n",
      "[Step 27020] Loss: 9.38e+07 -1.5676941871643066 0.05829840153455734\n",
      "[Step 27021] Loss: 9.39e+07 -1.567315697669983 0.05832233279943466\n",
      "[Step 27022] Loss: 9.37e+07 -1.5668262243270874 0.05833470821380615\n",
      "[Step 27023] Loss: 9.39e+07 -1.5663418769836426 0.05835946276783943\n",
      "[Step 27024] Loss: 9.42e+07 -1.5659199953079224 0.058392468839883804\n",
      "[Step 27025] Loss: 9.38e+07 -1.5655817985534668 0.05841144546866417\n",
      "[Step 27026] Loss: 9.38e+07 -1.5652199983596802 0.05843454971909523\n",
      "[Step 27027] Loss: 9.40e+07 -1.5647553205490112 0.058464255183935165\n",
      "[Step 27028] Loss: 9.34e+07 -1.5642688274383545 0.05848075821995735\n",
      "[Step 27029] Loss: 9.51e+07 -1.5639342069625854 0.05850386247038841\n",
      "[Step 27030] Loss: 9.43e+07 -1.5637084245681763 0.058512937277555466\n",
      "[Step 27031] Loss: 9.58e+07 -1.5633376836776733 0.058537691831588745\n",
      "[Step 27032] Loss: 9.66e+07 -1.5633405447006226 0.05852696672081947\n",
      "[Step 27033] Loss: 9.33e+07 -1.5632418394088745 0.05852779000997543\n",
      "[Step 27034] Loss: 9.42e+07 -1.563246726989746 0.058501385152339935\n",
      "[Step 27035] Loss: 9.43e+07 -1.5631645917892456 0.05849973484873772\n",
      "[Step 27036] Loss: 9.62e+07 -1.56343412399292 0.05848405882716179\n",
      "[Step 27037] Loss: 9.43e+07 -1.5636868476867676 0.05847250670194626\n",
      "[Step 27038] Loss: 9.45e+07 -1.564056634902954 0.058453526347875595\n",
      "[Step 27039] Loss: 9.35e+07 -1.5643625259399414 0.05843537300825119\n",
      "[Step 27040] Loss: 9.56e+07 -1.5644346475601196 0.0584188736975193\n",
      "[Step 27041] Loss: 9.42e+07 -1.5643986463546753 0.05841474607586861\n",
      "[Step 27042] Loss: 9.41e+07 -1.5643335580825806 0.05842217430472374\n",
      "[Step 27043] Loss: 9.40e+07 -1.5643175840377808 0.05841474607586861\n",
      "[Step 27044] Loss: 9.56e+07 -1.564628005027771 0.05838256701827049\n",
      "[Step 27045] Loss: 9.47e+07 -1.5649775266647339 0.0583520345389843\n",
      "[Step 27046] Loss: 9.48e+07 -1.565375566482544 0.058344610035419464\n",
      "[Step 27047] Loss: 9.41e+07 -1.565788745880127 0.0583256296813488\n",
      "[Step 27048] Loss: 9.57e+07 -1.566429853439331 0.058303352445364\n",
      "[Step 27049] Loss: 9.59e+07 -1.5672731399536133 0.058257970958948135\n",
      "[Step 27050] Loss: 9.43e+07 -1.5678786039352417 0.05821919068694115\n",
      "[Step 27051] Loss: 9.39e+07 -1.5683635473251343 0.05819938704371452\n",
      "[Step 27052] Loss: 9.43e+07 -1.5687952041625977 0.05818040668964386\n",
      "[Step 27053] Loss: 9.41e+07 -1.5692192316055298 0.05815235152840614\n",
      "[Step 27054] Loss: 9.47e+07 -1.5697102546691895 0.058125946670770645\n",
      "[Step 27055] Loss: 9.38e+07 -1.5701651573181152 0.058113571256399155\n",
      "[Step 27056] Loss: 9.48e+07 -1.5707294940948486 0.0580780915915966\n",
      "[Step 27057] Loss: 9.43e+07 -1.5712236166000366 0.05804508551955223\n",
      "[Step 27058] Loss: 9.48e+07 -1.5717318058013916 0.05801950395107269\n",
      "[Step 27059] Loss: 9.33e+07 -1.5722156763076782 0.05799805372953415\n",
      "[Step 27060] Loss: 9.40e+07 -1.5725798606872559 0.057992275804281235\n",
      "[Step 27061] Loss: 9.38e+07 -1.5729243755340576 0.05798567458987236\n",
      "[Step 27062] Loss: 9.40e+07 -1.5731374025344849 0.057968348264694214\n",
      "[Step 27063] Loss: 9.48e+07 -1.573335886001587 0.05796422064304352\n",
      "[Step 27064] Loss: 9.42e+07 -1.573451042175293 0.057955969125032425\n",
      "[Step 27065] Loss: 9.50e+07 -1.5733891725540161 0.057968348264694214\n",
      "[Step 27066] Loss: 9.43e+07 -1.5733087062835693 0.05798320099711418\n",
      "[Step 27067] Loss: 9.39e+07 -1.5731608867645264 0.058004654943943024\n",
      "[Step 27068] Loss: 9.39e+07 -1.5729366540908813 0.05800795555114746\n",
      "[Step 27069] Loss: 9.37e+07 -1.5726163387298584 0.05802610516548157\n",
      "[Step 27070] Loss: 9.52e+07 -1.5721209049224854 0.05805911123752594\n",
      "[Step 27071] Loss: 9.34e+07 -1.5716077089309692 0.058087993413209915\n",
      "[Step 27072] Loss: 9.36e+07 -1.57111394405365 0.058126773685216904\n",
      "[Step 27073] Loss: 9.39e+07 -1.570628046989441 0.05814327672123909\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/autograd/function.py(575): apply\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/distributions/relaxed_straight_through.py(86): rsample\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/distributions/independent.py(108): rsample\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/distributions/torch_distribution.py(49): __call__\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/runtime.py(345): default_process_message\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/runtime.py(383): apply_stack\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/primitives.py(189): sample\n/tmp/ipykernel_182257/2470522040.py(79): guide\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/trace_messenger.py(191): __call__\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/trace_messenger.py(216): get_trace\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/enum.py(60): get_importance_trace\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(57): _get_trace\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/elbo.py(237): _get_traces\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(193): loss_and_surrogate_loss\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/messenger.py(32): _context_wrap\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/ops/jit.py(98): compiled\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/jit/_trace.py(764): _trace_impl\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/jit/_trace.py(1002): trace\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/ops/jit.py(107): __call__\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(239): loss_and_surrogate_loss\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(250): loss_and_grads\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/svi.py(145): step\n/tmp/ipykernel_182257/1639097067.py(2): <module>\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3670): run_code\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3610): run_ast_nodes\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3365): run_cell_async\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/async_helpers.py(128): _pseudo_sync_runner\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3153): _run_cell\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3098): run_cell\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/zmqshell.py(549): run_cell\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py(449): do_execute\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(778): execute_request\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py(362): execute_request\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(534): process_one\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n/usr/lib/python3.13/asyncio/events.py(89): _run\n/usr/lib/python3.13/asyncio/base_events.py(2034): _run_once\n/usr/lib/python3.13/asyncio/base_events.py(677): run_forever\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/tornado/platform/asyncio.py(205): start\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelapp.py(739): start\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/traitlets/config/application.py(1075): launch_instance\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel_launcher.py(18): <module>\n<frozen runpy>(88): _run_code\n<frozen runpy>(198): _run_module_as_main\nRuntimeError: KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/autograd/function.py(559): apply\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/ops/jit.py(120): __call__\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(239): loss_and_surrogate_loss\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(250): loss_and_grads\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/svi.py(145): step\n  /tmp/ipykernel_182257/1639097067.py(2): <module>\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3670): run_code\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3610): run_ast_nodes\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3365): run_cell_async\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/async_helpers.py(128): _pseudo_sync_runner\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3153): _run_cell\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3098): run_cell\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py(449): do_execute\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(778): execute_request\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py(362): execute_request\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(534): process_one\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /usr/lib/python3.13/asyncio/events.py(89): _run\n  /usr/lib/python3.13/asyncio/base_events.py(2034): _run_once\n  /usr/lib/python3.13/asyncio/base_events.py(677): run_forever\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/tornado/platform/asyncio.py(205): start\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelapp.py(739): start\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/traitlets/config/application.py(1075): launch_instance\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel_launcher.py(18): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m100_000\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     loss = \u001b[43msvi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_factor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_assignments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step % \u001b[32m1\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m      4\u001b[39m         mean_logits = pyro.get_param_store()[\u001b[33m\"\u001b[39m\u001b[33mqz_logits\u001b[39m\u001b[33m\"\u001b[39m].mean().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/svi.py:145\u001b[39m, in \u001b[36mSVI.step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m poutine.trace(param_only=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m params = \u001b[38;5;28mset\u001b[39m(\n\u001b[32m    148\u001b[39m     site[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m].unconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture.trace.nodes.values()\n\u001b[32m    149\u001b[39m )\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py:250\u001b[39m, in \u001b[36mJitTrace_ELBO.loss_and_grads\u001b[39m\u001b[34m(self, model, guide, *args, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_and_grads\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     loss, surrogate_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_and_surrogate_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     surrogate_loss.backward()\n\u001b[32m    254\u001b[39m     loss = loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py:239\u001b[39m, in \u001b[36mJitTrace_ELBO.loss_and_surrogate_loss\u001b[39m\u001b[34m(self, model, guide, *args, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m loss, surrogate_loss\n\u001b[32m    237\u001b[39m     \u001b[38;5;28mself\u001b[39m._loss_and_surrogate_loss = loss_and_surrogate_loss\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loss_and_surrogate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/ops/jit.py:120\u001b[39m, in \u001b[36mCompiledFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m poutine.block(hide=\u001b[38;5;28mself\u001b[39m._param_names):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m poutine.trace(param_only=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompiled\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams_and_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m param_capture.trace.nodes.keys():\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._param_names:\n",
      "\u001b[31mRuntimeError\u001b[39m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/autograd/function.py(575): apply\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/distributions/relaxed_straight_through.py(86): rsample\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/distributions/independent.py(108): rsample\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/distributions/torch_distribution.py(49): __call__\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/runtime.py(345): default_process_message\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/runtime.py(383): apply_stack\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/primitives.py(189): sample\n/tmp/ipykernel_182257/2470522040.py(79): guide\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/trace_messenger.py(191): __call__\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/trace_messenger.py(216): get_trace\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/enum.py(60): get_importance_trace\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(57): _get_trace\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/elbo.py(237): _get_traces\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(193): loss_and_surrogate_loss\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/poutine/messenger.py(32): _context_wrap\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/ops/jit.py(98): compiled\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/jit/_trace.py(764): _trace_impl\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/jit/_trace.py(1002): trace\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/ops/jit.py(107): __call__\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(239): loss_and_surrogate_loss\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(250): loss_and_grads\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/svi.py(145): step\n/tmp/ipykernel_182257/1639097067.py(2): <module>\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3670): run_code\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3610): run_ast_nodes\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3365): run_cell_async\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/async_helpers.py(128): _pseudo_sync_runner\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3153): _run_cell\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3098): run_cell\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/zmqshell.py(549): run_cell\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py(449): do_execute\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(778): execute_request\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py(362): execute_request\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(534): process_one\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n/usr/lib/python3.13/asyncio/events.py(89): _run\n/usr/lib/python3.13/asyncio/base_events.py(2034): _run_once\n/usr/lib/python3.13/asyncio/base_events.py(677): run_forever\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/tornado/platform/asyncio.py(205): start\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelapp.py(739): start\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/traitlets/config/application.py(1075): launch_instance\n/home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel_launcher.py(18): <module>\n<frozen runpy>(88): _run_code\n<frozen runpy>(198): _run_module_as_main\nRuntimeError: KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/torch/autograd/function.py(559): apply\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/ops/jit.py(120): __call__\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(239): loss_and_surrogate_loss\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/trace_elbo.py(250): loss_and_grads\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/pyro/infer/svi.py(145): step\n  /tmp/ipykernel_182257/1639097067.py(2): <module>\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3670): run_code\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3610): run_ast_nodes\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3365): run_cell_async\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/async_helpers.py(128): _pseudo_sync_runner\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3153): _run_cell\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py(3098): run_cell\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/zmqshell.py(549): run_cell\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py(449): do_execute\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(778): execute_request\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/ipkernel.py(362): execute_request\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(437): dispatch_shell\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(534): process_one\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelbase.py(545): dispatch_queue\n  /usr/lib/python3.13/asyncio/events.py(89): _run\n  /usr/lib/python3.13/asyncio/base_events.py(2034): _run_once\n  /usr/lib/python3.13/asyncio/base_events.py(677): run_forever\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/tornado/platform/asyncio.py(205): start\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel/kernelapp.py(739): start\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/traitlets/config/application.py(1075): launch_instance\n  /home/jhaberbe/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/ipykernel_launcher.py(18): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n\n"
     ]
    }
   ],
   "source": [
    "for step in range(100_000):\n",
    "    loss = svi.step(X.float(), K.float(), size_factor.float(), group_assignments=folder.float())\n",
    "    if step % 1 == 0:\n",
    "        mean_logits = pyro.get_param_store()[\"qz_logits\"].mean().item()\n",
    "        percentage_logits_above_0 = (pyro.get_param_store()[\"qz_logits\"] > 0).float().mean().item()\n",
    "        \n",
    "        wandb.log({\n",
    "            \"step\": step,\n",
    "            \"loss\": loss,\n",
    "            \"mean_logits\": mean_logits,\n",
    "            \"percentage_logits_above_0\": percentage_logits_above_0\n",
    "        })\n",
    "        \n",
    "        print(f\"[Step {step}] Loss: {loss:.2e}\", mean_logits, percentage_logits_above_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c018667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pre_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x79ad83d83250>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 79ace7129f60, raw_cell=\"pyro.get_param_store().save(\"/home/jhaberbe/Projec..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/jhaberbe/Projects/indian-buffet-process/notebook/sample-specific-changes.ipynb#X21sZmlsZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBrokenPipeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_init.py:603\u001b[39m, in \u001b[36m_WandbInit._pre_run_cell_hook\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backend.interface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    602\u001b[39m     \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33mpausing backend\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface.py:770\u001b[39m, in \u001b[36mInterfaceBase.publish_pause\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    769\u001b[39m     pause = pb.PauseRequest()\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_shared.py:289\u001b[39m, in \u001b[36mInterfaceShared._publish_pause\u001b[39m\u001b[34m(self, pause)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb.PauseRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(pause=pause)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[39m, in \u001b[36mInterfaceSock._publish\u001b[39m\u001b[34m(self, record, local)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[33m\"\u001b[39m\u001b[33mpb.Record\u001b[39m\u001b[33m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mself\u001b[39m._assign(record)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[39m, in \u001b[36mSockClient.send_record_publish\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m    172\u001b[39m server_req.request_id = record.control.mailbox_slot\n\u001b[32m    173\u001b[39m server_req.record_publish.CopyFrom(record)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[39m, in \u001b[36mSockClient.send_server_request\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[39m, in \u001b[36mSockClient._send_message\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m    149\u001b[39m header = struct.pack(\u001b[33m\"\u001b[39m\u001b[33m<BI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mW\u001b[39m\u001b[33m\"\u001b[39m), raw_size)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[39m, in \u001b[36mSockClient._sendall_with_error_handle\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    128\u001b[39m start_time = time.monotonic()\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     sent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sent == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mBrokenPipeError\u001b[39m: [Errno 32] Broken pipe"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x79ad83d83250>> (for post_run_cell), with arguments args (<ExecutionResult object at 79ace7129fd0, execution_count=30 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 79ace7129f60, raw_cell=\"pyro.get_param_store().save(\"/home/jhaberbe/Projec..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/jhaberbe/Projects/indian-buffet-process/notebook/sample-specific-changes.ipynb#X21sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBrokenPipeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/wandb_init.py:614\u001b[39m, in \u001b[36m_WandbInit._post_run_cell_hook\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    611\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33mresuming backend\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface.py:778\u001b[39m, in \u001b[36mInterfaceBase.publish_resume\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    777\u001b[39m     resume = pb.ResumeRequest()\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_shared.py:293\u001b[39m, in \u001b[36mInterfaceShared._publish_resume\u001b[39m\u001b[34m(self, resume)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb.ResumeRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    292\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(resume=resume)\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[39m, in \u001b[36mInterfaceSock._publish\u001b[39m\u001b[34m(self, record, local)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[33m\"\u001b[39m\u001b[33mpb.Record\u001b[39m\u001b[33m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mself\u001b[39m._assign(record)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[39m, in \u001b[36mSockClient.send_record_publish\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m    172\u001b[39m server_req.request_id = record.control.mailbox_slot\n\u001b[32m    173\u001b[39m server_req.record_publish.CopyFrom(record)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[39m, in \u001b[36mSockClient.send_server_request\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[39m, in \u001b[36mSockClient._send_message\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m    149\u001b[39m header = struct.pack(\u001b[33m\"\u001b[39m\u001b[33m<BI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mW\u001b[39m\u001b[33m\"\u001b[39m), raw_size)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/indian-buffet-process/.venv/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[39m, in \u001b[36mSockClient._sendall_with_error_handle\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    128\u001b[39m start_time = time.monotonic()\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     sent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sent == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mBrokenPipeError\u001b[39m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "pyro.get_param_store().save(\"/home/jhaberbe/Projects/indian-buffet-process/output/choroid-plexus/macrophage-latent-features-05-08-2025.pt\")\n",
    "output = pyro.get_param_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2067422",
   "metadata": {},
   "source": [
    "# Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0d5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "output = torch.load(open(\"/home/jhaberbe/Projects/indian-buffet-process/output/choroid-plexus/macrophage-latent-features-05-08-2025.pt\", \"rb\"), weights_only=False)[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eaf0902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.matrix.ClusterGrid at 0x7b77d07e5550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.clustermap(\n",
    "    pd.DataFrame((output[\"qz_logits\"]).cpu().detach().numpy()).gt(0).iloc[::5],\n",
    "    method=\"ward\",\n",
    "    metric=\"cityblock\",\n",
    "    center=0,\n",
    "    row_colors=adata.obs[\"cogdx\"].iloc[::5].replace({\n",
    "    1: \"blue\",\n",
    "    2: \"orange\",\n",
    "    4: \"red\"\n",
    "}).tolist(),\n",
    "xticklabels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eeab3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_features = pd.DataFrame((output[\"qz_logits\"]).cpu().detach().numpy()).gt(0)\n",
    "latent_features[\"specimen\"] = adata.obs[\"orig.ident\"].tolist()\n",
    "\n",
    "latent_features = latent_features.groupby([\"specimen\"]).sum().div(adata.obs[\"orig.ident\"].value_counts(), axis=0)\n",
    "latent_features[\"group\"] = adata.obs.drop_duplicates(subset=\"orig.ident\").set_index(\"orig.ident\")[\"cogdx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a86a85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running Bayesian beta model for '0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8d19ee636c436bade360fed18f6e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 51.68% certainty based on mean\n",
      "   C > A with 88.78% certainty based on mean\n",
      "   M > A with 87.33% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7ac0c2a36149e9b5779160f64ea7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.18% certainty based on mean\n",
      "   C > A with 79.88% certainty based on mean\n",
      "   M > A with 79.92% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '5'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d81d45cc014d9a86cfa3608525e8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.05% certainty based on mean\n",
      "   C > A with 83.30% certainty based on mean\n",
      "   M > A with 81.80% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '9'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9394a7eedb2a476dab11c7af97f69196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C < M with 50.10% certainty based on mean\n",
      "   C > A with 82.80% certainty based on mean\n",
      "   M > A with 81.90% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '11'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb5d3bc84a74a14801b3a008648d642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C < M with 50.60% certainty based on mean\n",
      "   C > A with 84.45% certainty based on mean\n",
      "   M > A with 84.47% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '14'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcd1f0066e14d2f9f476cfd68528585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.20% certainty based on mean\n",
      "   C > A with 90.42% certainty based on mean\n",
      "   M > A with 90.25% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '16'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c7391a0e1d413ab8de2651a9c5a308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C < M with 50.90% certainty based on mean\n",
      "   C > A with 93.17% certainty based on mean\n",
      "   M > A with 92.50% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '17'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8814f750144e18879872687ec14a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.02% certainty based on mean\n",
      "   C > A with 87.38% certainty based on mean\n",
      "   M > A with 89.12% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '18'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e041e2b4b94f6f9d0907c79396a6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 51.50% certainty based on mean\n",
      "   C > A with 96.85% certainty based on mean\n",
      "   M > A with 96.67% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '19'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65a56829258489bba0a7bce270f9c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 51.12% certainty based on mean\n",
      "   C > A with 86.20% certainty based on mean\n",
      "   M > A with 86.10% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '20'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1f418d676b438dbb99b75acb36ab48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 51.28% certainty based on mean\n",
      "   C > A with 93.08% certainty based on mean\n",
      "   M > A with 92.53% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '22'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc95247859a46e4b2bf880fefe35121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.18% certainty based on mean\n",
      "   C > A with 91.17% certainty based on mean\n",
      "   M > A with 91.88% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '23'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a0fc16016b485ebc5bfc7dc0e0fdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 51.50% certainty based on mean\n",
      "   C > A with 90.85% certainty based on mean\n",
      "   M > A with 90.38% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '24'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35858163681d4a64bab73be46aad1d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.75% certainty based on mean\n",
      "   C > A with 93.15% certainty based on mean\n",
      "   M > A with 92.55% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '26'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31be0b8ac4d44a2ebe7186f32df68df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.98% certainty based on mean\n",
      "   C > A with 87.58% certainty based on mean\n",
      "   M > A with 86.88% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '30'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8ec58f15d3441397ecc04a9f0cb7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 51.10% certainty based on mean\n",
      "   C > A with 93.08% certainty based on mean\n",
      "   M > A with 93.73% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd10d7115ae5475b811a18922a543177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.08% certainty based on mean\n",
      "   C > A with 85.42% certainty based on mean\n",
      "   M > A with 85.17% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '33'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17ae9efc688417aa2e4a09a6009f1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.42% certainty based on mean\n",
      "   C > A with 85.97% certainty based on mean\n",
      "   M > A with 87.17% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '34'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8573cb78bf2c4797b0a97cb1149b18c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C < M with 50.28% certainty based on mean\n",
      "   C > A with 78.88% certainty based on mean\n",
      "   M > A with 79.53% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '35'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6031f17b9ed9425496cd3d0c5b706ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C < M with 50.75% certainty based on mean\n",
      "   C > A with 84.60% certainty based on mean\n",
      "   M > A with 84.03% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '37'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b671002b85457987d660046ab95ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 50.52% certainty based on mean\n",
      "   C > A with 83.10% certainty based on mean\n",
      "   M > A with 83.35% certainty based on mean\n",
      "\n",
      " Running Bayesian beta model for '38'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef995d71149141209d002e745c836475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C > M with 51.52% certainty based on mean\n",
      "   C > A with 81.55% certainty based on mean\n",
      "   M > A with 80.17% certainty based on mean\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "alpha = 0.1\n",
    "groups = [\"C\", \"M\", \"A\"]\n",
    "eps = 1e-3\n",
    "n_samples = 1_000  # reduce if performance is an issue\n",
    "\n",
    "def run_pymc_beta_model(feature_vals, group_labels):\n",
    "    group_idx = pd.Categorical(group_labels, categories=groups).codes\n",
    "    clipped_vals = np.clip(feature_vals, eps, 1 - eps)\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        a = pm.Exponential('a', 1.0, shape=len(groups))\n",
    "        b = pm.Exponential('b', 1.0, shape=len(groups))\n",
    "        \n",
    "        obs = pm.Beta('obs', alpha=a[group_idx], beta=b[group_idx],\n",
    "                      observed=clipped_vals)\n",
    "        \n",
    "        trace = pm.sample(n_samples, tune=1000, chains=4, progressbar=True, target_accept=0.9)\n",
    "        \n",
    "    return trace\n",
    "\n",
    "def credible_difference(trace, param, group1, group2, threshold=0.95):\n",
    "    # Extract posterior samples for group-specific parameter (e.g. alpha[0], alpha[1])\n",
    "    samples1 = trace.posterior[param].sel(a_dim_0=groups.index(group1)).values.flatten()\n",
    "    samples2 = trace.posterior[param].sel(a_dim_0=groups.index(group2)).values.flatten()\n",
    "    \n",
    "    diff = samples1 - samples2\n",
    "    prob_diff = np.mean(diff > 0)  # P(group1 > group2)\n",
    "\n",
    "    # Two-sided\n",
    "    prob = max(prob_diff, 1 - prob_diff)\n",
    "    return prob > threshold, prob\n",
    "\n",
    "# ---- Main Loop ----\n",
    "for feature in latent_features.columns:\n",
    "    if feature == \"group\":\n",
    "        continue\n",
    "    if latent_features[feature].mean() == 1 or latent_features[feature].mean() == 0:\n",
    "        continue\n",
    "\n",
    "    df = latent_features[[feature, \"group\"]].dropna()\n",
    "    if df[\"group\"].nunique() < 2:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n Running Bayesian beta model for '{feature}'\")\n",
    "    trace = run_pymc_beta_model(df[feature].values, df[\"group\"])\n",
    "\n",
    "    # Pairwise group comparisons based on posterior of means\n",
    "    for g1, g2 in combinations(groups, 2):\n",
    "        # Compute posterior means from alpha and beta\n",
    "        a1 = trace.posterior['a'].sel(a_dim_0=groups.index(g1)).values.flatten()\n",
    "        b1 = trace.posterior['b'].sel(b_dim_0=groups.index(g1)).values.flatten()\n",
    "        a2 = trace.posterior['a'].sel(a_dim_0=groups.index(g2)).values.flatten()\n",
    "        b2 = trace.posterior['b'].sel(b_dim_0=groups.index(g2)).values.flatten()\n",
    "\n",
    "        mean1 = a1 / (a1 + b1)\n",
    "        mean2 = a2 / (a2 + b2)\n",
    "\n",
    "        prob_diff = np.mean(mean1 > mean2)\n",
    "        prob = max(prob_diff, 1 - prob_diff)\n",
    "\n",
    "        direction = \">\" if prob_diff > 0.5 else \"<\"\n",
    "        print(f\"   {g1} {direction} {g2} with {prob:.2%} certainty based on mean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39498bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='variable', ylabel='value'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAATBBJREFUeJzt3XtcVHX+P/DXmYEZhtsoIiCIgoGKV7wgoiWabJh2Ic2l8rso+dOtwEuUFm5i5X5D8xKVrGT7NdvdWN02NbcMc0k0FUtByjIvGAqhAyoJchtg5vz+IKemGUyUmYNzXs/HY7bmcz5zPu/jTvDycz7nHEEURRFEREREMqKQugAiIiIie2MAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2XGSuoDOyGg04vz58/Dw8IAgCFKXQ0RERDdAFEVcvXoV/v7+UCiuP8fDAGTF+fPnERgYKHUZREREdBPKysrQs2fP6/ZhALLCw8MDQOsfoKenp8TVEBER0Y2oqalBYGCg6ff49TAAWXHttJenpycDEBER0W3mRpavcBE0ERERyQ4DEBEREckOAxARERHJDtcAERERORCDwYDm5mapy7AJZ2dnKJXKDtmX5AEoMzMTq1atgk6nw9ChQ/Hmm29i1KhRVvt+++23SEtLQ0FBAc6dO4fXXnsNCxcutOhXXl6O5557Dp988gnq6+sREhKCd955ByNHjrTx0RAREUlDFEXodDpcuXJF6lJsqkuXLvDz87vl+/RJGoC2bNmClJQUZGVlITIyEhkZGYiNjcXJkyfh4+Nj0b++vh59+vTB9OnT8fTTT1vd548//oixY8diwoQJ+OSTT9C9e3ecPn0aXbt2tfXhEBERSeZa+PHx8YGrq6vD3chXFEXU19ejsrISANCjR49b2p8giqLYEYXdjMjISERERGDdunUAWu/AHBgYiHnz5uH555+/7meDgoKwcOFCixmg559/HgcOHMDnn39+03XV1NRAq9Wiurqal8ETEVGnZzAYcOrUKfj4+KBbt25Sl2NTly9fRmVlJfr27WtxOqw9v78lWwTd1NSEgoICxMTE/FyMQoGYmBjk5+ff9H537NiBkSNHYvr06fDx8cGwYcPw9ttvX/czer0eNTU1Zi8iIqLbxbU1P66urhJXYnvXjvFW1zlJFoAuXboEg8EAX19fs3ZfX1/odLqb3u/333+P9evXIzQ0FLt27cKTTz6J+fPn4913323zM+np6dBqtaYXH4NBRES3I0c77WVNRx2jw10GbzQaMXz4cLzyyisYNmwY5s6dizlz5iArK6vNz6SmpqK6utr0Kisrs2PFREREZG+SLYL29vaGUqlERUWFWXtFRQX8/Pxuer89evTAgAEDzNrCwsLwwQcftPkZtVoNtVp902MSEdHtp76uHjt35OKHc+cRNigUd8eOg7Oz5BdHk51I9v+0SqXCiBEjkJubi7i4OACtsze5ublITk6+6f2OHTsWJ0+eNGs7deoUevfufSvlEhGRAyk9+wMej1+ISt1FU1v/gaH46z9fg6f2tx+kSbc/SU+BpaSk4O2338a7776L7777Dk8++STq6uqQmJgIAEhISEBqaqqpf1NTE4qKilBUVISmpiaUl5ejqKgIxcXFpj5PP/00Dh06hFdeeQXFxcXIzs7Ghg0bkJSUZPfjIyKizunVl9aZhR8AOPHtafw18x8SVUT2JulcX3x8PC5evIi0tDTodDqEh4cjJyfHtDC6tLQUCsXPGe38+fMYNmyY6f3q1auxevVqREdHIy8vDwAQERGBbdu2ITU1FS+//DKCg4ORkZGBGTNm2PXYiIjo+hoaGsz+AmsvLc0t+DzvkNVtOf/Jxe/uv9POFbUKCQmBRqORZOzf0tTUBJVKJXUZHUrS+wB1VrwPEBGR7R07dgyTJ0+WZOwuQhAEwfIkiEFsQo34gwQVATt37sTgwYNv6rONjY0oKSlBcHAwXFxcfrP/1atX8cQTT2D79u3w9PTE4sWL8eGHHyI8PBwZGRkICgrC7Nmzcfr0aWzfvh1Tp07Fpk2b8MEHHyAtLQ3FxcXo0aMH5s2bh2eeeca0X0EQsG3bNtPSFqD1zs0ZGRmYNWsWzp49i+DgYPzzn//EG2+8gcLCQoSEhCAzMxPR0dG3fKzt+f3N1V5ERCSJkJAQ7Ny5U5Kx16/5G/bv+dKi/bFZD+OB6fdIUFHrn4e9pKSk4MCBA9ixYwd8fX2RlpaGwsJChIeHm/qsXr0aaWlpWLZsGQCgoKAAv//97/Hiiy8iPj4eBw8exFNPPYVu3bph1qxZ7Rp/0aJFyMjIwIABA7B27Vrcf//9KCkpsetNHBmAiIhIEhqN5qZnPG7VK6+9gKTE53Hs6HFTW8y90Vj8wnw4q5wlqclerl69infffRfZ2dmYOHEiAOCdd96Bv7+/Wb+7777bbHZnxowZmDhxIpYuXQoA6Nu3L44fP45Vq1a1OwAlJydj2rRpAID169cjJycH//d//4fFixffwpG1j8PdB4iIiOi3dOmqxXvb1yNt5dOoM1Yi/c1UrM162eHDD9B6w+Dm5mazB49rtVr069fPrN+vHyD+3XffYezYsWZtY8eOxenTp2EwGNpVQ1RUlOnfnZycMHLkSHz33Xft2setYgAiIiLZ6jfwDjShFr2CA6QupdNxc3Nr92cEQcCvlxbf6iMrbIUBiIiISEb69OkDZ2dnHD582NRWXV2NU6dOXfdzYWFhOHDggFnbgQMHzB5K2r17d1y4cMG0/fTp06ivr7fY16FDP1+F19LSgoKCAoSFhd3U8dwsrgEiIiKSEQ8PD8ycOROLFi2Cl5cXfHx8sGzZMigUius+Z+uZZ55BREQEli9fjvj4eOTn52PdunX4y1/+Yupz9913Y926dYiKioLBYMBzzz0HZ2fL04qZmZkIDQ1FWFgYXnvtNfz44494/PHHbXK8beEMEBERkcysXbsWUVFRuO+++xATE4OxY8ciLCzsupfQDx8+HP/617+wefNmDBo0CGlpaXj55ZfNFkCvWbMGgYGBuOuuu/DYY4/h2WeftfqE+hUrVmDFihUYOnQo9u/fjx07dsDb29sWh9omzgARERHJjIeHB9577z3T+7q6Orz00kuYO3cuAODs2bNWPzdt2jTT1VvW+Pv7Y9euXWZtV65csegXFhaGL774ov2FdyAGICIiIpk5evQoTpw4gVGjRqG6uhovv/wyAODBBx+UuDL7YQAiIiKSodWrV+PkyZOmh5N//vnndj8NJSUGICIiIpkZNmwYCgoK7D5uUFCQxWXyUuEiaCIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHV4FRkRE5MDKy8tRVVVlt/G8vLwQEND5Hy7LAEREROSgysvLMWHCBDQ0NNhtTI1Ggz179txwCNq3bx9WrVqFgoICXLhwAdu2bUNcXJxtiwQDEBERkcOqqqpCQ0MDli9+BsGBgTYfr6SsDEtfXYOqqqobDkB1dXUYOnQoHn/8cUydOtXGFf6MAYiIiMjBBQcGIiw0ROoyrLr33ntx77332n1cLoImIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItnhVWBEREQkmdraWhQXF5vel5SUoKioCF5eXujVq5fNxmUAIiIicnAlZWWddpwjR45gwoQJpvcpKSkAgJkzZ2LTpk0dVZoFBiAiIiIH5eXlBY1Gg6WvrrHbmBqNBl5eXjfcf/z48RBF0YYVWccARERE5KACAgKwZ88ePgvMCgYgIiIiBxYQEHBbBBJ741VgREREJDsMQERERCQ7nSIAZWZmIigoCC4uLoiMjMSXX37ZZt9vv/0W06ZNQ1BQEARBQEZGxnX3vWLFCgiCgIULF3Zs0URERHTbkjwAbdmyBSkpKVi2bBkKCwsxdOhQxMbGorKy0mr/+vp69OnTBytWrICfn99193348GG89dZbGDJkiC1KJyIiotuU5AFo7dq1mDNnDhITEzFgwABkZWXB1dUVGzdutNo/IiICq1atwiOPPAK1Wt3mfmtrazFjxgy8/fbb6Nq1q63KJyIiotuQpAGoqakJBQUFiImJMbUpFArExMQgPz//lvadlJSEKVOmmO27LXq9HjU1NWYvIiIiclySBqBLly7BYDDA19fXrN3X1xc6ne6m97t582YUFhYiPT39hvqnp6dDq9WaXoGBgTc9NhEREXV+DncfoLKyMixYsAC7d++Gi4vLDX0mNTXVdOttAKipqWEIIiIih1BeXs4bIVohaQDy9vaGUqlERUWFWXtFRcVvLnBuS0FBASorKzF8+HBTm8FgwL59+7Bu3Tro9XoolUqzz6jV6uuuJyIiIrodlZeXY8L48WhobLTbmBoXF+zJy7vhEJSeno6tW7fixIkT0Gg0GDNmDFauXIl+/frZtE5JA5BKpcKIESOQm5uLuLg4AIDRaERubi6Sk5Nvap8TJ07EsWPHzNoSExPRv39/PPfccxbhh4iIyFFVVVWhobERT05+GP5ePjYf73xVJdbv/DeqqqpuOADt3bsXSUlJiIiIQEtLC5YsWYJ77rkHx48fh5ubm81qlfwUWEpKCmbOnImRI0di1KhRyMjIQF1dHRITEwEACQkJCAgIMK3naWpqwvHjx03/Xl5ejqKiIri7uyMkJAQeHh4YNGiQ2Rhubm7o1q2bRTsREZEc+Hv5INjXX+oyrMrJyTF7v2nTJvj4+KCgoADjxo2z2biSB6D4+HhcvHgRaWlp0Ol0CA8PR05OjmlhdGlpKRSKn9dqnz9/HsOGDTO9X716NVavXo3o6Gjk5eXZu3wiIiLqQNXV1QDQrifK3wzJAxAAJCcnt3nK69ehJigoCKIotmv/DEZERESdn9FoxMKFCzF27Fibn7XpFAGIiIiIKCkpCd988w32799v87EYgIiIiEhyycnJ+Oijj7Bv3z707NnT5uMxABEREZFkRFHEvHnzsG3bNuTl5SE4ONgu4zIAERERkWSSkpKQnZ2NDz/8EB4eHqYnQWi1Wmg0GpuNywBERETk4M5XVXbacdavXw8AGD9+vFn7O++8g1mzZnVAVdYxABERETkoLy8vaFxcsH7nv+02psbFpV2XsLf3yu6OwgBERETkoAICArAnL4/PArOCAYiIiMiBBQQE3BaBxN4Uv92FiIiIyLEwABEREZHsMAARERGR7DAAERERkewwABERkWxVXLgIJ2hw5ccaqUshO2MAIiIi2WloaMTTf1yKZ+a+DA9FD8xPXIqVL70p2T1pyP4YgIiISHZeeyULuTn7TIHH0GLAexv/jS1/3y5tYWQ3vA8QERHJisFgwI4Pcqxu27ZlJx5JeMjOFdlWeXk5b4RoBQMQERHJiqHFgPq6BqvbrtbU2rka2yovL0d0dDT0er3dxlSr1di7d+9NhaAVK1YgNTUVCxYsQEZGRscX9wsMQEREJCsqtQojR4fjyKEii21jxkXYvyAbqqqqgl6vh6uyG5SCs83HM4jNqNdfRlVVVbsD0OHDh/HWW29hyJAhNqrOHNcAERGR7Dz7wlPw8HQ3a/Pv6Ye58xMkqsi2lIIznBQqm79uNmTV1tZixowZePvtt9G1a9cOPnrrGICIiEh2Bgzuhw8+fQdTH70XevEqZsx+CP/a+Vf4+HpLXZosJSUlYcqUKYiJibHbmAxAREQkS349fDBtxhTUixcx+aGJ8NR6SF2SLG3evBmFhYVIT0+367hcA0RERESSKCsrw4IFC7B79264uLjYdWwGICIiIpJEQUEBKisrMXz4cFObwWDAvn37sG7dOuj1eiiVSpuMzQBEREREkpg4cSKOHTtm1paYmIj+/fvjueees1n4ARiAiIiIHJ5BbAaMdhqnHTw8PDBo0CCzNjc3N3Tr1s2ivaMxABERETkoLy8vqNVq1Osv221MtVoNLy8vu413sxiAiIiIHFRAQAD27t17Wz0KIy8vr+OKuQ4GICIiIgcWEBBwWzyby954HyAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSnU4RgDIzMxEUFAQXFxdERkbiyy+/bLPvt99+i2nTpiEoKAiCICAjI8OiT3p6OiIiIuDh4QEfHx/ExcXh5MmTNjwCIiIiup1IHoC2bNmClJQULFu2DIWFhRg6dChiY2NRWVlptX99fT369OmDFStWwM/Pz2qfvXv3IikpCYcOHcLu3bvR3NyMe+65B3V1dbY8FCIiIrpNSH4Z/Nq1azFnzhwkJiYCALKysvDxxx9j48aNeP755y36R0REICIiAgCsbgeAnJwcs/ebNm2Cj48PCgoKMG7cOIv+er0eer3e9L6mpuamj4eIiIg6P0lngJqamlBQUICYmBhTm0KhQExMDPLz8ztsnOrqagBo886U6enp0Gq1pldgYGCHjU1ERESdj6QB6NKlSzAYDPD19TVr9/X1hU6n65AxjEYjFi5ciLFjx7b5XJHU1FRUV1ebXmVlZR0yNhEREXVOkq8BsrWkpCR888032Lx5c5t91Go1PD09zV5ERERke/v27cP9998Pf39/CIKA7du322VcSQOQt7c3lEolKioqzNorKiraXODcHsnJyfjoo4+wZ88e9OzZ85b3R0RERB2rrq4OQ4cORWZmpl3HlXQRtEqlwogRI5Cbm4u4uDgAraescnNzkZycfNP7FUUR8+bNw7Zt25CXl4fg4OAOqpiIiMixNVX/iIbKCzA0NkLp4gKNTw+otF1tNt69996Le++912b7b4vkV4GlpKRg5syZGDlyJEaNGoWMjAzU1dWZrgpLSEhAQEAA0tPTAbQunD5+/Ljp38vLy1FUVAR3d3eEhIQAaD3tlZ2djQ8//BAeHh6m9URarRYajUaCoyQiIur8mqp/RO25M6b3hoZ61J47A/fed9g0BElB8gAUHx+PixcvIi0tDTqdDuHh4cjJyTEtjC4tLYVC8fOZuvPnz2PYsGGm96tXr8bq1asRHR2NvLw8AMD69esBAOPHjzcb65133sGsWbNsejxERES3q4bKC2206xiAbCE5ObnNU17XQs01QUFBEEXxuvv7re1ERERkydDYaL1d32DnSmzP4a8CIyIiohujdHGx3q52vOUjDEBEREQEAND49Gij/davzO5sOsUpMCIiIpKeStsV7r3vQEOlDgZ9A5RqDTQ+fjZd/1NbW4vi4mLT+5KSEhQVFcHLywu9evWy2bgMQERERGSi0na164LnI0eOYMKECab3KSkpAICZM2di06ZNNhuXAYiIiIgkM378eEkuXuIaICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSTHp6OiIiIuDh4QEfHx/ExcXh5MmTNh+XzwIjIiIik6pT53A+/2s0XLoCjXcX+EcNgVff3jYbb+/evUhKSkJERARaWlqwZMkS3HPPPTh+/Djc3NxsNi4DEBEREQFoDT+nt35mel934RJOb/0MoVPvtlkIysnJMXu/adMm+Pj4oKCgAOPGjbPJmABPgREREdFPzud/3a52W6iurgYAeHl52XQcBiAiIiICADRcutKu9o5mNBqxcOFCjB07FoMGDbLpWDwFRkRERAAAjXcX1F24ZLXdHpKSkvDNN99g//79Nh+LM0BEREQEAPCPGtKu9o6UnJyMjz76CHv27EHPnj1tPh4DEBEREQEAvPr2RujUu+HWwxsKZye49fC26QJoABBFEcnJydi2bRs+++wzBAcH22ysX+IpMCIiIjLx6tvbpoHn15KSkpCdnY0PP/wQHh4e0Ol0AACtVguNRmOzcTkDRERERJJZv349qqurMX78ePTo0cP02rJli03H5QwQERERSUYURUnG5QwQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJTqcIQJmZmQgKCoKLiwsiIyPx5Zdfttn322+/xbRp0xAUFARBEJCRkXHL+yQiIiJ5kTwAbdmyBSkpKVi2bBkKCwsxdOhQxMbGorKy0mr/+vp69OnTBytWrICfn1+H7JOIiIjkRfIAtHbtWsyZMweJiYkYMGAAsrKy4Orqio0bN1rtHxERgVWrVuGRRx6BWq3ukH3q9XrU1NSYvYiIiMhxSRqAmpqaUFBQgJiYGFObQqFATEwM8vPz7bbP9PR0aLVa0yswMPCmxiYiIqLbg6QB6NKlSzAYDPD19TVr9/X1NT0MzR77TE1NRXV1telVVlZ2U2MTERHRzVuxYgUEQcDChQttPhafBQZArVa3eTqNiIhITj7b9Tn+mvkPFJ86i5C+Qfh/Sf+Du2Pvsvm4hw8fxltvvYUhQ4bYfCxA4hkgb29vKJVKVFRUmLVXVFS0ucBZin0SERHJwWe7PsfCuS/gm69OoLGhEd98dQJP/3EpPtv1uU3Hra2txYwZM/D222+ja9euNh3rGkkDkEqlwogRI5Cbm2tqMxqNyM3NRVRUVKfZJxERkRz8NfMfFm2iKOKvf3nPpuMmJSVhypQpZut3bU3yU2ApKSmYOXMmRo4ciVGjRiEjIwN1dXVITEwEACQkJCAgIADp6ekAWhc5Hz9+3PTv5eXlKCoqgru7O0JCQm5on0RERGSp+NRZq+1n2mjvCJs3b0ZhYSEOHz5sszGskTwAxcfH4+LFi0hLS4NOp0N4eDhycnJMi5hLS0uhUPw8UXX+/HkMGzbM9H716tVYvXo1oqOjkZeXd0P7JCIiIkshfYPwzVcnLNrv6Btkk/HKysqwYMEC7N69Gy4uLjYZoy2CKIqiXUe8DdTU1ECr1aK6uhqenp5Sl0NERDZy7NgxTJ48GTt37sTgwYOlLuemNTY2oqSkBMHBwbcUJD7b9Tme/uNS/DIaCIKAjA1/xoR77uyIUs1s374dDz30EJRKpanNYDBAEAQoFAro9XqzbcD1j7U9v78lvxEiERGRFLZu/hjPPrEcXYRgpKWswud7DkldkuTujr0Lr721HIPCw6Bx1WBQeJjNwg8ATJw4EceOHUNRUZHpNXLkSMyYMQNFRUUW4acjSX4KjIiIyN7+9Y8P8ec/rQXQOsNx5tQ5zHs8FW/9Yw0ixw6XuDpp3R17l10uewcADw8PDBo0yKzNzc0N3bp1s2jvaJwBIiIi2dm4PtuizWg04p23/ilBNSQFzgAREZGsNDbqcf4H608GOHum1M7V0K9du6DJ1jgDREREsuLiokZg7wCr20L6Bdu5GpIKAxAREcnO3PkJFm1Ozk6Y/eQMCaohKTAAERGR7Dz48CSsylyGO/r2hlE0YFB4P2x4by2GRdy+l8JT+3ANEBERyVLsfXfDv3d3TJ48Gal/Xn9b3weI2o8zQERERA5CDvc27qhjZAAiIiK6zTk7OwMA6uvrJa7E9q4d47Vjvlk8BUZERHSbUyqV6NKlCyorKwEArq6uEARB4qo6liiKqK+vR2VlJbp06XLLd4lmACIiInIAfn5+AGAKQY6qS5cupmO9FQxAREREDkAQBPTo0QM+Pj5obm6WuhybcHZ27rDngzEAERERORClUmnTh4g6Ci6CJiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZuekbIRYXF+PMmTMYN24cNBoNRFF0uOeO0O1PFEUY9I0QBAWUarXU5RB1KuXl5aiqqpK6DEkVFxeb/VPuvLy8EBAQIHUZdtHuAHT58mXEx8fjs88+gyAIOH36NPr06YPZs2eja9euWLNmjS3qJGq35qs1qCs/B2OTHgDg5OoOt17BUKoYhIjKy8sRHR0NvV4vdSmdwvz586UuoVNQq9XYu3evLEJQuwPQ008/DScnJ5SWliIsLMzUHh8fj5SUFAYg6hSMzU24erYYEI2mtpb6WtSWnIZn34GcrSTZq6qqgl6vh6uyG5SCs9TlUCdgEJtRr7+MqqoqBiBrPv30U+zatQs9e/Y0aw8NDcW5c+c6rDByDA0NDZJMLbuLLdDCaNFu0Dfi1LGv0SRIs/wtJCQEGo1GkrGJrFEKznBSqKQuQ1oiAP6dCFZ+ZDq0dgeguro6uLq6WrRXVVVBzTUW9CvFxcWYPHmy3cddNOdx/E/c/Va3vZr+Cj7df9DOFbXauXMnBg8eLMnYRPQrRgEwKtCafkRAYQQUotRVkZ20OwDddddd+Nvf/obly5cDAARBgNFoxKuvvooJEyZ0eIF0ewsJCcHOnTvtPq6LaADQYtEuAkhJ/RMWSnQKLCQkRJJxiehXjAJg/OUT06+FIYYguWh3AHr11VcxceJEHDlyBE1NTVi8eDG+/fZbVFVV4cCBA7aokW5jGo1GkhkPURRxteQ0WmprzOvx6YGBfo5/bpuIrkPET2Hn1wRA/Gk2iBxeuxdCDBo0CKdOncKdd96JBx98EHV1dZg6dSqOHj2KO+64wxY1ErWbIAjwCAqBa0BvNEKBXfv24zKc4MrwQ0QA2lz0I3IxkFzc1H2AtFot/vSnP3V0LUQdSlAo4NKtOy6f12HxyjXYGT1R6pKIqDMQgDZXPguc/ZGLds8A7du377qvm5GZmYmgoCC4uLggMjISX3755XX7v//+++jfvz9cXFwwePBgizUmtbW1SE5ORs+ePaHRaDBgwABkZWXdVG1EROSAFEZYnur6aSE0yUK7Z4DGjx9v0fbLe6oYDIZ27W/Lli1ISUlBVlYWIiMjkZGRgdjYWJw8eRI+Pj4W/Q8ePIhHH30U6enpuO+++5CdnY24uDgUFhZi0KBBAICUlBR89tln+Mc//oGgoCB8+umneOqpp+Dv748HHnigfQdMRESORyECMLae8hKF1pkfhZGXw8tIu2eAfvzxR7NXZWUlcnJyEBERgU8//bTdBaxduxZz5sxBYmKiaabG1dUVGzdutNr/9ddfx6RJk7Bo0SKEhYVh+fLlGD58ONatW2fqc/DgQcycORPjx49HUFAQ5s6di6FDh/7mzBIREcmIQgSURsDJ0PpPhh9ZaXcA0mq1Zi9vb2/87ne/w8qVK7F48eJ27aupqQkFBQWIiYn5uSCFAjExMcjPz7f6mfz8fLP+ABAbG2vWf8yYMdixYwfKy8shiiL27NmDU6dO4Z577rG6T71ej5qaGrMXEREROa4Oux2ur68vTp482a7PXLp0CQaDAb6+vhb70ul0Vj+j0+l+s/+bb76JAQMGoGfPnlCpVJg0aRIyMzMxbtw4q/tMT083C3WBgYHtOg4iIiK6vbR7DdDXX39t9l4URVy4cAErVqxAeHh4R9V1S958800cOnQIO3bsQO/evbFv3z4kJSXB39/fYvYIAFJTU5GSkmJ6X1NTwxBERETkwNodgMLDwyEIAkTRfPX86NGj21y30xZvb28olUpUVFSYtVdUVMDPz8/qZ/z8/K7bv6GhAUuWLMG2bdswZcoUAMCQIUNQVFSE1atXWw1AarWaj/EgIiKSkXafAispKcH333+PkpISlJSU4Ny5c6ivr8fBgwfRv3//du1LpVJhxIgRyM3NNbUZjUbk5uYiKirK6meioqLM+gPA7t27Tf2bm5vR3NwMhcL80JRKJYxGXt5IRERENzED1Lt37w4tICUlBTNnzsTIkSMxatQoZGRkoK6uDomJiQCAhIQEBAQEID09HQCwYMECREdHY82aNZgyZQo2b96MI0eOYMOGDQAAT09PREdHY9GiRdBoNOjduzf27t2Lv/3tb1i7dm2H1k5ERES3pxsKQG+88cYN73D+/PntKiA+Ph4XL15EWloadDodwsPDkZOTY1roXFpaajabM2bMGGRnZ+OFF17AkiVLEBoaiu3bt5vuAQQAmzdvRmpqKmbMmIGqqir07t0b//u//4snnniiXbURERGRYxLEXy/msSI4OPjGdiYI+P7772+5KKnV1NRAq9Wiuroanp6eUpdDt+jYsWOYPHkydu7cKcmDWYk6o2v/XXg4+cFJoZK6HOoEWoxNuNqiu61/Vrbn9/cNzQCVlJR0SGFEREREnUGH3QeIiIiI6HZxU0+D/+GHH7Bjxw6UlpaiqanJbBsXGhMREVFn1+4AlJubiwceeAB9+vTBiRMnMGjQIJw9exaiKGL48OG2qJGIiIioQ7X7FFhqaiqeffZZHDt2DC4uLvjggw9QVlaG6OhoTJ8+3RY1EhEREXWodgeg7777DgkJCQAAJycnNDQ0wN3dHS+//DJWrlzZ4QUSERERdbR2ByA3NzfTup8ePXrgzJkzpm2XLl3quMqIiIiIbKTda4BGjx6N/fv3IywsDJMnT8YzzzyDY8eOYevWrRg9erQtaiQiIiLqUO0OQGvXrkVtbS0A4KWXXkJtbS22bNmC0NBQXgFGREREt4V2B6BXXnkF//M//wOg9XRYVlZWhxdFREREZEvtXgN08eJFTJo0CYGBgVi0aBG++uorW9RFREREZDPtDkAffvghLly4gKVLl+Lw4cMYPnw4Bg4ciFdeeQVnz561QYlEREREHeumHoXRtWtXzJ07F3l5eTh37hxmzZqFv//97wgJCeno+oiIiIg63C09C6y5uRlHjhzBF198gbNnz8LX17ej6iIiIiKymZsKQHv27MGcOXPg6+uLWbNmwdPTEx999BF++OGHjq6PiIiIqMO1+yqwgIAAVFVVYdKkSdiwYQPuv/9+qNVqW9RGREREZBPtDkAvvvgipk+fji5dutigHCIiIiLba3cAmjNnji3qICIiIrKbW1oETURERHQ7YgAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2Wn3s8CIiG5HotEI3ZHjuHjsNAz6FnS5oycCxg6Fyt1V6tKISAIMQEQkCyW78nHxq1Om95VHT6C6pByDEx+EUu0sYWVEJAWeAiMih6evrsXFr09btl+5iovfFEtQERFJrVPMAGVmZmLVqlXQ6XQYOnQo3nzzTYwaNarN/u+//z6WLl2Ks2fPIjQ0FCtXrsTkyZPN+nz33Xd47rnnsHfvXrS0tGDAgAH44IMP0KtXL1sfDhG1oaGhAcXF9g8cLRVXAFG0uu2HE8W4qGqxb0E/CQkJgUajkWRsIrmTPABt2bIFKSkpyMrKQmRkJDIyMhAbG4uTJ0/Cx8fHov/Bgwfx6KOPIj09Hffddx+ys7MRFxeHwsJCDBo0CABw5swZ3HnnnZg9ezZeeukleHp64ttvv4WLi4u9D4+IfqG4uNjiLyv2ENDVG68/Nt/qtne3ZGP78/vtXFGrnTt3YvDgwZKMTSR3gii28dciO4mMjERERATWrVsHADAajQgMDMS8efPw/PPPW/SPj49HXV0dPvroI1Pb6NGjER4ejqysLADAI488AmdnZ/z973+/qZpqamqg1WpRXV0NT0/Pm9oHdR7Hjh3D5MmT+cumE5BqBggAGg+fhrGy2rxR5QTNuIEQJFoDJOUM0LX/Ljyc/OCkUElSA3UuLcYmXG3R3dY/K9vz+1vSGaCmpiYUFBQgNTXV1KZQKBATE4P8/Hyrn8nPz0dKSopZW2xsLLZv3w6gNUB9/PHHWLx4MWJjY3H06FEEBwcjNTUVcXFxVvep1+uh1+tN72tqam7twIjIKo1GI9kPVkO//ijLO4KKr07B2NICJ58uGPjA3XDt3lWSeohIWpIugr506RIMBgN8fX3N2n19faHT6ax+RqfTXbd/ZWUlamtrsWLFCkyaNAmffvopHnroIUydOhV79+61us/09HRotVrTKzAwsAOOjog6E6XKGUH3REETOwyPrH8ZLqP6MvzInQjAoGh9GYXW9yQbDncVmNFoBAA8+OCDePrppxEeHo7nn38e9913n+kU2a+lpqaiurra9CorK7NnyURkR4IgwCgapS6DpCYCMCgBUdH6Mip/ei91YWQvkp4C8/b2hlKpREVFhVl7RUUF/Pz8rH7Gz8/vuv29vb3h5OSEAQMGmPUJCwvD/v3WFzqq1Wqo1eqbPQwiIrrdGJQAhF81CoBRASgZkOVA0hkglUqFESNGIDc319RmNBqRm5uLqKgoq5+Jiooy6w8Au3fvNvVXqVSIiIjAyZMnzfqcOnUKvXv37uAjICKi244IWIafa9vaaCeHI/ll8CkpKZg5cyZGjhyJUaNGISMjA3V1dUhMTAQAJCQkICAgAOnp6QCABQsWIDo6GmvWrMGUKVOwefNmHDlyBBs2bDDtc9GiRYiPj8e4ceMwYcIE5OTk4D//+Q/y8vKkOEQiIup0RLQZgkgWJA9A8fHxuHjxItLS0qDT6RAeHo6cnBzTQufS0lIoFD9PVI0ZMwbZ2dl44YUXsGTJEoSGhmL79u2mewABwEMPPYSsrCykp6dj/vz56NevHz744APceeeddj8+IiLqZAQAgmh9tkfB019yIXkAAoDk5GQkJydb3WZt1mb69OmYPn36dff5+OOP4/HHH++I8oiIyNEojIARP4UgAYDYGooEroKWi04RgIiIiOxKQOtiZxGtIUgQeUZMZhiAiIhIvq6dDiPZcbj7ABERXY/Y3IIuru5Sl0FEEuMMEBHJQnN9I87uykfDqXP4a+JiNHx+HFe7+sCjp+9vf5iIHA5ngIhIFk5v24Oqk2eBn57/LNbU48S/PoW+pk7awohIEgxAROTw6iqqcLXM8vmCxqYWXDp2WoKKiEhqDEBE5PCaamrb3MYZICJ5YgAiIofn1sMbgsL6Nc7u/t3tXA0RdQYMQETk8FTurvCLGGjR7urjBe8BfSSoiIikxgBERLLQa0IE7rhvHBTdPHC64gc4h/oj7LF7oXDmxbBEcsQARESy4T3oDriM7ofUf2+Ac19/OLmopC6JiCTCAERERESywwBEREREssMARERERLLDAERERESywwBEREREssMARESyYrzagL6+gRCNRqlLISIJ8QYYRCQLjT/WoPjDPDTqLuOVh+egIfdrXFZr0a1/kNSlEZEEGIDIIel/vIzGixUwNuvRTRQxuF+o1CWRxE5tzUXDxSs/NzS14MyOPLh2fwiablrJ6iIiafAUGDmcxkuVqCsrgaGxHqLBABcY8df05XAWecpDrq6WV5qHn5+IRhGXvim2f0FEJDnOAJFDEUURDZUXLNpd1GoYYZCgIuoMWhr019nWaMdKiKiz4AwQORTR0AKxpdnqNmeIdq6GOguPnj5tPvPLMyjAztUQUWfAAEQORVA6QVBa/0XXDMHO1VBn4eSiRuC44Rbt2mB/ePXtJUFFRCQ1BiByKIIgwKW7r0V7c3MzaqGUoCLqLPwiBmLAjMlQBnrjwOljUA0NQt+HfwdBwR+DRHLE//LJ4Wh8esDVvxcUKjUAAU0QsHjlGjQL/LrLnUegL9RDgvDap+/Dqac3FEp+J4jkiv/1k0Ny8faBW2AwlC4uUEHEmiWL0U1shrG5SerSiIioE2AAIodkbG5GbclpGBobAAAKhQIuMOLqWV7yTEREvAze4ZWXl6OqqkrqMuzOXWyB1spl74aGepz8+is0yfR0mJeXFwICeNUTEREDkAMrLy/HhAkT0NDQIHUpdrd47mzMePA+q9teTX8Fn+4/aOeKOgeNRoM9e/YwBBGR7DEAObCqqio0NDRg+eJnEBwYKHU5dqV1c7XaLooiZj/2KBLif2/niqRXUlaGpa+uQVVVFQMQEckeA5AMBAcGIiw0ROoy7EsUIRoNEH5180NRoURIn2CJiiIios6CAYgckyDAoFBCEI1QiCJEAKKggMh7vhARETrJVWCZmZkICgqCi4sLIiMj8eWXX163//vvv4/+/fvDxcUFgwcPxs6dO9vs+8QTT0AQBGRkZHRw1dTpCQJEhRIGpROMSieGHyIiMpH8N8KWLVuQkpKCZcuWobCwEEOHDkVsbCwqKyut9j948CAeffRRzJ49G0ePHkVcXBzi4uLwzTffWPTdtm0bDh06BH9/f1sfBhEREd1GJA9Aa9euxZw5c5CYmIgBAwYgKysLrq6u2Lhxo9X+r7/+OiZNmoRFixYhLCwMy5cvx/Dhw7Fu3TqzfuXl5Zg3bx7ee+89ODs7X7cGvV6PmpoasxfdZkQRgmgERD7wlIiIfpukAaipqQkFBQWIiYkxtSkUCsTExCA/P9/qZ/Lz8836A0BsbKxZf6PRiD/84Q9YtGgRBg4c+Jt1pKenQ6vVml6BMrti6nYnGA1QGlugNBrgZGyBwtDCIERERNclaQC6dOkSDAYDfH3NH17p6+sLnU5n9TM6ne43+69cuRJOTk6YP3/+DdWRmpqK6upq06usrKydR0JSEUQjlKLR7DnvCohQGC1vgkhERHSNw10FVlBQgNdffx2FhYUQBOG3PwBArVZDrVbbuDKyBUE0Wm+H2DoLdIPfASIikhdJA5C3tzeUSiUqKirM2isqKuDn52f1M35+ftft//nnn6OyshK9evUybTcYDHjmmWeQkZGBs2fPduxBkLTaONNlij0/XQYPAEZBwUAEoLhY3s9Du3b8/HOQ9/ETSRqAVCoVRowYgdzcXMTFxQFoXb+Tm5uL5ORkq5+JiopCbm4uFi5caGrbvXs3oqKiAAB/+MMfrK4R+sMf/oDExESbHAdJRxQEq+t9RAAKowGKXyQkQTTCKChlezn8paofIQjCDZ8adnT8cyCSN8lPgaWkpGDmzJkYOXIkRo0ahYyMDNTV1ZnCSkJCAgICApCeng4AWLBgAaKjo7FmzRpMmTIFmzdvxpEjR7BhwwYAQLdu3dCtWzezMZydneHn54d+/frZ9+DI5kRBAfFXa4BEtM72KH91ekwAoBANMIiCLGeCrtbVQhRFPDn5Yfh7+UhdDknsq5KT+PeBXKnLIJKM5AEoPj4eFy9eRFpaGnQ6HcLDw5GTk2Na6FxaWgrFL/7GPmbMGGRnZ+OFF17AkiVLEBoaiu3bt2PQoEFSHUKnV+Lgi7oFQUBXdze4aVzQ0mJA1dVadPVwQ/cuWsu+AMrPn0dNvfweEHte13rq2N/LB8G+vDeW3J2/fFHqEogkJXkAAoDk5OQ2T3nl5eVZtE2fPh3Tp0+/4f3Lfd3P0lfXSF2C3SX94THMfcT6d2TlX97CgYJCO1dERESdSacIQGRbcnwavNrZGaIoWlwJ2NzSgidnJeDJWQkSVSadA4ePYP3f/iF1GUSdn1EAjD+deRBEQGEE5HfW3OExAMmALJ8Gj9YF9QrRYPq5JQIQVGpZ/lkAjn8qlMgqEa1hRvzpJ8FvBRqjABiVv/i8ABgEQGlgCHIwDEDksESFAgZRgCCKgACIkOfiZyLZEgEYlDBLLqIAGAEordxD7FpYsvDTjJC1z9BtiwGIHJsgtF4qT0RWGcTm1kDggATRCUprv+ZEBVoM+tbZILN2wAmuVvclioDB2GSDKjsPg9gsdQl2xQBERCRj9YbLUpdgMxqhG5SCyuq2RkMNABFqQQslnNECPRrFK3AX1FAISov+zWI96loqbVwx2RMDEDm2a0+JR+s9g3gKjMicq7IblIKz1GXYhCA6tXm3eI2iK5T4ORyp4ARnwRVGtAAwD0AiRCgUTvAQrD+hwFEYxGaHDsS/xgBEDkthNEDxi5shijK/EzSRNUrBGU4K67Mktz0RgEGExeplwQilaBn6BAhQQgkoDGZrgQSFEU4KGfy6dNBToW2Rwf+jJEui0Sz8ALwTNJHsCGi9euvXV4EJRkBs69ef0HqVmMLw06WjdqqV7I4BiBySwsrzwYDWn2UCxNYrwojI8QmwvHpLvPY/Vn4O/HJhNH9MODSeCyAiInkR0DrLY0G0vDKMHBYDEDkko6CwuvZRBDj7Q0SAQmw9zWX6SfHTDRIVDEBywVNg5JgEAUZBAcUvnhTfeo8zJdf/EFGrayGIa31kiQGIHJaoUMIgKlrvBA203hCR4YdInkT8aiH0L7bxx4IsMQCRY+OdoInI9HDTX8wH83SX7HENEBEROS4RPz3c9FdTPkZFmzdJJHlgACIiIsdl9eGmQOsTkjk7LGc8BUZEJGOO/DBUAFCIzlC08Xd9g9gC0Wiwc0WdFx+GSkREDs/VxQWAYz8MFQCUUMFT0dOiXRSNaDBegYughQJOMKAJDeKPMEAvQZWdh1qthpeXl9Rl2AUDEBGRDHVx8wAAvPHGGwgJCZG4Gtva9s9P8EH2Tog/XRHqrHLGxHvvRM6He0x9FHCCxtkTL6xYgND+wVKVKjkvLy8EBARIXYZdMAAREclYSEgIBg8eLHUZNjV48GDMnPMY9uUehNpFjd9NjkbC1CSLfi0tLcjbdQhTpz8gQZVkbwxARETk8HoH98Qf/t/vAQCNjXqcK/nBar9T352xZ1kkIV4FRkREsqJWq+Dn72N1W1CfQDtXQ1JhACIiIlkRBAGPP/GYRbtCocCsPz4iQUUkBZ4CIyIi2Xlk5kNQOimx4c2/QXe+EsEhvZCy5EmMvnOk1KWRnTAAERGRLE2f8QD6DwnG5MmT8b+vZzr8YnAyx1NgREREJDsMQERERCQ7DEBEREQkOwxAREREJDsMQEREJEv/+seHePr/vYiuij7404IV2LP7gNQlkR0xABERkexsfncb/vyntajUXQIAnD3zA56e+wIO7T8icWVkLwxAREQkK6IoYmNWtkW70WjEprc2S1ARSaFTBKDMzEwEBQXBxcUFkZGR+PLLL6/b//3330f//v3h4uKCwYMHY+fOnaZtzc3NeO655zB48GC4ubnB398fCQkJOH/+vK0Pg4iIbgN6fRN05yutbjv7fZmdqyGpSB6AtmzZgpSUFCxbtgyFhYUYOnQoYmNjUVlp/ct58OBBPProo5g9ezaOHj2KuLg4xMXF4ZtvvgEA1NfXo7CwEEuXLkVhYSG2bt2KkydP4oEH+HRfIiICXFzU6B3c0+q2vmF32LkakorkAWjt2rWYM2cOEhMTMWDAAGRlZcHV1RUbN2602v/111/HpEmTsGjRIoSFhWH58uUYPnw41q1bBwDQarXYvXs3fv/736Nfv34YPXo01q1bh4KCApSWllrdp16vR01NjdmLiIgc1x/nz7Roc1Y5Y/ZTMySohqQgaQBqampCQUEBYmJiTG0KhQIxMTHIz8+3+pn8/Hyz/gAQGxvbZn8AqK6uhiAI6NKli9Xt6enp0Gq1pldgIJ8GTETkyO6beg9ee2s5QsP6wCi2YMiIAfi/f2Zg6PCBUpdGdiJpALp06RIMBgN8fX3N2n19faHT6ax+RqfTtat/Y2MjnnvuOTz66KPw9PS02ic1NRXV1dWmV1kZzwETETm6iZPG4cVVKagWS/HcS08hfOQgqUsiO3Loh6E2Nzfj97//PURRxPr169vsp1aroVar7VgZERERSUnSAOTt7Q2lUomKigqz9oqKCvj5+Vn9jJ+f3w31vxZ+zp07h88++6zN2R8iIiKSH0lPgalUKowYMQK5ubmmNqPRiNzcXERFRVn9TFRUlFl/ANi9e7dZ/2vh5/Tp0/jvf/+Lbt262eYAiIiI6LYk+SmwlJQUzJw5EyNHjsSoUaOQkZGBuro6JCYmAgASEhIQEBCA9PR0AMCCBQsQHR2NNWvWYMqUKdi8eTOOHDmCDRs2AGgNPw8//DAKCwvx0UcfwWAwmNYHeXl5QaVSSXOgRERE1GlIHoDi4+Nx8eJFpKWlQafTITw8HDk5OaaFzqWlpVAofp6oGjNmDLKzs/HCCy9gyZIlCA0Nxfbt2zFoUOvitfLycuzYsQMAEB4ebjbWnj17MH78eLscFxEREXVekgcgAEhOTkZycrLVbXl5eRZt06dPx/Tp0632DwoKgiiKHVkeERERORjJb4RIREREZG8MQERERCQ7DEBEREQkOwxAREREJDudYhE0EVFHEYwilAYRgggYFQIMSgCCIHVZRNTJMAARkcNQGEQ4N4u4FneURhFKA9CkAkMQEZnhKTAicgyiefi5RiECSsPPfRSG1hd4uwwiWeMMEBE5BEGERfi5RmEUYTQCzs0iFD/lHhFAixNgcOLMEJEccQaIiByCKLSGGusbzcMP0BqWnFpECEbOBBHJEQMQETkGQYCxjZ9oRgXMwo/pIwCUBgYgIjliACIih9HsLMDwi59qIoBmJwGigqe5iMgc1wARkeMQBDSrBLQYr10G39oGUYQI62uEjAxHRLLEGSAicjiiQoBRKfx86bsgoNlZsFgjZFCgzdNmROTYOANEJDPnL1+UugTJqBRKaJ01UAgCalv0qGtpkrokycj5e0AEMAARyc76T96XugRJ9ezaHRqVGt9fPA+D0Sh1OUQkEQYgIpl58t7p8O/WXeoy7M5ZUCLAVQuNkwoA0GI0QNdQg6steokrk8b5yxdlH4ZJ3hiAiGTGv1t3BPv6S12G3an0RrNL4Z0USgS4dUWTileJEckRl/8RkcMTjCLvA0REZhiAiMjhCcw4RPQrDEBE5PCMirYfk8H7ABHJEwMQETk+QUCLlYee8j5ARPLFRdBEJAsGp9ZnhSkN1+4SLcCgxM83SyQiWWEAIiJZEIwiRAFoceaUDxExABGRgxOMIpybf74KzKAQ0ewscOaHSOb4VyEiclyiCFWT+SXwSiOgahIBkZeGEckZAxAROSylwfoT4BUioLj2FAxRhGBkICKSG54CIyKHJVwv1IginJpFU0gSAbQ4tS6WJiLHxwBE8iQaoRBFiABEQcH1IA7KqBAAK3d6FtF6c0Qnw89tAgDnlta+DEFEjo8BiGRHYTRAIf78FHBRNMKoULYGIRk4X1UpdQl21cutK9yc1GZtVfo6eDq7AAqlRX+Dvgklly/bqzzJyO17QPRrDEAkK4JoNAs/QOvf/BVGAwwKx74yyMPNHYIgYP3Of0tdil05K50QM2AERgb3R1NLM/ad/Ar5Z77FlidftNpfr9dj6T/+Yt8iJaJxcYGXl5fUZRBJggFIBkrKyqQuodPo0a0rvLWeFu0CgB/Ky3G1odH+RdnJ1bpaiKKIN954AyEhIVKXI5mA4tHInz8fLW7OUDYYLLZ7BffEzp07JajM/ry8vBAQECB1GUSS6BQBKDMzE6tWrYJOp8PQoUPx5ptvYtSoUW32f//997F06VKcPXsWoaGhWLlyJSZPnmzaLooili1bhrfffhtXrlzB2LFjsX79eoSGhtrjcDoNLy8vaDQaLH11jdSl2IyTUokJUZEYEHIHftDp8Mnez1H/ixAzuF8oxo2KQKNej0/y9uHR+6cgYeqDVvf1yrq/4Iuir+1VuiQ0Gg1GjRrl0L/0rv5QgStnfoBS5YxuA/pArXU3bdNX16K5+AIejZwI9z7+aDlxHqLh5xCkUDkhbPI4uPl2k6J0srP6unp8lnMAGsELhz4vRP/+YXB27hS/FskOBFGU9trPLVu2ICEhAVlZWYiMjERGRgbef/99nDx5Ej4+Phb9Dx48iHHjxiE9PR333XcfsrOzsXLlShQWFmLQoEEAgJUrVyI9PR3vvvsugoODsXTpUhw7dgzHjx+Hi4vLb9ZUU1MDrVaL6upqeHpazhbcTsrLy1FVVSV1GTYhiCK80QzVLx5zaQBwCc5oERTQii1wx8+/3IyiiKuCE7Sw/Fu/AYAOKoc+BQY4/t/4S3YdROXRk6b3gkKBO+4fh25hwag6eRbFO/ZCNPx8CrRr395Qqp3RWFUN1+5e8IsYCE03rRSlk52Vnv0Bj8cvRKXuoqmt/8BQ/PWfr8FT6yFhZXQr2vP7W/IAFBkZiYiICKxbtw4AYDQaERgYiHnz5uH555+36B8fH4+6ujp89NFHprbRo0cjPDwcWVlZEEUR/v7+eOaZZ/Dss88CAKqrq+Hr64tNmzbhkUce+c2aHCkAObL6Cz+g8aLOot3ZwxMuPj1w9cxJyw8pFNB090NDxQVcez64oHSCe9AdcHbjD73bWfXZ8zixeZdFu1KtwtA/TsVXG7bC0Nhksb1f/D3oEuy4oZCsS058Hvs+y7don/XHR5Cy5EkJKqKO0J7f35LO9TU1NaGgoACpqammNoVCgZiYGOTnW34xASA/Px8pKSlmbbGxsdi+fTsAoKSkBDqdDjExMabtWq0WkZGRyM/PtxqA9Ho99Hq96X1NTc2tHBb9QkNDA4qLi22ybx+xCc5W2puu1qDqai2sxhmjET9UVKIJznCBEUYAjQYF8P1Zm9T4ayEhIdBoNHYZqzOy5feh6dtSq+0GfRO+/mSf1fADAGfyj0JVK80sKb8Ptvs+XE9Lcws+zztkdVvOf3Lxu/vvtHNFreT+fbA3SQPQpUuXYDAY4Ovra9bu6+uLEydOWP2MTqez2l+n05m2X2trq8+vpaen46WXXrqpY6DrKy4uNluf1ZG2vLkW/fsEW7Q3NzfjX9t3YPb0aVY/l7ZsGfYfKbRJTb9l586dGDx4sCRjdwa2/D4kjInFA8PGWt32f5s2YubYSVa3bdvxId59LscmNf0Wfh9s9334LV2EIAhWbn1RXl4uWU1y/z7YG1d7AUhNTTWbVaqpqUFgYKCEFTmOkJAQm11R4y62AFbW87Q4q3Hf9EcgotniMQgGAEteWi7ZWh85X30F2Pb7YKyuQ+P+7yzaBRdn/HH5EujzvoFoZRbo4aTZiP/TfJvU9Fv4fbDd9+G3rF/zN+zf86VF+2OzHsYD0++RoCJ+H+xN0gDk7e0NpVKJiooKs/aKigr4+flZ/Yyfn991+1/7Z0VFBXr06GHWJzw83Oo+1Wo11Gq11W10azQajc3+RiOKRtSVlqCp+kdTm1LjCv/gUCicnNF4qRL1F8pMz3gSlE7oEnQHunOtj2Rs+X0AgAtqD5TtOQLR2LrQ2cnVBX2nTYRHgA9qffxx6oNcNNc1AGhdIB0YPQI9IgfZrB66Plt/H67nlddeQFLi8zh29LipLebeaCx+YT6cVdZOrpOjkTQAqVQqjBgxArm5uYiLiwPQugg6NzcXycnJVj8TFRWF3NxcLFy40NS2e/duREVFAQCCg4Ph5+eH3NxcU+CpqanBF198gSef5MI2RyIICrj3vgMtDfUwNNRDoVabLWR28faBqktXNF+tgaBQwNlDC0Ehj7s9y1WPiIHwHtAH1SXnoVA5oUufACicWn/Muft3R/iT03Hl+x9gaGqGNsgfKndXiSsmqXTpqsV729ej8PDXKDtbjrBBfdE37A6pyyI7kvwUWEpKCmbOnImRI0di1KhRyMjIQF1dHRITEwEACQkJCAgIQHp6OgBgwYIFiI6Oxpo1azBlyhRs3rwZR44cwYYNGwAAgiBg4cKF+POf/4zQ0FDTZfD+/v6mkEWOxUnjCieN9V9kCidnqLvyni5y4uymgfcg67/IFE5KePXtbeeKqDMbHjEEwyOGSF0GSUDyABQfH4+LFy8iLS0NOp0O4eHhyMnJMS1iLi0theIXf2sfM2YMsrOz8cILL2DJkiUIDQ3F9u3bTfcAAoDFixejrq4Oc+fOxZUrV3DnnXciJyfnhu4BRERERI5P8vsAdUa8DxAREdHtpz2/v7kggoiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZEfyR2F0Rtdujl1TUyNxJURERHSjrv3evpGHXDAAWXH16lUAQGBgoMSVEBERUXtdvXoVWq32un34LDArjEYjzp8/Dw8PDwiCIHU5RNSBampqEBgYiLKyMj7rj8jBiKKIq1evwt/f3+xB6tYwABGRrPBhx0QEcBE0ERERyRADEBEREckOAxARyYparcayZcugVqulLoWIJMQ1QERERCQ7nAEiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiKHs379egwZMgSenp7w9PREVFQUPvnkE9P2xsZGJCUloVu3bnB3d8e0adNQUVEhYcVEZG+8CoyIHM5//vMfKJVKhIaGQhRFvPvuu1i1ahWOHj2KgQMH4sknn8THH3+MTZs2QavVIjk5GQqFAgcOHJC6dCKyEwYgIpIFLy8vrFq1Cg8//DC6d++O7OxsPPzwwwCAEydOICwsDPn5+Rg9erTElRKRPfAUGBE5NIPBgM2bN6Ourg5RUVEoKChAc3MzYmJiTH369++PXr16IT8/X8JKicienKQugIjIFo4dO4aoqCg0NjbC3d0d27Ztw4ABA1BUVASVSoUuXbqY9ff19YVOp5OmWCKyOwYgInJI/fr1Q1FREaqrq/Hvf/8bM2fOxN69e6Uui4g6CQYgInJIKpUKISEhAIARI0bg8OHDeP311xEfH4+mpiZcuXLFbBaooqICfn5+ElVLRPbGNUBEJAtGoxF6vR4jRoyAs7MzcnNzTdtOnjyJ0tJSREVFSVghEdkTZ4CIyOGkpqbi3nvvRa9evXD16lVkZ2cjLy8Pu3btglarxezZs5GSkgIvLy94enpi3rx5iIqK4hVgRDLCAEREDqeyshIJCQm4cOECtFothgwZgl27duF3v/sdAOC1116DQqHAtGnToNfrERsbi7/85S8SV01E9sT7ABEREZHscA0QERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxAROayzZ89CEAQUFRXd8GdmzZqFuLi46/YZP348Fi5ceEu1EZG0+CgMInJYgYGBuHDhAry9vaUuhYg6GQYgInJITU1NUKlU8PPzk7oUIuqEeAqMiCS3YcMG+Pv7w2g0mrU/+OCDePzxx3HmzBk8+OCD8PX1hbu7OyIiIvDf//7XrG9QUBCWL1+OhIQEeHp6Yu7cuRanwAwGA2bPno3g4GBoNBr069cPr7/+utWaXnrpJXTv3h2enp544okn0NTU1Gb9er0ezz77LAICAuDm5obIyEjk5eXd0p8JEdkWAxARSW769Om4fPky9uzZY2qrqqpCTk4OZsyYgdraWkyePBm5ubk4evQoJk2ahPvvvx+lpaVm+1m9ejWGDh2Ko0ePYunSpRbjGI1G9OzZE++//z6OHz+OtLQ0LFmyBP/617/M+uXm5uK7775DXl4e/vnPf2Lr1q146aWX2qw/OTkZ+fn52Lx5M77++mtMnz4dkyZNwunTp2/xT4aIbEYkIuoEHnzwQfHxxx83vX/rrbdEf39/0WAwWO0/cOBA8c033zS97927txgXF2fWp6SkRAQgHj16tM1xk5KSxGnTppnez5w5U/Ty8hLr6upMbevXrxfd3d1NtURHR4sLFiwQRVEUz507JyqVSrG8vNxsvxMnThRTU1Ovf9BEJBnOABFRpzBjxgx88MEH0Ov1AID33nsPjzzyCBQKBWpra/Hss88iLCwMXbp0gbu7O7777juLGaCRI0f+5jiZmZkYMWIEunfvDnd3d2zYsMFiP0OHDoWrq6vpfVRUFGpra1FWVmaxv2PHjsFgMKBv375wd3c3vfbu3YszZ87czB8FEdkBF0ETUadw//33QxRFfPzxx4iIiMDnn3+O1157DQDw7LPPYvfu3Vi9ejVCQkKg0Wjw8MMPW6zLcXNzu+4YmzdvxrPPPos1a9YgKioKHh4eWLVqFb744oubrru2thZKpRIFBQVQKpVm29zd3W96v0RkWwxARNQpuLi4YOrUqXjvvfdQXFyMfv36Yfjw4QCAAwcOYNasWXjooYcAtIaOs2fPtnuMAwcOYMyYMXjqqadMbdZmab766is0NDRAo9EAAA4dOgR3d3cEBgZa9B02bBgMBgMqKytx1113tbsmIpIGT4ERUacxY8YMfPzxx9i4cSNmzJhhag8NDcXWrVtRVFSEr776Co899pjFFWM3IjQ0FEeOHMGuXbtw6tQpLF26FIcPH7bo19TUhNmzZ+P48ePYuXMnli1bhuTkZCgUlj8y+/btixkzZiAhIQFbt25FSUkJvvzyS6Snp+Pjjz9ud41EZB8MQETUadx9993w8vLCyZMn8dhjj5na165di65du2LMmDG4//77ERsba5odao8//vGPmDp1KuLj4xEZGYnLly+bzQZdM3HiRISGhmLcuHGIj4/HAw88gBdffLHN/b7zzjtISEjAM888g379+iEuLg6HDx9Gr1692l0jEdmHIIqiKHURRERERPbEGSAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikp3/Dxg90YQEDbL4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "module = 30\n",
    "sns.boxplot(\n",
    "    latent_features.reset_index().melt(id_vars=[\"index\", \"group\"]).query(\"variable == @module\"),\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    hue=\"group\",\n",
    ")\n",
    "sns.swarmplot(\n",
    "    latent_features.reset_index().melt(id_vars=[\"index\", \"group\"]).query(\"variable == @module\"),\n",
    "    x=\"variable\",\n",
    "    y=\"value\",\n",
    "    hue=\"group\",\n",
    "    dodge=True,\n",
    "    edgecolor=\"k\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0846af14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LYVE1         0.793833\n",
       "FGF13         0.769718\n",
       "MRC1          0.757403\n",
       "THBS1         0.697261\n",
       "RBPJ          0.674024\n",
       "                ...   \n",
       "CACNA1D      -0.339605\n",
       "IFNLR1       -0.344400\n",
       "SLC7A5       -0.357060\n",
       "AC093895.1   -0.381418\n",
       "SYNDIG1      -0.414010\n",
       "Name: 20, Length: 5336, dtype: float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "table = pd.DataFrame(\n",
    "    output[\"qW_loc\"].cpu().detach().numpy(),\n",
    "    columns=adata[:, (adata.X > 0).mean(axis=0) > 0.05].var_names\n",
    ")\n",
    "\n",
    "module = 20\n",
    "table.T.sort_values(by=module, ascending=False)[module].iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb97e332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SH3BP4        0.495088\n",
       "CADM1         0.491092\n",
       "SULF2         0.474518\n",
       "PADI2         0.464853\n",
       "CXCR4         0.463738\n",
       "                ...   \n",
       "SLC39A14     -0.315872\n",
       "LYVE1        -0.320042\n",
       "AL357522.1   -0.324311\n",
       "PDIA4        -0.335150\n",
       "MIPOL1       -0.354294\n",
       "Name: 23, Length: 5336, dtype: float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = 23\n",
    "table.T.sort_values(by=module, ascending=False)[module].iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe43d52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RASGEF1C     0.655784\n",
       "LINC01141    0.652819\n",
       "DSCAM        0.617452\n",
       "FOXP2        0.591161\n",
       "HS3ST4       0.576612\n",
       "               ...   \n",
       "F13A1       -0.322607\n",
       "MYRIP       -0.338108\n",
       "TTN         -0.342168\n",
       "SIGLEC1     -0.345072\n",
       "THBS1       -0.442212\n",
       "Name: 30, Length: 5336, dtype: float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = 30\n",
    "table.T.sort_values(by=module, ascending=False)[module].iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfb9db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
